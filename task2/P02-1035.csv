col1,col2
"We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model.",{}
We report on the results of applying this system to parsing the UPenn Wall Street Journal (WSJ) treebank.,{}
The model combines full and partial parsing techniques to reach full grammar coverage on unseen data.,{}
The treebank annotations are used to provide partially labeled data for discriminative statistical estimation using exponential models.,{}
Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets.,{}
"On a gold standard of manually annotated f-structures for a subset of the WSJ treebank, this evaluation reaches 79% F-score.",{}
An evaluation on a gold standard of dependency relations for,{}
Statistical parsing using combined systems of handcoded linguistically fine-grained grammars and stochastic disambiguation components has seen considerable progress in recent years.,"{'title': '1 Introduction', 'number': '1'}"
"However, such attempts have so far been confined to a relatively small scale for various reasons.","{'title': '1 Introduction', 'number': '1'}"
"Firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grained statistical parsing systems.","{'title': '1 Introduction', 'number': '1'}"
"Rather, parameter estimation for such models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999).","{'title': '1 Introduction', 'number': '1'}"
"Furthermore, the effort involved in coding broadcoverage grammars by hand has often led to the specialization of grammars to relatively small domains, thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text.","{'title': '1 Introduction', 'number': '1'}"
"The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal (henceforth WSJ) treebank (Marcus et al., 1994).","{'title': '1 Introduction', 'number': '1'}"
"The problem of grammar coverage, i.e. the fact that not all sentences receive an analysis, is tackled in our approach by an extension of a fullfledged Lexical-Functional Grammar (LFG) and a constraint-based parser with partial parsing techniques.","{'title': '1 Introduction', 'number': '1'}"
"In the absence of a complete parse, a socalled “FRAGMENT grammar” allows the input to be analyzed as a sequence of well-formed chunks.","{'title': '1 Introduction', 'number': '1'}"
The set of fragment parses is then chosen on the basis of a fewest-chunk method.,"{'title': '1 Introduction', 'number': '1'}"
With this combination of full and partial parsing techniques we achieve 100% grammar coverage on unseen data.,"{'title': '1 Introduction', 'number': '1'}"
Another goal of this work is the best possible exploitation of the WSJ treebank for discriminative estimation of an exponential model on LFG parses.,"{'title': '1 Introduction', 'number': '1'}"
We define discriminative or conditional criteria with respect to the set of grammar parses consistent with the treebank annotations.,"{'title': '1 Introduction', 'number': '1'}"
Such data can be gathered by applying labels and brackets taken from the treebank annotation to the parser input.,"{'title': '1 Introduction', 'number': '1'}"
The rudimentary treebank annotations are thus used to provide partially labeled data for discriminative estimation of a probability model on linguistically fine-grained parses.,"{'title': '1 Introduction', 'number': '1'}"
"Concerning empirical evaluation of disambiguation performance, we feel that an evaluation measuring matches of predicate-argument relations is more appropriate for assessing the quality of our LFGbased system than the standard measure of matching labeled bracketing on section 23 of the WSJ treebank.","{'title': '1 Introduction', 'number': '1'}"
The first evaluation we present measures matches of predicate-argument relations in LFG fstructures (henceforth the LFG annotation scheme) to a gold standard of manually annotated f-structures for a representative subset of the WSJ treebank.,"{'title': '1 Introduction', 'number': '1'}"
The evaluation measure counts the number of predicateargument relations in the f-structure of the parse selected by the stochastic model that match those in the gold standard annotation.,"{'title': '1 Introduction', 'number': '1'}"
Our parser plus stochastic disambiguator achieves 79% F-score under this evaluation regime.,"{'title': '1 Introduction', 'number': '1'}"
"Furthermore, we employ another metric which maps predicate-argument relations in LFG fstructures to the dependency relations (henceforth the DR annotation scheme) proposed by Carroll et al. (1999).","{'title': '1 Introduction', 'number': '1'}"
Evaluation with this metric measures the matches of dependency relations to Carroll et al.’s gold standard corpus.,"{'title': '1 Introduction', 'number': '1'}"
"For a direct comparison of our results with Carroll et al.’s system, we computed an F-score that does not distinguish different types of dependency relations.","{'title': '1 Introduction', 'number': '1'}"
Under this measure we obtain 76% F-score.,"{'title': '1 Introduction', 'number': '1'}"
This paper is organized as follows.,"{'title': '1 Introduction', 'number': '1'}"
"Section 2 describes the Lexical-Functional Grammar, the constraint-based parser, and the robustness techniques employed in this work.","{'title': '1 Introduction', 'number': '1'}"
In section 3 we present the details of the exponential model on LFG parses and the discriminative statistical estimation technique.,"{'title': '1 Introduction', 'number': '1'}"
Experimental results are reported in section 4.,"{'title': '1 Introduction', 'number': '1'}"
A discussion of results is in section 5.,"{'title': '1 Introduction', 'number': '1'}"
"The grammar used for this project was developed in the ParGram project (Butt et al., 1999).","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"It uses LFG as a formalism, producing c(onstituent)-structures (trees) and f(unctional)-structures (attribute value matrices) as output.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
The c-structures encode constituency.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"F-structures encode predicate-argument relations and other grammatical information, e.g., number, tense.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"The XLE parser (Maxwell and Kaplan, 1993) was used to produce packed representations, specifying all possible grammar analyses of the input.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"The grammar has 314 rules with regular expression right-hand sides which compile into a collection of finite-state machines with a total of 8,759 states and 19,695 arcs.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
The grammar uses several lexicons and two guessers: one guesser for words recognized by the morphological analyzer but not in the lexicons and one for those not recognized.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"As such, most nouns, adjectives, and adverbs have no explicit lexical entry.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"The main verb lexicon contains 9,652 verb stems and 23,525 subcategorization frame-verb stem entries; there are also lexicons for adjectives and nouns with subcategorization frames and for closed class items.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"For estimation purposes using the WSJ treebank, the grammar was modified to parse part of speech tags and labeled bracketing.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
A stripped down version of the WSJ treebank was created that used only those POS tags and labeled brackets relevant for determining grammatical relations.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
The WSJ labeled brackets are given LFG lexical entries which constrain both the c-structure and the f-structure of the parse.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"For example, the WSJ’s ADJP-PRD label must correspond to an AP in the c-structure and an XCOMP in the f-structure.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"In this version of the corpus, all WSJ labels with -SBJ are retained and are restricted to phrases corresponding to SUBJ in the LFG grammar; in addition, it contains NP under VP (OBJ and OBJth in the LFG grammar), all -LGS tags (OBL-AG), all -PRD tags (XCOMP), VP under VP (XCOMP), SBAR- (COMP), and verb POS tags under VP (V in the c-structure).","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"For example, our labeled bracketing of wsj 1305.mrg is [NP-SBJHis credibility] is/VBZ also [PP-PRD on the line] in the investment community.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
Some mismatches between the WSJ labeled bracketing and the LFG grammar remain.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
These often arise when a given constituent fills a grammatical role in more than one clause.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"For example, in wsj 1303.mrg Japan’s Daiwa Securities Co. named Masahiro Dozen president., the noun phrase Masahiro Dozen is labeled as an NP-SBJ.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"However, the LFG grammar treats it as the OBJ of the matrix clause.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"As a result, the labeled bracketed version of this sentence does not receive a full parse, even though its unlabeled, string-only counterpart is wellformed.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"Some other bracketing mismatches remain, usually the result of adjunct attachment.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"Such mismatches occur in part because, besides minor modifications to match the bracketing for special constructions, e.g., negated infinitives, the grammar was not altered to mirror the idiosyncrasies of the WSJ bracketing.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"To increase robustness, the standard grammar has been augmented with a FRAGMENT grammar.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"This grammar parses the sentence as well-formed chunks specified by the grammar, in particular as Ss, NPs, PPs, and VPs.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
These chunks have both c-structures and f-structures corresponding to them.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
Any token that cannot be parsed as one of these chunks is parsed as a TOKEN chunk.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
The TOKENs are also recorded in the c- and f-structures.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
The grammar has a fewest-chunk method for determining the correct parse.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"For example, if a string can be parsed as two NPs and a VP or as one NP and an S, the NP-S option is chosen.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
A sample FRAGMENT c-structure and f-structure are shown in Fig.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"1 for wsj 0231.mrg (The golden share was scheduled to expire at the beginning of), an incomplete sentence; the parser builds one S chunk and then one TOKEN for the stranded preposition.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
A final capability of XLE that increases coverage of the standard-plus-fragment grammar is a SKIMMING technique.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
Skimming is used to avoid timeouts and memory problems.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"When the amount of time or memory spent on a sentence exceeds a threshhold, XLE goes into skimming mode for the constituents whose processing has not been completed.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"When XLE skims these remaining constituents, it does a bounded amount of work per subtree.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
This guarantees that XLE finishes processing a sentence in a polynomial amount of time.,"{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"In parsing section 23, 7.2% of the sentences were skimmed; 26.1% of these resulted in full parses, while 73.9% were FRAGMENT parses.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
"The grammar coverage achieved 100% of section 23 as unseen unlabeled data: 74.7% as full parses, 25.3% FRAGMENT and/or SKIMMED parses.","{'title': '2 Robust Parsing using LFG', 'number': '2'}"
We employed the well-known family of exponential models for stochastic disambiguation.,"{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"In this paper we are concerned with conditional exponential models of the form: where X(y) is the set of parses for sentence y, Zλ(y) = PxEX(y) eλ'f(x) is a normalizing constant, λ = (λ1, ... , λn) E IRn is a vector of log-parameters, f = (f1, ... , fn) is a vector of property-functions fi : X IR for i = 1, ... , n on the set of parses X, and λ f(x) is the vector dot product Pni=1 λifi(x).","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"In our experiments, we used around 1000 complex property-functions comprising information about c-structure, f-structure, and lexical elements in parses, similar to the properties used in Johnson et al. (1999).","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"For example, there are property functions for c-structure nodes and c-structure subtrees, indicating attachment preferences.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
High versus low attachment is indicated by property functions counting the number of recursively embedded phrases.,"{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Other property functions are designed to refer to f-structure attributes, which correspond to grammatical functions in LFG, or to atomic attributevalue pairs in f-structures.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"More complex property functions are designed to indicate, for example, the branching behaviour of c-structures and the (non)parallelism of coordinations on both c-structure and f-structure levels.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Furthermore, properties refering to lexical elements based on an auxiliary distribution approach as presented in Riezler et al. (2000) are included in the model.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses.,"{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001).","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Since the discriminative task is kept in mind during estimation, discriminative methods can yield improved performance.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more complex LFG parses.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"However, instead of retreating to unsupervised estimation techniques or creating small LFG treebanks by hand, we use the labeled bracketing of the WSJ training sections to guide discriminative estimation.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"That is, discriminative criteria are defined with respect to the set ofparses consistent with the WSJ annotations.1 The objective function in our approach, denoted by P(λ), is the joint of the negative log-likelihood −L(λ) and a Gaussian regularization term −G(λ) on the parameters λ.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Let {(yj, zj)Imj=1 be a set of training data, consisting of pairs of sentences y and partial annotations z, let X(y, z) be the set of parses for sentence y consistent with annotation z, and let X(y) be the set of all parses produced by the grammar for sentence y.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Furthermore, let p[f] denote the expectation of function f under distribution p. Then P(λ) can be defined for a conditional exponential model pλ(zIy) as: Intuitively, the goal of estimation is to find model pa'An earlier approach using partially labeled data for estimating stochastics parsers is Pereira and Schabes’s (1992) work on training PCFG from partially bracketed data.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Their approach differs from the one we use here in that Pereira and Schabes take an EM-based approach maximizing the joint likelihood of the parses and strings of their training data, while we maximize the conditional likelihood of the sets of parses given the corresponding strings in a discriminative estimation setting. rameters which make the two expectations in the last equation equal, i.e. which adjust the model parameters to put all the weight on the parses consistent with the annotations, modulo a penalty term from the Gaussian prior for too large or too small weights.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"Since a closed form solution for such parameters is not available, numerical optimization methods have to be used.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
"In our experiments, we applied a conjugate gradient routine, yielding a fast converging optimization algorithm where at each iteration the negative log-likelihood P(λ) and the gradient vector have to be evaluated.2 For our task the gradient takes the form: The derivatives in the gradient vector intuitively are again just a difference of two expectations Note also that this expression shares many common terms with the likelihood function, suggesting an efficient implementation of the optimization routine.","{'title': '3 Discriminative Statistical Estimation from Partially Labeled Data', 'number': '3'}"
The basic training data for our experiments are sections 02-21 of the WSJ treebank.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"As a first step, all sections were parsed, and the packed parse forests unpacked and stored.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"For discriminative estimation, this data set was restricted to sentences which receive a full parse (in contrast to a FRAGMENT or SKIMMED parse) for both its partially labeled and its unlabeled variant.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"Furthermore, only sentences 2An alternative numerical method would be a combination of iterative scaling techniques with a conditional EM algorithm (Jebara and Pentland, 1998).","{'title': '4 Experimental Evaluation', 'number': '4'}"
"However, it has been shown experimentally that conjugate gradient techniques can outperform iterative scaling techniques by far in running time (Minka, 2001). which received at most 1,000 parses were used.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"From this set, sentences of which a discriminative learner cannot possibly take advantage, i.e. sentences where the set of parses assigned to the partially labeled string was not a proper subset of the parses assigned the unlabeled string, were removed.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"These successive selection steps resulted in a final training set consisting of 10,000 sentences, each with parses for partially labeled and unlabeled versions.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"Altogether there were 150,000 parses for partially labeled input and 500,000 for unlabeled input.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"For estimation, a simple property selection procedure was applied to the full set of around 1000 properties.","{'title': '4 Experimental Evaluation', 'number': '4'}"
This procedure is based on a frequency cutoff on instantiations of properties for the parses in the labeled training set.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
The result of this procedure is a reduction of the property vector to about half its size.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Furthermore, a held-out data set was created from section 24 of the WSJ treebank for experimental selection of the variance parameter of the prior distribution.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"This set consists of 120 sentences which received only full parses, out of which the most plausible one was selected manually.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"Two different sets of test data were used: (i) 700 sentences randomly extracted from section 23 of the WSJ treebank and given gold-standard f-structure annotations according to our LFG scheme, and (ii) 500 sentences from the Brown corpus given gold standard annotations by Carroll et al. (1999) according to their dependency relations (DR) scheme.3 Annotating the WSJ test set was bootstrapped by parsing the test sentences using the LFG grammar and also checking for consistency with the Penn Treebank annotation.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"Starting from the (sometimes fragmentary) parser analyses and the Treebank annotations, gold standard parses were created by manual corrections and extensions of the LFG parses.","{'title': '4 Experimental Evaluation', 'number': '4'}"
Manual corrections were necessary in about half of the cases.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
The average sentence length of the WSJ f-structure bank is 19.8 words; the average number of predicate-argument relations in the goldstandard f-structures is 31.2.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Performance on the LFG-annotated WSJ test set was measured using both the LFG and DR metrics, thanks to an f-structure-to-DR annotation mapping.","{'title': '4 Experimental Evaluation', 'number': '4'}"
Performance on the DR-annotated Brown test set was only measured using the DR metric.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"The LFG evaluation metric is based on the comparison of full f-structures, represented as triples relation(predicate, argument).","{'title': '4 Experimental Evaluation', 'number': '4'}"
The predicateargument relations of the f-structure for one parse of the sentence Meridian will pay a premium of $30.5 million to assume $2 billion in deposits. are shown in Fig.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
2.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"The DR annotation for our example sentence, obtained via a mapping from f-structures to Carroll et al’s annotation scheme, is shown in Fig.","{'title': '4 Experimental Evaluation', 'number': '4'}"
3.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Superficially, the LFG and DR representations are very similar.","{'title': '4 Experimental Evaluation', 'number': '4'}"
One difference between the annotation schemes is that the LFG representation in general specifies more relation tuples than the DR representation.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Also, multiple occurences of the same lexical item are indicated explicitly in the LFG representation but not in the DR representation.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"The main conceptual difference between the two annotation schemes is the fact that the DR scheme crucially refers to phrase-structure properties and word order as well as to grammatical relations in the definition of dependency relations, whereas the LFG scheme abstracts away from serialization and phrase-structure.","{'title': '4 Experimental Evaluation', 'number': '4'}"
Facts like this can make a correct mapping of LFG f-structures to DR relations problematic.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Indeed, we believe that we still underestimate by a few points because of DR mapping difficulties.","{'title': '4 Experimental Evaluation', 'number': '4'}"
"4 In our evaluation, we report F-scores for both types of annotation, LFG and DR, and for three types of parse selection, (i) lower bound: random choice of a parse from the set of analyses (averaged over 10 runs), (ii) upper bound: selection of the parse with the best F-score according to the annotation scheme used, and (iii) stochastic: the parse selected by the stochastic disambiguator.","{'title': '4 Experimental Evaluation', 'number': '4'}"
The error reduction row lists the reduction in error rate relative to the upper and lower bounds obtained by the stochastic disambiguation model.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
F-score is defined as 2 × precision × recall/(precision + recall).,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"The effect of the quality of the parses on disambiguation performance can be illustrated by breaking down the F-scores according to whether the parser yields full parses, FRAGMENT, SKIMMED, or SKIMMED+FRAGMENT parses for the test sentences.","{'title': '4 Experimental Evaluation', 'number': '4'}"
The percentages of test examples which belong to the respective classes of quality are listed in the first row of Table 2.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
F-scores broken down according to classes of parse quality are recorded in the following rows.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"The first column shows F-scores for all parses in the test set, as in Table 1.","{'title': '4 Experimental Evaluation', 'number': '4'}"
The second column shows the best F-scores when restricting attention to examples which receive only full parses.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"The third column reports F-scores for examples which receive only non-full parses, i.e.","{'title': '4 Experimental Evaluation', 'number': '4'}"
FRAGMENT or SKIMMED parses or SKIMMED+FRAGMENT parses.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Columns 4-6 break down non-full parses according to examples which receive only FRAGMENT, only SKIMMED, or only SKIMMED+FRAGMENT parses.","{'title': '4 Experimental Evaluation', 'number': '4'}"
Results of the evaluation on Carroll et al.’s Brown test set are given in Table 3.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
Evaluation results for the DR measure applied to the Brown corpus test set broken down according to parse-quality are shown in Table 2.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
In Table 3 we show the DR measure along with an evaluation measure which facilitates a direct comparison of our results to those of Carroll et al. (1999).,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Following Carroll et al. (1999), we count a dependency relation as correct if the gold standard has a relation with the same governor and dependent but perhaps with a different relation-type.","{'title': '4 Experimental Evaluation', 'number': '4'}"
This dependency-only (DO) measure thus does not reflect mismatches between arguments and modifiers in a small number of cases.,"{'title': '4 Experimental Evaluation', 'number': '4'}"
"Note that since for the evaluation on the Brown corpus, no heldout data were available to adjust the variance parameter of a Bayesian model, we used a plain maximumlikelihood model for disambiguation on this test set.","{'title': '4 Experimental Evaluation', 'number': '4'}"
We have presented a first attempt at scaling up a stochastic parsing system combining a hand-coded linguistically fine-grained grammar and a stochastic disambiguation model to the WSJ treebank.,"{'title': '5 Discussion', 'number': '5'}"
Full grammar coverage is achieved by combining specialized constraint-based parsing techniques for LFG grammars with partial parsing techniques.,"{'title': '5 Discussion', 'number': '5'}"
"Furthermore, a maximal exploitation of treebank annotations for estimating a distribution on fine-grained LFG parses is achieved by letting grammar analyses which are consistent with the WSJ labeled bracketing define a gold standard set for discriminative estimation.","{'title': '5 Discussion', 'number': '5'}"
"The combined system trained on WSJ data achieves full grammar coverage and disambiguation performance of 79% F-score on WSJ data, and 76% F-score on the Brown corpus test set.","{'title': '5 Discussion', 'number': '5'}"
"While disambiguation performance of around 79% F-score on WSJ data seems promising, from one perspective it only offers a 3% absolute improvement over a lower bound random baseline.","{'title': '5 Discussion', 'number': '5'}"
"We think that the high lower bound measure highlights an important aspect of symbolic constraintbased grammars (in contrast to treebank grammars): the symbolic grammar already significantly restricts/disambiguates the range of possible analyses, giving the disambiguator a much narrower window in which to operate.","{'title': '5 Discussion', 'number': '5'}"
"As such, it is more appropriate to assess the disambiguator in terms of reduction in error rate (36% relative to the upper bound) than in terms of absolute F-score.","{'title': '5 Discussion', 'number': '5'}"
Both the DR and LFG annotations broadly agree in their measure of error reduction.,"{'title': '5 Discussion', 'number': '5'}"
"The lower reduction in error rate relative to the upper bound for DR evaluation on the Brown corpus can be attributed to a corpus effect that has also been observed by Gildea (2001) for training and testing PCFGs on the WSJ and Brown corpora.5 Breaking down results according to parse quality shows that irrespective of evaluation measure and corpus, around 4% overall performance is lost due to non-full parses, i.e.","{'title': '5 Discussion', 'number': '5'}"
"FRAGMENT, or SKIMMED, or SKIMMED+FRAGMENT parses.","{'title': '5 Discussion', 'number': '5'}"
"Due to the lack of standard evaluation measures and gold standards for predicate-argument matching, a comparison of our results to other stochastic parsing systems is difficult.","{'title': '5 Discussion', 'number': '5'}"
"To our knowledge, so far the only direct point of comparison is the parser of Carroll et al. (1999) which is also evaluated on Carroll et al.’s test corpus.","{'title': '5 Discussion', 'number': '5'}"
"They report an F-score of 75.1% for a DO evaluation that ignores predicate labels, counting only dependencies.","{'title': '5 Discussion', 'number': '5'}"
"Under this measure, our system achieves 76.1% F-score.","{'title': '5 Discussion', 'number': '5'}"
