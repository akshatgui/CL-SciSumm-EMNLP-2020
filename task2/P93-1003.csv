col1,col2
The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus.,{}
The taggers provide part-of-speech categories which are used by finite-state recognizers to extract simple noun phrases for both languages.,{}
Noun phrases are then mapped to each other using an iterative re-estimation algorithm that bears similarities to the Baum-Welch algorithm which is used for training the taggers.,{}
"The algorithm provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated.",{}
"Improvements to the basic algorithm are described, which enable context to be accounted for when constructing the noun phrase mappings.",{}
"Areas of investigation using bilingual corpora have included the following: The work described here makes use of the aligned Canadian Hansards [Gale and Church, 1991b] to obtain noun phrase correspondences between the English and French text.","{'title': 'INTRODUCTION', 'number': '1'}"
The term &quot;correspondence&quot; is used here to signify a mapping between words in two aligned sentences.,"{'title': 'INTRODUCTION', 'number': '1'}"
Consider an English sentence Ei and a French sentence Fi which are assumed to be approximate translations of each other.,"{'title': 'INTRODUCTION', 'number': '1'}"
The subscript i denotes the i'th alignment of sentences in both languages.,"{'title': 'INTRODUCTION', 'number': '1'}"
A word sequence in Ei is defined here as the correspondence of another sequence in Fi if the words of one sequence are considered to represent the words in the other.,"{'title': 'INTRODUCTION', 'number': '1'}"
"Single word correspondences have been investigated [Gale and Church, 1991a] using a statistic operating on contingency tables.","{'title': 'INTRODUCTION', 'number': '1'}"
"An algorithm for producing collocational correspondences has also been described [Smadja, 1992].","{'title': 'INTRODUCTION', 'number': '1'}"
The algorithm involves several steps.,"{'title': 'INTRODUCTION', 'number': '1'}"
English collocations are first extracted from the English side of the corpus.,"{'title': 'INTRODUCTION', 'number': '1'}"
Instances of the English collocation are found and the mutual information is calculated between the instances and various single word candidates in aligned French sentences.,"{'title': 'INTRODUCTION', 'number': '1'}"
The highest ranking candidates are then extended by another word and the procedure is repeated until a corresponding French collocation having the highest mutual information is found.,"{'title': 'INTRODUCTION', 'number': '1'}"
"An alternative approach is described here, which employs simple iterative re-estimation.","{'title': 'INTRODUCTION', 'number': '1'}"
It is used to make correspondences between simple noun phrases that have been isolated in corresponding sentences of each language using finitestate recognizers.,"{'title': 'INTRODUCTION', 'number': '1'}"
The algorithm is applicable for finding single or multiple word correspondences and can accommodate additional kinds of phrases.,"{'title': 'INTRODUCTION', 'number': '1'}"
"In contrast to the other methods that have been mentioned, the algorithm can be extended in a straightforward way to enable correct correspondences to be made in circumstances where numerous low frequency phrases are involved.","{'title': 'INTRODUCTION', 'number': '1'}"
This is important consideration because in large text corpora roughly a third of the word types only occur once.,"{'title': 'INTRODUCTION', 'number': '1'}"
Several applications for bilingual correspondence information have been suggested.,"{'title': 'INTRODUCTION', 'number': '1'}"
"They can be used in bilingual concordances, for automatically constructing bilingual lexicons, and probabilistically quantified correspondences may be useful for statistical translation methods.","{'title': 'INTRODUCTION', 'number': '1'}"
Figure 1 illustrates how the corpus is analyzed.,"{'title': 'COMPONENTS', 'number': '2'}"
The words in sentences are first tagged with their corresponding part-of-speech categories.,"{'title': 'COMPONENTS', 'number': '2'}"
"Each tagger contains a hidden Markov model (HMM), which is trained using samples of raw text from the Hansards for each language.","{'title': 'COMPONENTS', 'number': '2'}"
"The taggers are robust and operate with a low error rate [Kupiec, 19921.","{'title': 'COMPONENTS', 'number': '2'}"
Simple noun phrases (excluding pronouns and digits) are then extracted from the sentences by finite-state recognizers that are specified by regular expressions defined in terms of part-ofspeech categories.,"{'title': 'COMPONENTS', 'number': '2'}"
Simple noun phrases are identified because they are most reliably recognized; it is also assumed that they can be identified unambiguously.,"{'title': 'COMPONENTS', 'number': '2'}"
"The only embedding that is allowed is by prepositional phrases involving &quot;of' in English and &quot;de&quot; in French, as noun phrases involving them can be identified with relatively low error (revisions to this restriction are considered later).","{'title': 'COMPONENTS', 'number': '2'}"
Noun phrases are placed in an index to associate a unique identifier with each one.,"{'title': 'COMPONENTS', 'number': '2'}"
"A noun phrase is defined by its word sequence, excluding any leading determiners.","{'title': 'COMPONENTS', 'number': '2'}"
Singular and plural forms of common nouns are thus distinct and assigned different positions in the index.,"{'title': 'COMPONENTS', 'number': '2'}"
"For each sentence corresponding to an alignment, the index positions of all noun phrases in the sentence are recorded in a separate data structure, providing a compact representation of the corpus.","{'title': 'COMPONENTS', 'number': '2'}"
So far it has been assumed (for the sake of simplicity) that there is always a one-to-one mapping between English and French sentences.,"{'title': 'COMPONENTS', 'number': '2'}"
"In practice, if an alignment program produces blocks of several sentences in one or both languages, this can be accommodated by treating the block instead as a single bigger &quot;compound sentence&quot; in which noun phrases have a higher number of possible correspondences.","{'title': 'COMPONENTS', 'number': '2'}"
Some terminology is necessary to describe the algorithm concisely.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
Let there be L total alignments in the corpus; then Ei is the English sentence for alignment i.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
Let the function 0(E2) be the number of noun phrases identified in the sentence.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"If there are k of them, k = cb(Ei), and they can be referenced by j = 1...k. Considering the j'th noun phrase in sentence Ei, the function p(Ei, j) produces an identifier for the phrase, which is the position of the phrase in the English index.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"If this phrase is at position s, then p(Ei, j) = s. In turn, the French sentence Fi will contain 0(Fi) noun phrases and given the p'th one, its position in the French index will be given by p(Fi,p).","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
It will also be assumed that there are a total of VE and VE phrases in the English and French indexes respectively.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"Finally, the indicator function /0 has the value unity if its argument is true, and zero otherwise.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"Assuming these definitions, the algorithm is stated in Figure 2.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
The equations assume a directionality: finding French &quot;target&quot; correspondences for English &quot;source&quot; phrases.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"The algorithm is reversible, by swapping E with F. The model for correspondence is that a source noun phrase in Ei is responsible for producing the various different target noun phrases in Fi with correspondingly different probabilities.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"Two quantities are calculated; C,.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"(s, t) and Pr(s,t).","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"Computation proceeds by evaluating Equation (1), Equation (2) and then iteratively applying Equations (3) and (2); r increasing with each successive iteration.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"The argument s refers to the English noun phrase npE(s) having position s in the English index, and the argument t refers to the French noun phrase npF(t) at position t in the French index.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
Equation (1) assumes that each English noun phrase in Ei is initially equally likely to correspond to each French noun phrase in Fi.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"All correspondences are thus equally weighted, reflecting a state of ignorance.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"Weights are summed over the corpus, so noun phrases that co-occur in several sentences will have larger sums.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"The weights Co(s, t) can be interpreted as the mean number of times that npF(t) corresponds to npE(s) given the corpus and the initial assumption of equiprobable correspondences.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"These weights can be used to form a new estimate of the probability that npF(t) corresponds to npE(s), by considering the mean number of times npF(t) corresponds to npE(s) as a fraction of the total mean number of correspondences for npE(s), as in Equation (2).","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"The procedure is then iterated using Equations (3), and (2) to obtain successively refined, convergent estimates of the probability that npF(t) corresponds to npE(s).","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
The probability of correspondences can be used as a method of ranking them (occurrence counts can be taken into account as an indication of the reliability of a correspondence).,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"Although Figure 2 defines the coefficients simply, the algorithm is not implemented literally from it.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
The algorithm employs a compact representation of the correspondences for efficient operation.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
An arbitrarily large corpus can be accommodated by segmenting it appropriately.,"{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"The algorithm described here is an instance of a general approach to statistical estimation, represented by the EM algorithm [Dempster et al., 1977].","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"In contrast to reservations that have been expressed [Gale and Church, 1991a] about using the EM algorithm to provide word correspondences, there have been no indications that prohibitive amounts of memory might be required, or that the approach lacks robustness.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"Unlike the other methods that have been mentioned, the approach has the capability to accommodate more context to improve performance.","{'title': 'THE MAPPING ALGORITHM', 'number': '3'}"
"A sample of the aligned corpus comprising 2,600 alignments was used for testing the algorithm (not all of the alignments contained sentences).","{'title': 'RESULTS', 'number': '4'}"
"4,900 distinct English noun phrases and 5,100 distinct French noun phrases were extracted from the sample.","{'title': 'RESULTS', 'number': '4'}"
"When forming correspondences involving long sentences with many clauses, it was observed that the position at which a noun phrase occurred in Ei was very roughly proportional to the corresponding noun phrase in F. .","{'title': 'RESULTS', 'number': '4'}"
"In such cases it was not necessary to form correspondences with all noun phrases in Fi for each noun phrase in E. Instead, the location of a phrase in Ei was mapped linearly to a position in Fi and correspondences were formed for noun phrases occurring in a window around that position.","{'title': 'RESULTS', 'number': '4'}"
"This resulted in a total of 34,000 correspondences.","{'title': 'RESULTS', 'number': '4'}"
The mappings are stable within a few (2-4) iterations.,"{'title': 'RESULTS', 'number': '4'}"
"In discussing results, a selection of examples will be presented that demonstrates the strengths and weaknesses of the algorithm.","{'title': 'RESULTS', 'number': '4'}"
"To give an indication of noun phrase frequency counts in the sample, the highest ranking correspondences are shown in Table 1.","{'title': 'RESULTS', 'number': '4'}"
The figures in columns (1) and (3) indicate the number of instances of the noun phrase to their right.,"{'title': 'RESULTS', 'number': '4'}"
"To give an informal impression of overall performance, the hundred highest ranking correspondences were inspected and of these, ninety were completely correct.","{'title': 'RESULTS', 'number': '4'}"
Less frequently occurring noun phrases are also of interest for purposes of evaluation; some of these are shown in Table 2.,"{'title': 'RESULTS', 'number': '4'}"
The table also illustrates an unembedded English noun phrase having multiple prepositional phrases in its French correspondent.,"{'title': 'RESULTS', 'number': '4'}"
"Organizational acronyms (which may be not be available in general-purpose dictionaries) are also extracted, as the taggers are robust.","{'title': 'RESULTS', 'number': '4'}"
"Even when a noun phrase only occurs once, a correct correspondence can be found if there are only single noun phrases in each sentence of the alignment.","{'title': 'RESULTS', 'number': '4'}"
"This is demonstrated in the last row of Table 2, which is the result of the following alignment: Ei: &quot;The whole issue of free trade has been mentioned.&quot; &quot;On a mentionne la question du libreechange.&quot; Table 3 shows some incorrect correspondences produced by the algorithm (in the table, &quot;usine&quot; means &quot;factory&quot;).","{'title': 'RESULTS', 'number': '4'}"
"The sentences that are responsible for these correspondences illustrate some of the problems associated with the correspondence model: Ei: &quot;They use what is known as the dual system in which there is a mix of on-the-job and offthe-job training.&quot; Fi: &quot;Ils ont recours a une formation mixte, partie en usine et partie hors usine.&quot; The first problem is that the conjunctive modifiers in the English sentence cannot be accommodated by the noun phrase recognizer.","{'title': 'RESULTS', 'number': '4'}"
The tagger also assigned &quot;on-the-job&quot; as a noun when adjectival use would be preferred.,"{'title': 'RESULTS', 'number': '4'}"
"If verb correspondences were included, there is a mismatch between the three that exist in the English sentence and the single one in the French.","{'title': 'RESULTS', 'number': '4'}"
"If the English were to reflect the French for the correspondence model to be appropriate, the noun phrases would perhaps be &quot;part in the factory&quot; and &quot;part out of the factory&quot;.","{'title': 'RESULTS', 'number': '4'}"
"Considered as a translation, this is lame.","{'title': 'RESULTS', 'number': '4'}"
"The majority of errors that occur are not the result of incorrect tagging or noun phrase recognition, but are the result of the approximate nature of the correspondence model.","{'title': 'RESULTS', 'number': '4'}"
"The correspondences in Table 4 are likewise flawed (in the table, &quot;souris&quot; means &quot;mouse&quot; and &quot;tigre de papier&quot; means &quot;paper tiger&quot;): These correspondences are the result of the following sentences: Ei: &quot;It is a roaring rabbit, a toothless tiger.&quot; Fi: &quot;C' est un tigre de papier, un souris qui rugit.&quot; In the case of the alliterative English phrase &quot;roaring rabbit&quot;, the (presumably) rhetorical aspect is preserved as a rhyme in &quot;souris qui rugit&quot;; the result being that &quot;rabbit&quot; corresponds to &quot;souris&quot; (mouse).","{'title': 'RESULTS', 'number': '4'}"
"Here again, even if the best correspondence were made the result would be wrong because of the relatively sophisticated considerations involved in the translation.","{'title': 'RESULTS', 'number': '4'}"
"As regards future possibilities, the algorithm lends itself to a range of improvements and applications, which are outlined next.","{'title': 'EXTENSIONS', 'number': '5'}"
Finding Word Correspondences: The algorithm finds corresponding noun phrases but provides no information about word-level correspondences within them.,"{'title': 'EXTENSIONS', 'number': '5'}"
One possibility is simply to eliminate the tagger and noun phrase recognizer (treating all words as individual phrases of length unity and having a larger number of correspondences).,"{'title': 'EXTENSIONS', 'number': '5'}"
"Alternatively, the following strategy can be adopted, which involves fewer total correspondences.","{'title': 'EXTENSIONS', 'number': '5'}"
"First, the algorithm is used to build noun phrase correspondences, then the phrase pairs that are produced are themselves treated as a bilingual noun phrase corpus.","{'title': 'EXTENSIONS', 'number': '5'}"
"The algorithm is then employed again on this corpus, treating all words as individual phrases.","{'title': 'EXTENSIONS', 'number': '5'}"
This results in a set of single word correspondences for the internal words in noun phrases.,"{'title': 'EXTENSIONS', 'number': '5'}"
"Reducing Ambiguity: The basic algorithm assumes that noun phrases can be uniquely identified in both languages, which is only true for simple noun phrases.","{'title': 'EXTENSIONS', 'number': '5'}"
The problem of prepositional phrase attachment is exemplified by the following correspondences: The correct English and French noun phrases are &quot;Secretary of State for External Affairs&quot; and &quot;secretaire d' Etat aux Affaires exterieures&quot;.,"{'title': 'EXTENSIONS', 'number': '5'}"
"If prepositional phrases involving &quot;for&quot; and &quot;a&quot; were also permitted, these phrases would be correctly identified; however many other adverbial prepositional phrases would also be incorrectly attached to noun phrases.","{'title': 'EXTENSIONS', 'number': '5'}"
"If all embedded prepositional phrases were permitted by the noun phrase recognizer, the algorithm could be used to reduce the degree of ambiguity between alternatives.","{'title': 'EXTENSIONS', 'number': '5'}"
"Consider a sequence npePPe of an unembedded English noun phrase npe followed by a prepositional phrase ppe, and likewise a corresponding French sequence npf ppf.","{'title': 'EXTENSIONS', 'number': '5'}"
Possible interpretations of this are: 1.,"{'title': 'EXTENSIONS', 'number': '5'}"
The prepositional phrase attaches to the noun phrase in both languages.,"{'title': 'EXTENSIONS', 'number': '5'}"
2.,"{'title': 'EXTENSIONS', 'number': '5'}"
The prepositional phrase attaches to the noun phrase in one language and does not in the other.,"{'title': 'EXTENSIONS', 'number': '5'}"
3.,"{'title': 'EXTENSIONS', 'number': '5'}"
The prepositional phrase does not attach to the noun phrase in either language.,"{'title': 'EXTENSIONS', 'number': '5'}"
"If the prepositional phrases attach to the noun phrases in both languages, they are likely to be repeated in most instances of the noun phrase; it is less likely that the same prepositional phrase will be used adverbially with each instance of the noun phrase.","{'title': 'EXTENSIONS', 'number': '5'}"
This provides a heuristic method for reducing ambiguity in noun phrases that occur several times.,"{'title': 'EXTENSIONS', 'number': '5'}"
The only modifications required to the algorithm are that the additional possible noun phrases and correspondences between them must be included.,"{'title': 'EXTENSIONS', 'number': '5'}"
"Given thresholds on the number of occurrences and the probability of the correspondence, the most likely correspondence can be predicted.","{'title': 'EXTENSIONS', 'number': '5'}"
"Including Context: In the algorithm, correspondences between source and target noun phrases are considered irrespectively of other correspondences in an alignment.","{'title': 'EXTENSIONS', 'number': '5'}"
"This does not make the best use of the information available, and can be improved upon.","{'title': 'EXTENSIONS', 'number': '5'}"
"For example, consider the following alignment: &quot;The Bill was introduced just before Christmas.&quot; Fi: &quot;Le projet de loi a ete presente juste avant le conge des Fetes.&quot; Here it is assumed that there are many instances of the correspondence &quot;Bill&quot; and &quot;projet de loi&quot;, but only one instance of &quot;Christmas&quot; and &quot;conge des Fetes&quot;.","{'title': 'EXTENSIONS', 'number': '5'}"
This suggests that &quot;Bill&quot; corresponds to &quot;projet de loi&quot; with a high probability and that &quot;Christmas&quot; likewise corresponds strongly to &quot;conge des Fetes&quot;.,"{'title': 'EXTENSIONS', 'number': '5'}"
"However, the model will assert that &quot;Christmas&quot; corresponds to &quot;projet de loi&quot; and to &quot;conge des Fetes&quot; with equal probability, no matter how likely the correspondence between &quot;Bill&quot; and &quot;projet de loi&quot;.","{'title': 'EXTENSIONS', 'number': '5'}"
The model can be refined to reflect this situation by considering the joint probability that a target npF(t) corresponds to a source npE(s) and all the other possible correspondences in the alignment are produced.,"{'title': 'EXTENSIONS', 'number': '5'}"
"This situation is very similar to that involved in training HMM text taggers, where joint probabilities are computed that a particular word corresponds to a particular part-ofspeech, and the rest of the words in the sentence are also generated (e.g.","{'title': 'EXTENSIONS', 'number': '5'}"
"[Cutting et al., 1992]).","{'title': 'EXTENSIONS', 'number': '5'}"
The algorithm described in this paper provides a practical means for obtaining correspondences between noun phrases in a bilingual corpus.,"{'title': 'CONCLUSION', 'number': '6'}"
Linguistic structure is used in the form of noun phrase recognizers to select phrases for a stochastic model which serves as a means of minimizing errors due to the approximations inherent in the correspondence model.,"{'title': 'CONCLUSION', 'number': '6'}"
"The algorithm is robust, and extensible in several ways.","{'title': 'CONCLUSION', 'number': '6'}"
