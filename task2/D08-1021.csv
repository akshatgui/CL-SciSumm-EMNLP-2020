col1,col2
We improve the quality of paraphrases extracted from parallel corpora by requiring that phrases and their paraphrases be the same syntactic type.,Introduction
This is achieved by parsing the English side of a parallel corpus and altering the phrase extraction algorithm to extract phrase labels alongside bilingual phrase pairs.,Introduction
"In order to retain broad coverage of non-constituent phrases, complex syntactic labels are introduced.",Introduction
A manual evaluation indicates a 19% absolute improvement in paraphrase quality over the baseline method.,Introduction
Paraphrases are alternative ways of expressing the same information.,Experiment/Discussion
Being able to identify or generate paraphrases automatically is useful in a wide range of natural language applications.,Experiment/Discussion
"Recent work has shown how paraphrases can improve question answering through query expansion (Riezler et al., 2007), automatic evaluation of translation and summarization by modeling alternative lexicalization (Kauchak and Barzilay, 2006; Zhou et al., 2006; Owczarzak et al., 2006), and machine translation both by dealing with out of vocabulary words and phrases (Callison-Burch et al., 2006) and by expanding the set of reference translations for minimum error rate training (Madnani et al., 2007).",Experiment/Discussion
"While all applications require the preservation of meaning when a phrase is replaced by its paraphrase, some additionally require the resulting sentence to be grammatical.",Experiment/Discussion
"In this paper we examine the effectiveness of placing syntactic constraints on a commonly used paraphrasing technique that extracts paraphrases from parallel corpora (Bannard and Callison-Burch, 2005).",Experiment/Discussion
The paraphrasing technique employs various aspects of phrase-based statistical machine translation including phrase extraction heuristics to obtain bilingual phrase pairs from word alignments.,Experiment/Discussion
English phrases are considered to be potential paraphrases of each other if they share a common foreign language phrase among their translations.,Experiment/Discussion
Multiple paraphrases are frequently extracted for each phrase and can be ranked using a paraphrase probability based on phrase translation probabilities.,Experiment/Discussion
We find that the quality of the paraphrases that are generated in this fashion improves significantly when they are required to be the same syntactic type as the phrase that they are paraphrasing.,Experiment/Discussion
This constraint: A thorough manual evaluation of the refined paraphrasing technique finds a 19% absolute improvement in the number of paraphrases that are judged to be correct.,Experiment/Discussion
This paper is structured as follows: Section 2 describes related work in syntactic constraints on phrase-based SMT and work utilizing syntax in paraphrase discovery.,Experiment/Discussion
Section 3 details the problems with extracting paraphrases from parallel corpora and our improvements to the technique.,Experiment/Discussion
Section 4 describes our experimental design and evaluation methodology.,Experiment/Discussion
"Section 5 gives the results of our experiments, and Section 6 discusses their implications.",Experiment/Discussion
A number of research efforts have focused on employing syntactic constraints in statistical machine translation.,Experiment/Discussion
Wu (1997) introduced the inversion transduction grammar formalism which treats translation as a process of parallel parsing of the source and target language via a synchronized grammar.,Experiment/Discussion
The synchronized grammar places constraints on which words can be aligned across bilingual sentence pairs.,Experiment/Discussion
"To achieve computational efficiency, the original proposal used only a single non-terminal label rather than a linguistic grammar.",Experiment/Discussion
"Subsequent work used more articulated parses to improve alignment quality by applying cohesion constraints (Fox, 2002; Lin and Cherry, 2002).",Experiment/Discussion
"If two English phrases are in disjoint subtrees in the parse, then the phrasal cohesion constraint prevents them from being aligned to overlapping sequences in the foreign sentence.",Experiment/Discussion
"Other recent work has incorporated constituent and dependency subtrees into the translation rules used by phrase-based systems (Galley et al., 2004; Quirk et al., 2005).",Experiment/Discussion
"Phrase-based rules have also been replaced with synchronous context free grammars (Chiang, 2005) and with tree fragments (Huang and Knight, 2006).",Experiment/Discussion
"A number of techniques for generating paraphrases have employed syntactic information, either in the process of extracting paraphrases from monolingual texts or in the extracted patterns themselves.",Experiment/Discussion
Lin and Pantel (2001) derived paraphrases based on the distributional similarity of paths in dependency trees.,Experiment/Discussion
Barzilay and McKeown (2001) incorporated part-of-speech information and other morphosyntactic clues into their co-training algorithm.,Experiment/Discussion
They extracted paraphrase patterns that incorporate this information.,Experiment/Discussion
Ibrahim et al. (2003) generated structural paraphrases capable of capturing longdistance dependencies.,Experiment/Discussion
Pang et al. (2003) employed a syntax-based algorithm to align equivalent English sentences by merging corresponding nodes in parse trees and compressing them down into a word lattice.,Experiment/Discussion
Perhaps the most closely related work is a recent extension to Bannard and Callison-Burch’s paraphrasing method.,Experiment/Discussion
"Zhao et al. (2008b) extended the method so that it is capable of generating richer paraphrase patterns that include part-of-speech slots, rather than simple lexical and phrasal paraphrases.",Experiment/Discussion
"For example, they extracted patterns such as consider NN → take NN into consideration.",Experiment/Discussion
"To accomplish this, Zhao el al. used dependency parses on the English side of the parallel corpus.",Experiment/Discussion
"Their work differs from the work presented in this paper because their syntactic constraints applied to slots within paraphrase patters, and our constraints apply to the paraphrases themselves.",Experiment/Discussion
Bannard and Callison-Burch (2005) extract paraphrases from bilingual parallel corpora.,Experiment/Discussion
"They give a probabilistic formation of paraphrasing which naturally falls out of the fact that they use techniques from phrase-based statistical machine translation: Phrase translation probabilities p(f|e1) and p(e2|f) are commonly calculated using maximum likelihood estimation (Koehn et al., 2003): where the counts are collected by enumerating all bilingual phrase pairs that are consistent with the word alignments for sentence pairs in a bilingual parallel corpus.",Experiment/Discussion
Various phrase extraction heuristics are possible.,Experiment/Discussion
"Och and Ney (2004) defined consistent bilingual phrase pairs as follows: where f1 is a foreign sentence, ei is an English sentence and A is a set of word alignment points.",Experiment/Discussion
The heuristic allows unaligned words to be included at the boundaries of the source or target language phrases.,Experiment/Discussion
"For example, when enumerating the consistent phrase pairs for the sentence pair given in Figure 1, la igualdad would align not only to equal, but also to create equal, and to create equal.",Experiment/Discussion
In SMT these alternative translations are ranked by the translation probabilities and other feature functions during decoding.,Experiment/Discussion
The interaction between the phrase extraction heuristic and unaligned words results in an undesirable effect for paraphrasing.,Experiment/Discussion
"By Bannard and Callison-Burch’s definition, equal, create equal, and to create equal would be considered paraphrases because they are aligned to the same foreign phrase.",Experiment/Discussion
Tables 1 and 2 show how sub- and super-phrases can creep into the paraphrases: equal can be paraphrased as equal rights and create equal can be paraphrased as equal.,Experiment/Discussion
Obviously when e2 is substituted for e1 the resulting sentence will generally be ungrammatical.,Experiment/Discussion
"The first case could result in equal equal rights, and the second would drop the verb.",Experiment/Discussion
This problem is pervasive.,Experiment/Discussion
"To test its extent we attempted to generate paraphrases for 900,000 phrases using Bannard and Callison-Burch’s method trained on the Europarl corpora (as described in Section 4).",Experiment/Discussion
"It generated a total of 3.7 million paraphrases for 400,000 phrases in the list.1 We observed that 34% of the paraphrases (excluding the phrase itself) were super- or sub-strings of the original phrase.",Experiment/Discussion
The most probable paraphrase was a super- or sub-string of the phrase 73% of the time.,Experiment/Discussion
"There are a number of strategies that might be adopted to alleviate this problem: • We could change the phrase extraction heuristic’s treatment of unaligned words, or we could attempt to ensure that we have fewer unaligned items in our word alignments.",Experiment/Discussion
• The paraphrase criterion could be changed from being e2 =� e1 to specifying that e2 is not sub- or super-string of e1.,Experiment/Discussion
In this paper we adopt a different strategy.,Experiment/Discussion
The essence of our strategy is to constrain paraphrases to be the same syntactic type as the phrases that they are paraphrasing.,Experiment/Discussion
Syntactic constraints can apply in two places: during phrase extraction and when substituting paraphrases into sentences.,Experiment/Discussion
These are described in sections 3.1 and 3.2.,Experiment/Discussion
"When we apply syntactic constraints to the phrase extraction heuristic, we change how bilingual phrase pairs are enumerated and how the component probabilities of the paraphrase probability are calculated.",Experiment/Discussion
"We use the syntactic type s of e1 in a refined version of the paraphrase probability: where p(e2|e1, s(e1)) can be approximated as: We define a new phrase extraction algorithm that operates on an English parse tree P along with foreign sentence f1 , English sentence ei, and word alignment A.",Experiment/Discussion
"We dub this SBP for syntactic bilingual phrases: The SBP phrase extraction algorithm produces tuples containing a foreign phrase, an English phrase and a syntactic label (f, e, s).",Experiment/Discussion
"After enumerating these for all phrase pairs in a parallel corpus, we can calculate p(f|e1, s(e1)) and p(e2|f, s(e1)) as: By redefining the probabilities in this way we partition the space of possible paraphrases by their syntactic categories.",Experiment/Discussion
In order to enumerate all phrase pairs with their syntactic labels we need to parse the English side of the parallel corpus (but not the foreign side).,Experiment/Discussion
This limits the potential applicability of our refined paraphrasing method to languages which have parsers.,Experiment/Discussion
Table 3 gives an example of the refined paraphrases for equal when it occurs as an adjective or adjectival phrase.,Experiment/Discussion
Note that most of the paraphrases that were possible under the baseline model (Table 1) are now excluded.,Experiment/Discussion
"We no longer get the noun equality, the verb equals, the adverb equally, the determier the or the NP equal rights.",Experiment/Discussion
"The paraphrases seem to be higher quality, especially if one considers their fidelity when they replace the original phrase in the context of some sentence.",Experiment/Discussion
We tested the rate of paraphrases that were suband super-strings when we constrain paraphrases based on non-terminal nodes in parse trees.,Experiment/Discussion
"The percent of the best paraphrases being substrings dropped from 73% to 24%, and the overall percent of paraphrases subsuming or being subsumed by the original phrase dropped from 34% to 12%.",Experiment/Discussion
"However, the number of phrases for which we were able to generated paraphrases dropped from 400,000 to 90,000, since we limited ourselves to phrases that were valid syntactic constituents.",Experiment/Discussion
"The number of unique paraphrases dropped from several million to 800,000.",Experiment/Discussion
The fact that we are able to produce paraphrases for a much smaller set of phrases is a downside to using syntactic constraints as we have initially proposed.,Experiment/Discussion
It means that we would not be able to generate paraphrases for phrases such as create equal.,Experiment/Discussion
"Many NLP tasks, such as SMT, which could benefit from paraphrases require broad coverage and may need to paraphrases for phrases which are not syntactic constituents.",Experiment/Discussion
"To generate paraphrases for a wider set of phrases, we change our phrase extraction heuristic again so that it produces phrase pairs for arbitrary spans in the sentence, including spans that aren’t syntactic constituents.",Experiment/Discussion
"We assign every span in a sentence a syntactic label using CCG-style notation (Steedman, 1999), which gives a syntactic role with elements missing on the left and/or right hand sides.",Experiment/Discussion
The function CCG-labels describes the set of CCGlabels for the phrase spanning positions i to i + n in a parse tree P. It generates three complex syntactic labels for the non-syntactic constituent phrase create equal in the parse tree given in Figure 2: We can use these complex labels instead of atomic non-terminal symbols to handle non-constituent phrases.,Experiment/Discussion
"For example, Table 4 shows the paraphrases and syntactic labels that are generated for the non-constituent phrase create equal.",Experiment/Discussion
The paraphrases are significantly better than the paraphrases generated for the phrase by the baseline method (refer back to Table 2).,Experiment/Discussion
The labels shown in the figure are a fraction of those that can be derived for the phrase in the parallel corpus.,Experiment/Discussion
"Each of these corresponds to a different syntactic context, and each has its own set of associated paraphrases.",Experiment/Discussion
"We increase the number of phrases that are paraphrasable from the 90,000 in our initial definition of SBP to 250,000 when we use complex CCG labels.",Experiment/Discussion
"The number of unique paraphrases increases from 800,000 to 3.5 million, which is nearly as many paraphrases that were produced by the baseline method for the sample.",Experiment/Discussion
"In addition to applying syntactic constraints to our phrase extraction algorithm, we can also apply them when we substitute a paraphrase into a sentence.",Experiment/Discussion
"To do so, we limit the paraphrases to be the same syntactic type as the phrase that it is replacing, based on the syntactic labels that are derived from the phrase tree for a test sentence.",Experiment/Discussion
Since each phrase normally has a set of different CCG labels (instead of a single non-termal symbol) we need a way of choosing which label to use when applying the constraint.,Experiment/Discussion
There are several different possibilities for choosing among labels.,Experiment/Discussion
"We could simultaneously choose the best paraphrase and the best label for the phrase in the parse tree of the test sentence: Alternately, we could average over all of the labels that are generated for the phrase in the parse tree: The potential drawback of using Equations 8 and 9 is that the CCG labels for a particular sentence significantly reduces the paraphrases that can be used.",Experiment/Discussion
"For instance, VP/(NP/NNS) is the only label for the paraphrases in Table 4 that is compatible with the parse tree given in Figure 2.",Experiment/Discussion
"Because the CCG labels for a given sentence are so specific, many times there are no matches.",Experiment/Discussion
Therefore we also investigated a looser constraint.,Experiment/Discussion
We choose the highest probability paraphrase with any label (i.e. the set of labels extracted from all parse trees in our parallel corpus): Equation 10 only applies syntactic constraints during phrase extraction and ignores them during substitution.,Experiment/Discussion
"In our experiments, we evaluate the quality of the paraphrases that are generated using Equations 8, 9 and 10.",Experiment/Discussion
We compare their quality against the Bannard and Callison-Burch (2005) baseline.,Experiment/Discussion
We conducted a manual evaluation to evaluate paraphrase quality.,Experiment/Discussion
We evaluated whether paraphrases retained the meaning of their original phrases and whether they remained grammatical when they replaced the original phrase in a sentence.,Experiment/Discussion
"Our paraphrase model was trained using the Europarl corpus (Koehn, 2005).",Experiment/Discussion
"We used ten parallel corpora between English and (each of) Danish, Dutch, Finnish, French, German, Greek, Italian, Portuguese, Spanish, and Swedish, with approximately 30 million words per language for a total of 315 million English words.",Experiment/Discussion
"Automatic word alignments were created for these using Giza++ (Och and Ney, 2003).",Experiment/Discussion
"The English side of each parallel corpus was parsed using the Bikel parser (Bikel, 2002).",Experiment/Discussion
A total of 1.6 million unique sentences were parsed.,Experiment/Discussion
"A trigram language model was trained on these English sentences using the SRI language modeling toolkit (Stolcke, 2002).",Experiment/Discussion
The paraphrase model and language model for the Bannard and Callison-Burch (2005) baseline were trained on the same data to ensure a fair comparison.,Experiment/Discussion
"The test set was the English portion of test sets used in the shared translation task of the ACL2007 Workshop on Statistical Machine Translation (Callison-Burch et al., 2007).",Experiment/Discussion
The test sentences were also parsed with the Bikel parser.,Experiment/Discussion
"The phrases to be evaluated were selected such that there was an even balance of phrase lengths (from one word long up to five words long), with half of the phrases being valid syntactic constituents and half being arbitrary sequences of words.",Experiment/Discussion
410 phrases were selected at random for evaluation.,Experiment/Discussion
"30 items were excluded from our results subsequent to evaluation on the grounds that they consisted solely of punctuation and stop words like determiners, prepositions and pronouns.",Experiment/Discussion
This left a total of 380 unique phrases.,Experiment/Discussion
We produced paraphrases under the following eight conditions: 1.,Experiment/Discussion
Baseline – The paraphrase probability defined by Bannard and Callison-Burch (2005).,Experiment/Discussion
Calculated over multiple parallel corpora as given in Equation 5.,Experiment/Discussion
Note that under this condition the best paraphrase is the same for each occurrence of the phrase irrespective of which sentence it occurs in.,Experiment/Discussion
2.,Experiment/Discussion
Baseline + LM – The paraphrase probability (as above) combined with the language model probability calculated for the sentence with the phrase replaced with the paraphrase.,Experiment/Discussion
3.,Experiment/Discussion
Extraction Constraints – This condition selected the best paraphrase according to Equation 10.,Experiment/Discussion
It chooses the single best paraphrase over all labels.,Experiment/Discussion
"Conditions 3 and 5 only apply the syntactic constraints at the phrase extraction stage, and do not require that the paraphrase have the same syntactic label as the phrase in the sentence that it is being subtituted into. corresponds to Equation 8, which selects the highest probability paraphrase which matches at least one of the syntactic labels of the phrase in the test sentence.",Experiment/Discussion
"Conditions 5–8 apply the syntactic constraints both and the phrase extraction and at the substitution stages. condition corresponds to Equation 9, which averages over all of the syntactic labels for the phrase in the sentence, instead of choosing the single one which maximizes the probability.",Experiment/Discussion
8.,Experiment/Discussion
"Averaged Substitution Constraints + LM – As above, but including a language model probability.",Experiment/Discussion
We evaluated the paraphrase quality through a substitution test.,Experiment/Discussion
We retrieved a number of sentences which contained each test phrase and substituted the phrase with automatically-generated paraphrases.,Experiment/Discussion
Annotators judged whether the paraphrases had the same meaning as the original and whether the resulting sentences were grammatical.,Experiment/Discussion
They assigned two values to each sentence using the 5-point scales given in Table 5.,Experiment/Discussion
"We considered an item to have the same meaning if it was assigned a score of 3 or greater, and to be grammatical if it was assigned a score of 4 or 5.",Experiment/Discussion
"We evaluated several instances of a phrase when it occurred multiple times in the test corpus, since paraphrase quality can vary based on context (Szpektor et al., 2007).",Experiment/Discussion
"There were an average of 3.1 instances for each phrase, with a maximum of 6.",Experiment/Discussion
"There were a total of 1,195 sentences that paraphrases were substituted into, with a total of 8,422 judgements collected.",Experiment/Discussion
Note that 7 different paraphrases were judged on average for every instance.,Experiment/Discussion
"This is because annotators judged paraphrases for eight conditions, and because we collected judgments for the 5-best paraphrases for many of the conditions.",Experiment/Discussion
"We measured inter-annotator agreement with the Kappa statistic (Carletta, 1996) using the 1,391 items that two annotators scored in common.",Experiment/Discussion
The two annotators assigned the same absolute score 47% of the time.,Experiment/Discussion
"If we consider chance agreement to be 20% for 5-point scales, then K = 0.33, which is commonly interpreted as “fair” (Landis and Koch, 1977).",Experiment/Discussion
"If we instead measure agreement in terms of how often the annotators both judged an item to be above or below the thresholds that we set, then their rate of agreement was 80%.",Experiment/Discussion
"In this case chance agreement would be 50%, so K = 0.61, which is “substantial”.",Experiment/Discussion
"In order to allow other researchers to recreate our results or extend our work, we have prepared the following materials for download2: • The complete set of paraphrases generated for the test set.",Experiment/Discussion
This includes the 3.7 million paraphrases generated by the baseline method and the 3.5 million paraphrases generated with syntactic constraints.,Experiment/Discussion
"• The code that we used to produce these paraphrases and the complete data sets (including all 10 word-aligned parallel corpora along with their English parses), so that researchers can extract paraphrases for new sets of phrases.",Experiment/Discussion
• The manual judgments about paraphrase quality.,Experiment/Discussion
"These may be useful as development material for setting the weights of a log-linear formulation of paraphrasing, as suggested in Zhao et al. (2008a).",Experiment/Discussion
Table 6 summarizes the results of the manual evaluation.,Experiment/Discussion
We can observe a strong trend in the syntactically constrained approaches performing better of the eight conditions.,Experiment/Discussion
"Correct meaning is the percent of time that a condition was assigned a 3, 4, or 5, and correct grammar is the percent of time that it was given a 4 or 5, using the scales from Table 5. than the baseline.",Experiment/Discussion
They retain the correct meaning more often (ranging from 4% to up to 15%).,Experiment/Discussion
"They are judged to be grammatical far more frequently (up to 26% more often without the language model, and 24% with the language model) .",Experiment/Discussion
"They perform nearly 20% better when both meaning and grammaticality are used as criteria.3 Another trend that can be observed is that incorporating a language model probability tends to result in more grammatical output (a 7–9% increase), but meaning suffers as a result in some cases.",Experiment/Discussion
"When the LM is applied there is a drop of 12% in correct meaning for the baseline, but only a slight dip of 12% for the syntactically-constrained phrases.",Experiment/Discussion
"Note that for the conditions where the paraphrases were required to have the same syntactic type as the phrase in the parse tree, there was a reduction in the number of paraphrases that could be applied.",Experiment/Discussion
"For the first two conditions, paraphrases were posited for 1194 sentences, conditions 3 and 4 could be applied to 1142 of those sentences, but conditions 5–8 could only be applied to 876 sentences.",Experiment/Discussion
The substitution constraints reduce coverage to 73% of the test sentences.,Experiment/Discussion
Given that the extraction constraints have better coverage and nearly identical performance on 3Our results show a significantly lower score for the baseline than reported in Bannard and Callison-Burch (2005).,Experiment/Discussion
"This is potentially due to the facts that in this work we evaluated on out-of-domain news commentary data, and we randomly selected phrases.",Experiment/Discussion
"In the pervious work the test phrases were drawn from WordNet, and they were evaluated solely on in-domain European parliament data. the meaning criterion, they might be more suitable in some circumstances.",Experiment/Discussion
In this paper we have presented a novel refinement to paraphrasing with bilingual parallel corpora.,Results/Conclusion
We illustrated that a significantly higher performance can be achieved by constraining paraphrases to have the same syntactic type as the original phrase.,Results/Conclusion
A thorough manual evaluation found an absolute improvement in quality of 19% using strict criteria about paraphrase accuracy when comparing against a strong baseline.,Results/Conclusion
"The syntactically enhanced paraphrases are judged to be grammatically correct over two thirds of the time, as opposed to the baseline method which was grammatically correct under half of the time.",Results/Conclusion
This paper proposed constraints on paraphrases at two stages: when deriving them from parsed parallel corpora and when substituting them into parsed test sentences.,Results/Conclusion
These constraints produce paraphrases that are better than the baseline and which are less commonly affected by problems due to unaligned words.,Results/Conclusion
"Furthermore, by introducing complex syntactic labels instead of solely relying on non-terminal symbols in the parse trees, we are able to keep the broad coverage of the baseline method.",Results/Conclusion
"Syntactic constraints significantly improve the quality of this paraphrasing method, and their use opens the question about whether analogous constraints can be usefully applied to paraphrases generated from purely monolingual corpora.",Results/Conclusion
"Our improvements to the extraction of paraphrases from parallel corpora suggests that it may be usefully applied to other NLP applications, such as generation, which require grammatical output.",Results/Conclusion
"Thanks go to Sally Blatz, Emily Hinchcliff and Michelle Bland for conducting the manual evaluation and to Michelle Bland and Omar Zaidan for proofreading and commenting on a draft of this paper.",Results/Conclusion
This work was supported by the National Science Foundation under Grant No.,Results/Conclusion
0713448.,Results/Conclusion
The views and findings are the author’s alone.,Results/Conclusion
