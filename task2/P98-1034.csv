col1,col2
"Finding simple, non-recursive, base noun phrases is an important subtask for many natural language processing applications.",{}
"While previous empirical methods for base NP identification have been rather complex, this paper instead proposes a very simple algorithm that is tailored to the relative simplicity of the task.",{}
"In particular, we present a corpus-based approach for finding base NPs by matching part-ofspeech tag sequences.",{}
The training phase of the algorithm is based on two successful techniques: first the base NP grammar is read from a &quot;treebank&quot; corpus; then the grammar is improved by selecting rules with high &quot;benefit&quot; scores.,{}
"Using this simple algorithm with a naive heuristic for matching rules, we achieve surprising accuracy in an evaluation on the",{}
"Finding base noun phrases is a sensible first step for many natural language processing (NLP) tasks: Accurate identification of base noun phrases is arguably the most critical component of any partial parser; in addition, information retrieval systems rely on base noun phrases as the main source of multi-word indexing terms; furthermore, the psycholinguistic studies of Gee and Grosjean (1983) indicate that text chunks like base noun phrases play an important role in human language processing.","{'title': '1 Introduction', 'number': '1'}"
"In this work we define base NPs to be simple, nonrecursive noun phrases — noun phrases that do not contain other noun phrase descendants.","{'title': '1 Introduction', 'number': '1'}"
"The bracketed portions of Figure 1, for example, show the base NPs in one sentence from the Penn Treebank Wall Street Journal (WSJ) corpus (Marcus et al., 1993).","{'title': '1 Introduction', 'number': '1'}"
"Thus, the string the sunny confines of resort towns like Boca Raton and Hot Springs is too complex to be a base NP; instead, it contains four simpler noun phrases, each of which is considered a base NP: the sunny confines, resort towns, Boca Raton, and Hot Springs.","{'title': '1 Introduction', 'number': '1'}"
Previous empirical research has addressed the problem of base NP identification.,"{'title': '1 Introduction', 'number': '1'}"
"Several algorithms identify &quot;terminological phrases&quot; — certain When [it] is [time] for [their biannual powwow] , [the nation] 's [manufacturing titans] typically jet off to [the sunny confines] of [resort towns] like [Boca Raton] and [Hot Springs]. base noun phrases with initial determiners and modifiers removed: Justeson & Katz (1995) look for repeated phrases; Bourigault (1992) uses a handcrafted noun phrase grammar in conjunction with heuristics for finding maximal length noun phrases; Voutilainen's NPTool (1993) uses a handcrafted lexicon and constraint grammar to find terminological noun phrases that include phrase-final prepositional phrases.","{'title': '1 Introduction', 'number': '1'}"
"Church's PARTS program (1988), on the other hand, uses a probabilistic model automatically trained on the Brown corpus to locate core noun phrases as well as to assign parts of speech.","{'title': '1 Introduction', 'number': '1'}"
"More recently, Ramshaw & Marcus (In press) apply transformation-based learning (Brill, 1995) to the problem.","{'title': '1 Introduction', 'number': '1'}"
"Unfortunately, it is difficult to directly compare approaches.","{'title': '1 Introduction', 'number': '1'}"
Each method uses a slightly different definition of base NP.,"{'title': '1 Introduction', 'number': '1'}"
Each is evaluated on a different corpus.,"{'title': '1 Introduction', 'number': '1'}"
Most approaches have been evaluated by hand on a small test set rather than by automatic comparison to a large test corpus annotated by an impartial third party.,"{'title': '1 Introduction', 'number': '1'}"
"A notable exception is the Ramshaw & Marcus work, which evaluates their transformation-based learning approach on a base NP corpus derived from the Penn Treebank WSJ, and achieves precision and recall levels of approximately 93%.","{'title': '1 Introduction', 'number': '1'}"
This paper presents a new algorithm for identifying base NPs in an arbitrary text.,"{'title': '1 Introduction', 'number': '1'}"
"Like some of the earlier work on base NP identification, ours is a trainable, corpus-based algorithm.","{'title': '1 Introduction', 'number': '1'}"
"In contrast to other corpus-based approaches, however, we hypothesized that the relatively simple nature of base NPs would permit their accurate identification using correspondingly simple methods.","{'title': '1 Introduction', 'number': '1'}"
"Assume, for example, that we use the annotated text of Figure 1 as our training corpus.","{'title': '1 Introduction', 'number': '1'}"
"To identify base NPs in an unseen text, we could simply search for all occurrences of the base NPs seen during training — it, time, their biannual powwow, .. .","{'title': '1 Introduction', 'number': '1'}"
", Hot Springs — and mark them as base NPs in the new text.","{'title': '1 Introduction', 'number': '1'}"
"However, this method would certainly suffer from data sparseness.","{'title': '1 Introduction', 'number': '1'}"
"Instead, we use a similar approach, but back off from lexical items to parts of speech: we identify as a base NP any string having the same part-of-speech tag sequence as a base NP from the training corpus.","{'title': '1 Introduction', 'number': '1'}"
"The training phase of the algorithm employs two previously successful techniques: like Charniak's (1996) statistical parser, our initial base NP grammar is read from a &quot;treebank&quot; corpus; then the grammar is improved by selecting rules with high &quot;benefit&quot; scores.","{'title': '1 Introduction', 'number': '1'}"
"Our benefit measure is identical to that used in transformation-based learning to select an ordered set of useful transformations (Brill, 1995).","{'title': '1 Introduction', 'number': '1'}"
"Using this simple algorithm with a naive heuristic for matching rules, we achieve surprising accuracy in an evaluation on two base NP corpora of varying complexity, both derived from the Penn Treebank WSJ.","{'title': '1 Introduction', 'number': '1'}"
The first base NP corpus is that used in the Ramshaw & Marcus work.,"{'title': '1 Introduction', 'number': '1'}"
The second espouses a slightly simpler definition of base NP that conforms to the base NPs used in our Empire sentence analyzer.,"{'title': '1 Introduction', 'number': '1'}"
These simpler phrases appear to be a good starting point for partial parsers that purposely delay all complex attachment decisions to later phases of processing.,"{'title': '1 Introduction', 'number': '1'}"
Overall results for the approach are promising.,"{'title': '1 Introduction', 'number': '1'}"
"For the Empire corpus, our base NP finder achieves 94% precision and recall; for the Ramshaw & Marcus corpus, it obtains 91% precision and recall, which is 2% less than the best published results.","{'title': '1 Introduction', 'number': '1'}"
"Ramshaw & Marcus, however, provide the learning algorithm with word-level information in addition to the partof-speech information used in our base NP finder.","{'title': '1 Introduction', 'number': '1'}"
"By controlling for this disparity in available knowledge sources, we find that our base NP algorithm performs comparably, achieving slightly worse precision (-1.1%) and slightly better recall (+0.2%) than the Ramshaw & Marcus approach.","{'title': '1 Introduction', 'number': '1'}"
"Moreover, our approach offers many important advantages that make it appropriate for many NLP tasks: Note also that the treebank approach to base NP identification obtains good results in spite of a very simple algorithm for &quot;parsing&quot; base NPs.","{'title': '1 Introduction', 'number': '1'}"
"This is extremely encouraging, and our evaluation suggests at least two areas for immediate improvement.","{'title': '1 Introduction', 'number': '1'}"
"First, by replacing the naive match heuristic with a probabilistic base NP parser that incorporates lexical preferences, we would expect a nontrivial increase in recall and precision.","{'title': '1 Introduction', 'number': '1'}"
"Second, many of the remaining base NP errors tend to follow simple patterns; these might be corrected using localized, learnable repair rules.","{'title': '1 Introduction', 'number': '1'}"
The remainder of the paper describes the specifics of the approach and its evaluation.,"{'title': '1 Introduction', 'number': '1'}"
The next section presents the training and application phases of the treebank approach to base NP identification in more detail.,"{'title': '1 Introduction', 'number': '1'}"
Section 3 describes our general approach for pruning the base NP grammar as well as two instantiations of that approach.,"{'title': '1 Introduction', 'number': '1'}"
"The evaluation and a discussion of the results appear in Section 4, along with techniques for reducing training time and an initial investigation into the use of local repair heuristics.","{'title': '1 Introduction', 'number': '1'}"
Figure 2 depicts the treebank approach to base NP identification.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
"For training, the algorithm requires a corpus that has been annotated with base NPs.","{'title': '2 The Treebartk Approach', 'number': '2'}"
"More specifically, we assume that the training corpus is a sequence of words wi, w2,..., along with a set of base NP annotations b(i1,j1), ..., where b(,j) indicates that the NP brackets words i through j: [Nr, wi, , wj].","{'title': '2 The Treebartk Approach', 'number': '2'}"
The goal of the training phase is to create a base NP grammar from this training corpus: The resulting &quot;grammar&quot; can then be used to identify base NPs in a novel text.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
Not this year.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
National Association of Manufacturers settled on the Hoosier capital of Indianapolis for its next meeting.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
And the city decided to treat its guests more like royalty or rock stars than factory owners.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
Not [this year).,"{'title': '2 The Treebartk Approach', 'number': '2'}"
/National Association) of /Manufacturers! settled on the Hoosier capital) of [Indianapolis) for I its next meeting).,"{'title': '2 The Treebartk Approach', 'number': '2'}"
And the city) decided to treat its guests more like !royalty) or frock stars/ than [factory owners).,"{'title': '2 The Treebartk Approach', 'number': '2'}"
Training Corpus When [it/ is [time/ for /their biannual powwow) . the nation] 's [manufacturing titans/ typically jet off to the sunny confines/ of /resort towns) like [Boca Raton) and [Hot Springs!.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
3.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
"If there are multiple rules that match beginning at ti, use the longest matching rule R. Add the new base noun phrase t(i,i+IRi_i) to the set of base NPs.","{'title': '2 The Treebartk Approach', 'number': '2'}"
Continue matching at ti+tRi.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
"With the rules stored in an appropriate data structure, this greedy &quot;parsing&quot; of base NPs is very fast.","{'title': '2 The Treebartk Approach', 'number': '2'}"
"In our implementation, for example, we store the rules in a decision tree, which permits base NP identification in time linear in the length of the tagged input text when using the longest match heuristic.","{'title': '2 The Treebartk Approach', 'number': '2'}"
"Unfortunately, there is an obvious problem with the algorithm described above.","{'title': '2 The Treebartk Approach', 'number': '2'}"
There will be many unhelpful rules in the rule set extracted from the training corpus.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
These &quot;bad&quot; rules arise from four sources: bracketing errors in the corpus; tagging errors; unusual or irregular linguistic constructs (such as parenthetical expressions); and inherent ambiguities in the base NPs — in spite of their simplicity.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
"For example, the rule (VBG NNS), which was extracted from manufacturing/VBG titans/NNS in the example text, is ambiguous, and will cause erroneous bracketing in sentences such as The execs squeezed in a few meetings before [boarding/VBG buses/NNS] again.","{'title': '2 The Treebartk Approach', 'number': '2'}"
"In order to have a viable mechanism for identifying base NPs using this algorithm, the grammar must be improved by removing problematic rules.","{'title': '2 The Treebartk Approach', 'number': '2'}"
The next section presents two such methods for automatically pruning the base NP grammar.,"{'title': '2 The Treebartk Approach', 'number': '2'}"
"As described above, our goal is to use the base NP corpus to extract and select a set of noun phrase rules that can be used to accurately identify base NPs in novel text.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
Our general pruning procedure is shown in Figure 3.,"{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"First, we divide the base NP corpus into two parts: a training corpus and a pruning corpus.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
The initial base NP grammar is extracted from the training corpus as described in Section 2.,"{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Next, the pruning corpus is used to evaluate the set of rules and produce a ranking of the rules in terms of their utility in identifying base NPs.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"More specifically, we use the rule set and the longest match heuristic to find all base NPs in the pruning corpus.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
Performance of the rule set is measured in terms of labeled precision (P): We then assign to each rule a score that denotes the &quot;net benefit&quot; achieved by using the rule during NP parsing of the improvement corpus.,"{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"The benefit of rule r is given by Br = Cr — Er where Cr is the number of NPs correctly identified by r, and Er is the number of precision errors for which r is responsible.1 A rule is considered responsible for an error if it was the first rule to bracket part of a reference NP, i.e., an NP in the base NP training corpus.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Thus, rules that form erroneous bracketings are not penalized if another rule previously bracketed part of the same reference NP.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"For example, suppose the fragment containing base NPs Boca Raton, Hot Springs, and Palm Beach is bracketed as shown below. resort towns like [NP, Boca/NNP Raton/NNP , Hot/NNP] [NP, Springs/NNP], and [NP, Palm/NNP Beach/NNP1 Rule (NNP NNP , NNP) brackets NPi; (NNP) brackets NP2; and (NNP NNP) brackets NP3.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Rule (NNP NNP , NNP) incorrectly identifies Boca Raton , Hot as a noun phrase, so its score is —1.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Rule (NNP) incorrectly identifies Springs, but it is not held responsible for the error because of the previous error by (NNP NNP , NNP) on the same original NP Hot Springs: so its score is 0.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Finally, rule (NNP NNP) receives a score of 1 for correctly identifying Palm Beach as a base NP.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
The benefit scores from evaluation on the pruning corpus are used to rank the rules in the grammar.,"{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"With such a ranking, we can improve the rule set by discarding the worst rules.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Thus far, we have investigated two iterative approaches for discarding rules, a thresholding approach and an incremental approach.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"We describe each, in turn, in the subsections below.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"'This same benefit measure is also used in the R&M study, but it is used to rank transformations rather than to rank NP rules.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Given a ranking on the rule set, the threshold algorithm simply discards rules whose score is less than a predefined threshold R. For all of our experiments, we set R = 1 to select rules that propose more correct bracketings than incorrect.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"The process of evaluating, ranking, and discarding rules is repeated until no rules have a score less than R. For our evaluation on the WSJ corpus, this typically requires only four to five iterations.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
Thresholding provides a very coarse mechanism for pruning the NP grammar.,"{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"In particular, because of interactions between the rules during bracketing, thresholding discards rules whose score might increase in the absence of other rules that are also being discarded.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Consider, for example, the Boca Raton fragments given earlier.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"In the absence of (NNP NNP , NNP), the rule (NNP NNP) would have received a score of three for correctly identifying all three NPs.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"As a result, we explored a more fine-grained method of discarding rules: Each iteration of incremental pruning discards the N worst rules, rather than all rules whose rank is less than some threshold.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"In all of our experiments, we set N = 10.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"As with thresholding, the process of evaluating, ranking, and discarding rules is repeated, this time until precision of the current rule set on the pruning corpus begins to drop.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
The rule set that maximized precision becomes the final rule set.,"{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"In the experiments below, we compare the thresholding and incremental methods for pruning the NP grammar to a rule set that was pruned by hand.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"When the training corpus is large, exhaustive review of the extracted rules is not practical.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"This is the case for our initial rule set, culled from the WSJ corpus, which contains approximately 4500 base NP rules.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Rather than identifying and discarding individual problematic rules, our reviewer identified problematic classes of rules that could be removed from the grammar automatically.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"In particular, the goal of the human reviewer was to discard rules that introduced ambiguity or corresponded to overly complex base NPs.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Within our partial parsing framework, these NPs are better identified by more informed components of the NLP system.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"Our reviewer identified the following classes of rules as possibly troublesome: rules that contain a preposition, period, or colon; rules that contain WH tags; rules that begin/end with a verb or adverb; rules that contain pronouns with any other tags; rules that contain misplaced commas or quotes; rules that end with adjectives.","{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
Rules covered under any of these classes were omitted from the human-pruned rule sets used in the experiments of Section 4.,"{'title': '3 Pruning the Base NP Grammar', 'number': '3'}"
"To evaluate the treebank approach to base NP identification, we created two base NP corpora.","{'title': '4 Evaluation', 'number': '4'}"
Each is derived from the Penn Treebank WSJ.,"{'title': '4 Evaluation', 'number': '4'}"
The first corpus attempts to duplicate the base NPs used the Ramshaw & Marcus (R&M) study.,"{'title': '4 Evaluation', 'number': '4'}"
"The second corpus contains slightly less complicated base NPs — base NPs that are better suited for use with our sentence analyzer, Empire.'","{'title': '4 Evaluation', 'number': '4'}"
"By evaluating on both corpora, we can measure the effect of noun phrase complexity on the treebank approach to base NP identification.","{'title': '4 Evaluation', 'number': '4'}"
"In particular, we hypothesize that the treebank approach will be most appropriate when the base NPs are sufficiently simple.","{'title': '4 Evaluation', 'number': '4'}"
"For all experiments, we derived the training, pruning, and testing sets from the 25 sections of Wall Street Journal distributed with the Penn Treebank II.","{'title': '4 Evaluation', 'number': '4'}"
All experiments employ 5-fold cross validation.,"{'title': '4 Evaluation', 'number': '4'}"
"More specifically, in each of five runs, a different fold is used for testing the final, pruned rule set; three of the remaining folds comprise the training corpus (to create the initial rule set); and the final partition is the pruning corpus (to prune bad rules from the initial rule set).","{'title': '4 Evaluation', 'number': '4'}"
All results are averages across the five folds.,"{'title': '4 Evaluation', 'number': '4'}"
Performance is measured in terms of precision and recall.,"{'title': '4 Evaluation', 'number': '4'}"
Precision was described earlier — it is a standard measure of accuracy.,"{'title': '4 Evaluation', 'number': '4'}"
"Recall, on the other hand, is an attempt to measure coverage: Throughout the table, we see the effects of base NP complexity — the base NPs of the R&M corpus are substantially more difficult for our approach to identify than the simpler NPs of the Empire corpus.","{'title': '4 Evaluation', 'number': '4'}"
"For the R&M corpus, we lag the best published results (93.1P/93.5R) by approximately 3%.","{'title': '4 Evaluation', 'number': '4'}"
"This straightforward comparison, however, is not entirely appropriate.","{'title': '4 Evaluation', 'number': '4'}"
Ramshaw & Marcus allow their learning algorithm to access word-level information in addition to part-of-speech tags.,"{'title': '4 Evaluation', 'number': '4'}"
"The treebank approach, on the other hand, makes use only of part-ofspeech tags.","{'title': '4 Evaluation', 'number': '4'}"
Table 2 compares Ramshaw & Marcus' (In press) results with and without lexical knowledge.,"{'title': '4 Evaluation', 'number': '4'}"
The first column reports their performance when using lexical templates; the second when lexical templates are not used; the third again shows the treebank approach using incremental pruning.,"{'title': '4 Evaluation', 'number': '4'}"
The treebank approach and the R&M approach without lecial templates are shown to perform comparably (-1.1P/+0.2R).,"{'title': '4 Evaluation', 'number': '4'}"
Lexicalization of our base NP finder will be addressed in Section 4.1.,"{'title': '4 Evaluation', 'number': '4'}"
"Finally, note the relatively small difference between the threshold and incremental pruning methods in Table 1.","{'title': '4 Evaluation', 'number': '4'}"
"For some applications, this minor drop in performance may be worth the decrease in training time.","{'title': '4 Evaluation', 'number': '4'}"
Another effective technique to speed up training is motivated by Charniak's (1996) observation that the benefit of using rules that only occurred once in training is marginal.,"{'title': '4 Evaluation', 'number': '4'}"
"By discarding these rules before pruning, we reduce the size of the initial grammar — and the time for incremental pruning — by 60%, with a performance drop of only -0.3P/-0.1R.","{'title': '4 Evaluation', 'number': '4'}"
It is informative to consider the kinds of errors made by the treebank approach to bracketing.,"{'title': '4 Evaluation', 'number': '4'}"
"In particular, the errors may indicate options for incorporating lexical information into the base NP finder.","{'title': '4 Evaluation', 'number': '4'}"
"Given the increases in performance achieved by Ramshaw & Marcus by including word-level cues, we would hope to see similar improvements by exploiting lexical information in the treebank approach.","{'title': '4 Evaluation', 'number': '4'}"
For each corpus we examined the first 100 or so errors and found that certain linguistic constructs consistently cause trouble.,"{'title': '4 Evaluation', 'number': '4'}"
"(In the examples that follow, the bracketing shown is the error.)","{'title': '4 Evaluation', 'number': '4'}"
# of NPs in the annotated text Table 1 summarizes the performance of the treebank approach to base NP identification on the R&M and Empire corpora using the initial and pruned rule sets.,"{'title': '4 Evaluation', 'number': '4'}"
"The first column of results shows the performance of the initial, unpruned base NP grammar.","{'title': '4 Evaluation', 'number': '4'}"
The next two columns show the performance of the automatically pruned rule sets.,"{'title': '4 Evaluation', 'number': '4'}"
The final column indicates the performance of rule sets that had been pruned using the handcrafted pruning heuristics.,"{'title': '4 Evaluation', 'number': '4'}"
"As expected, the initial rule set performs quite poorly.","{'title': '4 Evaluation', 'number': '4'}"
Both automated approaches provide significant increases in both recall and precision.,"{'title': '4 Evaluation', 'number': '4'}"
"In addition, they outperform the rule set pruned using handcrafted pruning heuristics.","{'title': '4 Evaluation', 'number': '4'}"
Many errors appear to stem from four underlying causes.,"{'title': '4 Evaluation', 'number': '4'}"
"First, close to 20% can be attributed to errors in the Treebank and in the Base NP corpus, bringing the effective performance of the algorithm to 94.2P/95.9R and 91.5P/92.7R for the Empire and R&M corpora, respectively.","{'title': '4 Evaluation', 'number': '4'}"
"For example, neither corpus includes WH-phrases as base NPs.","{'title': '4 Evaluation', 'number': '4'}"
"When the bracketer correctly recognizes these NPs, they are counted as errors.","{'title': '4 Evaluation', 'number': '4'}"
Part-of-speech tagging errors are a second cause.,"{'title': '4 Evaluation', 'number': '4'}"
"Third, many NPs are missed by the bracketer because it lacks the appropriate rule.","{'title': '4 Evaluation', 'number': '4'}"
"For example, household products business is bracketed as [household/NN products/NNS] [business/NM.","{'title': '4 Evaluation', 'number': '4'}"
"Fourth, idiomatic and specialized expressions, especially time, date, money, and numeric phrases, also account for a substantial portion of the errors.","{'title': '4 Evaluation', 'number': '4'}"
These last two categories of errors can often be detected because they produce either recognizable patterns or unlikely linguistic constructs.,"{'title': '4 Evaluation', 'number': '4'}"
"Consecutive NPs, for example, usually denote bracketing errors, as in [household/NN products/NNS] [business/NM.","{'title': '4 Evaluation', 'number': '4'}"
Merging consecutive NPs in the correct contexts would fix many such errors.,"{'title': '4 Evaluation', 'number': '4'}"
Idiomatic and specialized expressions might be corrected by similarly local repair heuristics.,"{'title': '4 Evaluation', 'number': '4'}"
Typical examples might include changing [effective/JJ Monday/NNP] to effective [Monday]; changing [the/DT balance/NN due/JJ] to [the balance] due; and changing were/VBP In't/RB the/DT only/RB losers/NNS] to were n't [the only losers].,"{'title': '4 Evaluation', 'number': '4'}"
"Given these observations, we implemented three local repair heuristics.","{'title': '4 Evaluation', 'number': '4'}"
The first merges consecutive NPs unless either might be a time expression.,"{'title': '4 Evaluation', 'number': '4'}"
The second identifies two simple date expressions.,"{'title': '4 Evaluation', 'number': '4'}"
The third looks for quantifiers preceding of NP.,"{'title': '4 Evaluation', 'number': '4'}"
"The first heuristic, for example, merges [household products] [business] to form [household products business], but leaves increased [15 %) [last Friday] untouched.","{'title': '4 Evaluation', 'number': '4'}"
"The second heuristic merges [June 5] , [1995] into [June 5, 1995]; and [June] , [1995] into [June, 1995].","{'title': '4 Evaluation', 'number': '4'}"
The third finds examples like some of [the companies] and produces [some] of [the companies].,"{'title': '4 Evaluation', 'number': '4'}"
These heuristics represent an initial exploration into the effectiveness of employing lexical information in a post-processing phase rather than during grammar induction and bracketing.,"{'title': '4 Evaluation', 'number': '4'}"
"While we are investigating the latter in current work, local repair heuristics have the advantage of keeping the training and bracketing algorithms both simple and fast.","{'title': '4 Evaluation', 'number': '4'}"
The effect of these heuristics on recall and precision is shown in Table 3.,"{'title': '4 Evaluation', 'number': '4'}"
"We see consistent improvements for both corpora and both pruning methods, achieving approximately 94P/R for the Empire corpus and approximately 91P/R for the R&M corpus.","{'title': '4 Evaluation', 'number': '4'}"
Note that these are the final results reported in the introduction and conclusion.,"{'title': '4 Evaluation', 'number': '4'}"
"Although these experiments represent only an initial investigation into the usefulness of local repair heuristics, we are very encouraged by the results.","{'title': '4 Evaluation', 'number': '4'}"
The heuristics uniformly boost precision without harming recall; they help the R&M corpus even though they were designed in response to errors in the Empire corpus.,"{'title': '4 Evaluation', 'number': '4'}"
"In addition, these three heuristics alone recover 1/2 to 1/3 of the improvements we can expect to obtain from lexicalization based on the R&M results.","{'title': '4 Evaluation', 'number': '4'}"
This paper presented a new method for identifying base NPs.,"{'title': '5 Conclusions', 'number': '5'}"
"Our treebank approach uses the simple technique of matching part-of-speech tag sequences, with the intention of capturing the simplicity of the corresponding syntactic structure.","{'title': '5 Conclusions', 'number': '5'}"
It employs two existing corpus-based techniques: the initial noun phrase grammar is extracted directly from an annotated corpus; and a benefit score calculated from errors on an improvement corpus selects the best subset of rules via a coarse- or fine-grained pruning algorithm.,"{'title': '5 Conclusions', 'number': '5'}"
"The overall results are surprisingly good, especially considering the simplicity of the method.","{'title': '5 Conclusions', 'number': '5'}"
It achieves 94% precision and recall on simple base NPs.,"{'title': '5 Conclusions', 'number': '5'}"
It achieves 91% precision and recall on the more complex NPs of the Rainshaw & Marcus corpus.,"{'title': '5 Conclusions', 'number': '5'}"
"We believe, however, that the base NP finder can be improved further.","{'title': '5 Conclusions', 'number': '5'}"
"First, the longest-match heuristic of the noun phrase bracketer could be replaced by more sophisticated parsing methods that account for lexical preferences.","{'title': '5 Conclusions', 'number': '5'}"
"Rule application, for example, could be disambiguated statistically using distributions induced during training.","{'title': '5 Conclusions', 'number': '5'}"
We are currently investigating such extensions.,"{'title': '5 Conclusions', 'number': '5'}"
One approach closely related to ours — weighted finite-state transducers (e.g.,"{'title': '5 Conclusions', 'number': '5'}"
"(Pereira and Riley, 1997)) — might provide a principled way to do this.","{'title': '5 Conclusions', 'number': '5'}"
We could then consider applying our error-driven pruning strategy to rules encoded as transducers.,"{'title': '5 Conclusions', 'number': '5'}"
"Second, we have only recently begun to explore the use of local repair heuristics.","{'title': '5 Conclusions', 'number': '5'}"
"While initial results are promising, the full impact of such heuristics on overall performance can be determined only if they are systematically learned and tested using available training data.","{'title': '5 Conclusions', 'number': '5'}"
Future work will concentrate on the corpusbased acquisition of local repair heuristics.,"{'title': '5 Conclusions', 'number': '5'}"
"In conclusion, the treebank approach to base NPs provides an accurate and fast bracketing method, running in time linear in the length of the tagged text.","{'title': '5 Conclusions', 'number': '5'}"
"The approach is simple to understand, implement, and train.","{'title': '5 Conclusions', 'number': '5'}"
"The learned grammar is easily modified for use with new corpora, as rules can be added or deleted with minimal interaction problems.","{'title': '5 Conclusions', 'number': '5'}"
"Finally, the approach provides a general framework for developing other treebank grammars (e.g., for subject/verb/object identification) in addition to these for base NPs.","{'title': '5 Conclusions', 'number': '5'}"
Acknowledgments.,"{'title': '5 Conclusions', 'number': '5'}"
This work was supported in part by NSF Grants IRI-9624639 and GER-9454149.,"{'title': '5 Conclusions', 'number': '5'}"
We thank Mitre for providing their part-of-speech tagger.,"{'title': '5 Conclusions', 'number': '5'}"
