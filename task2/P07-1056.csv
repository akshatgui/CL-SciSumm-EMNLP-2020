col1,col2
Automatic sentiment classification has been extensively studied and applied in recent years.,{}
"However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical.",{}
"We investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products.",{}
"First, we extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30% over the original SCL algorithm and 46% over a supervised baseline.",{}
"Second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another.",{}
This measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains.,{}
"Sentiment detection and classification has received considerable attention recently (Pang et al., 2002; Turney, 2002; Goldberg and Zhu, 2004).","{'title': '1 Introduction', 'number': '1'}"
"While movie reviews have been the most studied domain, sentiment analysis has extended to a number of new domains, ranging from stock message boards to congressional floor debates (Das and Chen, 2001; Thomas et al., 2006).","{'title': '1 Introduction', 'number': '1'}"
"Research results have been deployed industrially in systems that gauge market reaction and summarize opinion from Web pages, discussion boards, and blogs.","{'title': '1 Introduction', 'number': '1'}"
"With such widely-varying domains, researchers and engineers who build sentiment classification systems need to collect and curate data for each new domain they encounter.","{'title': '1 Introduction', 'number': '1'}"
"Even in the case of market analysis, if automatic sentiment classification were to be used across a wide range of domains, the effort to annotate corpora for each domain may become prohibitive, especially since product features change over time.","{'title': '1 Introduction', 'number': '1'}"
"We envision a scenario in which developers annotate corpora for a small number of domains, train classifiers on those corpora, and then apply them to other similar corpora.","{'title': '1 Introduction', 'number': '1'}"
"However, this approach raises two important questions.","{'title': '1 Introduction', 'number': '1'}"
"First, it is well known that trained classifiers lose accuracy when the test data distribution is significantly different from the training data distribution 1.","{'title': '1 Introduction', 'number': '1'}"
"Second, it is not clear which notion of domain similarity should be used to select domains to annotate that would be good proxies for many other domains.","{'title': '1 Introduction', 'number': '1'}"
"We propose solutions to these two questions and evaluate them on a corpus of reviews for four different types of products from Amazon: books, DVDs, electronics, and kitchen appliances2.","{'title': '1 Introduction', 'number': '1'}"
"First, we show how to extend the recently proposed structural correspondence learning (SCL) domain adaptation algorithm (Blitzer et al., 2006) for use in sentiment classification.","{'title': '1 Introduction', 'number': '1'}"
A key step in SCL is the selection of pivot features that are used to link the source and target domains.,"{'title': '1 Introduction', 'number': '1'}"
We suggest selecting pivots based not only on their common frequency but also according to their mutual information with the source labels.,"{'title': '1 Introduction', 'number': '1'}"
"For data as diverse as product reviews, SCL can sometimes misalign features, resulting in degradation when we adapt between domains.","{'title': '1 Introduction', 'number': '1'}"
In our second extension we show how to correct misalignments using a very small number of labeled instances.,"{'title': '1 Introduction', 'number': '1'}"
"Second, we evaluate the A-distance (Ben-David et al., 2006) between domains as measure of the loss due to adaptation from one to the other.","{'title': '1 Introduction', 'number': '1'}"
"The Adistance can be measured from unlabeled data, and it was designed to take into account only divergences which affect classification accuracy.","{'title': '1 Introduction', 'number': '1'}"
"We show that it correlates well with adaptation loss, indicating that we can use the A-distance to select a subset of domains to label as sources.","{'title': '1 Introduction', 'number': '1'}"
In the next section we briefly review SCL and introduce our new pivot selection method.,"{'title': '1 Introduction', 'number': '1'}"
Section 3 describes datasets and experimental method.,"{'title': '1 Introduction', 'number': '1'}"
Section 4 gives results for SCL and the mutual information method for selecting pivot features.,"{'title': '1 Introduction', 'number': '1'}"
Section 5 shows how to correct feature misalignments using a small amount of labeled target domain data.,"{'title': '1 Introduction', 'number': '1'}"
Section 6 motivates the A-distance and shows that it correlates well with adaptability.,"{'title': '1 Introduction', 'number': '1'}"
We discuss related work in Section 7 and conclude in Section 8.,"{'title': '1 Introduction', 'number': '1'}"
"Before reviewing SCL, we give a brief illustrative example.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
Suppose that we are adapting from reviews of computers to reviews of cell phones.,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"While many of the features of a good cell phone review are the same as a computer review – the words “excellent” and “awful” for example – many words are totally new, like “reception”.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"At the same time, many features which were useful for computers, such as “dual-core” are no longer useful for cell phones.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"Our key intuition is that even when “good-quality reception” and “fast dual-core” are completely distinct for each domain, if they both have high correlation with “excellent” and low correlation with “awful” on unlabeled data, then we can tentatively align them.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"After learning a classifier for computer reviews, when we see a cell-phone feature like “goodquality reception”, we know it should behave in a roughly similar manner to “fast dual-core”.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"Given labeled data from a source domain and unlabeled data from both source and target domains, SCL first chooses a set of m pivot features which occur frequently in both domains.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"Then, it models the correlations between the pivot features and all other features by training linear pivot predictors to predict occurrences of each pivot in the unlabeled data from both domains (Ando and Zhang, 2005; Blitzer et al., 2006).","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
The Eth pivot predictor is characterized by its weight vector wt; positive entries in that weight vector mean that a non-pivot feature (like “fast dualcore”) is highly correlated with the corresponding pivot (like “excellent”).,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
The pivot predictor column weight vectors can be arranged into a matrix W = [wt]e1.,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
Let 0 E Rkxd be the top k left singular vectors of W (here d indicates the total number of features).,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
These vectors are the principal predictors for our weight space.,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"If we chose our pivot features well, then we expect these principal predictors to discriminate among positive and negative words in both domains.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"At training and test time, suppose we observe a feature vector x.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
We apply the projection 0x to obtain k new real-valued features.,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"Now we learn a predictor for the augmented instance (x, 0x).","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"If 0 contains meaningful correspondences, then the predictor which uses 0 will perform well in both source and target domains.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
The efficacy of SCL depends on the choice of pivot features.,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"For the part of speech tagging problem studied by Blitzer et al. (2006), frequently-occurring words in both domains were good choices, since they often correspond to function words such as prepositions and determiners, which are good indicators of parts of speech.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"This is not the case for sentiment classification, however.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"Therefore, we require that pivot features also be good predictors of the source label.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"Among those features, we then choose the ones with highest mutual information to the source label.","{'title': '2 Structural Correspondence Learning', 'number': '2'}"
Table 1 shows the set-symmetric differences between the two methods for pivot selection when adapting a classifier from books to kitchen appliances.,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
We refer throughout the rest of this work to our method for selecting pivots as SCL-MI.,"{'title': '2 Structural Correspondence Learning', 'number': '2'}"
"We constructed a new dataset for sentiment domain adaptation by selecting Amazon product reviews for four different product types: books, DVDs, electronics and kitchen appliances.","{'title': '3 Dataset and Baseline', 'number': '3'}"
"Each review consists of a rating (0-5 stars), a reviewer name and location, a product name, a review title and date, and the review text.","{'title': '3 Dataset and Baseline', 'number': '3'}"
"Reviews with rating > 3 were labeled positive, those with rating < 3 were labeled negative, and the rest discarded because their polarity was ambiguous.","{'title': '3 Dataset and Baseline', 'number': '3'}"
"After this conversion, we had 1000 positive and 1000 negative examples for each domain, the same balanced composition as the polarity dataset (Pang et al., 2002).","{'title': '3 Dataset and Baseline', 'number': '3'}"
"In addition to the labeled data, we included between 3685 (DVDs) and 5945 (kitchen) instances of unlabeled data.","{'title': '3 Dataset and Baseline', 'number': '3'}"
The size of the unlabeled data was limited primarily by the number of reviews we could crawl and download from the Amazon website.,"{'title': '3 Dataset and Baseline', 'number': '3'}"
"Since we were able to obtain labels for all of the reviews, we also ensured that they were balanced between positive and negative examples, as well.","{'title': '3 Dataset and Baseline', 'number': '3'}"
"While the polarity dataset is a popular choice in the literature, we were unable to use it for our task.","{'title': '3 Dataset and Baseline', 'number': '3'}"
"Our method requires many unlabeled reviews and despite a large number of IMDB reviews available online, the extensive curation requirements made preparing a large amount of data difficult 3.","{'title': '3 Dataset and Baseline', 'number': '3'}"
"For classification, we use linear predictors on unigram and bigram features, trained to minimize the Huber loss with stochastic gradient descent (Zhang, 3For a description of the construction of the polarity dataset, see http://www.cs.cornell.edu/people/ pabo/movie-review-data/.","{'title': '3 Dataset and Baseline', 'number': '3'}"
2004).,"{'title': '3 Dataset and Baseline', 'number': '3'}"
"On the polarity dataset, this model matches the results reported by Pang et al. (2002).","{'title': '3 Dataset and Baseline', 'number': '3'}"
"When we report results with SCL and SCL-MI, we require that pivots occur in more than five documents in each domain.","{'title': '3 Dataset and Baseline', 'number': '3'}"
"We set k, the number of singular vectors of the weight matrix, to 50.","{'title': '3 Dataset and Baseline', 'number': '3'}"
Each labeled dataset was split into a training set of 1600 instances and a test set of 400 instances.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
All the experiments use a classifier trained on the training set of one domain and tested on the test set of a possibly different domain.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"The baseline is a linear classifier trained without adaptation, while the gold standard is an in-domain classifier trained on the same domain as it is tested.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
Figure 1 gives accuracies for all pairs of domain adaptation.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"The domains are ordered clockwise from the top left: books, DVDs, electronics, and kitchen.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"For each set of bars, the first letter is the source domain and the second letter is the target domain.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
The thick horizontal bars are the accuracies of the in-domain classifiers for these domains.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
Thus the first set of bars shows that the baseline achieves 72.8% accuracy adapting from DVDs to books.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
SCL-MI achieves 79.7% and the in-domain gold standard is 80.4%.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
We say that the adaptation loss for the baseline model is 7.6% and the adaptation loss for the SCL-MI model is 0.7%.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
The relative reduction in error due to adaptation of SCL-MI for this test is 90.8%.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
We can observe from these results that there is a rough grouping of our domains.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"Books and DVDs are similar, as are kitchen appliances and electronics, but the two groups are different from one another.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"Adapting classifiers from books to DVDs, for instance, is easier than adapting them from books to kitchen appliances.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"We note that when transferring from kitchen to electronics, SCL-MI actually outperforms the in-domain classifier.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
This is possible since the unlabeled data may contain information that the in-domain classifier does not have access to.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
At the beginning of Section 2 we gave examples of how features can change behavior across domains.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
The first type of behavior is when predictive features from the source domain are not predictive or do not appear in the target domain.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
The second is domain polarity negative positive books plot <num> pages predictable reader grisham engaging reading this page <num> must read fascinating kitchen the plastic poorly designed excellent product espresso leaking awkward to defective are perfect years now a breeze Table 2: Correspondences discovered by SCL for books and kitchen appliances.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
The top row shows features that only appear in books and the bottom features that only appear in kitchen appliances.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"The left and right columns show negative and positive features in correspondence, respectively. when predictive features from the target domain do not appear in the source domain.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"To show how SCL deals with those domain mismatches, we look at the adaptation from book reviews to reviews of kitchen appliances.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
We selected the top 1000 most informative features in both domains.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"In both cases, between 85 and 90% of the informative features from one domain were not among the most informative of the other domain4.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
SCL addresses both of these issues simultaneously by aligning features from the two domains.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
Table 2 illustrates one row of the projection matrix 0 for adapting from books to kitchen appliances; the features on each row appear only in the corresponding domain.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
A supervised classifier trained on book reviews cannot assign weight to the kitchen features in the second row of table 2.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"In contrast, SCL assigns weight to these features indirectly through the projection matrix.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"When we observe the feature “predictable” with a negative book review, we update parameters corresponding to the entire projection, including the kitchen-specific features “poorly designed” and “awkward to”.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"While some rows of the projection matrix 0 are useful for classification, SCL can also misalign features.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
This causes problems when a projection is discriminative in the source domain but not in the target.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
This is the case for adapting from kitchen appliances to books.,"{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"Since the book domain is quite broad, many projections in books model topic distinctions such as between religious and political books.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"These projections, which are uninformative as to the target label, are put into correspondence with the fewer discriminating projections in the much narrower kitchen domain.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
"When we adapt from kitchen to books, we assign weight to these uninformative projections, degrading target classification accuracy.","{'title': '4 Experiments with SCL and SCL-MI', 'number': '4'}"
We now show how to use a small amount of target domain labeled data to learn to ignore misaligned projections from SCL-MI.,"{'title': '5 Correcting Misalignments', 'number': '5'}"
"Using the notation of Ando and Zhang (2005), we can write the supervised training objective of SCL on the source domain as where y is the label.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"The weight vector w E Rd weighs the original features, while v E Rk weighs the projected features.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"Ando and Zhang (2005) and Blitzer et al. (2006) suggest λ = 10−4, µ = 0, which we have used in our results so far.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"Suppose now that we have trained source model weight vectors ws and vs. A small amount of target domain data is probably insufficient to significantly change w, but we can correct v, which is much smaller.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"We augment each labeled target instance xj with the label assigned by the source domain classifier (Florian et al., 2004; Blitzer et al., 2006).","{'title': '5 Correcting Misalignments', 'number': '5'}"
"Then we solve Since we don’t want to deviate significantly from the source parameters, we set λ = µ = 10−1.","{'title': '5 Correcting Misalignments', 'number': '5'}"
Figure 2 shows the corrected SCL-MI model using 50 target domain labeled instances.,"{'title': '5 Correcting Misalignments', 'number': '5'}"
We chose this number since we believe it to be a reasonable amount for a single engineer to label with minimal effort.,"{'title': '5 Correcting Misalignments', 'number': '5'}"
"For reasons of space, for each target domain we show adaptation from only the two domains on which SCL-MI performed the worst relative to the supervised baseline.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"For example, the book domain shows only results from electronics and kitchen, but not DVDs.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"As a baseline, we used the label of the source domain classifier as a feature in the target, but did not use any SCL features.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"We note that the baseline is very close to just using the source domain classifier, because with only 50 target domain instances we do not have enough data to relearn all of the parameters in w. As we can see, though, relearning the 50 parameters in v is quite helpful.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"The corrected model always improves over the baseline for every possible transfer, including those not shown in the figure.","{'title': '5 Correcting Misalignments', 'number': '5'}"
The idea of using the regularizer of a linear model to encourage the target parameters to be close to the source parameters has been used previously in domain adaptation.,"{'title': '5 Correcting Misalignments', 'number': '5'}"
"In particular, Chelba and Acero (2004) showed how this technique can be effective for capitalization adaptation.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"The major difference between our approach and theirs is that we only penalize deviation from the source parameters for the weights v of projected features, while they work with the weights of the original features only.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"For our small amount of labeled target data, attempting to penalize w using ws performed no better than our baseline.","{'title': '5 Correcting Misalignments', 'number': '5'}"
"Because we only need to learn to ignore projections that misalign features, we can make much better use of our labeled data by adapting only 50 parameters, rather than 200,000.","{'title': '5 Correcting Misalignments', 'number': '5'}"
Table 3 summarizes the results of sections 4 and 5.,"{'title': '5 Correcting Misalignments', 'number': '5'}"
Structural correspondence learning reduces the error due to transfer by 21%.,"{'title': '5 Correcting Misalignments', 'number': '5'}"
Choosing pivots by mutual information allows us to further reduce the error to 36%.,"{'title': '5 Correcting Misalignments', 'number': '5'}"
"Finally, by adding 50 instances of target domain data and using this to correct the misaligned projections, we achieve an average relative reduction in error of 46%.","{'title': '5 Correcting Misalignments', 'number': '5'}"
Sections 2-5 focused on how to adapt to a target domain when you had a labeled source dataset.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
We now take a step back to look at the problem of selecting source domain data to label.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
We study a setting where an engineer knows roughly her domains of interest but does not have any labeled data yet.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"In that case, she can ask the question “Which sources should I label to obtain the best performance over all my domains?” On our product domains, for example, if we are interested in classifying reviews of kitchen appliances, we know from sections 4-5 that it would be foolish to label reviews of books or DVDs rather than electronics.","{'title': '6 Measuring Adaptability', 'number': '6'}"
Here we show how to select source domains using only unlabeled data and the SCL representation.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
We propose to measure domain adaptability by using the divergence of two domains after the SCL projection.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"We can characterize domains by their induced distributions on instance space: the more different the domains, the more divergent the distributions.","{'title': '6 Measuring Adaptability', 'number': '6'}"
"Here we make use of the A-distance (BenDavid et al., 2006).","{'title': '6 Measuring Adaptability', 'number': '6'}"
"The key intuition behind the A-distance is that while two domains can differ in arbitrary ways, we are only interested in the differences that affect classification accuracy.","{'title': '6 Measuring Adaptability', 'number': '6'}"
Let A be the family of subsets of Rk corresponding to characteristic functions of linear classifiers (sets on which a linear classifier returns positive value).,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"Then the A distance between two probability distributions is dA(D, D0) = 2 sup |PrD [A] − PrD, [A] |.","{'title': '6 Measuring Adaptability', 'number': '6'}"
"A∈A That is, we find the subset in A on which the distributions differ the most in the Li sense.","{'title': '6 Measuring Adaptability', 'number': '6'}"
Ben-David et al. (2006) show that computing the A-distance for a finite sample is exactly the problem of minimizing the empirical risk of a classifier that discriminates between instances drawn from D and instances drawn from D0.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"This is convenient for us, since it allows us to use classification machinery to compute the A-distance.","{'title': '6 Measuring Adaptability', 'number': '6'}"
We follow Ben-David et al. (2006) and use the Huber loss as a proxy for the A-distance.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"Our procedure is as follows: Given two domains, we compute the SCL representation.","{'title': '6 Measuring Adaptability', 'number': '6'}"
Then we create a data set where each instance Ox is labeled with the identity of the domain from which it came and train a linear classifier.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"For each pair of domains we compute the empirical average per-instance Huber loss, subtract it from 1, and multiply the result by 100.","{'title': '6 Measuring Adaptability', 'number': '6'}"
We refer to this quantity as the proxy A-distance.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"When it is 100, the two domains are completely distinct.","{'title': '6 Measuring Adaptability', 'number': '6'}"
"When it is 0, the two domains are indistinguishable using a linear classifier.","{'title': '6 Measuring Adaptability', 'number': '6'}"
Figure 3 is a correlation plot between the proxy A-distance and the adaptation error.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
Suppose we wanted to label two domains out of the four in such a way as to minimize our error on all the domains.,"{'title': '6 Measuring Adaptability', 'number': '6'}"
"Using the proxy A-distance as a criterion, we observe that we would choose one domain from either books or DVDs, but not both, since then we would not be able to adequately cover electronics or kitchen appliances.","{'title': '6 Measuring Adaptability', 'number': '6'}"
"Similarly we would also choose one domain from either electronics or kitchen appliances, but not both.","{'title': '6 Measuring Adaptability', 'number': '6'}"
"Sentiment classification has advanced considerably since the work of Pang et al. (2002), which we use as our baseline.","{'title': '7 Related Work', 'number': '7'}"
Thomas et al. (2006) use discourse structure present in congressional records to perform more accurate sentiment classification.,"{'title': '7 Related Work', 'number': '7'}"
Pang and Lee (2005) treat sentiment analysis as an ordinal ranking problem.,"{'title': '7 Related Work', 'number': '7'}"
"In our work we only show improvement for the basic model, but all of these new techniques also make use of lexical features.","{'title': '7 Related Work', 'number': '7'}"
Thus we believe that our adaptation methods could be also applied to those more refined models.,"{'title': '7 Related Work', 'number': '7'}"
"While work on domain adaptation for sentiment classifiers is sparse, it is worth noting that other researchers have investigated unsupervised and semisupervised methods for domain adaptation.","{'title': '7 Related Work', 'number': '7'}"
The work most similar in spirit to ours that of Turney (2002).,"{'title': '7 Related Work', 'number': '7'}"
He used the difference in mutual information with two human-selected features (the words “excellent” and “poor”) to score features in a completely unsupervised manner.,"{'title': '7 Related Work', 'number': '7'}"
Then he classified documents according to various functions of these mutual information scores.,"{'title': '7 Related Work', 'number': '7'}"
We stress that our method improves a supervised baseline.,"{'title': '7 Related Work', 'number': '7'}"
"While we do not have a direct comparison, we note that Turney (2002) performs worse on movie reviews than on his other datasets, the same type of data as the polarity dataset.","{'title': '7 Related Work', 'number': '7'}"
"We also note the work of Aue and Gamon (2005), who performed a number of empirical tests on domain adaptation of sentiment classifiers.","{'title': '7 Related Work', 'number': '7'}"
Most of these tests were unsuccessful.,"{'title': '7 Related Work', 'number': '7'}"
We briefly note their results on combining a number of source domains.,"{'title': '7 Related Work', 'number': '7'}"
They observed that source domains closer to the target helped more.,"{'title': '7 Related Work', 'number': '7'}"
In preliminary experiments we confirmed these results.,"{'title': '7 Related Work', 'number': '7'}"
"Adding more labeled data always helps, but diversifying training data does not.","{'title': '7 Related Work', 'number': '7'}"
"When classifying kitchen appliances, for any fixed amount of labeled data, it is always better to draw from electronics as a source than use some combination of all three other domains.","{'title': '7 Related Work', 'number': '7'}"
"Domain adaptation alone is a generally wellstudied area, and we cannot possibly hope to cover all of it here.","{'title': '7 Related Work', 'number': '7'}"
"As we noted in Section 5, we are able to significantly outperform basic structural correspondence learning (Blitzer et al., 2006).","{'title': '7 Related Work', 'number': '7'}"
We also note that while Florian et al. (2004) and Blitzer et al.,"{'title': '7 Related Work', 'number': '7'}"
"(2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data.","{'title': '7 Related Work', 'number': '7'}"
"We believe the most important reason for this is that they explore structured prediction problems, where labels of surrounding words from the source classifier may be very informative, even if the current label is not.","{'title': '7 Related Work', 'number': '7'}"
In contrast our simple binary prediction problem does not exhibit such behavior.,"{'title': '7 Related Work', 'number': '7'}"
This may also be the reason that the model of Chelba and Acero (2004) did not aid in adaptation.,"{'title': '7 Related Work', 'number': '7'}"
"Finally we note that while Blitzer et al. (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al.","{'title': '7 Related Work', 'number': '7'}"
(2004).,"{'title': '7 Related Work', 'number': '7'}"
"By only adapting the SCLrelated part of the weight vector v, we are able to make better use of our small amount of unlabeled data than these previous techniques.","{'title': '7 Related Work', 'number': '7'}"
Sentiment classification has seen a great deal of attention.,"{'title': '8 Conclusion', 'number': '8'}"
Its application to many different domains of discourse makes it an ideal candidate for domain adaptation.,"{'title': '8 Conclusion', 'number': '8'}"
This work addressed two important questions of domain adaptation.,"{'title': '8 Conclusion', 'number': '8'}"
"First, we showed that for a given source and target domain, we can significantly improve for sentiment classification the structural correspondence learning model of Blitzer et al. (2006).","{'title': '8 Conclusion', 'number': '8'}"
We chose pivot features using not only common frequency among domains but also mutual information with the source labels.,"{'title': '8 Conclusion', 'number': '8'}"
We also showed how to correct structural correspondence misalignments by using a small amount of labeled target domain data.,"{'title': '8 Conclusion', 'number': '8'}"
"Second, we provided a method for selecting those source domains most likely to adapt well to given target domains.","{'title': '8 Conclusion', 'number': '8'}"
The unsupervised A-distance measure of divergence between domains correlates well with loss due to adaptation.,"{'title': '8 Conclusion', 'number': '8'}"
Thus we can use the Adistance to select source domains to label which will give low target domain error.,"{'title': '8 Conclusion', 'number': '8'}"
"In the future, we wish to include some of the more recent advances in sentiment classification, as well as addressing the more realistic problem of ranking.","{'title': '8 Conclusion', 'number': '8'}"
We are also actively searching for a larger and more varied set of domains on which to test our techniques.,"{'title': '8 Conclusion', 'number': '8'}"
We thank Nikhil Dinesh for helpful advice throughout the course of this work.,"{'title': 'Acknowledgements', 'number': '9'}"
This material is based upon work partially supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No.,"{'title': 'Acknowledgements', 'number': '9'}"
NBCHD03001.,"{'title': 'Acknowledgements', 'number': '9'}"
"Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the Department of Interior-National BusinessCenter (DOI-NBC).","{'title': 'Acknowledgements', 'number': '9'}"
