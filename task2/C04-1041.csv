col1,col2
This paper describes the role of supertagging in a wide-coverage CCG parser which uses a log-linear model to select an analysis.,Introduction
"The supertagger reduces the derivation space over which model estimation is performed, reducing the space required for discriminative training.",Introduction
It also dramatically increases the speed of the parser.,Introduction
We show that large increases in speedcan be obtained by tightly integrating the su pertagger with the CCG grammar and parser.This is the first work we are aware of to success fully integrate a supertagger with a full parser which uses an automatically extracted grammar.We also further reduce the derivation space us ing constraints on category combination.,Introduction
The result is an accurate wide-coverage CCG parserwhich is an order of magnitude faster than comparable systems for other linguistically moti vated formalisms.,Introduction
Lexicalised grammar formalisms such as Lexicalized Tree Adjoining Grammar (LTAG) and Com binatory Categorial Grammar (CCG) assign one or more syntactic structures to each word in a sentencewhich are then manipulated by the parser.,Experiment/Discussion
"Supertag ging was introduced for LTAG as a way of increasingparsing efficiency by reducing the number of struc tures assigned to each word (Bangalore and Joshi, 1999).",Experiment/Discussion
"Supertagging has more recently been applied to CCG (Clark, 2002; Curran and Clark, 2003).Supertagging accuracy is relatively high for man ually constructed LTAGs (Bangalore and Joshi,1999).",Experiment/Discussion
"However, for LTAGs extracted automati cally from the Penn Treebank, performance is much lower (Chen et al, 1999; Chen et al, 2002).",Experiment/Discussion
"In fact, performance for such grammars is below that needed for successful integration into a full parser (Sarkar et al, 2000).",Experiment/Discussion
"In this paper we demonstratethat CCG supertagging accuracy is not only sufficient for accurate and robust parsing using an auto matically extracted grammar, but also offers several practical advantages.",Experiment/Discussion
Our wide-coverage CCG parser uses a log-linear model to select an analysis.,Experiment/Discussion
"The model paramaters are estimated using a discriminative method, that is,one which requires all incorrect parses for a sentence as well as the correct parse.",Experiment/Discussion
"Since an auto matically extracted CCG grammar can produce anextremely large number of parses, the use of a su pertagger is crucial in limiting the total number of parses for the training data to a computationally manageable number.",Experiment/Discussion
The supertagger is also crucial for increasing thespeed of the parser.,Experiment/Discussion
"We show that spectacular in creases in speed can be obtained, without affectingaccuracy or coverage, by tightly integrating the su pertagger with the CCG grammar and parser.",Experiment/Discussion
"To achieve maximum speed, the supertagger initially assigns only a small number of CCG categories toeach word, and the parser only requests more cate gories from the supertagger if it cannot provide an analysis.",Experiment/Discussion
"We also demonstrate how extra constraints on the category combinations, and the application of beam search using the parsing model, can further increase parsing speed.This is the first work we are aware of to succes fully integrate a supertagger with a full parser which uses a lexicalised grammar automatically extractedfrom the Penn Treebank.",Experiment/Discussion
We also report signifi cantly higher parsing speeds on newspaper text than any previously reported for a full wide-coverage parser.,Experiment/Discussion
Our results confirm that wide-coverage CCG parsing is feasible for many large-scale NLP tasks.,Experiment/Discussion
"Parsing using CCG can be viewed as a two-stage process: first assign lexical categories to the wordsin the sentence, and then combine the categories to gether using CCG?s combinatory rules.1 The first stage can be accomplished by simply assigning to each word all categories from the word?s entry in the lexicon (Hockenmaier, 2003).",Experiment/Discussion
"1See Steedman (2000) for an introduction to CCG, and see Clark et al (2002) and Hockenmaier (2003) for an introduction to wide-coverage parsing using CCG.",Experiment/Discussion
The WSJ is a publication that I enjoy reading NP/N N (S[dcl]\NP)/NP NP/N N (NP\NP)/(S[dcl]/NP) NP (S[dcl]\NP)/(S[ng]\NP) (S[ng]\NP)/NP Figure 1: Example sentence with CCG lexical categories frequency # cat types # cat tokens in # sentences in 2-21 # cat tokens in # sentences in 00 cut-off 2-21 not in cat set with missing cat 00 not in cat set with missing cat 1 1 225 0 0 12 (0.03%) 12 (0.6%) 10 409 1 933 (0.2%) 1 712 (4.3%) 79 (0.2%) 69 (3.6%) Table 1: Statistics for the lexical category setAn alternative is to use a statistical tagging approach to assign one or more categories.,Experiment/Discussion
A statisti cal model can be used to determine the most likelycategories given the word?s context.,Experiment/Discussion
"The advantage of this supertagging approach is that the number of categories assigned to each word can be re duced, with a correspondingly massive reduction in the number of derivations.",Experiment/Discussion
Bangalore and Joshi (1999) use a standard Markov model tagger to assign LTAG elementarytrees to words.,Experiment/Discussion
Here we use the Maximum En tropy models described in Curran and Clark (2003).,Experiment/Discussion
"An advantage of the Maximum Entropy approachis that it is easy to encode a wide range of poten tially useful information as features; for example,Clark (2002) has shown that POS tags provide use ful information for supertagging.",Experiment/Discussion
The next section describes the set of lexical categories used by our supertagger and parser.,Experiment/Discussion
2.1 The Lexical Category Set.,Experiment/Discussion
"The set of lexical categories is obtained from CCGbank (Hockenmaier and Steedman, 2002; Hockenmaier, 2003), a corpus of CCG normal-form deriva tions derived semi-automatically from the PennTreebank.",Experiment/Discussion
"Following Clark (2002), we apply a fre quency cutoff to the training set, only using thosecategories which appear at least 10 times in sections 2-21.",Experiment/Discussion
Figure 1 gives an example sentence su pertagged with the correct CCG lexical categories.,Experiment/Discussion
Table 1 gives the number of different category types and shows the coverage on training (seen) anddevelopment (unseen) data (section 00 from CCGbank).,Experiment/Discussion
The table also gives statistics for the com plete set containing every lexical category type inCCGbank.2 These figures show that using a fre quency cutoff can significantly reduce the size of the category set with only a small loss in coverage.,Experiment/Discussion
2The numbers differ slightly from those reported in Clark (2002) since a newer version of CCGbank is being used here.,Experiment/Discussion
Clark (2002) compares the size of grammarsextracted from CCGbank with automatically extracted LTAGs.,Experiment/Discussion
"The grammars of Chen and Vijay Shanker (2000) contain between 2,000 and 9,000 tree frames, depending on the parameters used inthe extraction process, significantly more elemen tary structures than the number of lexical categories derived from CCGbank.",Experiment/Discussion
We hypothesise this is a key factor in the higher accuracy for supertaggingusing a CCG grammar compared with an automati cally extracted LTAG.,Experiment/Discussion
2.2 The Tagging Model.,Experiment/Discussion
The supertagger uses probabilities p(y|x) where y is a lexical category and x is a context.,Experiment/Discussion
"The conditional probabilities have the following log-linear form: p(y|x) = 1 Z(x)e ? i ?i fi(y,x) (1) where fi is a feature, ?i is the corresponding weight, and Z(x) is a normalisation constant.",Experiment/Discussion
The context is a 5-word window surrounding the target word.,Experiment/Discussion
Features are defined for each word in the window and for the POS tag of each word.,Experiment/Discussion
"Curran and Clark(2003) describes the model and explains how Gen eralised Iterative Scaling, together with a Gaussian prior for smoothing, can be used to set the weights.",Experiment/Discussion
"The supertagger in Curran and Clark (2003) finds the single most probable category sequence given the sentence, and uses additional features defined in terms of the previously assigned categories.",Experiment/Discussion
"Theper-word accuracy is between 91 and 92% on un seen data in CCGbank; however, Clark (2002) shows this is not high enough for integration into a parser since the large number of incorrect categories results in a significant loss in coverage.",Experiment/Discussion
Clark (2002) shows how the models in (1) can be used to define a multi-tagger which can assign more than one category to a word.,Experiment/Discussion
"For each word inthe sentence, the multi-tagger assigns all those cat ? CATS/ ACC SENT ACC SENT WORD ACC (POS) ACC 0.1 1.4 97.0 62.6 96.4 57.4 0.075 1.5 97.4 65.9 96.8 60.6 0.05 1.7 97.8 70.2 97.3 64.4 0.01 2.9 98.5 78.4 98.2 74.2 0.01k=100 3.5 98.9 83.6 98.6 78.9 0 21.9 99.1 84.8 99.0 83.0 Table 2: Supertagger accuracy on section 00 egories whose probability according to (1) is within some factor, ?, of the highest probability category for the word.",Experiment/Discussion
We follow Clark (2002) in ignoring the featuresbased on the previously assigned categories; there fore every tagging decision is local and the Viterbi algorithm is not required.,Experiment/Discussion
"This simple approach has the advantage of being very efficient, and we findthat it is accurate enough to enable highly accu rate parsing.",Experiment/Discussion
"However, a method which used theforward-backward algorithm to sum over all possi ble sequences, or some other method which took into account category sequence information, may well improve the results.",Experiment/Discussion
"For words seen at least k times in the trainingdata, the tagger can only assign categories appear ing in the word?s entry in the tag dictionary.",Experiment/Discussion
Eachentry in the tag dictionary is a list of all the cate gories seen with that word in the training data.,Experiment/Discussion
"For words seen less than k times, we use an alternative dictionary based on the word?s POS tag: the tagger can only assign categories that have been seen with the POS tag in the training data.",Experiment/Discussion
"A value of k = 20was used in this work, and sections 2-21 of CCG bank were used as training data.Table 2 gives the per-word accuracy (acc) on sec tion 00 for various values of ?, together with the average number of categories per word.",Experiment/Discussion
The sent acc column gives the precentage of sentences whose words are all supertagged correctly.,Experiment/Discussion
The figures for ? = 0.01k=100 correspond to a value of 100 for thetag dictionary parameter k. The set of categories as signed to a word is considered correct if it contains the correct category.,Experiment/Discussion
"The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran andClark (2003) tagger.",Experiment/Discussion
The drop in accuracy is ex pected given the importance of POS tags as features.,Experiment/Discussion
The figures for ? = 0 are obtained by assigning all categories to a word from the word?s entry in the tag dictionary.,Experiment/Discussion
"For words which appear less than 20 times in the training data, the dictionary based on the word?s POS tag is used.",Experiment/Discussion
The table demonstrates the significant reduction in the average number of categories that can be achieved through the use of a supertagger.,Experiment/Discussion
"To give one example, the number of categories in the tag dictionary?s entry for the wordis is 45 (only considering categories which have appeared at least 10 times in the training data).",Experiment/Discussion
"However, in the sentence Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group., the supertag ger correctly assigns 1 category to is for ? = 0.1, and 3 categories for ? = 0.01.",Experiment/Discussion
The parser is described in detail in Clark and Curran (2004).,Experiment/Discussion
It takes POS tagged sentences as input with each word assigned a set of lexical categories.,Experiment/Discussion
"A packed chart is used to efficiently represent all of the possible analyses for a sentence, and the CKY chart parsing algorithm described in Steedman (2000) is used to build the chart.",Experiment/Discussion
Clark and Curran (2004) evaluate a number of log-linear parsing models for CCG.,Experiment/Discussion
"In this paper weuse the normal-form model, which defines proba bilities with the conditional log-linear form in (1), where y is a derivation and x is a sentence.",Experiment/Discussion
"Featuresare defined in terms of the local trees in the derivation, including lexical head information and word word dependencies.",Experiment/Discussion
The normal-form derivations in CCGbank provide the gold standard training data.,Experiment/Discussion
The feature set we use is from the best performing normal-form model in Clark and Curran (2004).,Experiment/Discussion
"For a given sentence the output of the parser is a dependency structure corresponding to the most probable derivation, which can be found using theViterbi algorithm.",Experiment/Discussion
The dependency relations are de fined in terms of the argument slots of CCG lexical categories.,Experiment/Discussion
Clark et al (2002) and Clark and Curran (2004) give a detailed description of the dependency structures.,Experiment/Discussion
3.1 Model Estimation.,Experiment/Discussion
In Clark and Curran (2004) we describe a discrim inative method for estimating the parameters of a log-linear parsing model.,Experiment/Discussion
The estimation method maximises the following objective function: L?(?),Experiment/Discussion
= L(?),Experiment/Discussion
?G(?),Experiment/Discussion
"(2) = log m ? j=1 P?(d j|S j) ? n ? i=1 ?2i 2?2The data consists of sentences S 1, . . .",Experiment/Discussion
", S m, to gether with gold standard normal-form derivations, d1, . . .",Experiment/Discussion
", dm.",Experiment/Discussion
L(?),Experiment/Discussion
"is the log-likelihood of model ?, and G(?)",Experiment/Discussion
is a Gaussian prior term used to avoid overfitting (n is the number of features; ?i is the weight for feature fi; and ? is a parameter of theGaussian).,Experiment/Discussion
"The objective function is optimised using L-BFGS (Nocedal and Wright, 1999), an iterative algorithm from the numerical optimisation lit erature.The algorithm requires the gradient of the objective function, and the value of the objective function, at each iteration.",Experiment/Discussion
Calculation of these val ues requires all derivations for each sentence in the training data.,Experiment/Discussion
In Clark and Curran (2004) wedescribe efficient methods for performing the cal culations using packed charts.,Experiment/Discussion
"However, a very large amount of memory is still needed to store the packed charts for the complete training data even though the representation is very compact; in Clark and Curran (2003) we report a memory usage of 30 GB.",Experiment/Discussion
To handle this we have developed a parallel implementation of the estimation algorithm which runs on a Beowulf cluster.,Experiment/Discussion
"The need for large high-performance computing resources is a disadvantage of our earlier approach.In the next section we show how use of the supertag ger, combined with normal-form constraints on thederivations, can significantly reduce the memory re quirements for the model estimation.",Experiment/Discussion
"Since the training data contains the correct lexicalcategories, we ensure the correct category is as signed to each word when generating the packed charts for model estimation.",Experiment/Discussion
"Whilst training theparser, the supertagger can be thought of as supply ing a number of plausible but incorrect categoriesfor each word; these, together with the correct cat egories, determine the parts of the parse space that are used in the estimation process.",Experiment/Discussion
"We would like to keep the packed charts as small as possible, but not lose accuracy in the resulting parser.",Experiment/Discussion
Section 4.2discusses the use of various settings on the supertag ger.,Experiment/Discussion
The next section describes how normal-form constraints can further reduce the derivation space.,Experiment/Discussion
4.1 Normal-Form Constraints.,Experiment/Discussion
"As well as the supertagger, we use two additional strategies for reducing the derivation space.",Experiment/Discussion
"Thefirst, following Hockenmaier (2003), is to only al low categories to combine if the combination hasbeen seen in sections 2-21 of CCGbank.",Experiment/Discussion
"For exam ple, NP/NP could combine with NP/NP accordingto CCG?s combinatory rules (by forward composi tion), but since this particular combination does not appear in CCGbank the parser does not allow it.The second strategy is to use Eisner?s normal form constraints (Eisner, 1996).",Experiment/Discussion
The constraints SUPERTAGGING/PARSING USAGE CONSTRAINTS DISK MEMORY ? = 0.01 ? 0.05 ? 0.1 17 GB 31 GB CCGbank constraints 13 GB 23 GB Eisner constraints 9 GB 16 GB ? = 0.05 ? 0.1 2 GB 4 GB Table 3: Space requirements for model training dataprevent any constituent which is the result of a forward (backward) composition serving as the primary functor in another forward (backward) composition or a forward (backward) application.,Experiment/Discussion
"Eis ner only deals with a grammar without type-raising,and so the constraints do not guarantee a normal form parse when using a grammar extracted from CCGbank.",Experiment/Discussion
"However, the constraints are still useful in restricting the derivation space.",Experiment/Discussion
"As far as we are aware, this is the first demonstration of the utility of such constraints for a wide-coverage CCG parser.",Experiment/Discussion
4.2 Results (Space Requirements).,Experiment/Discussion
"Table 3 shows the effect of different supertagger set tings, and the normal-form constraints, on the size of the packed charts used for model estimation.",Experiment/Discussion
"The disk usage is the space taken on disk by the charts,and the memory usage is the space taken in memory during the estimation process.",Experiment/Discussion
"The training sen tences are parsed using a number of nodes from a 64-node Beowulf cluster.3 The time taken to parse the training sentences depends on the supertagging and parsing constraints, and the number of nodes used, but is typically around 30 minutes.",Experiment/Discussion
"The first row of the table corresponds to using the least restrictive ? value of 0.01, and reverting to ? = 0.05, and finally ? = 0.1, if the chart size exceeds some threshold.",Experiment/Discussion
"The threshold was set at300,000 nodes in the chart.",Experiment/Discussion
Packed charts are created for approximately 94% of the sentences in sec tions 2-21 of CCGbank.,Experiment/Discussion
"The coverage is not 100%because, for some sentences, the parser cannot pro vide an analysis, and some charts exceed the node limit even at the ? = 0.1 level.",Experiment/Discussion
"This strategy was used in our earlier work (Clark and Curran, 2003) and, as the table shows, results in very large charts.Note that, even with this relaxed setting on the su pertagger, the number of categories assigned to each word is only around 3 on average.",Experiment/Discussion
"This suggests that it is only through use of the supertagger that we are able to estimate a log-linear parsing model on all of the training data at all, since without it the memory 3The figures in the table are estimates based on a sample of the nodes in the cluster.",Experiment/Discussion
"requirements would be far too great, even for the entire 64-node cluster.4 The second row shows the reduction in size if the parser is only allowed to combine categorieswhich have combined in the training data.",Experiment/Discussion
"This sig nificantly reduces the number of categories created using the composition rules, and also prevents thecreation of unlikely categories using rule combina tions not seen in CCGbank.",Experiment/Discussion
The results show thatthe memory and disk usage are reduced by approx imately 25% using these constraints.,Experiment/Discussion
The third row shows a further reduction in size when using the Eisner normal-form constraints.,Experiment/Discussion
"Even with the CCGbank rule constraints, theparser still builds many non-normal-form derivations, since CCGbank does contain cases of compo sition and type-raising.",Experiment/Discussion
"(These are used to analysesome coordination and extraction cases, for example.)",Experiment/Discussion
The combination of the two types of normal form constraints reduces the memory requirements by 48% over the original approach.,Experiment/Discussion
In Clark andCurran (2004) we show that the parsing model re sulting from training data generated in this way produces state-of-the-art CCG dependency recovery: 84.6 F-score over labelled dependencies.,Experiment/Discussion
"The final row corresponds to a more restrictive setting on the supertagger, in which a value of ? = 0.05 is used initially and ? = 0.1 is used if thenode limit is exceeded.",Experiment/Discussion
The two types of normal form constraints are also used.,Experiment/Discussion
In Clark and Curran(2004) we show that using this more restrictive set ting has a small negative impact on the accuracy of the resulting parser (about 0.6 F-score over labelled dependencies).,Experiment/Discussion
"However, the memory requirement for training the model is now only 4 GB, a reduction of 87% compared with the original approach.",Experiment/Discussion
"The previous section showed how to combine the supertagger and parser for the purpose of creating training data, assuming the correct category for each word is known.",Results/Conclusion
In this section we describe our approach to tightly integrating the supertagger and parser for parsing unseen data.,Results/Conclusion
"Our previous approach to parsing unseen data (Clark et al, 2002; Clark and Curran, 2003) wasto use the least restrictive setting of the supertagger which still allows a reasonable compromise be tween speed and accuracy.",Results/Conclusion
"Our philosophy was to give the parser the greatest possibility of finding thecorrect parse, by giving it as many categories as pos sible, while still retaining reasonable efficiency.4Another possible solution would be to use sampling meth ods, e.g. Osborne (2000).",Results/Conclusion
SUPERTAGGING/PARSING TIME SENTS WORDS CONSTRAINTS SEC /SEC /SEC ? = 0.01?,Results/Conclusion
0.1 3 523 0.7 16 CCGbank constraints 1 181 2.0 46 Eisner constraints 995 2.4 55 ? = 0.1?,Results/Conclusion
"0.01k=100 608 3.9 90 CCGbank constraints 124 19.4 440 Eisner constraints 100 24.0 546 Parser beam 67 35.8 814 94% coverage 49 49.0 1 114 Parser beam 46 52.2 1 186 Oracle 18 133.4 3 031 Table 4: Parse times for section 23 The problem with this approach is that, for some sentences, the number of categories in the chart still gets extremely large and so parsing is unacceptably slow.",Results/Conclusion
"Hence we applied a limit to the number of categories in the chart, as in the previous section,and reverted to a more restrictive setting of the su pertagger if the limit was exceeded.",Results/Conclusion
"We first used a value of ? = 0.01, and then reverted to ? = 0.05, and finally ? = 0.1.",Results/Conclusion
"In this paper we take the opposite approach: westart with a very restrictive setting of the supertag ger, and only assign more categories if the parser cannot find an analysis spanning the sentence.",Results/Conclusion
In this way the parser interacts much more closely with the supertagger.,Results/Conclusion
"In effect, the parser is using the grammar to decide if the categories provided by thesupertagger are acceptable, and if not the parser re quests more categories.",Results/Conclusion
"The parser uses the 5 levels given in Table 2, starting with ? = 0.1 and moving through the levels to ? = 0.01k=100 . The advantage of this approach is that parsing speeds are much higher.",Results/Conclusion
We also show that our new approach slightly increases parsing accuracy over the previous method.,Results/Conclusion
"This suggests that, given our current parsing model, it is better to rely largely on the supertagger to provide the correct categoriesrather than use the parsing model to select the cor rect categories from a very large derivation space.",Results/Conclusion
5.1 Results (Parse Times).,Results/Conclusion
"The results in this section are all using the best per forming normal-form model in Clark and Curran (2004), which corresponds to row 3 in Table 3.",Results/Conclusion
All experiments were run on a 2.8 GHZ Intel Xeon P4 with 2 GB RAM.,Results/Conclusion
"Table 4 gives parse times for the 2,401 sentences in section 23 of CCGbank.",Results/Conclusion
"The final two columns give the number of sentences, and the number of ? CATS/ 0.1 FIRST 0.01 FIRST WORD PARSES % PARSES % 0.1 1.4 1689 88.4 0 0.0 0.075 1.5 43 2.3 7 0.4 0.05 1.7 51 2.7 39 2.0 0.01 2.9 79 4.1 1816 95.1 0.01k=100 3.5 33 1.7 33 1.7 NO SPAN 15 0.8 15 0.8 Table 5: Supertagger ? levels used on section 00words, parsed per second.",Results/Conclusion
"For all of the figures re ported on section 23, unless stated otherwise, the parser is able to provide an analysis for 98.5% of the sentences.",Results/Conclusion
"The parse times and speeds include the failed sentences, but do not include the time takenby the supertagger; however, the supertagger is ex tremely efficient, and takes less than 6 seconds to supertag section 23, most of which consists of load time for the Maximum Entropy model.",Results/Conclusion
The first three rows correspond to our strategy ofearlier work by starting with the least restrictive set ting of the supertagger.,Results/Conclusion
"The first value of ? is 0.01; if the parser cannot find a spanning analysis, this ischanged to ? = 0.01k=100; if the node limit is ex ceeded (for these experiments set at 1,000,000), ? is changed to 0.05.",Results/Conclusion
"If the node limit is still exceeded, ? is changed to 0.075, and finally 0.1.",Results/Conclusion
"The second row has the CCGbank rule restriction applied, and the third row the Eisner normal-form restrictions.The next three rows correspond to our new strat egy of starting with the least restrictive setting of thesupertagger (?",Results/Conclusion
"= 0.1), and moving through the set tings if the parser cannot find a spanning analysis.",Results/Conclusion
"The table shows that the normal-form constraints have a significant impact on the speed, reducing theparse times for the old strategy by 72%, and reduc ing the times for the new strategy by 84%.",Results/Conclusion
"The new strategy also has a spectacular impact on the speed compared with the old strategy, reducing the times by 83% without the normal-form constraints and 90% with the constraints.",Results/Conclusion
The 94% coverage row corresponds to using only the first two supertagging levels; the parser ignores the sentence if it cannot get an analysis at the ? = 0.05 level.,Results/Conclusion
"The percentage of sentences without an analysis is now 6%, but the parser is extremely fast,processing almost 50 sentences a second.",Results/Conclusion
"This configuration of the system would be useful for obtaining data for lexical knowledge acquisition, for ex ample, for which large amounts of data are required.",Results/Conclusion
"The oracle row shows the parser speed when it is provided with only the correct lexical categories.The parser is extremely fast, and in Clark and Cur ran (2004) we show that the F-score for labelled dependencies is almost 98%.",Results/Conclusion
"This demonstratesthe large amount of information in the lexical categories, and the potential for improving parser ac curacy and efficiency by improving the supertagger.",Results/Conclusion
"Finally, the first parser beam row corresponds to the parser using a beam search to further reduce thederivation space.",Results/Conclusion
"The beam search works by prun ing categories from the chart: a category can only be part of a derivation if its beam score is within some factor, ?, of the highest scoring category forthat cell in the chart.",Results/Conclusion
"Here we simply use the ex ponential of the inside score of a category as the beam score; the inside score for a category c is the sum over all sub-derivations dominated by c of the weights of the features in those sub-derivations (see Clark and Curran (2004).5The value of ? that we use here reduces the accu racy of the parser on section 00 by a small amount (0.3% labelled F-score), but has a significant impacton parser speed, reducing the parse times by a fur ther 33%.",Results/Conclusion
"The final parser beam row combines thebeam search with the fast, reduced coverage config uration of the parser, producing speeds of over 50 sentences per second.",Results/Conclusion
"Table 5 gives the percentage of sentences which are parsed at each supertagger level, for both the new and old parsing strategies.",Results/Conclusion
"The results show that, for the old approach, most of the sentences areparsed using the least restrictive setting of the supertagger (?",Results/Conclusion
"= 0.01); conversely, for the new ap proach, most of the sentences are parsed using the most restrictive setting (?",Results/Conclusion
= 0.1).,Results/Conclusion
"As well as investigating parser efficiency, we have also evaluated the accuracy of the parser onsection 00 of CCGbank, using both parsing strate gies together with the normal-form constraints.",Results/Conclusion
"Thenew strategy increases the F-score over labelled de pendencies by approximately 0.5%, leading to the figures reported in Clark and Curran (2004).",Results/Conclusion
5.2 Comparison with Other Work.,Results/Conclusion
The only other work we are aware of to investigate the impact of supertagging on parsing efficiency is the work of Sarkar et al (2000) for LTAG.,Results/Conclusion
Sarkar etal.,Results/Conclusion
"did find that LTAG supertagging increased pars ing speed, but at a significant cost in coverage: only 1,324 sentences out of a test set of 2,250 received a parse.",Results/Conclusion
"The parse times reported are also not as good as those reported here: the time taken to parse the 2,250 test sentences was over 5 hours.5Multiplying by an estimate of the outside score may im prove the efficacy of the beam.",Results/Conclusion
Kaplan et al (2004) report high parsing speedsfor a deep parsing system which uses an LFG gram mar: 1.9 sentences per second for 560 sentencesfrom section 23 of the Penn Treebank.,Results/Conclusion
"They also re port speeds for the publicly available Collins parser (Collins, 1999): 2.8 sentences per second for the same set.",Results/Conclusion
The best speeds we have reported for the CCG parser are an order of magnitude faster.,Results/Conclusion
"This paper has shown that by tightly integrating a supertagger with a CCG parser, very fast parse times can be achieved for Penn Treebank WSJ text.",Results/Conclusion
"As far as we are aware, the times reported here are an orderof magnitude faster than any reported for compara ble systems using linguistically motivated grammar formalisms.",Results/Conclusion
The techniques we have presented inthis paper increase the speed of the parser by a factor of 77.,Results/Conclusion
"This makes this parser suitable for large scale NLP tasks.The results also suggest that further improvements can be obtained by improving the supertagger, which should be possible given the simple tag ging approach currently being used.The novel parsing strategy of allowing the grammar to decide if the supertagging is likely to be cor rect suggests a number of interesting possibilities.In particular, we would like to investigate only re pairing those areas of the chart that are most likely to contain errors, rather than parsing the sentence from scratch using a new set of lexical categories.",Results/Conclusion
This could further increase parsing effficiency.,Results/Conclusion
"Acknowledgements We would like to thank Julia Hockenmaier, whosework creating the CCGbank made this research possible, and Mark Steedman for his advice and guid ance.",Results/Conclusion
"This research was supported by EPSRC grant GR/M96889, and a Commonwealth scholarship and a Sydney University Travelling scholarship to the second author.",Results/Conclusion
