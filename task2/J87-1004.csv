col1,col2
"An efficient parsing algorithm for augmented context-free grammars is introduced, and its application to on-line natural language interfaces discussed.",{}
"The algorithm is a generalized LR parsing algorithm, which precomputes an LR shift-reduce parsing table (possibly with multiple entries) from a given augmented context-free grammar.",{}
"Unlike the standard LR parsing algorithm, it can handle arbitrary context-free grammars, including ambiguous grammars, while most of the LR efficiency is preserved by introducing the concept of a &quot;graph-structured stack&quot;.",{}
The graph-structured stack allows an LR shift-reduce parser to maintain multiple parses without parsing any part of the input twice in the same way.,{}
We can also view our parsing algorithm as an extended chart parsing algorithm efficiently guided by LR parsing tables.,{}
"The algorithm is fast, due to the LR table precomputation.",{}
"In several experiments with different English grammars and sentences, timings indicate a fiveto tenfold speed advantage over Earley's context-free parsing algorithm. algorithm parses a sentence strictly from left to right that is, starts parsing as soon as the user types in the first word of a sentence, without waiting for completion of the sentence.",{}
"A practical on-line parser based on the algorithm has been implemented in Common Lisp, and running on Symbolics and HP Al workstations.",{}
The parser is used in the multi-lingual machine translation project at CMU.,{}
"Also, a commercial on-line parser for Japanese language is being built by Intelligent Technology Incorporation, on the technique developed at",{}
"An efficient parsing algorithm for augmented context-free grammars is introduced, and its application to on-line natural language interfaces discussed.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
"The algorithm is a generalized LR parsing algorithm, which precomputes an LR shift-reduce parsing table (possibly with multiple entries) from a given augmented context-free grammar.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
"Unlike the standard LR parsing algorithm, it can handle arbitrary context-free grammars, including ambiguous grammars, while most of the LR efficiency is preserved by introducing the concept of a &quot;graph-structured stack&quot;.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
The graph-structured stack allows an LR shift-reduce parser to maintain multiple parses without parsing any part of the input twice in the same way.,"{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
We can also view our parsing algorithm as an extended chart parsing algorithm efficiently guided by LR parsing tables.,"{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
"The algorithm is fast, due to the LR table precomputation.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
"In several experiments with different English grammars and sentences, timings indicate a five- to tenfold speed advantage over Earley's context-free parsing algorithm.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
"The algorithm parses a sentence strictly from left to right on-line, that is, it starts parsing as soon as the user types in the first word of a sentence, without waiting for completion of the sentence.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
"A practical on-line parser based on the algorithm has been implemented in Common Lisp, and running on Symbolics and HP Al workstations.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
The parser is used in the multi-lingual machine translation project at CMU.,"{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
"Also, a commercial on-line parser for Japanese language is being built by Intelligent Technology Incorporation, based on the technique developed at CMU.","{'title': 'Center for Machine Translation Carnegie-Mellon University Pittsburgh, PA 15213', 'number': '1'}"
Parsing efficiency is crucial when building practical natural language systems on smaller computers such as personal workstations.,"{'title': '1 INTRODUCTION', 'number': '2'}"
"This is especially the case for interactive systems such as natural language database access, interfaces to expert systems, and interactive machine translation.","{'title': '1 INTRODUCTION', 'number': '2'}"
"This paper introduces an efficient on-line parsing algorithm, and focuses on its practical application to natural language interfaces.","{'title': '1 INTRODUCTION', 'number': '2'}"
"The algorithm can be viewed as a generalized LR parsing algorithm that can handle arbitrary context-free grammars, including ambiguous grammars.","{'title': '1 INTRODUCTION', 'number': '2'}"
Section 2 describes the algorithm by extending the standard LR parsing algorithm with the idea of a &quot;graph-structured stack&quot;.,"{'title': '1 INTRODUCTION', 'number': '2'}"
"Section 3 describes how to represent parse trees efficiently, so that all possible parse trees (the parse forest) take at most polynomial space as the ambiguity of a sentence grows exponentially.","{'title': '1 INTRODUCTION', 'number': '2'}"
"In section 4, several examples are given.","{'title': '1 INTRODUCTION', 'number': '2'}"
"Section 5 presents several empirical results of the algorithm's practical performance, including comparison with Earley's algorithm.","{'title': '1 INTRODUCTION', 'number': '2'}"
"In section 6, we discuss how to enhance the algorithm to handle augmented context-free grammars rather than pure context-free grammars.","{'title': '1 INTRODUCTION', 'number': '2'}"
"Section 7 describes the concept of on-line parsing, taking advantage of left-to-right operation of our parsing algorithm.","{'title': '1 INTRODUCTION', 'number': '2'}"
"The on-line parser parses a sentence strictly from left to right, and starts parsing as soon as the user types in the first word, without waiting for the end of line.","{'title': '1 INTRODUCTION', 'number': '2'}"
Benefits of on-line parsing are then discussed.,"{'title': '1 INTRODUCTION', 'number': '2'}"
"Finally, several versions of on-line parser have been implemented, and they are mentioned in section 8.","{'title': '1 INTRODUCTION', 'number': '2'}"
"The LR parsing algorithms (Aho and Ullman 1972, Aho and Johnson 1974) were developed originally for programming languages.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
An LR parsing algorithm is a Copyright 1987 by the Association for Computational Linguistics.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"To copy otherwise, or to republish, requires a fee and/or specific permission.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
0362-613X/87 /010031-46$ 03.00 shift-reduce parsing algorithm deterministically guided by a parsing table indicating what action should be taken next.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"The parsing table can be obtained automatically from a context-free phrase structure grammar, using an algorithm first developed by DeRemer (1969, 1971).","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"We do not describe the algorithms here, referring the reader to chapter 6 in Aho and Ullman (1977).","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
We assume that the reader is familiar with the standard LR parsing algorithm (not necessarily with the parsing table construction algorithm).,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The LR paring algorithm is one of the most efficient parsing algorithms.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"It is totally deterministic, and no backtracking or search is involved.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Unfortunately, we cannot directly adopt the LR parsing technique for natural languages, because it is applicable only to a small subset of context-free grammars called LR grammars, and it is almost certain that any practical natural language grammars are not LR.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"If a grammar is non-LR, its parsing table will have multiple entries;1 one or more of the action table entries will be multiply defined (Shieber 1983).","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Figures 2.1 and 2.2 show an example of a non-LR grammar and its parsing table.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Grammar symbols starting with &quot;s&quot; represent pre-terminals.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Entries &quot;sh n&quot; in the action table (the left part of the table) indicate the action &quot;shift one word from input buffer onto the stack, and go to state n&quot;.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Entries &quot;re n&quot; indicate the action &quot;reduce constituents on the stack using rule n&quot;.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"The entry &quot;acc&quot; stands for the action &quot;accept&quot;, and blank spaces represent &quot;error&quot;.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The goto table (the right part of the table) decides to what state the parser should go after a reduce action.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
These operations shall become clear when we trace the algorithm with example sentences in section 4.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The exact definition and operation of the LR parser can be found in Aho and Ullman (1977).,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
We can see that there are two multiple entries in the action table; on the rows of state 11 and 12 at the column labeled &quot;prep&quot;.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Roughly speaking, this is the situation where the parser encounters a preposition of a PP right after a NP.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"If this PP does not modify the NP, then the parser can go ahead to reduce the NP into a higher nonterminal such as PP or VP, using rule 6 or 7, respectively (re& and re7 in the multiple entries).","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"If, on the other hand, the PP does modify the NP, then the parser must wait (sh6) until the PP is completed so it can build a higher NP using rule 5.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"It has been thought that, for LR parsing, multiple entries are fatal because once a parsing table has multiple entries, deterministic parsing is no longer possible and some kind of non-determinism is necessary.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"We handle multiple entries with a special technique, named a graphstructured stack.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In order to introduce the concept, we first give a simpler form of non-determinism, and make refinements on it.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Subsection 2.1 describes a simple and straightforward non-deterministic technique, that is, pseudo-parallelism (breadth-first search), in which the system maintains a number of stacks simultaneously, called the Stack List.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
A disadvantage of the stack list is then described.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"The next subsection describes the idea of stack combination, which was introduced in the author's earlier research (Tomita 1984), to make the algorithm much more efficient.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"With this idea, stacks are represented as trees (or a forest).","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Finally, a further refinement, the graph-structured stack, is described to make the algorithm even more efficient; efficient enough to run in polynomial time.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The simplest idea would be to handle multiple entries non-deterministically.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"We adopt pseudo-parallelism (breadth-first search), maintaining a list of stacks (the Stack List).","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The pseudo-parallelism works as follows.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
A number of processes are operated in parallel.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Each process has a stack and behaves basically the same as in standard LR parsing.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"When a process encounters a multiple entry, the process is split into several processes (one for each entry), by replicating its stack.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"When a process encounters an error entry, the process is killed, by removing its stack from the stack list.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
All processes are synchronized; they shift a word at the same time so that they always look at the same word.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Thus, if a process encounters a shift action, it waits until all other processes also encounter a (possibly different) shift action.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Figure 2.3 shows a snapshot of the stack list right after shifting the word with in the sentence I saw a man on the bed in the apartment with a telescope using the grammar in Figure 2.1 and the parsing table in Figure 2.2.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"For the sake of convenience, we denote a stack with vertices and edges.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"The leftmost vertex is the bottom of the stack, and the rightmost vertex is the top of the stack.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Vertices represented by a circle are called state vertices, and they represent a state number.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Vertices represented by a square are called symbol vertices, and they represent a grammar symbol.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Each stack is exactly the same as a stack in the standard LR parsing algorithm.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"The distance between vertices (length of an edge) does not have any significance, except it may help the reader understand the status of the stacks.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In the figures, &quot;p&quot; stands for *prep, and &quot;d&quot; stands for *det throughout this paper.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Since the sentence is 14-way ambiguous, the stack has been split into 14 stacks.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"For example, the sixth stack (05 1 *p 6 NP 11 *p 6) is in the status where I saw a man on the bed has been reduced into S, and the apartment has been reduced into NP.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"From the LR parsing table, we know that the top of the stack, state 6, is expecting *det or *n and eventually a NP.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Thus, after a telescope comes in, a PP with a telescope will be formed, and the PP will modify the NP the apartment, and in the apartment will modify the S I saw a man.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
We notice that some stacks in the stack list appear to be identical.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
This is because they have reached the current state in different ways.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"For example, the sixth and seventh stacks are identical, because I saw a man on the bed has been reduced into S in two different ways.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"A disadvantage of the stack list method is that there are no interconnections between stacks (processes), and there is no way in which a process can utilize what other processes have done already.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"The number of stacks in the stack list grows exponentially as ambiguities are encountered.3 For example, these 14 processes in Figure 2.3 will parse the rest of the sentence the telescope 14 I saw a man on the bed in the apartment with a telescope (with the the grammar and the table in Figures 2.1 and 2.2). times in exactly the same way.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"This can be avoided by using a tree-structured stack, which is described in the following subsection.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"If two processes are in a common state, that is, if two stacks have a common state number at the rightmost vertex, they will behave in exactly the same manner until the vertex is popped from the stacks by a reduce action.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"To avoid this redundant operation, these processes are unified into one process by combining their stacks.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Whenever two or more processes have a common state number on the top of their stacks, the top vertices are unified, and these stacks are represented as a tree, where the top vertex corresponds to the root of the tree.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
We call this a tree-structured stack.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"When the top vertex is popped, the tree-structured stack is split into the original number of stacks.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In general, the system maintains a number of tree-structured stacks in parallel, so stacks are represented as a forest.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Figure 2.4 shows a snapshot of the tree-structured stack immediately after shifting the word with.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In contrast to the previous example, the telescope will be parsed only once.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Although the amount of computation is significantly reduced by the stack combination technique, the number of branches of the tree-structured stack (the number of bottoms of the stack) that must be maintained still grows exponentially as ambiguities are encountered.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In the next subsection, we describe a further modification in which stacks are represented as a directed acyclic graph, in order to avoid such inefficiency.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"So far, when a stack is split, a copy of the whole stack is made.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"However, we do not necessarily have to copy the whole stack: even after different parallel operations on the tree-structured stack, the bottom portion of the stack may remain the same.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Only the necessary portion of the stack should therefore be split.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"When a stack is split, the stack is thus represented as a tree, where the bottom of the stack corresponds to the root of the tree.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"With the stack combination technique described in the previous subsection, stacks are represented as a directed acyclic graph.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
Figure 2.5 shows a snapshot of the graph stack.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
It is easy to show that the algorithm with the graph-structured stack does not parse any part of an input sentence more than once in the same way.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"This is because, if two processes had parsed a part of a sentence in the same way, they would have been in the same state, and they would have been combined as one process.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The graph-structured stack looks very similar to a chart in chart parsing.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In fact, one can also view our algorithm as an extended chart parsing algorithm that is guided by LR parsing tables.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The major extension is that nodes in the chart contain more information (LR state numbers) than in conventional chart parsing.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In this paper, however, we describe the algorithm as a generalized LR parsing algorithm only.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"So far, we have focussed on how to accept or reject a sentence.","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"In practice, however, the parser must not only accept or reject sentences but also build the syntactic structure(s) of the sentence (parse forest).","{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
The next section describes how to represent the parse forest and how to build it with our parsing algorithm.,"{'title': '2 THE CONTEXT-FREE PARSING ALGORITHM', 'number': '3'}"
"Our parsing algorithm is an all-path parsing algorithm; that is, it produces all possible parses in case an input sentence is ambiguous.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
Such all-path parsing is of ten needed in natural language processing to manage temporarily or absolutely ambiguous input sentences.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
The ambiguity (the number of parses) of a sentence may grow exponentially as the length of a sentence grows (Church and Patil 1982).,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"Thus, one might notice that, even with an efficient parsing algorithm such as the one we described, the parser would take exponential time because exponential time would be required merely to print out all parse trees (parse forest).","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
We must therefore provide an efficient representation so that the size of the parse forest does not grow exponentially.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
This section describes two techniques for providing an efficient representation: subtree sharing and local ambiguity packing.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"It should be mentioned that these two techniques are not completely new ideas, and some existing systems (e.g., Earley's (1970) algorithm) have already adopted these techniques, either implicitly or explicitly.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"If two or more trees have a common subtree, the subtree should be represented only once.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"For example, the parse forest for the sentence I saw a man in the park with a telescope should be represented as in Figure 3.1.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"To implement this, we no longer push grammatical symbols on the stack; instead, we push pointers to a node of the shared forest.4 When the parser &quot;shifts&quot; a word, it creates a leaf node labeled with the word and the pre-terminal, and, instead of the pre-terminal symbol, a pointer to the newly created leaf node is pushed onto the stack. lithe exact same leaf node (i.e., the node labeled with the same word and the same pre-terminal) already exists, a pointer to this existing node is pushed onto the stack, without creating another node.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"When the parser &quot;reduces&quot; the stack, it pops pointers from the stack, creates a new node whose successive nodes are pointed to by those popped pointers, and pushes a pointer to the newly created node onto the stack.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"Using this relatively simple procedure, our parsing algorithm can produce the shared forest as its output without any other special book-keeping mechanism, because it never does the same reduce action twice in the same manner.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
We say that two or more subtrees represent local ambiguity if they have common leaf nodes and their top nodes are labeled with the same non-terminal symbol.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"That is to say, a fragment of a sentence is locally ambiguous if the fragment can be reduced to a certain non-terminal symbol in two or more ways.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"If a sentence has many local ambiguities, the total ambiguity would grow exponentially.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"To avoid this, we use a technique called local ambiguity packing, which works in the following way.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
The top nodes of subtrees that represent local ambiguity are merged and treated by higher-level structures as if there were only one node.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"Such a node is called a packed node, and nodes before packing are called subnodes of the packed node.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
An example of a shared-packed forest is shown in Figure 3.2.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
Packed nodes are represented by boxes.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
We have three packed nodes in Figure 3.2; one with three subnodes and two with two subnodes.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
Local ambiguity packing can be easily implemented with our parsing algorithm as follows.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"In the graph-structured stack, if two or more symbol vertices have a common state vertex immediately on their left and a common state vertex immediately on their right, they represent local ambiguity.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
Nodes pointed to by these symbol vertices are to be packed as one node.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"In Figure 2.5, for example, we see one 5-way local ambiguity and two 2-way local ambiguities.","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
The algorithm is made clear by the example in the following section.,"{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
"Recently, the author (Tomita 1986) suggested a technique to disambiguate a sentence out of the sharedpacked forest representation by asking the user a minimal number of questions in natural language (without showing any tree structures).","{'title': '3 AN EFFICIENT REPRESENTATION OF A PARSE FOREST', 'number': '4'}"
This section presents three examples.,"{'title': '4 EXAMPLES', 'number': '5'}"
"The first example, using the sentence I saw a man in the apartment with a telescope, is intended to help the reader understand the algorithm mOre clearly.","{'title': '4 EXAMPLES', 'number': '5'}"
"The second example, with the sentence That information is important is doubtful, is presented to demonstrate that our algorithm is able to handle multi-part-of-speech words without any special mechanism.","{'title': '4 EXAMPLES', 'number': '5'}"
"In the sentence, that is a multi-part-of-speech word, because it could also be a determiner or a pronoun.","{'title': '4 EXAMPLES', 'number': '5'}"
The third example is provided to show that the algorithm is also able to handle unknown words by considering an unknown word as a special multi-part-of-speech word whose part of speech can be anything.,"{'title': '4 EXAMPLES', 'number': '5'}"
"We use an example sentence / * a *, where *s represent unknown words.","{'title': '4 EXAMPLES', 'number': '5'}"
"This subsection gives a trace of the algorithm with the grammar in Figure 2.1, the parsing table in Figure 2.2, and the sentence I saw a man in the park with a telescope.","{'title': '4 EXAMPLES', 'number': '5'}"
"At the very beginning, the stack contains only one vertex labeled 0, and the parse forest contains nothing.","{'title': '4 EXAMPLES', 'number': '5'}"
"By looking at the action table, the next action, &quot;shift 4&quot;, is determined as in standard LR parsing.","{'title': '4 EXAMPLES', 'number': '5'}"
"Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 35 Masaru Tomita An Efficient Augmented-Context-Free Parsing Algorithm When shifting the word /, the algorithm creates a leaf node in the parse forest labeled with the word / and its preterminal *n, and pushes a pointer to the leaf node onto the stack.","{'title': '4 EXAMPLES', 'number': '5'}"
"The next action, &quot;reduce 3, is determined from the action table.","{'title': '4 EXAMPLES', 'number': '5'}"
Next Word = 'saw' 0 0 4 9-11F-40 (p.31 0 [6n ' I' ] We reduce the stack basically in the same manner as standard LR parsing.,"{'title': '4 EXAMPLES', 'number': '5'}"
"It pops the top vertex &quot;4&quot; and the pointer &quot;0&quot; from the stack, and creates a new node in the parse forest whose successor is the node pointed to by the pointer.","{'title': '4 EXAMPLES', 'number': '5'}"
"The newly created node is labeled with the left-hand side symbol of rule 3, namely &quot;NP&quot;.","{'title': '4 EXAMPLES', 'number': '5'}"
"The pointer to this newly created node, namely &quot;1&quot;, is pushed onto the stack.","{'title': '4 EXAMPLES', 'number': '5'}"
"The action, &quot;shift 7&quot;, is determined as the next action.","{'title': '4 EXAMPLES', 'number': '5'}"
"Now, we have At this point, we encounter a multiple entry, &quot;reduce 7&quot; and &quot;shift 6&quot;, and both actions are to be executed.","{'title': '4 EXAMPLES', 'number': '5'}"
"Reduce actions are always executed first, and shift actions are executed only when there is no remaining reduce action to execute.","{'title': '4 EXAMPLES', 'number': '5'}"
"In this way, the parser works strictly from left to right; it does everything that can be done before shifting the next word.","{'title': '4 EXAMPLES', 'number': '5'}"
"After executing &quot;reduce 7&quot;, the stack and the parse forest look like the following.","{'title': '4 EXAMPLES', 'number': '5'}"
"The top vertex labeled &quot;12&quot; is not popped away, because it still has an action not yet executed.","{'title': '4 EXAMPLES', 'number': '5'}"
"Such a top vertex, or more generally, vertices with one or more actions yet to be executed, are called &quot;active&quot;.","{'title': '4 EXAMPLES', 'number': '5'}"
"Thus, we have two active vertices in the stack above: one labeled &quot;12&quot;, and the other labeled &quot;8&quot;.","{'title': '4 EXAMPLES', 'number': '5'}"
"The action &quot;reduce 1&quot; is determined from the action table, and is associated with the latter vertex.","{'title': '4 EXAMPLES', 'number': '5'}"
"After about 20 steps (see below), the action &quot;accept&quot; is finally executed.","{'title': '4 EXAMPLES', 'number': '5'}"
"It returns &quot;25&quot; as the top node of the parse forest, and halts the process.","{'title': '4 EXAMPLES', 'number': '5'}"
"This subsection gives a trace of the algorithm with the sentence That information is important is doubtful, to demonstrate that our algorithm can handle multi-part-ofspeech words (in this sentence, that) just like multiple entries without any special mechanism.","{'title': '4 EXAMPLES', 'number': '5'}"
We use the grammar at the right and the parsing table below.,"{'title': '4 EXAMPLES', 'number': '5'}"
"At the very beginning, the parse forest contains nothing, and the stack contains only one vertex, labeled 0.","{'title': '4 EXAMPLES', 'number': '5'}"
"The first word of the sentence is that, which can be categorized as *that, *det or *n. The action table tells us that all of these categories are legal.","{'title': '4 EXAMPLES', 'number': '5'}"
"Thus, the algorithm behaves as if a multiple entry is encountered.","{'title': '4 EXAMPLES', 'number': '5'}"
"Three actions, &quot;shift 3&quot;, &quot;shift 4&quot;, and &quot;shift 5&quot;, are to be executed.","{'title': '4 EXAMPLES', 'number': '5'}"
Note that three different leaf nodes have been created in the parse forest.,"{'title': '4 EXAMPLES', 'number': '5'}"
"One of the three possibilities, that as a noun, is discarded immediately after the parser sees the next word information.","{'title': '4 EXAMPLES', 'number': '5'}"
"After executing the two shift actions, we have After executing &quot;shift 10&quot;, we have This time, only one leaf node has been created in the parse forest, because both shift actions regarded the word as belonging to the same category, i.e., noun.","{'title': '4 EXAMPLES', 'number': '5'}"
"Now we have two active vertices, and &quot;reduce 3&quot; is arbitrarily chosen as the next action to execute.","{'title': '4 EXAMPLES', 'number': '5'}"
"After executing The parser accepts the sentence, and returns &quot;15&quot; as the top node of the parse forest.","{'title': '4 EXAMPLES', 'number': '5'}"
The forest consists of only one tree which is the desired structure for That information is important is doubtful.,"{'title': '4 EXAMPLES', 'number': '5'}"
"In the previous subsection, we saw the parsing algorithm handling a multi-part-of-speech word just like multiple entries without any special mechanism.","{'title': '4 EXAMPLES', 'number': '5'}"
That capability can also be applied to handle unknown words (words whose categories are unknown).,"{'title': '4 EXAMPLES', 'number': '5'}"
An unknown word can be thought of as a special type of a multi-part-of-speech word whose categories can be anything.,"{'title': '4 EXAMPLES', 'number': '5'}"
"In the following, we present another trace of the parser with the sentence / * a *, where *s represent an unknown word.","{'title': '4 EXAMPLES', 'number': '5'}"
We use the same grammar and parsing table as in the first example (Figures 2.1 and 2.2).,"{'title': '4 EXAMPLES', 'number': '5'}"
"At the very beginning, we have The possibility of the first unknown word being a preposition has now disappeared.","{'title': '4 EXAMPLES', 'number': '5'}"
"The parser accepts the sentence in only one way, and returns &quot;10&quot; as the root node of the parse forest.","{'title': '4 EXAMPLES', 'number': '5'}"
We have shown that our parsing algorithm can handle unknown words without any special mechanism.,"{'title': '4 EXAMPLES', 'number': '5'}"
"In this section, we present some empirical results of the algorithm's practical performance.","{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
"Since space is limited, we only show the highlights of the results, referring the reader to chapter 6 of Tomita (1985) for more detail.","{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
"Figure 5.1 shows the relationship between parsing time of the Tomita algorithm and the length of input sentence, and Figure 5.2 shows the comparison with Earley's algorithm (or active chart parsing), using a sample English grammar that consists of 220 context-free rules and 40 sample sentences taken from actual publications.","{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
"All programs are run on DEC-20 and written in MacLisp, but not compiled.","{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
"Although the experiment is informal, the result show that the Tomita algorithm is about 5 to 10 times faster than Earley's algorithm, due to the pre-compilation of the grammar into the LR table.","{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
The Earley/Tomita ratio seems to increase as the size of grammar grows as shown in Figure 5.3.,"{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
Figure 5.4 shows the relationship between the size of a produced sharedpacked forest representation (in terms of the number of nodes) and the ambiguity of its input sentence (the number of possible parses).,"{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
The sample sentences are created from the following schema. noun verb det noun (prep det noun)n-1 An example sentence with this structure is I saw a man in the park on the hill with a telescope.,"{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
"The result shows that all possible parses can be represented in almost 0(log n) space, where n is the number of possible parses in a sentence.5 Figure 5.5 shows the relationship between the parsing time and the ambiguity of a sentence.","{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
Recall that within the given time the algorithm produces all possible parses in the shared-packed forest representation.,"{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
It is concluded that our algorithm can parse (and produce a forest for) a very ambiguous sentence with a million possible parses in a reasonable time.,"{'title': '5 EMPIRICAL RESULTS', 'number': '6'}"
"So far, we have described the algorithm as a pure context-free parsing algorithm.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"In practice, it is often desired for each grammar nonterminal to have attributes, and for each grammar rule to have an augmentation to define, pass, and test the attribute values.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"It is also desired to produce a functional structure (in the sense of functional grammar formalism (Kay 1984, Bresnan and Kaplan 1982) rather than the context-free forest.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"Subsection 6.1 describes the augmentation, and subsection 6.2 discusses the shared-packed representation for functional structures.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
We attach a Lisp function to each grammar rule for this augmentation.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"Whenever the parser reduces constituents into a higher-level nonterminal using a phrase structure rule, the Lisp program associated with the rule is evaluated.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"The Lisp program handles such aspects as construction of a syntax/semantic representation of the input sentence, passing attribute values among constituents at different levels and checking syntactic/semantic constraints such as subject-verb agreement.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"If the Lisp function returns NIL, the parser does not do the reduce action with the rule.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"If the Lisp function returns a non-NIL value, then this value is given to the newly created non-terminal.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
The value includes attributes of the nonterminal and a partial syntactic/semantic representation constructed thus far.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
Notice that those Lisp functions can be precompiled into machine code by the standard Lisp compiler.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"A functional structure used in the functional grammar formalisms (Kay 1984, Bresnan and Kaplan 1982, Shieber 1985) is in general a directed acyclic graph (dag) rather than a tree.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"This is because some value may be shared by two different attributes in the same sentence (e.g., the &quot;agreement&quot; attributes of subject and main verb).","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
Pereira (1985) introduced a method to share dag structures.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"However, the dag structure sharing method is much more complex and computationally expensive than tree structure sharing.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"Therefore, we handle only treestructured functional structures for the sake of efficiency and simplicity.6 In the example, the &quot;agreement&quot; attributes of subject and main verb may thus have two different values.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
The identity of these two values is tested explicitly by a test in the augmentation.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
Sharing treestructured functional structures requires only a minor modification on the subtree sharing method for the shared-packed forest representation described in subsection 3.1.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
Local ambiguity packing for augmented context-free grammars is not as easy.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
Suppose two certain nodes have been packed into one packed node.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"Although these two nodes have the same category name (e.g., NP), they may have different attribute values.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"When a certain test in the Lisp function refers to an attribute of the packed node, its value may not be uniquely determined.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"In this case, the parser can no longer treat the packed node as one node, and the parser will unpack the packed node into two individual nodes again.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"The question, then, is how often this unpacking needs to take place in practice.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"The more frequently it takes place, the less significant it is to do local ambiguity packing.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"However, most of sentence ambiguity comes from such phenomena as PP-attachment and conjunction scoping, and it is unlikely to require unpacking in these cases.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"For instance, consider the noun phrase: a man in the park with a telescope, which is locally ambiguous (whether telescope modifies man or park).","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"Two NP nodes (one for each interpretation) will be packed into one node, but it is unlikely that the two NP nodes have different attribute values which are referred to later by some tests in the augmentation.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"The same argument holds with the noun phrases: pregnant women and children large file equipment Although more comprehensive experiments are desired, it is expected that only a few packed nodes need to be unpacked in practical applications.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"It is in general very painful to create, extend, and modify augmentations written in Lisp.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
The Lisp functions should be generated automatically from more abstract specifications.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
We have implemented the LFG compiler that compiles augmentations in a higher level notation into Lisp functions.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
The notation is similar to the Lexical Functional Grammar (LFG) formalism (Bresnan and Kaplan 1982) and PATR-1I (Shieber 1984).,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
An example of the LFG-like notation and its compiled Lisp function are shown in Figures 6.1 and 6.2.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
We generate only non-destructive functions with no side-effects to make sure that a process never alters other processes or the parser's control flow.,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"A generated function takes a list of arguments, each of which is a value associated with each right-hand side symbol, and returns a value to be associated with the left-hand side symbol.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"Each value is a list of f-structures, in case of disjunction and local ambiguity.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
That a semantic grammar in the LFG-like notation can also be generated automatically from a domain semantics specification and a purely syntactic grammar is discussed further in Tomita and Carbonell (1986).,"{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
"The discussion is, however, beyond the scope of this paper.","{'title': '6 AUGMENTED CONTEXT-FREE GRAMMARS', 'number': '7'}"
Our parsing algorithm parses a sentence strictly from left to right.,"{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"This characteristics makes on-line parsing possible; i.e., to parse a sentence as the user types it in, without waiting for completion of the sentence.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
An example session of on-line parsing is presented in Figure 7.1 for the sample sentence I saw a man with a telescope.,"{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"As in this example, the user often wants to hit the &quot;backspace&quot; key to correct previously input words.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"In the case in which these words have already been processed by the parser, the parser must be able to &quot;unparse&quot; the words, without parsing the sentence from the beginning all over again.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"To implement unparsing, the parser needs to store system status each time a word is parsed.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"Fortunately, this can be nicely done with our parsing algorithm; only pointers to the graph-structured stack and the parse forest need to be stored.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"It should be noted that our parsing algorithm is not the only algorithm that parses a sentence strictly from left to right; Other left-to-right algorithms include Earley's (1970) algorithm, the active chart parsing algorithm (Winograd 1983), and a breadth-first version of ATN (Woods 1970).","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"Despite the availability of left-to-right algorithms, surprisingly few on-line parsers exist.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
NLMenu (Tennant et al. 1983) adopted on-line parsing for a menu-based system but not for typed inputs.,"{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"In the rest of this section, we discuss two benefits of on-line parsing, quicker response time and early error detection.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
One obvious benefit of on-line parsing is that it reduces the parser's response time significantly.,"{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"When the user finishes typing a whole sentence, most of the input sentence has been already processed by the parser.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"Although this does not affect CPU time, it could reduce response time from the user's point of view significantly.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
On-line parsing is therefore useful in interactive systems in which input sentences are typed in by the user on-line; it is not particularly useful in batch systems in which input sentences are provided in a file.,"{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"Another benefit of on-line parsing is that it can detect an error almost as soon as the error occurs, and it can warn the user immediately.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"In this way, on-line parsing could provide better man-machine communication.","{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
Further studies on human factors are necessary.,"{'title': '7 THE ON-LINE PARSER', 'number': '8'}"
"This paper has introduced an efficient context-free parsing algorithm, and its application to on-line natural language interfaces has been discussed.","{'title': '8 CONCLUSION', 'number': '9'}"
"A pilot on-line parser was first implemented in MacLisp at the Computer Science Department, Carnegie-Mellon University (CMU) as a part of the author's thesis work (Tomita 1985).","{'title': '8 CONCLUSION', 'number': '9'}"
The empirical results in section 5 are based on this parser.,"{'title': '8 CONCLUSION', 'number': '9'}"
CMU's machine translation project (Carbonell and Tomita 1986) adopts on-line parsing for multiple languages.,"{'title': '8 CONCLUSION', 'number': '9'}"
"It can parse unsegmented sentences (with no spaces between words, typical in Japanese).","{'title': '8 CONCLUSION', 'number': '9'}"
"To handle unsegmented sentences, its grammar is written in a character-based manner; all terminal symbols in the grammar are characters rather than words.","{'title': '8 CONCLUSION', 'number': '9'}"
"Thus, morphological rules, as well as syntactic rules, are written in the augmented context-free grammar.","{'title': '8 CONCLUSION', 'number': '9'}"
"The parser takes about 1-3 seconds CPU time per sentence on a Symbolics 3600 with about 800 grammar rules; its response time (real time), however, is less than a second due to on-line parsing.","{'title': '8 CONCLUSION', 'number': '9'}"
"This speed does not seem to be affected very much by the length of sentence or the size of grammar, as discussed in section 5.","{'title': '8 CONCLUSION', 'number': '9'}"
We expect further improvements for fully segmented sentences (such as English) where words rather then characters are the atomic units.,"{'title': '8 CONCLUSION', 'number': '9'}"
"A commercial on-line parser for Japanese language is being developed in Common Lisp jointly by Intelligent Technology Incorporation (ITI) and Carnegie Group Incorporation (CGI), based on the technique developed at CMU.","{'title': '8 CONCLUSION', 'number': '9'}"
"Finally, in the continuous speech recognition project at CMU (Hayes et al. 1986), the on-line parsing algoComputational Linguistics, Volume 13, Numbers 1-2, January-June 1987 45 Masaru Tomita An Efficient Augmented-Context-Free Parsing Algorithm rithm is being extended to handle speech input, to make the speech parsing process efficient and capable of being pipelined with lower level processes such as acoustic/phonetic level recognition (Tomita 1986).","{'title': '8 CONCLUSION', 'number': '9'}"
"I would like to thank Jaime Carbonell, Phil Hayes, James Allen, Herb Simon, Hozumi Tanaka, and Ralph Grishman for their helpful comments on the early version of this paper.","{'title': 'AKNOWLEDGMENTS', 'number': '10'}"
"Kazuhiro Toyoshima and Hideto Kagamida have implemented the runtime parser and the LR table compiler, respectively, in Common Lisp.","{'title': 'AKNOWLEDGMENTS', 'number': '10'}"
"Lori Levin, Teruko Watanabe, Peggy Anderson, and Donna Gates have developed Japanese and English grammars in the LFG-like notation.","{'title': 'AKNOWLEDGMENTS', 'number': '10'}"
Hiroaki Saito has implemented the algorithm for speech input.,"{'title': 'AKNOWLEDGMENTS', 'number': '10'}"
"Ron Kaplan, Martin Kay, Lauri Karttunen, and Stuart Shieber provided useful comments on the implementation of LFG and dag structure sharing.","{'title': 'AKNOWLEDGMENTS', 'number': '10'}"
