col1,col2
"NLTK, the Natural Language Toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware.",{}
"NLTK covers symbolic and statistical natural language processing, and is interfaced to annotated corpora.",{}
"Students augment and replace existing components, learn structured programming by example, and manipulate sophisticated models from the outset.",{}
Teachers of introductory courses on computational linguistics are often faced with the challenge of setting up a practical programming component for student assignments and projects.,"{'title': '1 Introduction', 'number': '1'}"
"This is a difficult task because different computational linguistics domains require a variety of different data structures and functions, and because a diverse range of topics may need to be included in the syllabus.","{'title': '1 Introduction', 'number': '1'}"
"A widespread practice is to employ multiple programming languages, where each language provides native data structures and functions that are a good fit for the task at hand.","{'title': '1 Introduction', 'number': '1'}"
"For example, a course might use Prolog for parsing, Perl for corpus processing, and a finite-state toolkit for morphological analysis.","{'title': '1 Introduction', 'number': '1'}"
"By relying on the built-in features of various languages, the teacher avoids having to develop a lot of software infrastructure.","{'title': '1 Introduction', 'number': '1'}"
An unfortunate consequence is that a significant part of such courses must be devoted to teaching programming languages.,"{'title': '1 Introduction', 'number': '1'}"
"Further, many interesting projects span a variety of domains, and would require that multiple languages be bridged.","{'title': '1 Introduction', 'number': '1'}"
"For example, a student project that involved syntactic parsing of corpus data from a morphologically rich language might involve all three of the languages mentioned above: Perl for string processing; a finite state toolkit for morphological analysis; and Prolog for parsing.","{'title': '1 Introduction', 'number': '1'}"
It is clear that these considerable overheads and shortcomings warrant a fresh approach.,"{'title': '1 Introduction', 'number': '1'}"
"Apart from the practical component, computational linguistics courses may also depend on software for in-class demonstrations.","{'title': '1 Introduction', 'number': '1'}"
"This context calls for highly interactive graphical user interfaces, making it possible to view program state (e.g. the chart of a chart parser), observe program execution step-by-step (e.g. execution of a finite-state machine), and even make minor modifications to programs in response to “what if” questions from the class.","{'title': '1 Introduction', 'number': '1'}"
"Because of these difficulties it is common to avoid live demonstrations, and keep classes for theoretical presentations only.","{'title': '1 Introduction', 'number': '1'}"
"Apart from being dull, this approach leaves students to solve important practical problems on their own, or to deal with them less efficiently in office hours.","{'title': '1 Introduction', 'number': '1'}"
"In this paper we introduce a new approach to the above challenges, a streamlined and flexible way of organizing the practical component of an introductory computational linguistics course.","{'title': '1 Introduction', 'number': '1'}"
"We describe NLTK, the Natural Language Toolkit, which we have developed in conjunction with a course we have taught at the University of Pennsylvania.","{'title': '1 Introduction', 'number': '1'}"
The Natural Language Toolkit is available under an open source license from http://nltk.sf.net/.,"{'title': '1 Introduction', 'number': '1'}"
"NLTK runs on all platforms supported by Python, including Windows, OS X, Linux, and Unix.","{'title': '1 Introduction', 'number': '1'}"
The most basic step in setting up a practical component is choosing a suitable programming language.,"{'title': '2 Choice of Programming Language', 'number': '2'}"
A number of considerations influenced our choice.,"{'title': '2 Choice of Programming Language', 'number': '2'}"
"First, the language must have a shallow learning curve, so that novice programmers get immediate rewards for their efforts.","{'title': '2 Choice of Programming Language', 'number': '2'}"
"Second, the language must support rapid prototyping and a short develop/test cycle; an obligatory compilation step is a serious detraction.","{'title': '2 Choice of Programming Language', 'number': '2'}"
"Third, the code should be self-documenting, with a transparent syntax and semantics.","{'title': '2 Choice of Programming Language', 'number': '2'}"
"Fourth, it should be easy to write structured programs, ideally object-oriented but without the burden associated with languages like C++.","{'title': '2 Choice of Programming Language', 'number': '2'}"
"Finally, the language must have an easy-to-use graphics library to support the development of graphical user interfaces.","{'title': '2 Choice of Programming Language', 'number': '2'}"
"In surveying the available languages, we believe that Python offers an especially good fit to the above requirements.","{'title': '2 Choice of Programming Language', 'number': '2'}"
Python is an object-oriented scripting language developed by Guido van Rossum and available on all platforms (www.python.org).,"{'title': '2 Choice of Programming Language', 'number': '2'}"
"Python offers a shallow learning curve; it was designed to be easily learnt by children (van Rossum, 1999).","{'title': '2 Choice of Programming Language', 'number': '2'}"
"As an interpreted language, Python is suitable for rapid prototyping.","{'title': '2 Choice of Programming Language', 'number': '2'}"
"Python code is exceptionally readable, and it has been praised as “executable pseudocode.” Python is an object-oriented language, but not punitively so, and it is easy to encapsulate data and methods inside Python classes.","{'title': '2 Choice of Programming Language', 'number': '2'}"
"Finally, Python has an interface to the Tk graphics toolkit (Lundh, 1999), and writing graphical interfaces is straightforward.","{'title': '2 Choice of Programming Language', 'number': '2'}"
Several criteria were considered in the design and implementation of the toolkit.,"{'title': '3 Design Criteria', 'number': '3'}"
These design criteria are listed in the order of their importance.,"{'title': '3 Design Criteria', 'number': '3'}"
"It was also important to decide what goals the toolkit would not attempt to accomplish; we therefore include an explicit set of nonrequirements, which the toolkit is not expected to satisfy.","{'title': '3 Design Criteria', 'number': '3'}"
Ease of Use.,"{'title': '3 Design Criteria', 'number': '3'}"
The primary purpose of the toolkit is to allow students to concentrate on building natural language processing (NLP) systems.,"{'title': '3 Design Criteria', 'number': '3'}"
"The more time students must spend learning to use the toolkit, the less useful it is.","{'title': '3 Design Criteria', 'number': '3'}"
Consistency.,"{'title': '3 Design Criteria', 'number': '3'}"
The toolkit should use consistent data structures and interfaces.,"{'title': '3 Design Criteria', 'number': '3'}"
Extensibility.,"{'title': '3 Design Criteria', 'number': '3'}"
"The toolkit should easily accommodate new components, whether those components replicate or extend the toolkit’s existing functionality.","{'title': '3 Design Criteria', 'number': '3'}"
The toolkit should be structured in such a way that it is obvious where new extensions would fit into the toolkit’s infrastructure.,"{'title': '3 Design Criteria', 'number': '3'}"
Documentation.,"{'title': '3 Design Criteria', 'number': '3'}"
"The toolkit, its data structures, and its implementation all need to be carefully and thoroughly documented.","{'title': '3 Design Criteria', 'number': '3'}"
All nomenclature must be carefully chosen and consistently used.,"{'title': '3 Design Criteria', 'number': '3'}"
Simplicity.,"{'title': '3 Design Criteria', 'number': '3'}"
"The toolkit should structure the complexities of building NLP systems, not hide them.","{'title': '3 Design Criteria', 'number': '3'}"
"Therefore, each class defined by the toolkit should be simple enough that a student could implement it by the time they finish an introductory course in computational linguistics.","{'title': '3 Design Criteria', 'number': '3'}"
Modularity.,"{'title': '3 Design Criteria', 'number': '3'}"
"The interaction between different components of the toolkit should be kept to a minimum, using simple, well-defined interfaces.","{'title': '3 Design Criteria', 'number': '3'}"
"In particular, it should be possible to complete individual projects using small parts of the toolkit, without worrying about how they interact with the rest of the toolkit.","{'title': '3 Design Criteria', 'number': '3'}"
This allows students to learn how to use the toolkit incrementally throughout a course.,"{'title': '3 Design Criteria', 'number': '3'}"
Modularity also makes it easier to change and extend the toolkit.,"{'title': '3 Design Criteria', 'number': '3'}"
Comprehensiveness.,"{'title': '3 Design Criteria', 'number': '3'}"
The toolkit is not intended to provide a comprehensive set of tools.,"{'title': '3 Design Criteria', 'number': '3'}"
"Indeed, there should be a wide variety of ways in which students can extend the toolkit.","{'title': '3 Design Criteria', 'number': '3'}"
Efficiency.,"{'title': '3 Design Criteria', 'number': '3'}"
The toolkit does not need to be highly optimized for runtime performance.,"{'title': '3 Design Criteria', 'number': '3'}"
"However, it should be efficient enough that students can use their NLP systems to perform real tasks.","{'title': '3 Design Criteria', 'number': '3'}"
Cleverness.,"{'title': '3 Design Criteria', 'number': '3'}"
Clear designs and implementations are far preferable to ingenious yet indecipherable ones.,"{'title': '3 Design Criteria', 'number': '3'}"
"The toolkit is implemented as a collection of independent modules, each of which defines a specific data structure or task.","{'title': '4 Modules', 'number': '4'}"
A set of core modules defines basic data types and processing systems that are used throughout the toolkit.,"{'title': '4 Modules', 'number': '4'}"
"The token module provides basic classes for processing individual elements of text, such as words or sentences.","{'title': '4 Modules', 'number': '4'}"
"The tree module defines data structures for representing tree structures over text, such as syntax trees and morphological trees.","{'title': '4 Modules', 'number': '4'}"
"The probability module implements classes that encode frequency distributions and probability distributions, including a variety of statistical smoothing techniques.","{'title': '4 Modules', 'number': '4'}"
The remaining modules define data structures and interfaces for performing specific NLP tasks.,"{'title': '4 Modules', 'number': '4'}"
"This list of modules will grow over time, as we add new tasks and algorithms to the toolkit.","{'title': '4 Modules', 'number': '4'}"
The parser module defines a high-level interface for producing trees that represent the structures of texts.,"{'title': '4 Modules', 'number': '4'}"
The chunkparser module defines a sub-interface for parsers that identify nonoverlapping linguistic groups (such as base noun phrases) in unrestricted text.,"{'title': '4 Modules', 'number': '4'}"
Four modules provide implementations for these abstract interfaces.,"{'title': '4 Modules', 'number': '4'}"
The srparser module implements a simple shift-reduce parser.,"{'title': '4 Modules', 'number': '4'}"
The chartparser module defines a flexible parser that uses a chart to record hypotheses about syntactic constituents.,"{'title': '4 Modules', 'number': '4'}"
The pcfgparser module provides a variety of different parsers for probabilistic grammars.,"{'title': '4 Modules', 'number': '4'}"
And the rechunkparser module defines a transformational regular-expression based implementation of the chunk parser interface.,"{'title': '4 Modules', 'number': '4'}"
"The tagger module defines a standard interface for augmenting each token of a text with supplementary information, such as its part of speech or its WordNet synset tag; and provides several different implementations for this interface.","{'title': '4 Modules', 'number': '4'}"
The fsa module defines a data type for encoding finite state automata; and an interface for creating automata from regular expressions.,"{'title': '4 Modules', 'number': '4'}"
Debugging time is an important factor in the toolkit’s ease of use.,"{'title': '4 Modules', 'number': '4'}"
"To reduce the amount of time students must spend debugging their code, we provide a type checking module, which can be used to ensure that functions are given valid arguments.","{'title': '4 Modules', 'number': '4'}"
The type checking module is used by all of the basic data types and processing classes.,"{'title': '4 Modules', 'number': '4'}"
"Since type checking is done explicitly, it can slow the toolkit down.","{'title': '4 Modules', 'number': '4'}"
"However, when efficiency is an issue, type checking can be easily turned off; and with type checking is disabled, there is no performance penalty.","{'title': '4 Modules', 'number': '4'}"
"Visualization modules define graphical interfaces for viewing and manipulating data structures, and graphical tools for experimenting with NLP tasks.","{'title': '4 Modules', 'number': '4'}"
The draw.tree module provides a simple graphical interface for displaying tree structures.,"{'title': '4 Modules', 'number': '4'}"
The draw.tree edit module provides an interface for building and modifying tree structures.,"{'title': '4 Modules', 'number': '4'}"
The draw.plot graph module can be used to graph mathematical functions.,"{'title': '4 Modules', 'number': '4'}"
The draw.fsa module provides a graphical tool for displaying and simulating finite state automata.,"{'title': '4 Modules', 'number': '4'}"
The draw.chart module provides an interactive graphical tool for experimenting with chart parsers.,"{'title': '4 Modules', 'number': '4'}"
The visualization modules provide interfaces for interaction and experimentation; they do not directly implement NLP data structures or tasks.,"{'title': '4 Modules', 'number': '4'}"
Simplicity of implementation is therefore less of an issue for the visualization modules than it is for the rest of the toolkit.,"{'title': '4 Modules', 'number': '4'}"
The classifier module defines a standard interface for classifying texts into categories.,"{'title': '4 Modules', 'number': '4'}"
This interface is currently implemented by two modules.,"{'title': '4 Modules', 'number': '4'}"
The classifier.naivebayes module defines a text classifier based on the Naive Bayes assumption.,"{'title': '4 Modules', 'number': '4'}"
"The classifier.maxent module defines the maximum entropy model for text classification, and implements two algorithms for training the model: Generalized Iterative Scaling and Improved Iterative Scaling.","{'title': '4 Modules', 'number': '4'}"
The classifier.feature module provides a standard encoding for the information that is used to make decisions for a particular classification task.,"{'title': '4 Modules', 'number': '4'}"
"This standard encoding allows students to experiment with the differences between different text classification algorithms, using identical feature sets.","{'title': '4 Modules', 'number': '4'}"
The classifier.featureselection module defines a standard interface for choosing which features are relevant for a particular classification task.,"{'title': '4 Modules', 'number': '4'}"
Good feature selection can significantly improve classification performance.,"{'title': '4 Modules', 'number': '4'}"
"The toolkit is accompanied by extensive documentation that explains the toolkit, and describes how to use and extend it.","{'title': '5 Documentation', 'number': '5'}"
"This documentation is divided into three primary categories: Tutorials teach students how to use the toolkit, in the context of performing specific tasks.","{'title': '5 Documentation', 'number': '5'}"
"Each tutorial focuses on a single domain, such as tagging, probabilistic systems, or text classification.","{'title': '5 Documentation', 'number': '5'}"
"The tutorials include a high-level discussion that explains and motivates the domain, followed by a detailed walk-through that uses examples to show how NLTK can be used to perform specific tasks.","{'title': '5 Documentation', 'number': '5'}"
"Reference Documentation provides precise definitions for every module, interface, class, method, function, and variable in the toolkit.","{'title': '5 Documentation', 'number': '5'}"
"It is automatically extracted from docstring comments in the Python source code, using Epydoc (Loper, 2002).","{'title': '5 Documentation', 'number': '5'}"
Technical Reports explain and justify the toolkit’s design and implementation.,"{'title': '5 Documentation', 'number': '5'}"
They are used by the developers of the toolkit to guide and document the toolkit’s construction.,"{'title': '5 Documentation', 'number': '5'}"
"Students can also consult these reports if they would like further information about how the toolkit is designed, and why it is designed that way.","{'title': '5 Documentation', 'number': '5'}"
NLTK can be used to create student assignments of varying difficulty and scope.,"{'title': '6 Uses of NLTK', 'number': '6'}"
"In the simplest assignments, students experiment with an existing module.","{'title': '6 Uses of NLTK', 'number': '6'}"
The wide variety of existing modules provide many opportunities for creating these simple assignments.,"{'title': '6 Uses of NLTK', 'number': '6'}"
"Once students become more familiar with the toolkit, they can be asked to make minor changes or extensions to an existing module.","{'title': '6 Uses of NLTK', 'number': '6'}"
A more challenging task is to develop a new module.,"{'title': '6 Uses of NLTK', 'number': '6'}"
"Here, NLTK provides some useful starting points: predefined interfaces and data structures, and existing modules that implement the same interface.","{'title': '6 Uses of NLTK', 'number': '6'}"
"As an example of a moderately difficult assignment, we asked students to construct a chunk parser that correctly identifies base noun phrase chunks in a given text, by defining a cascade of transformational chunking rules.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"The NLTK rechunkparser module provides a variety of regular-expression based rule types, which the students can instantiate to construct complete rules.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"For example, ChunkRule(’<NN.W) builds chunks from sequences of consecutive nouns; ChinkRule(’<VB.>’) excises verbs from existing chunks; SplitRule(’<NN>’, ’<DT>’) splits any existing chunk that contains a singular noun followed by determiner into two pieces; and MergeRule(’<JJ>’, ’<JJ>’) combines two adjacent chunks where the first chunk ends and the second chunk starts with adjectives.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"The chunking tutorial motivates chunk parsing, describes each rule type, and provides all the necessary code for the assignment.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"The provided code is responsible for loading the chunked, part-of-speech tagged text using an existing tokenizer, creating an unchunked version of the text, applying the chunk rules to the unchunked text, and scoring the result.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
Students focus on the NLP task only – providing a rule set with the best coverage.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
In the remainder of this section we reproduce some of the cascades created by the students.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
The first example illustrates a combination of several rule types: ChunkRule(’<DT><NN.*><VB.><NN.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"*>’), ChunkRule(’<DT><VB.><NN.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"*>’), ChunkRule(’<.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"*>’), UnChunkRule(’<IN|VB.*|CC|MD|RB.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"*>’), UnChunkRule(&quot;<,|\\.|“|’’>&quot;), MergeRule(’<NN.*|DT|JJ.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"*|CD>’, ’<NN.*|DT|JJ.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"*|CD>’), SplitRule(’<NN.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"*>’, ’<DT|JJ>’) ] The next example illustrates a brute-force statistical approach.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
The student calculated how often each part-of-speech tag was included in a noun phrase.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
They then constructed chunks from any sequence of tags that occurred in a noun phrase more than 50% of the time.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"In the third example, the student constructed a single chunk containing the entire text, and then excised all elements that did not belong.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
NLTK provides graphical tools that can be used in class demonstrations to help explain basic NLP concepts and algorithms.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
These interactive tools can be used to display relevant data structures and to show the step-by-step execution of algorithms.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"Both data structures and control flow can be easily modified during the demonstration, in response to questions from the class.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"Since these graphical tools are included with the toolkit, they can also be used by students.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
This allows students to experiment at home with the algorithms that they have seen presented in class.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
The chart parsing tool is an example of a graphical tool provided by NLTK.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"This tool can be used to explain the basic concepts behind chart parsing, and to show how the algorithm works.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
Chart parsing is a flexible parsing algorithm that uses a data structure called a chart to record hypotheses about syntactic constituents.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
Each hypothesis is represented by a single edge on the chart.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
A set of rules determine when new edges can be added to the chart.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"This set of rules controls the overall behavior of the parser (e.g., whether it parses top-down or bottom-up).","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"The chart parsing tool demonstrates the process of parsing a single sentence, with a given grammar and lexicon.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
Its display is divided into three sections: the bottom section displays the chart; the middle section displays the sentence; and the top section displays the partial syntax tree corresponding to the selected edge.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
Buttons along the bottom of the window are used to control the execution of the algorithm.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
The main display window for the chart parsing tool is shown in Figure 1.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
This tool can be used to explain several different aspects of chart parsing.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"First, it can be used to explain the basic chart data structure, and to show how edges can represent hypotheses about syntactic constituents.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
It can then be used to demonstrate and explain the individual rules that the chart parser uses to create new edges.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"Finally, it can be used to show how these individual rules combine to find a complete parse for a given sentence.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"To reduce the overhead of setting up demonstrations during lecture, the user can define a list of preset charts.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
The tool can then be reset to any one of these charts at any time.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
The chart parsing tool allows for flexible control of the parsing algorithm.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"At each step of the algorithm, the user can select which rule or strategy they wish to apply.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"This allows the user to experiment with mixing different strategies (e.g., top-down and bottom-up).","{'title': 'Example: Chunk Parsing', 'number': '7'}"
The user can exercise fine-grained control over the algorithm by selecting which edge they wish to apply a rule to.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
This flexibility allows lecturers to use the tool to respond to a wide variety of questions; and allows students to experiment with different variations on the chart parsing algorithm.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
NLTK provides students with a flexible framework for advanced projects.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"Typical projects involve the development of entirely new functionality for a previously unsupported NLP task, or the development of a complete system out of existing and new modules.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
The toolkit’s broad coverage allows students to explore a wide variety of topics.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"In our introductory computational linguistics course, topics for student projects included text generation, word sense disambiguation, collocation analysis, and morphological analysis.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"NLTK eliminates the tedious infrastructurebuilding that is typically associated with advanced student projects by providing students with the basic data structures, tools, and interfaces that they need.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
This allows the students to concentrate on the problems that interest them.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"The collaborative, open-source nature of the toolkit can provide students with a sense that their projects are meaningful contributions, and not just exercises.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
Several of the students in our course have expressed interest in incorporating their projects into the toolkit.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"Finally, many of the modules included in the toolkit provide students with good examples of what projects should look like, with well thought-out interfaces, clean code structure, and thorough documentation.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
The probabilistic parsing module was created as a class project for a statistical NLP course.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
The toolkit provided the basic data types and interfaces for parsing.,"{'title': 'Example: Chunk Parsing', 'number': '7'}"
"The project extended these, adding a new probabilistic parsing interface, and using subclasses to create a probabilistic version of the context free grammar data structure.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"These new components were used in conjunction with several existing components, such as the chart data structure, to define two implementations of the probabilistic parsing interface.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"Finally, a tutorial was written that explained the basic motivations and concepts behind probabilistic parsing, and described the new interfaces, data structures, and parsers.","{'title': 'Example: Chunk Parsing', 'number': '7'}"
"We used NLTK as a basis for the assignments and student projects in CIS-530, an introductory computational linguistics class taught at the University of Pennsylvania.","{'title': '7 Evaluation', 'number': '8'}"
"CIS-530 is a graduate level class, although some advanced undergraduates were also enrolled.","{'title': '7 Evaluation', 'number': '8'}"
Most students had a background in either computer science or linguistics (and occasionally both).,"{'title': '7 Evaluation', 'number': '8'}"
"Students were required to complete five assignments, two exams, and a final project.","{'title': '7 Evaluation', 'number': '8'}"
All class materials are available from the course website http://www.cis.upenn.edu/~cis530/.,"{'title': '7 Evaluation', 'number': '8'}"
"The experience of using NLTK was very positive, both for us and for the students.","{'title': '7 Evaluation', 'number': '8'}"
The students liked the fact that they could do interesting projects from the outset.,"{'title': '7 Evaluation', 'number': '8'}"
They also liked being able to run everything on their computer at home.,"{'title': '7 Evaluation', 'number': '8'}"
The students found the extensive documentation very helpful for learning to use the toolkit.,"{'title': '7 Evaluation', 'number': '8'}"
"They found the interfaces defined by NLTK intuitive, and appreciated the ease with which they could combine different components to create complete NLP systems.","{'title': '7 Evaluation', 'number': '8'}"
We did encounter a few difficulties during the semester.,"{'title': '7 Evaluation', 'number': '8'}"
One problem was finding large clean corpora that the students could use for their assignments.,"{'title': '7 Evaluation', 'number': '8'}"
Several of the students needed assistance finding suitable corpora for their final projects.,"{'title': '7 Evaluation', 'number': '8'}"
Another issue was the fact that we were actively developing NLTK during the semester; some modules were only completed one or two weeks before the students used them.,"{'title': '7 Evaluation', 'number': '8'}"
"As a result, students who worked at home needed to download new versions of the toolkit several times throughout the semester.","{'title': '7 Evaluation', 'number': '8'}"
"Luckily, Python has extensive support for installation scripts, which made these upgrades simple.","{'title': '7 Evaluation', 'number': '8'}"
"The students encountered a couple of bugs in the toolkit, but none were serious, and all were quickly corrected.","{'title': '7 Evaluation', 'number': '8'}"
The computational component of computational linguistics courses takes many forms.,"{'title': '8 Other Approaches', 'number': '9'}"
"In this section we briefly review a selection of approaches, classified according to the (original) target audience.","{'title': '8 Other Approaches', 'number': '9'}"
Linguistics Students.,"{'title': '8 Other Approaches', 'number': '9'}"
Various books introduce programming or computing to linguists.,"{'title': '8 Other Approaches', 'number': '9'}"
"These are elementary on the computational side, providing a gentle introduction to students having no prior experience in computer science.","{'title': '8 Other Approaches', 'number': '9'}"
"Examples of such books are: Using Computers in Linguistics (Lawler and Dry, 1998), and Programming for Linguistics: Java Technology for Language Researchers (Hammond, 2002).","{'title': '8 Other Approaches', 'number': '9'}"
Grammar Developers.,"{'title': '8 Other Approaches', 'number': '9'}"
"Infrastructure for grammar development has a long history in unification-based (or constraint-based) grammar frameworks, from DCG (Pereira and Warren, 1980) to HPSG (Pollard and Sag, 1994).","{'title': '8 Other Approaches', 'number': '9'}"
"Recent work includes (Copestake, 2000; Baldridge et al., 2002a).","{'title': '8 Other Approaches', 'number': '9'}"
"A concurrent development has been the finite state toolkits, such as the Xerox toolkit (Beesley and Karttunen, 2002).","{'title': '8 Other Approaches', 'number': '9'}"
This work has found widespread pedagogical application.,"{'title': '8 Other Approaches', 'number': '9'}"
Other Researchers and Developers.,"{'title': '8 Other Approaches', 'number': '9'}"
A variety of toolkits have been created for research or R&D purposes.,"{'title': '8 Other Approaches', 'number': '9'}"
"Examples include the CMU-Cambridge Statistical Language Modeling Toolkit (Clarkson and Rosenfeld, 1997), the EMU Speech Database System (Harrington and Cassidy, 1999), the General Architecture for Text Engineering (Bontcheva et al., 2002), the Maxent Package for Maximum Entropy Models (Baldridge et al., 2002b), and the Annotation Graph Toolkit (Maeda et al., 2002).","{'title': '8 Other Approaches', 'number': '9'}"
"Although not originally motivated by pedagogical needs, all of these toolkits have pedagogical applications and many have already been used in teaching.","{'title': '8 Other Approaches', 'number': '9'}"
"NLTK provides a simple, extensible, uniform framework for assignments, projects, and class demonstrations.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
"It is well documented, easy to learn, and simple to use.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
We hope that NLTK will allow computational linguistics classes to include more hands-on experience with using and building NLP components and systems.,"{'title': '9 Conclusions and Future Work', 'number': '10'}"
NLTK is unique in its combination of three factors.,"{'title': '9 Conclusions and Future Work', 'number': '10'}"
"First, it was deliberately designed as courseware and gives pedagogical goals primary status.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
"Second, its target audience consists of both linguists and computer scientists, and it is accessible and challenging at many levels of prior computational skill.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
"Finally, it is based on an object-oriented scripting language supporting rapid prototyping and literate programming.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
We plan to continue extending the breadth of materials covered by the toolkit.,"{'title': '9 Conclusions and Future Work', 'number': '10'}"
"We are currently working on NLTK modules for Hidden Markov Models, language modeling, and tree adjoining grammars.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
"We also plan to increase the number of algorithms implemented by some existing modules, such as the text classification module.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
Finding suitable corpora is a prerequisite for many student assignments and projects.,"{'title': '9 Conclusions and Future Work', 'number': '10'}"
We are therefore putting together a collection of corpora containing data appropriate for every module defined by the toolkit.,"{'title': '9 Conclusions and Future Work', 'number': '10'}"
"NLTK is an open source project, and we welcome any contributions.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
"Readers who are interested in contributing to NLTK, or who have suggestions for improvements, are encouraged to contact the authors.","{'title': '9 Conclusions and Future Work', 'number': '10'}"
"We are indebted to our students for feedback on the toolkit, and to anonymous reviewers, Jee Bang, and the workshop organizers for comments on an earlier version of this paper.","{'title': '10 Acknowledgments', 'number': '11'}"
We are grateful to Mitch Marcus and the Department of Computer and Information Science at the University of Pennsylvania for sponsoring the work reported here.,"{'title': '10 Acknowledgments', 'number': '11'}"
