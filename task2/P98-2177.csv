col1,col2
several unsupervised statistical models for the prepositional phrase attachment task that approach the accuracy of the best supervised methods for this task.,{}
"Our unsupervised approach uses a heuristic based on attachment proximity and trains from raw text that is annotated with only part-of-speech tags and morphological base forms, as opposed to attachment information.",{}
It is therefore less resource-intensive and more portable than previous corpus-based algorithm proposed for this task.,{}
We present results for prepositional phrase attachment in both English and Spanish.,{}
"Prepositional phrase attachment is the task of deciding, for a given preposition in a sentence, the attachment site that corresponds to the interpretation of the sentence.","{'title': '1 Introduction', 'number': '1'}"
"For example, the task in the following examples is to decide whether the preposition with modifies the preceding noun phrase (with head word shirt) or the preceding verb phrase (with head word bought or washed).","{'title': '1 Introduction', 'number': '1'}"
"In sentence 1, with modifies the noun shirt, since with pockets describes the shirt.","{'title': '1 Introduction', 'number': '1'}"
"However in sentence 2, with modifies the verb washed since with soap describes how the shirt is washed.","{'title': '1 Introduction', 'number': '1'}"
"While this form of attachment ambiguity is usually easy for people to resolve, a computer requires detailed knowledge about words (e.g., washed vs. bought) in order to successfully resolve such ambiguities and predict the correct interpretation.","{'title': '1 Introduction', 'number': '1'}"
"Most of the previous successful approaches to this problem have been statistical or corpusbased, and they consider only prepositions whose attachment is ambiguous between a preceding noun phrase and verb phrase.","{'title': '2 Previous Work', 'number': '2'}"
"Previous work has framed the problem as a classification task, in which the goal is to predict N or V, corresponding to noun or verb attachment, given the head verb v, the head noun n, the preposition p, and optionally, the object of the preposition n2.","{'title': '2 Previous Work', 'number': '2'}"
"For example, the (v,n,p, n2) tuples corresponding to the example sentences are The correct classifications of tuples 1 and 2 are N and V, respectively.","{'title': '2 Previous Work', 'number': '2'}"
"(Hindle and Rooth, 1993) describes a partially supervised approach in which the FIDDITCH partial parser was used to extract (v, n, p) tuples from raw text, where p is a preposition whose attachment is ambiguous between the head verb v and the head noun n. The extracted tuples are then used to construct a classifier, which resolves unseen ambiguities at around 80% accuracy.","{'title': '2 Previous Work', 'number': '2'}"
"Later work, such as (Ratnaparkhi et al., 1994; Brill and Resnik, 1994; Collins and Brooks, 1995; Merlo et al., 1997; Zavrel and Daelemans, 1997; Franz, 1997), trains and tests on quintuples of the form (v, n,p, n2, a) extracted from the Penn treebank(Marcus et al., 1994), and has gradually improved on this accuracy with other kinds of statistical learning methods, yielding up to 84.5% accuracy(Collins and Brooks, 1995).","{'title': '2 Previous Work', 'number': '2'}"
"Recently, (Stetina and Naga,o, 1997) have reported 88% accuracy by using a corpus-based model in conjunction with a semantic dictionary.","{'title': '2 Previous Work', 'number': '2'}"
"While previous corpus-based methods are highly accurate for this task, they are difficult to port to other languages because they require resources that are expensive to construct or simply nonexistent in other languages.","{'title': '2 Previous Work', 'number': '2'}"
"We present an unsupervised algorithm for prepositional phrase attachment in English that requires only an part-of-speech tagger and a morphology database, and is therefore less resourceintensive and more portable than previous approaches, which have all required either treebanks or partial parsers.","{'title': '2 Previous Work', 'number': '2'}"
"The exact task of our algorithm will be to construct a classifier c/ which maps an instance of an ambiguous prepositional phrase (v, n, p, n2) to either N or V, corresponding to noun attachment or verb attachment, respectively.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"In the full natural language parsing task, there are more than just two potential attachment sites, but we limit our task to choosing between a verb v and a noun n so that we may compare with previous supervised attempts on this problem.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"While we will be given the candidate attachment sites during testing, the training procedure assumes no a priori information about potential attachment sites.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"We generate training data from raw text by using a part-of-speech tagger, a simple chunker, an extraction heuristic, and a morphology database.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
The order in which these tools are applied to raw text is shown in Table 1.,"{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"The tagger from (Ratnaparkhi, 1996) first annotates sentences of raw text with a sequence of partof-speech tags.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"The chunker, implemented with two small regular expressions, then replaces simple noun phrases and quantifier phrases with their head words.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
The extraction heuristic then finds head word tuples and their likely attachments from the tagged and chunked text.,"{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"The heuristic relies on the observed fact that in English and in languages with similar word order, the attachment site of a preposition is usually located only a few words to the left of the preposition.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Finally, numbers are replaced by a single token, the text is converted to lower case, and the morphology database is used to find the base forms of the verbs and nouns.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
The extracted head word tuples differ from the training data used in previous supervised attempts in an important way.,"{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"In the supervised case, both of the potential sites, namely the verb v and the noun n are known before the attachment is resolved.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"In the unsupervised case discussed here, the extraction heuristic only finds what it thinks are unambiguous cases of prepositional phrase attachment.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Therefore, there is only one possible attachment site for the preposition, and either the verb v or the noun n does not exist, in the case of noun-attached preposition or a verb-attached preposition, respectively.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"This extraction heuristic loosely resembles a step in the bootstrapping procedure used to get training data for the classifier of (Hindle and Rooth, 1993).","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"In that step, unambiguous attachments from the FIDDITCH parser's output are initially used to resolve some of the ambiguous attachments, and the resolved cases are iteratively used to disambiguate the remaining unresolved cases.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Our procedure differs critically from (Hindle and Rooth, 1993) in that we do not iterate, we extract unambiguous attachments from unparsed input sentences, and we totally ignore the ambiguous cases.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
It is the hypothesis of this approach that the information in just the unambiguous attachment events can resolve the ambiguous attachment events of the test data.,"{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Given a tagged and chunked sentence, the extraction heuristic returns head word tuples of the form (v,p, n2) or (n,p, n2), where v is the verb, n is the noun, p is the preposition, n2 is the object of the preposition.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
The main idea of the extraction heuristic is that an attachment site of a preposition is usually within a few words to the left of the preposition.,"{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"We extract : (v,p, n2) if Table 1 also shows the result of the applying the extraction heuristic to a sample sentence.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"The heuristic ignores cases where p = of, since such cases are rarely ambiguous, and we opt to model them deterministically as noun attachments.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
We will report accuracies (in Section 5) on both cases where p = of and where p 0 of.,"{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Also, the heuristic excludes examples with the verb to be from the training set (but not the test set) since we found them to be unreliable sources of evidence.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Applying the extraction heuristic to 970K unannotated sentences from the 1988 Wall St. Journal' data yields approximately 910K unique head word tuples of the form (v, p, n2) or (n,p, n2).","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"The extraction heuristic is far from perfect; when applied to and compared with the annotated Wall St. Journal data of the Penn treebank, only 69% of the extracted head word tuples represent correct attachments.2 The extracted tuples are meant to be a noisy but abundant substitute for the information that one might get from a treebank.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Tables 2 and 3 list the most frequent extracted head word tuples for unambiguous verb and noun attachments, respectively.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"Many of the frequent nounattached (n,p, n2) tuples, such as num to num,3 are incorrect.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"The prepositional phrase to num is usually attached to a verb such as rise or fall in the Wall St. Journal domain, e.g., Profits rose 46 % to 52 million.","{'title': '3 Unsupervised Prepositional', 'number': '3'}"
"While the extracted tuples of the form (n, p, n2) and (v, p, n2) represent unambiguous noun and verb attachments in which either the verb or noun is known, our eventual goal is to resolve ambiguous attachments in the test data of the form (v, n,p, n2), in which both the noun n and verb v are always known.","{'title': '4 Statistical Models', 'number': '4'}"
We therefore must use any information in the unambiguous cases to resolve the ambiguous cases.,"{'title': '4 Statistical Models', 'number': '4'}"
"A natural way is to use a classifier that compares the probability of each outcome: We do not currently use n2 in the probability model, and we omit it from further discussion.","{'title': '4 Statistical Models', 'number': '4'}"
"We can factor Pr(v,n,p, a) as follows: The terms Pr(n) and Pr(v) are independent of the attachment a and need not be computed in c/ (1), but the estimation of Pr(alv, n) and Pr(pja,v,n) is problematic since our training data, i.e., the head words extracted from raw text, occur with either n or v, but never both n, v. This leads to make some heuristically motivated approximations.","{'title': '4 Statistical Models', 'number': '4'}"
"Let the random variable 0 range over {true, false), and let it denote the presence or absence of any preposition that is unambiguously attached to the noun or verb in question.","{'title': '4 Statistical Models', 'number': '4'}"
Then p(cb = trueln) is the conditional probability that a particular noun n in free text has an unambiguous prepositional phrase attachment.,"{'title': '4 Statistical Models', 'number': '4'}"
(0 = true will be written simply as true.),"{'title': '4 Statistical Models', 'number': '4'}"
"We approximate Pr(alv, n) as follows: The rationale behind this approximation is that the tendency of a v, n pair towards a noun (verb) attachment is related to the tendency of the noun (verb) alone to occur with an unambiguous prepositional phrase.","{'title': '4 Statistical Models', 'number': '4'}"
"The Z(v, n) term exists only to make the approximation a well formed probability over a E IN, 171.","{'title': '4 Statistical Models', 'number': '4'}"
"We approximate Pr(pla,v,n) as follows: The rationale behind these approximations is that when generating p given a noun (verb) attachment, only the counts involving the noun (verb) are relevant, assuming also that the noun (verb) has an attached prepositional phrase, i.e., 0 = true.","{'title': '4 Statistical Models', 'number': '4'}"
"We use word statistics from both the tagged corpus and the set of extracted head word tuples to estimate the probability of generating 0 = true, p, and n2.","{'title': '4 Statistical Models', 'number': '4'}"
"Counts from the extracted set of tuples assume that 0 = true, while counts from the corpus itself may correspond to either 0 = true or 0 = false, depending on if the noun if p = of otherwise or verb in question is, or is not, respectively, unambiguously attached to a preposition.","{'title': '4 Statistical Models', 'number': '4'}"
"The quantities Pr(trueln) and Pr(truelv) denote the conditional probability that n or v will occur with some unambiguously attached preposition, and are estimated as follows: p, and define cN Ep cAp) as the number of noun attached tuples.","{'title': '4 Statistical Models', 'number': '4'}"
"Analogously, define cv(p) = E, c(v, p, true) and cv = Ep cv (P)• The counts c(n,p,true) and c(v,p,true) are from the extracted head word tuples.","{'title': '4 Statistical Models', 'number': '4'}"
"Using the above notation, we can interpolate as follows: where c(n) and c(v) are counts from the tagged corpus, and where c(n, true) and c(v, true) are counts from the extracted head word tuples.","{'title': '4 Statistical Models', 'number': '4'}"
"The terms Pr(pin, true) and Pr(plv, true) denote the conditional probability that a particular preposition p will occur as an unambiguous attachment to n or v. We present two techniques to estimate this probability, one based on bigram counts and another based on an interpolation method.","{'title': '4 Statistical Models', 'number': '4'}"
"This technique uses the bigram counts of the extracted head word tuples, and backs off to the uniform distribution when the denominator is zero. where 7) is the set of possible prepositions, where all the counts c(...) are from the extracted head word tuples.","{'title': '4 Statistical Models', 'number': '4'}"
"This technique is similar to the one in (Hindle and Rooth, 1993), and interpolates between the tendencies of the (v, p) and (n, p) bigrams and the tendency of the type of attachment (e.g., N or V) towards a particular preposition p. First, define cN(p) = En c(n,p,true) as the number of noun attached tuples with the preposition","{'title': '4 Statistical Models', 'number': '4'}"
Approximately 970K unannotated sentences from the 1988 Wall St. Journal were processed in a manner identical to the example sentence in Table 1.,"{'title': '5 Evaluation in English', 'number': '5'}"
"The result was approximately 910,000 head word tuples of the form (v ,p, n2) or (n,p, n2).","{'title': '5 Evaluation in English', 'number': '5'}"
"Note that while the head word tuples represent correct attachments only 69% of the time, their quantity is about 45 times greater than the quantity of data used in previous supervised approaches.","{'title': '5 Evaluation in English', 'number': '5'}"
"The extracted data was used as training material for the three classifiers clbasel Chnterp, and cibigram• Each classifier is constructed as follows: Cl base This is the &quot;baseline&quot; classifier that predicts N of p = of, and V otherwise. c/interp: This classifier has the form of equation (1), uses the method in section 4.1 to generate 0, and the method in section 4.2.2 to generate p. clbigram: This classifier has the form of equation (1), uses the method in section 4.1 to generate 0, and the method in section 4.2.1 to generate p. Table 4 shows accuracies of the classifiers on the test set of (Ratnaparkhi et al., 1994), which is derived from the manually annotated attachments in the Penn Treebank Wall St. Journal data.","{'title': '5 Evaluation in English', 'number': '5'}"
"The Penn Treebank is drawn from the 1989 Wall St. Journal data, so there is no possibility of overlap with our training data.","{'title': '5 Evaluation in English', 'number': '5'}"
"Furthermore, the extraction heuristic was developed and tuned on a &quot;development set&quot;, i.e., a set of annotated examples that did not overlap with either the test set or the training set.","{'title': '5 Evaluation in English', 'number': '5'}"
"Table 5 shows the two probabilities Pr(alv, n) and Pr (pla, v, n), using the same approximations as c/bigram, for the ambiguous example rise num to num.","{'title': '5 Evaluation in English', 'number': '5'}"
(Recall that Pr(v) and Pr(n) are not needed.),"{'title': '5 Evaluation in English', 'number': '5'}"
"While the tuple (num, to, num) is more frequent than (rise, to, num), the conditional probabilities prefer a = V, which is the choice that maximizes Pr (v , n, p, a).","{'title': '5 Evaluation in English', 'number': '5'}"
"Both classifiers c/interp and c/bigram clearly outperform the. baseline, but the classifier does not outperform dbigraml even though it interpolates between the less specific evidence (the preposition counts) and more specific evidence (the bigram counts).","{'title': '5 Evaluation in English', 'number': '5'}"
This may be due to the errors in our extracted training data; supervised classifiers that train from clean data typically benefit greatly by combining less specific evidence with more specific evidence.,"{'title': '5 Evaluation in English', 'number': '5'}"
"Despite the errors in the training data, the performance of the unsupervised classifiers (81.9%) begins to approach the best performance of the comparable supervised classifiers (84.5%).","{'title': '5 Evaluation in English', 'number': '5'}"
"(Our goal is to replicate the supervision of a treebank, but not a semantic dictionary, so we do not compare against (Stetina and Nagao, 1997).)","{'title': '5 Evaluation in English', 'number': '5'}"
"Furthermore, we do not use the second noun n2, whereas the best supervised methods use this information.","{'title': '5 Evaluation in English', 'number': '5'}"
"Our result shows that the information in imperfect but abundant data from unambiguous attachments, as shown in Tables 2 and 3, is sufficient to resolve ambiguous prepositional phrase attachments at accuracies just under the supervised state-of-the-art accuracy.","{'title': '5 Evaluation in English', 'number': '5'}"
"We claim that our approach is portable to languages with similar word order, and we support this claim by demonstrating our approach on the Spanish language.","{'title': '6 Evaluation in Spanish', 'number': '6'}"
"We used the Spanish tagger and morphological analyzer developed at the Xerox Research Centre Europe4 and we modified the extraction heuristic to account for the new tagset, and to account for the Spanish equivalents of the words of (i.e., de or del) and to be (i.e., ser).","{'title': '6 Evaluation in Spanish', 'number': '6'}"
Chunking was not performed on the Spanish data.,"{'title': '6 Evaluation in Spanish', 'number': '6'}"
"We used 450k sentences of raw text from the Linguistic Data Consortium's Spanish News Text Collection to extract a training set, and we used a non-overlapping set of 50k sentences from the collection to create test sets.","{'title': '6 Evaluation in Spanish', 'number': '6'}"
Three native Spanish speakers were asked to extract and annotate ambiguous instances of Spanish prepositional phrase attachments.,"{'title': '6 Evaluation in Spanish', 'number': '6'}"
"They annotated two sets (using the full sentence context); one set consisted of all ambiguous prepositional phrase attachments of the form (v, n,p, n2), and the other set consisted of cases where p = con.","{'title': '6 Evaluation in Spanish', 'number': '6'}"
"For testing our classifier, we used only those judgments on which all three annotators agreed.","{'title': '6 Evaluation in Spanish', 'number': '6'}"
"The performance of the classifiers Clbigram, dinterp) and c/base, when trained and tested on Spanish language data, are shown in Table 6.","{'title': '6 Evaluation in Spanish', 'number': '6'}"
"The Spanish test set has fewer ambiguous prepositions than the English test set, as shown by the accuracy of Ciba„.","{'title': '6 Evaluation in Spanish', 'number': '6'}"
"However, the accuracy improvements of Clbygrara over Cl ba„ are statistically significant for both test sets.5","{'title': '6 Evaluation in Spanish', 'number': '6'}"
The unsupervised algorithm for prepositional phrase attachment presented here is the only algorithm in the published literature that can significantly outperform the baseline without using data derived from a treebank or parser.,"{'title': '7 Conclusion', 'number': '7'}"
"The accuracy of our technique approaches the accuracy of the best supervised methods, and does so with only a tiny fraction of the supervision.","{'title': '7 Conclusion', 'number': '7'}"
"Since only a small part of the extraction heuristic is specific to English, and since partof-speech taggers and morphology databases are widely available in other languages, our approach is far more portable than previous approaches for this problem.","{'title': '7 Conclusion', 'number': '7'}"
We successfully demonstrated the portability of our approach by applying it to the prepositional phrase attachment task in the Spanish language.,"{'title': '7 Conclusion', 'number': '7'}"
"We thank Dr. Lauri Kartunnen for lending us the Spanish natural language tools, and Mike Collins for helpful discussions on this work.","{'title': '8 Acknowledgments', 'number': '8'}"
