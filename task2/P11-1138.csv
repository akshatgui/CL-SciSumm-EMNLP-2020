col1,col2
Disambiguating concepts and entities in a context sensitive way is a fundamental problem in natural language processing.,{}
The comprehensiveness of Wikipedia has made the online encyclopedia an increasingly popular target for disambiguation.,{}
"Disambiguation to Wikipedia is similar to a traditional Word Sense Disambiguation task, but distinct in that the Wikipedia link structure provides additional information about which disambiguations are compatible.",{}
"In this work we analyze approaches that utilize this information to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches.",{}
"We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.",{}
Wikification is the task of identifying and linking expressions in text to their referent Wikipedia pages.,"{'title': '1 Introduction', 'number': '1'}"
"Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009).","{'title': '1 Introduction', 'number': '1'}"
Previous studies on Wikification differ with respect to the corpora they address and the subset of expressions they attempt to link.,"{'title': '1 Introduction', 'number': '1'}"
"For example, some studies focus on linking only named entities, whereas others attempt to link all “interesting” expressions, mimicking the link structure found in Wikipedia.","{'title': '1 Introduction', 'number': '1'}"
"Regardless, all Wikification systems are faced with a key Disambiguation to Wikipedia (D2W) task.","{'title': '1 Introduction', 'number': '1'}"
"In the D2W task, we’re given a text along with explicitly identified substrings (called mentions) to disambiguate, and the goal is to output the corresponding Wikipedia page, if any, for each mention.","{'title': '1 Introduction', 'number': '1'}"
"For example, given the input sentence “I am visiting friends in <Chicago>,” we output http://en.wikipedia.org/wiki/Chicago – the Wikipedia page for the city of Chicago, Illinois, and not (for example) the page for the 2002 film of the same name.","{'title': '1 Introduction', 'number': '1'}"
"Local D2W approaches disambiguate each mention in a document separately, utilizing clues such as the textual similarity between the document and each candidate disambiguation’s Wikipedia page.","{'title': '1 Introduction', 'number': '1'}"
"Recent work on D2W has tended to focus on more sophisticated global approaches to the problem, in which all mentions in a document are disambiguated simultaneously to arrive at a coherent set of disambiguations (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009).","{'title': '1 Introduction', 'number': '1'}"
"For example, if a mention of “Michael Jordan” refers to the computer scientist rather than the basketball player, then we would expect a mention of “Monte Carlo” in the same document to refer to the statistical technique rather than the location.","{'title': '1 Introduction', 'number': '1'}"
Global approaches utilize the Wikipedia link graph to estimate coherence.,"{'title': '1 Introduction', 'number': '1'}"
"Document teat with mentions In this paper, we analyze global and local approaches to the D2W task.","{'title': '1 Introduction', 'number': '1'}"
"Our contributions are as follows: (1) We present a formulation of the D2W task as an optimization problem with local and global variants, and identify the strengths and the weaknesses of each, (2) Using this formulation, we present a new global D2W system, called GLOW.","{'title': '1 Introduction', 'number': '1'}"
"In experiments on existing and novel D2W data sets,1 GLOW is shown to outperform the previous stateof-the-art system of (Milne and Witten, 2008b), (3) We present an error analysis and identify the key remaining challenge: determining when mentions refer to concepts not captured in Wikipedia.","{'title': '1 Introduction', 'number': '1'}"
We formalize our Disambiguation to Wikipedia (D2W) task as follows.,"{'title': '2 Problem Definition and Approach', 'number': '2'}"
"We are given a document d with a set of mentions M = {m1,... , mN}, and our goal is to produce a mapping from the set of mentions to the set of Wikipedia titles W = {t1, ... , t|W|}.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"Often, mentions correspond to a concept without a Wikipedia page; we treat this case by adding a special null title to the set W. The D2W task can be visualized as finding a many-to-one matching on a bipartite graph, with mentions forming one partition and Wikipedia titles the other (see Figure 1).","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"We denote the output matching as an N-tuple Γ = (t1, ... , tN) where ti is the output disambiguation for mention mi.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
A local D2W approach disambiguates each mention mi separately.,"{'title': '2 Problem Definition and Approach', 'number': '2'}"
"Specifically, let 0(mi, tj) be a score function reflecting the likelihood that the candidate title tj E W is the correct disambiguation for mi E M. A local approach solves the following optimization problem: Local D2W approaches, exemplified by (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007), utilize 0 functions that assign higher scores to titles with content similar to that of the input document.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"We expect, all else being equal, that the correct disambiguations will form a “coherent” set of related concepts.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"Global approaches define a coherence function 0, and attempt to solve the following disambiguation problem: The global optimization problem in Eq.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"2 is NPhard, and approximations are required (Cucerzan, 2007).","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"The common approach is to utilize the Wikipedia link graph to obtain an estimate pairwise relatedness between titles 0(ti, tj) and to efficiently generate a disambiguation context Γ′, a rough approximation to the optimal Γ*.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"We then solve the easier problem: ence of unambiguous mentions in the input document, and the second approach inevitably adds irrelevant titles to the disambiguation context.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
"As we demonstrate in our experiments, by utilizing a more accurate disambiguation context, GLOW is able to achieve better performance.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
Eq.,"{'title': '2 Problem Definition and Approach', 'number': '2'}"
"3 can be solved by finding each ti and then mapping mi independently as in a local approach, but still enforces some degree of coherence among the disambiguations.","{'title': '2 Problem Definition and Approach', 'number': '2'}"
Wikipedia was first explored as an information source for named entity disambiguation and information retrieval by Bunescu and Pasca (2006).,"{'title': '3 Related Work', 'number': '3'}"
"There, disambiguation is performed using an SVM kernel that compares the lexical context around the ambiguous named entity to the content of the candidate disambiguation’s Wikipedia page.","{'title': '3 Related Work', 'number': '3'}"
"However, since each ambiguous mention required a separate SVM model, the experiment was on a very limited scale.","{'title': '3 Related Work', 'number': '3'}"
Mihalcea and Csomai applied Word Sense Disambiguation methods to the Disambiguation to Wikipedia task (2007).,"{'title': '3 Related Work', 'number': '3'}"
"They experimented with two methods: (a) the lexical overlap between the Wikipedia page of the candidate disambiguations and the context of the ambiguous mention, and (b) training a Naive Bayes classiffier for each ambiguous mention, using the hyperlink information found in Wikipedia as ground truth.","{'title': '3 Related Work', 'number': '3'}"
"Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework.","{'title': '3 Related Work', 'number': '3'}"
"Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010).","{'title': '3 Related Work', 'number': '3'}"
"The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007).2 On the other hand, in (Cucerzan, 2007) the disambiguation context is taken to be all plausible disambiguations of the named entities in the text, and title relatedness is based on the overlap in categories and incoming links.","{'title': '3 Related Work', 'number': '3'}"
Both approaches have limitations.,"{'title': '3 Related Work', 'number': '3'}"
"The first approach relies on the pres2(Milne and Witten, 2008b) also weight each mention in r′ by its estimated disambiguation utility, which can be modeled by augmenting 0 on per-problem basis.","{'title': '3 Related Work', 'number': '3'}"
"In this section, we present our global D2W system, which solves the optimization problem in Eq.","{'title': '4 System Architecture', 'number': '4'}"
3.,"{'title': '4 System Architecture', 'number': '4'}"
"We refer to the system as GLOW, for Global Wikification.","{'title': '4 System Architecture', 'number': '4'}"
We use GLOW as a test bed for evaluating local and global approaches for D2W.,"{'title': '4 System Architecture', 'number': '4'}"
"GLOW combines a powerful local model φ with an novel method for choosing an accurate disambiguation context V, which as we show in our experiments allows it to outperform the previous state of the art.","{'title': '4 System Architecture', 'number': '4'}"
We represent the functions φ and ψ as weighted sums of features.,"{'title': '4 System Architecture', 'number': '4'}"
"Specifically, we set: where each feature φi(m, t) captures some aspect of the relatedness between the mention m and the Wikipedia title t. Feature functions ψi(t, t′) are defined analogously.","{'title': '4 System Architecture', 'number': '4'}"
We detail the specific feature functions utilized in GLOW in following sections.,"{'title': '4 System Architecture', 'number': '4'}"
"The coefficients wi are learned using a Support Vector Machine over bootstrapped training data from Wikipedia, as described in Section 4.5.","{'title': '4 System Architecture', 'number': '4'}"
"At a high level, the GLOW system optimizes the objective function in Eq.","{'title': '4 System Architecture', 'number': '4'}"
3 in a two-stage process.,"{'title': '4 System Architecture', 'number': '4'}"
"We first execute a ranker to obtain the best non-null disambiguation for each mention in the document, and then execute a linker that decides whether the mention should be linked to Wikipedia, or whether instead switching the top-ranked disambiguation to null improves the objective function.","{'title': '4 System Architecture', 'number': '4'}"
"As our experiments illustrate, the linking task is the more challenging of the two by a significant margin.","{'title': '4 System Architecture', 'number': '4'}"
Figure 2 provides detailed pseudocode for GLOW.,"{'title': '4 System Architecture', 'number': '4'}"
"Given a document d and a set of mentions M, we start by augmenting the set of mentions with all phrases in the document that could be linked to Wikipedia, but were not included in M. Introducing these additional mentions provides context that may be informative for the global coherence computation (it has no effect on local approaches).","{'title': '4 System Architecture', 'number': '4'}"
"In the second step, we construct for each mention mi a limited set of candidate Wikipedia titles Ti that mi may refer to.","{'title': '4 System Architecture', 'number': '4'}"
Considering only a small subset of Wikipedia titles as potential disambiguations is crucial for tractability (we detail which titles are selected below).,"{'title': '4 System Architecture', 'number': '4'}"
"In the third step, the ranker outputs the most appropriate non-null disambiguation ti for each mention mi.","{'title': '4 System Architecture', 'number': '4'}"
"In the final step, the linker decides whether the top-ranked disambiguation is correct.","{'title': '4 System Architecture', 'number': '4'}"
"The disambiguation (mi, ti) may be incorrect for several reasons: (1) mention mi does not have a corresponding Wikipedia page, (2) mi does have a corresponding Wikipedia page, but it was not included in Ti, or (3) the ranker erroneously chose an incorrect disambiguation over the correct one.","{'title': '4 System Architecture', 'number': '4'}"
"In the below sections, we describe each step of the GLOW algorithm, and the local and global features utilized, in detail.","{'title': '4 System Architecture', 'number': '4'}"
"Because we desire a system that can process documents at scale, each step requires trade-offs between accuracy and efficiency.","{'title': '4 System Architecture', 'number': '4'}"
"4.1 Disambiguation Candidates Generation The first step in GLOW is to extract all mentions that can refer to Wikipedia titles, and to construct a set of disambiguation candidates for each mention.","{'title': '4 System Architecture', 'number': '4'}"
"Following previous work, we use Wikipedia hyperlinks to perform these steps.","{'title': '4 System Architecture', 'number': '4'}"
"GLOW utilizes an anchortitle index, computed by crawling Wikipedia, that maps each distinct hyperlink anchor text to its target Wikipedia titles.","{'title': '4 System Architecture', 'number': '4'}"
"For example, the anchor text “Chicago” is used in Wikipedia to refer both to the city in Illinois and to the movie.","{'title': '4 System Architecture', 'number': '4'}"
Anchor texts in the index that appear in document d are used to supplement the mention set M in Step 1 of the GLOW algorithm in Figure 2.,"{'title': '4 System Architecture', 'number': '4'}"
Because checking all substrings Table 1: Ranker features.,"{'title': '4 System Architecture', 'number': '4'}"
I[ti_tj] is an indicator variable which is 1 iff ti links to t1 or vise-versa.,"{'title': '4 System Architecture', 'number': '4'}"
"I[ti—tj] is 1 iff the titles point to each other. in the input text against the index is computationally inefficient, we instead prune the search space by applying a publicly available shallow parser and named entity recognition system.3 We consider only the expressions marked as named entities by the NER tagger, the noun-phrase chunks extracted by the shallow parser, and all sub-expressions of up to 5 tokens of the noun-phrase chunks.","{'title': '4 System Architecture', 'number': '4'}"
"To retrieve the disambiguation candidates Ti for a given mention mi in Step 2 of the algorithm, we query the anchor-title index.","{'title': '4 System Architecture', 'number': '4'}"
Ti is taken to be the set of titles most frequently linked to with anchor text mi in Wikipedia.,"{'title': '4 System Architecture', 'number': '4'}"
"For computational efficiency, we utilize only the top 20 most frequent target pages for the anchor text; the accuracy impact of this optimization is analyzed in Section 6.","{'title': '4 System Architecture', 'number': '4'}"
"From the anchor-title index, we compute two local features Oi(m, t).","{'title': '4 System Architecture', 'number': '4'}"
"The first, P(tIm), is the fraction of times the title t is the target page for an anchor text m. This single feature is a very reliable indicator of the correct disambiguation (Fader et al., 2009), and we use it as a baseline in our experiments.","{'title': '4 System Architecture', 'number': '4'}"
"The second, P(t), gives the fraction of all Wikipedia articles that link to t. local features 0(t, m).","{'title': '4 System Architecture', 'number': '4'}"
"These features capture the intuition that a given Wikipedia title t is more likely to be referred to by mention m appearing in document d if the Wikipedia page for t has high textual similarity to d, or if the context surrounding hyperlinks to t are similar to m’s context in d. For each Wikipedia title t, we construct a top200 token TF-IDF summary of the Wikipedia page t, which we denote as Text(t) and a top-200 token TF-IDF summary of the context within which t was hyperlinked to in Wikipedia, which we denote as Context(t).","{'title': '4 System Architecture', 'number': '4'}"
"We keep the IDF vector for all tokens in Wikipedia, and given an input mention m in a document d, we extract the TF-IDF representation of d, which we denote Text(d), and a TF-IDF representation of a 100-token window around m, which we denote Context(m).","{'title': '4 System Architecture', 'number': '4'}"
This allows us to define four local features described in Table 1.,"{'title': '4 System Architecture', 'number': '4'}"
We additionally compute weighted versions of the features described above.,"{'title': '4 System Architecture', 'number': '4'}"
Error analysis has shown that in many cases the summaries of the different disambiguation candidates for the same surface form s were very similar.,"{'title': '4 System Architecture', 'number': '4'}"
"For example, consider the disambiguation candidates of “China’ and their TF-IDF summaries in Figure 1.","{'title': '4 System Architecture', 'number': '4'}"
"The majority of the terms selected in all summaries refer to the general issues related to China, such as “legalism, reform, military, control, etc.”, while a minority of the terms actually allow disambiguation between the candidates.","{'title': '4 System Architecture', 'number': '4'}"
"The problem stems from the fact that the TF-IDF summaries are constructed against the entire Wikipedia, and not against the confusion set of disambiguation candidates of m. Therefore, we re-weigh the TF-IDF vectors using the TF-IDF scheme on the disambiguation candidates as a adhoc document collection, similarly to an approach in (Joachims, 1997) for classifying documents.","{'title': '4 System Architecture', 'number': '4'}"
"In our scenario, the TF of the a token is the original TF-IDF summary score (a real number), and the IDF term is the sum of all the TF-IDF scores for the token within the set of disambiguation candidates for m. This adds 4 more “reweighted local” features in Global approaches require a disambiguation context V and a relatedness measure 0 in Eq.","{'title': '4 System Architecture', 'number': '4'}"
3.,"{'title': '4 System Architecture', 'number': '4'}"
"In this section, we describe our method for generating a disambiguation context, and the set of global features 0i(t, t′) forming our relatedness measure.","{'title': '4 System Architecture', 'number': '4'}"
"In previous work, Cucerzan defined the disambiguation context as the union of disambiguation candidates for all the named entity mentions in the input document (2007).","{'title': '4 System Architecture', 'number': '4'}"
"The disadvantage of this approach is that irrelevant titles are inevitably added to the disambiguation context, creating noise.","{'title': '4 System Architecture', 'number': '4'}"
"Milne and Witten, on the other hand, use a set of unambiguous mentions (2008b).","{'title': '4 System Architecture', 'number': '4'}"
"This approach utilizes only a fraction of the available mentions for context, and relies on the presence of unambiguous mentions with high disambiguation utility.","{'title': '4 System Architecture', 'number': '4'}"
"In GLOW, we utilize a simple and efficient alternative approach: we first train a local disambiguation system, and then use the predictions of that system as the disambiguation context.","{'title': '4 System Architecture', 'number': '4'}"
"The advantage of this approach is that unlike (Milne and Witten, 2008b) we use all the available mentions in the document, and unlike (Cucerzan, 2007) we reduce the amount of irrelevant titles in the disambiguation context by taking only the top-ranked disambiguation per mention.","{'title': '4 System Architecture', 'number': '4'}"
Our global features are refinements of previously proposed semantic relatedness measures between Wikipedia titles.,"{'title': '4 System Architecture', 'number': '4'}"
"We are aware of two previous methods for estimating the relatedness between two Wikipedia concepts: (Strube and Ponzetto, 2006), which uses category overlap, and (Milne and Witten, 2008a), which uses the incoming link structure.","{'title': '4 System Architecture', 'number': '4'}"
"Previous work experimented with two relatedness measures: NGD, and Specificity-weighted Cosine Similarity.","{'title': '4 System Architecture', 'number': '4'}"
"Consistent with previous work, we found NGD to be the better-performing of the two.","{'title': '4 System Architecture', 'number': '4'}"
Thus we use only NGD along with a well-known Pontwise Mutual Information (PMI) relatedness measure.,"{'title': '4 System Architecture', 'number': '4'}"
"Given a Wikipedia title collection W, titles t1 and t2 with a set of incoming links L1, and L2 respectively, PMI and NGD are defined as follows: The NGD and the PMI measures can also be computed over the set of outgoing links, and we include these as features as well.","{'title': '4 System Architecture', 'number': '4'}"
We also included a feature indicating whether the articles each link to one another.,"{'title': '4 System Architecture', 'number': '4'}"
"Lastly, rather than taking the sum of the relatedness scores as suggested by Eq.","{'title': '4 System Architecture', 'number': '4'}"
"3, we use two features: the average and the maximum relatedness to V. We expect the average to be informative for many documents.","{'title': '4 System Architecture', 'number': '4'}"
"The intuition for also including the maximum relatedness is that for longer documents that may cover many different subtopics, the maximum may be more informative than the average.","{'title': '4 System Architecture', 'number': '4'}"
"We have experimented with other semantic features, such as category overlap or cosine similarity between the TF-IDF summaries of the titles, but these did not improve performance in our experiments.","{'title': '4 System Architecture', 'number': '4'}"
The complete set of global features used in GLOW is given in Table 1.,"{'title': '4 System Architecture', 'number': '4'}"
"Given the mention m and the top-ranked disambiguation t, the linker attempts to decide whether t is indeed the correct disambiguation of m. The linker includes the same features as the ranker, plus additional features we expect to be particularly relevant to the task.","{'title': '4 System Architecture', 'number': '4'}"
"We include the confidence of the ranker in t with respect to second-best disambiguation t′, intended to estimate whether the ranker may have made a mistake.","{'title': '4 System Architecture', 'number': '4'}"
"We also include several properties of the mention m: the entropy of the distribution P(tlm), the percent of Wikipedia titles in which m appears hyperlinked versus the percent of times m appears as plain text, whether m was detected by NER as a named entity, and a Good-Turing estimate of how likely m is to be out-of-Wikipedia concept based on the counts in P(t1m).","{'title': '4 System Architecture', 'number': '4'}"
"We train the coefficients for the ranker features using a linear Ranking Support Vector Machine, using training data gathered from Wikipedia.","{'title': '4 System Architecture', 'number': '4'}"
Wikipedia links are considered gold-standard links for the training process.,"{'title': '4 System Architecture', 'number': '4'}"
The methods for compiling the Wikipedia training corpus are given in Section 5.,"{'title': '4 System Architecture', 'number': '4'}"
We train the linker as a separate linear Support Vector Machine.,"{'title': '4 System Architecture', 'number': '4'}"
Training data for the linker is obtained by applying the ranker on the training set.,"{'title': '4 System Architecture', 'number': '4'}"
"The mentions for which the top-ranked disambiguation did not match the gold disambiguation are treated as negative examples, while the mentions the ranker got correct serve as positive examples.","{'title': '4 System Architecture', 'number': '4'}"
"We evaluate GLOW on four data sets, of which two are from previous work.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"The first data set, from (Milne and Witten, 2008b), is a subset of the AQUAINT corpus of newswire text that is annotated to mimic the hyperlink structure in Wikipedia.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"That is, only the first mentions of “important” titles were hyperlinked.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
Titles deemed uninteresting and redundant mentions of the same title are not linked.,"{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"The second data set, from (Cucerzan, 2007), is taken from MSNBC news and focuses on disambiguating named entities after running NER and co-reference resolution systems on newsire text.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"In this case, all mentions of all the detected named entities are linked.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
We also constructed two additional data sets.,"{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"The first is a subset of the ACE co-reference data set, which has the advantage that mentions and their types are given, and the co-reference is resolved.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"We asked annotators on Amazon’s Mechanical Turk to link the first nominal mention of each co-reference chain to Wikipedia, if possible.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"Finding the accuracy of a majority vote of these annotations to be approximately 85%, we manually corrected the annotations to obtain ground truth for our experiments.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"The second data set we constructed, Wiki, is a sample of paragraphs from Wikipedia pages.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
Mentions in this data set correspond to existing hyperlinks in the Wikipedia text.,"{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"Because Wikipedia editors explicitly link mentions to Wikipedia pages, their anchor text tends to match the title of the linked-topage—as a result, in the overwhelming majority of cases, the disambiguation decision is as trivial as string matching.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"In an attempt to generate more challenging data, we extracted 10,000 random paragraphs for which choosing the top disambiguation according to P(t|m) results in at least a 10% ranker error rate.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"40 paragraphs of this data was utilized for testing, while the remainder was used for training.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
The data sets are summarized in Table 2.,"{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"The table shows the number of annotated mentions which were hyperlinked to non-null Wikipedia pages, and the number of titles in the documents (without counting repetitions).","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"For example, the AQUAINT data set contains 727 mentions,4 all of which refer to distinct titles.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"The MSNBC data set contains 747 mentions mapped to non-null Wikipedia pages, but some mentions within the same document refer to the same titles.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"There are 372 titles in the data set, when multiple instances of the same title within one document are not counted.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"To isolate the performance of the individual components of GLOW, we use multiple distinct metrics for evaluation.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"Ranker accuracy, which measures the performance of the ranker alone, is computed only over those mentions with a non-null gold disambiguation that appears in the candidate set.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
It is equal to the fraction of these mentions for which the ranker returns the correct disambiguation.,"{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"Thus, a perfect ranker should achieve a ranker accuracy of 1.0, irrespective of limitations of the candidate generator.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"Linker accuracy is defined as the fraction of all mentions for which the linker outputs the correct disambiguation (note that, when the title produced by the ranker is incorrect, this penalizes linker accuracy).","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"Lastly, we evaluate our whole system against other baselines using a previously-employed “bag of titles” (BOT) evaluation (Milne and Witten, 2008b).","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"In BOT, we compare the set of titles output for a document with the gold set of titles for that document (ignoring duplicates), and utilize standard precision, recall, and F1 measures.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"In BOT, the set of titles is collected from the mentions hyperlinked in the gold annotation.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"That is, if the gold annotation is { (China, People’s Republic of China), (Taiwan, Taiwan), (Jiangsu, Jiangsu)} of the number of generated disambiguation candidates.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"Listed is the fraction of identified mentions m whose target disambiguation t is among the top k candidates ranked in descending order of P(t|m). and the predicted anotation is: { (China, People’s Republic of China), (China, History of China), (Taiwan, null), (Jiangsu, Jiangsu), (republic, Government)} , then the BOT for the gold annotation is: {People’s Republic of China, Taiwan, Jiangsu} , and the BOT for the predicted annotation is: {People’s Republic of China, History of China, Jiangsu} .","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"The title Government is not included in the BOT for predicted annotation, because its associate mention republic did not appear as a mention in the gold annotation.","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
Both the precision and the recall of the above prediction is 0.66.,"{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
"We note that in the BOT evaluation, following (Milne and Witten, 2008b) we consider all the titles within a document, even if some the titles were due to mentions we failed to identify.5","{'title': '5 Data sets and Evaluation Methodology', 'number': '5'}"
