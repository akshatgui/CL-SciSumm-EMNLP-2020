col1,col2
Standard pairwise coreference resolution systems are subject to errors resulting from their performing anaphora identification as an implicit part of coreference resolution.,{}
"In this paper, we propose an integer linear programming (ILP) formulation for coreference resolution which models anaphoricity and coreference as a joint task, such that each local model informs the other for the final assignments. joint ILP formulation provides score improvements of 3.7-5.3% over a base coreference classifier on the ACE datasets.",{}
"The task of coreference resolution involves imposing a partition on a set of entity mentions in a document, where each partition corresponds to some entity in an underlying discourse model.","{'title': '1 Introduction', 'number': '1'}"
"Most work treats coreference resolution as a binary classification task in which each decision is made in a pairwise fashion, independently of the others (McCarthy and Lehnert, 1995; Soon et al., 2001; Ng and Cardie, 2002b; Morton, 2000; Kehler et al., 2004).","{'title': '1 Introduction', 'number': '1'}"
There are two major drawbacks with most systems that make pairwise coreference decisions.,"{'title': '1 Introduction', 'number': '1'}"
The first is that identification of anaphora is done implicitly as part of the coreference resolution.,"{'title': '1 Introduction', 'number': '1'}"
"Two common types of errors with these systems are cases where: (i) the system mistakenly identifies an antecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention.","{'title': '1 Introduction', 'number': '1'}"
"To reduce such errors, Ng and Cardie (2002a) and Ng (2004) use an anaphoricity classifier –which has the sole task of saying whether or not any antecedents should be identified for each mention– as a filter for their coreference system.","{'title': '1 Introduction', 'number': '1'}"
"They achieve higher performance by doing so; however, their setup uses the two classifiers in a cascade.","{'title': '1 Introduction', 'number': '1'}"
"This requires careful determination of an anaphoricity threshold in order to not remove too many mentions from consideration (Ng, 2004).","{'title': '1 Introduction', 'number': '1'}"
"This sensitivity is unsurprising, given that the tasks are codependent.","{'title': '1 Introduction', 'number': '1'}"
"The second problem is that most coreference systems make each decision independently of previous ones in a greedy fashion (McCallum and Wellner, 2004).","{'title': '1 Introduction', 'number': '1'}"
"Clearly, the determination of membership of a particular mention into a partition should be conditioned on how well it matches the entity as a whole.","{'title': '1 Introduction', 'number': '1'}"
"Since independence between decisions is an unwarranted assumption for the task, models that consider a more global context are likely to be more appropriate.","{'title': '1 Introduction', 'number': '1'}"
"Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using rerankers.","{'title': '1 Introduction', 'number': '1'}"
"In this paper, we propose to recast the task of coreference resolution as an optimization problem, namely an integer linear programming (ILP) problem.","{'title': '1 Introduction', 'number': '1'}"
This framework has several properties that make it highly suitable for addressing the two aforementioned problems.,"{'title': '1 Introduction', 'number': '1'}"
The first is that it can utilize existing classifiers; ILP performs global inference based on their output rather than formulating a new inference procedure for solving the basic task.,"{'title': '1 Introduction', 'number': '1'}"
"Second, the ILP approach supports inference over multiple classifiers, without having to fiddle with special parameterization.","{'title': '1 Introduction', 'number': '1'}"
"Third, it is much more efficient than conditional random fields, especially when long-distance features are utilized (Roth and Yih, 2005).","{'title': '1 Introduction', 'number': '1'}"
"Finally, it is straightforward to create categorical global constraints with ILP; this is done in a declarative manner using inequalities on the assignments to indicator variables.","{'title': '1 Introduction', 'number': '1'}"
"This paper focuses on the first problem, and proposes to model anaphoricity determination and coreference resolution as a joint task, wherein the decisions made by each locally trained model are mutually constrained.","{'title': '1 Introduction', 'number': '1'}"
The presentation of the ILP model proceeds in two steps.,"{'title': '1 Introduction', 'number': '1'}"
"In the first, intermediary step, we simply use ILP to find a global assignment based on decisions made by the coreference classifier alone.","{'title': '1 Introduction', 'number': '1'}"
"The resulting assignment is one that maximally agrees with the decisions of the classifier, that is, where all and only the links predicted to be coreferential are used for constructing the chains.","{'title': '1 Introduction', 'number': '1'}"
"This is in contrast with the usual clustering algorithms, in which a unique antecedent is typically picked for each anaphor (e.g., the most probable or the most recent).","{'title': '1 Introduction', 'number': '1'}"
The second step provides the joint formulation: the coreference classifier is now combined with an anaphoricity classifier and constraints are added to ensure that the ultimate coreference and anaphoricity decisions are mutually consistent.,"{'title': '1 Introduction', 'number': '1'}"
Both of these formulations achieve significant performance gains over the base classifier.,"{'title': '1 Introduction', 'number': '1'}"
"Specifically, the joint model achieves f-score improvements of 3.7-5.3% on three datasets.","{'title': '1 Introduction', 'number': '1'}"
"We begin by presenting the basic coreference classifier and anaphoricity classifier and their performance, including an upperbound that shows the limitation of using them in a cascade.","{'title': '1 Introduction', 'number': '1'}"
We then give the details of our ILP formulations and evaluate their performance with respect to each other and the base classifier.,"{'title': '1 Introduction', 'number': '1'}"
"The classification approach tackles coreference in two steps by: (i) estimating the probability, PC(COREF|hi, ji), of having a coreferential outcome given a pair of mentions hi, ji, and (ii) applying a selection algorithm that will single out a unique candidate out of the subset of candidates i for which the probability PC(COREF|hi, ji) reaches a particular value (typically .5).","{'title': '2 Base models: coreference classifier', 'number': '2'}"
We use a maximum entropy model for the coreference classifier.,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Such models are well-suited for coreference, because they are able to handle many different, potentially overlapping learning features without making independence assumptions.","{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Previous work on coreference using maximum entropy includes (Kehler, 1997; Morton, 1999; Morton, 2000).","{'title': '2 Base models: coreference classifier', 'number': '2'}"
The model is defined in a standard fashion as follows: comes (COREF and ¬COREF).,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Model parameters are estimated using maximum entropy (Berger et al., 1996).","{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Specifically, we estimate parameters with the limited memory variable metric algorithm implemented in the Toolkit for Advanced Discriminative Modeling1 (Malouf, 2002).","{'title': '2 Base models: coreference classifier', 'number': '2'}"
We use a Gaussian prior with a variance of 1000 — no attempt was made to optimize this value.,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Training instances for the coreference classifier are constructed based on pairs of mentions of the form hi, ji, where j and i are the descriptions for an anaphor and one of its candidate antecedents, respectively.","{'title': '2 Base models: coreference classifier', 'number': '2'}"
Each such pair is assigned either a label COREF (i.e. a positive instance) or a label ¬COREF (i.e. a negative instance) depending on whether or not the two mentions corefer.,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
"In generating the training data, we followed the method of (Soon et al., 2001) creating for each anaphor: (i) a positive instance for the pair hi, ji where i is the closest antecedent for j, and (ii) a negative instance for each pair hi, ki where k intervenes between i and j.","{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Once trained, the classifier is used to create a set of coreferential links for each test document; these links in turn define a partition over the entire set of mentions.","{'title': '2 Base models: coreference classifier', 'number': '2'}"
In the system of Soon et. al.,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
"(2001) system, this is done by pairing each mention j with each preceding mention i.","{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Each test instance hi, ji thus formed is then evaluated by the classifier, which returns a probability representing the likelihood that these two mentions are coreferential.","{'title': '2 Base models: coreference classifier', 'number': '2'}"
Soon et. al.,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
"(2001) use “Closest-First” selection: that is, the process terminates as soon as an antecedent (i.e., a test instance with probability > .5) is found or the beginning of the text is reached.","{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Another option is to pick the antecedent with the best overall probability (Ng and Cardie, 2002b).","{'title': '2 Base models: coreference classifier', 'number': '2'}"
"Our features for the coreference classifier fall into three main categories: (i) features of the anaphor, (ii) features of antecedent mention, and (iii) relational features (i.e., features that describe properties which hold between the two mentions, e.g. distance).","{'title': '2 Base models: coreference classifier', 'number': '2'}"
This feature set is similar (though not equivalent) to that used by Ng and Cardie (2002a).,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
We omit details here for the sake of brevity — the ILP systems we employ here could be equally well applied to many different base classifiers using many different feature sets.,"{'title': '2 Base models: coreference classifier', 'number': '2'}"
"As mentioned in the introduction, coreference classifiers such as that presented in section 2 suffer from errors in which (a) they assign an antecedent to a non-anaphor mention or (b) they assign no antecedents to an anaphoric mention.","{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
Ng and Cardie (2002a) suggest overcoming such failings by augmenting their coreference classifier with an anaphoricity classifier which acts as a filter during model usage.,"{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
Only the mentions that are deemed anaphoric are considered for coreference resolution.,"{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
"Interestingly, they find a degredation in performance.","{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
"In particular, they obtain significant improvements in precision, but with larger losses in recall (especially for proper names and common nouns).","{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
"To counteract this, they add ad hoc constraints based on string matching and extended mention matching which force certain mentions to be resolved as anaphors regardless of the anaphoricity classifier.","{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
This allows them to improve overall f-scores by 1-3%.,"{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
Ng (2004) obtains f-score improvements of 2.8-4.5% by tuning the anaphoricity threshold on held-out data.,"{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
The task for the anaphoricity determination component is the following: one wants to decide for each mention i in a document whether i is anaphoric or not.,"{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
"That is, this task can be performed using a simple binary classifier with two outcomes: ANAPH and ANAPH.","{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
The classifier estimates the conditional probabilities P(ANAPH|i) and predicts ANAPH for i when P(ANAPH|i) > .5.,"{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
"We use the following model for our anaphoricity classifier: This model is trained in the same manner as the coreference classifier, also with a Gaussian prior with a variance of 1000.","{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
The features used for the anaphoricity classifier are quite simple.,"{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
"They include information regarding (1) the mention itself, such as the number of words and whether it is a pronoun, and (2) properties of the potential antecedent set, such as the number of preceding mentions and whether there is a previous mention with a matching string.","{'title': '3 Base models: anaphoricity classifier', 'number': '3'}"
"This section provides the performance of the pairwise coreference classifier, both when used alone (COREF-PAIRWISE) and when used in a cascade where the anaphoricity classifier acts as a filter on which mentions should be resolved (AC-CASCADE).","{'title': '4 Base model results', 'number': '4'}"
"In both systems, antecedents are determined in the manner described in section 2.","{'title': '4 Base model results', 'number': '4'}"
"To demonstrate the inherent limitations of cascading, we also give results for an oracle system, ORACLE-LINK, which assumes perfect linkage.","{'title': '4 Base model results', 'number': '4'}"
"That is, it always picks the correct antecedent for an anaphor.","{'title': '4 Base model results', 'number': '4'}"
Its only errors are due to being unable to resolve mentions which were marked as nonanaphoric (by the imperfect anaphoricity classifier) when in fact they were anaphoric.,"{'title': '4 Base model results', 'number': '4'}"
We evaluate these systems on the datasets from the ACE corpus (Phase 2).,"{'title': '4 Base model results', 'number': '4'}"
"This corpus is divided into three parts, each corresponding to a different genre: newspaper texts (NPAPER), newswire texts (NWIRE), and broadcasted news transcripts (BNEWS).","{'title': '4 Base model results', 'number': '4'}"
Each of these is split into a train part and a devtest part.,"{'title': '4 Base model results', 'number': '4'}"
"Progress during the development phase was determined by using crossvalidation on only the training set for the NPAPER (COREF-PAIRWISE), the anaphoricity-coreference cascade system (AC-CASCADE), and the oracle which performs perfect linkage (ORACLE-LINK).","{'title': '4 Base model results', 'number': '4'}"
The first two systems make strictly local pairwise coreference decisions. section.,"{'title': '4 Base model results', 'number': '4'}"
No human-annotated linguistic information is used in the input.,"{'title': '4 Base model results', 'number': '4'}"
"The corpus text was preprocessed with the OpenNLP Toolkit2 (i.e., a sentence detector, a tokenizer, a POS tagger, and a Named Entity Recognizer).","{'title': '4 Base model results', 'number': '4'}"
"In our experiments, we consider only the true ACE mentions.","{'title': '4 Base model results', 'number': '4'}"
This is because our focus is on evaluating pairwise local approaches versus the global ILP approach rather than on building a full coreference resolution system.,"{'title': '4 Base model results', 'number': '4'}"
It is worth noting that previous work tends to be vague in both these respects: details on mention filtering or providing performance figures for markable identification are rarely given.,"{'title': '4 Base model results', 'number': '4'}"
"Following common practice, results are given in terms of recall and precision according to the standard model-theoretic metric (Vilain et al., 1995).","{'title': '4 Base model results', 'number': '4'}"
This method operates by comparing the equivalence classes defined by the resolutions produced by the system with the gold standard classes: these are the two “models”.,"{'title': '4 Base model results', 'number': '4'}"
"Roughly, the scores are obtained by determining the minimal perturbations brought to one model in order to map it onto the other model.","{'title': '4 Base model results', 'number': '4'}"
"Recall is computed by trying to map the predicted chains onto the true chains, while precision is computed the other way around.","{'title': '4 Base model results', 'number': '4'}"
We test significant differences with paired t-tests (p < .05).,"{'title': '4 Base model results', 'number': '4'}"
The anaphoricity classifier has an average accuracy of 80.2% on the three ACE datasets (using a threshold of .5).,"{'title': '4 Base model results', 'number': '4'}"
This score is slightly lower than the scores reported by Ng and Cardie (2002a) for another data set (MUC).,"{'title': '4 Base model results', 'number': '4'}"
"Table 1 summarizes the results, in terms of recall (R), precision (P), and f-score (F) on the three ACE data sets.","{'title': '4 Base model results', 'number': '4'}"
"As can be seen, the AC-CASCADE system generally provides slightly better precision at the expense of recall than the COREF-PAIRWISE system, but the performance varies across the three datasets.","{'title': '4 Base model results', 'number': '4'}"
The source of this variance is likely due to the fact that we applied a uniform anaphoricity threshold of .5 across all datasets; Ng (2004) optimizes this threshold for each of the datasets: .3 for BNEWS and NWIRE and .35 for NPAPER.,"{'title': '4 Base model results', 'number': '4'}"
This variance reinforces our argument for determining anaphoricity and coreference jointly.,"{'title': '4 Base model results', 'number': '4'}"
The limitations of the cascade approach are also shown by the oracle results.,"{'title': '4 Base model results', 'number': '4'}"
"Even if we had a system that can pick the correct antecedents for all truly anaphoric mentions, it would have a maximum recall of roughly 70% for the different datasets.","{'title': '4 Base model results', 'number': '4'}"
The results in the previous section demonstrate the limitations of a cascading approach for determining anaphoricity and coreference with separate models.,"{'title': '5 Integer programming formulations', 'number': '5'}"
The other thing to note is that the results in general provide a lot of room for improvement — this is true for other state-of-the-art systems as well.,"{'title': '5 Integer programming formulations', 'number': '5'}"
The integer programming formulation we provide here has qualities which address both of these issues.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"In particular, we define two objective functions for coreference resolution to be optimized with ILP.","{'title': '5 Integer programming formulations', 'number': '5'}"
The first uses only information from the coreference classifier (COREF-ILP) and the second integrates both anaphoricity and coreference in a joint formulation (JOINT-ILP).,"{'title': '5 Integer programming formulations', 'number': '5'}"
"Our problem formulation and use of ILP are based on both (Roth and Yih, 2004) and (Barzilay and Lapata, 2006).","{'title': '5 Integer programming formulations', 'number': '5'}"
"For solving the ILP problem, we use lp solve, an open-source linear programming solver which implements the simplex and the Branch-and-Bound methods.3 In practice, each test document is processed to define a distinct ILP problem that is then submitted to the solver.","{'title': '5 Integer programming formulations', 'number': '5'}"
Barzilay and Lapata (2006) use ILP for the problem of aggregation in natural language generation: clustering sets of propositions together to create more concise texts.,"{'title': '5 Integer programming formulations', 'number': '5'}"
They cast it as a set partitioning problem.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"This is very much like coreference, where each partition corresponds to an entity in a discourse model.","{'title': '5 Integer programming formulations', 'number': '5'}"
COREF-ILP uses an objective function that is based on only the coreference classifier and the probabilities it produces.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"Given that the classifier produces probabilities pC = PC(COREF|i, j), the assignment cost of commiting to a coreference link is cC(i,j) = −log(pC).","{'title': '5 Integer programming formulations', 'number': '5'}"
"A complement assignment cost cC(i,j) = −log(1−pC) is associated with choosing not to establish a link.","{'title': '5 Integer programming formulations', 'number': '5'}"
"In what follows, M denotes the set of mentions in the document, and P the set of possible coreference links over these mentions (i.e., P = {hi, ji|hi, ji ∈ M × M and i < j}).","{'title': '5 Integer programming formulations', 'number': '5'}"
"Finally, we use indicator variables x(i,j) that are set to 1 if mentions i and j are coreferent, and 0 otherwise.","{'title': '5 Integer programming formulations', 'number': '5'}"
"The objective function takes the following form: This is essentially identical to Barzilay and Lapata’s objective function, except that we consider only pairs in which the i precedes the j (due to the structure of the problem).","{'title': '5 Integer programming formulations', 'number': '5'}"
"Also, we minimize rather than maximize due to the fact we transform the model probabilities with −log (like Roth and Yih (2004)).","{'title': '5 Integer programming formulations', 'number': '5'}"
This preliminary objective function merely guarantees that ILP will find a global assignment that maximally agrees with the decisions made by the coreference classifier.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"Concretely, this amounts to taking all (and only) those links for which the classifier returns a probability above .5.","{'title': '5 Integer programming formulations', 'number': '5'}"
This formulation does not yet take advantage of information from a classifier that specializes in anaphoricity; this is the subject of the next section.,"{'title': '5 Integer programming formulations', 'number': '5'}"
Roth and Yih (2004) use ILP to deal with the joint inference problem of named entity and relation identification.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"This requires labeling a set of named entities in a text with labels such as person and location, and identifying relations between them such as spouse of and work for.","{'title': '5 Integer programming formulations', 'number': '5'}"
"In theory, each of these tasks would likely benefit from utilizing the information produced by the other, but if done as a cascade will be subject to propogation of errors.","{'title': '5 Integer programming formulations', 'number': '5'}"
"Roth and Yih thus set this up as problem in which each task is performed separately; their output is used to assign costs associated with indicator variables in an objective function, which is then minimized subject to constraints that relate the two kinds of outputs.","{'title': '5 Integer programming formulations', 'number': '5'}"
"These constraints express qualities of what a global assignment of values for these tasks must respect, such as the fact that the arguments to the spouse of relation must be entities with person labels.","{'title': '5 Integer programming formulations', 'number': '5'}"
"Importantly, the ILP objective function encodes not only the best label produced by each classifier for each decision; it utilizes the probabilities (or scores) assigned to each label and attempts to find a global optimum (subject to the constraints).","{'title': '5 Integer programming formulations', 'number': '5'}"
The parallels to our anaphoricity/coreference scenario are straightforward.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"The anaphoricity problem is like the problem of identifying the type of entity (where the labels are now ANAPH and ¬ANAPH), and the coreference problem is like that of determining the relations between mentions (where the labels are now COREF or ¬COREF).","{'title': '5 Integer programming formulations', 'number': '5'}"
"Based on these parallels, the JOINT-ILP system brings the two decisions of anaphoricity and coreference together by including both in a single objective function and including constraints that ensure the consistency of a solution for both tasks.","{'title': '5 Integer programming formulations', 'number': '5'}"
"Let cAj and cAj be defined analogously to the coreference classifier costs for pA = PA(ANAPH|j), the probability the anaphoricity classifier assigns to a mention j being anaphoric.","{'title': '5 Integer programming formulations', 'number': '5'}"
"Also, we have indicator variables yj that are set to 1 if mention j is anaphoric and 0 otherwise.","{'title': '5 Integer programming formulations', 'number': '5'}"
"The objective function takes the following form: The structure of this objective function is very similar to Roth and Yih’s, except that we do not utilize constraint costs in the objective function itself.","{'title': '5 Integer programming formulations', 'number': '5'}"
Roth and Yih use these to make certain combinations impossible (like a location being an argument to a spouse of relation); we enforce such effects in the constraint equations instead.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"The joint objective function (5) does not constrain the assignment of the xhi,ji and yj variables to be consistent with one another.","{'title': '5 Integer programming formulations', 'number': '5'}"
"To enforce consistency, we add further constraints.","{'title': '5 Integer programming formulations', 'number': '5'}"
"In what follows, Mj is the set of all mentions preceding mention j in the document.","{'title': '5 Integer programming formulations', 'number': '5'}"
"Resolve only anaphors: if a pair of mentions hi, ji is coreferent (xhi,ji=1), then mention j must be anaphoric (yj=1).","{'title': '5 Integer programming formulations', 'number': '5'}"
These constraints thus directly relate the two tasks.,"{'title': '5 Integer programming formulations', 'number': '5'}"
"By formulating the problem this way, the decisions of the anaphoricity classifier are not taken on faith as they were with AC-CASCADE.","{'title': '5 Integer programming formulations', 'number': '5'}"
"Instead, we optimize over consideration of both possibilities in the objective function (relative to the probability output by the classifier) while ensuring that the final assignments respect the signifance of what it is to be anaphoric or non-anaphoric.","{'title': '5 Integer programming formulations', 'number': '5'}"
Table 2 summarizes the results for these different systems.,"{'title': '6 Joint Results', 'number': '6'}"
Both ILP systems are significantly better than the baseline system COREF-PAIRWISE.,"{'title': '6 Joint Results', 'number': '6'}"
"Despite having lower precision than COREF-PAIRWISE, the COREF-ILP system obtains very large gains in recall to end up with overall f-score gains of 4.3%, 4.2%, and 3.0% across BNEWS, NPAPER, and NWIRE, respectively.","{'title': '6 Joint Results', 'number': '6'}"
The fundamental reason for the increase in recall and drop in precision is that COREF-ILP can posit multiple antecedents for each mention.,"{'title': '6 Joint Results', 'number': '6'}"
"This is an extra degree of freedom that allows COREFILP to cast a wider net, with a consequent risk of capturing incorrect antecedents.","{'title': '6 Joint Results', 'number': '6'}"
Precision is not completely degraded because the optimization performed by ILP utilizes the pairwise probabilities of mention pairs as weights in the objective function to make its assignments.,"{'title': '6 Joint Results', 'number': '6'}"
"Thus, highly improbable links are still heavily penalized and are not chosen as coreferential.","{'title': '6 Joint Results', 'number': '6'}"
The JOINT-ILP system demonstrates the benefit ILP’s ability to support joint task formulations.,"{'title': '6 Joint Results', 'number': '6'}"
It produces significantly better f-scores by regaining some of the ground on precision lost by COREFILP.,"{'title': '6 Joint Results', 'number': '6'}"
The most likely source of the improved precision of JOINT-ILP is that weights corresponding to the anaphoricity probabilities and constraints (8) and (10) reduce the number of occurrences of nonanaphors being assigned antecedents.,"{'title': '6 Joint Results', 'number': '6'}"
There are also improvements in recall over COREF-ILP for NPAPER and NWIRE.,"{'title': '6 Joint Results', 'number': '6'}"
"A possible source of this difference is constraint (9), which ensures that mentions which are considered anaphoric must have at least one antecedent.","{'title': '6 Joint Results', 'number': '6'}"
"Compared to COREF-PAIRWISE, JOINT-ILP dramatically improves recall with relatively small losses in precision, providing overall f-score gains of 5.3%, 4.9%, and 3.7% on the three datasets.","{'title': '6 Joint Results', 'number': '6'}"
"As was just demonstrated, ILP provides a principled way to model dependencies between anaphoricity decisions and coreference decisions.","{'title': '7 Related Work', 'number': '7'}"
"In a similar manner, this framework could also be used to capture dependencies among coreference decisions themselves.","{'title': '7 Related Work', 'number': '7'}"
This option —which we will leave for future work— would make such an approach akin to yj ≥ Luo et al. (2004) use Bell trees to represent the search space of the coreference resolution problem (where each leaf is possible partition).,"{'title': '7 Related Work', 'number': '7'}"
The problem is thus recast as that of finding the “best” path through the tree.,"{'title': '7 Related Work', 'number': '7'}"
"Given the rapidly growing size of Bell trees, Luo et al. resort to a beam search algorithm and various pruning strategies, potentially resulting in picking a non-optimal solution.","{'title': '7 Related Work', 'number': '7'}"
"The results provided by Luo et al. are difficult to compare with ours, since they use a different evaluation metric.","{'title': '7 Related Work', 'number': '7'}"
"Another global approach to coreference is the application of Conditional Random Fields (CRFs) (McCallum and Wellner, 2004).","{'title': '7 Related Work', 'number': '7'}"
"Although both are global approaches, CRFs and ILP have important differences.","{'title': '7 Related Work', 'number': '7'}"
ILP uses separate local classifiers which are learned without knowledge of the output constraints and are then integrated into a larger inference task.,"{'title': '7 Related Work', 'number': '7'}"
CRFs estimate a global model that directly uses the constraints of the domain.,"{'title': '7 Related Work', 'number': '7'}"
This involves heavy computations which cause CRFs to generally be slow and inefficient (even using dynamic programming).,"{'title': '7 Related Work', 'number': '7'}"
"Again, the results presented in McCallum and Wellner (2004) are hard to compare with our own results.","{'title': '7 Related Work', 'number': '7'}"
"They only consider proper names, and they only tackled the task of identifying the correct antecedent only for mentions which have a true antecedent.","{'title': '7 Related Work', 'number': '7'}"
"A third global approach is offered by Ng (2005), who proposes a global reranking over partitions generated by different coreference systems.","{'title': '7 Related Work', 'number': '7'}"
"This approach proceeds by first generating 54 candidate partitions, which are each generated by a different system.","{'title': '7 Related Work', 'number': '7'}"
"These different coreference systems are obtained as combinations over three different learners (C4.5, Ripper, and Maxent), three sampling methods, two feature sets (Soon et al., 2001; Ng and Cardie, 2002b), and three clustering algorithms (Best-First, Closest-First, and aggressivemerge).","{'title': '7 Related Work', 'number': '7'}"
"The features used by the reranker are of two types: (i) partition-based features which are here simple functions of the local features, and (ii) method-based features which simply identify the coreference system used for generating the given partition.","{'title': '7 Related Work', 'number': '7'}"
"Although this approach leads to significant gains on the both the MUC and the ACE datasets, it has some weaknesses.","{'title': '7 Related Work', 'number': '7'}"
"Most importantly, the different systems employed for generating the different partitions are all instances of the local classification approach, and they all use very similar features.","{'title': '7 Related Work', 'number': '7'}"
This renders them likely to make the same types of errors.,"{'title': '7 Related Work', 'number': '7'}"
"The ILP approach could in fact be integrated with these other approaches, potentially realizing the advantages of multiple global systems, with ILP conducting their interactions.","{'title': '7 Related Work', 'number': '7'}"
We have provided two ILP formulations for resolving coreference and demonstrated their superiority to a pairwise classifier that makes its coreference assignments greedily.,"{'title': '8 Conclusions', 'number': '8'}"
"In particular, we have also shown that ILP provides a natural means to express the use of both anaphoricity classification and coreference classification in a single system, and that doing so provides even further performance improvements, specifically f-score improvements of 5.3%, 4.9%, and 3.7% over the base coreference classifier on the ACE datasets.","{'title': '8 Conclusions', 'number': '8'}"
"With ILP, it is not necessary to carefully control the anaphoricity threshold.","{'title': '8 Conclusions', 'number': '8'}"
This is in stark contrast to systems which use the anaphoricity classifier as a filter for the coreference classifier in a cascade setup.,"{'title': '8 Conclusions', 'number': '8'}"
The ILP objective function incorporates the probabilities produced by both classifiers as weights on variables that indicate the ILP assignments for those tasks.,"{'title': '8 Conclusions', 'number': '8'}"
The indicator variables associated with those assignments allow several constraints between the tasks to be straightforwardly stated to ensure consistency to the assignments.,"{'title': '8 Conclusions', 'number': '8'}"
We thus achieve large improvements with a simple formulation and no fuss.,"{'title': '8 Conclusions', 'number': '8'}"
ILP solutions are also obtained very quickly for the objective functions and constraints we use.,"{'title': '8 Conclusions', 'number': '8'}"
"In future work, we will explore the use of global constraints, similar to those used by (Barzilay and Lapata, 2006) to improve both precision and recall.","{'title': '8 Conclusions', 'number': '8'}"
"For example, we expect transitivity constraints over coreference pairs, as well as constraints on the entire partition (e.g., the number of entities in the document), to help considerably.","{'title': '8 Conclusions', 'number': '8'}"
"We will also consider linguistic constraints (e.g., restrictions on pronouns) in order to improve precision.","{'title': '8 Conclusions', 'number': '8'}"
"We would like to thank Ray Mooney, Rohit Kate, and the three anonymous reviewers for their comments.","{'title': 'Acknowledgments', 'number': '9'}"
This work was supported by NSF grant IIS0535154.,"{'title': 'Acknowledgments', 'number': '9'}"
