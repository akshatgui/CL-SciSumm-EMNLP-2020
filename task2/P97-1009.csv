col1,col2
Most previous corpus-based algorithms disambiguate a word with a classifier trained from previous usages of the same word.,{}
Separate classifiers have to be trained for different words.,{}
We present an algorithm that uses the same knowledge sources to disambiguate different words.,{}
The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts.,{}
"Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context.","{'title': '1 Introduction', 'number': '1'}"
"WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution.","{'title': '1 Introduction', 'number': '1'}"
"In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus.","{'title': '1 Introduction', 'number': '1'}"
"Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples.","{'title': '1 Introduction', 'number': '1'}"
Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts.,"{'title': '1 Introduction', 'number': '1'}"
A basic intuition that underlies those algorithms is the following: (1) Two occurrences of the same word have identical meanings if they have similar local contexts.,"{'title': '1 Introduction', 'number': '1'}"
"In other words, most previous corpus-based WSD algorithms learn to disambiguate a polysemous word from previous usages of the same word.","{'title': '1 Introduction', 'number': '1'}"
This has several undesirable consequences.,"{'title': '1 Introduction', 'number': '1'}"
"Firstly, a word must occur thousands of times before a good classifier can be learned.","{'title': '1 Introduction', 'number': '1'}"
"In Yarowsky's experiment (Yarowsky, 1995), an average of 3936 examples were used to disambiguate between two senses.","{'title': '1 Introduction', 'number': '1'}"
"In Ng and Lee's experiment, 192,800 occurrences of 191 words were used as training examples.","{'title': '1 Introduction', 'number': '1'}"
"There are thousands of polysemous words, e.g., there are 11,562 polysemous nouns in WordNet.","{'title': '1 Introduction', 'number': '1'}"
"For every polysemous word to occur thousands of times each, the corpus must contain billions of words.","{'title': '1 Introduction', 'number': '1'}"
"Secondly, learning to disambiguate a word from the previous usages of the same word means that whatever was learned for one word is not used on other words, which obviously missed generality in natural languages.","{'title': '1 Introduction', 'number': '1'}"
"Thirdly, these algorithms cannot deal with words for which classifiers have not been learned.","{'title': '1 Introduction', 'number': '1'}"
"In this paper, we present a WSD algorithm that relies on a different intuition: (2) Two different words are likely to have similar meanings if they occur in identical local contexts.","{'title': '1 Introduction', 'number': '1'}"
"Consider the sentence: (3) The new facility will employ 500 of the existing 600 employees The word &quot;facility&quot; has 5 possible meanings in WordNet 1.5 (Miller, 1990): (a) installation, (b) proficiency/technique, (c) adeptness, (d) readiness, (e) toilet/bathroom.","{'title': '1 Introduction', 'number': '1'}"
"To disambiguate the word, we consider other words that appeared in an identical local context as &quot;facility&quot; in (3).","{'title': '1 Introduction', 'number': '1'}"
Table 1 is a list of words that have also been used as the subject of &quot;employ&quot; in a 25-million-word Wall Street Journal corpus.,"{'title': '1 Introduction', 'number': '1'}"
The &quot;freq&quot; column are the number of times these words were used as the subject of &quot;employ&quot;.,"{'title': '1 Introduction', 'number': '1'}"
"ORG includes all proper names recognized as organizations The logA column are their likelihood ratios (Dunning, 1993).","{'title': '1 Introduction', 'number': '1'}"
The meaning of &quot;facility&quot; in (3) can be determined by choosing one of its 5 senses that is most similar' to the meanings of words in Table 1.,"{'title': '1 Introduction', 'number': '1'}"
"This way, a polysemous word is disambiguated with past usages of other words.","{'title': '1 Introduction', 'number': '1'}"
Whether or not it appears in the corpus is irrelevant.,"{'title': '1 Introduction', 'number': '1'}"
"Our approach offers several advantages: The required resources of the algorithm include the following: (a) an untagged text corpus, (b) a broad-coverage parser, (c) a concept hierarchy, such as the WordNet (Miller, 1990) or Roget's Thesaurus, and (d) a similarity measure between concepts.","{'title': '1 Introduction', 'number': '1'}"
"In the next section, we introduce our definition of local contexts and the database of local contexts.","{'title': '1 Introduction', 'number': '1'}"
A description of the disambiguation algorithm is presented in Section 3.,"{'title': '1 Introduction', 'number': '1'}"
Section 4 discusses the evaluation results.,"{'title': '1 Introduction', 'number': '1'}"
"Psychological experiments show that humans are able to resolve word sense ambiguities given a narrow window of surrounding words (Choueka and Lusignan, 1985).","{'title': '2 Local Context', 'number': '2'}"
Most WSD algorithms take as input ito be defined in Section 3.1 a polysemous word and its local context.,"{'title': '2 Local Context', 'number': '2'}"
Different systems have different definitions of local contexts.,"{'title': '2 Local Context', 'number': '2'}"
"In (Leacock, Towwell, and Voorhees, 1996), the local context of a word is an unordered set of words in the sentence containing the word and the preceding sentence.","{'title': '2 Local Context', 'number': '2'}"
In (Ng and Lee.,"{'title': '2 Local Context', 'number': '2'}"
"1996), a local context of a word consists of an ordered sequence of 6 surrounding part-of-speech tags, its morphological features, and a set of collocations.","{'title': '2 Local Context', 'number': '2'}"
"In our approach, a local context of a word is defined in terms of the syntactic dependencies between the word and other words in the same sentence.","{'title': '2 Local Context', 'number': '2'}"
"A dependency relationship (Hudson, 1984; Mel'euk, 1987) is an asymmetric binary relationship between a word called head (or governor, parent), and another word called modifier (or dependent, daughter).","{'title': '2 Local Context', 'number': '2'}"
Dependency grammars represent sentence structures as a set of dependency relationships.,"{'title': '2 Local Context', 'number': '2'}"
Normally the dependency relationships form a tree that connects all the words in a sentence.,"{'title': '2 Local Context', 'number': '2'}"
An example dependency structure is shown in (4).,"{'title': '2 Local Context', 'number': '2'}"
"The local context of a word W is a triple that corresponds to a dependency relationship in which W is the head or the modifier: (type word position) where type is the type of the dependency relationship, such as subj (subject), adjn (adjunct), comp I (first complement), etc.","{'title': '2 Local Context', 'number': '2'}"
; word is the word related to W via the dependency relationship; and posit ion can either be head or mod.,"{'title': '2 Local Context', 'number': '2'}"
The position indicates whether word is the head or the modifier in dependency relation.,"{'title': '2 Local Context', 'number': '2'}"
"Since a word may be involved in several dependency relationships, each occurrence of a word may have multiple local contexts.","{'title': '2 Local Context', 'number': '2'}"
"The local contexts of the two nouns &quot;boy&quot; and &quot;dog&quot; in (4) are as follows (the dependency relations between nouns and their determiners are ignored): boy (subj chase head) dog (adjn brown mod) (compl chase head) Using a broad coverage parser to parse a corpus, we construct a Local Context Database.","{'title': '2 Local Context', 'number': '2'}"
An entry in the database is a pair: where lc is a local context and C(lc) is a set of (word frequency likelihood)-triples.,"{'title': '2 Local Context', 'number': '2'}"
Each triple specifies how often word occurred in lc and the likelihood ratio of lc and word.,"{'title': '2 Local Context', 'number': '2'}"
"The likelihood ratio is obtained by treating word and /c as a bigram and computed with the formula in (Dunning, 1993).","{'title': '2 Local Context', 'number': '2'}"
The database entry corresponding to Table 1 is as follows:,"{'title': '2 Local Context', 'number': '2'}"
The polysemous words in the input text are disambiguated in the following steps: Step A. Parse the input text and extract local contexts of each word.,"{'title': '3 The Approach', 'number': '3'}"
Let LC. denote the set of local contexts of all occurrences of w in the input text.,"{'title': '3 The Approach', 'number': '3'}"
Step B.,"{'title': '3 The Approach', 'number': '3'}"
Search the local context database and find words that appeared in an identical local context as w. They are called selectors of w: Step C. Select a sense s of w that maximizes the similarity between w and Selectors.,"{'title': '3 The Approach', 'number': '3'}"
Step D. The sense s is assigned to all occurrences of w in the input text.,"{'title': '3 The Approach', 'number': '3'}"
"This implements the &quot;one sense per discourse&quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992).","{'title': '3 The Approach', 'number': '3'}"
Step C. needs further explanation.,"{'title': '3 The Approach', 'number': '3'}"
"In the next subsection, we define the similarity between two word senses (or concepts).","{'title': '3 The Approach', 'number': '3'}"
We then explain how the similarity between a word and its selectors is maximized.,"{'title': '3 The Approach', 'number': '3'}"
"There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994).","{'title': '3 The Approach', 'number': '3'}"
All of those similarity measures are defined directly by a formula.,"{'title': '3 The Approach', 'number': '3'}"
"We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: where cornmon(A, B) is a proposition that states the commonalities between A and B; /(s) is the amount of information contained in the proposition s. Assumption 2: The differences between A and B is measured by where describe(A, B) is a proposition that describes what A and B are.","{'title': '3 The Approach', 'number': '3'}"
"Assumption 3: The similarity between A and B, sim(A, B), is a function of their commonality and differences.","{'title': '3 The Approach', 'number': '3'}"
"That is, sim(A, B) = f (I (common(A, B)), I (describe(A, B))) The domain of f (x, y) is {(x , y)ix > 0, y > 0, y > x}.","{'title': '3 The Approach', 'number': '3'}"
Assumption 4: Similarity is independent of the unit used in the information measure.,"{'title': '3 The Approach', 'number': '3'}"
"According to Information Theory (Cover and Thomas, 1991), /(s) = —log bP(s), where P(s) is the probability of s and b is the unit.","{'title': '3 The Approach', 'number': '3'}"
"When b = 2, /(s) is the number of bits needed to encode s. Since log bx =12412 , Assumption 4 means that the function f must satisfy the following condition: Vc > 0, f(x, y) f (cx, Assumption 5: Similarity is additive with respect to commonality.","{'title': '3 The Approach', 'number': '3'}"
"If cornman(A, B) consists of two independent parts, then the sim(A, B) is the sum of the similarities computed when each part of the commonality is considered.","{'title': '3 The Approach', 'number': '3'}"
"In other words: f (xi + x2, y) = f(xi,y)+ f(x2,y).","{'title': '3 The Approach', 'number': '3'}"
"A corollary of Assumption 5 is that Vy, f(0, y) = f (x + 0, y) — f (x,y) = 0, which means that when there is no commonality between A and B, their similarity is 0, no matter how different they are.","{'title': '3 The Approach', 'number': '3'}"
"For example, the similarity between &quot;depth-first search&quot; and &quot;leather sofa&quot; is neither higher nor lower than the similarity between &quot;rectangle&quot; and &quot;interest rate&quot;.","{'title': '3 The Approach', 'number': '3'}"
Assumption 6: The similarity between a pair of identical objects is 1.,"{'title': '3 The Approach', 'number': '3'}"
"When A and B are identical. knowning their commonalities means knowing what they are, i.e., I (comman(A, B)) = I (describe(A.","{'title': '3 The Approach', 'number': '3'}"
B)).,"{'title': '3 The Approach', 'number': '3'}"
"Therefore, the function f must have the following property: Vx, f (x, x) = 1.","{'title': '3 The Approach', 'number': '3'}"
Assumption 7: The function f (x. y) is continuous.,"{'title': '3 The Approach', 'number': '3'}"
"Similarity Theorem: The similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are: Proof: To prove the theorem. we need to show f(x,y) = s. Since f(x,y) = f(s.1) (due to Assumption 4), we only need to show that when LI, is a rational number, f (x,y) = .","{'title': '3 The Approach', 'number': '3'}"
"The result can be generalized to all real numbers because f is continuous and for any real number, there are rational numbers that are infinitely close to it.","{'title': '3 The Approach', 'number': '3'}"
Suppose m and n are positive integers.,"{'title': '3 The Approach', 'number': '3'}"
(due to Assumption 5).,"{'title': '3 The Approach', 'number': '3'}"
"Thus. f (x, y) = ;-; f (nx, y).","{'title': '3 The Approach', 'number': '3'}"
Substituting fi for x in this equation: Q.E.D.,"{'title': '3 The Approach', 'number': '3'}"
For example.,"{'title': '3 The Approach', 'number': '3'}"
Figure 1 is a fragment of the WordNet.,"{'title': '3 The Approach', 'number': '3'}"
The nodes are concepts (or synsets as they are called in the WordNet).,"{'title': '3 The Approach', 'number': '3'}"
The links represent IS-A relationships.,"{'title': '3 The Approach', 'number': '3'}"
"The number attached to a node C is the probability P(C) that a randomly selected noun refers to an instance of C. The probabilities are estimated by the frequency of concepts in SemCor (Miller et al., 1994), a sense-tagged subset of the Brown corpus.","{'title': '3 The Approach', 'number': '3'}"
"If x is a Hill and y is a Coast, the commonality between x and p is that &quot;x is a GeoForm and y is a GeoForm&quot;.","{'title': '3 The Approach', 'number': '3'}"
The information contained in this statement is —2 x logP(GeoF arm).,"{'title': '3 The Approach', 'number': '3'}"
The similarity between the concepts Hill and Coast is: where p(ni co is the probability of that an object belongs to all the maximally specific super classes (Cts) of both C and C'.,"{'title': '3 The Approach', 'number': '3'}"
We now provide the details of Step C in our algorithm.,"{'title': '3 The Approach', 'number': '3'}"
"The input to this step consists of a polysemous word V110 and its selectors {WI, W2 WO.","{'title': '3 The Approach', 'number': '3'}"
"The word Wi has ni senses: {sii, • • • , sin.","{'title': '3 The Approach', 'number': '3'}"
}* Step C.1: Construct a similarity matrix (8).,"{'title': '3 The Approach', 'number': '3'}"
The rows and columns represent word senses.,"{'title': '3 The Approach', 'number': '3'}"
The matrix is divided into (k 1) x (k + 1) blocks.,"{'title': '3 The Approach', 'number': '3'}"
The blocks on the diagonal are all Os.,"{'title': '3 The Approach', 'number': '3'}"
The elements in block Sii are the similarity measures between the senses of Wi and the senses of It:).,"{'title': '3 The Approach', 'number': '3'}"
Similarity measures lower than a threshold 0 are considered to be noise and are ignored.,"{'title': '3 The Approach', 'number': '3'}"
"In our experiments, 9 = 0.2 was used.","{'title': '3 The Approach', 'number': '3'}"
Step C.5: Modify the similarity matrix to remove the similarity values between other senses of W.i„ and senses of other words.,"{'title': '3 The Approach', 'number': '3'}"
"For all 1, j, m, such that 1 E [1,ni,..] and 1 0 Imax and j imax and m E [1, nil' Let's consider again the word &quot;facility&quot; in (3).","{'title': '3 The Approach', 'number': '3'}"
It has two local contexts: subject of &quot;employ&quot; (subj employ head) and modifiee of &quot;new&quot; (adjn new mod).,"{'title': '3 The Approach', 'number': '3'}"
Table 1 lists words that appeared in the first local context.,"{'title': '3 The Approach', 'number': '3'}"
Table 2 lists words that appeared in the second local context.,"{'title': '3 The Approach', 'number': '3'}"
Only words with top-20 likelihood ratio were used in our experiments.,"{'title': '3 The Approach', 'number': '3'}"
The two groups of words are merged and used as the selectors of &quot;facility&quot;.,"{'title': '3 The Approach', 'number': '3'}"
The words &quot;facility&quot; has 5 senses in the WordNet.,"{'title': '3 The Approach', 'number': '3'}"
Senses 1 and 5 are subclasses of artifact.,"{'title': '3 The Approach', 'number': '3'}"
Senses 2 and 3 are kinds of state.,"{'title': '3 The Approach', 'number': '3'}"
Sense 4 is a kind of abstraction.,"{'title': '3 The Approach', 'number': '3'}"
"Many of the selectors in Tables 1 and Table 2 have artifact senses, such as &quot;post&quot;, &quot;product&quot;, &quot;system&quot;, &quot;unit&quot;, &quot;memory device&quot;, &quot;machine&quot;, &quot;plant&quot;, &quot;model&quot;, &quot;program&quot;, etc.","{'title': '3 The Approach', 'number': '3'}"
"Therefore, Senses 1 and 5 of &quot;facility&quot; received much more support, 5.37 and 2.42 respectively, than other senses.","{'title': '3 The Approach', 'number': '3'}"
Sense 1 is selected.,"{'title': '3 The Approach', 'number': '3'}"
"Consider another example that involves an unknown proper name: We treat unknown proper nouns as a polysemous word which could refer to a person, an organization, or a location.","{'title': '3 The Approach', 'number': '3'}"
"Since &quot;DreamLand&quot; is the subject of &quot;employed&quot;, its meaning is determined by maximizing the similarity between one of {person, organization, locaton} and the words in Table 1.","{'title': '3 The Approach', 'number': '3'}"
"Since Table 1 contains many &quot;organization&quot; words, the support for the &quot;organization&quot; sense is much higher than the others.","{'title': '3 The Approach', 'number': '3'}"
"We used a subset of the SemCor (Miller et al., 1994) to evaluate our algorithm.","{'title': '4 Evaluation', 'number': '4'}"
"General-purpose lexical resources, such as WordNet, Longman Dictionary of Contemporary English (LDOCE), and Roget's Thesaurus, strive to achieve completeness.","{'title': '4 Evaluation', 'number': '4'}"
They often make subtle distinctions between word senses.,"{'title': '4 Evaluation', 'number': '4'}"
"As a result, when the WSD task is defined as choosing a sense out of a list of senses in a general-purpose lexical resource, even humans may frequently disagree with one another on what the correct sense should be.","{'title': '4 Evaluation', 'number': '4'}"
The subtle distinctions between different word senses are often unnecessary.,"{'title': '4 Evaluation', 'number': '4'}"
"Therefore, we relaxed the correctness criterion.","{'title': '4 Evaluation', 'number': '4'}"
A selected sense sanswer is correct if it is &quot;similar enough&quot; to the sense tag S key in SemCor.,"{'title': '4 Evaluation', 'number': '4'}"
We experimented with three interpretations of &quot;similar enough&quot;.,"{'title': '4 Evaluation', 'number': '4'}"
"The strictest interpretation is SiM(Sanswer, skey)=1, which is true only when sanswer=skey.","{'title': '4 Evaluation', 'number': '4'}"
"The most relaxed interpretation is SiM(Sanewer, S key) >0, which is true if sanswer and skey are the descendents of the same top-level concepts in WordNet (e.g., entity, group, location, etc.).","{'title': '4 Evaluation', 'number': '4'}"
"A compromise between these two is SiM(Sanswer, Skey) > 0.27, where 0.27 is the average similarity of 50,000 randomly generated pairs (w, w') in which w and w' belong to the same Roget's category.","{'title': '4 Evaluation', 'number': '4'}"
"We use three words &quot;duty&quot;, &quot;interest&quot; and &quot;line&quot; as examples to provide a rough idea about what sim(sanswer, skey) > 0.27 means.","{'title': '4 Evaluation', 'number': '4'}"
The word &quot;duty&quot; has three senses in WordNet 1.5.,"{'title': '4 Evaluation', 'number': '4'}"
"The similarity between the three senses are all below 0.27, although the similarity between Senses 1 (responsibility) and 2 (assignment, chore) is very close (0.26) to the threshold.","{'title': '4 Evaluation', 'number': '4'}"
The word &quot;interest&quot; has 8 senses.,"{'title': '4 Evaluation', 'number': '4'}"
"Senses 1 (sake, benefit) and 7 (interestingness) are merged.2 Senses 3 (fixed charge for borrowing money), 4 (a right or legal share of something), and 5 (financial interest in something) are merged.","{'title': '4 Evaluation', 'number': '4'}"
The word &quot;interest&quot; is reduced to a 5-way ambiguous word.,"{'title': '4 Evaluation', 'number': '4'}"
"The other three senses are 2 (curiosity), 6 (interest group) and 8 (pastime, hobby).","{'title': '4 Evaluation', 'number': '4'}"
The word &quot;line&quot; has 27 senses.,"{'title': '4 Evaluation', 'number': '4'}"
The similarity threshold 0.27 reduces the number of senses to 14.,"{'title': '4 Evaluation', 'number': '4'}"
The reduced senses are where each group is a reduced sense and the numbers are original WordNet sense numbers.,"{'title': '4 Evaluation', 'number': '4'}"
We used a 25-million-word Wall Street Journal corpus (part of LDC/DCI3 CDROM) to construct the local context database.,"{'title': '4.2 Results', 'number': '5'}"
The text was parsed in 126 hours on a SPARC-Ultra 1/140 with 96MB of memory.,"{'title': '4.2 Results', 'number': '5'}"
"We then extracted from the parse trees 8,665,362 dependency relationships in which the head or the modifier is a noun.","{'title': '4.2 Results', 'number': '5'}"
"We then filtered out (lc, word) pairs with a likelihood ratio lower than 5 (an arbitrary threshold).","{'title': '4.2 Results', 'number': '5'}"
"The resulting database contains 354,670 local contexts with a total of 1,067,451 words in them (Table 1 is counted as one local context with 20 words in it).","{'title': '4.2 Results', 'number': '5'}"
"Since the local context database is constructed from WSJ corpus which are mostly business news, we only used the &quot;press reportage&quot; part of SemCor which consists of 7 files with about 2000 words each.","{'title': '4.2 Results', 'number': '5'}"
"Furthermore, we only applied our algorithm to nouns.","{'title': '4.2 Results', 'number': '5'}"
"Table 3 shows the results on 2,832 polysemous nouns in SemCor.","{'title': '4.2 Results', 'number': '5'}"
"This number also includes proper nouns that do not contain simple markers (e.g., Mr., Inc.) to indicate its category.","{'title': '4.2 Results', 'number': '5'}"
"Such a proper noun is treated as a 3-way ambiguous word: person, organization, or location.","{'title': '4.2 Results', 'number': '5'}"
We also showed as a baseline the performance of the simple strategy of always choosing the first sense of a word in the WordNet.,"{'title': '4.2 Results', 'number': '5'}"
"Since the WordNet senses are ordered according to their frequency in SemCor, choosing the first sense is roughly the same as choosing the sense with highest prior probability, except that we are not using all the files in SemCor.","{'title': '4.2 Results', 'number': '5'}"
It can be seen from Table 3 that our algorithm performed slightly worse than the baseline when the strictest correctness criterion is used.,"{'title': '4.2 Results', 'number': '5'}"
"However, when the condition is relaxed, its performance gain is much lager than the baseline.","{'title': '4.2 Results', 'number': '5'}"
"This means that when the algorithm makes mistakes, the mistakes tend to be close to the correct answer.","{'title': '4.2 Results', 'number': '5'}"
"The Step C in Section 3.2 is similar to Resnik's noun group disambiguation (Resnik, 1995a), although he did not address the question of the creation of noun groups.","{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
"The earlier work on WSD that is most similar to ours is (Li, Szpakowicz, and Matwin, 1995).","{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
They proposed a set of heuristic rules that are based on the idea that objects of the same or similar verbs are similar.,"{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
Our algorithm treats all local contexts equally in its decision-making.,"{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
"However, some local contexts hardly provide any constraint on the meaning of a word.","{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
"For example, the object of &quot;get&quot; can practically be anything.","{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
This type of contexts should be filtered out or discounted in decision-making.,"{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
Our assumption that similar words appear in identical context does not always hold.,"{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
"For example, where PER refers to proper names recognized as persons.","{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
None of these is similar to the &quot;body part&quot; meaning of &quot;heart&quot;.,"{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
"In fact, &quot;heart&quot; is the only body part that beats.","{'title': '5 Discussion 5.1 Related Work', 'number': '6'}"
We have presented a new algorithm for word sense disambiguation.,"{'title': '6 Conclusion', 'number': '7'}"
"Unlike most previous corpusbased WSD algorithm where separate classifiers are trained for different words, we use the same local context database and a concept hierarchy as the knowledge sources for disambiguating all words.","{'title': '6 Conclusion', 'number': '7'}"
This allows our algorithm to deal with infrequent words or unknown proper nouns.,"{'title': '6 Conclusion', 'number': '7'}"
Unnecessarily subtle distinction between word senses is a well-known problem for evaluating WSD algorithms with general-purpose lexical resources.,"{'title': '6 Conclusion', 'number': '7'}"
Our use of similarity measure to relax the correctness criterion provides a possible solution to this problem.,"{'title': '6 Conclusion', 'number': '7'}"
