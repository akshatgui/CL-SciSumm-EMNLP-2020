col1,col2
"This paper shows how finite approximations of long distance dependency (LDD) resolution can be obtained automatically for wide-coverage, robust, probabilistic Lexical-Functional Grammar (LFG) resources acquired from treebanks.",{}
"We extract LFG subcategorisation frames and paths linking LDDreentrancies from f-structures generated automati cally for the Penn-II treebank trees and use them in an LDD resolution algorithm to parse new text.Unlike (Collins, 1999; Johnson, 2002), in our ap proach resolution of LDDs is done at f-structure (attribute-value structure representations of basicpredicate-argument or dependency structure) with out empty productions, traces and coindexation in CFG parse trees.",{}
"Currently our best automaticallyinduced grammars achieve 80.97% f-score for f structures parsing section 23 of the WSJ part of the Penn-II treebank and evaluating against the DCU1051 and 80.24% against the PARC 700 Depen dency Bank (King et al, 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al, 2004).",{}
"The determination of syntactic structure is an important step in natural language processing as syntactic structure strongly determines semantic interpretation in the form of predicate-argument struc ture, dependency relations or logical form.","{'title': 'Introduction', 'number': '1'}"
"For a substantial number of linguistic phenomena such as topicalisation, wh-movement in relative clausesand interrogative sentences, however, there is an important difference between the location of the (surface) realisation of linguistic material and the location where this material should be interpreted semantically.","{'title': 'Introduction', 'number': '1'}"
"Resolution of such long-distance dependencies (LDDs) is therefore crucial in the determination of accurate predicate-argument struc1Manually constructed f-structures for 105 randomly se lected trees from Section 23 of the WSJ section of the Penn-II Treebankture, deep dependency relations and the construction of proper meaning representations such as log ical forms (Johnson, 2002).","{'title': 'Introduction', 'number': '1'}"
"Modern unification/constraint-based grammarssuch as LFG or HPSG capture deep linguistic information including LDDs, predicate-argument structure, or logical form.","{'title': 'Introduction', 'number': '1'}"
"Manually scaling rich uni fication grammars to naturally occurring free text, however, is extremely time-consuming, expensiveand requires considerable linguistic and computa tional expertise.","{'title': 'Introduction', 'number': '1'}"
"Few hand-crafted, deep unification grammars have in fact achieved the coverage and robustness required to parse a corpus of say the size and complexity of the Penn treebank: (Riezler et al., 2002) show how a deep, carefully hand-craftedLFG is successfully scaled to parse the Penn-II treebank (Marcus et al, 1994) with discriminative (log linear) parameter estimation techniques.The last 20 years have seen continuously increas ing efforts in the construction of parse-annotated corpora.","{'title': 'Introduction', 'number': '1'}"
"Substantial treebanks2 are now available for many languages (including English, Japanese, Chinese, German, French, Czech, Turkish), others are currently under construction (Arabic, Bulgarian) or near completion (Spanish, Catalan).","{'title': 'Introduction', 'number': '1'}"
"Treebankshave been enormously influential in the develop ment of robust, state-of-the-art parsing technology:grammars (or grammatical information) automat ically extracted from treebank resources providethe backbone of many state-of-the-art probabilis tic parsing approaches (Charniak, 1996; Collins, 1999; Charniak, 1999; Hockenmaier, 2003; Kleinand Manning, 2003).","{'title': 'Introduction', 'number': '1'}"
"Such approaches are attractive as they achieve robustness, coverage and performance while incurring very low grammar devel opment cost.","{'title': 'Introduction', 'number': '1'}"
"However, with few notable exceptions(e.g. Collins?","{'title': 'Introduction', 'number': '1'}"
"Model 3, (Johnson, 2002), (Hocken maier, 2003) ), treebank-based probabilistic parsersreturn fairly simple ?surfacey?","{'title': 'Introduction', 'number': '1'}"
"CFG trees, with out deep syntactic or semantic information.","{'title': 'Introduction', 'number': '1'}"
Thegrammars used by such systems are sometimes re 2Or dependency banks.ferred to as ?half?,"{'title': 'Introduction', 'number': '1'}"
(or ?shallow?),"{'title': 'Introduction', 'number': '1'}"
"grammars (Johnson, 2002), i.e. they do not resolve LDDs but interpret linguistic material purely locally where it oc curs in the tree.","{'title': 'Introduction', 'number': '1'}"
"Recently (Cahill et al, 2002) showed how wide-coverage, probabilistic unification grammarresources can be acquired automatically from fstructure-annotated treebanks.","{'title': 'Introduction', 'number': '1'}"
Many second gen eration treebanks provide a certain amount of deep syntactic or dependency information (e.g. in the form of Penn-II functional tags and traces) supporting the computation of representations ofdeep linguistic information.,"{'title': 'Introduction', 'number': '1'}"
"Exploiting this in formation (Cahill et al, 2002) implement an automatic LFG f-structure annotation algorithmthat associates nodes in treebank trees with f structure annotations in the form of attribute-valuestructure equations representing abstract predicate argument structure/dependency relations.","{'title': 'Introduction', 'number': '1'}"
"From the f-structure annotated treebank they automatically extract wide-coverage, robust, PCFG-based LFG approximations that parse new text into trees and f-structure representations.","{'title': 'Introduction', 'number': '1'}"
"The LFG approximations of (Cahill et al, 2002), however, are only ?half?","{'title': 'Introduction', 'number': '1'}"
"grammars, i.e. like most of their probabilistic CFG cousins (Charniak, 1996; Johnson, 1999; Klein and Manning, 2003) they do not resolve LDDs but interpret linguistic material purely locally where it occurs in the tree.In this paper we show how finite approxima tions of long distance dependency resolution can be obtained automatically for wide-coverage, robust, probabilistic LFG resources automatically acquired from treebanks.","{'title': 'Introduction', 'number': '1'}"
We extract LFG subcategorisation frames and paths linking LDD reentrancies fromf-structures generated automatically for the PennII treebank trees and use them in an LDD resolu tion algorithm to parse new text.,"{'title': 'Introduction', 'number': '1'}"
"Unlike (Collins, 1999; Johnson, 2002), in our approach LDDs are resolved on the level of f-structure representation,rather than in terms of empty productions and coindexation on parse trees.","{'title': 'Introduction', 'number': '1'}"
"Currently we achieve f structure/dependency f-scores of 80.24 and 80.97for parsing section 23 of the WSJ part of the Penn II treebank, evaluating against the PARC 700 and DCU 105 respectively.","{'title': 'Introduction', 'number': '1'}"
The paper is structured as follows: we give a brief introduction to LFG.,"{'title': 'Introduction', 'number': '1'}"
"We outline the automatic f-structure annotation algorithm, PCFG-based LFG grammar approximations and parsing architecturesof (Cahill et al, 2002).","{'title': 'Introduction', 'number': '1'}"
We present our subcategorisation frame extraction and introduce the treebank based acquisition of finite approximations of LFG functional uncertainty equations in terms of LDD paths.,"{'title': 'Introduction', 'number': '1'}"
"We present the f-structure LDD resolution algorithm, provide results and extensive evaluation.We compare our method with previous work.","{'title': 'Introduction', 'number': '1'}"
"Fi nally, we conclude.","{'title': 'Introduction', 'number': '1'}"
"Lexical-Functional Grammar (Kaplan and Bres nan, 1982; Dalrymple, 2001) minimally involves two levels of syntactic representation:3 c-structure and f-structure.","{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
C(onstituent)-structure represents the grouping of words and phrases into largerconstituents and is realised in terms of a CF PSG grammar.,"{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
"F(unctional)-structure represents abstract syntactic functions such as SUBJ(ect), OBJ(ect), OBL(ique), closed and open clausal COMP/XCOMP(lement), ADJ(unct), APP(osition) etc. and is implemented in terms of recursive feature structures (attribute-value matrices).","{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
"C-structurecaptures surface grammatical configurations, f structure encodes abstract syntactic information approximating to predicate-argument/dependency structure or simple logical form (van Genabithand Crouch, 1996).","{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
"C- and f-structures are re lated in terms of functional annotations (constraints, attribute-value equations) on c-structure rules (cf.","{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
Figure 1).,"{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
S NP VP U.N. V NP signs treaty [ SUBJ [ PRED U.N. ] PRED sign OBJ [ PRED treaty ] ] S ? NP VP ?SUBJ=?,"{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
VP ? V NP ?=?,"{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
?OBJ=?,"{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
"NP ? U.N V ? signs ?PRED=U.N. ?PRED=sign Figure 1: Simple LFG C- and F-Structure Uparrows point to the f-structure associated with the mother node, downarrows to that of the local node.The equations are collected with arrows instanti ated to unique tree node identifiers, and a constraint solver generates an f-structure.","{'title': 'Lexical Functional Grammar (LFG). ', 'number': '2'}"
The Penn-II treebank employs CFG trees with addi tional ?functional?,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
"node annotations (such as -LOC,-TMP, -SBJ, -LGS, . . .","{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
) as well as traces and coin dexation (to indicate LDDs) as basic data structures.,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
"The f-structure annotation algorithm of (Cahill et 3LFGs may also involve morphological and semantic levels of representation.al., 2002) exploits configurational, categorial, Penn II ?functional?, local head and trace informationto annotate nodes with LFG feature-structure equa tions.","{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
"A slightly adapted version of (Magerman, 1994)?s scheme automatically head-lexicalises the Penn-II trees.","{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
This partitions local subtrees of depth one (corresponding to CFG rules) into left and rightcontexts (relative to head).,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
The annotation algo rithm is modular with four components (Figure 2): left-right (L-R) annotation principles (e.g. leftmost NP to right of V head of VP type rule is likely to be an object etc.); coordination annotation principles (separating these out simplifies other componentsof the algorithm); traces (translates traces and coin dexation in trees into corresponding reentrancies in f-structure ( 1 in Figure 3)); catch all and clean-up.,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
Lexical information is provided via macros for POS tag classes.,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
L/R Context ? Coordination ? Traces ? Catch-All Figure 2: Annotation AlgorithmThe f-structure annotations are passed to a con straint solver to produce f-structures.,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
"Annotationis evaluated in terms of coverage and quality, sum marised in Table 1.","{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
"Coverage is near complete with 99.82% of the 48K Penn-II sentences receiving a single, connected f-structure.","{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
Annotation quality is measured in terms of precision and recall (P&R) against the DCU 105.,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
The algorithm achieves an F-score of 96.57% for full f-structures and 94.3% for preds-only f-structures.4 S S-TPC- 1 NP U.N. VP V signs NP treaty NP Det the N headline VP V said S T- 1 ? ?,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
TOPIC [ SUBJ [ PRED U.N. ] PRED sign OBJ [ PRED treaty ] ] 1 SUBJ [ SPEC the PRED headline ] PRED say COMP 1 ? ?,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
?Figure 3: Penn-II style tree with LDD trace and cor responding reentrancy in f-structure4Full f-structures measure all attribute-value pairs includ ing?minor?,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
"features such as person, number etc. The stricter preds-only captures only paths ending in PRED:VALUE.","{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
# frags # sent percent 0 85 0.176 1 48337 99.820 2 2 0.004 all preds P 96.52 94.45 R 96.63 94.16 Table 1: F-structure annotation results for DCU 105,"{'title': 'Automatic F-Structure Annotation. ', 'number': '3'}"
"Based on these resources (Cahill et al, 2002) de veloped two parsing architectures.","{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
Both generate PCFG-based approximations of LFG grammars.,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
In the pipeline architecture a standard PCFG is extracted from the ?raw?,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
treebank to parse unseen text.,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
The resulting parse-trees are then annotated by the automatic f-structure annotation algorithm and resolved into f-structures.,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
In the integrated architecture the treebank is first annotated with f-structure equations.,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
An annotated PCFG is then extracted where each non-terminal symbol in the grammar has been augmented with LFG f-equations: NP[?OBJ=?],"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
DT[?SPEC=?],"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
NN[?=?],"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
Nodes followed by annotations are treated as a monadic category for grammar extraction and parsing.,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
"Post-parsing, equations are collected from parse trees and resolved into f-structures.Both architectures parse raw text into ?proto?","{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
fstructures with LDDs unresolved resulting in in complete argument structures as in Figure 4.,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
S S NP U.N. VP V signs NP treaty NP Det the N headline VP V said ? ?,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
TOPIC [ SUBJ [ PRED U.N. ] PRED sign OBJ [ PRED treaty ] ] SUBJ [ SPEC the PRED headline ] PRED say ? ?,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
Figure 4: Shallow-Parser Output with UnresolvedLDD and Incomplete Argument Structure (cf.,"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
Fig ure 3),"{'title': 'PCFG-Based LFG Approximations. ', 'number': '4'}"
"Theoretically, LDDs can span unbounded amounts of intervening linguistic material as in [U.N. signs treaty]1 the paper claimed . . .","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
a source said []1.,"{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"In LFG, LDDs are resolved at the f-structure level, obviating the need for empty productions and tracesin trees (Dalrymple, 2001), using functional uncer tainty (FU) equations.","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
FUs are regular expressions specifying paths in f-structure between a source(where linguistic material is encountered) and a target (where linguistic material is interpreted semantically).,"{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"To account for the fronted sentential con stituents in Figures 3 and 4, an FU equation of the form ? TOPIC = ? COMP* COMP would be required.The equation states that the value of the TOPIC at tribute is token identical with the value of the finalCOMP argument along a path through the immedi ately enclosing f-structure along zero or more COMPattributes.","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
This FU equation is annotated to the top icalised sentential constituent in the relevant CFG rules as follows S ? S NP VP ?TOPIC=?,"{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
?SUBJ=?,"{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"?TOPIC=?COMP*COMP and generates the LDD-resolved proper f-structurein Figure 3 for the traceless tree in Figure 4, as re quired.In addition to FU equations, subcategorisation in formation is a crucial ingredient in LFG?s accountof LDDs.","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"As an example, for a topicalised con stituent to be resolved as the argument of a local predicate as specified by the FU equation, the local predicate must (i) subcategorise for the argument in question and (ii) the argument in question must not be already filled.","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"Subcategorisation requirements are provided lexically in terms of semantic forms(subcat lists) and coherence and completeness con ditions (all GFs specified must be present, and noothers may be present) on f-structure representa tions.","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
Semantic forms specify which grammatical functions (GFs) a predicate requires locally.,"{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"For ourexample in Figures 3 and 4, the relevant lexical en tries are: V ? said ?PRED=say??","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"SUBJ, ? COMP?","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
V ? signs ?PRED=sign??,"{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
"SUBJ, ? OBJ?","{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
FU equations and subcategorisation requirements together ensure that LDDs can only be resolved at suitable f-structure locations.,"{'title': 'LDDs and LFG FU-Equations. ', 'number': '5'}"
In order to model the LFG account of LDD resolu tion we require subcat frames (i.e. semantic forms)and LDD resolution paths through f-structure.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Tra ditionally, such resources were handcoded.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
Here weshow how they can be acquired from f-structure an notated treebank resources.LFG distinguishes between governable (arguments) and nongovernable (adjuncts) grammati cal functions (GFs).,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"If the automatic f-structureannotation algorithm outlined in Section 3 generates high quality f-structures, reliable seman tic forms can be extracted (reverse-engineered): for each f-structure generated, for each level of embedding we determine the local PRED valueand collect the governable, i.e. subcategoris able grammatical functions present at that level of embedding.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"For the proper f-structure in Figure 3 we obtain sign([subj,obj]) and say([subj,comp]).","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
We extract frames from the full WSJ section of the Penn-II Treebank with48K trees.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Unlike many other approaches, our ex traction process does not predefine frames, fully reflects LDDs in the source data-structures (cf.Figure 3), discriminates between active and passive frames, computes GF, GF:CFG category pair as well as CFG category-based subcategorisation frames and associates conditional probabilities with frames.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Given a lemma l and an argument list s, the probability of s given l is estimated as: P(s|l) := count(l, s)?n i=1 count(l, si) Table 2 summarises the results.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
We extract 3586 verb lemmas and 10969 unique verbal semanticform types (lemma followed by non-empty argu ment list).,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Including prepositions associated with the subcategorised OBLs and particles, this number goes up to 14348.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"The number of unique frametypes (without lemma) is 38 without specific prepositions and particles, 577 with.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
F-structure anno tations allow us to distinguish passive and activeframes.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
Table 3 shows the most frequent seman tic forms for accept.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Passive frames are marked p. We carried out a comprehensive evaluation of the automatically acquired verbal semantic forms against the COMLEX Resource (Macleod et al,1994) for the 2992 active verb lemmas that both resources have in common.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
We report on the evalu ation of GF-based frames for the full frames with complete prepositional and particle infomation.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
We use relative conditional probability thresholds (1% and 5%) to filter the selection of semantic forms (Table 4).,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"(O?Donovan et al, 2004) provide a more detailed description of the extraction and evaluation of semantic forms.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
Without Prep/Part With Prep/Part Lemmas 3586 3586 Sem.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
Forms 10969 14348 Frame Types 38 577 Active Frame Types 38 548 Passive Frame Types 21 177 Table 2: Verb Results Semantic Form Occurrences Prob.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"accept([obj,subj]) 122 0.813 accept([subj],p) 9 0.060 accept([comp,subj]) 5 0.033 accept([subj,obl:as],p) 3 0.020 accept([obj,subj,obl:as]) 3 0.020 accept([obj,subj,obl:from]) 3 0.020 accept([subj]) 2 0.013 accept([obj,subj,obl:at]) 1 0.007 accept([obj,subj,obl:for]) 1 0.007 accept([obj,subj,xcomp]) 1 0.007 Table 3: Semantic forms for the verb accept.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
Threshold 1% Threshold 5% P R F-Score P R F-Score Exp. 73.7% 22.1% 34.0% 78.0% 18.3% 29.6% Table 4: COMLEX ComparisonWe further acquire finite approximations of FU equations.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
by extracting paths between co-indexedmaterial occurring in the automatically generated fstructures from sections 02-21 of the Penn-II tree bank.,"{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"We extract 26 unique TOPIC, 60 TOPIC-RELand 13 FOCUS path types (with a total of 14,911 token occurrences), each with an associated probability.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"We distinguish between two types of TOPIC REL paths, those that occur in wh-less constructions, and all other types (c.f Table 5).","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Given a path p andan LDD type t (either TOPIC, TOPIC-REL or FO CUS), the probability of p given t is estimated as: P(p|t) := count(t, p)?n i=1 count(t, pi)In order to get a first measure of how well the ap proximation models the data, we compute the path types in section 23 not covered by those extracted from 02-21: 23/(02-21).","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"There are 3 such path types (Table 6), each occuring exactly once.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Given that the total number of path tokens in section 23 is 949,the finite approximation extracted from 02-23 cov ers 99.69% of all LDD paths in section 23.","{'title': 'Acquiring Lexical and LDD Resources. ', 'number': '6'}"
"Given a set of semantic forms s with probabilities P(s|l) (where l is a lemma), a set of paths p withP(p|t) (where t is either TOPIC, TOPIC-REL or FO CUS) and an f-structure f , the core of the algorithm to resolve LDDs recursively traverses f to: find TOPIC|TOPIC-REL|FOCUS:g pair; retrieve TOPIC|TOPIC-REL|FOCUS paths; for each path p with GF1 : . . .","{'title': 'Resolving LDDs in F-Structure. ', 'number': '7'}"
": GFn : GF, traverse f along GF1 : . . .","{'title': 'Resolving LDDs in F-Structure. ', 'number': '7'}"
: GFn to sub-f-structure h; retrieve local PRED:l; add GF:g to h iff ? GF is not present at h wh-less TOPIC-REL # wh-less TOPIC-REL # subj 5692 adjunct 1314 xcomp:adjunct 610 obj 364 xcomp:obj 291 xcomp:xcomp:adjunct 96 comp:subj 76 xcomp:subj 67 Table 5: Most frequent wh-less TOPIC-REL paths 02?21 23 23 /(02?21) TOPIC 26 7 2 FOCUS 13 4 0 TOPIC-REL 60 22 1 Table 6: Number of path types extracted?,"{'title': 'Resolving LDDs in F-Structure. ', 'number': '7'}"
"h together with GF is locally complete and co herent with respect to a semantic form s for l rank resolution by P(s|l) ? P(p|t) The algorithm supports multiple, interacting TOPIC, TOPIC-REL and FOCUS LDDs.","{'title': 'Resolving LDDs in F-Structure. ', 'number': '7'}"
"We use P(s|l) ? P(p|t) to rank a solution, depending on how likely the PRED takes semantic frame s, and how likely the TOPIC, FOCUS or TOPIC-REL is resolved using path p. The algorithm also supports resolution of LDDs where no overt linguistic material introducesa source TOPIC-REL function (e.g. in reduced rela tive clause constructions).","{'title': 'Resolving LDDs in F-Structure. ', 'number': '7'}"
"We distinguish between passive and active constructions, using the relevant semantic frame type when resolving LDDs.","{'title': 'Resolving LDDs in F-Structure. ', 'number': '7'}"
We ran experiments with grammars in both the pipeline and the integrated parsing architectures.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"The first grammar is a basic PCFG, while A-PCFG includes the f-structure annotations.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"We apply a parent transformation to each grammar (Johnson, 1999) to give P-PCFG and PA-PCFG.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"We train on sections 02-21 (grammar, lexical extraction andLDD paths) of the Penn-II Treebank and test on sec tion 23.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"The only pre-processing of the trees that wedo is to remove empty nodes, and remove all PennII functional tags in the integrated model.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
We evalu ate the parse trees using evalb.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"Following (Riezler et al., 2002), we convert f-structures into dependency triple format.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
Using their software we evaluate the f-structure parser output against: 1.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"The DCU 105 (Cahill et al, 2002).","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
2.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"The full 2,416 f-structures automatically gen-.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"erated by the f-structure annotation algorithm for the original Penn-II trees, in a CCG-style (Hockenmaier, 2003) evaluation experiment Pipeline Integrated PCFG P-PCFG A-PCFG PA-PCFG 2416 Section 23 trees.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
# Parses 2416 2416 2416 2414 Lab.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
F-Score 75.83 80.80 79.17 81.32 Unlab.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"F-Score 78.28 82.70 81.49 83.28 DCU 105 F-Strs All GFs F-Score (before LDD resolution) 79.82 79.24 81.12 81.20 All GFs F-Score (after LDD resolution) 83.79 84.59 86.30 87.04 Preds only F-Score (before LDD resolution) 70.00 71.57 73.45 74.61 Preds only F-Score (after LDD resolution) 73.78 77.43 78.76 80.97 2416 F-Strs All GFs F-Score (before LDD resolution) 81.98 81.49 83.32 82.78 All GFs F-Score (after LDD resolution) 84.16 84.37 86.45 86.00 Preds only F-Score (before LDD resolution) 72.00 73.23 75.22 75.10 Preds only F-Score (after LDD resolution) 74.07 76.12 78.36 78.40 PARC 700 Dependency Bank Subset of GFs following (Kaplan et al, 2004) 77.86 80.24 77.68 78.60 Table 7: Parser Evaluation 3.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"A subset of 560 dependency structures of thePARC 700 Dependency Bank following (Ka plan et al, 2004)The results are given in Table 7.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
The parenttransformed grammars perform best in both architectures.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"In all cases, there is a marked improvement (2.07-6.36%) in the f-structures after LDD res olution.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"We achieve between 73.78% and 80.97% preds-only and 83.79% to 87.04% all GFs f-score, depending on gold-standard.","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"We achieve between77.68% and 80.24% against the PARC 700 follow ing the experiments in (Kaplan et al, 2004).","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"For details on how we map the f-structures produced by our parsers to a format similar to that of the PARC 700 Dependency Bank, see (Burke et al, 2004).","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
Table 8 shows the evaluation result brokendown by individual GF (preds-only) for the inte grated model PA-PCFG against the DCU 105.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"Inorder to measure how many of the LDD reentran cies in the gold-standard f-structures are captured correctly by our parsers, we developed evaluation software for f-structure LDD reentrancies (similar to Johnson?s (2002) evaluation to capture traces and their antecedents in trees).","{'title': 'Experiments and Evaluation. ', 'number': '8'}"
Table 9 shows the results with the integrated model achieving more than 76% correct LDD reentrancies.,"{'title': 'Experiments and Evaluation. ', 'number': '8'}"
"(Collins, 1999)?s Model 3 is limited to wh-traces in relative clauses (it doesn?t treat topicalisation, focus etc.).","{'title': 'Related Work. ', 'number': '9'}"
Johnson?s (2002) work is closest toours in spirit.,"{'title': 'Related Work. ', 'number': '9'}"
Like our approach he provides a fi nite approximation of LDDs.,"{'title': 'Related Work. ', 'number': '9'}"
"Unlike our approach,however, he works with tree fragments in a post processing approach to add empty nodes and their DEP.","{'title': 'Related Work. ', 'number': '9'}"
"PRECISION RECALL F-SCORE adjunct 717/903 = 79 717/947 = 76 78 app 14/15 = 93 14/19 = 74 82 comp 35/43 = 81 35/65 = 54 65 coord 109/143 = 76 109/161 = 68 72 det 253/264 = 96 253/269 = 94 95 focus 1/1 = 100 1/1 = 100 100 obj 387/445 = 87 387/461 = 84 85 obj2 0/1 = 0 0/2 = 0 0 obl 27/56 = 48 27/61 = 44 46 obl2 1/3 = 33 1/2 = 50 40 obl ag 5/11 = 45 5/12 = 42 43 poss 69/73 = 95 69/81 = 85 90 quant 40/55 = 73 40/52 = 77 75 relmod 26/38 = 68 26/50 = 52 59 subj 330/361 = 91 330/414 = 80 85 topic 12/12 = 100 12/13 = 92 96 topicrel 35/42 = 83 35/52 = 67 74 xcomp 139/160 = 87 139/146 = 95 91 OVERALL 83.78 78.35 80.97 Table 8: Preds-only results of PA-PCFG against the DCU 105antecedents to parse trees, while we present an ap proach to LDD resolution on the level of f-structure.","{'title': 'Related Work. ', 'number': '9'}"
"It seems that the f-structure-based approach is more abstract (99 LDD path types against approximately 9,000 tree-fragment types in (Johnson, 2002)) andfine-grained in its use of lexical information (sub cat frames).","{'title': 'Related Work. ', 'number': '9'}"
"In contrast to Johnson?s approach, ourLDD resolution algorithm is not biased.","{'title': 'Related Work. ', 'number': '9'}"
It computes all possible complete resolutions and orderranks them using LDD path and subcat frame probabilities.,"{'title': 'Related Work. ', 'number': '9'}"
"It is difficult to provide a satisfactory comparison between the two methods, but we have car ried out an experiment that compares them at the f-structure level.","{'title': 'Related Work. ', 'number': '9'}"
We take the output of Charniak?s Pipeline Integrated PCFG P-PCFG A-PCFG PA-PCFG TOPIC Precision (11/14) (12/13) (12/13) (12/12) Recall (11/13) (12/13) (12/13) (12/13) F-Score 0.81 0.92 0.92 0.96 FOCUS Precision (0/1) (0/1) (0/1) (0/1) Recall (0/1) (0/1) (0/1) (0/1) F-Score 0 0 0 0 TOPIC-REL Precision (20/34) (27/36) (34/42) (34/42) Recall (20/52) (27/52) (34/52) (34/52) F-Score 0.47 0.613 0.72 0.72 OVERALL 0.54 0.67 0.75 0.76 Table 9: LDD Evaluation on the DCU 105 Charniak -LDD res.,"{'title': 'Related Work. ', 'number': '9'}"
+LDD res.,"{'title': 'Related Work. ', 'number': '9'}"
"(Johnson, 2002) All GFs 80.86 86.65 85.16 Preds Only 74.63 80.97 79.75 Table 10: Comparison at f-structure level of LDD resolution to (Johnson, 2002) on the DCU 105 parser (Charniak, 1999) and, using the pipeline f-structure annotation model, evaluate against the DCU 105, both before and after LDD resolution.","{'title': 'Related Work. ', 'number': '9'}"
"Using the software described in (Johnson, 2002) we add empty nodes to the output of Charniak?s parser,pass these trees to our automatic annotation algorithm and evaluate against the DCU 105.","{'title': 'Related Work. ', 'number': '9'}"
The results are given in Table 10.,"{'title': 'Related Work. ', 'number': '9'}"
Our method of resolv ing LDDs at f-structure level results in a preds-only f-score of 80.97%.,"{'title': 'Related Work. ', 'number': '9'}"
"Using (Johnson, 2002)?s method of adding empty nodes to the parse-trees results in an f-score of 79.75%.(Hockenmaier, 2003) provides CCG-based models of LDDs.","{'title': 'Related Work. ', 'number': '9'}"
Some of these involve extensive clean up of the underlying Penn-II treebank resource prior to grammar extraction.,"{'title': 'Related Work. ', 'number': '9'}"
"In contrast, in our approach we leave the treebank as is and only add (but never correct) annotations.","{'title': 'Related Work. ', 'number': '9'}"
"Earlier HPSG work (Tateisi et al, 1998) is based on independently constructedhand-crafted XTAG resources.","{'title': 'Related Work. ', 'number': '9'}"
"In contrast, we acquire our resources from treebanks and achieve sub stantially wider coverage.","{'title': 'Related Work. ', 'number': '9'}"
"Our approach provides wide-coverage, robust, and ? with the addition of LDD resolution ? ?deep?or ?full?, PCFG-based LFG approximations.","{'title': 'Related Work. ', 'number': '9'}"
"Crucially, we do not claim to provide fully adequate sta tistical models.","{'title': 'Related Work. ', 'number': '9'}"
"It is well known (Abney, 1997) that PCFG-type approximations to unification grammars can yield inconsistent probability models due toloss of probability mass: the parser successfully re turns the highest ranked parse tree but the constraint solver cannot resolve the f-equations (generated in the pipeline or ?hidden?","{'title': 'Related Work. ', 'number': '9'}"
in the integrated model) and the probability mass associated with that tree is lost.,"{'title': 'Related Work. ', 'number': '9'}"
"This case, however, is surprisingly rare for our grammars: only 0.0018% (85 out of 48424) of theoriginal Penn-II trees (without FRAGs) fail to pro duce an f-structure due to inconsistent annotations(Table 1), and for parsing section 23 with the in tegrated model (A-PCFG), only 9 sentences do notreceive a parse because no f-structure can be gen erated for the highest ranked tree (0.4%).","{'title': 'Related Work. ', 'number': '9'}"
"Parsing with the pipeline model, all sentences receive onecomplete f-structure.","{'title': 'Related Work. ', 'number': '9'}"
Research on adequate probability models for unification grammars is important.,"{'title': 'Related Work. ', 'number': '9'}"
"(Miyao et al, 2003) present a Penn-II treebank based HPSG with log-linear probability mod els.","{'title': 'Related Work. ', 'number': '9'}"
"They achieve coverage of 50.2% on section 23, as against 99% in our approach.","{'title': 'Related Work. ', 'number': '9'}"
"(Riezler etal., 2002; Kaplan et al, 2004) describe how a care fully hand-crafted LFG is scaled to the full Penn-II treebank with log-linear based probability models.","{'title': 'Related Work. ', 'number': '9'}"
They achieve 79% coverage (full parse) and 21% fragement/skimmed parses.,"{'title': 'Related Work. ', 'number': '9'}"
"By the same measure,full parse coverage is around 99% for our automat ically acquired PCFG-based LFG approximations.Against the PARC 700, the hand-crafted LFG grammar reported in (Kaplan et al, 2004) achieves an f score of 79.6%.","{'title': 'Related Work. ', 'number': '9'}"
"For the same experiment, our best automatically-induced grammar achieves an f-score of 80.24%.","{'title': 'Related Work. ', 'number': '9'}"
"We presented and extensively evaluated a finiteapproximation of LDD resolution in automatically constructed, wide-coverage, robust, PCFG based LFG approximations, effectively turning the ?half?(or ?shallow?)-grammars presented in (Cahill et al, 2002) into ?full?","{'title': 'Conclusions. ', 'number': '10'}"
or ?deep?,"{'title': 'Conclusions. ', 'number': '10'}"
grammars.,"{'title': 'Conclusions. ', 'number': '10'}"
"In our approach, LDDs are resolved in f-structure, not trees.","{'title': 'Conclusions. ', 'number': '10'}"
"The method achieves a preds-only f-score of 80.97% for f-structures with the PA-PCFG in the integrated architecture against the DCU 105and 78.4% against the 2,416 automatically gener ated f-structures for the original Penn-II treebanktrees.","{'title': 'Conclusions. ', 'number': '10'}"
"Evaluating against the PARC 700 Depen dency Bank, the P-PCFG achieves an f-score of 80.24%, an overall improvement of approximately 0.6% on the result reported for the best hand-crafted grammars in (Kaplan et al, 2004).","{'title': 'Conclusions. ', 'number': '10'}"
AcknowledgementsThis research was funded by Enterprise Ireland Ba sic Research Grant SC/2001/186 and IRCSET.,"{'title': 'Conclusions. ', 'number': '10'}"
