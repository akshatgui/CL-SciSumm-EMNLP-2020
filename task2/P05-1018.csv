col1,col2
This paper considers the problem of automatic assessment of local coherence.,{}
We present a novel entity-based representation of discourse which is inspired by Centering Theory and can be computed automatically from raw text.,{}
We view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function.,{}
Our experiments demonstrate that the induced model achieves significantly higher accuracy than a state-of-the-art coherence model.,{}
A key requirement for any system that produces text is the coherence of its output.,"{'title': '1 Introduction', 'number': '1'}"
"Not surprisingly, a variety of coherence theories have been developed over the years (e.g., Mann and Thomson, 1988; Grosz et al. 1995) and their principles have found application in many symbolic text generation systems (e.g., Scott and de Souza, 1990; Kibble and Power, 2004).","{'title': '1 Introduction', 'number': '1'}"
"The ability of these systems to generate high quality text, almost indistinguishable from human writing, makes the incorporation of coherence theories in robust large-scale systems particularly appealing.","{'title': '1 Introduction', 'number': '1'}"
"The task is, however, challenging considering that most previous efforts have relied on handcrafted rules, valid only for limited domains, with no guarantee of scalability or portability (Reiter and Dale, 2000).","{'title': '1 Introduction', 'number': '1'}"
"Furthermore, coherence constraints are often embedded in complex representations (e.g., Asher and Lascarides, 2003) which are hard to implement in a robust application.","{'title': '1 Introduction', 'number': '1'}"
"This paper focuses on local coherence, which captures text relatedness at the level of sentence-tosentence transitions, and is essential for generating globally coherent text.","{'title': '1 Introduction', 'number': '1'}"
The key premise of our work is that the distribution of entities in locally coherent texts exhibits certain regularities.,"{'title': '1 Introduction', 'number': '1'}"
"This assumption is not arbitrary — some of these regularities have been recognized in Centering Theory (Grosz et al., 1995) and other entity-based theories of discourse.","{'title': '1 Introduction', 'number': '1'}"
"The algorithm introduced in the paper automatically abstracts a text into a set of entity transition sequences, a representation that reflects distributional, syntactic, and referential information about discourse entities.","{'title': '1 Introduction', 'number': '1'}"
"We argue that this representation of discourse allows the system to learn the properties of locally coherent texts opportunistically from a given corpus, without recourse to manual annotation or a predefined knowledge base.","{'title': '1 Introduction', 'number': '1'}"
We view coherence assessment as a ranking problem and present an efficiently learnable model that orders alternative renderings of the same information based on their degree of local coherence.,"{'title': '1 Introduction', 'number': '1'}"
"Such a mechanism is particularly appropriate for generation and summarization systems as they can produce multiple text realizations of the same underlying content, either by varying parameter values, or by relaxing constraints that control the generation process.","{'title': '1 Introduction', 'number': '1'}"
"A system equipped with a ranking mechanism, could compare the quality of the candidate outputs, much in the same way speech recognizers employ language models at the sentence level.","{'title': '1 Introduction', 'number': '1'}"
Our evaluation results demonstrate the effectiveness of our entity-based ranking model within the general framework of coherence assessment.,"{'title': '1 Introduction', 'number': '1'}"
"First, we evaluate the utility of the model in a text ordering task where our algorithm has to select a maximally coherent sentence order from a set of candidate permutations.","{'title': '1 Introduction', 'number': '1'}"
"Second, we compare the rankings produced by the model against human coherence judgments elicited for automatically generated summaries.","{'title': '1 Introduction', 'number': '1'}"
"In both experiments, our method yields a significant improvement over a state-of-the-art coherence model based on Latent Semantic Analysis (Foltz et al., 1998).","{'title': '1 Introduction', 'number': '1'}"
"In the following section, we provide an overview of existing work on the automatic assessment of local coherence.","{'title': '1 Introduction', 'number': '1'}"
"Then, we introduce our entity-based representation, and describe our ranking model.","{'title': '1 Introduction', 'number': '1'}"
"Next, we present the experimental framework and data.","{'title': '1 Introduction', 'number': '1'}"
Evaluation results conclude the paper.,"{'title': '1 Introduction', 'number': '1'}"
"Local coherence has been extensively studied within the modeling framework put forward by Centering Theory (Grosz et al., 1995; Walker et al., 1998; Strube and Hahn, 1999; Poesio et al., 2004; Kibble and Power, 2004).","{'title': '2 Related Work', 'number': '2'}"
One of the main assumptions underlying Centering is that a text segment which foregrounds a single entity is perceived to be more coherent than a segment in which multiple entities are discussed.,"{'title': '2 Related Work', 'number': '2'}"
The theory formalizes this intuition by introducing constraints on the distribution of discourse entities in coherent text.,"{'title': '2 Related Work', 'number': '2'}"
"These constraints are formulated in terms offocus, the most salient entity in a discourse segment, and transition of focus between adjacent sentences.","{'title': '2 Related Work', 'number': '2'}"
"The theory also establishes constraints on the linguistic realization of focus, suggesting that it is more likely to appear in prominent syntactic positions (such as subject or object), and to be referred to with anaphoric expressions.","{'title': '2 Related Work', 'number': '2'}"
"A great deal of research has attempted to translate principles of Centering Theory into a robust coherence metric (Miltsakaki and Kukich, 2000; Hasler, 2004; Karamanis et al., 2004).","{'title': '2 Related Work', 'number': '2'}"
"Such a translation is challenging in several respects: one has to specify the “free parameters” of the system (Poesio et al., 2004) and to determine ways of combining the effects of various constraints.","{'title': '2 Related Work', 'number': '2'}"
A common methodology that has emerged in this research is to develop and evaluate coherence metrics on manually annotated corpora.,"{'title': '2 Related Work', 'number': '2'}"
"For instance, Miltsakaki and Kukich (2000) annotate a corpus of student essays with transition information, and show that the distribution of transitions correlates with human grades.","{'title': '2 Related Work', 'number': '2'}"
Karamanis et al. (2004) use a similar methodology to compare coherence metrics with respect to their usefulness for text planning in generation.,"{'title': '2 Related Work', 'number': '2'}"
The present work differs from these approaches in two key respects.,"{'title': '2 Related Work', 'number': '2'}"
"First, our method does not require manual annotation of input texts.","{'title': '2 Related Work', 'number': '2'}"
"We do not aim to produce complete centering annotations; instead, our inference procedure is based on a discourse representation that preserves essential entity transition information, and can be computed automatically from raw text.","{'title': '2 Related Work', 'number': '2'}"
"Second, we learn patterns of entity distribution from a corpus, without attempting to directly implement or refine Centering constraints.","{'title': '2 Related Work', 'number': '2'}"
In this section we introduce our entity-based representation of discourse.,"{'title': '3 The Coherence Model', 'number': '3'}"
We describe how it can be computed and how entity transition patterns can be extracted.,"{'title': '3 The Coherence Model', 'number': '3'}"
The latter constitute a rich feature space on which probabilistic inference is performed.,"{'title': '3 The Coherence Model', 'number': '3'}"
"Text Representation Each text is represented by an entity grid, a two-dimensional array that captures the distribution of discourse entities across text sentences.","{'title': '3 The Coherence Model', 'number': '3'}"
"We follow Miltsakaki and Kukich (2000) in assuming that our unit of analysis is the traditional sentence (i.e., a main clause with accompanying subordinate and adjunct clauses).","{'title': '3 The Coherence Model', 'number': '3'}"
"The rows of the grid correspond to sentences, while the columns correspond to discourse entities.","{'title': '3 The Coherence Model', 'number': '3'}"
By discourse entity we mean a class of coreferent noun phrases.,"{'title': '3 The Coherence Model', 'number': '3'}"
"For each occurrence of a discourse entity in the text, the corresponding grid cell contains information about its grammatical role in the given sentence.","{'title': '3 The Coherence Model', 'number': '3'}"
Each grid column thus corresponds to a string from a set of categories reflecting the entity’s presence or absence in a sequence of sentences.,"{'title': '3 The Coherence Model', 'number': '3'}"
"Our set consists of four symbols: S (subject), O (object), X (neither subject nor object) and – (gap which signals the entity’s absence from a given sentence).","{'title': '3 The Coherence Model', 'number': '3'}"
Table 1 illustrates a fragment of an entity grid constructed for the text in Table 2.,"{'title': '3 The Coherence Model', 'number': '3'}"
"Since the text contains six sentences, the grid columns are of length six.","{'title': '3 The Coherence Model', 'number': '3'}"
"Consider for instance the grid column for the entity trial, [O – – – – X].","{'title': '3 The Coherence Model', 'number': '3'}"
It records that trial is present in sentences 1 and 6 (as O and X respectively) but is absent from the rest of the sentences. cluster coreferent discourse entities is an important prerequisite for computing entity grids.,"{'title': '3 The Coherence Model', 'number': '3'}"
"The same entity may appear in different linguistic forms, e.g., Microsoft Corp., Microsoft, and the company, but should still be mapped to a single entry in the grid.","{'title': '3 The Coherence Model', 'number': '3'}"
Table 1 exemplifies the entity grid for the text in Table 2 when coreference resolution is taken into account.,"{'title': '3 The Coherence Model', 'number': '3'}"
"To automatically compute entity classes, we employ a state-of-the-art noun phrase coreference resolution system (Ng and Cardie, 2002) trained on the MUC (6–7) data sets.","{'title': '3 The Coherence Model', 'number': '3'}"
"The system decides whether two NPs are coreferent by exploiting a wealth of features that fall broadly into four categories: lexical, grammatical, semantic and positional.","{'title': '3 The Coherence Model', 'number': '3'}"
"Once we have identified entity classes, the next step is to fill out grid entries with relevant syntactic information.","{'title': '3 The Coherence Model', 'number': '3'}"
"We employ a robust statistical parser (Collins, 1997) to determine the constituent structure for each sentence, from which subjects (s), objects (o), and relations other than subject or object (x) are identified.","{'title': '3 The Coherence Model', 'number': '3'}"
"Passive verbs are recognized using a small set of patterns, and the underlying deep grammatical role for arguments involved in the passive construction is entered in the grid (see the grid cell o for Microsoft, Sentence 2, Table 2).","{'title': '3 The Coherence Model', 'number': '3'}"
"When a noun is attested more than once with a different grammatical role in the same sentence, we default to the role with the highest grammatical ranking: subjects are ranked higher than objects, which in turn are ranked higher than the rest.","{'title': '3 The Coherence Model', 'number': '3'}"
"For example, the entity Microsoft is mentioned twice in Sentence 1 with the grammatical roles x (for Microsoft Corp.) and s (for the company), but is represented only by s in the grid (see Tables 1 and 2). for coherence assessment that is based on grid representation.","{'title': '3 The Coherence Model', 'number': '3'}"
A fundamental assumption underlying our approach is that the distribution of entities in coherent texts exhibits certain regularities reflected in grid topology.,"{'title': '3 The Coherence Model', 'number': '3'}"
Some of these regularities are formalized in Centering Theory as constraints on transitions of local focus in adjacent sentences.,"{'title': '3 The Coherence Model', 'number': '3'}"
"Grids of coherent texts are likely to have some dense columns (i.e., columns with just a few gaps such as Microsoft in Table 1) and many sparse columns which will consist mostly of gaps (see markets, earnings in Table 1).","{'title': '3 The Coherence Model', 'number': '3'}"
One would further expect that entities corresponding to dense columns are more often subjects or objects.,"{'title': '3 The Coherence Model', 'number': '3'}"
These characteristics will be less pronounced in low-coherence texts.,"{'title': '3 The Coherence Model', 'number': '3'}"
"Inspired by Centering Theory, our analysis revolves around patterns of local entity transitions.","{'title': '3 The Coherence Model', 'number': '3'}"
"A local entity transition is a sequence IS, O, X, –}n that represents entity occurrences and their syntactic roles in n adjacent sentences.","{'title': '3 The Coherence Model', 'number': '3'}"
Local transitions can be easily obtained from a grid as continuous subsequences of each column.,"{'title': '3 The Coherence Model', 'number': '3'}"
Each transition will have a certain probability in a given grid.,"{'title': '3 The Coherence Model', 'number': '3'}"
"For instance, the probability of the transition [S –] in the grid from Table 1 is 0.08 (computed as a ratio of its frequency (i.e., six) divided by the total number of transitions of length two (i.e., 75)).","{'title': '3 The Coherence Model', 'number': '3'}"
Each text can thus be viewed as a distribution defined over transition types.,"{'title': '3 The Coherence Model', 'number': '3'}"
We believe that considering all entity transitions may uncover new patterns relevant for coherence assessment.,"{'title': '3 The Coherence Model', 'number': '3'}"
We further refine our analysis by taking into account the salience of discourse entities.,"{'title': '3 The Coherence Model', 'number': '3'}"
Centering and other discourse theories conjecture that the way an entity is introduced and mentioned depends on its global role in a given discourse.,"{'title': '3 The Coherence Model', 'number': '3'}"
"Therefore, we discriminate between transitions of salient entities and the rest, collecting statistics for each group separately.","{'title': '3 The Coherence Model', 'number': '3'}"
"We identify salient entities based on their Table 3: Example of a feature-vector document representation using all transitions of length two given syntactic categories: S, O, X, and –. frequency,1 following the widely accepted view that the occurrence frequency of an entity correlates with its discourse prominence (Morris and Hirst, 1991; Grosz et al., 1995).","{'title': '3 The Coherence Model', 'number': '3'}"
Ranking We view coherence assessment as a ranking learning problem.,"{'title': '3 The Coherence Model', 'number': '3'}"
The ranker takes as input a set of alternative renderings of the same document and ranks them based on their degree of local coherence.,"{'title': '3 The Coherence Model', 'number': '3'}"
Examples of such renderings include a set of different sentence orderings of the same text and a set of summaries produced by different systems for the same document.,"{'title': '3 The Coherence Model', 'number': '3'}"
"Ranking is more suitable than classification for our purposes since in text generation, a system needs a scoring function to compare among alternative renderings.","{'title': '3 The Coherence Model', 'number': '3'}"
"Furthermore, it is clear that coherence assessment is not a categorical decision but a graded one: there is often no single coherent rendering of a given text but many different possibilities that can be partially ordered.","{'title': '3 The Coherence Model', 'number': '3'}"
"As explained previously, coherence constraints are modeled in the grid representation implicitly by entity transition sequences.","{'title': '3 The Coherence Model', 'number': '3'}"
"To employ a machine learning algorithm to our problem, we encode transition sequences explicitly using a standard feature vector notation.","{'title': '3 The Coherence Model', 'number': '3'}"
"Each grid rendering j of a document di is represented by a feature vector d3(xij) = (p1(xij), p2(xij),..., pm(xij)), where m is the number of all predefined entity transitions, and pt(xij) the probability of transition t in grid xij.","{'title': '3 The Coherence Model', 'number': '3'}"
Note that considerable latitude is available when specifying the transition types to be included in a feature vector.,"{'title': '3 The Coherence Model', 'number': '3'}"
"These can be all transitions of a given length (e.g., two or three) or the most frequent transitions within a document collection.","{'title': '3 The Coherence Model', 'number': '3'}"
An example of a feature space with transitions of length two is illustrated in Table 3.,"{'title': '3 The Coherence Model', 'number': '3'}"
"The training set consists of ordered pairs of renderings (xij,xik), where xij and xik are renderings of the same document di, and xij exhibits a higher degree of coherence than xik.","{'title': '3 The Coherence Model', 'number': '3'}"
"Without loss of generality, we assume j > k. The goal of the training procedure is to find a parameter vector w� that yields a “ranking score” function w� · d3(xij), which minimizes the number of violations of pairwise rankings provided in the training set.","{'title': '3 The Coherence Model', 'number': '3'}"
"Thus, the ideal w� would satisfy the condition w·(d3(xij)−d3(xik)) > 0 Vj,i,k such that j > k. The problem is typically treated as a Support Vector Machine constraint optimization problem, and can be solved using the search technique described in Joachims (2002a).","{'title': '3 The Coherence Model', 'number': '3'}"
"This approach has been shown to be highly effective in various tasks ranging from collaborative filtering (Joachims, 2002a) to parsing (Toutanova et al., 2004).","{'title': '3 The Coherence Model', 'number': '3'}"
"In our ranking experiments, we use Joachims’ (2002a) SVMlight package for training and testing with all parameters set to their default values.","{'title': '3 The Coherence Model', 'number': '3'}"
In this section we describe two evaluation tasks that assess the merits of the coherence modeling framework introduced above.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"We also give details regarding our data collection, and parameter estimation.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Finally, we introduce the baseline method used for comparison with our approach.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Text structuring algorithms (Lapata, 2003; Barzilay and Lee, 2004; Karamanis et al., 2004) are commonly evaluated by their performance at information-ordering.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"The task concerns determining a sequence in which to present a pre-selected set of information-bearing items; this is an essential step in concept-to-text generation, multi-document summarization, and other text-synthesis problems.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Since local coherence is a key property of any well-formed text, our model can be used to rank alternative sentence orderings.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
We do not assume that local coherence is sufficient to uniquely determine the best ordering — other constraints clearly play a role here.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"However, we expect that the accuracy of a coherence model is reflected in its performance in the ordering task.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Data To acquire a large collection for training and testing, we create synthetic data, wherein the candidate set consists of a source document and permutations of its sentences.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
This framework for data acquisition is widely used in evaluation of ordering algorithms as it enables large scale automatic evaluation.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"The underlying assumption is that the original sentence order in the source document must be coherent, and so we should prefer models that rank it higher than other permutations.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Since we do not know the relative quality of different permutations, our corpus includes only pairwise rankings that comprise the original document and one of its permutations.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Given k original documents, each with n randomly generated permutations, we obtain k · n (trivially) annotated pairwise rankings for training and testing.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Using the technique described above, we collected data in two different genres: newspaper articles and accident reports written by government officials.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
The first collection consists of Associated Press articles from the North American News Corpus on the topic of natural disasters.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
The second includes narratives from the National Transportation Safety Board’s database2.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Both sets have documents of comparable length – the average number of sentences is 10.4 and 11.5, respectively.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"For each set, we used 100 source articles with 20 randomly generated permutations for training.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"The same number of pairwise rankings (i.e., 2000) was used for testing.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"We held out 10 documents (i.e., 200 pairwise rankings) from the training data for development purposes.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
We further test the ability of our method to assess coherence by comparing model induced rankings against rankings elicited by human judges.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Admittedly, the information ordering task only partially approximates degrees of coherence violation using different sentence permutations of a source document.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
A stricter evaluation exercise concerns the assessment of texts with naturally occurring coherence violations as perceived by human readers.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"A representative example of such texts are automatically generated summaries which often contain sentences taken out of context and thus display problems with respect to local coherence (e.g., dangling anaphors, thematically unrelated sentences).","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"A model that exhibits high agreement with human judges not only accurately captures the coherence properties of the summaries in question, but ultimately holds promise for the automatic evaluation of machine-generated texts.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Existing automatic evaluation measures such as BLEU (Papineni et al., 2002) and ROUGE (Lin and Hovy, 2003), are not designed for the coherence assessment task, since they focus on content similarity between system output and reference texts.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Data Our evaluation was based on materials from the Document Understanding Conference (DUC, 2003), which include multi-document summaries produced by human writers and by automatic summarization systems.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"In order to learn a ranking, we require a set of summaries, each of which have been rated in terms of coherence.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"We therefore elicited judgments from human subjects.3 We randomly selected 16 input document clusters and five systems that had produced summaries for these sets, along with summaries composed by several humans.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"To ensure that we do not tune a model to a particular system, we used the output summaries of distinct systems for training and testing.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Our set of training materials contained 4 · 16 summaries (average length 4.8), yielding (4)·16 = 96 pairwise rankings.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"2 In a similar fashion, we obtained 32 pairwise rankings for the test set.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
Six documents from the training data were used as a development set.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Coherence ratings were obtained during an elicitation study by 177 unpaid volunteers, all native speakers of English.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
The study was conducted remotely over the Internet.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Participants first saw a set of instructions that explained the task, and defined the notion of coherence using multiple examples.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
The summaries were randomized in lists following a Latin square design ensuring that no two summaries in a given list were generated from the same document cluster.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
Participants were asked to use a seven point scale to rate how coherent the summaries were without having seen the source texts.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
The ratings (approximately 23 per summary) given by our subjects were averaged to provide a rating between 1 and 7 for each summary.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
The reliability of the collected judgments is crucial for our analysis; we therefore performed several tests to validate the quality of the annotations.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"First, we measured how well humans agree in their coherence assessment.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"We employed leaveone-out resampling4 (Weiss and Kulikowski, 1991), by correlating the data obtained from each participant with the mean coherence ratings obtained from all other participants.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
The inter-subject agreement was r = .768.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Second, we examined the effect of different types of summaries (human- vs. machine-generated.)","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"An ANOVA revealed a reliable effect of summary type: F(1;15) = 20.38, p < 0.01 indicating that human summaries are perceived as significantly more coherent than system-generated ones.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Finally, the judgments of our participants exhibit a significant correlation with DUC evaluations (r = .41, p < 0.01).","{'title': '4 Evaluation Set-Up', 'number': '4'}"
Our model has two free parameters: the frequency threshold used to identify salient entities and the length of the transition sequence.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
These parameters were tuned separately for each data set on the corresponding held-out development set.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"For our ordering and summarization experiments, optimal saliencebased models were obtained for entities with frequency > 2.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
The optimal transition length was < 3 for ordering and < 2 for summarization.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
We compare our algorithm against the coherence model proposed by Foltz et al. (1998) which measures coherence as a function of semantic relatedness between adjacent sentences.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Semantic relatedness is computed automatically using Latent Semantic Analysis (LSA, Landauer and Dumais 1997) from raw text without employing syntactic or other annotations.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"This model is a good point of comparison for several reasons: (a) it is fully automatic, (b) it is a not a straw-man baseline; it correlates reliably with human judgments and has been used to analyze discourse structure, and (c) it models an aspect of coherence which is orthogonal to ours (their model is lexicalized).","{'title': '4 Evaluation Set-Up', 'number': '4'}"
Following Foltz et al. (1998) we constructed vector-based representations for individual words from a lemmatized version of the North American News Text Corpus (350 million words) using a term-document matrix.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
We used singular value decomposition to reduce the semantic space to 100 dimensions obtaining thus a space similar to LSA.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
We represented the meaning of a sentence as a vector by taking the mean of the vectors of its words.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
The similarity between two sentences was determined by measuring the cosine of their means.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
An overall text coherence measure was obtained by averaging the cosines for all pairs of adjacent sentences.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"In sum, each text was represented by a single feature, its sentence-to-sentence semantic similarity.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"During training, the ranker learns an appropriate threshold value for this feature.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
Model performance was assessed in the same way for information ordering and summary evaluation.,"{'title': '4 Evaluation Set-Up', 'number': '4'}"
"Given a set of pairwise rankings, we measure accuracy as the ratio of correct predictions made by the model over the size of the test set.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
"In this setup, random prediction results in an accuracy of 50%.","{'title': '4 Evaluation Set-Up', 'number': '4'}"
The evaluation of our coherence model was driven by two questions: (1) How does the proposed model compare to existing methods for coherence assessment that make use of distinct representations?,"{'title': '5 Results', 'number': '5'}"
(2) What is the contribution of linguistic knowledge to the model’s performance?,"{'title': '5 Results', 'number': '5'}"
Table 4 summarizes the accuracy of various configurations of our model for the ordering and coherence assessment tasks.,"{'title': '5 Results', 'number': '5'}"
"We first compared a linguistically rich grid model that incorporates coreference resolution, expressive syntactic information, and a salience-based feature space (Coreference+Syntax+Salience) against the LSA baseline (LSA).","{'title': '5 Results', 'number': '5'}"
"As can be seen in Table 4, the grid model outperforms the baseline in both ordering and summary evaluation tasks, by a wide margin.","{'title': '5 Results', 'number': '5'}"
We conjecture that this difference in performance stems from the ability of our model to discriminate between various patterns of local sentence transitions.,"{'title': '5 Results', 'number': '5'}"
"In contrast, the baseline model only measures the degree of overlap across successive sentences, without taking into account the properties of the entities that contribute to the overlap.","{'title': '5 Results', 'number': '5'}"
"Not surprisingly, the difference between the two methods is more pronounced for the second task — summary evaluation.","{'title': '5 Results', 'number': '5'}"
Manual inspection of our summary corpus revealed that low-quality summaries often contain repetitive information.,"{'title': '5 Results', 'number': '5'}"
"In such cases, simply knowing about high cross-sentential overlap is not sufficient to distinguish a repetitive summary from a well-formed one.","{'title': '5 Results', 'number': '5'}"
In order to investigate the contribution of linguistic knowledge on model performance we compared the full model introduced above against models using more impoverished representations.,"{'title': '5 Results', 'number': '5'}"
"We focused on three sources of linguistic knowledge — syntax, coreference resolution, and salience — which play a prominent role in Centering analyses of discourse coherence.","{'title': '5 Results', 'number': '5'}"
An additional motivation for our study is exploration of the trade-off between robustness and richness of linguistic annotations.,"{'title': '5 Results', 'number': '5'}"
"NLP tools are typically trained on human-authored texts, and may deteriorate in performance when applied to automatically generated texts with coherence violations.","{'title': '5 Results', 'number': '5'}"
"Syntax To evaluate the effect of syntactic knowledge, we eliminated the identification of grammatical relations from our grid computation and recorded solely whether an entity is present or absent in a sentence.","{'title': '5 Results', 'number': '5'}"
"This leaves only the coreference and salience information in the model, and the results are shown in Table 4 under (Coreference+Salience).","{'title': '5 Results', 'number': '5'}"
"The omission of syntactic information causes a uniform drop in performance on both tasks, which confirms its importance for coherence analysis.","{'title': '5 Results', 'number': '5'}"
"Coreference To measure the effect of fullyfledged coreference resolution, we constructed entity classes simply by clustering nouns on the basis of their identity.","{'title': '5 Results', 'number': '5'}"
"In other words, each noun in a text corresponds to a different entity in a grid, and two nouns are considered coreferent only if they are identical.","{'title': '5 Results', 'number': '5'}"
The performance of the model (Syntax+Salience) is shown in the third row of Table 4.,"{'title': '5 Results', 'number': '5'}"
"While coreference resolution improved model performance in ordering, it caused a decrease in accuracy in summary evaluation.","{'title': '5 Results', 'number': '5'}"
This drop in performance can be attributed to two factors related to the nature of our corpus — machine-generated texts.,"{'title': '5 Results', 'number': '5'}"
"First, an automatic coreference resolution tool expectedly decreases in accuracy because it was trained on well-formed human-authored texts.","{'title': '5 Results', 'number': '5'}"
"Second, automatic summarization systems do not use anaphoric expressions as often as humans do.","{'title': '5 Results', 'number': '5'}"
"Therefore, a simple entity clustering method is more suitable for automatic summaries.","{'title': '5 Results', 'number': '5'}"
"Salience Finally, we evaluate the contribution of salience information by comparing our original model (Coreference+Syntax+Salience) which accounts separately for patterns of salient and non-salient entities against a model that does not attempt to discriminate between them (Coreference+Syntax).","{'title': '5 Results', 'number': '5'}"
Our results on the ordering task indicate that models that take salience information into account consistently outperform models that do not.,"{'title': '5 Results', 'number': '5'}"
The effect of salience is less pronounced for the summarization task when it is combined with coreference information (Coreference + Salience).,"{'title': '5 Results', 'number': '5'}"
"This is expected, since accurate identification of coreferring entities is prerequisite to deriving accurate salience models.","{'title': '5 Results', 'number': '5'}"
"However, as explained above, our automatic coreference tool introduces substantial noise in our representation.","{'title': '5 Results', 'number': '5'}"
"Once this noise is removed (see Syntax+Salience), the salience model has a clear advantage over the other models.","{'title': '5 Results', 'number': '5'}"
In this paper we proposed a novel framework for representing and measuring text coherence.,"{'title': '6 Discussion and Conclusions', 'number': '6'}"
Central to this framework is the entity grid representation of discourse which we argue captures important patterns of sentence transitions.,"{'title': '6 Discussion and Conclusions', 'number': '6'}"
We re-conceptualize coherence assessment as a ranking task and show that our entity-based representation is well suited for learning an appropriate ranking function; we achieve good performance on text ordering and summary coherence evaluation.,"{'title': '6 Discussion and Conclusions', 'number': '6'}"
"On the linguistic side, our results yield empirical support to some of Centering Theory’s main claims.","{'title': '6 Discussion and Conclusions', 'number': '6'}"
We show that coherent texts are characterized by transitions with particular properties which do not hold for all discourses.,"{'title': '6 Discussion and Conclusions', 'number': '6'}"
"Our work, however, not only validates these findings, but also quantitatively measures the predictive power of various linguistic features for the task of coherence assessment.","{'title': '6 Discussion and Conclusions', 'number': '6'}"
An important future direction lies in augmenting our entity-based model with lexico-semantic knowledge.,"{'title': '6 Discussion and Conclusions', 'number': '6'}"
"One way to achieve this goal is to cluster entities based on their semantic relatedness, thereby creating a grid representation over lexical chains (Morris and Hirst, 1991).","{'title': '6 Discussion and Conclusions', 'number': '6'}"
"An entirely different approach is to develop fully lexicalized models, akin to traditional language models.","{'title': '6 Discussion and Conclusions', 'number': '6'}"
"Cache language models (Kuhn and Mori, 1990) seem particularly promising in this context.","{'title': '6 Discussion and Conclusions', 'number': '6'}"
"In the discourse literature, entity-based theories are primarily applied at the level of local coherence, while relational models, such as Rhetorical Structure Theory (Mann and Thomson, 1988; Marcu, 2000), are used to model the global structure of discourse.","{'title': '6 Discussion and Conclusions', 'number': '6'}"
"We plan to investigate how to combine the two for improved prediction on both local and global levels, with the ultimate goal of handling longer texts.","{'title': '6 Discussion and Conclusions', 'number': '6'}"
