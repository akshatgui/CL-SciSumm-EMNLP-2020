col1,col2
"In this paper, we present a novel approach for mining opinions from product reviews, where it converts opinion mining task to identify product features, expressions of opinions and relations between them.",{}
"By taking advantage of the observation that a lot of product features are phrases, a concept of phrase dependency parsing is introduced, which extends traditional dependency parsing to phrase level.",{}
This concept is then implemented for extracting relations between product features and expressions of opinions.,{}
Experimental evaluations show that the mining task can benefit from phrase dependency parsing.,{}
"As millions of users contribute rich information to the Internet everyday, an enormous number of product reviews are freely written in blog pages, Web forums and other consumer-generated mediums (CGMs).","{'title': '1 Introduction', 'number': '1'}"
This vast richness of content becomes increasingly important information source for collecting and tracking customer opinions.,"{'title': '1 Introduction', 'number': '1'}"
Retrieving this information and analyzing this content are impossible tasks if they were to be manually done.,"{'title': '1 Introduction', 'number': '1'}"
"However, advances in machine learning and natural language processing present us with a unique opportunity to automate the decoding of consumers’ opinions from online reviews.","{'title': '1 Introduction', 'number': '1'}"
Previous works on mining opinions can be divided into two directions: sentiment classification and sentiment related information extraction.,"{'title': '1 Introduction', 'number': '1'}"
"The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).","{'title': '1 Introduction', 'number': '1'}"
The latter focuses on extracting the elements composing a sentiment text.,"{'title': '1 Introduction', 'number': '1'}"
"The elements include source of opinions who expresses an opinion (Choi et al., 2005); target of opinions which is a receptor of an opinion (Popescu and Etzioni, 2005); opinion expression which delivers an opinion (Wilson et al., 2005b).","{'title': '1 Introduction', 'number': '1'}"
Some researchers refer this information extraction task as opinion extraction or opinion mining.,"{'title': '1 Introduction', 'number': '1'}"
"Comparing with the former one, opinion mining usually produces richer information.","{'title': '1 Introduction', 'number': '1'}"
"In this paper, we define an opinion unit as a triple consisting of a product feature, an expression of opinion, and an emotional attitude(positive or negative).","{'title': '1 Introduction', 'number': '1'}"
We use this definition as the basis for our opinion mining task.,"{'title': '1 Introduction', 'number': '1'}"
"Since a product review may refer more than one product feature and express different opinions on each of them, the relation extraction is an important subtask of opinion mining.","{'title': '1 Introduction', 'number': '1'}"
Consider the following sentences: and its size(4) [cannot be beat](4).,"{'title': '1 Introduction', 'number': '1'}"
"The phrases underlined are the product features, marked with square brackets are opinion expressions.","{'title': '1 Introduction', 'number': '1'}"
Product features and opinion expressions with identical superscript compose a relation.,"{'title': '1 Introduction', 'number': '1'}"
"For the first sentence, an opinion relation exists between “the Canon SD500” and “recommend”, but not between “picture” and “recommend”.","{'title': '1 Introduction', 'number': '1'}"
"The example shows that more than one relation may appear in a sentence, and the correct relations are not simple Cartesian product of opinion expressions and product features.","{'title': '1 Introduction', 'number': '1'}"
"Simple inspection of the data reveals that product features usually contain more than one word, such as “LCD screen”, “image color”, “Canon PowerShot SD500”, and so on.","{'title': '1 Introduction', 'number': '1'}"
An incomplete product feature will confuse the successive analysis.,"{'title': '1 Introduction', 'number': '1'}"
"For example, in passage “Image color is disappointed”, the negative sentiment becomes obscure if only “image” or “color” is picked out.","{'title': '1 Introduction', 'number': '1'}"
"Since a product feature could not be represented by a single word, dependency parsing might not be the best approach here unfortunately, which provides dependency relations only between words.","{'title': '1 Introduction', 'number': '1'}"
Previous works on relation extraction usually use the head word to represent the whole phrase and extract features from the word level dependency tree.,"{'title': '1 Introduction', 'number': '1'}"
This solution is problematic because the information provided by the phrase itself can not be used by this kind of methods.,"{'title': '1 Introduction', 'number': '1'}"
"And, experimental results show that relation extraction task can benefit from dependencies within a phrase.","{'title': '1 Introduction', 'number': '1'}"
"To solve this issue, we introduce the concept of phrase dependency parsing and propose an approach to construct it.","{'title': '1 Introduction', 'number': '1'}"
Phrase dependency parsing segments an input sentence into “phrases” and links segments with directed arcs.,"{'title': '1 Introduction', 'number': '1'}"
"The parsing focuses on the “phrases” and the relations between them, rather than on the single words inside each phrase.","{'title': '1 Introduction', 'number': '1'}"
"Because phrase dependency parsing naturally divides the dependencies into local and global, a novel tree kernel method has also been proposed.","{'title': '1 Introduction', 'number': '1'}"
The remaining parts of this paper are organized as follows: In Section 2 we discuss our phrase dependency parsing and our approach.,"{'title': '1 Introduction', 'number': '1'}"
"In Section 3, experiments are given to show the improvements.","{'title': '1 Introduction', 'number': '1'}"
"In Section 4, we present related work and Section 5 concludes the paper.","{'title': '1 Introduction', 'number': '1'}"
Fig.,"{'title': '2 The Approach', 'number': '2'}"
"1 gives the architecture overview for our approach, which performs the opinion mining task in three main steps: (1) constructing phrase dependency tree from results of chunking and dependency parsing; (2) extracting candidate product features and candidate opinion expressions; (3) extracting relations between product features and opinion expressions.","{'title': '2 The Approach', 'number': '2'}"
Dependency grammar is a kind of syntactic theories presented by Lucien Tesni`ere(1959).,"{'title': '2 The Approach', 'number': '2'}"
"In dependency grammar, structure is determined by the relation between a head and its dependents.","{'title': '2 The Approach', 'number': '2'}"
"In general, the dependent is a modifier or complement; the head plays a more important role in determining the behaviors of the pair.","{'title': '2 The Approach', 'number': '2'}"
"Therefore, criteria of how to establish dependency relations and how to distinguish the head and dependent in such relations is central problem for dependency grammar.","{'title': '2 The Approach', 'number': '2'}"
Fig.,"{'title': '2 The Approach', 'number': '2'}"
2(a) shows the dependency representation of an example sentence.,"{'title': '2 The Approach', 'number': '2'}"
The root of the sentence is “enjoyed”.,"{'title': '2 The Approach', 'number': '2'}"
"There are seven pairs of dependency relationships, depicted by seven arcs from heads to dependents.","{'title': '2 The Approach', 'number': '2'}"
"Currently, the mainstream of dependency parsing is conducted on lexical elements: relations are built between single words.","{'title': '2 The Approach', 'number': '2'}"
A major information loss of this word level dependency tree compared with constituent tree is that it doesn’t explicitly provide local structures and syntactic categories (i.e.,"{'title': '2 The Approach', 'number': '2'}"
"NP, VP labels) of phrases (Xia and Palmer, 2001).","{'title': '2 The Approach', 'number': '2'}"
"On the other hand, dependency tree provides connections between distant words, which are useful in extracting long distance relations.","{'title': '2 The Approach', 'number': '2'}"
"Therefore, compromising between the two, we extend the dependency tree node with phrases.","{'title': '2 The Approach', 'number': '2'}"
That implies a noun phrase “Cannon SD500 PowerShot” can be a dependent that modifies a verb phrase head “really enjoy using” with relation type “dobj”.,"{'title': '2 The Approach', 'number': '2'}"
"The feasibility behind is that a phrase is a syntactic unit regardless of the length or syntactic category (Santorini and Kroch, 2007), and it is acceptable to substitute a single word by a phrase with same syntactic category in a sentence.","{'title': '2 The Approach', 'number': '2'}"
"Formally, we define the dependency parsing with phrase nodes as phrase dependency parsing.","{'title': '2 The Approach', 'number': '2'}"
A dependency relationship which is an asymmetric binary relationship holds between two phrases.,"{'title': '2 The Approach', 'number': '2'}"
"One is called head, which is the central phrase in the relation.","{'title': '2 The Approach', 'number': '2'}"
"The other phrase is called dependent, which modifies the head.","{'title': '2 The Approach', 'number': '2'}"
"A label representing the relation type is assigned to each dependency relationship, such as subj (subject), obj (object), and so on.","{'title': '2 The Approach', 'number': '2'}"
Fig.2(c) shows an example of phrase dependency parsing result.,"{'title': '2 The Approach', 'number': '2'}"
"By comparing the phrase dependency tree and the word level dependency tree in Fig.2, the former delivers a more succinct tree structure.","{'title': '2 The Approach', 'number': '2'}"
Local words in same phrase are compacted into a single node.,"{'title': '2 The Approach', 'number': '2'}"
These words provide local syntactic and semantic effects which enrich the phrase they belong to.,"{'title': '2 The Approach', 'number': '2'}"
"But they should have limited influences on the global tree topology, especially in applications which emphasis the whole tree structures, such as tree kernels.","{'title': '2 The Approach', 'number': '2'}"
"Pruning away local dependency relations by additional phrase structure information, phrase dependency parsing accelerates following processing of opinion relation extraction.","{'title': '2 The Approach', 'number': '2'}"
"To construct phrase dependency tree, we propose a method which combines results from an existing shallow parser and a lexical dependency parser.","{'title': '2 The Approach', 'number': '2'}"
"A phrase dependency tree is defined as T = (V , E ), where V is the set of phrases, E is the dependency relations among the phrases in V representing by direct edges.","{'title': '2 The Approach', 'number': '2'}"
"To reserve the word level dependencies inside a phrase, we define a nested structure for a phrase Ti in V : Ti = (U, Ei).","{'title': '2 The Approach', 'number': '2'}"
"Vi = {v1, v2, · · · , vm} is the internal words, Ei is the internal dependency relations.","{'title': '2 The Approach', 'number': '2'}"
"We conduct the phrase dependency parsing in this way: traverses word level dependency tree in preorder (visits root node first, then traverses the children recursively).","{'title': '2 The Approach', 'number': '2'}"
"When visits a node R, searches in its children and finds the node set D which are in the same phrase with R according Algorithm 1 Pseudo-Code for constructing the phrase dependency tree INPUT: OUTPUT: phrase dependency tree T = (V , E ) where to the shallow parsing result.","{'title': '2 The Approach', 'number': '2'}"
Compacts D and R into a single node.,"{'title': '2 The Approach', 'number': '2'}"
Then traverses all the remaining children in the same way.,"{'title': '2 The Approach', 'number': '2'}"
The algorithm is shown in Alg.,"{'title': '2 The Approach', 'number': '2'}"
1.,"{'title': '2 The Approach', 'number': '2'}"
"The output of the algorithm is still a tree, for we only cut edges which are compacted into a phrase, the connectivity is keeped.","{'title': '2 The Approach', 'number': '2'}"
"Note that there will be inevitable disagrees between shallow parser and lexical dependency parser, the algorithm implies that we simply follow the result of the latter one: the phrases from shallow parser will not appear in the final result if they cannot be found in the procedure.","{'title': '2 The Approach', 'number': '2'}"
Consider the following example: Fig.2 shows the procedure of phrase dependency parsing.,"{'title': '2 The Approach', 'number': '2'}"
Fig.2(a) is the result of the lexical dependency parser.,"{'title': '2 The Approach', 'number': '2'}"
Shallow parsers result is shown in Fig.2(b).,"{'title': '2 The Approach', 'number': '2'}"
"Chunk phrases “NP(We)”, “VP(really enjoyed using)” and “NP(the Canon PowerShot SD500)” are nodes in the output phrase dependency tree.","{'title': '2 The Approach', 'number': '2'}"
"When visiting node “enjoyed” in Fig.2(a), the shallow parser tells that “really” and “using” which are children of “enjoy” are in the same phrase with their parent, then the three nodes are packed.","{'title': '2 The Approach', 'number': '2'}"
The final phrase dependency parsing tree is shown in the Fig.,"{'title': '2 The Approach', 'number': '2'}"
2(c).,"{'title': '2 The Approach', 'number': '2'}"
"In this work, we define that product features are products, product parts, properties of products, properties of parts, company names and related objects.","{'title': '2 The Approach', 'number': '2'}"
"For example,in consumer electronic domain, “Canon PowerShot”, “image quality”,“camera”, “laptop” are all product features.","{'title': '2 The Approach', 'number': '2'}"
"From analyzing the labeled corpus, we observe that more than 98% of product features are in a single phrase, which is either noun phrase (NP) or verb phrase (VP).","{'title': '2 The Approach', 'number': '2'}"
"Based on it, all NPs and VPs are selected as candidate product features.","{'title': '2 The Approach', 'number': '2'}"
While prepositional phrases (PPs) and adjectival phrases (ADJPs) are excluded.,"{'title': '2 The Approach', 'number': '2'}"
"Although it can cover nearly all the true product features, the precision is relatively low.","{'title': '2 The Approach', 'number': '2'}"
The large amount of noise candidates may confuse the relation extraction classifier.,"{'title': '2 The Approach', 'number': '2'}"
"To shrink the size of candidate set, we introduce language model by an intuition that the more likely a phrase to be a product feature, the more closely it related to the product review.","{'title': '2 The Approach', 'number': '2'}"
"In practice, for a certain domain of product reviews, a language model is build on easily acquired unlabeled data.","{'title': '2 The Approach', 'number': '2'}"
"Each candidate NP or VP chunk in the output of shallow parser is scored by the model, and cut off if its score is less than a threshold.","{'title': '2 The Approach', 'number': '2'}"
"Opinion expressions are spans of text that express a comment or attitude of the opinion holder, which are usually evaluative or subjective phrases.","{'title': '2 The Approach', 'number': '2'}"
"We also analyze the labeled corpus for opinion expressions and observe that many opinion expressions are used in multiple domains, which is identical with the conclusion presented by Kobayashi et al. (2007).","{'title': '2 The Approach', 'number': '2'}"
"They collected 5,550 opinion expressions from various sources .","{'title': '2 The Approach', 'number': '2'}"
The coverage of the dictionary is high in multiple domains.,"{'title': '2 The Approach', 'number': '2'}"
"Motivated by those observations, we use a dictionary which contains 8221 opinion expressions to select candidates (Wilson et al., 2005b).","{'title': '2 The Approach', 'number': '2'}"
"An assumption we use to filter candidate opinion expressions is that opinion expressions tend to appear closely with product features, which is also used to extract product features by Hu and Liu (2004).","{'title': '2 The Approach', 'number': '2'}"
"In our experiments, the tree distance between product feature and opinion expression in a relation should be less than 5 in the phrase dependency parsing tree.","{'title': '2 The Approach', 'number': '2'}"
This section describes our method on extracting relations between opinion expressions and product features using phrase dependency tree.,"{'title': '2 The Approach', 'number': '2'}"
Manually built patterns were used in previous works which have an obvious drawback that those patterns can hardly cover all possible situations.,"{'title': '2 The Approach', 'number': '2'}"
"By taking advantage of the kernel methods which can search a feature space much larger than that could be represented by a feature extraction-based approach, we define a new tree kernel over phrase dependency trees and incorporate this kernel within an SVM to extract relations between opinion expressions and product features.","{'title': '2 The Approach', 'number': '2'}"
The potential relation set consists of the all combinations between candidate product features and candidate opinion expressions in a sentence.,"{'title': '2 The Approach', 'number': '2'}"
"Given a phrase dependency parsing tree, we choose the subtree rooted at the lowest common parent(LCP) of opinion expression and product feature to represent the relation.","{'title': '2 The Approach', 'number': '2'}"
"Dependency tree kernels has been proposed by (Culotta and Sorensen, 2004).","{'title': '2 The Approach', 'number': '2'}"
Their kernel is defined on lexical dependency tree by the convolution of similarities between all possible subtrees.,"{'title': '2 The Approach', 'number': '2'}"
"However, if the convolution containing too many irrelevant subtrees, over-fitting may occur and decreases the performance of the classifier.","{'title': '2 The Approach', 'number': '2'}"
"In phrase dependency tree, local words in a same phrase are compacted, therefore it provides a way to treat “local dependencies” and “global dependencies” differently (Fig.","{'title': '2 The Approach', 'number': '2'}"
3).,"{'title': '2 The Approach', 'number': '2'}"
"As a consequence, these two kinds of dependencies will not disturb each other in measuring similarity.","{'title': '2 The Approach', 'number': '2'}"
Later experiments prove the validity of this statement.,"{'title': '2 The Approach', 'number': '2'}"
"We generalize the definition by (Culotta and Sorensen, 2004) to fit the phrase dependency tree.","{'title': '2 The Approach', 'number': '2'}"
"Use the symbols in Section 2.1.2, 9 i and 9j are two trees with root Ri and Rj, K(9 i, Jj) is the kernel function for them.","{'title': '2 The Approach', 'number': '2'}"
"Firstly, each tree node Tk E 9i is augmented with a set of features F, and an instance of F for Tk is Fk = {fk}.","{'title': '2 The Approach', 'number': '2'}"
"A match function m(Ti, Tj) is defined on comparing a subset of nodes’ features M C_ F. And in the same way, a similarity function s(Ti, Tj) are defined on 5 C F where i 1 if fis = fs C(fs, fl 0 otherwise (3) For the given phrase dependency parsing trees, the kernel function K(9i, 9j) is defined as folKc is the kernel function over Ri and Rj’s children.","{'title': '2 The Approach', 'number': '2'}"
"Denote a is a continuous subsequence of indices a, a + 1, · · · a + l (a) for Ri’s children where l(a) is its length, as is the s-th element in a.","{'title': '2 The Approach', 'number': '2'}"
And likewise b for Rj. where the constant 0 < A < 1 normalizes the effects of children subsequences’ length.,"{'title': '2 The Approach', 'number': '2'}"
"Compared with the definitions in (Culotta and Sorensen, 2004), we add term Kin to handle the internal nodes of a pharse, and make this extension still satisfy the kernel function requirements (composition of kernels is still a kernel (Joachims et al., 2001)).","{'title': '2 The Approach', 'number': '2'}"
The consideration is that the local words should have limited effects on whole tree structures.,"{'title': '2 The Approach', 'number': '2'}"
"So the kernel is defined on external children (Kc) and internal nodes (Kin) separately, annotator extracted 3595 relations, while the other annotator A2 extracted 3745 relations, an A1 d 3217 cases of them matched.","{'title': '2 The Approach', 'number': '2'}"
"In order to measure the annotation quality, we use the following metric to measure the inter-annotator agreement, which is also used by Wiebe et al. (2005). as the result, the local words are not involved in In this section, we describe the annotated corpus and experiment configurations including baseline We conducted experiments with labeled corpus which are selected from Hu and Liu (2004), Jindal and Liu (2008) have built.","{'title': '2 The Approach', 'number': '2'}"
"Their documents are collected from Amazon.com and CNet.com, where products have a large number of reviews.","{'title': '2 The Approach', 'number': '2'}"
They also manually labeled product features and polarity orientations.,"{'title': '2 The Approach', 'number': '2'}"
"Our corpus is selected from them, which contains customer reviews of 11 products belong to 5 categories(Diaper, Cell Phone, Digital Camera, DVD Player, and MP3 Player).","{'title': '2 The Approach', 'number': '2'}"
Table 1 gives the detail statistics.,"{'title': '2 The Approach', 'number': '2'}"
"Since we need to evaluate not only the product features but also the opinion expressions and relations between them, we asked two annotators to annotate them independently.","{'title': '2 The Approach', 'number': '2'}"
The annotators started from identifying product features.,"{'title': '2 The Approach', 'number': '2'}"
"Then for each product feature, they annotated the opinion expression which has relation with it.","{'title': '2 The Approach', 'number': '2'}"
"Finally, one Features for match function where agr(a||b) represents the inter-annotator agreement between annotator a and b, A and B are the sets of anchors annotated by annotators a and b. agr(A1||A2) was 85.9% and agr(A2||A1) was 89.5%.","{'title': '2 The Approach', 'number': '2'}"
It indicates that the reliability of our annotated corpus is satisfactory.,"{'title': '2 The Approach', 'number': '2'}"
Results of extracting product features and opinion expressions are shown in Table 2.,"{'title': '2 The Approach', 'number': '2'}"
"We use precision, recall and F-measure to evaluate performances.","{'title': '2 The Approach', 'number': '2'}"
"The candidate product features are extracted by the method described in Section 2.2, whose result is in the first row.","{'title': '2 The Approach', 'number': '2'}"
"6760 of 24414 candidate product features remained after the filtering, which means we cut 72% of irrelevant candidates with a cost of 14.5%(1-85.5%) loss in true answers.","{'title': '2 The Approach', 'number': '2'}"
"Similar to the product feature extraction, the precision of extracting opinion expression is relatively low, while the recall is 75.2%.","{'title': '2 The Approach', 'number': '2'}"
"Since both product features and opinion expressions extractions are preprocessing steps, recall is more important.","{'title': '2 The Approach', 'number': '2'}"
"In order to compare with state-of-the-art results, we also evaluated the following methods.","{'title': '2 The Approach', 'number': '2'}"
Table 5 shows the performances of different relation extraction methods with in-domain data.,"{'title': '2 The Approach', 'number': '2'}"
"For each domain, we conducted 5-fold cross validation.","{'title': '2 The Approach', 'number': '2'}"
Table 6 shows the performances of the extraction methods on cross-domain data.,"{'title': '2 The Approach', 'number': '2'}"
We use the digital camera and cell phone domain as training set.,"{'title': '2 The Approach', 'number': '2'}"
The other domains are used as testing set.,"{'title': '2 The Approach', 'number': '2'}"
Table 5 presents different methods’ results in five domains.,"{'title': '3.3.2 Results Discussion', 'number': '3'}"
"We observe that the three learning based methods(SVM-1, SVM-WTree, SVM-PTree) perform better than the Adjacent baseline in the first three domains.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"However, in other domains, directly adjacent method is better than the learning based methods.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
The main difference between the first three domains and the last two domains is the size of data(Table 1).,"{'title': '3.3.2 Results Discussion', 'number': '3'}"
It implies that the simple Adjacent method is also competent when the training set is small.,"{'title': '3.3.2 Results Discussion', 'number': '3'}"
"A further inspection into the result of first 3 domains, we can also conclude that: 1) Tree kernels(SVM-WTree and SVM-PTree) are better than Adjacent, SVM-1 and SVM-2 in all domains.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
It proofs that the dependency tree is important in the opinion relation extraction.,"{'title': '3.3.2 Results Discussion', 'number': '3'}"
The reason for that is a connection between an opinion and its target can be discovered with various syntactic structures.,"{'title': '3.3.2 Results Discussion', 'number': '3'}"
2) The kernel defined on phrase dependency tree (SVM-PTree) outperforms kernel defined on word level dependency tree(SVMWTree) by 4.8% in average.,"{'title': '3.3.2 Results Discussion', 'number': '3'}"
"We believe the main reason is that phrase dependency tree provides a more succinct tree structure, and the separative treatment of local dependencies and global dependencies in kernel computation can indeed improve the performance of relation extraction.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"To analysis the results of preprocessing steps’ influences on the following relation extraction, we provide 2 additional experiments which the product features and opinion expressions are all correctly extracted respectively: OERight and PFRight.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"These two results show that given an exactly extraction of opinion expression and product feature, the results of opinion relation extraction will be much better.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"Further, opinion expressions are more influential which naturally means the opinion expressions are crucial in opinion relation extraction.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"For evaluations on cross domain, the Adjacent method doesn’t need training data, its results are the same as the in-domain experiments.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"Note in Table 3 and Table 4, we don’t use domain related features in SVM-1, SVM-WTree, SVMPTree, but SVM-2’s features are domain dependent.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"Since the cross-domain training set is larger than the original one in Diaper and DVD domain, the models are trained more sufficiently.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"The final results on cross-domain are even better than in-domain experiments on SVM-1, SVM-WTree, and SVM-PTree with percentage of 4.6%, 8.6%, 10.3% in average.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"And the cross-domain training set is smaller than in-domain in MP3, but it also achieve competitive performance with the in-domain.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"On the other hand, SVM-2’s result decreased compared with the in-domain experiments because the test domain changed.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
"At the same time, SVM-PTree outperforms other methods which is similar in in-domain experiments.","{'title': '3.3.2 Results Discussion', 'number': '3'}"
Opinion mining has recently received considerable attention.,"{'title': '4 Related Work', 'number': '4'}"
"Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).","{'title': '4 Related Work', 'number': '4'}"
"While we focus on extracting product features, opinion expressions and mining relations in this paper.","{'title': '4 Related Work', 'number': '4'}"
"Kobayashi et al. (2007) presented their work on extracting opinion units including: opinion holder, subject, aspect and evaluation.","{'title': '4 Related Work', 'number': '4'}"
"Subject and aspect belong to product features, while evaluation is the opinion expression in our work.","{'title': '4 Related Work', 'number': '4'}"
They converted the task to two kinds of relation extraction tasks and proposed a machine learning-based method which combines contextual clues and statistical clues.,"{'title': '4 Related Work', 'number': '4'}"
Their experimental results showed that the model using contextual clues improved the performance.,"{'title': '4 Related Work', 'number': '4'}"
"However since the contextual information in a domain is specific, the model got by their approach can not easily converted to other domains.","{'title': '4 Related Work', 'number': '4'}"
Choi et al. (2006) used an integer linear programming approach to jointly extract entities and relations in the context of opinion oriented information extraction.,"{'title': '4 Related Work', 'number': '4'}"
"They identified expressions of opinions, sources of opinions and the linking relation that exists between them.","{'title': '4 Related Work', 'number': '4'}"
The sources of opinions denote to the person or entity that holds the opinion.,"{'title': '4 Related Work', 'number': '4'}"
"Another area related to our work is opinion expressions identification (Wilson et al., 2005a; Breck et al., 2007).","{'title': '4 Related Work', 'number': '4'}"
They worked on identifying the words and phrases that express opinions in text.,"{'title': '4 Related Work', 'number': '4'}"
"According to Wiebe et al. (2005), there are two types of opinion expressions, direct subjective expressions and expressive subjective elements.","{'title': '4 Related Work', 'number': '4'}"
"In this paper, we described our work on mining opinions from unstructured documents.","{'title': '5 Conclusions', 'number': '5'}"
We focused on extracting relations between product features and opinion expressions.,"{'title': '5 Conclusions', 'number': '5'}"
The novelties of our work included: 1) we defined the phrase dependency parsing and proposed an approach to construct the phrase dependency trees; 2) we proposed a new tree kernel function to model the phrase dependency trees.,"{'title': '5 Conclusions', 'number': '5'}"
Experimental results show that our approach improved the performances of the mining task.,"{'title': '5 Conclusions', 'number': '5'}"
"This work was (partially) funded by Chinese NSF 60673038, Doctoral Fund of Ministry of Education of China 200802460066, and Shanghai Science and Technology Development Funds 08511500302.","{'title': '6 Acknowledgement', 'number': '6'}"
The authors would like to thank the reviewers for their useful comments.,"{'title': '6 Acknowledgement', 'number': '6'}"
