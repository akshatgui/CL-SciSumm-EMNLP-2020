col1,col2
Automated identification of diverse sen timent types can be beneficial for manyNLP systems such as review summariza tion and public media analysis.,{}
In some ofthese systems there is an option of assign ing a sentiment value to a single sentence or a very short text.,{}
"In this paper we propose a supervised sentiment classification framework whichis based on data from Twitter, a popu lar microblogging service.",{}
"By utilizing50 Twitter tags and 15 smileys as sen timent labels, this framework avoids theneed for labor intensive manual annotation, allowing identification and classifi cation of diverse sentiment types of shorttexts.",{}
We evaluate the contribution of different feature types for sentiment classification and show that our framework successfully identifies sentiment types of untagged sentences.,{}
The quality of the senti ment identification was also confirmed byhuman judges.,{}
We also explore dependencies and overlap between different sen timent types represented by smileys and Twitter hashtags.,{}
"A huge amount of social media including news,forums, product reviews and blogs contain nu merous sentiment-based sentences.","{'title': 'Introduction', 'number': '1'}"
Sentiment is defined as ?a personal belief or judgment that ?* Both authors equally contributed to this paper.is not founded on proof or certainty?1.,"{'title': 'Introduction', 'number': '1'}"
Senti ment expressions may describe the mood of thewriter (happy/sad/bored/grateful/...),"{'title': 'Introduction', 'number': '1'}"
"or the opin ion of the writer towards some specific entity (X is great/I hate X, etc.).","{'title': 'Introduction', 'number': '1'}"
"Automated identification of diverse sentimenttypes can be beneficial for many NLP systems such as review summarization systems, dia logue systems and public media analysis systems.","{'title': 'Introduction', 'number': '1'}"
Sometimes it is directly requested by the user toobtain articles or sentences with a certain senti ment value (e.g Give me all positive reviews of product X/ Show me articles which explain why movie X is boring).,"{'title': 'Introduction', 'number': '1'}"
In some other cases obtaining sentiment value can greatly enhance information extraction tasks like review summarization.,"{'title': 'Introduction', 'number': '1'}"
"Whilethe majority of existing sentiment extraction sys tems focus on polarity identification (e.g., positive vs. negative reviews) or extraction of a handful of pre-specified mood labels, there are many useful and relatively unexplored sentiment types.","{'title': 'Introduction', 'number': '1'}"
Sentiment extraction systems usually require an extensive set of manually supplied sentiment words or a handcrafted sentiment-specific dataset.,"{'title': 'Introduction', 'number': '1'}"
"With the recent popularity of article tagging, some social media types like blogs allow users to add sentiment tags to articles.","{'title': 'Introduction', 'number': '1'}"
This allows to use blogsas a large user-labeled dataset for sentiment learning and identification.,"{'title': 'Introduction', 'number': '1'}"
"However, the set of sentiment tags in most blog platforms is somewhat re stricted.","{'title': 'Introduction', 'number': '1'}"
"Moreover, the assigned tag applies to the whole blog post while a finer grained sentiment extraction is needed (McDonald et al, 2007).With the recent popularity of the Twitter micro blogging service, a huge amount of frequently 1WordNet 2.1 definitions.","{'title': 'Introduction', 'number': '1'}"
241self-standing short textual sentences (tweets) became openly available for the research community.,"{'title': 'Introduction', 'number': '1'}"
Many of these tweets contain a wide vari ety of user-defined hashtags.,"{'title': 'Introduction', 'number': '1'}"
Some of these tagsare sentiment tags which assign one or more senti ment values to a tweet.,"{'title': 'Introduction', 'number': '1'}"
In this paper we propose away to utilize such tagged Twitter data for classi fication of a wide variety of sentiment types from text.,"{'title': 'Introduction', 'number': '1'}"
We utilize 50 Twitter tags and 15 smileys assentiment labels which allow us to build a classifier for dozens of sentiment types for short tex tual sentences.,"{'title': 'Introduction', 'number': '1'}"
"In our study we use four different feature types (punctuation, words, n-grams and patterns) for sentiment classification and evaluate the contribution of each feature type for this task.We show that our framework successfully identi fies sentiment types of the untagged tweets.","{'title': 'Introduction', 'number': '1'}"
We confirm the quality of our algorithm using human judges.,"{'title': 'Introduction', 'number': '1'}"
We also explore the dependencies and overlap between different sentiment types represented by smileys and Twitter tags.,"{'title': 'Introduction', 'number': '1'}"
Section 2 describes related work.,"{'title': 'Introduction', 'number': '1'}"
"Section 3 details classification features and the algorithm, while Section 4 describes the dataset and labels.","{'title': 'Introduction', 'number': '1'}"
"Automated and manual evaluation protocols and results are presented in Section 5, followed by a short discussion.","{'title': 'Introduction', 'number': '1'}"
"Sentiment analysis tasks typically combine twodifferent tasks: (1) Identifying sentiment expres sions, and (2) determining the polarity (sometimes called valence) of the expressed sentiment.","{'title': 'Related work. ', 'number': '2'}"
These tasks are closely related as the purpose of most works is to determine whether a sentence bears a positive or a negative (implicit or explicit) opinion about the target of the sentiment.,"{'title': 'Related work. ', 'number': '2'}"
"Several works (Wiebe, 2000; Turney, 2002;Riloff, 2003; Whitelaw et al, 2005) use lexical re sources and decide whether a sentence expressesa sentiment by the presence of lexical items (sen timent words).","{'title': 'Related work. ', 'number': '2'}"
"Others combine additional feature types for this decision (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Wilson et al, 2005; Bloom et al, 2007; McDonald et al, 2007; Titov and McDonald, 2008a; Melville et al, 2009).","{'title': 'Related work. ', 'number': '2'}"
"It was suggested that sentiment words may havedifferent senses (Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Wiebe and Mihal cea, 2006), thus word sense disambiguation can improve sentiment analysis systems (Akkaya et al., 2009).","{'title': 'Related work. ', 'number': '2'}"
All works mentioned above identifyevaluative sentiment expressions and their polar ity.,"{'title': 'Related work. ', 'number': '2'}"
"Another line of works aims at identifying abroader range of sentiment classes expressing various emotions such as happiness, sadness, boredom, fear, and gratitude, regardless (or in addi tion to) positive or negative evaluations.","{'title': 'Related work. ', 'number': '2'}"
"Mihalcea and Liu (2006) derive lists of words and phrases with happiness factor from a corpus of blog posts, where each post is annotated by the blogger with a mood label.","{'title': 'Related work. ', 'number': '2'}"
Balog et al (2006) use the mood annotation of blog posts coupled with news datain order to discover the events that drive the dom inant moods expressed in blogs.,"{'title': 'Related work. ', 'number': '2'}"
Mishne (2005) used an ontology of over 100 moods assigned to blog posts to classify blog texts according tomoods.,"{'title': 'Related work. ', 'number': '2'}"
"While (Mishne, 2005) classifies a blog entry (post), (Mihalcea and Liu, 2006) assign a hap piness factor to specific words and expressions.","{'title': 'Related work. ', 'number': '2'}"
Mishne used a much broader range of moods.,"{'title': 'Related work. ', 'number': '2'}"
"Strapparava and Mihalcea (2008) classify blogposts and news headlines to six sentiment cate gories.While most of the works on sentiment analysis focus on full text, some works address senti ment analysis in the phrasal and sentence level, see (Yu and Hatzivassiloglou, 2003; Wilson et al,2005; McDonald et al, 2007; Titov and McDon ald, 2008a; Titov and McDonald, 2008b; Wilson et al, 2009; Tsur et al, 2010) among others.","{'title': 'Related work. ', 'number': '2'}"
Only a few studies analyze the sentiment and polarity of tweets targeted at major brands.,"{'title': 'Related work. ', 'number': '2'}"
Jansenet al (2009) used a commercial sentiment analyzer as well as a manually labeled corpus.,"{'title': 'Related work. ', 'number': '2'}"
Davi dov et al (2010) analyze the use of the #sarcasmhashtag and its contribution to automatic recognition of sarcastic tweets.,"{'title': 'Related work. ', 'number': '2'}"
"To the best of our knowledge, there are no works employing Twitter hashtags to learn a wide range of emotions and the re lations between the different emotions.","{'title': 'Related work. ', 'number': '2'}"
242,"{'title': 'Related work. ', 'number': '2'}"
Below we propose a set of classification featuresand present the algorithm for sentiment classifica tion.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
3.1 Classification features.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"We utilize four basic feature types for sentimentclassification: single word features, n-gram fea tures, pattern features and punctuation features.For the classification, all feature types are com bined into a single feature vector.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
3.1.1 Word-based and n-gram-based features Each word appearing in a sentence serves as a binary feature with weight equal to the inverted count of this word in the Twitter corpus.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
We also took each consecutive word sequence containing2?5 words as a binary n-gram feature using a similar weighting strategy.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"Thus n-gram features al ways have a higher weight than features of their component words, and rare words have a higher weight than common words.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
Words or n-gramsappearing in less than 0.5% of the training set sen tences do not constitute a feature.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
ASCII smileys and other punctuation sequences containing two or more consecutive punctuation symbols were used as single-word features.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"Word features alsoinclude the substituted meta-words for URLs, ref erences and hashtags (see Subsection 4.1).","{'title': 'Sentiment classification framework. ', 'number': '3'}"
3.1.2 Pattern-based featuresOur main feature type is based on surface pat terns.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"For automated extraction of patterns, we followed the pattern definitions given in (Davidov and Rappoport, 2006).","{'title': 'Sentiment classification framework. ', 'number': '3'}"
We classified words into high-frequency words (HFWs) and content words (CWs).,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
A word whose corpus frequency is more (less) than FH (FC) is considered to be a HFW(CW).We estimate word frequency from the train ing set rather than from an external corpus.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"Unlike (Davidov and Rappoport, 2006), we consider allsingle punctuation characters or consecutive se quences of punctuation characters as HFWs.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"We also consider URL, REF, and HASHTAG tags as HFWs for pattern extraction.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
We define a pattern as an ordered sequence of high frequency words and slots for content words.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"Following (Davidov and Rappoport, 2008), the FH and FC thresholds were set to 1000 words per million (upper bound for FC) and 100 words per million (lower bound for FH )2.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
The patterns allow 2?6 HFWs and 1?5 slots forCWs.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"To avoid collection of patterns which capture only a part of a meaningful multiword ex pression, we require patterns to start and to end with a HFW.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
Thus a minimal pattern is of the form [HFW] [CW slot] [HFW].,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
For each sentenceit is possible to generate dozens of different pat terns that may overlap.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"As with words and n-gram features, we do not treat as features any patterns which appear in less than 0.5% of the training set sentences.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"Since each feature vector is based on a singlesentence (tweet), we would like to allow approximate pattern matching for enhancement of learn ing flexibility.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
The value of a pattern feature is estimated according the one of the following four scenarios3: ? ????????????????????????,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
1 count(p) : Exact match ? all the pattern components appear in the sentence in correct order without any additional words.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
count(p) : Sparse match ? same as exact match but additional non-matching words can be inserted between pattern components.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"??n N?count(p) : Incomplete match ? only n > 1 of N pattern components appear in the sentence, while some non-matching words can be inserted in-between.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
At least one of the appearing components should be a HFW.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
0 : No match ? nothing or only a single pattern component appears in the sentence.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
0 ? ?,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
1 and 0 ? ?,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"1 are parameters we use to assign reduced scores for imperfect matches.Since the patterns we use are relatively long, ex act matches are uncommon, and taking advantageof partial matches allows us to significantly re duce the sparsity of the feature vectors.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"We used ? = ? = 0.1 in all experiments.This pattern based framework was proven effi cient for sarcasm detection in (Tsur et al, 2010; 2Note that the FH and FC bounds allow overlap between some HFWs and CWs.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"See (Davidov and Rappoport, 2008) for a short discussion.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"3As with word and n-gram features, the maximal featureweight of a pattern p is defined as the inverse count of a pat tern in the complete Twitter corpus.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"243 Davidov et al, 2010).","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"3.1.3 Efficiency of feature selection Since we avoid selection of textual features which have a training set frequency below 0.5%, we perform feature selection incrementally, on each stage using the frequencies of the features obtained during the previous stages.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"Thus first we estimate the frequencies of single words in the training set, then we only consider creationof n-grams from single words with sufficient frequency, finally we only consider patterns composed from sufficiently frequent words and n grams.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"3.1.4 Punctuation-based features In addition to pattern-based features we used the following generic features: (1) Sentence length in words, (2) Number of ?!?","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"characters in the sentence, (3) Number of ???","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"characters in the sentence, (4) Number of quotes in the sentence, and (5) Number of capitalized/all capitals wordsin the sentence.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"All these features were normal ized by dividing them by the (maximal observed value times averaged maximal value of the other feature groups), thus the maximal weight of each of these features is equal to the averaged weight of a single pattern/word/n-gram feature.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
3.2 Classification algorithm.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
In order to assign a sentiment label to new exam ples in the test set we use a k-nearest neighbors(kNN)-like strategy.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
We construct a feature vec tor for each example in the training and the test set.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
We would like to assign a sentiment class toeach example in the test set.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"For each feature vec tor V in the test set, we compute the Euclidean distance to each of the matching vectors in the training set, where matching vectors are defined as ones which share at least one pattern/n-gram/word feature with v.Let ti, i = 1 . . .","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"k be the k vectors with low est Euclidean distance to v4 with assigned labels Li, i = 1 . . .","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"k. We calculate the mean distance d(ti, v) for this set of vectors and drop from the set up to five outliers for which the distance was more then twice the mean distance.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
The label assigned 4We used k = 10 for all experiments.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
to v is the label of the majority of the remaining vectors.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
"If a similar number of remaining vectors have different labels, we assigned to the test vector the most frequent of these labels according to their frequency in the dataset.","{'title': 'Sentiment classification framework. ', 'number': '3'}"
"If there are no matching vectors found for v, we assigned the default ?no sentiment?","{'title': 'Sentiment classification framework. ', 'number': '3'}"
label since there is significantly more non-sentiment sentences than sentiment sentences in Twitter.,"{'title': 'Sentiment classification framework. ', 'number': '3'}"
In our experiments we used an extensive Twit ter data collection as training and testing sets.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
In our training sets we utilize sentiment hashtags andsmileys as classification labels.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
Below we de scribe this dataset in detail.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
4.1 Twitter dataset.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
We have used a Twitter dataset generously pro vided to us by Brendan O?Connor.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"This dataset includes over 475 million tweets comprising roughly 15% of all public, non-?low quality?","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
tweets created from May 2009 to Jan 2010.Tweets are short sentences limited to 140 UTF 8 characters.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
All non-English tweets and tweets which contain less than 5 proper English words5 were removed from the dataset.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"Apart of simple text, tweets may contain URLaddresses, references to other Twitter users (ap pear as @<user>) or a content tags (also called hashtags) assigned by the tweeter (#<tag>)which we use as labels for our supervised clas sification framework.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"Two examples of typical tweets are: ?#ipad #sucks and 6,510 people agree.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"See more on Ipad sucks page: http://j.mp/4OiYyg??, and ?Pay nomind to those who talk behind ur back, it sim ply means that u?re 2 steps ahead.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
#ihatequotes?.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
Note that in the first example the hashtagged words are a grammatical part of the sentence (itbecomes meaningless without them) while #ihate qoutes of the second example is a mere sentiment label and not part of the sentence.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
Also note that hashtags can be composed of multiple words (with no spaces).,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
5Identification of proper English words was based on an available WN-based English dictionary 244 Category # of tags % agreement Strong sentiment 52 87 Likely sentiment 70 66 Context-dependent 110 61 Focused 45 75 No sentiment 3564 99 Table 1: Annotation results (2 judges) for the 3852 mostfrequent tweeter tags.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"The second column displays the av erage number of tags, and the last column shows % of tags annotated similarly by two judges.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"During preprocessing, we have replaced URL links, hashtags and references by URL/REF/TAG meta-words.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"This substitution obviously had some effect on the pattern recognition phase (see Section 3.1.2), however, our algorithm is robust enough to overcome this distortion.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
4.2 Hashtag-based sentiment labels.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
The Twitter dataset contains above 2.5 million dif ferent user-defined hashtags.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
Many tweets include more than a single tag and 3852 ?frequent?,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
tags appear in more than 1000 different tweets.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"Two human judges manually annotated these frequenttags into five different categories: 1 ? strong sen timent (e.g #sucks in the example above), 2 ?most likely sentiment (e.g., #notcute), 3 ? contextdependent sentiment (e.g., #shoutsout), 4 ? fo cused sentiment (e.g., #tmobilesucks where the target of the sentiment is part of the hashtag), and 5 ? no sentiment (e.g. #obama).","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
Table 1 shows annotation results and the percentage of similarly assigned values for each category.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
We selected 50 hashtags annotated ?1?,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
or ?2?by both judges.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
For each of these tags we automatically sampled 1000 tweets resulting in 50000 la beled tweets.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
We avoided sampling tweets which include more than one of the sampled hashtags.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
As a no-sentiment dataset we randomly sampled 10000 tweets with no hashtags/smileys from thewhole dataset assuming that such a random sam ple is unlikely to contain a significant amount of sentiment sentences.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
4.3 Smiley-based sentiment labels.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
While there exist many ?official?,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"lists of possibleASCII smileys, most of these smileys are infrequent or not commonly accepted and used as sen timent indicators by online communities.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
We used the Amazon Mechanical Turk (AMT) service in order to obtain a list of the most commonly used and unambiguous ASCII smileys.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
We asked each of ten AMT human subjects to provide at least 6 commonly used ASCII mood-indicating smileystogether with one or more single-word descrip tions of the smiley-related mood state.,"{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"From the obtained list of smileys we selected a subset of 15 smileys which were (1) provided by at least threehuman subjects, (2) described by at least two human subject using the same single-word descrip tion, and (3) appear at least 1000 times in our Twitter dataset.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
"We then sampled 1000 tweets foreach of these smileys, using these smileys as sentiment tags in the sentiment classification frame work described in the previous section.","{'title': 'Twitter dataset and sentiment tags. ', 'number': '4'}"
The purpose of our evaluation was to learn how well our framework can identify and distinguishbetween sentiment types defined by tags or smileys and to test if our framework can be successfully used to identify sentiment types in new un tagged sentences.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
5.1 Evaluation using cross-validation.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
In the first experiment we evaluated the consistency and quality of sentiment classification us ing cross-validation over the training set.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"Fullyautomated evaluation allowed us to test the performance of our algorithm under several dif ferent feature settings: Pn+W-M-Pt-, Pn+W+M-Pt-, Pn+W+M+Pt-, Pn-W-M-Pt+ and FULL, where +/?","{'title': 'Evaluation and Results. ', 'number': '5'}"
"stands for utilization/omission of the followingfeature types: Pn:punctuation, W:Word, M:n grams (M stands for ?multi?), Pt:patterns.","{'title': 'Evaluation and Results. ', 'number': '5'}"
FULL stands for utilization of all feature types.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"In this experimental setting, the training set was divided to 10 parts and a 10-fold cross validation test is executed.","{'title': 'Evaluation and Results. ', 'number': '5'}"
"Each time, we use 9 parts as thelabeled training data for feature selection and con struction of labeled vectors and the remaining part is used as a test set.","{'title': 'Evaluation and Results. ', 'number': '5'}"
The process was repeated tentimes.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"To avoid utilization of labels as strong fea tures in the test set, we removed all instances of involved label hashtags/smileys from the tweets used as the test set.","{'title': 'Evaluation and Results. ', 'number': '5'}"
245 Setup Smileys Hashtags random 0.06 0.02 Pn+W-M-Pt- 0.16 0.06 Pn+W+M-Pt- 0.25 0.15 Pn+W+M+Pt- 0.29 0.18 Pn-W-M-Pt+ 0.5 0.26 FULL 0.64 0.31 Table 2: Multi-class classification results for smileys andhashtags.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
The table shows averaged harmonic f-score for 10 fold cross validation.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
51 (16) sentiment classes were used for hashtags (smileys).,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Multi-class classification.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Under multi-class classification we attempt to assign a single label (51 labels in case of hashtags and 16 labels in case of smileys) to each of vectors in the test set.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Note that the random baseline for this task is 0.02 (0.06)for hashtags (smileys).,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Table 2 shows the perfor mance of our framework for these tasks.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Results are significantly above the random baseline and definitely nontrivial considering theequal class sizes in the test set.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"While still relatively low (0.31 for hashtags and 0.64 for smi leys), we observe much better performance forsmileys which is expected due to the lower num ber of sentiment types.","{'title': 'Evaluation and Results. ', 'number': '5'}"
The relatively low performance of hashtags can be explained by ambiguity of the hashtags andsome overlap of sentiments.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Examination of clas sified sentences reveals that many of them can be reasonably assigned to more than one of the available hashtags or smileys.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Thus a tweet ?I?mreading stuff that I DON?T understand again!,"{'title': 'Evaluation and Results. ', 'number': '5'}"
ha haha...wth am I doing?,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"may reasonably matchtags #sarcasm, #damn, #haha, #lol, #humor, #an gry etc. Close examination of the incorrectly classified examples also reveals that substantialamount of tweets utilize hashtags to explicitly in dicate the specific hashtagged sentiment, in these cases that no sentiment value could be perceived by readers unless indicated explicitly, e.g. ?De Blob game review posted on our blog.","{'title': 'Evaluation and Results. ', 'number': '5'}"
#fun?.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"Obviously, our framework fails to process such cases and captures noise since no sentiment datais present in the processed text labeled with a spe cific sentiment label.Binary classification.","{'title': 'Evaluation and Results. ', 'number': '5'}"
"In the binary classification experiments, we classified a sentence as either appropriate for a particular tag or as not bear Hashtags Avg #hate #jealous #cute #outrageous Pn+W-M-Pt- 0.57 0.6 0.55 0.63 0.53 Pn+W+M-Pt- 0.64 0.64 0.67 0.66 0.6 Pn+W+M+Pt- 0.69 0.66 0.67 0.69 0.64 Pn-W-M-Pt+ 0.73 0.75 0.7 0.69 0.69 FULL 0.8 0.83 0.76 0.71 0.78 Smileys Avg :) ; ) X( : d Pn+W-M-Pt- 0.64 0.66 0.67 0.56 0.65 Pn+W+M-Pt- 0.7 0.73 0.72 0.64 0.69 Pn+W+M+Pt- 0.7 0.74 0.75 0.66 0.69 Pn-W-M-Pt+ 0.75 0.78 0.75 0.68 0.72 FULL 0.86 0.87 0.9 0.74 0.81Table 3: Binary classification results for smileys and hashtags.","{'title': 'Evaluation and Results. ', 'number': '5'}"
Avg column shows averaged harmonic f-score for 10fold cross validation over all 50(15) sentiment hashtags (smi leys).,"{'title': 'Evaluation and Results. ', 'number': '5'}"
ing any sentiment6.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
For each of the 50 (15) labelsfor hashtags (smileys) we have performed a bi nary classification when providing as training/testsets only positive examples of the specific senti ment label together with non-sentiment examples.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Table 3 shows averaged results for this case and specific results for selected tags.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
We can see thatour framework successfully identifies diverse sentiment types.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"Obviously the results are much bet ter than those of multi-class classification, and the observed > 0.8 precision confirms the usefulnessof the proposed framework for sentiment classifi cation of a variety of different sentiment types.","{'title': 'Evaluation and Results. ', 'number': '5'}"
"We can see that even for binary classification settings, classification of smiley-labeled sentencesis a substantially easier task compared to classifi cation of hashtag-labeled tweets.","{'title': 'Evaluation and Results. ', 'number': '5'}"
"Comparing the contributed performance of different feature typeswe can see that punctuation, word and pattern features, each provide a substantial boost for classi fication quality while we observe only a marginalboost when adding n-grams as classification features.","{'title': 'Evaluation and Results. ', 'number': '5'}"
We can also see that pattern features contribute the performance more than all other fea tures together.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
5.2 Evaluation with human judges.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"In the second set of experiments we evaluated our framework on a test set of unseen and untaggedtweets (thus tweets that were not part of the train 6Note that this is a useful application in itself, as a filter that extracts sentiment sentences from a corpus for further focused study/processing.","{'title': 'Evaluation and Results. ', 'number': '5'}"
"246 ing data), comparing its output to tags assigned by human judges.","{'title': 'Evaluation and Results. ', 'number': '5'}"
"We applied our framework with its FULL setting, learning the sentiment tags fromthe training set for hashtags and smileys (sepa rately) and executed the framework on the reduced Tweeter dataset (without untagged data) allowingit to identify at least five sentences for each senti ment class.In order to make the evaluation harsher, we re moved all tweets containing at least one of the relevant classification hashtags (or smileys).","{'title': 'Evaluation and Results. ', 'number': '5'}"
"For each of the resulting 250 sentences for hashtags,and 75 sentences for smileys we generated an ?as signment task?.","{'title': 'Evaluation and Results. ', 'number': '5'}"
Each task presents a human judgewith a sentence and a list of ten possible hash tags.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"One tag from this list was provided by ouralgorithm, 8 other tags were sampled from the re maining 49 (14) available sentiment tags, and the tenth tag is from the list of frequent non-sentiment tags (e.g. travel or obama).","{'title': 'Evaluation and Results. ', 'number': '5'}"
The human judge was requested to select the 0-2 most appropriate tags from the list.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Allowing assignment of multiple tags conforms to the observation that even short sentences may express several different sentimenttypes and to the observation that some of the selected sentiment tags might express similar senti ment types.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
We used the Amazon Mechanical Turk service to present the tasks to English-speaking subjects.Each subject was given 50 tasks for Twitter hash tags or 25 questions for smileys.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"To ensure the quality of assignments, we added to each test fivemanually selected, clearly sentiment bearing, as signment tasks from the tagged Twitter sentences used in the training set.","{'title': 'Evaluation and Results. ', 'number': '5'}"
Each set was presented to four subjects.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
If a human subject failed to provide the intended ?correct?,"{'title': 'Evaluation and Results. ', 'number': '5'}"
answer to at least two of the control set questions we reject him/her from the calculation.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
In our evaluation the algorithmis considered to be correct if one of the tags se lected by a human judge was also selected by thealgorithm.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Table 4 shows results for human judge ment classification.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
The agreement score for this task was ? = 0.41 (we consider agreement when at least one of two selected items are shared).,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Table 4 shows that the majority of tags selectedby humans matched those selected by the algo rithm.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Precision of smiley tags is substantially Setup % Correct % No sentiment Control Smileys 84% 6% 92% Hashtags 77% 10% 90%Table 4: Results of human evaluation.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
The second col umn indicates percentage of sentences where judges find noappropriate tags from the list.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
The third column shows per formance on the control set.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Hashtags #happy #sad #crazy # bored#sad 0.67 - - #crazy 0.67 0.25 - #bored 0.05 0.42 0.35 #fun 1.21 0.06 1.17 0.43 Smileys :) ; ) : ( X(; ) 3.35 - - : ( 3.12 0.53 - X( 1.74 0.47 2.18 : S 1.74 0.42 1.4 0.15 Table 5: Percentage of co-appearance of tags in tweeter corpus.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"higher than of hashtag labels, due to the lessernumber of possible smileys and the lesser ambi guity of smileys in comparison to hashtags.","{'title': 'Evaluation and Results. ', 'number': '5'}"
5.3 Exploration of feature dependencies.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Our algorithm assigns a single sentiment type for each tweet.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"However, as discussed above, some sentiment types overlap (e.g., #awesome and #amazing).","{'title': 'Evaluation and Results. ', 'number': '5'}"
"Many sentences may express several types of sentiment (e.g., #fun and #scary in ?Oh My God http://goo.gl/fb/K2N5z #entertainment #fun #pictures #photography #scary #teaparty?).","{'title': 'Evaluation and Results. ', 'number': '5'}"
We would like to estimate such inter-sentiment dependencies and overlap automatically from the labeled data.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
We use two different methods for overlap estimation: tag co-occurrence and feature overlap.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
5.3.1 Tag co-occurrenceMany tweets contain more than a single hashtag or a single smiley type.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"As mentioned, we ex clude such tweets from the training set to reduce ambiguity.","{'title': 'Evaluation and Results. ', 'number': '5'}"
However such tag co-appearances canbe used for sentiment overlap estimation.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
We cal culated the relative co-occurrence frequencies of some hashtags and smileys.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Table 5 shows some of the observed co-appearance ratios.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
As expected some of the observed tags frequently co-appear with other similar tags.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
247 Hashtags #happy #sad #crazy # bored#sad 12.8 - - #crazy 14.2 3.5 - #bored 2.4 11.1 2.1 #fun 19.6 2.1 15 4.4 Smileys :) ; ) : ( X(; ) 35.9 - - : ( 31.9 10.5 - X( 8.1 10.2 36 : S 10.5 12.6 21.6 6.1 Table 6: Percentage of shared features in feature vectors for different tags.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"Interestingly, it appears that a relatively high ratio of co-appearance of tags is with opposite meanings (e.g., ?#ilove eating but #ihate feeling fat lol?","{'title': 'Evaluation and Results. ', 'number': '5'}"
or ?happy days of training going to end in a few days #sad #happy?).,"{'title': 'Evaluation and Results. ', 'number': '5'}"
This is possibly due to frequently expressed contrast sentiment types in the same sentence ? a fascinating phenomenareflecting the great complexity of the human emo tional state (and expression).,"{'title': 'Evaluation and Results. ', 'number': '5'}"
5.3.2 Feature overlapIn our framework we have created a set of fea ture vectors for each of the Twitter sentiment tags.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Comparison of shared features in feature vector sets allows us to estimate dependencies betweendifferent sentiment types even when direct tag cooccurrence data is very sparse.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
A feature is considered to be shared between two different senti ment labels if for both sentiment labels there is at least a single example in the training set whichhas a positive value of this feature.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
In order to automatically analyze such dependencies we calcu late the percentage of sharedWord/n-gram/Pattern features between different sentiment labels.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
Table 6 shows the observed feature overlap values for selected sentiment tags.,"{'title': 'Evaluation and Results. ', 'number': '5'}"
"We observe the trend of results obtained by comparison of shared feature vectors is similar to those obtained by means of label co-occurrence, although the numbers of the shared features arehigher.","{'title': 'Evaluation and Results. ', 'number': '5'}"
"These results, demonstrating the patternbased similarity of conflicting, sometimes contradicting, emotions are interesting from a psycho logical and cognitive perspective.","{'title': 'Evaluation and Results. ', 'number': '5'}"
We presented a framework which allows an au tomatic identification and classification of various sentiment types in short text fragments which isbased on Twitter data.,"{'title': 'Conclusion. ', 'number': '6'}"
Our framework is a su pervised classification one which utilizes Twitterhashtags and smileys as training labels.,"{'title': 'Conclusion. ', 'number': '6'}"
"The substantial coverage and size of the processed Twitter data allowed us to identify dozens of senti ment types without any labor-intensive manuallylabeled training sets or pre-provided sentiment specific features or sentiment words.We evaluated diverse feature types for senti ment extraction including punctuation, patterns,words and n-grams, confirming that each feature type contributes to the sentiment classifica tion framework.","{'title': 'Conclusion. ', 'number': '6'}"
We also proposed two different methods which allow an automatic identification of sentiment type overlap and inter-dependencies.In the future these methods can be used for automated clustering of sentiment types and senti ment dependency rules.,"{'title': 'Conclusion. ', 'number': '6'}"
"While hashtag labels arespecific to Twitter data, the obtained feature vectors are not heavily Twitter-specific and in the fu ture we would like to explore the applicability ofTwitter data for sentiment multi-class identifica tion and classification in other domains.","{'title': 'Conclusion. ', 'number': '6'}"
