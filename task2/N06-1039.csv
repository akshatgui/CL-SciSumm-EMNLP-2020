col1,col2
surface text patterns for a question answering system. of the 40th Annual Meeting of the As,Introduction
"Every day, a large number of news articles are created and reported, many of which are unique.",Experiment/Discussion
"But certain types of events, such as hurricanes or murders, are reported again and again throughout a year.",Experiment/Discussion
"The goal of Information Extraction, or IE, is to retrieve a certain type of news event from past articles and present the events as a table whose columns are filled with a name of a person or company, according to its role in the event.",Experiment/Discussion
"However, existing IE techniques require a lot of human labor.",Experiment/Discussion
"First, you have to specify the type of information you want and collect articles that include this information.",Experiment/Discussion
"Then, you have to analyze the articles and manually craft a set of patterns to capture these events.",Experiment/Discussion
Most existing IE research focuses on reducing this burden by helping people create such patterns.,Experiment/Discussion
"But each time you want to extract a different kind of information, you need to repeat the whole process: specify articles and adjust its patterns, either manually or semiautomatically.",Experiment/Discussion
There is a bit of a dangerous pitfall here.,Experiment/Discussion
"First, it is hard to estimate how good the system can be after months of work.",Experiment/Discussion
"Furthermore, you might not know if the task is even doable in the first place.",Experiment/Discussion
Knowing what kind of information is easily obtained in advance would help reduce this risk.,Experiment/Discussion
An IE task can be defined as finding a relation among several entities involved in a certain type of event.,Experiment/Discussion
"For example, in the MUC-6 management succession scenario, one seeks a relation between COMPANY, PERSON and POST involved with hiring/firing events.",Experiment/Discussion
"For each row of an extracted table, you can always read it as “COMPANY hired (or fired) PERSON for POST.” The relation between these entities is retained throughout the table.",Experiment/Discussion
"There are many existing works on obtaining extraction patterns for pre-defined relations (Riloff, 1996; Yangarber et al., 2000; Agichtein and Gravano, 2000; Sudo et al., 2003).",Experiment/Discussion
"Unrestricted Relation Discovery is a technique to automatically discover such relations that repeatedly appear in a corpus and present them as a table, with absolutely no human intervention.",Experiment/Discussion
"Unlike most existing IE research, a user does not specify the type of articles or information wanted.",Experiment/Discussion
"Instead, a system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form.",Experiment/Discussion
This technique will open up the possibility of trying new IE scenarios.,Experiment/Discussion
"Furthermore, the system itself can be used as an IE system, since an obtained relation is already presented as a table.",Experiment/Discussion
"If this system works to a certain extent, tuning an IE system becomes a search problem: all the tables are already built “preemptively.” A user only needs to search for a relevant table.",Experiment/Discussion
We implemented a preliminary system for this technique and obtained reasonably good performance.,Experiment/Discussion
Table 1 is a sample relation that was extracted as a table by our system.,Experiment/Discussion
"The columns of the table show article dates, names of hurricanes and the places they affected respectively.",Experiment/Discussion
The headers of the table and its keywords were also extracted automatically.,Experiment/Discussion
"In Unrestricted Relation Discovery, the discovery process (i.e. creating new tables) can be formulated as a clustering task.",Experiment/Discussion
The key idea is to cluster a set of articles that contain entities bearing a similar relation to each other in such a way that we can construct a table where the entities that play the same role are placed in the same column.,Experiment/Discussion
"Suppose that there are two articles A and B, and both report hurricane-related news.",Experiment/Discussion
"Article A contains two entities “Katrina” and “New Orleans”, and article B contains “Longwang” and “Taiwan”.",Experiment/Discussion
These entities are recognized by a Named Entity (NE) tagger.,Experiment/Discussion
We want to discover a relation among them.,Experiment/Discussion
"First, we introduce a notion called “basic pattern” to form a relation.",Experiment/Discussion
A basic pattern is a part of the text that is syntactically connected to an entity.,Experiment/Discussion
Some examples are “X is hit” or “Y’s residents”.,Experiment/Discussion
Figure 1 shows several basic patterns connected to the entities “Katrina” and “New Orleans” in article A.,Experiment/Discussion
"Similarly, we obtain the basic patterns for article B.",Experiment/Discussion
"Now, in Figure 2, both entities “Katrina” and “Longwang” have the basic pattern “headed” in common.",Experiment/Discussion
"In this case, we connect these two entities to each other.",Experiment/Discussion
"Furthermore, there is also a common basic pattern “was-hit” shared by “New Orleans” and “Taiwan”.",Experiment/Discussion
"Now, we found two sets of entities that can be placed in correspondence at the same time.",Experiment/Discussion
What does this mean?,Experiment/Discussion
We can infer that both entity sets (“Katrina”-“New Orleans” and “Longwang”-“Taiwan”) represent a certain relation that has something in common: a hurricane name and the place it affected.,Experiment/Discussion
"By finding multiple parallel correspondences between two articles, we can estimate the similarity of their relations.",Experiment/Discussion
"Generally, in a clustering task, one groups items by finding similar pairs.",Experiment/Discussion
"After finding a pair of articles that have a similar relation, we can bring them into the same cluster.",Experiment/Discussion
"In this case, we cluster articles by using their basic patterns as features.",Experiment/Discussion
"However, each basic pattern is still connected to its entity so that we can extract the name from it.",Experiment/Discussion
We can consider a basic pattern to represent something like the “role” of its entity.,Experiment/Discussion
"In this example, the entities that had “headed” as a basic pattern are hurricanes, and the entities that had “was-hit” as a basic pattern are the places it affected.",Experiment/Discussion
"By using basic patterns, we can align the entities into the corresponding column that represents a certain role in the relation.",Experiment/Discussion
"From this example, we create a two-by-two table, where each column represents the roles of the entities, and each row represents a different article, as shown in the bottom of Figure 2.",Experiment/Discussion
We can extend this table by finding another article in the same manner.,Experiment/Discussion
"In this way, we gradually extend a table while retaining a relation among its columns.",Experiment/Discussion
"In this example, the obtained table is just what an IE system (whose task is to find a hurricane name and the affected place) would create.",Experiment/Discussion
"However, these articles might also include other things, which could represent different relations.",Experiment/Discussion
"For example, the governments might call for help or some casualties might have been reported.",Experiment/Discussion
"To obtain such relations, we need to choose different entities from the articles.",Experiment/Discussion
"Several existing works have tried to extract a certain type of relation by manually choosing different pairs of entities (Brin, 1998; Ravichandran and Hovy, 2002).",Experiment/Discussion
Hasegawa et al. (2004) tried to extract multiple relations by choosing entity types.,Experiment/Discussion
"We assume that we can find such relations by trying all possible combinations from a set of entities we have chosen in advance; some combinations might represent a hurricane and government relation, and others might represent a place and its casualties.",Experiment/Discussion
"To ensure that an article can have several different relations, we let each article belong to several different clusters.",Experiment/Discussion
"In a real-world situation, only using basic patterns sometimes gives undesired results.",Experiment/Discussion
"For example, “(President) Bush flew to Texas” and “(Hurricane) Katrina flew to New Orleans” both have a basic pattern “flew to” in common, so “Bush” and “Katrina” would be put into the same column.",Experiment/Discussion
But we want to separate them in different tables.,Experiment/Discussion
"To alleviate this problem, we put an additional restriction on clustering.",Experiment/Discussion
"We use a bag-of-words approach to discriminate two articles: if the word-based similarity between two articles is too small, we do not bring them together into the same cluster (i.e. table).",Experiment/Discussion
"We exclude names from the similarity calculation at this stage because we want to link articles about the same type of event, not the same instance.",Experiment/Discussion
"In addition, we use the frequency of each basic pattern to compute the similarity of relations, since basic patterns like “say” or “have” appear in almost every article and it is dangerous to rely on such expressions.",Experiment/Discussion
"In the above explanation, we have assumed that we can obtain enough basic patterns from an article.",Experiment/Discussion
"However, the actual number of basic patterns that one can find from a single article is usually not enough, because the number of sentences is rather small in comparison to the variation of expressions.",Experiment/Discussion
So having two articles that have multiple basic patterns in common is very unlikely.,Experiment/Discussion
We extend the number of articles for obtaining basic patterns by using a cluster of comparable articles that report the same event instead of a single article.,Experiment/Discussion
We call this cluster of articles a “basic cluster.” Using basic clusters instead of single articles also helps to increase the redundancy of data.,Experiment/Discussion
We can give more confidence to repeated basic patterns.,Experiment/Discussion
Note that the notion of “basic cluster” is different from the clusters used for creating tables explained above.,Experiment/Discussion
"In the following sections, a cluster for creating a table is called a “metacluster,” because this is a cluster of basic clusters.",Experiment/Discussion
"A basic cluster consists of a set of articles that report the same event which happens at a certain time, and a metacluster consists of a set of events that contain the same relation over a certain period.",Experiment/Discussion
We try to increase the number of articles in a basic cluster by looking at multiple news sources simultaneously.,Experiment/Discussion
We use a clustering algorithm that uses a vector-space-model to obtain basic clusters.,Experiment/Discussion
Then we apply cross-document coreference resolution to connect entities of different articles within a basic cluster.,Experiment/Discussion
"This way, we can increase the number of basic patterns connected to each entity.",Experiment/Discussion
"Also, it allows us to give a weight to entities.",Experiment/Discussion
We calculate their weights using the number of occurrences within a cluster and their position within an article.,Experiment/Discussion
These entities are used to obtain basic patterns later.,Experiment/Discussion
We also use a parser and tree normalizer to generate basic patterns.,Experiment/Discussion
The format of basic patterns is crucial to performance.,Experiment/Discussion
"We think a basic pattern should be somewhat specific, since each pattern should capture an entity with some relevant context.",Experiment/Discussion
But at the same time a basic pattern should be general enough to reduce data sparseness.,Experiment/Discussion
We choose a predicate-argument structure as a natural solution for this problem.,Experiment/Discussion
"Compared to traditional constituent trees, a predicate-argument structure is a higher-level representation of sentences that has gained wide acceptance from the natural language community recently.",Experiment/Discussion
In this paper we used a logical feature structure called GLARF proposed by Meyers et al. (2001a).,Experiment/Discussion
A GLARF converter takes a syntactic tree as an input and augments it with several features.,Experiment/Discussion
"Figure 3 shows a sample GLARF structure obtained from the sentence “Katrina hit Louisiana’s coast.” We used GLARF for two reasons: first, unlike traditional constituent parsers, GLARF has an ability to regularize several linguistic phenomena such as participial constructions and coordination.",Experiment/Discussion
This allows us to handle this syntactic variety in a uniform way.,Experiment/Discussion
"Second, an output structure can be easily converted into a directed graph that represents the relationship between each word, without losing significant information from the original sentence.",Experiment/Discussion
"Compared to an ordinary constituent tree, it is easier to extract syntactic relationships.",Experiment/Discussion
"In the next section, we discuss how we used this structure to generate basic patterns.",Experiment/Discussion
The overall process to generate basic patterns and discover relations from unannotated news articles is shown in Figure 4.,Experiment/Discussion
"Theoretically this could be a straight pipeline, but due to the nature of the implementation we process some stages separately and combine them in the later stage.",Experiment/Discussion
"In the following subsection, we explain each component.",Experiment/Discussion
"First of all, we need a lot of news articles from multiple news sources.",Experiment/Discussion
We created a simple web crawler that extract the main texts from web pages.,Experiment/Discussion
We observed that the crawler can correctly take the main texts from about 90% of the pages from each news site.,Experiment/Discussion
We ran the crawler every day on several news sites.,Experiment/Discussion
Then we applied a simple clustering algorithm to the obtained articles in order to find a set of articles that talk about exactly the same news and form a basic cluster.,Experiment/Discussion
"We eliminate stop words and stem all the other words, then compute the similarity between two articles by using a bag-of-words approach.",Experiment/Discussion
"In news articles, a sentence that appears in the beginning of an article is usually more important than the others.",Experiment/Discussion
So we preserved the word order to take into account the location of each sentence.,Experiment/Discussion
"First we computed a word vector from each article: where Vw(A) is a vector element of word w in article A, IDF(w) is the inverse document frequency of word w, and POS(w, A) is a list of w’s positions in the article. avgwords is the average number of words for all articles.",Experiment/Discussion
"Then we calculated the cosine value of each pair of vectors: We computed the similarity of all possible pairs of articles from the same day, and selected the pairs whose similarity exceeded a certain threshold (0.65 in this experiment) to form a basic cluster.",Experiment/Discussion
"After getting a set of basic clusters, we pass them to an existing statistical parser (Charniak, 2000) and rule-based tree normalizer to obtain a GLARF structure for each sentence in every article.",Experiment/Discussion
The current implementation of a GLARF converter gives about 75% F-score using parser output.,Experiment/Discussion
"For the details of GLARF representation and its conversion, see Meyers et al. (2001b).",Experiment/Discussion
"In parallel with parsing and GLARFing, we also apply NE tagging and coreference resolution for each article in a basic cluster.",Experiment/Discussion
We used an HMM-based NE tagger whose performance is about 85% in Fscore.,Experiment/Discussion
"This NE tagger produces ACE-type Named Entities 1: PERSON, ORGANIZATION, GPE, LOCATION and FACILITY 2.",Experiment/Discussion
"After applying singledocument coreference resolution for each article, we connect the entities among different articles in the same basic cluster to obtain cross-document coreference entities with simple string matching.",Experiment/Discussion
"After getting a GLARF structure for each sentence and a set of documents whose entities are tagged and connected to each other, we merge the two outputs and create a big network of GLARF structures whose nodes are interconnected across different sentences/articles.",Experiment/Discussion
Now we can generate basic patterns for each entity.,Experiment/Discussion
"First, we compute the weight for each cross-document entity E in a certain basic cluster as follows: where e ∈ E is an entity within one article and mentions(e) and firstsent(e) are the number of mentions of entity e in a document and the position of the sentence where entity e first appeared, respectively.",Experiment/Discussion
C is a constant value which was 0.5 in this experiment.,Experiment/Discussion
"To reduce combinatorial complexity, we took only the five most highly weighted entities from each basic cluster to generate basic patterns.",Experiment/Discussion
We observed these five entities can cover major relations that are reported in a basic cluster.,Experiment/Discussion
"Next, we obtain basic patterns from the GLARF structures.",Experiment/Discussion
"We used only the first ten sentences in each article for getting basic patterns, as most important facts are usually written in the first few sentences of a news article.",Experiment/Discussion
Figure 5 shows all the basic patterns obtained from the sentence “Katrina hit Louisiana’s coast.” The shaded nodes “Katrina” and “Louisiana” are entities from which each basic pattern originates.,Experiment/Discussion
"We take a path of GLARF nodes from each entity node until it reaches any predicative node: noun, verb, or adjective in this case.",Experiment/Discussion
"Since the nodes “hit” and “coast” can be predicates in this example, we obtain three unique paths “Louisiana+T-POS:coast (Louisiana’s coast)”, “Katrina+SBJ:hit (Katrina hit something)”, and “Katrina+SBJ:hit-OBJ:coast (Katrina hit some coast)”.",Experiment/Discussion
"To increase the specificity of patterns, we generate extra basic patterns by adding a node that is immediately connected to a predicative node.",Experiment/Discussion
"(From this example, we generate two basic patterns: “hit” and “hit-coast” from the “Katrina” node.)",Experiment/Discussion
"Notice that in a GLARF structure, the type of each argument such as subject or object is preserved in an edge even if we extract a single path of a graph.",Experiment/Discussion
"Now, we replace both entities “Katrina” and “Louisiana” with variables based on their NE tags and obtain parameterized patterns: “GPE+T-POS:coast (Louisiana’s coast)”, “PER+SBJ:hit (Katrina hit something)”, and “PER+SBJ:hit-OBJ:coast (Katrina hit some coast)”.",Experiment/Discussion
"After taking all the basic patterns from every basic cluster, we compute the Inverse Cluster Frequency (ICF) of each unique basic pattern.",Experiment/Discussion
"ICF is similar to the Inverse Document Frequency (IDF) of words, which is used to calculate the weight of each basic pattern for metaclustering.",Experiment/Discussion
"Finally, we can perform metaclustering to obtain tables.",Experiment/Discussion
"We compute the similarity between each basic cluster pair, as seen in Figure 6.",Experiment/Discussion
"XA and XB are the set of cross-document entities from basic clusters cA and cB, respectively.",Experiment/Discussion
"We examine all possible mappings of relations (parallel mappings of multiple entities) from both basic clusters, and find all the mappings M whose similarity score exceeds a certain threshold. wordsim(cA, cB) is the bag-of-words similarity of two clusters.",Experiment/Discussion
"As a weighting function we used ICF: We then sort the similarities of all possible pairs of basic clusters, and try to build a metacluster by taking the most strongly connected pair first.",Experiment/Discussion
Note that in this process we may assign one basic cluster to several different metaclusters.,Experiment/Discussion
"When a link is found between two basic clusters that were already assigned to a metacluster, we try to put them into all the existing metaclusters it belongs to.",Experiment/Discussion
"However, we allow a basic cluster to be added only if it can fill all the columns in that table.",Experiment/Discussion
"In other words, the first two basic clusters (i.e. an initial two-row table) determines its columns and therefore define the relation of that table.",Experiment/Discussion
"We used twelve newspapers published mainly in the U.S. We collected their articles over two months (from Sep. 21, 2005 - Nov. 27, 2005).",Experiment/Discussion
"We obtained 643,767 basic patterns and 7,990 unique types.",Experiment/Discussion
Then we applied metaclustering to these basic clusters and obtained 302 metaclusters (tables).,Experiment/Discussion
We then removed duplicated rows and took only the tables that had 3 or more rows.,Experiment/Discussion
Finally we had 101 tables.,Experiment/Discussion
The total number the of articles and clusters we used are shown in Table 2.,Experiment/Discussion
We evaluated the obtained tables as follows.,Experiment/Discussion
"For each row in a table, we added a summary of the source articles that were used to extract the relation.",Experiment/Discussion
"Then for each table, an evaluator looks into every row and its source article, and tries to come up with a sentence that explains the relation among its columns.",Experiment/Discussion
The description should be as specific as possible.,Experiment/Discussion
"If at least half of the rows can fit the explanation, the table is considered “consistent.” For each consistent table, the evaluator wrote down the sentence using variable names ($1, $2, ...) to refer to its columns.",Experiment/Discussion
"Finally, we counted the number of consistent tables.",Experiment/Discussion
We also counted how many rows in each table can fit the explanation.,Experiment/Discussion
We evaluated 48 randomly chosen tables.,Experiment/Discussion
"Among these tables, we found that 36 tables were consistent.",Experiment/Discussion
"We also counted the total number of rows that fit each description, shown in Table 3.",Experiment/Discussion
Table 4 shows the descriptions of the selected tables.,Experiment/Discussion
The largest consistent table was about hurricanes (Table 5).,Experiment/Discussion
"Although we cannot exactly measure the recall of each table, we tried to estimate the recall by comparing this hurricane table to a manually created one (Table 6).",Experiment/Discussion
We found 6 out of 9 hurricanes 3.,Experiment/Discussion
It is worth noting that most of these hurricane names were automatically disambiguated although our NE tagger didn’t distinguish a hurricane name from a person ber of fitted/total rows. name.,Experiment/Discussion
The second largest table (about nominations of officials) is shown in Table 7.,Experiment/Discussion
We reviewed 10 incorrect rows from various tables and found 4 of them were due to coreference errors and one error was due to a parse error.,Experiment/Discussion
The other 4 errors were due to multiple basic patterns distant from each other that happened to refer to a different event reported in the same cluster.,Experiment/Discussion
The causes of the one remaining error was obscure.,Experiment/Discussion
Most inconsistent tables were a mixture of multiple relations and some of their rows still looked consistent.,Experiment/Discussion
We have a couple of open questions.,Experiment/Discussion
"First, the overall recall of our system might be lower than existing IE systems, as we are relying on a cluster of comparable articles rather than a single document to discover an event.",Experiment/Discussion
We might be able to improve this in the future by adjusting the basic clustering algorithm or weighting schema of basic patterns.,Experiment/Discussion
"Secondly, some combinations of basic patterns looked inherently vague.",Experiment/Discussion
"For example, we used the two basic patterns “pitched” and “’s-series” in the following sentence (the patterns are underlined): Ervin Santana pitched 5 1-3 gutsy innings in his postseason debut for the Angels, Adam Kennedy hit a goahead triple that sent Yankees outfielders crashing to the ground, and Los Angeles beat New York 5-3 Monday night in the decisive Game 5 of their AL playoff series.",Experiment/Discussion
It is not clear whether this set of patterns can yield any meaningful relation.,Experiment/Discussion
We are not sure how much this sort of table can affect overall IE performance.,Experiment/Discussion
In this paper we proposed Preemptive Information Extraction as a new direction of IE research.,Results/Conclusion
"As its key technique, we presented Unrestricted Relation Discovery that tries to find parallel correspondences between multiple entities in a document, and perform clustering using basic patterns as features.",Results/Conclusion
"To increase the number of basic patterns, we used a cluster of comparable articles instead of a single document.",Results/Conclusion
We presented the implementation of our preliminary system and its outputs.,Results/Conclusion
We obtained dozens of usable tables.,Results/Conclusion
Sep. and Nov. (from Wikipedia).,Results/Conclusion
Rows with a star (*) were actually extracted.,Results/Conclusion
The number of the source articles that contained a mention of the hurricane is shown in the right column.,Results/Conclusion
This research was supported by the National Science Foundation under Grant IIS-00325657.,Results/Conclusion
This paper does not necessarily reflect the position of the U.S. Government.,Results/Conclusion
We would like to thank Prof. Ralph Grishman who provided useful suggestions and discussions.,Results/Conclusion
