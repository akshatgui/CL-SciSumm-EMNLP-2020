col1,col2
"This document presents the results from Inst. of Computing Tech., CAS in the ACL- SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff.",{}
The authors introduce the unified HHMM-based frame of our Chinese lexical analyzer ICTCLAS and explain the operation of the six tracks.,{}
Then provide the evaluation results and give more analysis.,{}
Evaluation on ICTCLAS shows that its performance is competitive.,{}
"Compared with other system, ICTCLAS has ranked top both in CTB and PK closed track.",{}
"In PK open track, it ranks second position.",{}
"ICTCLAS BIG5 version was transformed from GB version only in two days; however, it achieved well in two BIG5 closed tracks.",{}
"Through the first bakeoff, we could learn more about the development in Chinese word segmentation and become more confident on our HHMM-based approach.",{}
"At the same time, we really find our problems during the evaluation.",{}
The bakeoff is interesting and helpful.,{}
"ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.","{'title': '1 Introduction', 'number': '1'}"
"We have taken six tracks: Academia Sinica closed (ASc), U. Penn Chinese Tree Bank open and closed(CTBo,c), Hong Kong CityU closed (HKc), Peking University open and closed(PKo,c).","{'title': '1 Introduction', 'number': '1'}"
The structure of this document is as follows.,"{'title': '1 Introduction', 'number': '1'}"
The next section presents the HHMM-based framework of ICTCLAS.,"{'title': '1 Introduction', 'number': '1'}"
Next we detail the operation of six tracks.,"{'title': '1 Introduction', 'number': '1'}"
The following section provides evaluation result and gives further analysis.,"{'title': '1 Introduction', 'number': '1'}"
2 HHMM-based Chinese lexical analysis,"{'title': '1 Introduction', 'number': '1'}"
"As illustrated in Figure 1, HHMM-based Chinese lexical analysis comprises five levels: atom segmentation, simple and recursive unknown words recognition, class-based segmentation and POS tagging.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"In the whole frame, class-based segmentation graph, which is a directed graph designed for word segmentation, is an essential intermediate data structure that links disambiguation, unknown words recognition with word segmentation and POS tagging.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"Atom segmentation, the bottom level of HHMM, is an initial step.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"Here, atom is defined to be the minimal segmentation unit that cannot be split in any stage.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"The atom consists of Chinese character, punctuation, symbol string, numeric expression and other non-Chinese char string.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
Any word is made up of an atom or more.,"{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
Atom segmentation is to segment original text into atom sequence and it provides pure and simple source for its parent HMM.,"{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"For instance, a sentence like &quot;2002.9,ICTCLAS (6,nEh:gfFApRtti&quot; (The free source codes of ICTCLAS was distributed in September, 2002) would be segmented as atom sequence &quot;2002.9/,/ICTCLAS/�J/n/Eh/�/q/fF /44M/M/�/&quot;.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"In this HMM, the original symbol is observation while the atom is state.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
We skip the detail of operation in that it's a simple application on the basis of HMM.,"{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
POS tagging and role tagging using Viterbi are also skipped because they are classic application of HMM.,"{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"Because of paper length limit, unknown words recognition is omitted.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"Suppose ILEXI to be the lexicon size, then the total number of word classes is ILEXI+9.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"Given the atom sequence A=(al,...an), let W=(wl,...wm) be the words sequence, C= (cl,...cm) be a corresponding class sequence of W, and W# be the choice of word segmentation with the maximized probability, respectively.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"Then, we could get: For a specific atom sequence A, P(A) is a constant and P(W,A)= P(W).","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"So, On the basis of Baye's Theorem, it can be induced that: where co is begin of sentence.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"For convenience, we often use the negative log probability instead of the proper form.","{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
That is:,"{'title': '2.1 ICTCLAS Framework', 'number': '2'}"
"We apply to word segmentation class-based HMM, which is a generalized approach covering both common words and unknown words. wi iff wi is listed in the segmentation lexicon; PER iff wi is unlisted� personal name; LOC iff wi is unlisted location name; ORG iff wi is unlisted organization name; TIME iff wi is unlisted time expression; NUM iff wi is unlisted numeric expression; STR iffwi is unlisted symbol string; BEG iff beginning of a sentence END iff ending of a sentence OTHER otherwise.","{'title': '2.2 Class-based HMM for word segmentation', 'number': '3'}"
"� &quot;unlisted&quot; is referred as being outside the lexicon According to the word class definition, if wi is listed in lexicon, then ci is wi, and p(wiIci) is equal to 1.0.Otherwise, p(wiIci) is probability that class ci initially activates wi , and it could be estimated in its child HMM for unknown words recognition.","{'title': '2.2 Class-based HMM for word segmentation', 'number': '3'}"
"As demonstrated in Figure 3, we provide the process of class-based word segmentation on &quot;Et MT,, 1893' 01&quot; (Mao Ze-Dong was born in the year of 1893).","{'title': '2.2 Class-based HMM for word segmentation', 'number': '3'}"
The significance of our method is: it covers the possible ambiguity.,"{'title': '2.2 Class-based HMM for word segmentation', 'number': '3'}"
"Moreover, unknown words, which are recognized in the following steps, can be added into the segmentation graph and proceeded as any other common words.","{'title': '2.2 Class-based HMM for word segmentation', 'number': '3'}"
"After transformation through class-based HMM, word segmentation becomes single-source shortest paths problem.","{'title': '2.2 Class-based HMM for word segmentation', 'number': '3'}"
Hence the best choice W# of word segmentation is easy to find using Djikstra's algorithm.,"{'title': '2.2 Class-based HMM for word segmentation', 'number': '3'}"
"Here, we would introduce the operation of some different track.","{'title': '3 Tracks', 'number': '4'}"
We participate all the closed tracks.,"{'title': '3 Tracks', 'number': '4'}"
"As for each closed track, we first extracted all the common words and tokens that appear in the training corpus.","{'title': '3 Tracks', 'number': '4'}"
Then build the segmentation core lexicons with the words.,"{'title': '3 Tracks', 'number': '4'}"
"Those named entity words are classified into different named entities: numeric and time expression, personal names, location names, and transliterated names.","{'title': '3 Tracks', 'number': '4'}"
"According to named entities in the given corpus, we could train both class-based segmentation HMM and rolebased HMM model for unknown word recognition.","{'title': '3 Tracks', 'number': '4'}"
"Therefore, the whole lexical system including unknown word detection is accomplished as shown in Figure 1.","{'title': '3 Tracks', 'number': '4'}"
We only participate GB code open tracks.,"{'title': '3 Tracks', 'number': '4'}"
"Actually, open track is similar to closed one.","{'title': '3 Tracks', 'number': '4'}"
The only difference is the size of training data set.,"{'title': '3 Tracks', 'number': '4'}"
"In Peking University open track, ICTCLAS is trained on sixmonth news corpus that is 5 months more than closed track.","{'title': '3 Tracks', 'number': '4'}"
The entire corpus is also from Peking University.,"{'title': '3 Tracks', 'number': '4'}"
"Except for the additional corpus, we have not employed any other special libraries or other resources.","{'title': '3 Tracks', 'number': '4'}"
"As for CTB open track, we find that it cannot benefit from that 5 month PKU corpus.","{'title': '3 Tracks', 'number': '4'}"
"Actually, PKU standard is very different from CTB one though they seemed similar.","{'title': '3 Tracks', 'number': '4'}"
Core lexicon extracted from Peking corpus degraded the performance on CTB testing data.,"{'title': '3 Tracks', 'number': '4'}"
"Except for some named entity corpus, we could not get any more sources related to CTB standard.","{'title': '3 Tracks', 'number': '4'}"
"Therefore, CTB open track is operated in the similar way as closed track.","{'title': '3 Tracks', 'number': '4'}"
"Before the bakeoff, BIG5-coded word segmentation has never been researched in our institute.","{'title': '3 Tracks', 'number': '4'}"
"Besides the character code, common words and sentence styles are greatly different in China mainland and Taiwan or Hong Kong.","{'title': '3 Tracks', 'number': '4'}"
"Because of time limitation, we have only spent two days on transforming our GB-coded ICTCLAS to BIG5coded lexical analyzer.","{'title': '3 Tracks', 'number': '4'}"
"For each BIG5 closed, we extracted a BIG5-coded core lexicon.","{'title': '3 Tracks', 'number': '4'}"
"Then, the Compared with other systems, ICTCLAS especially GB-coded version is competitive.","{'title': '3 Tracks', 'number': '4'}"
"In both GB-coded closed tracks, ICTCLAS ranked top.","{'title': '3 Tracks', 'number': '4'}"
ICTCLAS also rank second position in Peking open track.,"{'title': '3 Tracks', 'number': '4'}"
"Because of the lack of resources, CTB open track is almost as same as CTB closed track.","{'title': '3 Tracks', 'number': '4'}"
The final performance in BIG5 track is not very good.,"{'title': '3 Tracks', 'number': '4'}"
"As a preliminary BIG-coded system, however, we are satisfied with the result.","{'title': '3 Tracks', 'number': '4'}"
"As is shown in Table 1, It could also be concluded that class-based segmentation HMM is effective.","{'title': '3 Tracks', 'number': '4'}"
"Excepted for CTB, IV Recall is over 97%.","{'title': '3 Tracks', 'number': '4'}"
"Through the first bakeoff, we have learn more about the development in Chinese word segmentation and become more confident on our HHMMbased approach.","{'title': '5 Conclusion', 'number': '5'}"
"At the same time, we really find our problems during the evaluation.","{'title': '5 Conclusion', 'number': '5'}"
The bakeoff is interesting and helpful.,"{'title': '5 Conclusion', 'number': '5'}"
We look forward to participate forthcoming bakeoff.,"{'title': '5 Conclusion', 'number': '5'}"
The authors would like to thank Prof. Shiwen Yu of Peking University for the Peking corpus.,"{'title': '6 Acknowledgements', 'number': '6'}"
"And we acknowledge our debt to Gang Zou, Dr. Bin Wang, Dr. Jian Sun, Ji-Feng Li, Hao Zhang and other colleagues.","{'title': '6 Acknowledgements', 'number': '6'}"
Huaping Zhang would especially express gratitude to his graceful girl friend Feifei and her family for their encouragement.,"{'title': '6 Acknowledgements', 'number': '6'}"
"We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.","{'title': '6 Acknowledgements', 'number': '6'}"
