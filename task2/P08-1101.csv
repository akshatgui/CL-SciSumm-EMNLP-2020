col1,col2
Chinese word segmentation is a preliminary step.,{}
To avoid error propagation and improve segmentation by utilizing segmentation and tagging can be performed simultaneously.,{}
"A challenge for this joint approach is the large combined search space, which makes efficient decoding very hard.",{}
"Recent research has explored integration of segmentation and tagging, by decoding under restricted versions of the full combined search space.",{}
"In this paper, propose a joint segmentation and tagging model that does not impose any hard constraints on the interaction between word and Fast decoding is achieved by using a novel multiple-beam search algorithm.",{}
"The system uses a discriminative statistical model, trained using the generalized perceptron algorithm.",{}
The joint model gives an error reduction in segmentation accuracy of an error reduction in tagging acof compared to the traditional pipeline approach.,{}
"Since Chinese sentences do not contain explicitly marked word boundaries, word segmentation is a necessary step before POS tagging can be performed.","{'title': '1 Introduction', 'number': '1'}"
"Typically, a Chinese POS tagger takes segmented inputs, which are produced by a separate word segmentor.","{'title': '1 Introduction', 'number': '1'}"
"This two-step approach, however, has an obvious flaw of error propagation, since word segmentation errors cannot be corrected by the POS tagger.","{'title': '1 Introduction', 'number': '1'}"
A better approach would be to utilize POS information to improve word segmentation.,"{'title': '1 Introduction', 'number': '1'}"
"For example, the POS-word pattern “number word” + “^ (a common measure word)” can help in segmenting the character sequence “�^A” into the word sequence “� (one) ^ (measure word) A (person)” instead of “� (one) ^A (personal; adj)”.","{'title': '1 Introduction', 'number': '1'}"
"Moreover, the comparatively rare POS pattern “number word” + “number word” can help to prevent segmenting a long number word into two words.","{'title': '1 Introduction', 'number': '1'}"
"In order to avoid error propagation and make use of POS information for word segmentation, segmentation and POS tagging can be viewed as a single task: given a raw Chinese input sentence, the joint POS tagger considers all possible segmented and tagged sequences, and chooses the overall best output.","{'title': '1 Introduction', 'number': '1'}"
A major challenge for such a joint system is the large search space faced by the decoder.,"{'title': '1 Introduction', 'number': '1'}"
"For a sentence with n characters, the number of possible output sequences is O(2n−1 · Tn), where T is the size of the tag set.","{'title': '1 Introduction', 'number': '1'}"
"Due to the nature of the combined candidate items, decoding can be inefficient even with dynamic programming.","{'title': '1 Introduction', 'number': '1'}"
"Recent research on Chinese POS tagging has started to investigate joint segmentation and tagging, reporting accuracy improvements over the pipeline approach.","{'title': '1 Introduction', 'number': '1'}"
Various decoding approaches have been used to reduce the combined search space.,"{'title': '1 Introduction', 'number': '1'}"
Ng and Low (2004) mapped the joint segmentation and POS tagging task into a single character sequence tagging problem.,"{'title': '1 Introduction', 'number': '1'}"
Two types of tags are assigned to each character to represent its segmentation and POS.,"{'title': '1 Introduction', 'number': '1'}"
"For example, the tag “b NN” indicates a character at the beginning of a noun.","{'title': '1 Introduction', 'number': '1'}"
"Using this method, POS features are allowed to interact with segmentation.","{'title': '1 Introduction', 'number': '1'}"
"Since tagging is restricted to characters, the search space is reduced to O((4T)'), and beam search decoding is effective with a small beam size.","{'title': '1 Introduction', 'number': '1'}"
"However, the disadvantage of this model is the difficulty in incorporating whole word information into POS tagging.","{'title': '1 Introduction', 'number': '1'}"
"For example, the standard “word + POS tag” feature is not explicitly applicable.","{'title': '1 Introduction', 'number': '1'}"
Shi and Wang (2007) introduced POS information to segmentation by reranking.,"{'title': '1 Introduction', 'number': '1'}"
"N-best segmentation outputs are passed to a separately-trained POS tagger, and the best output is selected using the overall POSsegmentation probability score.","{'title': '1 Introduction', 'number': '1'}"
"In this system, the decoding for word segmentation and POS tagging are still performed separately, and exact inference for both is possible.","{'title': '1 Introduction', 'number': '1'}"
"However, the interaction between POS and segmentation is restricted by reranking: POS information is used to improve segmentation only for the N segmentor outputs.","{'title': '1 Introduction', 'number': '1'}"
"In this paper, we propose a novel joint model for Chinese word segmentation and POS tagging, which does not limiting the interaction between segmentation and POS information in reducing the combined search space.","{'title': '1 Introduction', 'number': '1'}"
"Instead, a novel multiple beam search algorithm is used to do decoding efficiently.","{'title': '1 Introduction', 'number': '1'}"
"Candidate ranking is based on a discriminative joint model, with features being extracted from segmented words and POS tags simultaneously.","{'title': '1 Introduction', 'number': '1'}"
"The training is performed by a single generalized perceptron (Collins, 2002).","{'title': '1 Introduction', 'number': '1'}"
"In experiments with the Chinese Treebank data, the joint model gave an error reduction of 14.6% in segmentation accuracy and 12.2% in the overall segmentation and tagging accuracy, compared to the traditional pipeline approach.","{'title': '1 Introduction', 'number': '1'}"
"In addition, the overall results are comparable to the best systems in the literature, which exploit knowledge outside the training data, even though our system is fully data-driven.","{'title': '1 Introduction', 'number': '1'}"
"Different methods have been proposed to reduce error propagation between pipelined tasks, both in general (Sutton et al., 2004; Daum´e III and Marcu, 2005; Finkel et al., 2006) and for specific problems such as language modeling and utterance classification (Saraclar and Roark, 2005) and labeling and chunking (Shimizu and Haas, 2006).","{'title': '1 Introduction', 'number': '1'}"
"Though our model is built specifically for Chinese word segmentation and POS tagging, the idea of using the perceptron model to solve multiple tasks simultaneously can be generalized to other tasks.","{'title': '1 Introduction', 'number': '1'}"
"We built a two-stage baseline system, using the perceptron segmentation model from our previous work (Zhang and Clark, 2007) and the perceptron POS tagging model from Collins (2002).","{'title': '2 The Baseline System', 'number': '2'}"
"We use baseline system to refer to the system which performs segmentation first, followed by POS tagging (using the single-best segmentation); baseline segmentor to refer to the segmentor from (Zhang and Clark, 2007) which performs segmentation only; and baseline POStagger to refer to the Collins tagger which performs POS tagging only (given segmentation).","{'title': '2 The Baseline System', 'number': '2'}"
The features used by the baseline segmentor are shown in Table 1.,"{'title': '2 The Baseline System', 'number': '2'}"
"The features used by the POS tagger, some of which are different to those from Collins (2002) and are specific to Chinese, are shown in Table 2.","{'title': '2 The Baseline System', 'number': '2'}"
"The word segmentation features are extracted from word bigrams, capturing word, word length and character information in the context.","{'title': '2 The Baseline System', 'number': '2'}"
"The word length features are normalized, with those more than 15 being treated as 15.","{'title': '2 The Baseline System', 'number': '2'}"
"The POS tagging features are based on contextual information from the tag trigram, as well as the neighboring three-word window.","{'title': '2 The Baseline System', 'number': '2'}"
"To reduce overfitting and increase the decoding speed, templates 4, 5, 6 and 7 only include words with less than 3 characters.","{'title': '2 The Baseline System', 'number': '2'}"
"Like the baseline segmentor, the baseline tagger also normalizes word length features.","{'title': '2 The Baseline System', 'number': '2'}"
"Templates 15 and 16 in Table 2 are inspired by the CTBMorph feature templates in Tseng et al. (2005), which gave the most accuracy improvement in their experiments.","{'title': '2 The Baseline System', 'number': '2'}"
Here the category of a character is the set of tags seen on the character during training.,"{'title': '2 The Baseline System', 'number': '2'}"
Other morphological features from Tseng et al. (2005) are not used because they require extra web corpora besides the training data.,"{'title': '2 The Baseline System', 'number': '2'}"
"During training, the baseline POS tagger stores special word-tag pairs into a tag dictionary (Ratnaparkhi, 1996).","{'title': '2 The Baseline System', 'number': '2'}"
Such information is used by the decoder to prune unlikely tags.,"{'title': '2 The Baseline System', 'number': '2'}"
"For each word occurring more than N times in the training data, the decoder can only assign a tag the word has been seen with in the training data.","{'title': '2 The Baseline System', 'number': '2'}"
"This method led to improvement in the decoding speed as well as the output accuracy for English POS tagging (Ratnaparkhi, 1996).","{'title': '2 The Baseline System', 'number': '2'}"
"Besides tags for frequent words, our baseline POS tagger also uses the tag dictionary to store closed-set tags (Xia, 2000) – those associated only with a limited number of Chinese words.","{'title': '2 The Baseline System', 'number': '2'}"
"In this section, we build a joint word segmentation and POS tagging model that uses exactly the same source of information as the baseline system, by applying the feature templates from the baseline word segmentor and POS tagger.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
No extra knowledge is used by the joint model.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"However, because word segmentation and POS tagging are performed simultaneously, POS information participates in word segmentation.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"We formulate joint word segmentation and POS tagging as a single problem, which maps a raw Chinese sentence to a segmented and POS tagged output.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Given an input sentence x, the output F(x) satisfies: where GEN(x) represents the set of possible outputs for x.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
Score(y) is computed by a feature-based linear model.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Denoting the global feature vector for the tagged sentence y with 4b(y), we have: where w� is the parameter vector in the model.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Each element in w� gives a weight to its corresponding element in 4b(y), which is the count of a particular feature over the whole sentence y.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"We calculate the w� value by supervised learning, using the averaged perceptron algorithm (Collins, 2002), given in Figure 1.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
1 We take the union of feature templates from the baseline segmentor (Table 1) and POS tagger (Table 2) as the feature templates for the joint system.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"All features are treated equally and processed together according to the linear model, regardless of whether they are from the baseline segmentor or tagger.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"In fact, most features from the baseline POS tagger, when used in the joint model, represent segmentation patterns as well.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"For example, the aforementioned pattern “number word” + “^”, which is Inputs: training examples (xi, yi) Initialization: set w� = 0 Algorithm: for t = 1..T, i = 1..N calculate zi = arg maxyEGEN(xi) Φ(y) - w� if zi =� yi useful only for the POS “number word” in the baseline tagger, is also an effective indicator of the segmentation of the two words (especially “^”) in the joint model.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
One of the main challenges for the joint segmentation and POS tagging system is the decoding algorithm.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"The speed and accuracy of the decoder is important for the perceptron learning algorithm, but the system faces a very large search space of combined candidates.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Given the linear model and feature templates, exact inference is very hard even with dynamic programming.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Experiments with the standard beam-search decoder described in (Zhang and Clark, 2007) resulted in low accuracy.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
This beam search algorithm processes an input sentence incrementally.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"At each stage, the incoming character is combined with existing partial candidates in all possible ways to generate new partial candidates.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"An agenda is used to control the search space, keeping only the B best partial candidates ending with the current character.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"The algorithm is simple and efficient, with a linear time complexity of O(BTn), where n is the size of input sentence, and T is the size of the tag set (T = 1 for pure word segmentation).","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"It worked well for word segmentation alone (Zhang and Clark, 2007), even with an agenda size as small as 8, and a simple beam search algorithm also works well for POS tagging (Ratnaparkhi, 1996).","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"However, when applied to the joint model, it resulted in a reduction in segmentation accuracy (compared to the baseline segmentor) even with B as large as 1024.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
One possible cause of the poor performance of the standard beam search method is the combined nature of the candidates in the search space.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"In the baseInput: raw sentence sent – a list of characters Variables: candidate sentence item – a list of (word, tag) pairs; maximum word-length record maxlen for each tag; the agenda list agendas; the tag dictionary tagdict; start index for current word; end index for current word Initialization: agendas[0] = [“”], agendas[i] = [] (i!","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"= 0) Algorithm: for end index = 1 to sent.length: foreach tag: for start index = max(1, end index − maxlen[tag] + 1) to end index: word = sent[start index..end index] if (word, tag) consistent with tagdict: for item E agendas[start index − 1]: line POS tagger, candidates in the beam are tagged sequences ending with the current word, which can be compared directly with each other.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"However, for the joint problem, candidates in the beam are segmented and tagged sequences up to the current character, where the last word can be a complete word or a partial word.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
A problem arises in whether to give POS tags to incomplete words.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"If partial words are given POS tags, it is likely that some partial words are “justified” as complete words by the current POS information.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"On the other hand, if partial words are not given POS tag features, the correct segmentation for long words can be lost during partial candidate comparison (since many short completed words with POS tags are likely to be preferred to a long incomplete word with no POS tag features).2 Another possible cause is the exponential growth in the number of possible candidates with increasing sentence size.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
The number increases from O(Tn) for the baseline POS tagger to O(2n−'Tn) for the joint system.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"As a result, for an incremental decoding algorithm, the number of possible candidates increases exponentially with the current word or character index.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"In the POS tagging problem, a new incoming word enlarges the number of possible candidates by a factor of T (the size of the tag set).","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"For the joint problem, however, the enlarging factor becomes 2T with each incoming character.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"The speed of search space expansion is much faster, but the number of candidates is still controlled by a single, fixed-size beam at any stage.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"If we assume that the beam is not large enough for all the candidates at at each stage, then, from the newly generated candidates, the baseline POS tagger can keep 1/T for the next processing stage, while the joint model can keep only 1/2T, and has to discard the rest.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Therefore, even when the candidate comparison standard is ignored, we can still see that the chance for the overall best candidate to fall out of the beam is largely increased.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Since the search space growth is exponential, increasing the fixed beam size is not effective in solving the problem.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"To solve the above problems, we developed a multiple beam search algorithm, which compares candidates only with complete tagged words, and enables the size of the search space to scale with the input size.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
The algorithm is shown in Figure 2.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"In this decoder, an agenda is assigned to each character in the input sentence, recording the B best segmented and tagged partial candidates ending with the character.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
The input sentence is still processed incrementally.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"However, now when a character is processed, existing partial candidates ending with any previous characters are available.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Therefore, the decoder enumerates all possible tagged words ending with the current character, and combines each word with the partial candidates ending with its previous character.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"All input characters are processed in the same way, and the final output is the best candidate in the final agenda.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"The time complexity of the algorithm is O(WTBn), with W being the maximum word size, T being the total number of POS tags and n the number of characters in the input.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
It is also linear in the input size.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Moreover, the decoding algorithm gives competent accuracy with a small agenda size of B = 16.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"To further limit the search space, two optimizations are used.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"First, the maximum word length for each tag is recorded and used by the decoder to prune unlikely candidates.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Because the majority of tags only apply to words with length 1 or 2, this method has a strong effect.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Development tests showed that it improves the speed significantly, while having a very small negative influence on the accuracy.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Second, like the baseline POS tagger, the tag dictionary is used for Chinese closed set tags and the tags for frequent words.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"To words outside the tag dictionary, the decoder still tries to assign every possible tag.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"Apart from features, the decoder maintains other types of information, including the tag dictionary, the word frequency counts used when building the tag dictionary, the maximum word lengths by tag, and the character categories.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
The above data can be collected by scanning the corpus before training starts.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"However, in both the baseline tagger and the joint POS tagger, they are updated incrementally during the perceptron training process, consistent with online learning.3 The online updating of word frequencies, maximum word lengths and character categories is straightforward.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"For the online updating of the tag dictionary, however, the decision for frequent words must be made dynamically because the word frequencies keep changing.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"This is done by caching the number of occurrences of the current most frequent word M, and taking all words currently above the threshold M/5000 + 5 as frequent words.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
"5000 is a rough figure to control the number of frequent words, set according to Zipf’s law.","{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
The parameter 5 is used to force all tags to be enumerated before a word is seen more than 5 times.,"{'title': '3 Joint Segmentation and Tagging Model', 'number': '3'}"
Ng and Low (2004) and Shi and Wang (2007) were described in the Introduction.,"{'title': '4 Related Work', 'number': '4'}"
Both models reduced the large search space by imposing strong restrictions on the form of search candidates.,"{'title': '4 Related Work', 'number': '4'}"
"In particular, Ng and Low (2004) used character-based POS tagging, which prevents some important POS tagging features such as word + POS tag; Shi and Wang (2007) used an N-best reranking approach, which limits the influence of POS tagging on segmentation to the N-best list.","{'title': '4 Related Work', 'number': '4'}"
"In comparison, our joint model does not impose any hard limitations on the interaction between segmentation and POS information.4 Fast decoding speed is achieved by using a novel multiple-beam search algorithm.","{'title': '4 Related Work', 'number': '4'}"
Nakagawa and Uchimoto (2007) proposed a hybrid model for word segmentation and POS tagging using an HMM-based approach.,"{'title': '4 Related Work', 'number': '4'}"
"Word information is used to process known-words, and character information is used for unknown words in a similar way to Ng and Low (2004).","{'title': '4 Related Work', 'number': '4'}"
"In comparison, our model handles character and word information simultaneously in a single perceptron model.","{'title': '4 Related Work', 'number': '4'}"
The Chinese Treebank (CTB) 4 is used for the experiments.,"{'title': '5 Experiments', 'number': '5'}"
"It is separated into two parts: CTB 3 (420K characters in 150K words / 10364 sentences) is used for the final 10-fold cross validation, and the rest (240K characters in 150K words / 4798 sentences) is used as training and test data for development.","{'title': '5 Experiments', 'number': '5'}"
"The standard F-scores are used to measure both the word segmentation accuracy and the overall segmentation and tagging accuracy, where the overall accuracy is TF = 2pr/(p + r), with the precision p being the percentage of correctly segmented and tagged words in the decoder output, and the recall r being the percentage of gold-standard tagged words that are correctly identified by the decoder.","{'title': '5 Experiments', 'number': '5'}"
"For direct comparison with Ng and Low (2004), the POS tagging accuracy is also calculated by the percentage of correct tags on each character.","{'title': '5 Experiments', 'number': '5'}"
"The learning curves of the baseline and joint models are shown in Figure 3, Figure 4 and Figure 5, respectively.","{'title': '5 Experiments', 'number': '5'}"
These curves are used to show the convergence of perceptron and decide the number of training iterations for the test.,"{'title': '5 Experiments', 'number': '5'}"
It should be noticed that the accuracies from Figure 4 and Figure 5 are not comparable because gold-standard segmentation is used as the input for the baseline tagger.,"{'title': '5 Experiments', 'number': '5'}"
"According to the figures, the number of training iterations for the baseline segmentor, POS tagger, and the joint system are set to 8, 6, and 7, respectively for the remaining experiments.","{'title': '5 Experiments', 'number': '5'}"
There are many factors which can influence the accuracy of the joint model.,"{'title': '5 Experiments', 'number': '5'}"
Here we consider the special character category features and the effect of the tag dictionary.,"{'title': '5 Experiments', 'number': '5'}"
The character category features (templates 15 and 16 in Table 2) represent a Chinese character by all the tags associated with the character in the training data.,"{'title': '5 Experiments', 'number': '5'}"
"They have been shown to improve the accuracy of a Chinese POS tagger (Tseng et al., 2005).","{'title': '5 Experiments', 'number': '5'}"
"In the joint model, these features also represent segmentation information, since they concern the starting and ending characters of a word.","{'title': '5 Experiments', 'number': '5'}"
Development tests showed that the overall tagging F-score of the joint model increased from 84.54% to 84.93% using the character category features.,"{'title': '5 Experiments', 'number': '5'}"
"In the development test, the use of the tag dictionary improves the decoding speed of the joint model, reducing the decoding time from 416 seconds to 256 seconds.","{'title': '5 Experiments', 'number': '5'}"
"The overall tagging accuracy also increased slightly, consistent with observations from the pure POS tagger.","{'title': '5 Experiments', 'number': '5'}"
The error analysis for the development test is shown in Table 3.,"{'title': '5 Experiments', 'number': '5'}"
"Here an error is counted when a word in the standard output is not produced by the decoder, due to incorrect segmentation or tag assignment.","{'title': '5 Experiments', 'number': '5'}"
"Statistics about the six most frequently mistaken tags are shown in the table, where each row presents the analysis of one tag from the standard output, and each column gives a wrongly assigned value.","{'title': '5 Experiments', 'number': '5'}"
The column “Seg” represents segmentation errors.,"{'title': '5 Experiments', 'number': '5'}"
Each figure in the table shows the percentage of the corresponding error from all the errors.,"{'title': '5 Experiments', 'number': '5'}"
"It can be seen from the table that the NN-VV and VV-NN mistakes were the most commonly made by the decoder, while the NR-NN mistakes are also frequent.","{'title': '5 Experiments', 'number': '5'}"
"These three types of errors significantly outnumber the rest, together contributing 14.92% of all the errors.","{'title': '5 Experiments', 'number': '5'}"
"Moreover, the most commonly mistaken tags are NN and VV, while among the most frequent tags in the corpus, PU, DEG and M had comparatively less errors.","{'title': '5 Experiments', 'number': '5'}"
"Lastly, segmentation errors contribute around half (51.47%) of all the errors.","{'title': '5 Experiments', 'number': '5'}"
"10-fold cross validation is performed to test the accuracy of the joint word segmentor and POS tagger, and to make comparisons with existing models in the literature.","{'title': '5 Experiments', 'number': '5'}"
"Following Ng and Low (2004), we partition the sentences in CTB 3, ordered by sentence ID, into 10 groups evenly.","{'title': '5 Experiments', 'number': '5'}"
"In the nth test, the nth group is used as the testing data.","{'title': '5 Experiments', 'number': '5'}"
"Table 4 shows the detailed results for the cross validation tests, each row representing one test.","{'title': '5 Experiments', 'number': '5'}"
"As can be seen from the table, the joint model outperforms the baseline system in each test.","{'title': '5 Experiments', 'number': '5'}"
"Table 5 shows the overall accuracies of the baseline and joint systems, and compares them to the relevant models in the literature.","{'title': '5 Experiments', 'number': '5'}"
"The accuracy of each model is shown in a row, where “Ng” represents the models from Ng and Low (2004) and “Shi” represents the models from Shi and Wang (2007).","{'title': '5 Experiments', 'number': '5'}"
"Each accuracy measure is shown in a column, including the segmentation F-score (SF), the overall tagging F-score (TF) and the tagging accuracy by characters (TA).","{'title': '5 Experiments', 'number': '5'}"
"As can be seen from the table, our joint model achieved the largest improvement over the baseline, reducing the segmentation error by 14.58% and the overall tagging error by 12.18%.","{'title': '5 Experiments', 'number': '5'}"
The overall tagging accuracy of our joint model was comparable to but less than the joint model of Shi and Wang (2007).,"{'title': '5 Experiments', 'number': '5'}"
"Despite the higher accuracy improvement from the baseline, the joint system did not give higher overall accuracy.","{'title': '5 Experiments', 'number': '5'}"
"One likely reason is that Shi and Wang (2007) included knowledge about special characters and semantic knowledge from web corpora (which may explain the higher baseline accuracy), while our system is completely data-driven.","{'title': '5 Experiments', 'number': '5'}"
"However, the comparison is indirect because our partitions of the CTB corpus are different.","{'title': '5 Experiments', 'number': '5'}"
"Shi and Wang (2007) also chunked the sentences before doing 10-fold cross validation, but used an uneven split.","{'title': '5 Experiments', 'number': '5'}"
We chose to follow Ng and Low (2004) and split the sentences evenly to facilitate further comparison.,"{'title': '5 Experiments', 'number': '5'}"
"Compared with Ng and Low (2004), our baseline model gave slightly better accuracy, consistent with our previous observations about the word segmentors (Zhang and Clark, 2007).","{'title': '5 Experiments', 'number': '5'}"
"Due to the large accuracy gain from the baseline, our joint model performed much better.","{'title': '5 Experiments', 'number': '5'}"
"In summary, when compared with existing joint word segmentation and POS tagging systems in the literature, our proposed model achieved the best accuracy boost from the cascaded baseline, and competent overall accuracy.","{'title': '5 Experiments', 'number': '5'}"
"We proposed a joint Chinese word segmentation and POS tagging model, which achieved a considerable reduction in error rate compared to a baseline twostage system.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
"We used a single linear model for combined word segmentation and POS tagging, and chose the generalized perceptron algorithm for joint training. and beam search for efficient decoding.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
"However, the application of beam search was far from trivial because of the size of the combined search space.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
"Motivated by the question of what are the comparable partial hypotheses in the space, we developed a novel multiple beam search decoder which effectively explores the large search space.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
Similar techniques can potentially be applied to other problems involving joint inference in NLP.,"{'title': '6 Conclusion and Future Work', 'number': '6'}"
"Other choices are available for the decoding of a joint linear model, such as exact inference with dynamic programming, provided that the range of features allows efficient processing.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
"The baseline feature templates for Chinese segmentation and POS tagging, when added together, makes exact inference for the proposed joint model very hard.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
"However, the accuracy loss from the beam decoder, as well as alternative decoding algorithms, are worth further exploration.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
The joint system takes features only from the baseline segmentor and the baseline POS tagger to allow a fair comparison.,"{'title': '6 Conclusion and Future Work', 'number': '6'}"
There may be additional features that are particularly useful to the joint system.,"{'title': '6 Conclusion and Future Work', 'number': '6'}"
"Open features, such as knowledge of numbers and European letters, and relationships from semantic networks (Shi and Wang, 2007), have been reported to improve the accuracy of segmentation and POS tagging.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
"Therefore, given the flexibility of the feature-based linear model, an obvious next step is the study of open features in the joint segmentor and POS tagger.","{'title': '6 Conclusion and Future Work', 'number': '6'}"
"We thank Hwee-Tou Ng and Mengqiu Wang for their helpful discussions and sharing of experimental data, and the anonymous reviewers for their suggestions.","{'title': 'Acknowledgements', 'number': '7'}"
This work is supported by the ORS and Clarendon Fund.,"{'title': 'Acknowledgements', 'number': '7'}"
