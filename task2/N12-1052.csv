col1,col2
It has been established that incorporating word cluster features derived from large unlabeled corpora can significantly improve prediction of linguistic structure.,{}
"While previous work has focused primarily on English, we extend these results to other languages along two dimensions.",{}
"First, we show that these results hold true for a number of languages across families.",{}
"Second, and more interestingly, we provide an algorithm for inducing cross-lingual clusters and we show that features derived from these clusters significantly improve the accuracy of cross-lingual structure prediction.",{}
"Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%.",{}
"When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%.",{}
The ability to predict the linguistic structure of sentences or documents is central to the field of natural language processing (NLP).,"{'title': '1 Introduction', 'number': '1'}"
"Structures such as named-entity tag sequences (Bikel et al., 1999) or sentiment relations (Pang and Lee, 2008) are inherently useful in data mining, information retrieval and other user-facing technologies.","{'title': '1 Introduction', 'number': '1'}"
"More fundamental structures such as part-of-speech tag sequences (Ratnaparkhi, 1996) or syntactic parse trees (Collins, 1997; K¨ubler et al., 2009), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY.","{'title': '1 Introduction', 'number': '1'}"
"2005; Collins et al., 2005).","{'title': '1 Introduction', 'number': '1'}"
"Currently, supervised data-driven methods dominate the literature on linguistic structure prediction (Smith, 2011).","{'title': '1 Introduction', 'number': '1'}"
"Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources.","{'title': '1 Introduction', 'number': '1'}"
"Notable exceptions include the CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011).","{'title': '1 Introduction', 'number': '1'}"
"While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages.","{'title': '1 Introduction', 'number': '1'}"
"This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure.","{'title': '1 Introduction', 'number': '1'}"
These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age.,"{'title': '1 Introduction', 'number': '1'}"
Unsupervised methods are appealing in that they are often inherently language independent.,"{'title': '1 Introduction', 'number': '1'}"
"This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011).","{'title': '1 Introduction', 'number': '1'}"
"However, the performance for most languages is still well below that of supervised systems and recent work has established that the performance is also below simple methods of linguistic transfer (McDonald et al., 2011).","{'title': '1 Introduction', 'number': '1'}"
In this study we focus on semi-supervised and linguistic-transfer methods for multilingual structure prediction.,"{'title': '1 Introduction', 'number': '1'}"
"In particular, we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: guages for dependency parsing and 4 languages for named-entity recognition (NER).","{'title': '1 Introduction', 'number': '1'}"
"This is the first study with such a broad view on this subject, in terms of language diversity.","{'title': '1 Introduction', 'number': '1'}"
2.,"{'title': '1 Introduction', 'number': '1'}"
Cross-lingual word cluster features for transferring linguistic structure from English to other languages.,"{'title': '1 Introduction', 'number': '1'}"
We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages.,"{'title': '1 Introduction', 'number': '1'}"
"This is achieved by means of a probabilistic model over large amounts of monolingual data in two languages, coupled with parallel data through which cross-lingual word-cluster constraints are enforced.","{'title': '1 Introduction', 'number': '1'}"
"We show that by augmenting the delexicalized direct transfer system of McDonald et al. (2011) with cross-lingual cluster features, we are able to reduce its error by up to 13% relative.","{'title': '1 Introduction', 'number': '1'}"
"Further, we show that by applying the same method to direct-transfer NER, we achieve a relative error reduction of 26%.","{'title': '1 Introduction', 'number': '1'}"
"In line with much previous work on word clusters for tasks such as dependency parsing and NER, for which local syntactic and semantic constraints are of importance, we induce word clusters by means of a probabilistic class-based language model (Brown et al., 1992; Clark, 2003).","{'title': '1 Introduction', 'number': '1'}"
"However, rather than the more commonly used model of Brown et al. (1992), we use the predictive class bigram model introduced by Uszkoreit and Brants (2008).","{'title': '1 Introduction', 'number': '1'}"
"The two models are very similar, but whereas the former takes classto-class transitions into account, the latter directly models word-to-class transitions.","{'title': '1 Introduction', 'number': '1'}"
"By ignoring classto-class transitions, an approximate maximum likelihood clustering can be found efficiently with the distributed exchange algorithm (Uszkoreit and Brants, 2008).","{'title': '1 Introduction', 'number': '1'}"
"This is a useful property, as we later develop an algorithm for inducing cross-lingual word clusters that calls this monolingual algorithm as a subroutine.","{'title': '1 Introduction', 'number': '1'}"
"More formally, let C : V H 1, ... , K be a (hard) clustering function that maps each word type from the vocabulary, V, to one of K cluster identities.","{'title': '1 Introduction', 'number': '1'}"
"With the model of Uszkoreit and Brants (2008), the likelihood of a sequence of word tokens, w = (wi)mi=1, with wi E V U {S}, where S is a designated start-ofsegment symbol, factors as Compare this to the model of Brown et al. (1992): By incorporating cross-lingual cluster features in a m linguistic transfer system, we are for the first time L'(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) . combining SSL and cross-lingual transfer. i=1","{'title': '1 Introduction', 'number': '1'}"
"Word cluster features have been shown to be useful in various tasks in natural language processing, including syntactic dependency parsing (Koo et al., 2008; Haffari et al., 2011; Tratz and Hovy, 2011), syntactic chunking (Turian et al., 2010), and NER (Freitag, 2004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010).","{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
"Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues.","{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
"While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Uszkoreit and Brants, 2008).","{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
"In addition to the clustering model that we make use of in this study, a number of additional word clustering and embedding variants have been proposed.","{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
"For example, Turian et al. (2010) assessed the effectiveness of the word embedding techniques of Collobert and Weston (2008) and Mnih and Hinton (2007) along with the word clustering technique of Brown et al.","{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
(1992) for syntactic chunking and NER.,"{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
"Recently, Dhillon et al. (2011) proposed a word embedding method based on canonical correlation analysis that provides state-of-the art results for wordbased SSL for English NER.","{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
"As an alternative to clustering words, Lin and Wu (2009) proposed a phrase clustering approach that obtained the state-of-the-art result for English NER.","{'title': '2 Monolingual Word Cluster Features', 'number': '2'}"
"Before moving on to the multilingual setting, we conduct a set of monolingual experiments where we evaluate the use of the monolingual word clusters just described as features for dependency parsing and NER.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"In the parsing experiments, we study the following thirteen languages:1 Danish (DA), German (DE), Greek (EL), English (EN), Spanish (ES), French (FR), Italian (IT), Korean (KO), Dutch (NL), Portugese (PT), Russian (RU), Swedish (SV) and Chinese (ZH) – representing the Chinese, Germanic, Hellenic, Romance, Slavic, Altaic and Korean genera.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"In the NER experiments, we study three Germanic languages: German (DE), English (EN) and Dutch (NL); and one Romance language: Spanish (ES).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
Details of the labeled and unlabeled data sets used are given in Appendix A.,"{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
For all experiments we fixed the number of clusters to 256 as this performed well on held-out data.,"{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"Furthermore, we only clustered the 1 million most frequent word types in each language for both efficiency and sparsity reasons.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"For languages in which our unlabeled data did not have at least 1 million types, we considered all types.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"All of the parsing experiments reported in this study are based on the transition-based dependency parsing paradigm (Nivre, 2008).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"For all languages and settings, we use an arc-eager decoding strategy, with a beam of eight hypotheses, and perform ten epochs of the averaged structured perceptron algorithm (Zhang and Clark, 2008).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
We extend the state-of-the-art feature model recently introduced by Zhang and Nivre (2011) by adding an additional word cluster based feature template for each word based template.,"{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"Additionally, we add templates where one or more partof-speech feature is replaced with the corresponding cluster feature.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
The resulting set of additional feature templates are shown in Table 1.,"{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"The expanded feature model includes all of the feature templates defined by Zhang and Nivre (2011), which we also use as the baseline model, whereas Table 1 only shows our new templates due to space limitations.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"For all NER experiments, we use a sequential firstorder conditional random field (CRF) with a unit variance Normal prior, trained with L-BFGS until c-convergence (c = 0.0001, typically obtained after less than 400 iterations).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
The feature model used for the NER tagger is shown in Table 2.,"{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"These are similar to the features used by Turian et al. (2010), with the main difference that we do not use any long range features and that we add templates that conjoin adjacent clusters and adjacent tags as well as templates that conjoin label transitions with tags, clusters and capitalization features.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"The results of the parsing experiments, measured with labeled accuracy score (LAS) on all sentence lengths, excluding punctuation, are shown in Table 3.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
The baselines are all comparable to the state-of-theart.,"{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"On average, the addition of word cluster features yields a 6% relative reduction in error and upwards of 15% (for RU).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"All languages improve except FR, which sees neither an increase nor a decrease in LAS.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"We observe an average absolute increase in LAS of approximately 1%, which is inline with previous observations (Koo et al., 2008).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"It is perhaps not surprising that RU sees a large gain as it is a highly inflected language, making observations of lexical features far more sparse.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"Some languages, e.g., FR, NL, and ZH see much smaller gains.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"One likely culprit is a divergence between the tokenization schemes used in the treebank and in our unlabeled data, which for Indo-European languages is closely related to the Penn Treebank tokenization.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"For example, the NL treebank contains many multi-word tokens that are typically broken apart by our automatic tokenizer.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"The NER results, in terms of F1 measure, are listed in Table 4.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
Introducing word cluster features for NER reduces relative errors on the test set by 21% (39% on the development set) on average.,"{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"Broken down per language, reductions on the test set vary from substantial for NL (30%) and EN (26%), down to more modest for DE (17%) and ES (12%).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"The addition of cluster features most markedly improve recognition of the PER category, with an average error reduction on the test set of 44%, while the reductions for ORG (19%), LOC (17%) and MISC (10%) are more modest, but still significant.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"Although our results are below the best reported results for EN and DE (Lin and Wu, 2009; Faruqui and Pad´o, 2010), the relative improvements of adding word clusters are inline with previous results on NER for EN (Miller et al., 2004; Turian et al., 2010), who report error reductions of approximately 25% from adding word cluster features.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"Slightly higher reductions where achieved for DE by Faruqui and Pad´o (2010), who report a reduction of 22%.","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
"Note that we did not tune hyper-parameters of the supervised learning methods and of the clustering method, such as the number of clusters (Turian et al., 2010; Faruqui and Pad´o, 2010), and that we did not apply any heuristic for data cleaning such as that used by Turian et al. (2010).","{'title': '3 Monolingual Cluster Experiments', 'number': '3'}"
All results of the previous section rely on the availability of large quantities of language specific annotations for each task.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
Cross-lingual transfer methods and unsupervised methods have recently been shown to hold promise as a way to at least partially sidestep the demand for labeled data.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Unsupervised methods attempt to infer linguistic structure without using any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010).","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005).","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011).","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
Our starting point is the delexicalized direct transfer method proposed by McDonald et al. (2011) based on work by Zeman and Resnik (2008).,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
This method was shown to outperform a number of state-of-the-art unsupervised and transfer-based baselines.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"The method is simple; for a given training set, the learner ignores all lexical identities and only observes features over other characteristics, e.g., part-of-speech tags, orthographic features, direction of syntactic attachment, etc.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"The learner builds a model from an annotated source language data set, after which the model is used to directly make target language predictions.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
There are three basic assumptions that drive this approach.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"First, that high-level tasks, such as syntactic parsing, can be learned reliably using coarse-grained statistics, such as part-of-speech tags, in place of fine-grained statistics such as lexical word identities.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Second, that the parameters of features over coarsegrained statistics are in some sense language independent, e.g., a feature that indicates that adjectives modify their closest noun is useful in all languages.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Third, that these coarse-grained statistics are robustly available across languages.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
The approach proposed by McDonald et al. (2011) relies on these three assumptions.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Below, we extend this approach to universal parsing by adding cross-lingual word cluster features.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"A cross-lingual word clustering is a clustering of words in two languages, in which the clusters correspond to some meaningful cross-lingual property.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"For example, prepositions from both languages should be in the same cluster, proper names from both languages in another cluster and so on.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"By adding features defined over these clusters, we can, to some degree, re-lexicalize the delexicalized models, while maintaining the “universality” of the features.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
This approach is outlined in Figure 1.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Assuming that we have an algorithm for generating cross-lingual word clusters (see Section 4.2), we can augment the delexicalized parsing algorithm to use these word cluster features at training and testing time.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"In order to further motivate the proposed approach, consider the accuracy of the supervised English parser.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"A parser with lexical, part-of-speech and cluster features achieves 90.7% LAS (see Table 3).","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"If we remove all lexical and cluster features, the same parser achieves 83.1%.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"However, if we add back just the cluster features, the accuracy jumps back up to 89.5%, which is only 1.2% below the full system.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Thus, if we can accurately learn cross-lingual clusters, there is hope of regaining some of the accuracy lost due to the delexicalization process.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
Our first method for inducing cross-lingual clusters has two stages.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"First, it clusters a source language (S) as in the monolingual case, and then projects these clusters to a target language (T), using word alignments.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Given two aligned word sequences set of scored alignments from the source language to the target language, where (wTj , wSaj, sj,aj) ∈ AT |S is an alignment from the ajth source word to the jth target word, with score sj,aj ≥ δ.2 We use the shorthand j ∈ AT |S to denote those target words wTj that are aligned to some source word wSaj.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Provided a clustering CS, we assign the target word t ∈ VT to the cluster with which it is most often aligned: where [·� is the indicator function.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
We refer to the cross-lingual clusters induced in this way as PROJECTED CLUSTERS.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
This simple projection approach has two potential drawbacks.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"First, it only provides a clustering of those target language words that occur in the word 2In our case, the alignment score corresponds to the conditional alignment probability p(wTj |wSa� ).","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"All E-alignments are ignored and we use S = 0.95 throughout. aligned data, which is typically smaller than our monolingual data sets.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Second, the mapped clustering may not necessarily correspond to an acceptable target language clustering in terms of monolingual likelihood.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"In order to tackle these issues, we propose the following more complex model.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"First, to find clusterings that are good according to both the source and target language, and to make use of more unlabeled data, we model word sequences in each language by the monolingual language model with likelihood function defined by equation (1).","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Denote these likelihood functions respectively by LS(wS; CS) and LT (wT; CT), where we have overloaded notation so that the word sequences denoted by wS and wT include much more plentiful non-aligned data when taken as an argument of the monolingual likelihood functions.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Second, we couple the clusterings defined by these individual models, by introducing additional factors based on word alignments, as proposed by Och (1999): and the symmetric LS|T(wS; AS|T, CS, CT).","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
Note that the simple projection defined by equation (2) correspond to a hard assignment variant of this probabilistic formulation when the source clustering is fixed.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Combining all four factors results in the joint monolingual and cross-lingual objective function The intuition of this approach is that the clusterings CS and CT are forced to jointly explain the source and target data, treating the word alignments as a form of soft constraints.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"We approximately optimize (3) with the alternating procedure in Algorithm 1, in which we iteratively maximize LS and LT , keeping the other factors fixed.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
In this way we can generate cross-lingual clusterings using all the monolingual data while forcing the clusterings to obey the word alignment constraints.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
We refer to the clusters induced with this method as X-LINGUAL CLUSTERS.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
In practice we found that each unconstrained monolingual run of the exchange algorithm (lines † Optimized via the exchange algorithm keeping the cluster of projected words fixed and only clustering additional words not in the projection.,"{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"1 and 3) moves the clustering too far from those that obey the word alignment constraints, which causes the procedure to fail to converge.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"However, we found that fixing the clustering of the words that are assigned clusters in the projection stages (lines 2 and 4) and only clustering the remaining words works well in practice.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"Furthermore, we found that iterating the procedure has little effect on performance and set N = 1 for all subsequent experiments.","{'title': '4 Cross-lingual Word Cluster Features', 'number': '4'}"
"In our first set of experiments on using cross-lingual cluster features, we evaluate direct transfer of our EN parser, trained on Stanford style dependencies (De Marneffe et al., 2006), to the the ten non-EN Indo-European languages listed in Section 3.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
We exclude KO and ZH as initial experiments proved direct transfer a poor technique when transferring parsers between such diverse languages.,"{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al. (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"In both cases the feature models are the same as those used in Section 3.1, except that they are delexicalized by removing all lexical word-identity features.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
We evaluate both the PROJECTED CLUSTERS and the X-LINGUAL CLUSTERS.,"{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"For these experiments we train the perceptron for only five epochs in order to prevent over-fitting, which is an acute problem due to the divergence between the training and testing data sets in this setting.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"Furthermore, in accordance to standard practices we only evaluate unlabeled attachment score (UAS) due to the fact that each treebank uses a different – possibly non-overlapping – label set.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"In our second set of experiments, we evaluate direct transfer of a NER system trained on EN to DE, ES and NL.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"We use the same feature models as in the monolingual case, with the exception that we use universal part-of-speech tags for all languages and we remove the capitalization feature when transferring from EN to DE.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"Capitalization is both a prevalent and highly predictive feature of named-entities in EN, while in DE, capitalization is even more prevalent, but has very low predictive power.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"Interestingly, while delexicalization has shown to be important for direct transfer of dependency-parsers (McDonald et al., 2011), we noticed in preliminary experiments that it substantially degrades performance for NER.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"We hypothesize that this is because word features are predictive of common proper names and that these are often translated directly across languages, at least in the case of newswire text.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"As for the transfer parser, when training the source NER model, we regularize the model more heavily by setting Q = 0.1.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
"Appendix A contains the details of the training, testing, unlabeled and parallel/aligned data sets.","{'title': '5 Cross-lingual Experiments', 'number': '5'}"
Table 5 lists the results of the transfer experiments for dependency parsing.,"{'title': '5.1 Results', 'number': '6'}"
"The baseline results are comparable to those in McDonald et al. (2011) and thus also significantly outperform the results of recent unsupervised approaches (Berg-Kirkpatrick and Klein, 2010; Naseem et al., 2010).","{'title': '5.1 Results', 'number': '6'}"
"Importantly, crosslingual cluster features are helpful across the board and give a relative error reduction ranging from 3% for DA to 13% for PT, with an average reduction of 6%, in terms of unlabeled attachment score (UAS).","{'title': '5.1 Results', 'number': '6'}"
This shows the utility of cross-lingual cluster features for syntactic transfer.,"{'title': '5.1 Results', 'number': '6'}"
"However, X-LINGUAL CLUSTERS provides roughly the same performance as PROJECTED CLUSTERS suggesting that even simple methods of cross-lingual clustering are sufficient for direct transfer dependency parsing.","{'title': '5.1 Results', 'number': '6'}"
We would like to stress that these results are likely to be under-estimating the parsers’ actual ability to predict Stanford-style dependencies in the target languages.,"{'title': '5.1 Results', 'number': '6'}"
This is because the target language annotations that we use for evaluation differ from the Stanford dependency annotation.,"{'title': '5.1 Results', 'number': '6'}"
Some of these differences are warranted in that certain target language phenomena are better captured by the native annotation.,"{'title': '5.1 Results', 'number': '6'}"
"However, differences such as choice of lexical versus functional head are more arbitrary.","{'title': '5.1 Results', 'number': '6'}"
To highlight this point we run two additional experiments.,"{'title': '5.1 Results', 'number': '6'}"
"First, we had linguists, who were also fluent speakers of German, re-annotate the DE test set so that unlabeled arcs are consistent with Stanfordstyle dependencies.","{'title': '5.1 Results', 'number': '6'}"
"Using this data, NO CLUSTERS obtains 60.0% UAS, PROJECTED CLUSTERS 63.6% and X-LINGUAL CLUSTERS 64.4%.","{'title': '5.1 Results', 'number': '6'}"
"When compared to the scores on the original data set (48.9%, 50.3% and 50.7%, respectively) we can see that not only is the baseline system doing much better, but that the improvements from cross-lingual clustering are much more pronounced.","{'title': '5.1 Results', 'number': '6'}"
"Next, we investigated the accuracy of subject and object dependencies, as these are often annotated in similar ways across treebanks, typically modifying the main verb of the sentence.","{'title': '5.1 Results', 'number': '6'}"
The bottom half of Table 5 gives the scores when restricted to such dependencies in the gold data.,"{'title': '5.1 Results', 'number': '6'}"
We measure the percentage of modifiers in subject and object dependencies that modify the correct word.,"{'title': '5.1 Results', 'number': '6'}"
"Indeed, here we see the difference in performance become clearer, with the cross-lingual cluster model reducing errors by 14% relative to the non-cross-lingual model and upwards of 22% relative for IT.","{'title': '5.1 Results', 'number': '6'}"
"We now turn to the results of the transfer experiments for NER, listed in Table 6.","{'title': '5.1 Results', 'number': '6'}"
"While the performance of the transfer systems is very poor when no word clusters are used, adding cross-lingual word clusters give substantial improvements across all languages.","{'title': '5.1 Results', 'number': '6'}"
"The simple PROJECTED CLUSTERS work well, but the X-LINGUAL CLUSTERS provide even larger improvements.","{'title': '5.1 Results', 'number': '6'}"
On average the latter reduce errors on the test set by 22% in terms of FI and up to 26% for ES.,"{'title': '5.1 Results', 'number': '6'}"
We also measure how well the direct transfer NER systems are able to detect entity boundaries (ignoring the entity categories).,"{'title': '5.1 Results', 'number': '6'}"
"Here, on average, the best clusters provide a 24% relative error reduction on the test set (75.8 vs. 68.1 FI).","{'title': '5.1 Results', 'number': '6'}"
To our knowledge there are no comparable results on transfer learning of NER systems.,"{'title': '5.1 Results', 'number': '6'}"
"Based on the results of this first attempt at this scenario, we believe that transfer learning by multilingual word clusters could be developed into a practical way to construct NER systems for resource poor languages.","{'title': '5.1 Results', 'number': '6'}"
"In the first part of this study, we showed that word clusters induced from a simple class-based language model can be used to significantly improve on stateof-the-art supervised dependency parsing and NER for a wide range of languages and even across language families.","{'title': '6 Conclusion', 'number': '7'}"
"Although the improvements vary between languages, the addition of word cluster features never has a negative impact on performance.","{'title': '6 Conclusion', 'number': '7'}"
This result has important practical consequences as it allows practitioners to simply plug in word cluster features into their current feature models.,"{'title': '6 Conclusion', 'number': '7'}"
"Given previous work on word clusters for various linguistic structure prediction tasks, these results are not too surprising.","{'title': '6 Conclusion', 'number': '7'}"
"However, to our knowledge this is the first study to apply the same type of word cluster features across languages and tasks.","{'title': '6 Conclusion', 'number': '7'}"
"In the second part, we provided two simple methods for inducing cross-lingual word clusters.","{'title': '6 Conclusion', 'number': '7'}"
"The first method works by projecting word clusters, induced from monolingual data, from a source language to a target language directly via word alignments.","{'title': '6 Conclusion', 'number': '7'}"
"The second method, on the other hand, makes use of monolingual data in both the source and the target language, together with word alignments that act as constraints on the joint clustering.","{'title': '6 Conclusion', 'number': '7'}"
"We then showed that by using these cross-lingual word clusters, we can significantly improve on direct transfer of discriminative models for both parsing and NER.","{'title': '6 Conclusion', 'number': '7'}"
"As in the monolingual case, both types of cross-lingual word cluster features yield improvements across the board, with the more complex method providing a significantly larger improvement for NER.","{'title': '6 Conclusion', 'number': '7'}"
"Although the performance of transfer systems is still substantially below that of supervised systems, this research provides one step towards bridging this gap.","{'title': '6 Conclusion', 'number': '7'}"
"Further, we believe that it opens up an avenue for future work on multilingual clustering methods, cross-lingual feature projection and domain adaptation for direct transfer of linguistic structure.","{'title': '6 Conclusion', 'number': '7'}"
"We thank John DeNero for help with creating the word alignments; Reut Tsarfaty and Joakim Nivre for rewarding discussions on evaluation; Slav Petrov and Kuzman Ganchev for discussions on cross-lingual clustering; and the anonymous reviewers, along with Joakim Nivre, for valuable comments that helped improve the paper.","{'title': 'Acknowledgments', 'number': '8'}"
The first author is grateful for the financial support of the Swedish National Graduate School of Language Technology (GSLT).,"{'title': 'Acknowledgments', 'number': '8'}"
"In the parsing experiments, we use the following data sets.","{'title': 'A Data Sets', 'number': '9'}"
"For DA, DE, EL, ES, IT, NL, PT and SV, we use the predefined training and evaluation data sets from the CoNLL 2006/2007 data sets (Buchholz and Marsi, 2006; Nivre et al., 2007).","{'title': 'A Data Sets', 'number': '9'}"
"For EN we use sections 02-21, 22, and 23 of the Penn WSJ Treebank (Marcus et al., 1993) for training, development and evaluation.","{'title': 'A Data Sets', 'number': '9'}"
"For FR we used the French Treebank (Abeill´e and Barrier, 2004) with splits defined in Candito et al. (2010).","{'title': 'A Data Sets', 'number': '9'}"
"For KO we use the Sejong Korean Treebank (Han et al., 2002) randomly splitting the data into 80% training, 10% development and 10% evaluation.","{'title': 'A Data Sets', 'number': '9'}"
"For RU we use the SynTagRus Treebank (Boguslavsky et al., 2000; Apresjan et al., 2006) randomly splitting the data into 80% training, 10% development and 10% evaluation.","{'title': 'A Data Sets', 'number': '9'}"
"For ZH we use the Penn Chinese Treebank v6 (Xue et al., 2005) using the proposed data splits from the documentation.","{'title': 'A Data Sets', 'number': '9'}"
"Both EN and ZH were converted to dependencies using v1.6.8 of the Stanford Converter (De Marneffe et al., 2006).","{'title': 'A Data Sets', 'number': '9'}"
FR was converted using the procedure defined in Candito et al. (2010).,"{'title': 'A Data Sets', 'number': '9'}"
RU and KO are native dependency treebanks.,"{'title': 'A Data Sets', 'number': '9'}"
For the CoNLL data sets we use the part-of-speech tags provided with the data.,"{'title': 'A Data Sets', 'number': '9'}"
"For all other data sets, we train a part-of-speech tagger on the training data in order to tag the development and evaluation data.","{'title': 'A Data Sets', 'number': '9'}"
"For the NER experiments we use the training, development and evaluation data sets from the CoNLL 2002/2003 shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003) for all four languages (DE, EN, ES and NL).","{'title': 'A Data Sets', 'number': '9'}"
"The data set for each language consists of newswire text annotated with four entity categories: Location (LOC), Miscellaneous (MISC), Organization (ORG) and Person (PER).","{'title': 'A Data Sets', 'number': '9'}"
"We use the part-of-speech tags supplied with the data, except for ES where we instead use universal part-of-speech tags (Petrov et al., 2011).","{'title': 'A Data Sets', 'number': '9'}"
Unlabeled data for training the monolingual cluster models was extracted from one year of newswire articles from multiple sources from a news aggregation website.,"{'title': 'A Data Sets', 'number': '9'}"
This consists of 0.8 billion (DA) to 121.6 billion (EN) tokens per language.,"{'title': 'A Data Sets', 'number': '9'}"
All word alignments for the cross-lingual clusterings were produced with the dual decomposition aligner described by DeNero and Macherey (2011) using 10.5 million (DA) to 12.1 million (FR) sentences of aligned web data.,"{'title': 'A Data Sets', 'number': '9'}"
