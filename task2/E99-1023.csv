col1,col2
"Dividing sentences in chunks of words is a useful preprocessing step for parsing, information extraction and information retrieval.",{}
"(Ramshaw and Marcus, 1995) have introduced a &quot;convenient&quot; data representation for chunking by converting it to a tagging task.",{}
In this paper we will examine seven different data representations for the problem of recognizing noun phrase chunks.,{}
We will show that the the data representation choice has a minor influence on chunking performance.,{}
"However, equipped with the most suitable data representation, our memory-based learning chunker was able to improve the best published chunking results for a standard data set.",{}
"The text corpus tasks parsing, information extraction and information retrieval can benefit from dividing sentences in chunks of words.","{'title': '1 Introduction', 'number': '1'}"
"(Ramshaw and Marcus, 1995) describe an error-driven transformation-based learning (TBL) method for finding NP chunks in texts.","{'title': '1 Introduction', 'number': '1'}"
"NP chunks (or baseNPs) are non-overlapping, non-recursive noun phrases.","{'title': '1 Introduction', 'number': '1'}"
"In their experiments they have modeled chunk recognition as a tagging task: words that are inside a baseNP were marked I, words outside a baseNP received an 0 tag and a special tag B was used for the first word inside a baseNP immediately following another baseNP.","{'title': '1 Introduction', 'number': '1'}"
"A text example: original: In [N early trading NI in [N Hong Kong N] [N Monday NI , [N gold N] was quoted at [N $ 366.50 NI [N an ounce N] â€¢ tagged: Other representations for NP chunking can be used as well.","{'title': '1 Introduction', 'number': '1'}"
"An example is the representation used in (Ratnaparkhi, 1998) where all the chunkinitial words receive the same start tag (analogous to the B tag) while the remainder of the words in the chunk are paired with a different tag.","{'title': '1 Introduction', 'number': '1'}"
This removes tagging ambiguities.,"{'title': '1 Introduction', 'number': '1'}"
In the Ratnaparkhi representation equal noun phrases receive the same tag sequence regardless of the context in which they appear.,"{'title': '1 Introduction', 'number': '1'}"
The data representation choice might influence the performance of chunking systems.,"{'title': '1 Introduction', 'number': '1'}"
In this paper we discuss how large this influence is.,"{'title': '1 Introduction', 'number': '1'}"
Therefore we will compare seven different data representation formats for the baseNP recognition task.,"{'title': '1 Introduction', 'number': '1'}"
We are particularly interested in finding out whether with one of the representation formats the best reported results for this task can be improved.,"{'title': '1 Introduction', 'number': '1'}"
The second section of this paper presents the general setup of the experiments.,"{'title': '1 Introduction', 'number': '1'}"
The results ean be found in the third section.,"{'title': '1 Introduction', 'number': '1'}"
In the fourth section we will describe some related work.,"{'title': '1 Introduction', 'number': '1'}"
In this section we present and explain the data representation formats and the machine learning algorithm that we have used.,"{'title': '2 Methods and experiments', 'number': '2'}"
In the final part we describe the feature representation used in our experiments.,"{'title': '2 Methods and experiments', 'number': '2'}"
"We have compared four complete and three partial data representation formats for the baseNP recognition task presented in (Ramshaw and Marcus, 1995).","{'title': '2 Methods and experiments', 'number': '2'}"
The four complete formats all use an I tag for words that are inside a baseNP and an 0 tag for words that are outside a baseNP.,"{'title': '2 Methods and experiments', 'number': '2'}"
They differ gold was quoted at S 366.50 an ounce . for seven different tagging formats.,"{'title': '2 Methods and experiments', 'number': '2'}"
"The I tag has been used for words inside a baseNP, 0 for words outside a baseNP, B and E for baseNP-initial words and E and] for baseNP-final words.","{'title': '2 Methods and experiments', 'number': '2'}"
"JOB' The first word inside a baseNP immediately following another baseNP receives a B tag (Ramshaw and Marcus, 1995).","{'title': '2 Methods and experiments', 'number': '2'}"
"I0B2 All baseNP-initial words receive a B tag (Ratnaparkhi, 1998).","{'title': '2 Methods and experiments', 'number': '2'}"
IOE1 The final word inside a baseNP immediately preceding another baseNP receives an E tag.,"{'title': '2 Methods and experiments', 'number': '2'}"
10E2 All baseNP-final words receive an E tag.,"{'title': '2 Methods and experiments', 'number': '2'}"
We wanted to compare these data representation formats with a standard bracket representation.,"{'title': '2 Methods and experiments', 'number': '2'}"
We have chosen to divide bracketing experiments in two parts: one for recognizing opening brackets and one for recognizing closing brackets.,"{'title': '2 Methods and experiments', 'number': '2'}"
Additionally we have worked with another partial representation which seemed promising: a tagging representation which disregards boundaries between adjacent chunks.,"{'title': '2 Methods and experiments', 'number': '2'}"
These boundaries can be recovered by combining this format with one of the bracketing formats.,"{'title': '2 Methods and experiments', 'number': '2'}"
"Our three partial representations are: All baseNP-initial words receive an [ tag, other words receive a . tag.","{'title': '2 Methods and experiments', 'number': '2'}"
"All baseNP-final words receive a ] tag, other words receive a . tag.","{'title': '2 Methods and experiments', 'number': '2'}"
"I0 Words inside a baseNP receive an I tag, others receive an 0 tag.","{'title': '2 Methods and experiments', 'number': '2'}"
"These partial representations can be combined in three pairs which encode the complete baseNP structure of the data: A word sequence is regarded as a baseNP if the first word has received an [ tag, the final word has received a ] tag and these are the only brackets that have been assigned to words in the sequence.","{'title': '2 Methods and experiments', 'number': '2'}"
"[ + JO In the 10 format, tags of words that have received an I tag and an [ tag are changed into B tags.","{'title': '2 Methods and experiments', 'number': '2'}"
The result is interpreted as the 10B2 format.,"{'title': '2 Methods and experiments', 'number': '2'}"
"10 + ] In the JO format, tags of words that have received an I tag and a ] tag are changed into E tags.","{'title': '2 Methods and experiments', 'number': '2'}"
The result is interpreted as the 10E2 format.,"{'title': '2 Methods and experiments', 'number': '2'}"
Examples of the four complete formats and the three partial formats can be found in table 1.,"{'title': '2 Methods and experiments', 'number': '2'}"
We have build a baseNP recognizer by training a machine learning algorithm with correct tagged data and testing it with unseen data.,"{'title': '2 Methods and experiments', 'number': '2'}"
The machine learning algorithm we used was a MemoryBased Learning algorithm (MBL).,"{'title': '2 Methods and experiments', 'number': '2'}"
During training it stores a symbolic feature representation of a word in the training data together with its classification (chunk tag).,"{'title': '2 Methods and experiments', 'number': '2'}"
In the testing phase the algorithm compares a feature representation of a test word with every training data item and chooses the classification of the training item which is closest to the test item.,"{'title': '2 Methods and experiments', 'number': '2'}"
"In the version of the algorithm that we have used, is 1-IG, the distances between feature representations are computed as the weighted sum of distances between individual features (Daelemans et al., 1998).","{'title': '2 Methods and experiments', 'number': '2'}"
"Equal features are defined to have distance 0, while the distance between other pairs is some feature-dependent value.","{'title': '2 Methods and experiments', 'number': '2'}"
"This value is equal to the information gain of the feature, an information theoretic measure which contains the in their treatment of chunk-initial and chunk-final [+1 words: normalized entropy decrease of the classification set caused by the presence of the feature.","{'title': '2 Methods and experiments', 'number': '2'}"
"Details of the algorithm can be found in (Daelemans et al., 1998)1.","{'title': '2 Methods and experiments', 'number': '2'}"
An important decision in an MBL experiment is the choice of the features that will be used for representing the data. is 1-IG is thought to be less sensitive to redundant features because of the data-dependent feature weighting that is included in the algorithm.,"{'title': '2 Methods and experiments', 'number': '2'}"
We have found that the presence of redundant features has a negative influence on the performance of the baseNP recognizer.,"{'title': '2 Methods and experiments', 'number': '2'}"
"In (Ramshaw and Marcus, 1995) a set of transformational rules is used for modifying the classification of words.","{'title': '2 Methods and experiments', 'number': '2'}"
"The rules use context information of the words, the part-of-speech tags that have been assigned to them and the chunk tags that are associated with them.","{'title': '2 Methods and experiments', 'number': '2'}"
We will use the same information as in our feature representation for words.,"{'title': '2 Methods and experiments', 'number': '2'}"
"In TBL, rules with different context information are used successively for solving different problems.","{'title': '2 Methods and experiments', 'number': '2'}"
We will use the same context information for all data.,"{'title': '2 Methods and experiments', 'number': '2'}"
The optimal context size will be determined by comparing the results of different context sizes on the training data.,"{'title': '2 Methods and experiments', 'number': '2'}"
Here we will perform four steps.,"{'title': '2 Methods and experiments', 'number': '2'}"
We will start with testing different context sizes of words with their part-ofspeech tag.,"{'title': '2 Methods and experiments', 'number': '2'}"
"After this, we will use the classification results of the best context size for determining the optimal context size for the classification tags.","{'title': '2 Methods and experiments', 'number': '2'}"
"As a third step, we will evaluate combinations of classification results and find the best combination.","{'title': '2 Methods and experiments', 'number': '2'}"
Finally we will examine the influence of an MBL algorithm parameter: the number of examined nearest neighbors.,"{'title': '2 Methods and experiments', 'number': '2'}"
"We have used the baseNP data presented in (Ramshaw and Marcus, 1995)2.","{'title': '3 Results', 'number': '3'}"
This data was divided in two parts.,"{'title': '3 Results', 'number': '3'}"
"The first part was training data and consisted of 211727 words taken from sections 15, 16, 17 and 18 from the Wall Street Journal corpus (WSJ).","{'title': '3 Results', 'number': '3'}"
The second part was test data and consisted of 47377 words taken from section 20 of the same corpus.,"{'title': '3 Results', 'number': '3'}"
The words were part-of-speech (POS) tagged with the Brill tagger and each word was classified as being inside or outside a baseNP with the IOB1 representation scheme.,"{'title': '3 Results', 'number': '3'}"
"The chunking classification was made by (Ramshaw and Marcus, 1995) based on the parsing information in the WSJ corpus.","{'title': '3 Results', 'number': '3'}"
"The performance of the baseNP recognizer can be measured in different ways: by computing the percentage of correct classification tags (accuracy), the percentage of recognized baseNPs that are correct (precision) and the percentage of baseNPs in the corpus that are found (recall).","{'title': '3 Results', 'number': '3'}"
"We will follow (Argamon et al., 1998) and use a combination of the precision and recall rates: Fo.--1 = (2*precision*recall)/(precision+recall).","{'title': '3 Results', 'number': '3'}"
In our first experiment series we have tried to discover the best word/part-of-speech tag context for each representation format.,"{'title': '3 Results', 'number': '3'}"
For computational reasons we have limited ourselves to working with section 15 of the WSJ corpus.,"{'title': '3 Results', 'number': '3'}"
This section contains 50442 words.,"{'title': '3 Results', 'number': '3'}"
We have run 5-fold crossvalidation experiments with all combinations of left and right contexts of word/POS tag pairs in the size range 0 to 4.,"{'title': '3 Results', 'number': '3'}"
A summary of the results can be found in table 2.,"{'title': '3 Results', 'number': '3'}"
The baseNP recognizer performed best with relatively small word/POS tag pair contexts.,"{'title': '3 Results', 'number': '3'}"
Different representation formats required different context sizes for optimal performance.,"{'title': '3 Results', 'number': '3'}"
All formats context sizes for the seven representation formats using 5-fold cross-validation on section 15 of the WSJ corpus. with explicit open bracket information preferred larger left context and most formats with explicit closing bracket information preferred larger right context size.,"{'title': '3 Results', 'number': '3'}"
The three combinations of partial representations systematically outperformed the four complete representations.,"{'title': '3 Results', 'number': '3'}"
This is probably caused by the fact that they are able to use two different context sizes for solving two different parts of the recognition problem.,"{'title': '3 Results', 'number': '3'}"
In a second series of experiments we used a &quot;cascaded&quot; classifier.,"{'title': '3 Results', 'number': '3'}"
This classifier has two stages (cascades).,"{'title': '3 Results', 'number': '3'}"
The first cascade is similar to the classifier described in the first experiment.,"{'title': '3 Results', 'number': '3'}"
For the second cascade we added the classifications of the first cascade as extra features.,"{'title': '3 Results', 'number': '3'}"
The extra features consisted of the left and the right context of the classification tags.,"{'title': '3 Results', 'number': '3'}"
The focus chunk tag (the classification of the current word) accounts for the correct classification in about 95% of the cases.,"{'title': '3 Results', 'number': '3'}"
The MBL algorithm assigns a large weight to this input feature and this makes it harder for the other features to contribute to a good result.,"{'title': '3 Results', 'number': '3'}"
To avoid this we have refrained from using this tag.,"{'title': '3 Results', 'number': '3'}"
Our goal was to find out the optimal number of extra classification tags in the input.,"{'title': '3 Results', 'number': '3'}"
We performed 5-fold cross-validation experiments with all combinations of left and right classification tag contexts in the range 0 tags to 3 tags.,"{'title': '3 Results', 'number': '3'}"
A summary of the results can be found in table 33.,"{'title': '3 Results', 'number': '3'}"
We achieved higher P3=1 for all representations except for the bracket pair representation.,"{'title': '3 Results', 'number': '3'}"
"The third experiment series was similar to the second but instead of adding output of one experiment we added classification results of three, four or five experiments of the first series.","{'title': '3 Results', 'number': '3'}"
By doing this we supplied the learning algorithm with information about different context sizes.,"{'title': '3 Results', 'number': '3'}"
This information is available to TBL in the rules which use different contexts.,"{'title': '3 Results', 'number': '3'}"
"We have limited ourselves to examining all successive combinations of three, four and five experiments of the lists (L=0/R=0, 1/1, 2/2, 3/3, 4/4), (0/1, 1/2, 2/3, 3/4) and (1/0, 2/1, 3/2, 4/3).","{'title': '3 Results', 'number': '3'}"
A summary of the results can be found in table 4.,"{'title': '3 Results', 'number': '3'}"
The results for four representation formats improved.,"{'title': '3 Results', 'number': '3'}"
In the fourth experiment series we have experimented with a different value for the number of nearest neighbors examined by the iBl-IG algorithm (parameter k).,"{'title': '3 Results', 'number': '3'}"
This algorithm standardly uses the single training item closest to the test 3In a number of cases a different base configuration in one experiment series outperformed the best base configuration found in the previous series.,"{'title': '3 Results', 'number': '3'}"
In the second series L/R=1/2 outperformed 2/2 for 10E2 when chunk tags were added and in the third series chunk tag context 1/1 outperformed 1/2 for IOB1 when different combinations were tested. right classification tag context sizes for the seven representation formats using 5-fold cross-validation on section 15 of the WSJ corpus obtained with iBl-IG parameter k=3.,"{'title': '3 Results', 'number': '3'}"
IOB1 is the best representation format but the differences with the results of the other formats are not significant. item.,"{'title': '3 Results', 'number': '3'}"
"However (Daelemans et al., 1999) report that for baseNP recognition better results can be obtained by making the algorithm consider the classification values of the three closest training items.","{'title': '3 Results', 'number': '3'}"
We have tested this by repeating the first experiment series and part of the third experiment series for k=3.,"{'title': '3 Results', 'number': '3'}"
In this revised version we have repeated the best experiment of the third series with the results for k=1 replaced by the k=3 results whenever the latter outperformed the first in the revised first experiment series.,"{'title': '3 Results', 'number': '3'}"
The results can be found in table 5.,"{'title': '3 Results', 'number': '3'}"
All formats benefited from this step.,"{'title': '3 Results', 'number': '3'}"
In this final experiment series the best results were obtained with IOB1 but the differences with the results of the other formats are not significant.,"{'title': '3 Results', 'number': '3'}"
"We have used the optimal experiment configurations that we had obtained from the fourth experiment series for processing the complete (Ramshaw and Marcus, 1995) data set.","{'title': '3 Results', 'number': '3'}"
The results can be found in table 6.,"{'title': '3 Results', 'number': '3'}"
They are better than the results for section 15 because more training data was used in these experiments.,"{'title': '3 Results', 'number': '3'}"
"Again the best result was obtained with IOB1 (F0=1=92.37) which is an improvement of the best reported Fi3=1 rate for this data set ((Rainshaw and Marcus, 1995): 92.03).","{'title': '3 Results', 'number': '3'}"
"We would like to apply our learning approach to the large data set mentioned in (Ramshaw and Marcus, 1995): Wall Street Journal corpus sections 2-21 as training material and section 0 as test material.","{'title': '3 Results', 'number': '3'}"
"With our present hardware applying our optimal experiment, configuration to this data would require several months of computer time.","{'title': '3 Results', 'number': '3'}"
Therefore we have only used the best stage 1 approach with IOB1 tags: a left and right context of three words and three POS tags combined with k=3.,"{'title': '3 Results', 'number': '3'}"
"This time the chunker achieved a p3=1 score of 93.81 which is half a point better than the results obtained by (Ramshaw and Marcus, 1995): 93.3 (other chunker rates for this data: accuracy: 98.04%; precision: 93.71%; recall: 93.90%).","{'title': '3 Results', 'number': '3'}"
"The concept of chunking was introduced by Abney in (Abney, 1991).","{'title': '4 Related work', 'number': '4'}"
He suggested to develop a chunking parser which uses a two-part syntactic analysis: creating word chunks (partial trees) and attaching the chunks to create complete syntactic trees.,"{'title': '4 Related work', 'number': '4'}"
Abney obtained support for such a chunking stage from psycholinguistic literature.,"{'title': '4 Related work', 'number': '4'}"
"Ramshaw and Marcus used transformationbased learning (TBL) for developing two chunkers (Ramshaw and Marcus, 1995).","{'title': '4 Related work', 'number': '4'}"
One was trained to recognize baseNPs and the other was trained to recognize both NP chunks and VP chunks.,"{'title': '4 Related work', 'number': '4'}"
Ramshaw and Marcus approached the chunking task as a tagging problem.,"{'title': '4 Related work', 'number': '4'}"
Their baseNP training and test data from the Wall Street Journal corpus are still being used as benchmark data for current chunking experiments.,"{'title': '4 Related work', 'number': '4'}"
"(Ramshaw and Marcus, 1995) shows that baseNP recognition (F0=1=92.0) is easier than finding both NP and VP chunks (F0=1=88.1) and that increasing the size of the training data increases the performance on the test set.","{'title': '4 Related work', 'number': '4'}"
The work by Ramshaw and Marcus has inspired three other groups to build chunking algorithms.,"{'title': '4 Related work', 'number': '4'}"
"(Argamon et al., 1998) introduce Memory-Based Sequence Learning and use it for different chunking experiments.","{'title': '4 Related work', 'number': '4'}"
Their algorithm stores sequences of POS tags with chunk brackets and uses this information for recognizing chunks in unseen data.,"{'title': '4 Related work', 'number': '4'}"
"It performed slightly worse on baseNP recognition than the (Ramshaw and Marcus, 1995) experiments (F0=1=91.6).","{'title': '4 Related work', 'number': '4'}"
"(Cardie and Pierce, 1998) uses a related method but they only store POS tag sequences forming complete baseNPs.","{'title': '4 Related work', 'number': '4'}"
These sequences were applied to unseen tagged data after which post-processing repair rules were used for fixing some frequent errors.,"{'title': '4 Related work', 'number': '4'}"
This approach performs worse than other reported approaches (F0=1=90.9). training data set.,"{'title': '4 Related work', 'number': '4'}"
The data was processed with the optimal input feature combinations found in the fourth experiment series.,"{'title': '4 Related work', 'number': '4'}"
The accuracy rate contains the fraction of chunk tags that was correct.,"{'title': '4 Related work', 'number': '4'}"
The other three rates regard baseNP recognition.,"{'title': '4 Related work', 'number': '4'}"
The bottom part of the table shows some other reported results with this data set.,"{'title': '4 Related work', 'number': '4'}"
"With all but two formats isl-IG achieves better Fo=1 rates than the best published result in (Ramshaw and Marcus, 1995).","{'title': '4 Related work', 'number': '4'}"
"(Veenstra, 1998) uses cascaded decision tree learning (IGTree) for baseNP recognition.","{'title': '4 Related work', 'number': '4'}"
"This algorithm stores context information of words, POS tags and chunking tags in a decision tree and classifies new items by comparing them to the training items.","{'title': '4 Related work', 'number': '4'}"
"The algorithm is very fast and it reaches the same performance as (Argamon et al., 1998) (F0=1=91.6).","{'title': '4 Related work', 'number': '4'}"
"(Daelemans et al., 1999) uses cascaded MBL (rB1-IG) in a similar way for several tasks among which baseNP recognition.","{'title': '4 Related work', 'number': '4'}"
They do not report Fo=i rates but their tag accuracy rates are a lot better than accuracy rates reported by others.,"{'title': '4 Related work', 'number': '4'}"
"However, they use the (R,amshaw and Marcus, 1995) data set in a different, training-test division (10-fold cross validation) which makes it difficult to compare their results with others.","{'title': '4 Related work', 'number': '4'}"
We have compared seven different data formats for the recognition of baseNPs with memory-based learning (lB1-10).,"{'title': '5 Concluding remarks', 'number': '5'}"
"The I0B1 format, introduced in (Ramshaw and Marcus, 1995), consistently came out as the best format.","{'title': '5 Concluding remarks', 'number': '5'}"
"However, the differences with other formats were not significant.","{'title': '5 Concluding remarks', 'number': '5'}"
"Some representation formats achieved better precision rates, others better recall rates.","{'title': '5 Concluding remarks', 'number': '5'}"
"This information is useful for tasks that require chunking structures because some tasks might, be more interested in high precision rates while others might be more interested in high recall rates.","{'title': '5 Concluding remarks', 'number': '5'}"
"The 031-1G algorithm has been able to improve the best reported Fo=1 rates for a standard data set, (92.37 versus (Ramshaw and Marcus, 1995)'s 92.03).","{'title': '5 Concluding remarks', 'number': '5'}"
This result was aided by using non-standard parameter values (k=3) and the algorithm was sensitive for redundant input features.,"{'title': '5 Concluding remarks', 'number': '5'}"
This means that finding an optimal performance or this task requires searching a large parameter/feature configuration space.,"{'title': '5 Concluding remarks', 'number': '5'}"
"An interesting topic for future research would be to embed Isl-IG in a standard search algorithm, like hillclimbing, and explore this parameter space.","{'title': '5 Concluding remarks', 'number': '5'}"
Some more room for improved performance lies in computing the POS tags in the data with a better tagger than presently used.,"{'title': '5 Concluding remarks', 'number': '5'}"
