col1,col2
"and Abstracts for Nice Summaries, In Workon Automatic Philadelphia, PA, pp.",{}
9-14.,{}
"Edmundson, H. (1969).",{}
“New methods in automatic of the 16(2).,{}
"Grefenstett, G. (1998).",{}
Producing intelligent telegraphic text reduction to provide an audio scanning serfor the blind.,{}
"In Notes of the AIII Spring on Intelligent Text Summarization,",{}
"In this paper we present Hedge Trimmer, a HEaDline GEneration system that creates a headline for a newspaper story by removing constituents from a parse tree of the first sentence until a length threshold has been reached.","{'title': '1 Introduction', 'number': '1'}"
"Linguistically-motivated heuristics guide the choice of which constituents of a story should be preserved, and which ones should be deleted.","{'title': '1 Introduction', 'number': '1'}"
"Our focus is on headline generation for English newspaper texts, with an eye toward the production of document surrogates—for cross-language information retrieval—and the eventual generation of readable headlines from speech broadcasts.","{'title': '1 Introduction', 'number': '1'}"
"In contrast to original newspaper headlines, which are often intended only to catch the eye, our approach produces informative abstracts describing the main theme or event of the newspaper article.","{'title': '1 Introduction', 'number': '1'}"
"We claim that the construction of informative abstracts requires access to deeper linguistic knowledge, in order to make substantial improvements over purely statistical approaches.","{'title': '1 Introduction', 'number': '1'}"
"In this paper, we present our technique for producing headlines using a parse-and-trim approach based on the BBN Parser.","{'title': '1 Introduction', 'number': '1'}"
"As described in Miller et al. (1998), the BBN parser builds augmented parse trees according to a process similar to that described in Collins (1997).","{'title': '1 Introduction', 'number': '1'}"
"The BBN parser has been used successfully for the task of information extraction in the SIFT system (Miller et al., 2000).","{'title': '1 Introduction', 'number': '1'}"
The next section presents previous work in the area of automatic generation of abstracts.,"{'title': '1 Introduction', 'number': '1'}"
"Following this, we present feasibility tests used to establish the validity of an approach that constructs headlines from words in a story, taken in order and focusing on the earlier part of the story.","{'title': '1 Introduction', 'number': '1'}"
"Next, we describe the application of the parse-and-trim approach to the problem of headline generation.","{'title': '1 Introduction', 'number': '1'}"
We discuss the linguistically-motivated heuristics we use to produce results that are headlinelike.,"{'title': '1 Introduction', 'number': '1'}"
"Finally, we evaluate Hedge Trimmer by comparing it to our earlier work on headline generation, a probabilistic model for automatic headline generation (Zajic et al, 2002).","{'title': '1 Introduction', 'number': '1'}"
"In this paper we will refer to this statistical system as HMM Hedge We demonstrate the effectiveness of our linguistically-motivated approach, Hedge Trimmer, over the probabilistic model, HMM Hedge, using both human evaluation and automatic metrics.","{'title': '1 Introduction', 'number': '1'}"
"Other researchers have investigated the topic of automatic generation of abstracts, but the focus has been different, e.g., sentence extraction (Edmundson, 1969; Johnson et al, 1993; Kupiec et al., 1995; Mann et al., 1992; Teufel and Moens, 1997; Zechner, 1995), processing of structured templates (Paice and Jones, 1993), sentence compression (Hori et al., 2002; Knight and Marcu, 2001; Grefenstette, 1998, Luhn, 1958), and generation of abstracts from multiple sources (Radev and McKeown, 1998).","{'title': '2 Previous Work', 'number': '2'}"
We focus instead on the construction of headline-style abstracts from a single story.,"{'title': '2 Previous Work', 'number': '2'}"
"Headline generation can be viewed as analogous to statistical machine translation, where a concise document is generated from a verbose one using a Noisy Channel Model and the Viterbi search to select the most likely summarization.","{'title': '2 Previous Work', 'number': '2'}"
"This approach has been explored in (Zajic et al., 2002) and (Banko et al., 2000).","{'title': '2 Previous Work', 'number': '2'}"
"The approach we use in Hedge is most similar to that of (Knight and Marcu, 2001), where a single sentence is shortened using statistical compression.","{'title': '2 Previous Work', 'number': '2'}"
"As in this work, we select headline words from story words in the order that they appear in the story—in particular, the first sentence of the story.","{'title': '2 Previous Work', 'number': '2'}"
"However, we use linguistically motivated heuristics for shortening the sentence; there is no statistical model, which means we do not require any prior training on a large corpus of story/headline pairs.","{'title': '2 Previous Work', 'number': '2'}"
"Linguistically motivated heuristics have been used by (McKeown et al, 2002) to distinguish constituents of parse trees which can be removed without affecting grammaticality or correctness.","{'title': '2 Previous Work', 'number': '2'}"
"GLEANS (Daumé et al, 2002) uses parsing and named entity tagging to fill values in headline templates.","{'title': '2 Previous Work', 'number': '2'}"
"Consider the following excerpt from a news story: In this case, the words in bold form a fluent and accurate headline for the story.","{'title': '2 Previous Work', 'number': '2'}"
Italicized words are deleted based on information provided in a parse-tree representation of the sentence.,"{'title': '2 Previous Work', 'number': '2'}"
"Our approach is based on the selection of words from the original story, in the order that they appear in the story, and allowing for morphological variation.","{'title': '3 Feasibility Testing', 'number': '3'}"
"To determine the feasibility of our headline-generation approach, we first attempted to apply our “select-wordsin-order” technique by hand.","{'title': '3 Feasibility Testing', 'number': '3'}"
"We asked two subjects to write headline headlines for 73 AP stories from the TIPSTER corpus for January 1, 1989, by selecting words in order from the story.","{'title': '3 Feasibility Testing', 'number': '3'}"
"Of the 146 headlines, 2 did not meet the “select-words-in-order” criteria because of accidental word reordering.","{'title': '3 Feasibility Testing', 'number': '3'}"
We found that at least one fluent and accurate headline meeting the criteria was created for each of the stories.,"{'title': '3 Feasibility Testing', 'number': '3'}"
The average length of the headlines was 10.76 words.,"{'title': '3 Feasibility Testing', 'number': '3'}"
"Later we examined the distribution of the headline words among the sentences of the stories, i.e. how many came from the first sentence of a story, how many from the second sentence, etc.","{'title': '3 Feasibility Testing', 'number': '3'}"
The results of this study are shown in Figure 1.,"{'title': '3 Feasibility Testing', 'number': '3'}"
We observe that 86.8% of the headline words were chosen from the first sentence of their stories.,"{'title': '3 Feasibility Testing', 'number': '3'}"
"We performed a subsequent study in which two subjects created 100 headlines for 100 AP stories from August 6, 1990.","{'title': '3 Feasibility Testing', 'number': '3'}"
51.4% of the headline words in the second set were chosen from the first sentence.,"{'title': '3 Feasibility Testing', 'number': '3'}"
The distribution of headline words for the second set shown in Figure 2.,"{'title': '3 Feasibility Testing', 'number': '3'}"
"Although humans do not always select headline words from the first sentence, we observe that a large percentage of headline words are often found in the first sentence.","{'title': '3 Feasibility Testing', 'number': '3'}"
"The input to Hedge is a story, whose first sentence is immediately passed through the BBN parser.","{'title': '4 Approach', 'number': '4'}"
The parse-tree result serves as input to a linguisticallymotivated module that selects story words to form headlines based on key insights gained from our observations of human-constructed headlines.,"{'title': '4 Approach', 'number': '4'}"
"That is, we conducted a human inspection of the 73 TIPSTER stories mentioned in Section 3 for the purpose of developing the Hedge Trimmer algorithm.","{'title': '4 Approach', 'number': '4'}"
"Based on our observations of human-produced headlines, we developed the following algorithm for parse-tree trimming: More recently, we conducted an automatic analysis of the human-generated headlines that supports several of the insights gleaned from this initial study.","{'title': '4 Approach', 'number': '4'}"
We parsed 218 human-produced headlines using the BBN parser and analyzed the results.,"{'title': '4 Approach', 'number': '4'}"
"For this analysis, we used 72 headlines produced by a third participant.1 The parsing results included 957 noun phrases (NP) and 315 clauses (S).","{'title': '4 Approach', 'number': '4'}"
"We calculated percentages based on headline-level, NP-level, and Sentence-level structures in the parsing results.","{'title': '4 Approach', 'number': '4'}"
"That is, we counted: Figure 3 summarizes the results of this automatic analysis.","{'title': '4 Approach', 'number': '4'}"
"In our initial human inspection, we considered each of these categories to be reasonable candidates for deletion in our parse tree and this automatic analysis indicates that we have made reasonable choices for deletion, with the possible exception of trailing PPs, which show up in over half of the human-generated headlines.","{'title': '4 Approach', 'number': '4'}"
This suggests that we should proceed with caution with respect to the deletion of trailing PPs; thus we consider this to be an option only if no other is available.,"{'title': '4 Approach', 'number': '4'}"
preposed adjuncts = 0/218 (0%) conjoined S = 1/218 ( .5%) conjoined VP = 7/218 (3%),"{'title': 'HEADLINE-LEVEL PERCENTAGES', 'number': '5'}"
"relative clauses = 3/957 (.3%) determiners = 31/957 (3%); of these, only 16 were “a” or “the” (1.6% overall) S-LEVEL PERCENTAGES2 time expressions = 5/315 (1.5%) trailing PPs = 165/315 (52%) trailing SBARs = 24/315 (8%) 1 No response was given for one of the 73 stories.","{'title': 'NP-LEVEL PERCENTAGES', 'number': '6'}"
2 Trailing constituents (SBARs and PPs) are computed by counting the number of SBARs (or PPs) not designated as an argument of (contained in) a verb phrase.,"{'title': 'NP-LEVEL PERCENTAGES', 'number': '6'}"
"For a comparison, we conducted a second analysis in which we used the same parser on just the first sentence of each of the 73 stories.","{'title': 'NP-LEVEL PERCENTAGES', 'number': '6'}"
"In this second analysis, the parsing results included 817 noun phrases (NP) and 316 clauses (S).","{'title': 'NP-LEVEL PERCENTAGES', 'number': '6'}"
A summary of these results is shown in Figure 4.,"{'title': 'NP-LEVEL PERCENTAGES', 'number': '6'}"
"Note that, across the board, the percentages are higher in this analysis than in the results shown in Figure 3 (ranging from 12% higher—in the case of trailing PPs—to 1500% higher in the case of time expressions), indicating that our choices of deletion in the Hedge Trimmer algorithm are well-grounded.","{'title': 'NP-LEVEL PERCENTAGES', 'number': '6'}"
preposed adjuncts = 2/73 (2.7%) conjoined S = 3/73 (4%) conjoined VP = 20/73 (27%),"{'title': 'HEADLINE-LEVEL PERCENTAGES', 'number': '7'}"
"relative clauses = 29/817 (3.5%) determiners = 205/817 (25%); of these, only 171 were “a” or “the” (21% overall)","{'title': 'NP-LEVEL PERCENTAGES', 'number': '8'}"
time expressions = 77/316 (24%) trailing PPs = 184/316 (58%) trailing SBARs = 49/316 (16%) each story.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"The first step relies on what is referred to as the Projection Principle in linguistic theory (Chomsky, 1981): Predicates project a subject (both dominated by S) in the surface structure.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Our human-generated headlines always conformed to this rule; thus, we adopted it as a constraint in our algorithm.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"An example of the application of step 1 above is the following, where boldfaced material from the parse tree representation is retained and italicized material is eliminated: with government]] officials said Tuesday.]","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
Output of step 1: Rebels agree to talks with government.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"When the parser produces a correct tree, this step provides a grammatical headline.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"However, the parser often produces an incorrect output.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Human inspection of our 624-sentence DUC-2003 evaluation set revealed that there were two such scenarios, illustrated by the following cases: In the first case, an S exists, but it does not conform to the requirements of step 1.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
This occurred in 2.6% of the sentences in the DUC-2003 evaluation data.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"We resolve this by selecting the lowest leftmost S, i.e., the entire string “What started as a local controversy has evolved into an international scandal” in the example above.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"In the second case, there is no S available.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
This occurred in 3.4% of the sentences in the evaluation data.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
We resolve this by selecting the root of the parse tree; this would be the entire string “Bangladesh and India signed a water sharing accord” above.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
No other parser errors were encountered in the DUC-2003 evaluation data.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
Step 2 of our algorithm eliminates low-content units.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
We start with the simplest low-content units: the determiners a and the.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Other determiners were not considered for deletion because our analysis of the humanconstructed headlines revealed that most of the other determiners provide important information, e.g., negation (not), quantifiers (each, many, several), and deictics (this, that).","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Beyond these, we found that the human-generated headlines contained very few time expressions which, although certainly not content-free, do not contribute toward conveying the overall “who/what content” of the story.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Since our goal is to provide an informative headline (i.e., the action and its participants), the identification and elimination of time expressions provided a significant boost in the performance of our automatic headline generator.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"We identified time expressions in the stories using BBN’s IdentiFinderTM (Bikel et al, 1999).","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
We implemented the elimination of time expressions as a twostep process: where X is tagged as part of a time expression The following examples illustrate the application of this step: Output of step 2: State Department lifted ban it has imposed on foreign fliers.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
Output of step 2: International relief agency announced that it is withdrawing from North Korea.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
We found that 53.2% of the stories we examined contained at least one time expression which could be deleted.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Human inspection of the 50 deleted time expressions showed that 38 were desirable deletions, 10 were locally undesirable because they introduced an ungrammatical fragment,3 and 2 were undesirable because they removed a potentially relevant constituent.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"However, even an undesirable deletion often pans out for two reasons: (1) the ungrammatical fragment is frequently deleted later by some other rule; and (2) every time a constituent is removed it makes room under the threshold for some other, possibly more relevant constituent.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
Consider the following examples.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
Example (7) was produced by a system which did not remove time expressions.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Example (8) shows that if the time expression Sunday were removed, it would make room below the 10-word threshold for another important piece of information.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"The final step, iterative shortening, removes linguistically peripheral material—through successive deletions—until the sentence is shorter than a given threshold.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"We took the threshold to be 10 for the DUC task, but it is a configurable parameter.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Also, given that the human-generated headlines tended to retain earlier material more often than later material, much of our iterative shortening is focused on deleting the rightmost phrasal categories until the length is below threshold.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
There are four types of iterative shortening rules.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"The first type is a rule we call “XP-over-XP,” which is implemented as follows: In constructions of the form [XP [XP ...] ...] remove the other children of the higher XP, where XP is NP, VP or S. This is a linguistic generalization that allowed us apply a single rule to capture three different phenomena (relative clauses, verb-phrase conjunction, and sentential conjunction).","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"The rule is applied iteratively, from the deepest rightmost applicable node backwards, until the length threshold is reached.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"The impact of XP-over-XP can be seen in these examples of NP-over-NP (relative clauses), VP-over-VP (verb-phrase conjunction), and S-over-S (sentential conjunction), respectively: Parse: [S [Det A] fire killed [Det a] [NP [NP firefighter] [SBAR who was fatally injured as he searched the house] ]] Output of NP-over-NP: fire killed firefighter has outpaced state laws, but the state says the company doesn’t have the proper licenses.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Parse: [S [Det A] company offering blood cholesterol tests in grocery stores says [S [S medical technology has outpaced state laws], [CC but] [S [Det the] state stays [Det the] company doesn’t have [Det the] proper licenses.]]","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
] Output of S-over-S: Company offering blood cholesterol tests in grocery store says medical technology has outpaced state laws The second type of iterative shortening is the removal of preposed adjuncts.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
The motivation for this type of shortening is that all of the human-generated headlines ignored what we refer to as the preamble of the story.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Assuming the Projection principle has been satisfied, the preamble is viewed as the phrasal material occurring before the subject of the sentence.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Thus, adjuncts are identified linguistically as any XP unit preceding the first NP (the subject) under the S chosen by step 1.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"This type of phrasal modifier is invisible to the XP-over-XP rule, which deletes material under a node only if it dominates another node of the same phrasal category.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"The impact of this type of shortening can be seen in the following example: Parse: [S [PP According to a now-finalized blueprint described by U.S. officials and other sources] [Det the] Bush administration plans to take complete, unilateral control of [Det a] postSaddam Hussein Iraq ] Output of Preposed Adjunct Removal: Bush administration plans to take complete unilateral control of post-Saddam Hussein Iraq The third and fourth types of iterative shortening are the removal of trailing PPs and SBARs, respectively: These are the riskiest of the iterative shortening rules, as indicated in our analysis of the human-generated headlines.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Thus, we apply these conservatively, only when there are no other categories of rules to apply.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Moreover, these rules are applied with a backoff option to avoid over-trimming the parse tree.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
First the PP shortening rule is applied.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"If the threshold has been reached, no more shortening is done.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"However, if the threshold has not been reached, the system reverts to the parse tree as it was before any PPs were removed, and applies the SBAR shortening rule.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"If the threshold still has not been reached, the PP rule is applied to the result of the SBAR rule.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
Other sequences of shortening rules are possible.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
The one above was observed to produce the best results on a 73-sentence development set of stories from the TIPSTER corpus.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"The intuition is that, when removing constituents from a parse tree, it’s best to remove smaller portions during each iteration, to avoid producing trees with undesirably few words.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
PPs tend to represent small parts of the tree while SBARs represent large parts of the tree.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
"Thus we try to reach the threshold by removing small constituents, but if we can’t reach the threshold that way, we restore the small constituents, remove a large constituent and resume the deletion of small constituents.","{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
The impact of these two types of shortening can be seen in the following examples: Parse: [S More oil-covered sea birds were found [PP over the weekend]] Output of PP Removal: More oil-covered sea birds were found.,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
Parse: [S Visiting China Interpol chief expressed confidence in Hong Kong’s smooth transition [SBAR while assuring closer cooperation after Hong Kong returns]] Output of SBAR Removal: Visiting China Interpol chief expressed confidence in Hong Kong’s smooth transition,"{'title': 'S-LEVEL PERCENTAGES', 'number': '9'}"
We conducted two evaluations.,"{'title': '5 Evaluation', 'number': '10'}"
One was an informal human assessment and one was a formal automatic evaluation.,"{'title': '5 Evaluation', 'number': '10'}"
"We compared our current system to a statistical headline generation system we presented at the 2001 DUC Summarization Workshop (Zajic et al., 2002), which we will refer to as HMM Hedge.","{'title': '5 Evaluation', 'number': '10'}"
HMM Hedge treats the summarization problem as analogous to statistical machine translation.,"{'title': '5 Evaluation', 'number': '10'}"
"The verbose language, articles, is treated as the result of a concise language, headlines, being transmitted through a noisy channel.","{'title': '5 Evaluation', 'number': '10'}"
The result of the transmission is that extra words are added and some morphological variations occur.,"{'title': '5 Evaluation', 'number': '10'}"
The Viterbi algorithm is used to calculate the most likely unseen headline to have generated the seen article.,"{'title': '5 Evaluation', 'number': '10'}"
The Viterbi algorithm is biased to favor headline-like characteristics gleaned from observation of human performance of the headline-construction task.,"{'title': '5 Evaluation', 'number': '10'}"
"Since the 2002 Workshop, HMM Hedge has been enhanced by incorporating part of speech of information into the decoding process, rejecting headlines that do not contain a word that was used as a verb in the story, and allowing morphological variation only on words that were used as verbs in the story.","{'title': '5 Evaluation', 'number': '10'}"
"HMM Hedge was trained on 700,000 news articles and headlines from the TIPSTER corpus.","{'title': '5 Evaluation', 'number': '10'}"
"BLEU (Papineni et al, 2002) is a system for automatic evaluation of machine translation.","{'title': '5 Evaluation', 'number': '10'}"
BLEU uses a modified n-gram precision measure to compare machine translations to reference human translations.,"{'title': '5 Evaluation', 'number': '10'}"
"We treat summarization as a type of translation from a verbose language to a concise one, and compare automatically generated headlines to human generated headlines.","{'title': '5 Evaluation', 'number': '10'}"
"For this evaluation we used 100 headlines created for 100 AP stories from the TIPSTER collection for August 6, 1990 as reference summarizations for those stories.","{'title': '5 Evaluation', 'number': '10'}"
These 100 stories had never been run through either system or evaluated by the authors prior to this evaluation.,"{'title': '5 Evaluation', 'number': '10'}"
We also used the 2496 manual abstracts for the DUC2003 10-word summarization task as reference translations for the 624 test documents of that task.,"{'title': '5 Evaluation', 'number': '10'}"
"We used two variants of HMM Hedge, one which selects headline words from the first 60 words of the story, and one which selects words from the first sentence of the story.","{'title': '5 Evaluation', 'number': '10'}"
"Table 1 shows the BLEU score using trigrams, and the 95% confidence interval for the score.","{'title': '5 Evaluation', 'number': '10'}"
"These results show that although Hedge Trimmer scores slightly higher than HMM Hedge on both data sets, the results are not statistically significant.","{'title': '5 Evaluation', 'number': '10'}"
"However, we believe that the difference in the quality of the systems is not adequately reflected by this automatic evaluation.","{'title': '5 Evaluation', 'number': '10'}"
Human evaluation indicates significantly higher scores than might be guessed from the automatic evaluation.,"{'title': '5 Evaluation', 'number': '10'}"
"For the 100 AP stories from the TIPSTER corpus for August 6, 1990, the output of Hedge Trimmer and HMM Hedge was evaluated by one human.","{'title': '5 Evaluation', 'number': '10'}"
"Each headline was given a subjective score from 1 to 5, with 1 being the worst and 5 being the best.","{'title': '5 Evaluation', 'number': '10'}"
The average score of HMM Hedge was 3.01 with standard deviation of 1.11.,"{'title': '5 Evaluation', 'number': '10'}"
The average score of Hedge Trimmer was 3.72 with standard deviation of 1.26.,"{'title': '5 Evaluation', 'number': '10'}"
"Using a t-score, the difference is significant with greater than 99.9% confidence.","{'title': '5 Evaluation', 'number': '10'}"
The types of problems exhibited by the two systems are qualitatively different.,"{'title': '5 Evaluation', 'number': '10'}"
"The probabilistic system is more likely to produce an ungrammatical result or omit a necessary argument, as in the examples below.","{'title': '5 Evaluation', 'number': '10'}"
"In contrast, the parser-based system is more likely to fail by producing a grammatical but semantically useless headline.","{'title': '5 Evaluation', 'number': '10'}"
"Finally, even when both systems produce acceptable output, Hedge Trimmer usually produces headlines which are more fluent or include more useful information. demanding that Chinese authorities respect culture.","{'title': '5 Evaluation', 'number': '10'}"
We have shown the effectiveness of constructing headlines by selecting words in order from a newspaper story.,"{'title': '6 Conclusions and Future Work', 'number': '11'}"
"The practice of selecting words from the early part of the document has been justified by analyzing the behavior of humans doing the task, and by automatic evaluation of a system operating on a similar principle.","{'title': '6 Conclusions and Future Work', 'number': '11'}"
"We have compared two systems that use this basic technique, one taking a statistical approach and the other a linguistic approach.","{'title': '6 Conclusions and Future Work', 'number': '11'}"
The results of the linguistically motivated approach show that we can build a working system with minimal linguistic knowledge and circumvent the need for large amounts of training data.,"{'title': '6 Conclusions and Future Work', 'number': '11'}"
"We should be able to quickly produce a comparable system for other languages, especially in light of current multi-lingual initiatives that include automatic parser induction for new languages, e.g. the TIDES initiative.","{'title': '6 Conclusions and Future Work', 'number': '11'}"
"We plan to enhance Hedge Trimmer by using a language model of Headlinese, the language of newspaper headlines (Mårdh 1980) to guide the system in which constituents to remove.","{'title': '6 Conclusions and Future Work', 'number': '11'}"
We Also we plan to allow for morphological variation in verbs to produce the present tense headlines typical of Headlinese.,"{'title': '6 Conclusions and Future Work', 'number': '11'}"
Hedge Trimmer will be installed in a translingual detection system for enhanced display of document surrogates for cross-language question answering.,"{'title': '6 Conclusions and Future Work', 'number': '11'}"
This system will be evaluated in upcoming iCLEF conferences.,"{'title': '6 Conclusions and Future Work', 'number': '11'}"
"The University of Maryland authors are supported, in part, by BBNT Contract 020124-7157, DARPA/ITO Contract N66001-97-C-8540, and NSF CISE Research Infrastructure Award EIA0130422.","{'title': '7 Acknowledgements', 'number': '12'}"
We would like to thank Naomi Chang and Jon Teske for generating reference headlines.,"{'title': '7 Acknowledgements', 'number': '12'}"
