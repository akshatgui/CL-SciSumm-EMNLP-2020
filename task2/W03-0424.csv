col1,col2
Entity Recognition systems need to integrate a wide variety of information for optimal performance.,Introduction
This paper demonstrates that a maximum entropy tagger can effectively encode such information and identify named entities with very high accuracy.,Introduction
"The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.",Introduction
Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.,Experiment/Discussion
Thus methods used for part of speech (POS) tagging and chunking can also be used for NER.,Experiment/Discussion
The papers from the CoNLL-2002 shared task which used such methods (e.g.,Experiment/Discussion
"Malouf (2002), Burger et al. (2002)) reported results significantly lower than the best system (Carreras et al., 2002).",Experiment/Discussion
"However, Zhou and Su (2002) have reported state of the art results on the MUC-6 and MUC-7 data using a HMM-based tagger.",Experiment/Discussion
"Zhou and Su (2002) used a wide variety of features, which suggests that the relatively poor performance of the taggers used in CoNLL-2002 was largely due to the feature sets used rather than the machine learning method.",Experiment/Discussion
We demonstrate this to be the case by improving on the best Dutch results from CoNLL-2002 using a maximum entropy (ME) tagger.,Experiment/Discussion
"We report reasonable precision and recall (84.9 F-score) for the CoNLL-2003 English test data, and an F-score of 68.4 for the CoNLL-2003 German test data.",Experiment/Discussion
Incorporating a diverse set of overlapping features in a HMM-based tagger is difficult and complicates the smoothing typically used for such taggers.,Experiment/Discussion
"In contrast, a ME tagger can easily deal with diverse, overlapping features.",Experiment/Discussion
We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.,Experiment/Discussion
The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .,Experiment/Discussion
"The tagger uses models of the form: where y is the tag, x is the context and the fi(x, y) are the features with associated weights λi.",Experiment/Discussion
The probability of a tag sequence y1 ... yn given a sentence w1 ... wn is approximated as follows: where xi is the context for word wi.,Experiment/Discussion
The tagger uses beam search to find the most probable sequence given the sentence.,Experiment/Discussion
The features are binary valued functions which pair a tag with various elements of the context; for example: � Generalised Iterative Scaling (GIS) is used to estimate the values of the weights.,Experiment/Discussion
"The tagger uses a Gaussian prior over the weights (Chen et al., 1999) which allows a large number of rare, but informative, features to be used without overfitting.",Experiment/Discussion
"We used three data sets: the English and German data for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003) and the Dutch data for the CoNLL2002 shared task (Tjong Kim Sang, 2002).",Experiment/Discussion
"Each word in the data sets is annotated with a named entity tag plus POS tag, and the words in the German and English data also have a chunk tag.",Experiment/Discussion
Our system does not currently exploit the chunk tags.,Experiment/Discussion
"There are 4 types of entities to be recognised: persons, locations, organisations, and miscellaneous entities not belonging to the other three classes.",Experiment/Discussion
The 2002 data uses the IOB-2 format in which a B-XXX tag indicates the first word of an entity of type XXX and I-XXX is used for subsequent words in an entity of type XXX.,Experiment/Discussion
The tag O indicates words outside of a named entity.,Experiment/Discussion
"The 2003 data uses a variant of IOB-2, IOB-1, in which I-XXX is used for all words in an entity, including the first word, unless the first word separates contiguous entities of the same type, in which case B-XXX is used.",Experiment/Discussion
"Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger.",Experiment/Discussion
"The first set of features apply to rare words, i.e. those which appear less than 5 times in the training data.",Experiment/Discussion
"The first two kinds of features encode prefixes and suffixes less than length 5, and the remaining rare word features encode other morphological characteristics.",Experiment/Discussion
These features are important for tagging unknown and rare words.,Experiment/Discussion
"The remaining features are the word, POS tag, and NE tag history features, using a window size of 2.",Experiment/Discussion
Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.,Experiment/Discussion
Table 2 lists the extra features used in our final system.,Experiment/Discussion
These features have been shown to be useful in other NER systems.,Experiment/Discussion
"The additional orthographic features have proved useful in other systems, for example Carreras et al. (2002), Borthwick (1999) and Zhou and Su (2002).",Experiment/Discussion
Some of the rows in Table 2 describe sets of contextual predicates.,Experiment/Discussion
The wi is only digits predicates apply to words consisting of all digits.,Experiment/Discussion
They encode the length of the digit string with separate predicates for lengths 1–4 and a single predicate for lengths greater than 4.,Experiment/Discussion
Titlecase applies to words with an initial uppercase letter followed by all lowercase (e.g.,Experiment/Discussion
Mr).,Experiment/Discussion
Mixedcase applies to words with mixed lower- and uppercase (e.g.,Experiment/Discussion
CityBank).,Experiment/Discussion
"The length predicates encode the number of characters in the word from 1 to 15, with a single predicate for lengths greater than 15.",Experiment/Discussion
The next set of contextual predicates encode extra information about NE tags in the current context.,Experiment/Discussion
The memory NE tag predicate (see e.g.,Experiment/Discussion
Malouf (2002)) records the NE tag that was most recently assigned to the current word.,Experiment/Discussion
The use of beam-search tagging means that tags can only be recorded from previous sentences.,Experiment/Discussion
This memory is cleared at the beginning of each document.,Experiment/Discussion
The unigram predicates (see e.g.,Experiment/Discussion
Tsukamoto et al. (2002)) encode the most probable tag for the next words in the window.,Experiment/Discussion
The unigram probabilities are relative frequencies obtained from the training data.,Experiment/Discussion
This feature enables us to know something about the likely NE tag of the next word before reaching it.,Experiment/Discussion
"Most systems use gazetteers to encode information about personal and organisation names, locations and trigger words.",Experiment/Discussion
There is considerable variation in the size of the gazetteers used.,Experiment/Discussion
Some studies found that gazetteers did not improve performance (e.g.,Experiment/Discussion
Malouf (2002)) whilst others gained significant improvement using gazetteers and triggers (e.g.,Experiment/Discussion
Carreras et al. (2002)).,Experiment/Discussion
Our system incorporates only English and Dutch first name and last name gazetteers as shown in Table 6.,Experiment/Discussion
"These gazetteers are used for predicates applied to the current, previous and next word in the window.",Experiment/Discussion
Collins (2002) includes a number of interesting contextual predicates for NER.,Experiment/Discussion
One feature we have adapted encodes whether the current word is more frequently seen lowercase than uppercase in a large external corpus.,Experiment/Discussion
This feature is useful for disambiguating beginning of sentence capitalisation and tagging sentences which are all capitalised.,Experiment/Discussion
The frequency counts have been obtained from 1 billion words of English newspaper text collected by Curran and Osborne (2002).,Experiment/Discussion
Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes.,Experiment/Discussion
This involves mapping characters to classes and merging adjacent characters of the same type.,Experiment/Discussion
"For example, Moody becomes Aa, A.B.C. becomes A.A.A. and 1,345.05 becomes 0,0.0.",Experiment/Discussion
"The classes are used to define unigram, bigram and trigram contextual predicates over the window.",Experiment/Discussion
"We have also defined additional composite features which are a combination of atomic features; for example, a feature which is active for mid-sentence titlecase words seen more frequently as lowercase than uppercase in a large external corpus.",Experiment/Discussion
The baseline development results for English using the supertagger features only are given in Table 3.,Experiment/Discussion
The full system results for the English development data are given in Table 7.,Experiment/Discussion
Clearly the additional features have a significant impact on both precision and recall scores across all entities.,Experiment/Discussion
"We have found that the word type features are particularly useful, as is the memory feature.",Experiment/Discussion
The performance of the final system drops by 1.97% if these features are removed.,Experiment/Discussion
The performance of the system if the gazetteer features are removed is given in Table 4.,Experiment/Discussion
The sizes of our gazetteers are given in Table 6.,Experiment/Discussion
"We have experimented with removing the other contextual predicates but each time performance was reduced, except for the next-next unigram tag feature which was switched off for all final experiments.",Experiment/Discussion
The results for the Dutch test data are given in Table 5.,Experiment/Discussion
"These improve upon the scores of the best performing system at CoNLL-2002 (Carreras et al., 2002).",Experiment/Discussion
The final results for the English test data are given in Table 7.,Experiment/Discussion
These are significantly lower than the results for the development data.,Experiment/Discussion
The results for the German development and test sets are given in Table 7.,Experiment/Discussion
For the German NER we removed the lowercase more frequent than uppercase feature.,Experiment/Discussion
"Apart from this change, the system was identical.",Experiment/Discussion
We did not add any extra gazetteer information for German.,Experiment/Discussion
Our NER system demonstrates that using a large variety of features produces good performance.,Results/Conclusion
"These features can be defined and extracted in a language independent manner, as our results for German, Dutch and English show.",Results/Conclusion
Maximum entropy models are an effective way of incorporating diverse and overlapping features.,Results/Conclusion
"Our maximum entropy tagger employs Gaussian smoothing which allows a large number of sparse, but informative, features to be used without overfitting.",Results/Conclusion
"Using a wider context window than 2 words may improve performance; a reranking phase using global features may also improve performance (Collins, 2002).",Results/Conclusion
We would like to thank Jochen Leidner for help collecting the Gazetteers.,Results/Conclusion
"This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.",Results/Conclusion
