col1,col2
Chinese part-of-speech (POS) tagging assigns one POS tag to each word in a Chinese sentence.,{}
"However, since words are not demarcated in a Chinese sentence, Chinese POS tagging requires word segmentation as a prerequisite.",{}
"We could perform Chinese POS tagging strictly after word segmentation approach), or perform both word segmentation and POS tagging in a combined, single step simultaneously (all-atonce approach).",{}
"Also, we could choose to assign POS tags on a word-by-word basis, making use of word features in the surrounding context (word-based), or on a character-by-character basis with character features (character-based).",{}
"This paper presents an in-depth study on such issues of processing architecture and feature representation for Chinese POS tagging, within a maximum entropy framework.",{}
"We found that while the all-at-once, characterbased approach is the best, the one-at-a-time, character-based approach is a worthwhile compromise, performing only slightly worse in terms of accuracy, but taking shorter time to train and run.",{}
"As part of our investigation, we also built a state-of-the-art Chinese word segmenter, which outperforms the best SIGHAN 2003 word segmenters in the closed track on 3 out of 4 test corpora.",{}
Most corpus-based language processing research has focused on the English language.,"{'title': '1 Introduction', 'number': '1'}"
"Theoretically, we should be able to just port corpus-based, machine learning techniques across different languages since the techniques are largely language independent.","{'title': '1 Introduction', 'number': '1'}"
"However, in practice, the special characteristics of different languages introduce complications.","{'title': '1 Introduction', 'number': '1'}"
"For Chinese in particular, words are not demarcated in a Chinese sentence.","{'title': '1 Introduction', 'number': '1'}"
"As such, we need to perform word segmentation before we can proceed with other tasks such as part-of-speech (POS) tagging and parsing, since one POS tag is assigned to each Chinese word (i.e., all characters in a Chinese word have the same POS tag), and the leaves of a parse tree for a Chinese sentence are words.","{'title': '1 Introduction', 'number': '1'}"
"To build a Chinese POS tagger, the following questions naturally arise: This paper presents an in-depth study on such issues of processing architecture and feature representation for Chinese POS tagging, within a maximum entropy framework.","{'title': '1 Introduction', 'number': '1'}"
We analyze the performance of the different approaches in our attempt to find the best approach.,"{'title': '1 Introduction', 'number': '1'}"
"To our knowledge, our work is the first to systematically investigate such issues in Chinese POS tagging.","{'title': '1 Introduction', 'number': '1'}"
"As a first step in our investigation, we built a Chinese word segmenter capable of performing word segmentation without using POS tag information.","{'title': '2 Word Segmentation', 'number': '2'}"
"Since errors in word segmentation will propagate to the subsequent POS tagging phase in the one-at-a-time approach, in order for our study to give relevant findings, it is important that the word segmenter we use gives state-ofthe-art accuracy.","{'title': '2 Word Segmentation', 'number': '2'}"
"The word segmenter we built is similar to the maximum entropy word segmenter of (Xue and Shen, 2003).","{'title': '2 Word Segmentation', 'number': '2'}"
Our word segmenter uses a maximum entropy framework and is trained on manually segmented sentences.,"{'title': '2 Word Segmentation', 'number': '2'}"
It classifies each Chinese character given the features derived from its surrounding context.,"{'title': '2 Word Segmentation', 'number': '2'}"
"Each character can be assigned one of 4 possible boundary tags: “b” for a character that begins a word and is followed by another character, “m” for a character that occurs in the middle of a word, “e” for a character that ends a word, and “s” for a character that occurs as a single-character word.","{'title': '2 Word Segmentation', 'number': '2'}"
"Besides implementing a subset of the features described in (Xue and Shen, 2003), we also came up with three additional types of features ((d) − (f) below) which improved the accuracy of word segmentation.","{'title': '2 Word Segmentation', 'number': '2'}"
"The default feature, boundary tag feature of the previous character, and boundary tag feature of the character two before the current character used in (Xue and Shen, 2003) were dropped from our word segmenter, as they did not improve word segmentation accuracy in our experiments.","{'title': '2 Word Segmentation', 'number': '2'}"
"In the following feature templates used in our word segmenter, C refers to a Chinese character while W refers to a Chinese word.","{'title': '2 Word Segmentation', 'number': '2'}"
Templates (a) − (c) refer to a context of five characters (the current character and two characters to its left and right).,"{'title': '2 Word Segmentation', 'number': '2'}"
"C0 denotes the current character, Cn For example, given the character sequence “新华社 记者”, when considering the character “社”, template (a) results in the following features C_2 =新 C_1 =华 C0 =社 C1 =记 C2 =者 to be set to 1, template (b) results in the features W0 C0 :This feature captures the word context in which the current character is found.","{'title': '2 Word Segmentation', 'number': '2'}"
"For example, the character “社” within the word “新华社” will have the feature W0 C0=新华社_社 set to 1.","{'title': '2 Word Segmentation', 'number': '2'}"
This feature helps in recognizing seen words.,"{'title': '2 Word Segmentation', 'number': '2'}"
Pu( C0 ) :A punctuation symbol is usually a good indication of a word boundary.,"{'title': '2 Word Segmentation', 'number': '2'}"
"This feature checks whether the current character is a punctuation symbol (such as “。”, “-”, “,”).","{'title': '2 Word Segmentation', 'number': '2'}"
"T(C )T(C )T(C )T( C )T(C ) :This feature is especially helpful in predicting the word segmentation of dates and numbers, whose exact characters may not have been seen in the training text.","{'title': '2 Word Segmentation', 'number': '2'}"
"Four type classes are defined: numbers represent class 1, dates (“日”, “月”, “年”, the Chinese character for “day”, “month”, “year”, respectively) represent class 2, English letters represent class 3, and other characters represent class 4.","{'title': '2 Word Segmentation', 'number': '2'}"
"For example, when considering the character “年” in the character sequence “九〇年代W”, the feature T (C_2) ... T (C2) =11243 will be set to 1 ( “九” and “〇” are the Chinese characters for “9” and “0” respectively).","{'title': '2 Word Segmentation', 'number': '2'}"
"During testing, the probability of a boundary tag sequence assignment t1... tn given a character sequence c1 ...cn is determined by using the maximum entropy classifier to compute the probability that a boundary tag ti is assigned to each individual character ci.","{'title': '2 Word Segmentation', 'number': '2'}"
"If we were to just assign each character the boundary tag with the highest probability, it is possible that the classifier produces a sequence of invalid tags (e.g., “m” followed by “s”).","{'title': '2 Word Segmentation', 'number': '2'}"
"To eliminate such possibilities, we implemented a dynamic programming algorithm which considers only valid boundary tag sequences given an input character sequence.","{'title': '2 Word Segmentation', 'number': '2'}"
"At each character position i, the algorithm considers each last word candidate ending at position i and consisting of K characters in length (K = 1, ..., 20 in our experiments).","{'title': '2 Word Segmentation', 'number': '2'}"
"To determine the boundary tag assignment to the last word W with K characters, the first character of W is assigned boundary tag “b”, the last character of W is assigned tag “e”, and the intervening characters are assigned tag “m”.","{'title': '2 Word Segmentation', 'number': '2'}"
"(If W is a single-character word, then the single character is assigned “s”.)","{'title': '2 Word Segmentation', 'number': '2'}"
"In this way, the dynamic programming algorithm only considers valid tag sequences, and we are also able to make use of the W0 C0 feature during testing.","{'title': '2 Word Segmentation', 'number': '2'}"
"After word segmentation is done by the maximum entropy classifier, a post-processing step is applied to correct inconsistently segmented words made up of 3 or more characters.","{'title': '2 Word Segmentation', 'number': '2'}"
"A word W is defined to be inconsistently segmented if the concatenation of 2 to 6 consecutive words elsewhere in the segmented output document matches W. In the post-processing step, the segmentation of the characters of these consecutive words is changed so that they are segmented as a single word.","{'title': '2 Word Segmentation', 'number': '2'}"
"To illustrate, if the concatenation of 2 consecutive words “巴赛 罗纳” in the segmented output document matches another word “巴赛罗纳”, then “巴赛 罗纳” will be re-segmented as “巴赛罗纳 ”.","{'title': '2 Word Segmentation', 'number': '2'}"
"To evaluate the accuracy of our word segmenter, we carried out 10-fold cross validation (CV) on the 250K-word Penn Chinese Treebank (CTB) (Xia et al., 2000) version 3.0.","{'title': '2 Word Segmentation', 'number': '2'}"
"The Java opennlp maximum entropy package from sourceforge1 was used in our implementation, and training was done with a feature cutoff of 2 and 100 iterations.","{'title': '2 Word Segmentation', 'number': '2'}"
"The accuracy of word segmentation is measured by recall (R), precision (P), and Fmeasure (2RP /(R + P) ).","{'title': '2 Word Segmentation', 'number': '2'}"
"Recall is the proportion of correctly segmented words in the gold-standard segmentation, and precision is the proportion of correctly segmented words in word segmenter’s output.","{'title': '2 Word Segmentation', 'number': '2'}"
Figure 1 gives the word segmentation Fmeasure of our word segmenter based on 10-fold CV on the 250K-word CTB.,"{'title': '2 Word Segmentation', 'number': '2'}"
Our word segmenter achieves an average F-measure of 95.1%.,"{'title': '2 Word Segmentation', 'number': '2'}"
"This accuracy compares favorably with (Luo, 2003), which reported 94.6% word segmentation F-measure using his full parser without additional lexical features, and about 94.9%2 word segmentation F-measure using only word boundaries information, no POS tags or constituent labels, but with lexical features derived from a 58K-entry word list.","{'title': '2 Word Segmentation', 'number': '2'}"
"The average training time taken to train on 90% of the 250K-word CTB was 12 minutes, while testing on 10% of CTB took about 1 minute.","{'title': '2 Word Segmentation', 'number': '2'}"
The running times reported in this paper were all obtained on an Intel Xeon 2.4GHz computer with 2GB RAM.,"{'title': '2 Word Segmentation', 'number': '2'}"
"Figure 1: CTB 10-fold CV word segmentation Fmeasure for our word segmenter As further evaluation, we tested our word segmenter on all the 4 test corpora (CTB, Academia Sinica (AS), Hong Kong CityU (HK) , and Peking University (PK)) of the closed track of the 2003 ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff (Sproat and Emerson, 2003).","{'title': '2 Word Segmentation', 'number': '2'}"
"For each of the 4 corpora, we trained our word segmenter on only the official released training data of that corpus.","{'title': '2 Word Segmentation', 'number': '2'}"
"Training was conducted with feature cutoff of 2 and 100 iterations (these parameters were obtained by cross validation on the training set), except for the AS corpus where we used cutoff 3 since the AS training corpus was too big to train with cutoff 2.","{'title': '2 Word Segmentation', 'number': '2'}"
"Figure 2 shows our word segmenter’s Fmeasure (based on the official word segmentation scorer of 2003 SIGHAN bakeoff) compared to those reported by all the 2003 SIGHAN participants in the four closed tracks (ASc, HKc, PKc, CTBc).","{'title': '2 Word Segmentation', 'number': '2'}"
"Our word segmenter achieved higher F-measure than the best reported F-measure in the SIGHAN bakeoff on the ASc, HKc, and PKc corpus.","{'title': '2 Word Segmentation', 'number': '2'}"
"For CTBc, due to the exceptionally high out-of-vocabulary (OOV) rate of the test data (18.1%), our word segmenter’s Fmeasure ranked in the third position.","{'title': '2 Word Segmentation', 'number': '2'}"
"(Note that the top participant of CTBc (Zhang et al., 2003) used additional named entity knowledge/data in their word segmenter).","{'title': '2 Word Segmentation', 'number': '2'}"
"We also compared the F-measure of our word segmenter on CTBO, the open category of the CTB corpus, where participants were free to use any available resources and were not restricted to only the official released training data of CTB.","{'title': '2 Word Segmentation', 'number': '2'}"
"On this CTBO task, we used as additional training data the AS training corpus provided by SIGHAN, after converting the AS training corpus to GB encoding.","{'title': '2 Word Segmentation', 'number': '2'}"
"We found that with this additional AS training data added to the original 3 Last ranked participant of SIGHAN CTB (closed) with F-measure 73.2% is not shown in Figure 2 due to space constraint. official released CTB training data of SIGHAN, our word segmenter achieved an F-measure of 92.2%, higher than the best reported F-measure in the CTB open task.","{'title': '2 Word Segmentation', 'number': '2'}"
"With sufficient training data, our word segmenter can perform very well.","{'title': '2 Word Segmentation', 'number': '2'}"
"In our evaluation, we also found that the additional features we introduced in Section 2.2 and the post-processing step consistently improved average word segmentation F-measure, when evaluated on the 4 SIGHAN test corpora in the closed track.","{'title': '2 Word Segmentation', 'number': '2'}"
"The additional features improved F-measure by an average of about 0.4%, and the post-processing step added on top of the use of all features further improved Fmeasure by 0.3% (i.e., for a cumulative total of 0.7% increase in F-measure).","{'title': '2 Word Segmentation', 'number': '2'}"
"Now that we have successfully built a state-ofthe-art Chinese word segmenter, we are ready to explore issues of processing architecture and feature representation for Chinese POS tagging.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"An English POS tagger based on maximum entropy modeling was built by (Ratnaparkhi, 1996).","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"As a first attempt, we investigated whether simply porting the method used by (Ratnaparkhi, 1996) for English POS tagging would work equally well for Chinese.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"Applying it in the context of Chinese POS tagging, Ratnaparkhi’s method assumes that words are pre-segmented, and it assigns POS tags on a word-by-word basis, making use of word features in the surrounding context.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"This gives rise to a one-at-a-time, word-based POS tagger.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"Note that in a one-at-a-time approach, the word-segmented input sentence given to the POS tagger may contain word segmentation errors, which can lower the POS tagging accuracy.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
The following feature templates were chosen.,"{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
W refers to a word while POS refers to the POS tag assigned.,"{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
The feature Pu(W0) checks if all characters in the current word are punctuation characters.,"{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
Feature (e) encodes the class of characters that constitute the surrounding words (similar to feature (f) of the word segmenter in Section 2.1).,"{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"Four type classes are defined: a word is of class 1 if it is a number; class 2 if the word is made up of only numeric characters followed by “H”, “月”,or “年”; class 3 when the word is made up of only English characters The testing procedure is similar to the beam search algorithm of (Ratnaparkhi, 1996), which tags each word one by one and maintains, as it sees a new word, the N most probable POS tag sequence candidates up to that point in the sentence.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"For our experiment, we have chosen N to be 3.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"The 250K-word CTB corpus, tagged with 32 different POS tags (such as “NR”, “PU”, etc) was employed in our evaluation of POS taggers in this study.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"We ran 10-fold CV on the CTB corpus, using our word segmenter’s output for each of the 10 runs as the input sentences to the POS tagger.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
POS tagging accuracy is simply calculated as (number of characters assigned correct POS tag) / (total number of characters).,"{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"Figure 3: POS tagging accuracy using one-at-atime, word-based POS tagger The POS tagging accuracy is plotted in Figure 3.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"The average POS tagging accuracy achieved for the 10 experiments was only 84.1%, far lower than the 96% achievable by English POS taggers on the English Penn Treebank tag set.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"The average training time was 25 minutes, while testing took about 20 seconds.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"As an experiment, we also conducted POS tagging using only the features (a), (f), and (g) in Section 3.1, similar to (Ratnaparkhi, 1996), and we obtained an average POS tagging accuracy of 83.1% for that set of features.","{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
The features that worked well for English POS tagging did not seem to apply to Chinese in the maximum entropy framework.,"{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
Language differences between Chinese and English have no doubt made the direct porting of an English POS tagging method to Chinese ineffective.,"{'title': '3 One-at-a-Time, Word-Based POS Tagger', 'number': '3'}"
"Since one-at-a-time, word-based POS tagging did not yield good accuracy, we proceeded to investigate other combinations of processing architecture and feature representation.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"We observed that character features were successfully used to build our word segmenter and that of (Xue and Shen, 2003).","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"Similarly, character features were used to build a maximum entropy Chinese parser by (Luo, 2003), where his parser could perform word segmentation, POS tagging, and parsing in an integrated, unified approach.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"We hypothesized that assigning POS tags on a character-by-character basis, making use of character features in the surrounding context may yield good accuracy.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"So we next investigate such a one-at-a-time, character-based POS tagger.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"The features that were used for our word segmenter ((a) − (f)) in Section 2.1 were yet again applied, with two additional features (g) and (h) to aid POS tag prediction.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
: This feature refers to the POS tag of the previous character before the current word.,"{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"For example, in the character sequence “74 AL MA”, when considering the character “A”, the feature POS(C−1W0 ) =PN is set to 1 (assuming “k” was tagged as PN).","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"C−2W0 )POS(C−1W0 ) : For the same example given above, when considering the character “A”, the feature POS(C−2W0 )POS(C−1W0 ) =P_PN is set to 1 (assuming “对” was tagged as P and “k” was tagged as PN).","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"The testing algorithm is similar to that described in Section 3.2, except that the probability of a word being assigned a POS tag t is estimated by the product of the probability of its individual characters being assigned the same POS tag t. For example, when estimating the probability of “WTWU” being tagged NR, we find the product of the probability of “WT” being tagged NR, “W” being tagged NR, and “U” being tagged NR.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"That is, we enforce the constraint that all characters within a segmented word in the presegmented input sentence must have the same POS tag.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
10-fold CV for CTB is repeated for this POS tagger.,"{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
Figure 4 shows the detailed POS tagging accuracy.,"{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"With a one-at-a-time, character-based POS tagger, the average POS tagging accuracy improved to 91.7%, 7.6% higher than that achieved by the one-at-a-time, word-based POS tagger.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"The average training timing was 55 minutes, while testing took about 50 seconds.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"Figure 4: POS tagging accuracy using one-at-atime, character-based POS tagger When a paired t-test was carried out to compare character-based and word-based one-ata-time approaches, the character-based approach was found to be significantly better than the word-based approach, at the level of significance 0.01.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"Assuming a one-at-a-time processing architecture, Chinese POS tagging using a character-based approach gives higher accuracy compared to a word-based approach.","{'title': '4 One-at-a-Time, Character-Based POS Tagger', 'number': '4'}"
"Encouraged by the success of character features, we next explored whether a change in processing architecture, from one-at-a-time to all-at-once, while still retaining the use of character features, could give further improvement to POS tagging accuracy.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"In this approach, both word segmentation and POS tagging will be performed in a combined, single step simultaneously.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"Each character is assigned both a boundary tag and a POS tag, for example “b_NN” (i.e., the first character in a word with POS tag NN).","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"Thus, given 4 possible boundary tags and 32 unique POS tags present in the training corpus, each character can potentially be assigned one of (4×32) classes.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"The features we used are identical to those employed in the character-based POS tagger described in section 4.1, except that features (g) and (h) are replaced with those listed below.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"In the following templates, B refers to the boundary tag assigned.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"For example, given the character sequence “V AL MA”, when considering the character “A”, template (g) results in the feature B(C−1W 0 )POS(C−1W 0 )=s_PN to be set to 1.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
(assuming “k” was tagged as PN).,"{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"Note that this approach is essentially that used by (Luo, 2003), since his parser performs both word segmentation and POS tagging (as well as parsing) in one unified approach.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"The features we used are similar to his tag features, except that we did not use features with three consecutive characters, since we found that the use of these features did not improve accuracy.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
We also added additional features (d) − (f).,"{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
Beam search algorithm is used with N = 3 during the testing phase.,"{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"10-fold CV on CTB was carried out again, using unsegmented test sentences as input to the program.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"Figure 5 shows the word segmentation Fmeasure, while Figure 6 shows the POS tagging accuracy achieved by this approach.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"With an allat-once, character-based approach, an average word segmentation F-measure of 95.2% and an average POS tagging accuracy of 91.9% was achieved.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"The average training timing was 3 hours, while testing took about 20 minutes.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"There is a slight improvement in word segmentation and POS tagging accuracy using this approach, compared to the one-at-a-time, character-based approach.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"When a paired t-test was carried out at the level of significance 0.01, the all-at-once approach was found to be significantly better than the one-at-a-time approach for POS tagging accuracy, although the difference was insignificant for word segmentation.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"However, the time required for training and testing is increased significantly for the all-atonce approach.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"When efficiency is a major consideration, or if high quality hand-segmented text is available, the one-at-a-time, characterbased approach could indeed be a worthwhile compromise, performing only slightly worse than the all-at-once approach.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
Table 1 summarizes the methods investigated in this paper.,"{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
Total testing time includes both word segmentation and POS tagging on 10% of CTB data.,"{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
"Note that an all-atonce, word-based approach is not applicable as word segmentation requires character features to determine the word boundaries.","{'title': '5 All-at-Once, Character-Based POS Tagger and Segmenter', 'number': '5'}"
Word-based or character-based?,"{'title': '6 Discussions', 'number': '6'}"
The findings that a character-based approach is better than a word-based approach for Chinese POS tagging is not too surprising.,"{'title': '6 Discussions', 'number': '6'}"
"Unlike in English where each English letter by itself does not possess any meaning, many Chinese characters have well defined meanings.","{'title': '6 Discussions', 'number': '6'}"
"For example, the single Chinese character “0” means “know”.","{'title': '6 Discussions', 'number': '6'}"
"And when a character appears as part of a word, the word derives part of its meaning from the component characters.","{'title': '6 Discussions', 'number': '6'}"
"For example, “0V,” means “knowledge”, “3'u0” means “ignorant”, “0-8” means “well-known”, etc.","{'title': '6 Discussions', 'number': '6'}"
"In addition, since the out-of-vocabulary (OOV) rate for Chinese words is much higher than the OOV rate for Chinese characters, in the presence of an unknown word, using the component characters in the word to help predict the correct POS tag is a good heuristic.","{'title': '6 Discussions', 'number': '6'}"
One-at-a-time or all-at-once?,"{'title': '6 Discussions', 'number': '6'}"
"The all-at-once approach, which considers all aspects of available information in an integrated, unified compared with the all-at-once, character-based approach previously proposed. framework, can make better informed decisions, but incurs a higher computational cost.","{'title': '6 Discussions', 'number': '6'}"
"Much previous research on Chinese language processing focused on word segmentation (Sproat et al., 1996; Teahan et al., 2000; Sproat and Emerson, 2003).","{'title': '7 Related Work', 'number': '7'}"
Relatively less work has been done on Chinese POS tagging.,"{'title': '7 Related Work', 'number': '7'}"
Kwong and Tsou (2003) discussed the implications of POS ambiguity in Chinese and the possible approaches to tackle this problem when tagging a corpus for NLP tasks.,"{'title': '7 Related Work', 'number': '7'}"
"Zhou and Su (2003) investigated an approach to build a Chinese analyzer that integrated word segmentation, POS tagging and parsing, based on a hidden Markov model.","{'title': '7 Related Work', 'number': '7'}"
"Jing et al. (2003) focused on Chinese named entity recognition, considering issues like character-based versus word-based approaches.","{'title': '7 Related Work', 'number': '7'}"
"To our knowledge, our work is the first to systematically investigate issues of processing architecture and feature representation for Chinese POS tagging.","{'title': '7 Related Work', 'number': '7'}"
"Our maximum entropy word segmenter is similar to that of (Xue and Shen, 2003), but the additional features we used and the postprocessing step gave improved word segmentation accuracy.","{'title': '7 Related Work', 'number': '7'}"
"The research most similar to ours is (Luo, 2003).","{'title': '7 Related Work', 'number': '7'}"
"Luo presented a maximum entropy character-based parser, which as a consequence of parsing also performed word segmentation and POS tagging.","{'title': '7 Related Work', 'number': '7'}"
"The all-at-once, characterbased approach reported in this paper is essentially the approach proposed by Luo.","{'title': '7 Related Work', 'number': '7'}"
"While our investigation reveals that such an approach gives good accuracy, our findings however indicate that a one-at-a-time, character-based approach to POS tagging gave quite comparable accuracy, with the benefit of incurring much reduced computational cost.","{'title': '7 Related Work', 'number': '7'}"
Language differences between English and Chinese have made direct porting of an English POS tagging method to Chinese ineffective.,"{'title': '8 Conclusion', 'number': '8'}"
"In Chinese, individual characters encode information that aids in POS tagging.","{'title': '8 Conclusion', 'number': '8'}"
Using a character-based approach for Chinese POS tagging is more effective than a word-based approach.,"{'title': '8 Conclusion', 'number': '8'}"
"Our study has also revealed that the one-at-a-time, character-based approach gives relatively good POS tagging accuracy with a much improved training and testing time,","{'title': '8 Conclusion', 'number': '8'}"
This research is partially supported by a research grant R252-000-125-112 from National University of Singapore Academic Research Fund.,"{'title': '9 Acknowledgements', 'number': '9'}"
