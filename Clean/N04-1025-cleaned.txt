Si and Callan (2001) and Collins-Thompson and Callan (2004) have demonstrated the use of language models is more robust for web documents and passages. $$$$$ To our knowledge, the only previous work which has considered a language modeling approach to readability is a preliminary study by Si and Callan (2001).
Si and Callan (2001) and Collins-Thompson and Callan (2004) have demonstrated the use of language models is more robust for web documents and passages. $$$$$ We also showed that the Smoothed Unigram method is robust for short passages and Web documents.

 $$$$$ This is a well-known issue in language model applications, and it is standard to compensate for this sparseness by smoothing the frequencies in the trained models.
 $$$$$ We thank the anonymous reviewers for their comments and Luo Si for helpful discussions.

In order to adjust search result presentation to the user's reading ability, we estimate the reading difficulty of each retrieved document using the Smoothed Unigram Model, a variation of a Multinomial Bayes classifier (Collins-Thompson and Callan, 2004). $$$$$ Our statistical model is based on a variation of the multinomial naïve Bayes classifier, which we call the ‘Smoothed Unigram’ model.
In order to adjust search result presentation to the user's reading ability, we estimate the reading difficulty of each retrieved document using the Smoothed Unigram Model, a variation of a Multinomial Bayes classifier (Collins-Thompson and Callan, 2004). $$$$$ We have shown that reading difficulty can be estimated with a simple language modeling approach using a modified naïve Bayes classifier.

The latter has been found to be more effective as the former when approaching the reading level of subjects in primary and secondary school age (Collins-Thompson and Callan, 2004). $$$$$ While word difficulty is well-known to be an excellent predictor of reading difficulty (Chall & Edgar, 1995), it was not at all clear how effective our language model approach would be for predicting Web page reading difficulty.
The latter has been found to be more effective as the former when approaching the reading level of subjects in primary and secondary school age (Collins-Thompson and Callan, 2004). $$$$$ Our evaluation suggests that reasonably effective models can be trained with small amounts of easilyacquired data.

Collins-Thompson and Callan (2004) adopted a similar approach and used a smoothed unigram model to predict the grade levels of short passages and web documents. $$$$$ As we show in our evaluation, this generally results in better accuracy for Web documents and very short passages (less than 10 words).
Collins-Thompson and Callan (2004) adopted a similar approach and used a smoothed unigram model to predict the grade levels of short passages and web documents. $$$$$ We also showed that the Smoothed Unigram method is robust for short passages and Web documents.

First, a language modeling approach generally gives much better accuracy for Web documents and short passages (Collins-Thompson and Callan, 2004). $$$$$ Some traditional semantic variables such as type-token ratio gave the best performance on commercial calibrated test passages, while our language modeling approach gave better accuracy for Web documents and very short passages (less than 10 words).
First, a language modeling approach generally gives much better accuracy for Web documents and short passages (Collins-Thompson and Callan, 2004). $$$$$ As we show in our evaluation, this generally results in better accuracy for Web documents and very short passages (less than 10 words).

However, there are other important criteria for the user besides relevance, such as readability (Collins-Thompson and Callan, 2004), novelty (Harman, 2003), and authority (Kleinberg, 1998). $$$$$ To our knowledge, the only previous work which has considered a language modeling approach to readability is a preliminary study by Si and Callan (2001).
However, there are other important criteria for the user besides relevance, such as readability (Collins-Thompson and Callan, 2004), novelty (Harman, 2003), and authority (Kleinberg, 1998). $$$$$ However, Reading A-Z documents were written to pre-established criteria which includes objective factors such as type/ token ratio (Reading A-Z.com, 2003), so it is not surprising that the correlation is high.

 $$$$$ This is a well-known issue in language model applications, and it is standard to compensate for this sparseness by smoothing the frequencies in the trained models.
 $$$$$ We thank the anonymous reviewers for their comments and Luo Si for helpful discussions.

Advanced NLP-based readability metrics developed so far typically deal with English, with a few attempts devoted to other languages, namely French (Collins-Thompson and Callan, 2004), Portuguese (Aluisio et al, 2010) and German (Bruck, 2008). $$$$$ Previous work (Stenner, 1996, also citing Squires et al., 1983 and Crawford et al., 1975) suggests that a comprehension rate of 75% for a text is a desirable target.
Advanced NLP-based readability metrics developed so far typically deal with English, with a few attempts devoted to other languages, namely French (Collins-Thompson and Callan, 2004), Portuguese (Aluisio et al, 2010) and German (Bruck, 2008). $$$$$ As an example of retraining, we showed that the classifier obtained good correlation with difficulty for at least two languages, English and French, with the only algorithm difference being a change in the morphology handling during feature processing.

Collins-Thompson and Callan (2004) used a smoothed unigram language model to predict the grade reading levels of web page documents and short passages. $$$$$ As we show in our evaluation, this generally results in better accuracy for Web documents and very short passages (less than 10 words).
Collins-Thompson and Callan (2004) used a smoothed unigram language model to predict the grade reading levels of web page documents and short passages. $$$$$ We also showed that the Smoothed Unigram method is robust for short passages and Web documents.

As a learning model, we use unigram language modelling introduced in (Collins-Thompson and Callan, 2004) to model the reading level of subjects in primary and secondary school. $$$$$ Our statistical model is based on a variation of the multinomial naïve Bayes classifier, which we call the ‘Smoothed Unigram’ model.
As a learning model, we use unigram language modelling introduced in (Collins-Thompson and Callan, 2004) to model the reading level of subjects in primary and secondary school. $$$$$ We derived the learning curve of our classifier as a function of the mean model training set size in tokens.

In some of the early works on statistical readability assessment, Si and Callan (2001) and Collins-Thompson and Callan (2004) reported the impact of using unigram language models to estimate the grade level of a given text. $$$$$ We derive a measure based on an extension of multinomial naïve Bayes classification that combines multiple language models to estimate the most likely grade level for a given passage.
In some of the early works on statistical readability assessment, Si and Callan (2001) and Collins-Thompson and Callan (2004) reported the impact of using unigram language models to estimate the grade level of a given text. $$$$$ To our knowledge, the only previous work which has considered a language modeling approach to readability is a preliminary study by Si and Callan (2001).

The widely used Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al, 1975) (as cited in (Collins-Thompson and Callan, 2004)). $$$$$ Widely-used traditional readability formulas such as Flesch-Kincaid usually perform poorly in this scenario.
The widely used Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al, 1975) (as cited in (Collins-Thompson and Callan, 2004)). $$$$$ We also included a fourth predictor: the FleschKincaid score (Kincaid et al. 1975), which is a linear combination of the text’s average sentence length (in tokens), and the average number of syllables per token.

classifier to better capture the variance in word usage across grade levels (Collins-Thompson and Callan, 2004). $$$$$ While traditional formulas are based on linear regression with two or three variables, statistical language models can capture more detailed patterns of individual word usage.
classifier to better capture the variance in word usage across grade levels (Collins-Thompson and Callan, 2004). $$$$$ The word ‘the’ is very common and varies less in frequency across grade levels.

Other related work has used models of vocabulary (Collins-Thompson and Callan, 2004). $$$$$ Section 3 summarizes related work on readability, focusing on existing vocabulary-based measures that can be thought of as simplified language model techniques.
Other related work has used models of vocabulary (Collins-Thompson and Callan, 2004). $$$$$ The results from the most closely related previous work (Si and Callan, 2001) are not directly comparable to ours; among other factors, their task used a dataset trained on science curriculum descriptions, not text written at different levels of difficulty.

Early work on automatic readability analysis framed the problem as a classification task: creating multiple classifiers for labeling a text as being one of several elementary school grade levels (Collins-Thompson and Callan, 2004). $$$$$ A comprehensive summary of early readability work may be found in Chall (1958) and Klare (1963).
Early work on automatic readability analysis framed the problem as a classification task: creating multiple classifiers for labeling a text as being one of several elementary school grade levels (Collins-Thompson and Callan, 2004). $$$$$ The results from the most closely related previous work (Si and Callan, 2001) are not directly comparable to ours; among other factors, their task used a dataset trained on science curriculum descriptions, not text written at different levels of difficulty.

It is also the last formula published for French L1, if we except the adaptation of the model by Collins-Thompson and Callan (2004) to French. $$$$$ Finally, we looked at how well the model could be extended to a language other than English – in this study, we give results for French.
It is also the last formula published for French L1, if we except the adaptation of the model by Collins-Thompson and Callan (2004) to French. $$$$$ To test the flexibility of our language model approach, we did a preliminary study for French reading difficulty prediction.
