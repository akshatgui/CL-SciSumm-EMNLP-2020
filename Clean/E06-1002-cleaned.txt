 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

With respect to the use of Wikipedia as a resource for natural language processing tasks, the work that is most closely related to ours is perhaps the name entity disambiguation algorithm proposed in (Bunescu and Pasca, 2006), where an SVM kernel is trained on the entries found in Wikipediafor ambiguous named entities. $$$$$ A disambiguation SVM kernel is trained to exploit the high coverage and rich structure of the knowledge encoded in an online encyclopedia.
With respect to the use of Wikipedia as a resource for natural language processing tasks, the work that is most closely related to ours is perhaps the name entity disambiguation algorithm proposed in (Bunescu and Pasca, 2006), where an SVM kernel is trained on the entries found in Wikipediafor ambiguous named entities. $$$$$ Section 3 describes the extraction of named entity entries (versus other types of entries) fromWikipedia.

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. $$$$$ 1.2 Approach.
The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. $$$$$ 4.1 Context-Article Similarity.

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

Based on the aforementioned resources of information, we follow the method presented in (Bunescu and Pasca, 2006) to build a dictionary called ViDic. $$$$$ Whenever the queries search for pinpointed, factual information, the burden of filling the gap between the output granularity (whole documents) and the targeted information (a set of sentences or relevant phrases) stays with theusers, by browsing the returned documents in or der to find the actually relevant bits of information.
Based on the aforementioned resources of information, we follow the method presented in (Bunescu and Pasca, 2006) to build a dictionary called ViDic. $$$$$ More exactly, the method: 1.

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance. $$$$$ Whenever the queries search for pinpointed, factual information, the burden of filling the gap between the output granularity (whole documents) and the targeted information (a set of sentences or relevant phrases) stays with theusers, by browsing the returned documents in or der to find the actually relevant bits of information.
(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance. $$$$$ It seems therefore natural to try to exploit the webin order to also improve the performance of relation extraction, i.e. the discovery of useful re lationships between named entities mentioned in text documents.

After the task of EL was initiated with Wikipedia-based works on entity disambiguation, in particular by Cucerzan (2007) and Bunescu and Pasca (2006), numerous systems have been developed, encouraged by the TAC 2009 KB population task (McNamee and Dang, 2009). $$$$$ Section 2 describes Wikipedia, with an emphasis on the features that are most important to the entity disambiguation task.
After the task of EL was initiated with Wikipedia-based works on entity disambiguation, in particular by Cucerzan (2007) and Bunescu and Pasca (2006), numerous systems have been developed, encouraged by the TAC 2009 KB population task (McNamee and Dang, 2009). $$$$$ The window size is set to 55, which is the value that was observed to give optimum performance in the related task of cross-document coreference (Gooi and Allan, 2004).

This is addressed by various methods, such as setting a threshold of minimal similarity for an entity selection (Bunescu and Pasca, 2006), or training a separate binary classifier to judge whether the returned top candidate is the actual denotation (Zheng et al, 2010). $$$$$ 4.1 Context-Article Similarity.
This is addressed by various methods, such as setting a threshold of minimal similarity for an entity selection (Bunescu and Pasca, 2006), or training a separate binary classifier to judge whether the returned top candidate is the actual denotation (Zheng et al, 2010). $$$$$ entity, when compared with the simple cosine similarity baseline.

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pasca, 2006) to link the noun phrase subjects into Wikipedia. $$$$$ The string from the second link (?Rome?)
We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pasca, 2006) to link the noun phrase subjects into Wikipedia. $$$$$ If there is a dictionary entry matching the proper name in the query q such that the set of denoted entities q:E contains at least two entities, one of them the true answer entity q:e, then the query q is included in the dataset.

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia. $$$$$ It seems therefore natural to try to exploit the webin order to also improve the performance of relation extraction, i.e. the discovery of useful re lationships between named entities mentioned in text documents.
Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia. $$$$$ 9Without solving it, a relation extraction system an alyzing the sentences in the above example could mistakenly consider the third as evidence that John Williams the composer fought at Rorke?s Drift.

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)

 $$$$$ 2.1 Redirect Pages.
 $$$$$ w+ C P  q;k subject to: w ((q; q:e)
