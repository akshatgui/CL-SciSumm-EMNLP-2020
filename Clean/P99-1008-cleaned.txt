Berland and Charniak (1999) use Hearst style techniques to learn meronym relation ships (part-whole) from corpora. $$$$$ Finding Parts In Very Large Corpora
Berland and Charniak (1999) use Hearst style techniques to learn meronym relation ships (part-whole) from corpora. $$$$$ Indeed, in [2] Hearst states that she tried to apply this strategy to the part-of relation, but failed.

(Berland and Charniak, 1999) proposed similar lexico-syntactic patterns to extract part-whole relationships. $$$$$ In that paper Hearst (a) finds lexical correlates to the hyponym relations by looking in text for cases where known hyponyms appear in proximity (e.g., in the construction (NP, NP and (NP other NN)) as in &quot;boats, cars, and other vehicles&quot;), (b) tests the proposed patterns for validity, and (c) uses them to extract relations from a corpus.
(Berland and Charniak, 1999) proposed similar lexico-syntactic patterns to extract part-whole relationships. $$$$$ Table 2 shows patterns A and B clearly outperform patterns C, D, and E. Although parts occur in all five patterns, the lists for A and B are predominately parts-oriented.

The OtherY-Model performs particularly poorly on smaller data sizes, where coverage of the Hearst-style patterns maybe limited, as also observed by Berland and Charniak (1999). $$$$$ And although WordNet is hand-built, there is general agreement that corpus-based methods have an advantage in the relative completeness of their coverage, particularly when used as supplements to the more laborintensive methods.
The OtherY-Model performs particularly poorly on smaller data sizes, where coverage of the Hearst-style patterns maybe limited, as also observed by Berland and Charniak (1999). $$$$$ This performed quite poorly.

Berland and Charniak (1999) report what they believed to be the first work finding part-whole relations from unlabelled corpora. $$$$$ Finding Parts In Very Large Corpora
Berland and Charniak (1999) report what they believed to be the first work finding part-whole relations from unlabelled corpora. $$$$$ To the best of our knowledge, there is no published work on automatically finding parts from unlabeled corpora.

In 1999, Berland and Charniak (Berland and Charniak, 1999) applied statistical methods on a very large corpus to find PART-WHOLE relations. $$$$$ And although WordNet is hand-built, there is general agreement that corpus-based methods have an advantage in the relative completeness of their coverage, particularly when used as supplements to the more laborintensive methods.
In 1999, Berland and Charniak (Berland and Charniak, 1999) applied statistical methods on a very large corpus to find PART-WHOLE relations. $$$$$ We then applied the same &quot;strong conditioning, sigdiff&quot; statistical test to rank the candidates.

Berland and Charniak (1999) used similar pattern-based techniques and other heuristics to extract meronymy (part-whole) relations. $$$$$ Casting our nets wider, the work most similar to what we present here is that by Hearst [2] on acquisition of hyponyms (&quot;isa&quot; relations).
Berland and Charniak (1999) used similar pattern-based techniques and other heuristics to extract meronymy (part-whole) relations. $$$$$ Pattern D is not so obviously bad as it differs from the plural case of pattern B only in the lack of the determiner &quot;the&quot; or &quot;a&quot;.

Berland and Charniak (1999) used a similar method for extracting instances of meronymy relation. $$$$$ We present a method for extracting parts of objects from wholes (e.g.
Berland and Charniak (1999) used a similar method for extracting instances of meronymy relation. $$$$$ We present a method of extracting parts of objects from wholes (e.g.

Lexical patterns have been successfully used to represent various semantic relations between words such as hypernymy (Hearst, 1992), and meronymy (Berland and Charniak, 1999). $$$$$ Following Hearst [2], we find possible patterns by taking two words that are in a part-whole relation (e.g, basement and building) and finding sentences in our corpus (we used the North American News Corpus (NANC) from LDC) that have these words within close proximity.
Lexical patterns have been successfully used to represent various semantic relations between words such as hypernymy (Hearst, 1992), and meronymy (Berland and Charniak, 1999). $$$$$ Metrics of the form p(w I p) have the desirable property that they are invariant over p with radically different base frequencies, and for this reason have been widely used in corpus-based lexical semantic research [3,6,9].

A similar approach was pursued in parallel by Berland and Charniak (1999). $$$$$ Casting our nets wider, the work most similar to what we present here is that by Hearst [2] on acquisition of hyponyms (&quot;isa&quot; relations).
A similar approach was pursued in parallel by Berland and Charniak (1999). $$$$$ We comment later on the differences in our approach that we believe were most important to our comparative success.

Berland and Charniak (1999) suggest their work may be useful for building a lexicon or ontology, like WordNet. $$$$$ The part list could be scanned by an end-user and added to an existing ontology (such as WordNet), or used as a part of a rough semantic lexicon.
Berland and Charniak (1999) suggest their work may be useful for building a lexicon or ontology, like WordNet. $$$$$ The program's output could be scanned by an enduser and added to an existing ontology (e.g., WordNet), or used as a part of a rough semantic lexicon.

Berland and Charniak (1999) use Hearst's manual procedure. $$$$$ Indeed, in [2] Hearst states that she tried to apply this strategy to the part-of relation, but failed.
Berland and Charniak (1999) use Hearst's manual procedure. $$$$$ Finally, as noted above, Hearst [2] tried to find parts in corpora but did not achieve good results.

In attribute extraction, typically one must choose between the precise results of rich patterns (involving punctuation and parts-of-speech) applied to small corpora (Berland and Charniak, 1999) and the high-coverage results of superficial patterns applied to web-scale data, e.g. via the Google API (Almuhareb and Poesio, 2004). $$$$$ Table 2 shows patterns A and B clearly outperform patterns C, D, and E. Although parts occur in all five patterns, the lists for A and B are predominately parts-oriented.
In attribute extraction, typically one must choose between the precise results of rich patterns (involving punctuation and parts-of-speech) applied to small corpora (Berland and Charniak, 1999) and the high-coverage results of superficial patterns applied to web-scale data, e.g. via the Google API (Almuhareb and Poesio, 2004). $$$$$ Table 4 summarizes these results.

Prior work has mostly focused on finding "relevant" attributes (Alfonseca et al., 2010) or "correct" parts (Berland and Charniak, 1999). $$$$$ Finding Parts In Very Large Corpora
Prior work has mostly focused on finding "relevant" attributes (Alfonseca et al., 2010) or "correct" parts (Berland and Charniak, 1999). $$$$$ To the best of our knowledge, there is no published work on automatically finding parts from unlabeled corpora.

Indeed, Berland and Charniak (1999) attempted to filter out attributes that were regarded as qualities (like drive ability) rather than parts (like steering wheels) by removing words ending with the suffixes -ness, -ing, and -ity. $$$$$ The second filters out all words ending with &quot;ing&quot;, &quot;ness&quot;, or &quot;ity&quot;, since these suffixes typically occur in words that denote a quality rather than a physical object.
Indeed, Berland and Charniak (1999) attempted to filter out attributes that were regarded as qualities (like drive ability) rather than parts (like steering wheels) by removing words ending with the suffixes -ness, -ing, and -ity. $$$$$ We try to weed out most of the qualities by removing words with the suffixes &quot;ness&quot;, &quot;ing&quot;, and &quot;ity.&quot; The most persistent problem is sparse data, which is the source of most of the noise.

Also, previous relation extraction work, http $$$$$ Certainly the large number of projects that use WordNet [1] would support this contention.
Also, previous relation extraction work, http $$$$$ Following Hearst [2], we find possible patterns by taking two words that are in a part-whole relation (e.g, basement and building) and finding sentences in our corpus (we used the North American News Corpus (NANC) from LDC) that have these words within close proximity.

Berland and Charniak (1999) used similar pattern-based techniques and other heuristics to extract meronymy (part-whole) relations. $$$$$ Casting our nets wider, the work most similar to what we present here is that by Hearst [2] on acquisition of hyponyms (&quot;isa&quot; relations).
Berland and Charniak (1999) used similar pattern-based techniques and other heuristics to extract meronymy (part-whole) relations. $$$$$ Pattern D is not so obviously bad as it differs from the plural case of pattern B only in the lack of the determiner &quot;the&quot; or &quot;a&quot;.

Berland and Charniak (1999) proposed a system for part-of relation extraction, based on the (Hearst 1992) approach. $$$$$ Lacking an objective definition of the part-of relation, we use the majority judgment of five human subjects to decide which proposed parts are correct.
Berland and Charniak (1999) proposed a system for part-of relation extraction, based on the (Hearst 1992) approach. $$$$$ Indeed, in [2] Hearst states that she tried to apply this strategy to the part-of relation, but failed.

(Berland and Charniak, 1999) use hand crafted patterns to discover part-of (meronymy) relation ships, and (Chklovski and Pantel, 2004) discover various interesting relations between verbs. $$$$$ Thus the relation found is strictly speaking between words, a relation Miller [1] calls &quot;meronymy.&quot; In this paper we use the more colloquial &quot;part-of&quot; terminology.
(Berland and Charniak, 1999) use hand crafted patterns to discover part-of (meronymy) relation ships, and (Chklovski and Pantel, 2004) discover various interesting relations between verbs. $$$$$ Table 2 shows patterns A and B clearly outperform patterns C, D, and E. Although parts occur in all five patterns, the lists for A and B are predominately parts-oriented.

OPINE's use of meronymy lexico-syntactic patterns is similar to that of many others, from (Berland and Charniak, 1999) to (Almuhareb and Poesio, 2004). $$$$$ Thus the relation found is strictly speaking between words, a relation Miller [1] calls &quot;meronymy.&quot; In this paper we use the more colloquial &quot;part-of&quot; terminology.
OPINE's use of meronymy lexico-syntactic patterns is similar to that of many others, from (Berland and Charniak, 1999) to (Almuhareb and Poesio, 2004). $$$$$ Table 2 shows patterns A and B clearly outperform patterns C, D, and E. Although parts occur in all five patterns, the lists for A and B are predominately parts-oriented.

relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). $$$$$ Thus the relation found is strictly speaking between words, a relation Miller [1] calls &quot;meronymy.&quot; In this paper we use the more colloquial &quot;part-of&quot; terminology.
relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). $$$$$ In this paper we apply much the same methodology to the part-of relation.
