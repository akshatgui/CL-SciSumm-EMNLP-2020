This technique has previously been used not only for part-of-speech tagging (Brill, 1994), but also for prepositional phrase attachment disambiguation (Brill and Resnik, 1994), and assigning unlabeled binary-branching tree structure to sentences (Brill, 1993a). $$$$$ A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation
This technique has previously been used not only for part-of-speech tagging (Brill, 1994), but also for prepositional phrase attachment disambiguation (Brill and Resnik, 1994), and assigning unlabeled binary-branching tree structure to sentences (Brill, 1993a). $$$$$ Prel)ositioual phrase attachment disambiguation is a difficult problem.

Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995). $$$$$ 1,'or all sentences that conlbrm to this pattern in the Penn Treeb~mk W{dl St, l:eet 3ourlml corpns (MSM93), such a 4-tuplc was formed, attd each :l-tuple was paired with the at~aehnteut de- cision used in the Treebauk parse) '\['here were 12,766 4q;ul)les in all, which were randomly split into 12,206 trnining s**mples and 500 test samples.
Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995). $$$$$ 12 V N 1 V is be 13 NI V V is pul.

Since Eric Brill first introduced the method of Transformation-Based Learning (TBL) it has been used to learn rules for many natural anguage processing tasks, such as part-of-speech tagging [Brill, 1995], PP attachment disambiguation [Brill and Resnik, 1994], text chunking [Ramshaw and Marcus, 1995], spelling correction [Mangu and Brill, 1997], dialogue act tagging [Samuel et al, 1998] and ellipsis resolution [Hardt, 1998]. $$$$$ A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation
Since Eric Brill first introduced the method of Transformation-Based Learning (TBL) it has been used to learn rules for many natural anguage processing tasks, such as part-of-speech tagging [Brill, 1995], PP attachment disambiguation [Brill and Resnik, 1994], text chunking [Ramshaw and Marcus, 1995], spelling correction [Mangu and Brill, 1997], dialogue act tagging [Samuel et al, 1998] and ellipsis resolution [Hardt, 1998]. $$$$$ ' l~-ansformat ion-Based Er ror -Dr iven Learn ing Tra, nS\]bl'm~d;ion-lmsed errol:-dHven learlting is ~ sin@e learning a.lgorithm tlmt has t)eeu applied to a. number of natural la.ngm,ge prol)ie.ms, includ- Jllg l)a.t't O\[' speech tagging and syuta.cl, ic l)m:sing (1h:i92, \]h:i93a, Bri!)gb, Bri9d).

This alternative, which we have yet to try, has the advantage of fitting into the transformation-based error-driven paradigm (Brill and Resnik, 1994) more cleanly than having a translation stage. $$$$$ The best-scoring transformation then becomes the first transformation i the learned list.
This alternative, which we have yet to try, has the advantage of fitting into the transformation-based error-driven paradigm (Brill and Resnik, 1994) more cleanly than having a translation stage. $$$$$ h> stead, semanl, ic class information is an attracLive alternative.

Brill and Resnik (1994) used the supervised transformation-based learning method and lexical and conceptual classes derived from WordNet, achieving 82% precision on 500 randomly selected examples. $$$$$ They then suggest using lexical preference, estimated from a large corpus of text, as a method of re- solving attachment ambiguity, a technique the}' call "lexical association."
Brill and Resnik (1994) used the supervised transformation-based learning method and lexical and conceptual classes derived from WordNet, achieving 82% precision on 500 randomly selected examples. $$$$$ In the experiments reported here we used WordNet version :l.2.

For example, in (Brill and Resnik, 1994) clustering PP heads according to WordNetsynsets produced only a 1% improvement in a PP disambiguation task, with respect to the non-clustered method. $$$$$ A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation
For example, in (Brill and Resnik, 1994) clustering PP heads according to WordNetsynsets produced only a 1% improvement in a PP disambiguation task, with respect to the non-clustered method. $$$$$ of Method Accuracy Transforms t-Scores 70.4- 75.8 '\]?anstbrma~ions 80.8 471 Trans\['ormati ons (no N2) 79.2 418 Transformations (classes) 8:1.8 26(5 Figure 5: Comparing l{esults in PP Attachment.

This huge number of tokens can be explained by the fact that the lexicon used for tokenization and tagging integrates many multi-word expressions which are not part of these mantic lexicon for (Brill and Resnik, 1994) and 0.77 for (LauerandDras, 1994)), but a direct comparison is difficult inasmuch as only three-word sequences (V N P, for (Brill and Resnik, 1994) and N N N for (Lauer and Dras, 1994)) were used for evaluation in those works, and the language studied is English. $$$$$ ZIn transformation #8, word token amount appears because it was used as the head noun for noun phrases representing percentage amounts, e.g. "5%."
This huge number of tokens can be explained by the fact that the lexicon used for tokenization and tagging integrates many multi-word expressions which are not part of these mantic lexicon for (Brill and Resnik, 1994) and 0.77 for (LauerandDras, 1994)), but a direct comparison is difficult inasmuch as only three-word sequences (V N P, for (Brill and Resnik, 1994) and N N N for (Lauer and Dras, 1994)) were used for evaluation in those works, and the language studied is English. $$$$$ This exlw, r iment also demonstrates how rely \[~?~l;ul:e-based lexicon or word classiflcat, ion scheme cau triviaJly be incorlJorated into the learner, by exLencling l;ransfot'nlal,iolls to allow thent to make l'efel'eAlc(?

In later stages of processing, a corpus-based approach (Brill and Resnik, 1994) is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions. $$$$$ A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation
In later stages of processing, a corpus-based approach (Brill and Resnik, 1994) is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions. $$$$$ 3 Initial accuracy on the test set is 64.0% when prepositional phrases are always attached to the object noun.

For example, the sentence Congress accused the president of peccadillos is classified according to the attachment site of the prepositional phrase: attachment toN: accused [the president of peccadillos] attachment to V: (4) accused [the president] [of peccadillos] The UPenn Treebank-II Parsed Wall Street Journal corpus includes PP-attachment information, and PP-attachment classifiers based on this data have been previously described in Ratnaparkhi, Reynar, Roukos (1994), Brill and Resnik (1994), and Collins and Brooks (1995). $$$$$ A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation
For example, the sentence Congress accused the president of peccadillos is classified according to the attachment site of the prepositional phrase: attachment toN: accused [the president of peccadillos] attachment to V: (4) accused [the president] [of peccadillos] The UPenn Treebank-II Parsed Wall Street Journal corpus includes PP-attachment information, and PP-attachment classifiers based on this data have been previously described in Ratnaparkhi, Reynar, Roukos (1994), Brill and Resnik (1994), and Collins and Brooks (1995). $$$$$ Next, the training set was expanded to include not only the cases o\[' ambiguous attachment \]Fonnd in the parsed Wall Street Journal corpus, as before, but also all the unambiguous prepositional phrase at- tachments tbnnd in the corpus, as well (contiml- ing to exclnde the tesl, set, of course).

A non-statistical supervised approach by Brill and Resnik (1994) yielded 81.8% accuracy using a transformation-based approach (Brill, 1995) and incorporating word-class information. $$$$$ A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation
A non-statistical supervised approach by Brill and Resnik (1994) yielded 81.8% accuracy using a transformation-based approach (Brill, 1995) and incorporating word-class information. $$$$$ Accuracy improved to 75.8% r using the larger training set, still significantly lower than accuracy obtained us-- lag tam tl:ansformal;ion-based approach.

 $$$$$ \[n the initial sl,~te mmotator, all prepositional phrases I \])at.terns were extra.clxxl usJ.ng tgrep, a. tree-based grep program written by Rich Pito.
 $$$$$ Ilow- ever, this l)eeomes less of a probh'.m as atmotated eorl}ora beeolne increasingly available, and sug- gests the comhinat ion o1:' supexvised and uusuper vised methods as a.u ilfl;eresth G ave\]me \['or \['urther rese;ire\] \[.

 $$$$$ \[n the initial sl,~te mmotator, all prepositional phrases I \])at.terns were extra.clxxl usJ.ng tgrep, a. tree-based grep program written by Rich Pito.
 $$$$$ Ilow- ever, this l)eeomes less of a probh'.m as atmotated eorl}ora beeolne increasingly available, and sug- gests the comhinat ion o1:' supexvised and uusuper vised methods as a.u ilfl;eresth G ave\]me \['or \['urther rese;ire\] \[.

 $$$$$ \[n the initial sl,~te mmotator, all prepositional phrases I \])at.terns were extra.clxxl usJ.ng tgrep, a. tree-based grep program written by Rich Pito.
 $$$$$ Ilow- ever, this l)eeomes less of a probh'.m as atmotated eorl}ora beeolne increasingly available, and sug- gests the comhinat ion o1:' supexvised and uusuper vised methods as a.u ilfl;eresth G ave\]me \['or \['urther rese;ire\] \[.

Supervised training methods already applied to PP attachment range from stochastic maximum likelihood (Collins and Brooks, 1995) or maximum entropy models (Ratnaparkhi et al, 1994) to the induction of transformation rules (Brill and Resnik, 1994), decision trees (Stetina and Nagao, 1997) and connectionist models (Sopena et al, 1998). $$$$$ It is applied to the training corpus, and learning continues on the modified corpus.
Supervised training methods already applied to PP attachment range from stochastic maximum likelihood (Collins and Brooks, 1995) or maximum entropy models (Ratnaparkhi et al, 1994) to the induction of transformation rules (Brill and Resnik, 1994), decision trees (Stetina and Nagao, 1997) and connectionist models (Sopena et al, 1998). $$$$$ (WAIH91) and Basili el al.

Brill and Resnik (1994) applied Error-Driven TransformationBased Learning, Ratnaparkhi, Reynar and Roukos (1994) applied a Maximum Entropy model, Franz (1996) used a Loglinear model, and Collins and Brooks (1995) obtained good results using a BackOff model. $$$$$ It is applied to the training corpus, and learning continues on the modified corpus.
Brill and Resnik (1994) applied Error-Driven TransformationBased Learning, Ratnaparkhi, Reynar and Roukos (1994) applied a Maximum Entropy model, Franz (1996) used a Loglinear model, and Collins and Brooks (1995) obtained good results using a BackOff model. $$$$$ As in the experiments here, their statistical model also makes use of a 4-tuple context (v, c<l, p, n2), and can use the identit.ies of the words, class inl'or- marion (tbr them, wdues of any of the class bits), rThe difference between these results ~nd tile result they quoted is likely due to a much bLrger training set used in their origimd experiments.

The other methods for which results have been reported on this dataset include decision trees, Maximum Entropy (Ratnaparkhi, Reynar, and Roukos, 1994), and Error-Driven TransformationBased Learning (Brill and Resnik, 1994), which were clearly outperformed by both IB1 and IBI-IG, even though e.g. Brill~ Resnik used more elaborate feature sets (words and WordNet classes). $$$$$ In the experiments reported here we used WordNet version :l.2.
The other methods for which results have been reported on this dataset include decision trees, Maximum Entropy (Ratnaparkhi, Reynar, and Roukos, 1994), and Error-Driven TransformationBased Learning (Brill and Resnik, 1994), which were clearly outperformed by both IB1 and IBI-IG, even though e.g. Brill~ Resnik used more elaborate feature sets (words and WordNet classes). $$$$$ WordNet id('.ntilicrs luwe been replaced by words Lh~LL describe the cont, cnt of the class.

Brill and Resnik (1994) applied Error-Driven Transformation-Based Learning to this task, using the verb, noun1, preposition, and noun2 features. $$$$$ It is applied to the training corpus, and learning continues on the modified corpus.
Brill and Resnik (1994) applied Error-Driven Transformation-Based Learning to this task, using the verb, noun1, preposition, and noun2 features. $$$$$ 

Supervised methods are as varied as the Back off approach by Collins and Brooks (1995) and the Transformation-based approach by Brill and Resnik (1994). $$$$$ A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation
Supervised methods are as varied as the Back off approach by Collins and Brooks (1995) and the Transformation-based approach by Brill and Resnik (1994). $$$$$ The best-scoring transformation then becomes the first transformation i the learned list.

We use the PPA data created by (Brill and Resnik, 1994) and (Ratnaparkhi et al, 1994) to objectively compare the performances of the systems. $$$$$ in reality, the search is data driven, and so the vast majority of al- lowable transformations are not examined.
We use the PPA data created by (Brill and Resnik, 1994) and (Ratnaparkhi et al, 1994) to objectively compare the performances of the systems. $$$$$ it: (~an a/so ask if" it is a~ member of some class C. s This al)proaeh I;o data.

(10) The lower bound for the B&R data is 63% (Brill and Resnik, 1994) and for the IBM data is 52% (Ratnaparkhi et al, 1994). $$$$$ in reality, the search is data driven, and so the vast majority of al- lowable transformations are not examined.
(10) The lower bound for the B&R data is 63% (Brill and Resnik, 1994) and for the IBM data is 52% (Ratnaparkhi et al, 1994). $$$$$ it: (~an a/so ask if" it is a~ member of some class C. s This al)proaeh I;o data.
