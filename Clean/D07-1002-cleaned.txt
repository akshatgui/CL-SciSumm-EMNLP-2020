(Shen and Lapata, 2007) has shown that shallow semantic information in the form of predicate argument structures (PASs) improves the automatic detection of correct answers to a target question. $$$$$ Their system identifies predicate argument structures by merging semanticrole information from PropBank and FrameNet.
(Shen and Lapata, 2007) has shown that shallow semantic information in the form of predicate argument structures (PASs) improves the automatic detection of correct answers to a target question. $$$$$ They use ASSERT (Pradhan et al, 2004), a publicly available shallow semantic parser trained on PropBank, to generate predicate-argument structures which subsequently form the basis of comparison between question and answer sentences.

For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system. $$$$$ Using Semantic Roles to Improve Question Answering
For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system. $$$$$ Question answering systems have traditionally de pended on a variety of lexical resources to bridge surface differences between questions and potential answers.

The alignment of answers to question types as a semantic role labelling task using similar methods was explored by Shen and Lapata (2007). $$$$$ Using Semantic Roles to Improve Question Answering
The alignment of answers to question types as a semantic role labelling task using similar methods was explored by Shen and Lapata (2007). $$$$$ Answer types are determined using classi fication rules similar to Li and Roth (2002).

The state-of-the-art in semantic role labelling has now advanced so much that a number of studies have shown that automatically inferred semantic argument structures can lead to tangible performance gains in NLP applications such as information extraction (Surdeanu et al, 2003), question answering (Shen and Lapata, 2007) or recognising textual entailment (Burchardt and Frank, 2006). $$$$$ Their system identifies predicate argument structures by merging semanticrole information from PropBank and FrameNet.
The state-of-the-art in semantic role labelling has now advanced so much that a number of studies have shown that automatically inferred semantic argument structures can lead to tangible performance gains in NLP applications such as information extraction (Surdeanu et al, 2003), question answering (Shen and Lapata, 2007) or recognising textual entailment (Burchardt and Frank, 2006). $$$$$ Semantic structures for questions and sentences are automatically derived using the model described in Section 4 (Model I).

FrameNet has a shorter history in NLP applications than WordNet, but lately more and more researchers have been demonstrating its potential to improve the quality of question answering (Shen and Lapata, 2007) and recognizing textual entailment (Burchardt et al, 2009). $$$$$ Using Semantic Roles to Improve Question Answering
FrameNet has a shorter history in NLP applications than WordNet, but lately more and more researchers have been demonstrating its potential to improve the quality of question answering (Shen and Lapata, 2007) and recognizing textual entailment (Burchardt et al, 2009). $$$$$ WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).

Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al, 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). $$$$$ Question answering (QA) is often cited as an obvious beneficiary of semantic 12 role labeling (Gildea and Jurafsky, 2002; Palmer et al., 2005; Narayanan and Harabagiu, 2004).
Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al, 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). $$$$$ Edge covers have been success fully applied in several natural language processing tasks, including machine translation (Taskar et al, 2005) and annotation projection (Pado?

Shen and Lapata (2007) developed an answer extraction module that incorporates FrameNet style semantic role information. $$$$$ In this paper we propose an answer extractionmodel which effectively incorporates FrameNetstyle semantic role information.
Shen and Lapata (2007) developed an answer extraction module that incorporates FrameNet style semantic role information. $$$$$ We present a graph-based answer extrac tion model which effectively incorporates FrameNet style role semantic information and show that it achieves promising results.

Indeed, the analysis produced by existing semantic role labelers has been shown to benefit a wide spectrum of applications ranging from information extraction (Surdeanu et al, 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al, 2005). $$$$$ WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).
Indeed, the analysis produced by existing semantic role labelers has been shown to benefit a wide spectrum of applications ranging from information extraction (Surdeanu et al, 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al, 2005). $$$$$ Most syntax-based QA systems (Wu et al, 2005) incorporate some means of comparison between the tree representing the question with the subtree surrounding the answer candidate.

Recent studies (e.g. Shen and Lapata (2007)) show that the use of FrameNet can potentially improve the performance of Question Answering systems. $$$$$ Using Semantic Roles to Improve Question Answering
Recent studies (e.g. Shen and Lapata (2007)) show that the use of FrameNet can potentially improve the performance of Question Answering systems. $$$$$ In the following section we provide an overview of existing work on question answering systems that exploit semantic role-based lexical resources.

Yet, Shen and Lapata (2007) also point out that the low coverage of the current version of FrameNet significantly limits the expected boost in performance. $$$$$ They find that semantic analysis does not boost performance due to the low recall of the semantic parser.
Yet, Shen and Lapata (2007) also point out that the low coverage of the current version of FrameNet significantly limits the expected boost in performance. $$$$$ Table 3: System Performance on TREC datasets (see Total column in Table 1); ?: significantly better than +SemParse; ?: significantly better than SynMatch (p < 0.01, using a ?2 test).tem to yield better performance over a purely syn tactic answer extraction module.

Other work incorporating syntactic and linguistic information into IR includes early research by (Smeaton, O Donnell and Kelledy, 1995), who employed tree structured analytics (TSAs) resembling dependency trees, the use of syntax to detect paraphrases for question answering (QA) (Lin and Pantel, 2001), and semantic role labelling in QA (Shen and Lapata, 2007). $$$$$ Most syntax-based QA systems (Wu et al, 2005) incorporate some means of comparison between the tree representing the question with the subtree surrounding the answer candidate.
Other work incorporating syntactic and linguistic information into IR includes early research by (Smeaton, O Donnell and Kelledy, 1995), who employed tree structured analytics (TSAs) resembling dependency trees, the use of syntax to detect paraphrases for question answering (QA) (Lin and Pantel, 2001), and semantic role labelling in QA (Shen and Lapata, 2007). $$$$$ Baseline We compared our answer extractionmethod to a QA system that exploits solely syntac tic information without making use of FrameNet or any other type of role semantic annotations.

Semantic role analysis has the potential of benefiting a wide spectrum of applications ranging from information extraction (Surdeanu et al, 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al, 2005). $$$$$ WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).
Semantic role analysis has the potential of benefiting a wide spectrum of applications ranging from information extraction (Surdeanu et al, 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al, 2005). $$$$$ Most syntax-based QA systems (Wu et al, 2005) incorporate some means of comparison between the tree representing the question with the subtree surrounding the answer candidate.

In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al, 1998) or PropBank (Palmeret al, 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al, 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006). $$$$$ Recent years have witnessed significant progress in developing methods for the automatic identificationand labeling of semantic roles conveyed by sentential constituents.1 The success of these methods, often referred to collectively as shallow semantic pars ing (Gildea and Jurafsky, 2002), is largely due to the availability of resources like FrameNet (Fillmore et al., 2003) and PropBank (Palmer et al, 2005), which document the surface realization of semantic roles in real world corpora.
In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al, 1998) or PropBank (Palmeret al, 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al, 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006). $$$$$ WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).
