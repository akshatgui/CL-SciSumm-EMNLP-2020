Miller et al (2004) describe a relevant technique for the latter. $$$$$ We evaluate the technique for named-entity tagging.
Miller et al (2004) describe a relevant technique for the latter. $$$$$ However, we also hoped that a third technique, active learning (Cohn et al., 1996; McCallum and Nigam, 1998), would be particularly effective when used in conjunction with hierarchical word clusters.

We chose to compare with ASO because it consistently outperforms cotraining (Blum and Mitchell, 1998) and clustering methods (Miller et al, 2004). $$$$$ Immediately, with only 5,000 words of training, the discriminative model significantly outperforms the HMM.
We chose to compare with ASO because it consistently outperforms cotraining (Blum and Mitchell, 1998) and clustering methods (Miller et al, 2004). $$$$$ The work presented here extends a substantial body of previous work (Blum and Mitchell, 1998; Riloff and Jones, 1999; Lin et al., 2003; Boschee et al, 2002; Collins and Singer, 1999; Yarowsky, 1995) that all focuses on reducing annotation requirements through a combination of (a) seed examples, (b) large unannotated corpora, and (c) training example selection.

By using prefixes of various lengths, we can produce clusterings of different granularities (Miller et al, 2004). $$$$$ Clusters of various granularity are specified by prefixes of the bit strings.
By using prefixes of various lengths, we can produce clusterings of different granularities (Miller et al, 2004). $$$$$ Similarly, alternative clustering techniques, perhaps based on different contextual features or different distance measures, could further improve performance.

Following Miller et al (2004), we use prefixes of the Brown cluster hierarchy to produce clusterings of varying granularity. $$$$$ Specifically, we picked up where Spatter left off, with the clustering algorithm of (Brown et al., 1990).
Following Miller et al (2004), we use prefixes of the Brown cluster hierarchy to produce clusterings of varying granularity. $$$$$ Clusters of various granularity are specified by prefixes of the bit strings.

We found that it was nontrivial to select the proper prefix lengths for the dependency parsing task; in particular, the prefix lengths used in the Miller et al (2004) work (between 12 and 20 bits) performed poorly in dependency parsing. $$$$$ Active learning is used to select training examples.
We found that it was nontrivial to select the proper prefix lengths for the dependency parsing task; in particular, the prefix lengths used in the Miller et al (2004) work (between 12 and 20 bits) performed poorly in dependency parsing. $$$$$ We used 4 different prefix lengths

As mentioned earlier, our approach was inspired by the success of Miller et al (2004), who demonstrated the effectiveness of using word clusters as features in a discriminative learning approach. $$$$$ To implement discriminative training, we followed the averaged perceptron approach of (Collins, 2002).
As mentioned earlier, our approach was inspired by the success of Miller et al (2004), who demonstrated the effectiveness of using word clusters as features in a discriminative learning approach. $$$$$ Figure 3 shows (a) discriminative tagger performance without cluster features, (b) the same tagger using active learning, (c) the discriminative tagger with cluster features, and (d) the discriminative tagger with cluster features using active learning.

Miller et al (2004) use word clusters (Brown et al, 1992) learned from unlabeled text, resulting in a performance improvement of NER. $$$$$ First were techniques for producing word clusters from large unannotated corpora (Brown et al., 1990; Pereira et al., 1993; Lee and Pereira, 1999).
Miller et al (2004) use word clusters (Brown et al, 1992) learned from unlabeled text, resulting in a performance improvement of NER. $$$$$ Specifically, we picked up where Spatter left off, with the clustering algorithm of (Brown et al., 1990).

Given the amount of training, our results are lower than in Miller et al (2004) (an F1 of 90 with less than 25K words of training). $$$$$ All experimental results given in this paper are with the Spatter clustering algorithm.
Given the amount of training, our results are lower than in Miller et al (2004) (an F1 of 90 with less than 25K words of training). $$$$$ With 50,000 words of training, performance for the discriminative model exceeds 90F, a level not reached by the HMM until it has observed 150,000 words of training.

 $$$$$ Instead, we simply iterated for 5 epochs in all cases, regardless of the training set size or number of features used.
 $$$$$ At least for the named-entity task we studied, using the method described, a single annotator could begin work after breakfast and, by lunchtime, have enough data annotated to achieve an F-score of 90.

Though all of them used the same hierarchical word clustering algorithm for the task of name tagging and reported improvements, we noticed that the clusters used by Miller et al (2004) were quite different from that of Ratinov and Roth (2009) and Turian et al (2010). $$$$$ Name Tagging With Word Clusters And Discriminative Training
Though all of them used the same hierarchical word clustering algorithm for the task of name tagging and reported improvements, we noticed that the clusters used by Miller et al (2004) were quite different from that of Ratinov and Roth (2009) and Turian et al (2010). $$$$$ Specifically, we picked up where Spatter left off, with the clustering algorithm of (Brown et al., 1990).

It has shown promise in improving the performance of many tasks such as name tagging (Miller et al, 2004), semantic class extraction (Lin et al, 2003), chunking (Ando and Zhang, 2005), coreference resolution (Bean and Riloff, 2004) and text classification (Blum and Mitchell, 1998). $$$$$ First, the method performed nearly as well as the currently best global discriminative model (Sha and Pereira, 2003), as evaluated on one of the few tasks for which there are any published results (noun phrase chunking).
It has shown promise in improving the performance of many tasks such as name tagging (Miller et al, 2004), semantic class extraction (Lin et al, 2003), chunking (Ando and Zhang, 2005), coreference resolution (Bean and Riloff, 2004) and text classification (Blum and Mitchell, 1998). $$$$$ The work presented here extends a substantial body of previous work (Blum and Mitchell, 1998; Riloff and Jones, 1999; Lin et al., 2003; Boschee et al, 2002; Collins and Singer, 1999; Yarowsky, 1995) that all focuses on reducing annotation requirements through a combination of (a) seed examples, (b) large unannotated corpora, and (c) training example selection.

This method has been shown to be quite successful in named entity recognition (Miller et al. 2004) and dependency parsing (Koo et al, 2008). $$$$$ We evaluate the technique for named-entity tagging.
This method has been shown to be quite successful in named entity recognition (Miller et al. 2004) and dependency parsing (Koo et al, 2008). $$$$$ First were techniques for producing word clusters from large unannotated corpora (Brown et al., 1990; Pereira et al., 1993; Lee and Pereira, 1999).

Previous approaches ,e.g., (Miller et al 2004) and (Koo et al 2008), have all used the Brown algorithm for clustering (Brown et al 1992). $$$$$ First were techniques for producing word clusters from large unannotated corpora (Brown et al., 1990; Pereira et al., 1993; Lee and Pereira, 1999).
Previous approaches ,e.g., (Miller et al 2004) and (Koo et al 2008), have all used the Brown algorithm for clustering (Brown et al 1992). $$$$$ Specifically, we picked up where Spatter left off, with the clustering algorithm of (Brown et al., 1990).

Miller et al, (2004) augmented name tagging training data with hierarchical word clusters and encoded cluster membership in features for improving name tagging. $$$$$ Name Tagging With Word Clusters And Discriminative Training
Miller et al, (2004) augmented name tagging training data with hierarchical word clusters and encoded cluster membership in features for improving name tagging. $$$$$ We present a technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus. membership is encoded in features that are incorporated in a discriminatively trained tagging model.

This simple solution has been shown effective for named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008). $$$$$ We evaluate the technique for named-entity tagging.
This simple solution has been shown effective for named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008). $$$$$ First were techniques for producing word clusters from large unannotated corpora (Brown et al., 1990; Pereira et al., 1993; Lee and Pereira, 1999).

Semi-supervised approach has been successfully applied to named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008). $$$$$ We evaluate the technique for named-entity tagging.
Semi-supervised approach has been successfully applied to named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008). $$$$$ First were techniques for producing word clusters from large unannotated corpora (Brown et al., 1990; Pereira et al., 1993; Lee and Pereira, 1999).

 $$$$$ Instead, we simply iterated for 5 epochs in all cases, regardless of the training set size or number of features used.
 $$$$$ At least for the named-entity task we studied, using the method described, a single annotator could begin work after breakfast and, by lunchtime, have enough data annotated to achieve an F-score of 90.

(Miller et al, 2004) cut the BCluster tree at a certain depth k to simplify the tree, meaning every leaf descending from a particular internal node at level k is made an immediate child of that node. $$$$$ The result of running the clustering algorithm is a binary tree, where each word occupies a single leaf node, and where each leaf node contains a single word.
(Miller et al, 2004) cut the BCluster tree at a certain depth k to simplify the tree, meaning every leaf descending from a particular internal node at level k is made an immediate child of that node. $$$$$ The root node defines a cluster containing the entire vocabulary.

In addition, Miller et al (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain. $$$$$ Armed with modern discriminative training methods, it seemed reasonable to us to revisit hierarchical clustering.
In addition, Miller et al (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain. $$$$$ Similarly, alternative clustering techniques, perhaps based on different contextual features or different distance measures, could further improve performance.

One approach has been that proposed in both Miller et al (2004) and Freitag (2004), uses distributional clustering to induce features from a large corpus, and then uses these features to augment the feature space of the labeled data. $$$$$ Our model uses a total of 19 classes of features.
One approach has been that proposed in both Miller et al (2004) and Freitag (2004), uses distributional clustering to induce features from a large corpus, and then uses these features to augment the feature space of the labeled data. $$$$$ For this experiment, we used all of the features described in Section 3 except word cluster features.
