The unigrams used for sentence/headline classification were learned from WordNet (Fellbaum, 1998) dictionary entries using the STEP system described in (Andreevskaia and Bergler, 2006b). $$$$$ The proposed approach based on the fuzzy logic(Zadeh, 1987) is used here to assign fuzzy sen timent tags to all words in WordNet (Fellbaum, 1998), that is it assigns sentiment tags and a degreeof centrality of the annotated words to the sentiment category.
The unigrams used for sentence/headline classification were learned from WordNet (Fellbaum, 1998) dictionary entries using the STEP system described in (Andreevskaia and Bergler, 2006b). $$$$$ WordNet Entries Word lists for sentiment tagging applications can be compiled using different methods.

Since sentiment-bearing words in English have different degree of centrality to the category of sentiment, we have constructed a measure of word centrality to the category of positive or negative sentiment described in our earlier work (Andreevskaiaand Bergler, 2006a). $$$$$ In this paper, we challenge the applicability of this assump tion to the semantic category of sentiment, whichconsists of positive, negative and neutral subcate gories, and present a dictionary-based Sentiment Tag Extraction Program (STEP) that we use to generate a fuzzy set of English sentiment-bearing words for the use in sentiment tagging systems 1.
Since sentiment-bearing words in English have different degree of centrality to the category of sentiment, we have constructed a measure of word centrality to the category of positive or negative sentiment described in our earlier work (Andreevskaiaand Bergler, 2006a). $$$$$ centrality to the semantic category The approach to sentiment category as a fuzzyset ascribes the category of sentiment some spe cific structural properties.

 $$$$$ At the second pass, the system goes through all WordNet glosses and identifies the entries that contain in their definitions the sentiment-bearing words from the extended seed list and adds these head words (or rather, lexemes) to the corresponding category ? positive, negative or neutral (the remainder).
 $$$$$ Therefore, the disagreement between the annota tors does not necessarily reflect a quality problem in human annotation, but rather a structural property of the semantic category.This suggests that inter-annotator disagree ment rates can serve as an important source of empirical information about the structural properties of the semantic category and canhelp define and validate fuzzy sets of seman tic category members for a number of NLP tasks and applications.

At lexical level, Andreevskaia and Bergler (2006) exploit an algorithm for extracting sentiment-bearing adjectives from the WordNet based on fuzzy logic. $$$$$ The proposed approach based on the fuzzy logic(Zadeh, 1987) is used here to assign fuzzy sen timent tags to all words in WordNet (Fellbaum, 1998), that is it assigns sentiment tags and a degreeof centrality of the annotated words to the sentiment category.
At lexical level, Andreevskaia and Bergler (2006) exploit an algorithm for extracting sentiment-bearing adjectives from the WordNet based on fuzzy logic. $$$$$ The list of sentiment-bearing adjectives.

Moreover, Andreevskaia and Bergler (2006) show that the performance of automatic annotation of subjectivity at the word level can be hurt by the presence of subjectivity-ambiguous words in the training sets they use. $$$$$ Automatic methods of sentiment annotation at the word level can be grouped into two major categories

However, Kim and Hovy (2004) and Andreevskaia and Bergler (2006) show that subjectivity recognition might be the harder problem with lower human agreement and automatic performance. $$$$$ in importance of various sentiment markers have crystallized in two main approaches

In addition, Andreevskaia and Bergler (2006) show that the performance of automatic annotation of subjectivity at the word level can be hurt by the presence of subjectivity-ambiguous words in the training sets they use. $$$$$ Automatic methods of sentiment annotation at the word level can be grouped into two major categories

Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al, 2006), sentiment classification of phrases (Wilson et al, 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). $$$$$ The majority of dictionary-based approaches use WordNet information, especially, synsets and hierarchies, to acquire sentiment-marked words (Hu and Liu, 2004; Valitutti et al, 2004; Kim and Hovy, 2004) or to measure the similarity between candidate words and sentiment-bearing words such as good and bad (Kamps et al, 2004).In this paper, we propose an approach to sentiment annotation of WordNet entries that was implemented and tested in the Semantic Tag Extrac tion Program (STEP).
Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al, 2006), sentiment classification of phrases (Wilson et al, 2005), sentiment tagging of words (Andreevskaia and Bergler, 2006b), and sentiment tagging of word senses (Esuli and Sebastiani, 2006a). $$$$$ Figure 1

Similarly, Andreevskaia and Bergler (2006) used WordNet to expand seed lists with fuzzy sentiment categories, in which words could be more central to one category than the other. $$$$$ Mining WordNet For A Fuzzy Sentiment

Non-neutral adjectives were extracted from WordNet and assigned fuzzy sentiment category membership/centrality scores and tags in Andreevskaia and Bergler (2006). $$$$$ Mining WordNet For A Fuzzy Sentiment

 $$$$$ At the second pass, the system goes through all WordNet glosses and identifies the entries that contain in their definitions the sentiment-bearing words from the extended seed list and adds these head words (or rather, lexemes) to the corresponding category ? positive, negative or neutral (the remainder).
 $$$$$ Therefore, the disagreement between the annota tors does not necessarily reflect a quality problem in human annotation, but rather a structural property of the semantic category.This suggests that inter-annotator disagree ment rates can serve as an important source of empirical information about the structural properties of the semantic category and canhelp define and validate fuzzy sets of seman tic category members for a number of NLP tasks and applications.

A similar method is presented in (Andreevskaia and Bergler, 2006) where WordNet synonyms, antonyms, and glosses are used to iteratively expand a list of seeds. $$$$$ Mining WordNet For A Fuzzy Sentiment

 $$$$$ At the second pass, the system goes through all WordNet glosses and identifies the entries that contain in their definitions the sentiment-bearing words from the extended seed list and adds these head words (or rather, lexemes) to the corresponding category ? positive, negative or neutral (the remainder).
 $$$$$ Therefore, the disagreement between the annota tors does not necessarily reflect a quality problem in human annotation, but rather a structural property of the semantic category.This suggests that inter-annotator disagree ment rates can serve as an important source of empirical information about the structural properties of the semantic category and canhelp define and validate fuzzy sets of seman tic category members for a number of NLP tasks and applications.
