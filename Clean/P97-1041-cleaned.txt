Palmer (1997) conducted a Chinese segmenter which merely made use of a manually segmented corpus (without referring to any lexicon). $$$$$ As a stand-alone segmenter, we show our algorithm to produce high performance Chinese segmentation.
Palmer (1997) conducted a Chinese segmenter which merely made use of a manually segmented corpus (without referring to any lexicon). $$$$$ For our experiments, we obtained corpora which had been manually segmented by native or nearnative speakers of Chinese and Thai.

In general, the word segmentation program utilizes the word entries, part-of-speech (POS) information (Chen and Liu, 1992) in a monolingual dictionary, segmentation rules (Palmer, 1997), and some statistical information (Sproat, et al, 1994). $$$$$ For example, since word segmentation is merely a preprocessing task for a wide variety of further tasks such as parsing, information extraction, and information retrieval, different segmentations can be useful or even essential for the different tasks.
In general, the word segmentation program utilizes the word entries, part-of-speech (POS) information (Chen and Liu, 1992) in a monolingual dictionary, segmentation rules (Palmer, 1997), and some statistical information (Sproat, et al, 1994). $$$$$ In fact, the CAW algorithm alone has been shown (Buckley et al., 1996; Broglio et al., 1996) to be adequate to be used successfully in Chinese information retrieval.

 $$$$$ In this manner a sequence of rules is built for iteratively improving the initial model.
 $$$$$ This paper benefited greatly from discussions with and comments from Marc Vilain, Lynette Hirschman, Sam Bayer, and the anonymous reviewers.

This approach was used by Palmer (1997) for word segmentation. $$$$$ We used our rule-based algorithm to improve the word segmentation rate for several segmentation algorithms in three languages.
This approach was used by Palmer (1997) for word segmentation. $$$$$ In this manner, an initial segmentation can be obtained that is more informed than a simple character-as-word approach.

Our work adds an existing system to improve the rules learned, while Palmer (1997) adds rules to improve an existing system's performance. $$$$$ In this experiment we demonstrate that our algorithm can also improve the output of such a system.
Our work adds an existing system to improve the rules learned, while Palmer (1997) adds rules to improve an existing system's performance. $$$$$ Our rule-based algorithm is thus able to produce an improvement to an existing high-performance system.

One may note that the error reductions here are smaller than Palmer (1997)'s error reductions. $$$$$ Our rule-based algorithm learned a sequence of 731 transformations which improved the score from 48.2 to 63.6, a 29.7% error reduction.
One may note that the error reductions here are smaller than Palmer (1997)'s error reductions. $$$$$ While the alphabetic system is obviously harder to segment, we still see a significant reduction in the segmenter error rate using the transformation-based algorithm.

In Palmer (1997), the baseline is how well an existing system performs before the rules are run. $$$$$ In this manner a sequence of rules is built for iteratively improving the initial model.
In Palmer (1997), the baseline is how well an existing system performs before the rules are run. $$$$$ Our rule-based algorithm is thus able to produce an improvement to an existing high-performance system.

If we were to use the same baseline as Palmer (1997), our baseline would be an F of 37.5% for IaB and 52.6% for IaC. $$$$$ With the above algorithm in place, we can use the training data to produce a rule sequence to augment an initial segmentation approximation in order to obtain a better approximation of the desired segmentation.
If we were to use the same baseline as Palmer (1997), our baseline would be an F of 37.5% for IaB and 52.6% for IaC. $$$$$ We can use these resources to provide an informed initial segmentation approximation separate from the greedy algorithm.

For example, (Palmer, 1997) developed a Chinese word segmenter using a manually segmented corpus. $$$$$ For our experiments, we obtained corpora which had been manually segmented by native or nearnative speakers of Chinese and Thai.
For example, (Palmer, 1997) developed a Chinese word segmenter using a manually segmented corpus. $$$$$ The rule-based algorithm we developed to improve word segmentation is very effective for segmenting Chinese; in fact, the rule sequences combined with a very simple initial segmentation, such as that from a maximum matching algorithm, produce performance comparable to manually-developed segmenters.

Palmer (1997) uses transform-based learning (TBL) to correct an initial segmentation. $$$$$ The learning algorithm also considers the entire training set at all learning steps, rather than decreasing the size of the training data as learning progresses, such as is the case in decision-tree induction (Quinlan, 1986).
Palmer (1997) uses transform-based learning (TBL) to correct an initial segmentation. $$$$$ Word segmentation can easily be cast as a transformation-based problem, which requires an initial model, a goal state into which we wish to transform the initial model (the &quot;gold standard&quot;), and a series of transformations to effect this improvement.

In a later paper, Palmer (1997) presents a transformation-based algorithm, which requires pre-segmented training data. $$$$$ This paper presents a trainable rule-based algorithm for performing word segmentation.
In a later paper, Palmer (1997) presents a transformation-based algorithm, which requires pre-segmented training data. $$$$$ This paper presents a trainable rule-based algorithm for performing word segmentation.

The use of TBL for Chinese word segmentation was first suggested in Palmer (1997). $$$$$ A very simple initial segmentation for Chinese is to consider each character a distinct word.
The use of TBL for Chinese word segmentation was first suggested in Palmer (1997). $$$$$ We can use these resources to provide an informed initial segmentation approximation separate from the greedy algorithm.
