Barzilay and Lapata (2008) presented early work in investigating the use of discourse to distinguish abridged from original encyclopedia articles. $$$$$ Our results are presented in Section 4.3.
Barzilay and Lapata (2008) presented early work in investigating the use of discourse to distinguish abridged from original encyclopedia articles. $$$$$ The corpus contains 107 articles from the full version of the encyclopedia and their corresponding simplified articles from Britannica Elementary (214 articles in total).

We adopt Barzilay and Lapata (2008)'s entity based local coherence model to represent a document by an entity grid, and extract local transitions among entities in continuous discourse constituents. $$$$$ Modeling Local Coherence: An Entity-Based Approach
We adopt Barzilay and Lapata (2008)'s entity based local coherence model to represent a document by an entity grid, and extract local transitions among entities in continuous discourse constituents. $$$$$ Local transitions can be easily obtained from a grid as continuous subsequences of each column.

A prominent example is the entity-based model by Barzilay and Lapata (2008). $$$$$ We focused on three sources of linguistic knowledge—syntax, coreference resolution, and salience—which play a prominent role in entity-based analyses of disBarzilay and Lapata Modeling Local Coherence course coherence (see Section 3.3 for details).
A prominent example is the entity-based model by Barzilay and Lapata (2008). $$$$$ Unfortunately, we could not Barzilay and Lapata Modeling Local Coherence employ Barzilay and Lee’s (2004) content models for the summary ranking task.

Adapted from the introduction to Barzilay and Lapata (2008). $$$$$ 1998) or sentences (Lapata 2003; Barzilay and Lee 2004).
Adapted from the introduction to Barzilay and Lapata (2008). $$$$$ Unfortunately, we could not Barzilay and Lapata Modeling Local Coherence employ Barzilay and Lee’s (2004) content models for the summary ranking task.

We follow Barzilay and Lapata (2008) and use the Fisher Sign test. $$$$$ We assess whether differences in accuracy are statistically significant using a Fisher Sign Test.
We follow Barzilay and Lapata (2008) and use the Fisher Sign test. $$$$$ First, note that the entity-grid model significantly outperforms LSA on both domains (p < .01 using a Sign test, see Table 5).

The entity-based coherence model, proposed by Barzilay and Lapata (2008), is one of the most popular statistical models of inter-sentential coherence, and learns coherence properties similar to those employed by Centering Theory (Grosz et al, 1995). $$$$$ This assumption is not arbitrary—some of these regularities have been recognized in Centering Theory (Grosz, Joshi, and Weinstein 1995) and other entity-based theories of discourse (e.g., Givon 1987; Prince 1981).
The entity-based coherence model, proposed by Barzilay and Lapata (2008), is one of the most popular statistical models of inter-sentential coherence, and learns coherence properties similar to those employed by Centering Theory (Grosz et al, 1995). $$$$$ Similar observations have been made in other work which is closer in spirit to Centering’s claims (Hasler 2004; Karamanis et al. 2004; Poesio et al.

Their local model of discourse coherence is based on the entity-grid (Barzilay and Lapata, 2008), as well as on the lexicalized IBM model (see Section 4.6 above); we have experimented with both, and showed that they have a minimal effect on grading performance with the FCE dataset. $$$$$ In this section we describe our entity-based representation of discourse.
Their local model of discourse coherence is based on the entity-grid (Barzilay and Lapata, 2008), as well as on the lexicalized IBM model (see Section 4.6 above); we have experimented with both, and showed that they have a minimal effect on grading performance with the FCE dataset. $$$$$ Barzilay and Lapata Modeling Local Coherence Furthermore, note that discourse-level information is absent from Schwarm and Ostendorf’s (2005) original model.

First, we show in a sentence ordering experiment that topological field information improves the entity grid model of Barzilay and Lapata (2008) more than grammatical role and simple clausal order information do, particularly when manual annotations of this information are not available. $$$$$ Such information can be expressed in many ways (e.g., using constituent labels or thematic role information).
First, we show in a sentence ordering experiment that topological field information improves the entity grid model of Barzilay and Lapata (2008) more than grammatical role and simple clausal order information do, particularly when manual annotations of this information are not available. $$$$$ We present two task-based experiments that put this hypothesis to the test: information ordering (Experiment 1) and summary coherence rating (Experiment 2).

Barzilay and Lapata (2008) introduce the entity grid as a method of representing the coherence of a document. $$$$$ Then, we introduce our entity-based representation, and define its linguistic properties.
Barzilay and Lapata (2008) introduce the entity grid as a method of representing the coherence of a document. $$$$$ Barzilay and Lapata Modeling Local Coherence coherence score assigned to the original document against each of its permutations.

In Barzilay and Lapata (2008), an entity grid is constructed for each document, and is represented as a matrix in which each row represents a sentence, and each column represents an entity. $$$$$ A local entity transition is a sequence {S, O, X, –}n that represents entity occurrences and their syntactic roles in n adjacent sentences.
In Barzilay and Lapata (2008), an entity grid is constructed for each document, and is represented as a matrix in which each row represents a sentence, and each column represents an entity. $$$$$ Co-occurrence information is collected in a frequency matrix, where each row corresponds to a unique word, and each column represents a given linguistic context (e.g., sentence, document, or paragraph).

We test a version of the entity grid representation augmented with topological fields in a sentence ordering experiment corresponding to Experiment 1 of Barzilay and Lapata (2008). $$$$$ We present two task-based experiments that put this hypothesis to the test: information ordering (Experiment 1) and summary coherence rating (Experiment 2).
We test a version of the entity grid representation augmented with topological fields in a sentence ordering experiment corresponding to Experiment 1 of Barzilay and Lapata (2008). $$$$$ We experimented with two models that yielded good performances in our previous experiments: Coreference+Syntax+Salience+ (see Experiment 1) and Coreference−Syntax+Salience+ (see Experiment 2).

This set is larger than the set that was used in Experiment 1 of Barzilay and Lapata (2008), which consists of 400 documents in two English subcorpora on earthquakes and accidents respectively. $$$$$ For the latter experiment the training data set was created by randomly sampling 50 Earthquakes and 50 Accidents documents.
This set is larger than the set that was used in Experiment 1 of Barzilay and Lapata (2008), which consists of 400 documents in two English subcorpora on earthquakes and accidents respectively. $$$$$ Six documents from the training data were used as a development set.

Barzilay and Lapata (2008) found that grammatical role improves performance in this task for an English corpus. $$$$$ Unfortunately, we could not Barzilay and Lapata Modeling Local Coherence employ Barzilay and Lee’s (2004) content models for the summary ranking task.
Barzilay and Lapata (2008) found that grammatical role improves performance in this task for an English corpus. $$$$$ We simply record whether an entity is mentioned in the discourse and in what grammatical role.

The results we obtain are higher than the results for the English corpora of Barzilay and Lapata (2008) (87.2% on the Earthquakes corpus and 90.4% on the Accidents corpus), but this is probably due to corpus differences as well as the availability of perfect coreference information in our experiments. $$$$$ In our experiments, we built two content models, one for the Accidents corpus and one for the Earthquake corpus.
The results we obtain are higher than the results for the English corpora of Barzilay and Lapata (2008) (87.2% on the Earthquakes corpus and 90.4% on the Accidents corpus), but this is probably due to corpus differences as well as the availability of perfect coreference information in our experiments. $$$$$ In fact, inspection of the grids from the Accidents corpus reveals that they have many sequences of the form [X X X], [X − − X], [X X − −], and [− − X X] in common, Two texts from the Earthquakes and Accidents corpus.

Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ In our experiments, we employ Ng and Cardie’s (2002) coreference resolution system.
Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ The system we employ (Ng and Cardie 2002) was trained on human-authored newspaper texts.

We extend the original entity-based coherence model (Barzilay and Lapata, 2008) by learning from more fine-grained coherence preferences in training data. $$$$$ Barzilay and Lapata Modeling Local Coherence coherence score assigned to the original document against each of its permutations.
We extend the original entity-based coherence model (Barzilay and Lapata, 2008) by learning from more fine-grained coherence preferences in training data. $$$$$ Barzilay and Lapata Modeling Local Coherence An important future direction lies in augmenting our entity-based representation with more fine-grained lexico-semantic knowledge.

We show that our multiple-rank model outperforms B & L's basic model on two tasks, sentence ordering and summary coherence rating, evaluated on the same datasets as in Barzilay and Lapata (2008). $$$$$ In the following sections we evaluate their performance on three tasks: sentence ordering, summary coherence rating, and readability assessment.
We show that our multiple-rank model outperforms B & L's basic model on two tasks, sentence ordering and summary coherence rating, evaluated on the same datasets as in Barzilay and Lapata (2008). $$$$$ Barzilay and Lapata Modeling Local Coherence Summary coherence rating can be also formulated as a ranking learning task.

For entity extraction, Barzilay and Lapata (2008) had two conditions: Coreference + and Coreference -. $$$$$ Entity Extraction.
For entity extraction, Barzilay and Lapata (2008) had two conditions: Coreference + and Coreference -. $$$$$ On the Earthquakes corpus every model that does not use coreference information (Coreference−Syntax[+/−]Salience[+/−]) performs significantly worse than models augmented with coreference (Coreference+ Syntax[+/−]Salience[+/−]).

Two evaluation tasks for Barzilay and Lapata (2008)'s entity-based model are sentence ordering and summary coherence rating. $$$$$ In the following sections we evaluate their performance on three tasks: sentence ordering, summary coherence rating, and readability assessment.
Two evaluation tasks for Barzilay and Lapata (2008)'s entity-based model are sentence ordering and summary coherence rating. $$$$$ Barzilay and Lapata Modeling Local Coherence Summary coherence rating can be also formulated as a ranking learning task.

Barzilay and Lapata (2008) experimented on two datasets: news articles on the topic of earthquakes (Earthquakes) and narratives on the topic of aviation accidents (Accidents). $$$$$ The first collection consists of Associated Press articles from the North American News Corpus on the topic of earthquakes (Earthquakes).
Barzilay and Lapata (2008) experimented on two datasets: news articles on the topic of earthquakes (Earthquakes) and narratives on the topic of aviation accidents (Accidents). $$$$$ The second includes narratives from the National Transportation Safety Board’s aviation accident database (Accidents).
