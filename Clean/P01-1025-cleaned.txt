We are aware of the fact that other measures of lexical association have been proposed (Evert and Krenn, 2001, and MI values were computed using Adam Berger's trigger toolkit (Berger, 1997). $$$$$ Methods For The Qualitative Evaluation Of Lexical Association Measures
We are aware of the fact that other measures of lexical association have been proposed (Evert and Krenn, 2001, and MI values were computed using Adam Berger's trigger toolkit (Berger, 1997). $$$$$ In computational linguistics, a variety of (statistical) measures have been proposed for identifying lexical associations between words in lexical tuples extracted from text corpora.

 $$$$$ The most problematic aspect here is that conclusions drawn from -best lists for a single (and often small) value of are only snapshots and likely to be misleading.
 $$$$$ The authors would like to thank the anonymous reviewers for many helpful comments and interesting references.

Following the methodology described by Evert and Krenn (2001), German PP-verb combinations were extracted from a chunk-parsed version of the Frankfurter Rundschau Corpus. $$$$$ The second set consists of PNV triples extracted from an 8 million word portion of the Frankfurter Rundschau Corpus4, in which partof-speech tags and minimal PPs were identified.5 The PNV triples were selected automatically such that the preposition and the noun are constituents of the same PP, and the PP and the verb co-occur within a sentence.
Following the methodology described by Evert and Krenn (2001), German PP-verb combinations were extracted from a chunk-parsed version of the Frankfurter Rundschau Corpus. $$$$$ The criteria used for the distinction between collocations and arbitrary word combinations are

 $$$$$ The most problematic aspect here is that conclusions drawn from -best lists for a single (and often small) value of are only snapshots and likely to be misleading.
 $$$$$ The authors would like to thank the anonymous reviewers for many helpful comments and interesting references.

In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable than frequency counting. $$$$$ A standard procedure for the evaluation of AMs is manual judgment of the -best candidates identified in a particular corpus by the measure in question.
In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable than frequency counting. $$$$$ This value corresponds to the expected precision value for random selection, and provides a baseline for the interpretation of the precision curves.

In particular Evert and Krenn (2001) use the chi-square test which assumes independent samples and is thus not really suitable for testing the significance of differences of two or more measures which are typically run on the same set of candidates (i.e., a dependent sample). $$$$$ The significance of differences between the AMs is addressed in section 6.
In particular Evert and Krenn (2001) use the chi-square test which assumes independent samples and is thus not really suitable for testing the significance of differences of two or more measures which are typically run on the same set of candidates (i.e., a dependent sample). $$$$$ Therefore, we use random samples from the candidate sets to obtain estimates for the proportion of true collocations among the low-frequency data.

As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). $$$$$ See section 3 for a description of the base data.
As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). $$$$$ We have assessed the significance of differences between AMs using the well-known test as described in (Krenn, 2000).12 The thin lines in Figure 10 delimit 95% confidence intervals around the best-performing measure for the AdjN data with (log-likelihood).

To overcome these limitations, we use the evaluation method described by Evert and Krenn (2001). $$$$$ This method leads to a very superficial judgment of AMs for the following reasons

Cf. also Evert and Krenn (2001) for empirical evidence justifying the exclusion of low-frequency data. $$$$$ Consequently, results achieved by individual measures may very well be due to chance (cf. sections 4.1 and 4.2), and evaluation with respect to frequency strata is not possible (cf. section 4.3).
Cf. also Evert and Krenn (2001) for empirical evidence justifying the exclusion of low-frequency data. $$$$$ Again, we conclude that the exclusion of low-frequency candidates was well justified.

The comparison to the t-test is especially interesting because it was found to achieve the best overall precision scores in other studies (see Evert and Krenn (2001)). $$$$$ Examining the precision and recall graphs in more detail, we find that for the AdjN data (Figure 1), log-likelihood and t-test lead to the best results, with log-likelihood giving an overall better result than the t-test.
The comparison to the t-test is especially interesting because it was found to achieve the best overall precision scores in other studies (see Evert and Krenn (2001)). $$$$$ Summing up, t-test – with a few exceptions around the first 5% of the data in the SLs – leads to the overall best precision results for high-frequency PNV data.

We also define four features that represent known collocation measures (Evert and Krenn, 2001) $$$$$ The measures – Mutual Information ( ) (Church and Hanks, 1989), the log-likelihood ratio test (Dunning, 1993), two statistical tests

To eliminate noisy low-frequency data (cf. also Evert and Krenn (2001)), we defined different frequency cut-off thresholds, c, for the bigram, trigram and quadgram candidate sets and only considered candidates above these thresholds. $$$$$ While we have previously considered data from a broad frequency range (i.e., frequencies for AdjN and for PNV), we will now split up the candidate sets into high-frequency and low-frequency occurrences.
To eliminate noisy low-frequency data (cf. also Evert and Krenn (2001)), we defined different frequency cut-off thresholds, c, for the bigram, trigram and quadgram candidate sets and only considered candidates above these thresholds. $$$$$ One way to deal with lowfrequency candidates is the introduction of cutoff thresholds.

We compare our P-Mod algorithm against the t-test measure, which, of all standard measures, yields the best results in general-language collocation extraction studies (Evert and Krenn, 2001), and also against the widely used C-value, which aims at enhancing the common frequency of occurrence measure by making it sensitive to nested terms (Frantzi et al, 2000). $$$$$ This is necessary, in particular, when co-occurrence frequency is used as an association measure.
We compare our P-Mod algorithm against the t-test measure, which, of all standard measures, yields the best results in general-language collocation extraction studies (Evert and Krenn, 2001), and also against the widely used C-value, which aims at enhancing the common frequency of occurrence measure by making it sensitive to nested terms (Frantzi et al, 2000). $$$$$ Weeber et al. (2000) and Figure 8).

Studies on collocation extraction (e.g., by Evert and Krenn (2001)) also point out the inadequacy of such evaluation methods. $$$$$ Methods For The Qualitative Evaluation Of Lexical Association Measures
Studies on collocation extraction (e.g., by Evert and Krenn (2001)) also point out the inadequacy of such evaluation methods. $$$$$ The major drawback of an approach where all low-frequency candidates are excluded is that a large part of the data is lost for collocation extraction.

The evaluation procedure used here (first suggested by Evert and Krenn (2001) for evaluating measures of lexical association) involves producing and evaluating just such a ranking. $$$$$ Methods For The Qualitative Evaluation Of Lexical Association Measures
The evaluation procedure used here (first suggested by Evert and Krenn (2001) for evaluating measures of lexical association) involves producing and evaluating just such a ranking. $$$$$ In this paper, we first specify requirements for a qualitative evaluation of lexical association measures (AMs).

This is consistent with results reportedby Evert and Krenn (2001). $$$$$ For instance, considering the set of AdjN base data with we might arrive at the following results (Table 2 gives the precision values of the highest ranked word combinations with )

Our evaluation was partly inspired by Evert and Krenn (2001). $$$$$ Methods For The Qualitative Evaluation Of Lexical Association Measures
Our evaluation was partly inspired by Evert and Krenn (2001). $$$$$ In this paper, we first specify requirements for a qualitative evaluation of lexical association measures (AMs).

In Krenn & Evert 2001, frequency outperformed mutual information though not the t test, while in Evert and Krenn 2001, log-likelihood and the t-test gave the best results, and mutual information again performed worse than frequency. $$$$$ The measures – Mutual Information ( ) (Church and Hanks, 1989), the log-likelihood ratio test (Dunning, 1993), two statistical tests
