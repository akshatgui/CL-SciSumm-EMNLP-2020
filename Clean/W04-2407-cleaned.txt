Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al, 2004). $$$$$ Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic pars ing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre, 2003).
Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al, 2004). $$$$$ Unlike most pre vious work on data-driven dependency parsing (Eisner, 1996; Collins et al, 1999; Yamada and Matsumoto, 2003;Nivre, 2003), we assume that dependency graphs are la beled with dependency types, although the evaluationwill give results for both labeled and unlabeled represen tations.

The parsing methodology investigated here has previously been applied to Swedish, where promising results were obtained with a relatively smalltreebank (approximately 5000 sentences for training), resulting in an attachment score of 84.7% and a labeled accuracy of 80.6% (Nivre et al, 2004). $$$$$ Model Labeled Unlabeled MCLE 74.7 (72.3) 81.5 (79.7) MBL non-lexical 76.5 (74.7) 82.9 (81.7) MBL lexical 81.7 (80.6) 85.7 (84.7) Table 4: Parsing accuracy for MCLE and MBL models, attachment score per sentence (per word in parentheses) If we compare the results concerning parsing accuracy to those obtained for other languages (given that there are no comparable results available for Swedish), we note that the best unlabeled attachment score is lower than forEnglish, where the best results are above 90% (attach ment score per word) (Collins et al, 1999; Yamada and Matsumoto, 2003), but higher than for Czech (Collins et al., 1999).
The parsing methodology investigated here has previously been applied to Swedish, where promising results were obtained with a relatively smalltreebank (approximately 5000 sentences for training), resulting in an attachment score of 84.7% and a labeled accuracy of 80.6% (Nivre et al, 2004). $$$$$ More over, the fact that our parser uses labeled dependenciesis probably also significant, since the possibility of using information from previously assigned (labeled) de pendencies during parsing seems to have a positive effect on accuracy (Nivre, 2004).

For a more detailed discussion of dependency graphs and well-formedness conditions, the reader is referred to Nivre (2003). $$$$$ 2.1 Dependency Graphs.
For a more detailed discussion of dependency graphs and well-formedness conditions, the reader is referred to Nivre (2003). $$$$$ For a more detailed discussion of dependency graphs and well-formedness conditions, the reader is referred to Nivre (2003).

Previous work on memory-based learning for deterministic parsing includes Veenstra and Daelemans (2000) and Nivre et al (2004). $$$$$ However, in order to maintain the efficiency of the parser, the classifier must also be implemented in such a way that each transition can still be performed in constant time.Previous work in this area includes the use of memory based learning to guide a standard shift-reduce parser(Veenstra and Daelemans, 2000) and the use of support vector machines to guide a deterministic depen dency parser (Yamada and Matsumoto, 2003).
Previous work on memory-based learning for deterministic parsing includes Veenstra and Daelemans (2000) and Nivre et al (2004). $$$$$ 2.4 Memory-Based Learning.

Models similar to model 2 have been found to work well for datasets with a rich annotation of dependency types, such as the Swedish dependency tree bank derived from Einarsson (1976), where the extra part-of-speech features are largely redundant (Nivre et al, 2004). $$$$$ Unlike most pre vious work on data-driven dependency parsing (Eisner, 1996; Collins et al, 1999; Yamada and Matsumoto, 2003;Nivre, 2003), we assume that dependency graphs are la beled with dependency types, although the evaluationwill give results for both labeled and unlabeled represen tations.
Models similar to model 2 have been found to work well for datasets with a rich annotation of dependency types, such as the Swedish dependency tree bank derived from Einarsson (1976), where the extra part-of-speech features are largely redundant (Nivre et al, 2004). $$$$$ Instead, we have to simulate the parser on the tree bank in order to derive, for each sentence, the transition sequence corresponding to the correct dependency tree.

These settings are the result of extensive experiments partially reported in Nivre et al (2004). $$$$$ (The final test set has not been used at all in the experiments reported in this paper.)
These settings are the result of extensive experiments partially reported in Nivre et al (2004). $$$$$ The results in the first column were obtained with the default settings of the TiMBL package, in particular: ? The IB1 classification algorithm (Aha et al, 1991).

The portion of words that are assigned the correct head and dependency type (or no head if the word is a root) (Nivre et al, 2004). $$$$$ In addition to the word form itself (TOP), we consider its part-of-speech (as assigned by an automatic part-of-speech tagger in a preprocessing phase), the dependency type by which it is related to its head (which may or may not be available in a given configuration depending on whether the head is to the left or to the right of the token in question), and the dependency types by which it is related to its leftmost and rightmost dependent, respectively (where the currentrightmost dependent may or may not be the rightmost de pendent in the complete dependency tree).
The portion of words that are assigned the correct head and dependency type (or no head if the word is a root) (Nivre et al, 2004). $$$$$ The attachment score is computed as theproportion of tokens (excluding punctuation) that are as signed the correct head (or no head if the token is a root).

Indirect support for this assumption can be gained from previous experiments with Swedish data, where al most the same accuracy (85% unlabeled attachment score) has been achieved with a tree bank which is much smaller but which contains proper dependency annotation (Nivre et al, 2004). $$$$$ However, since most previous studies instead use the mean attachment score per word (Eisner, 1996; Collins et al, 1999), we will give this measure as well.In order to measure label accuracy, we also define a la beled attachment score, where both the head and the label must be correct, but which is otherwise computed in the same way as the ordinary (unlabeled) attachment score.
Indirect support for this assumption can be gained from previous experiments with Swedish data, where al most the same accuracy (85% unlabeled attachment score) has been achieved with a tree bank which is much smaller but which contains proper dependency annotation (Nivre et al, 2004). $$$$$ Model Labeled Unlabeled MCLE 74.7 (72.3) 81.5 (79.7) MBL non-lexical 76.5 (74.7) 82.9 (81.7) MBL lexical 81.7 (80.6) 85.7 (84.7) Table 4: Parsing accuracy for MCLE and MBL models, attachment score per sentence (per word in parentheses) If we compare the results concerning parsing accuracy to those obtained for other languages (given that there are no comparable results available for Swedish), we note that the best unlabeled attachment score is lower than forEnglish, where the best results are above 90% (attach ment score per word) (Collins et al, 1999; Yamada and Matsumoto, 2003), but higher than for Czech (Collins et al., 1999).

This approach was pioneered by (Yamada and Matsumoto, 2003) and (Nivreet al, 2004). $$$$$ Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic pars ing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre, 2003).
This approach was pioneered by (Yamada and Matsumoto, 2003) and (Nivreet al, 2004). $$$$$ Moreover, the memory-based approach can easily handle multi-class classification, unlike the support vector machines used by Yamada and Matsumoto (2003).

It was extended to labeled dependency parsing by Nivre et al (2004) (for Swedish) and Nivre and Scholz (2004) (for English). $$$$$ This model, which we will refer to as the MCLE model, is described in more detail in Nivre (2004).
It was extended to labeled dependency parsing by Nivre et al (2004) (for Swedish) and Nivre and Scholz (2004) (for English). $$$$$ More over, the fact that our parser uses labeled dependenciesis probably also significant, since the possibility of using information from previously assigned (labeled) de pendencies during parsing seems to have a positive effect on accuracy (Nivre, 2004).

 $$$$$ The transitions Left-Arc and Right-Arc are subject to conditions that ensure that the graph conditions Uniquelabel and Single head are satisfied.
 $$$$$ We are grateful to three anonymous reviewers for constructive com ments on the preliminary version of the paper.

Based on results from previous optimization experiments (Nivre et al., 2004), we use the modified value difference metric (MVDM) to determine distances between instances, and distance-weighted class voting for determining the class of a new instance. $$$$$ For the experiments reported in this paper, we have used the software package TiMBL (Tilburg MemoryBased Learner), which provides a variety of metrics, al gorithms, and extra functions on top of the classical knearest neighbor classification kernel, such as value distance metrics and distance weighted class voting (Daele mans et al, 2003).
Based on results from previous optimization experiments (Nivre et al., 2004), we use the modified value difference metric (MVDM) to determine distances between instances, and distance-weighted class voting for determining the class of a new instance. $$$$$ Distance weighted class voting with inverse distance weighting (Dudani, 1976).

Compared to the state of the art in dependency parsing, the unlabeled attachment scores obtained for Swedish with model? 5, for both MBL and SVM, are about 1 percentage point higher than the results reported for MBL by Nivre et al (2004). $$$$$ The unlabeled attachment score is naturally higher, and it is worth noting that the relative differ ence between the MBL lexical model and the other twomodels is much smaller.
Compared to the state of the art in dependency parsing, the unlabeled attachment scores obtained for Swedish with model? 5, for both MBL and SVM, are about 1 percentage point higher than the results reported for MBL by Nivre et al (2004). $$$$$ Model Labeled Unlabeled MCLE 74.7 (72.3) 81.5 (79.7) MBL non-lexical 76.5 (74.7) 82.9 (81.7) MBL lexical 81.7 (80.6) 85.7 (84.7) Table 4: Parsing accuracy for MCLE and MBL models, attachment score per sentence (per word in parentheses) If we compare the results concerning parsing accuracy to those obtained for other languages (given that there are no comparable results available for Swedish), we note that the best unlabeled attachment score is lower than forEnglish, where the best results are above 90% (attach ment score per word) (Collins et al, 1999; Yamada and Matsumoto, 2003), but higher than for Czech (Collins et al., 1999).

In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al, 2004) and English (Nivre and Scholz, 2004). $$$$$ Unlike most pre vious work on data-driven dependency parsing (Eisner, 1996; Collins et al, 1999; Yamada and Matsumoto, 2003;Nivre, 2003), we assume that dependency graphs are la beled with dependency types, although the evaluationwill give results for both labeled and unlabeled represen tations.
In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al, 2004) and English (Nivre and Scholz, 2004). $$$$$ 2.1 Dependency Graphs.

More details on the memory-based prediction can be found in Nivre et al (2004) and Nivre and Scholz (2004). $$$$$ 2.4 Memory-Based Learning.
More details on the memory-based prediction can be found in Nivre et al (2004) and Nivre and Scholz (2004). $$$$$ This model, which we will refer to as the MCLE model, is described in more detail in Nivre (2004).

 $$$$$ The transitions Left-Arc and Right-Arc are subject to conditions that ensure that the graph conditions Uniquelabel and Single head are satisfied.
 $$$$$ We are grateful to three anonymous reviewers for constructive com ments on the preliminary version of the paper.

To assign probabilities to these actions, previous work has proposed memory-based classifiers (Nivre et al, 2004), SVMs (Nivre et al, 2006b), and Incremental Sigmoid Belief Networks (ISBN) (Titov and Henderson, 2007b). $$$$$ 2.4 Memory-Based Learning.
To assign probabilities to these actions, previous work has proposed memory-based classifiers (Nivre et al, 2004), SVMs (Nivre et al, 2006b), and Incremental Sigmoid Belief Networks (ISBN) (Titov and Henderson, 2007b). $$$$$ The memory-based classifiers used in the experi ments were constructed using the Tilburg Memory-BasedLearner (TiMBL) (Daelemans et al, 2003).

We build an ISBN model of dependency parsing using the parsing order proposed in (Nivre et al,2004). $$$$$ Memory-Based Dependency Parsing
We build an ISBN model of dependency parsing using the parsing order proposed in (Nivre et al,2004). $$$$$ This model, which we will refer to as the MCLE model, is described in more detail in Nivre (2004).

However, instead of performing deterministic parsing as in (Nivre et al, 2004), we use this ordering to define a generative history-based model, by integrating word prediction operations into the set of parser actions. $$$$$ For this purpose we define a number of features that can be used to define different models of parser state.
However, instead of performing deterministic parsing as in (Nivre et al, 2004), we use this ordering to define a generative history-based model, by integrating word prediction operations into the set of parser actions. $$$$$ This model, which we will refer to as the MCLE model, is described in more detail in Nivre (2004).

Another advantage of generative models is that they do not suffer from the label bias problems (Bottou, 1991), which is a potential problem for conditional or deterministic history-based models, such as (Nivre et al, 2004). $$$$$ Memory-based learning and problem solving is based ontwo fundamental principles: learning is the simple stor age of experiences in memory, and solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans, 1999).
Another advantage of generative models is that they do not suffer from the label bias problems (Bottou, 1991), which is a potential problem for conditional or deterministic history-based models, such as (Nivre et al, 2004). $$$$$ (1991).
