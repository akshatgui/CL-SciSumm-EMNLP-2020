Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

Callison-Burch et al (2006) point out three prominent factors. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Callison-Burch et al (2006) point out three prominent factors. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).
This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ In this paper we have shown that significant gains in coverage and translation quality can be had by integrating paraphrases into statistical machine translation.

Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ Bannard and Callison-Burch (2005) use bilingual parallel corpora to generate paraphrases.
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).

Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ Bannard and Callison-Burch (2005) use bilingual parallel corpora to generate paraphrases.
Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ By grams, and 4-grams from the Europarl Spanish test sentences for which translations were learned in increasingly large training corpora increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation (Brown et al., 1993).
We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).

Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ Without it, the multi-word paraphrases harm translation performance when compared to the baseline.

Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ We examined the application of paraphrases to deal with unknown phrases when translating from Spanish and French into English.
Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ For these language pairs a huge portion of phrases encountered at run-time will be unknown.
Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ Limited amounts of training data can further lead to a problem of low coverage in that many phrases encountered at run-time are not observed in the training data and therefore their translations will not be learned.

Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ Specifically we show that upon encountering an unknown source phrase, we can substitute a paraphrase for it and then proceed using the translation of that paraphrase.
Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ By substituting a paraphrase for an unknown source phrase there is a strong chance that its translation may also be a paraphrase of the equivalent target language phrase.

to explain how difficult it is to translate the source-side sentence in three respects: The OOV rates of the source sentences in the test set (Callison-Burch et al, 2006). $$$$$ However, for any given test set, a huge amount of training data has to be observed before translations are learned for a reasonable percentage of the test phrases.
to explain how difficult it is to translate the source-side sentence in three respects: The OOV rates of the source sentences in the test set (Callison-Burch et al, 2006). $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ This method is particularly pertinent to small data conditions, which are plagued by sparse data problems.

Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ To set the weights, am, we performed minimum error rate training (Och, 2003) on the development set using Bleu (Papineni et al., 2002) as the objective function.
Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ Just as we did in the baseline system, we performed minimum error rate training to set the weights of the nine feature functions in our translation model that exploits paraphrases.

Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ We can extend the definition of the paraphrase probability to include multiple corpora, as follows: where c is a parallel corpus from a set of parallel corpora C. Thus multiple corpora may be used by summing over all paraphrase probabilities calculated from a single corpus (as in Equation 1) and normalized by the number of parallel corpora.
Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).

 $$$$$ We examined the application of paraphrases to deal with unknown phrases when translating from Spanish and French into English.
 $$$$$ Thank you to Alexandra Birch and Stephanie Vandamme for creating the word alignments.

For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ For a training corpus containing 10,000 words translations will have been learned for only 10% of the unigrams (types, not tokens).
For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ It is not until nearly 10,000,000 words worth of training data have been analyzed that translation for more than 90% of the vocabulary items have been learned.

The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ Bannard and Callison-Burch (2005) use bilingual parallel corpora to generate paraphrases.
The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).

This work is most closely related to that of Callison-Burch et al (2006), who also translate source-side paraphrases of the OOV phrases. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
This work is most closely related to that of Callison-Burch et al (2006), who also translate source-side paraphrases of the OOV phrases. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).
