We use an automatic topic segmentation tool, LCSeg (Galley et al, 2003) setting parameters so that the derived segments are of the approximate desired length. $$$$$ We use the error metric Pk proposed by Beeferman et al. (1999) to evaluate segmentation accuracy.
We use an automatic topic segmentation tool, LCSeg (Galley et al, 2003) setting parameters so that the derived segments are of the approximate desired length. $$$$$ LCseg depends on several parameters.

 $$$$$ For all chains that have been identified, we use a weighting scheme that we believe is appropriate to the task of inducing the topical or sub-topical structure of text.
 $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).

The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ This corpus is one of a growing number of corpora with human-to-human multi-party conversations.

We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ In the case of the Meeting corpus, none of the algorithms are significantly different than the others, due to the the table are the results of significance tests between U00 and LCseg.

For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ Embodiments of this idea include semantic similarity (Morris and Hirst, 1991; Kozima, 1993), cosine similarity in word vector space (Hearst, 1994), inter-sentence similarity matrix (Reynar, 1994; Choi, 2000), entity repetition (Kan et al., 1998), word frequency models (Reynar, 1999), or adaptive language models (Beeferman et al., 1999).
For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ Instead of using word counts to compute similarity, we analyze lexical chains that overlap with the two windows.

Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ We tried to restrict ourselves to features whose inclusion is motivated by previous work (pauses, speech rate) and added features that are specific to multi-speaker speech (overlap, changes in speaker activity).
Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ Speaker change: we sometimes noticed a correlation between topic boundaries and sudden changes in speaker activity.

Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ In work on segmentation of spoken documents, intonational, prosodic, and acoustic indicators are used to detect topic boundaries (Grosz and Hirschberg, 1992; Nakatani et al., 1995; Hirschberg and Nakatani, 1996; Passonneau and Litman, 1997; Hirschberg and Nakatani, 1998; Beeferman et al., 1999; T¨ur et al., 2001).
Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).

 $$$$$ For all chains that have been identified, we use a weighting scheme that we believe is appropriate to the task of inducing the topical or sub-topical structure of text.
 $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).

Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ In this paper, we present an algorithm for segmenting meeting transcripts.
Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).

For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ Lexical cohesion: we also incorporated the lexical cohesion function computed by LCseg as a feature of the multi-source segmenter in a manner similar to the knowledge source combination performed by (Beeferman et al., 1999) and (T¨ur et al., 2001).

 $$$$$ For all chains that have been identified, we use a weighting scheme that we believe is appropriate to the task of inducing the topical or sub-topical structure of text.
 $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).

Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ Lexical cohesion: we also incorporated the lexical cohesion function computed by LCseg as a feature of the multi-source segmenter in a manner similar to the knowledge source combination performed by (Beeferman et al., 1999) and (T¨ur et al., 2001).

However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ Embodiments of this idea include semantic similarity (Morris and Hirst, 1991; Kozima, 1993), cosine similarity in word vector space (Hearst, 1994), inter-sentence similarity matrix (Reynar, 1994; Choi, 2000), entity repetition (Kan et al., 1998), word frequency models (Reynar, 1999), or adaptive language models (Beeferman et al., 1999).
However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).

The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ We used Cochran’s Q (1950) to evaluate the agreement among annotators.

The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ Lexical cohesion: we also incorporated the lexical cohesion function computed by LCseg as a feature of the multi-source segmenter in a manner similar to the knowledge source combination performed by (Beeferman et al., 1999) and (T¨ur et al., 2001).

Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ Lexical cohesion: we also incorporated the lexical cohesion function computed by LCseg as a feature of the multi-source segmenter in a manner similar to the knowledge source combination performed by (Beeferman et al., 1999) and (T¨ur et al., 2001).

The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ A significant error reduction is obtained by combining the two knowledge sources.
The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).

The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ The meeting segmenter comprises two components: one that capitalizes on word distribution to identify homogeneous units that are topically cohesive, and a second component that analyzes conversational features of meeting transcripts that are indicative of topic shifts, like silences, overlaps, and speaker changes.
The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).

Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ We have evaluated our segmenter on the ICSI Meeting corpus (Janin et al., 2003).
Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ Lexical cohesion: we also incorporated the lexical cohesion function computed by LCseg as a feature of the multi-source segmenter in a manner similar to the knowledge source combination performed by (Beeferman et al., 1999) and (T¨ur et al., 2001).

 $$$$$ For all chains that have been identified, we use a weighting scheme that we believe is appropriate to the task of inducing the topical or sub-topical structure of text.
 $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).
