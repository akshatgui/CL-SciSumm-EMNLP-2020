In the news domain, the best reported results on the ACE dataset have been achieved by a composite kernel which depends partially on a full parse, and partially on a collection of shallow syntactic features (Zhou et al, 2007). $$$$$ It depends.
In the news domain, the best reported results on the ACE dataset have been achieved by a composite kernel which depends partially on a full parse, and partially on a collection of shallow syntactic features (Zhou et al, 2007). $$$$$ Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7

As shown in Zhou et al (2007), the context path from root to the phrase node is an effective context information feature. $$$$$ the tree kernel proposed in Culota and Sorensen (2004) which is context-sensitive, that is, it considers the path from the tree root node to the sub-tree root node.
As shown in Zhou et al (2007), the context path from root to the phrase node is an effective context information feature. $$$$$ becomes context-sensitive with its dependence on the root node path instead of the root node itself.

In this paper, we use the same settings in (Zhou et al, 2007), i.e., each phrase node is enriched with its context paths of length 1, 2, 3. $$$$$ D= m i NnNn ii C iiii nnTTK 1 ]2[]2[],1[]1[ 11 1111 ])2[],1[(])2[],1[( (3) Where ? ][1 jN i is the set of root node paths with length i in tree T[j] while the maximal length of a root node path is defined by m. ? ])[...(][ 211 jnnnjn ii = is a root node path with length i in tree T[j] , which takes into account the i-1 ancestral nodes in2 [j] of 1n [j] in T[j].
In this paper, we use the same settings in (Zhou et al, 2007), i.e., each phrase node is enriched with its context paths of length 1, 2, 3. $$$$$ Context-Sensitive Convolution Tree Kernel In this paper, the m parameter of our context-sensitive convolution tree kernel as shown in Equation (3) indicates the maximal length of root node paths and is optimized to 3 using 5-fold cross validation on the ACE RDC 2003 training data.

We compare our method with the standard convolution tree kernel (CTK) on the state-of-the-art context sensitive shortest path-enclosed tree representation (CSPT, Zhou et al, 2007). $$$$$ Zhang et al(2006) systematically explored seven different tree spans, including the Shortest Path-enclosed Tree (SPT) and a Context Sensitive Path-enclosed Tree1 (CSPT), and found that SPT per formed best.
We compare our method with the standard convolution tree kernel (CTK) on the state-of-the-art context sensitive shortest path-enclosed tree representation (CSPT, Zhou et al, 2007). $$$$$ 3.2 Context-Sensitive Convolution Tree Kernel.

 $$$$$ In the embedded cases, SPT is enough.
 $$$$$ We would also like to thank the critical and insightful comments from the four anonymous reviewers.

To resolve this problem, Zhou et al (2007) took the ancestral information of sub-trees into consideration. $$$$$ However, there is one problem with this tree kernel

 $$$$$ In the embedded cases, SPT is enough.
 $$$$$ We would also like to thank the critical and insightful comments from the four anonymous reviewers.

Later, Zhang et al (2006) developed a composite kernel that combined parse tree kernel with entity kernel and Zhou et al (2007) experimented with a context-sensitive kernel by automatically determining context-sensitive tree spans. $$$$$ 3.2 Context-Sensitive Convolution Tree Kernel.
Later, Zhang et al (2006) developed a composite kernel that combined parse tree kernel with entity kernel and Zhou et al (2007) experimented with a context-sensitive kernel by automatically determining context-sensitive tree spans. $$$$$ Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7

Zhou et al (2007) use a context sensitive kernel in conjunction with features they used in their earlier publication (GuoDong et al., 2005). $$$$$ Zhang et al(2006) also showed that the widely-used Shortest Path-enclosed Tree (SPT) performed best.
Zhou et al (2007) use a context sensitive kernel in conjunction with features they used in their earlier publication (GuoDong et al., 2005). $$$$$ Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7

To the best of our knowledge, the most recent result was reported by (Zhou and Zhu, 2011), who extended their previous work in (Zhou et al, 2007). $$$$$ Culotta and Sorensen (2004) extended this work to estimate simi larity between augmented dependency trees and achieved the F-measure of 45.8 on the 5 relation types in the ACE RDC 2003 corpus.
To the best of our knowledge, the most recent result was reported by (Zhou and Zhu, 2011), who extended their previous work in (Zhou et al, 2007). $$$$$ As a result, our tree kernel is not limited by the constraints in previous tree kernels (as discussed in Section 2), such as Collins and Duffy (2001), Zhang et al(2006), Culotta and Sorensen (2004) and Bunescu and Mooney (2005a).

 $$$$$ In the embedded cases, SPT is enough.
 $$$$$ We would also like to thank the critical and insightful comments from the four anonymous reviewers.

Zhou et al (2007) tested their system on the ACE 2004 data. $$$$$ Since then, many methods, such as feature-based (Kambhatla 2004; Zhou et al2005, 2006), tree ker nel-based (Zelenko et al2003; Culotta and Sorensen 2004; Bunescu and Mooney 2005a; Zhang et al2006) and composite kernel-based (Zhao and Gris hman 2005; Zhang et al2006), have been proposed in lit erature.
Zhou et al (2007) tested their system on the ACE 2004 data. $$$$$ System P(%) R(%) F Linear Kernel 78.2 (77.2) 63.4 (60.7) 70.1 (68.0) Context-Sensitive Con volution Tree Kernel 81.1 (80.1) 66.7 (63.8) 73.2 (71.0) Composite Kernel 82.2 (80.8) 70.2 (68.4) 75.8 (74.1) Table 3

Zhou et al (2007) proposed the so called context sensitive tree kernel approach based on PST, which expands PET to include necessary contextual in formation. $$$$$ First, we systematically evaluate the context-sensitive convolution tree kernel and the dynamic context sensitive tree span proposed in this paper.
Zhou et al (2007) proposed the so called context sensitive tree kernel approach based on PST, which expands PET to include necessary contextual in formation. $$$$$ Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7

Zhou et al (2007) further extend it to Context-Sensitive Shortest Path-enclosed Tree (CS SPT), which dynamically includes necessary predicate-linked path information. $$$$$ It first automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.
Zhou et al (2007) further extend it to Context-Sensitive Shortest Path-enclosed Tree (CS SPT), which dynamically includes necessary predicate-linked path information. $$$$$ Zhang et al(2006) systematically explored seven different tree spans, including the Shortest Path-enclosed Tree (SPT) and a Context Sensitive Path-enclosed Tree1 (CSPT), and found that SPT per formed best.

Zhou et al (2007) point out that both SPT and the convolution tree kernel are context-free. $$$$$ 3.2 Context-Sensitive Convolution Tree Kernel.
Zhou et al (2007) point out that both SPT and the convolution tree kernel are context-free. $$$$$ Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7

Zhou et al (2007) describe a composite kernel to integrate a context-sensitive CTK and a state-of-the-art linear kernel. $$$$$ Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7

Zhou et al (2007) further propose Context-Sensitive SPT (CS-SPT), which can dynamically determine the tree span by extending the necessary predicate-linked path information outside SPT. $$$$$ First, it automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the widely-used Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.
Zhou et al (2007) further propose Context-Sensitive SPT (CS-SPT), which can dynamically determine the tree span by extending the necessary predicate-linked path information outside SPT. $$$$$ It first automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.

(2) CS-SPT only captures part of context sensitive information relating to predicate-linked structure (Zhou et al, 2007) and still loses much context-sensitive information. $$$$$ 3.2 Context-Sensitive Convolution Tree Kernel.
(2) CS-SPT only captures part of context sensitive information relating to predicate-linked structure (Zhou et al, 2007) and still loses much context-sensitive information. $$$$$ information.

In fact, SPT (Zhang et al, 2006) can be arrived at by carrying out part of the above removal operations using a single rule (i.e. all the constituents outside the linking path should be removed) and CS-CSPT (Zhou et al, 2007) further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT. $$$$$ It first automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.
In fact, SPT (Zhang et al, 2006) can be arrived at by carrying out part of the above removal operations using a single rule (i.e. all the constituents outside the linking path should be removed) and CS-CSPT (Zhou et al, 2007) further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT. $$$$$ That is, SPT even outperforms CSPT.

Furthermore, when the UPST (FPT) kernel is combined with a linear state-of-the-state feature based kernel (Zhou et al, 2005) into a composite one via polynomial interpolation in a setting similar to Zhou et al (2007) (i.e. polynomial degree d=2 and coefficient? =0.3), we get the so far best performance of 77.1 in F-measure for 7relation types on the ACE RDC 2004 data set. $$$$$ As the state-of-the-art, Zhang et al(2006) applied the convo lution tree kernel (Collins and Duffy 2001) and achieved comparable performance with a state-of-the art linear kernel (Zhou et al2005) on the 5 relation types in the ACE RDC 2003 corpus.
Furthermore, when the UPST (FPT) kernel is combined with a linear state-of-the-state feature based kernel (Zhou et al, 2005) into a composite one via polynomial interpolation in a setting similar to Zhou et al (2007) (i.e. polynomial degree d=2 and coefficient? =0.3), we get the so far best performance of 77.1 in F-measure for 7relation types on the ACE RDC 2004 data set. $$$$$ Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7
