Treebank texts contain complete structural parsers, POS tags, and annotation of the antecedents of definite pronouns (added by Ge et al 1998). $$$$$ We see a significant improvement after the word knowledge is added to the program.
Treebank texts contain complete structural parsers, POS tags, and annotation of the antecedents of definite pronouns (added by Ge et al 1998). $$$$$ In fact, the only part-of-speech tags necessary are those indicating nouns and pronouns.

Ge et al (1998) implement a Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbs's (1978) seminal syntax-based pronoun resolution algorithm. $$$$$ The first piece of useful information we consider is the distance between the pronoun and the candidate antecedent.
Ge et al (1998) implement a Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbs's (1978) seminal syntax-based pronoun resolution algorithm. $$$$$ For any pronoun we collect n(= 15 in the experiment) candidate antecedents proposed by Hobbs' algorithm.

Ge et al [1998] also present a statistical algorithm based on the study of statistical data in a large corpus and the application of a naive Bayes model. $$$$$ We present a statistical method for determining pronoun anaphora.
Ge et al [1998] also present a statistical algorithm based on the study of statistical data in a large corpus and the application of a naive Bayes model. $$$$$ Equation (1) is simply an application of Bayes' rule.

Ge et al (1998) uses a non-parametrized statistical model to find the antecedent from a list of candidates generated by applying the Hobbs algorithm to the English Penn Treebank. $$$$$ Once we have the trees in the proper form (to the degree this is possible) we run Hobbs' algorithm repeatedly for each pronoun until it has proposed n (= 15 in our experiment) candidates.
Ge et al (1998) uses a non-parametrized statistical model to find the antecedent from a list of candidates generated by applying the Hobbs algorithm to the English Penn Treebank. $$$$$ Lappin and Leass (1994) report on a (essentially non-statistical) approach that relies on salience measures derived from syntactic structure and a dynamic model of attentional state.

Compared with these work, our work uses machine-generated parse trees from which trainable features are extracted in a maximum-entropy coreference system, while (Ge et al, 1998) assumes that correct parse trees are given. $$$$$ We have implemented a slightly modified version of Hobbs algorithm for the Tree-bank parse trees.
Compared with these work, our work uses machine-generated parse trees from which trainable features are extracted in a maximum-entropy coreference system, while (Ge et al, 1998) assumes that correct parse trees are given. $$$$$ Due to relatively large differences between Tree-bank parse trees and Hobbs' trees, our Hobbs' implementation does not yield as high an accuracy as it would have if we had had perfect Hobbs' tree representations.

In other cases, these modules are integrated by means of statistical (Ge et al, 1998) or uncertainty reasoning techniques (Mitkov, 1997). $$$$$ (Mitkov (1997) does a detailed study on factors in anaphora resolution.)
In other cases, these modules are integrated by means of statistical (Ge et al, 1998) or uncertainty reasoning techniques (Mitkov, 1997). $$$$$ The algorithm has two modules.

(Ge et al 1998) incorporate gender, number, and animaticity information into a statistical model for anaphora resolution by gathering coreference statistics on particular nominal-pronoun pairs. $$$$$ A Statistical Approach To Anaphora Resolution
(Ge et al 1998) incorporate gender, number, and animaticity information into a statistical model for anaphora resolution by gathering coreference statistics on particular nominal-pronoun pairs. $$$$$ We incorporate multiple anaphora resolution factors into a statistical framework â€” specifically the distance between the pronoun and the proposed antecedent, gender/number/animaticity of the proposed antecedent, governing head information and noun phrase repetition.

Thus the size of the annotated data (3,115 personal pronouns, 2,198 possessive pronouns, 928 demonstrative pronouns) compares favourably with the size of evaluation data in other proposals (619 German pronouns in (Strube and Hahn, 1999), 2,477 English pronouns in (Ge et al, 1998), about 5,400 English coreferential expressions in (Ng and Cardie, 2002)). $$$$$ On the intuition pronouns closely follow their referents, this heuristic simply keeps track of the last noun seen and submits that noun as the referent of any pronouns following.
Thus the size of the annotated data (3,115 personal pronouns, 2,198 possessive pronouns, 928 demonstrative pronouns) compares favourably with the size of evaluation data in other proposals (619 German pronouns in (Strube and Hahn, 1999), 2,477 English pronouns in (Ge et al, 1998), about 5,400 English coreferential expressions in (Ng and Cardie, 2002)). $$$$$ By collating by referent and abstracting away to the gender classes of pronouns, rather than individual pronouns, we have the relative frequencies with which a given referent is referred to by pronouns of each gender class.

Exceptions are existant but few (2.5%) $$$$$ Generally, a singular pronoun cannot refer to a plural noun phrase. so that in resolving such a pronoun any plural candidates should be ruled out.
Exceptions are existant but few (2.5%) $$$$$ By collating by referent and abstracting away to the gender classes of pronouns, rather than individual pronouns, we have the relative frequencies with which a given referent is referred to by pronouns of each gender class.

Ge et al (1998) try to factorize the same principle by counting the number of times a discourse entities has been mentioned in the discourse already. $$$$$ The training corpus is marked with the number of times a referent has been mentioned up to that point in the story.
Ge et al (1998) try to factorize the same principle by counting the number of times a discourse entities has been mentioned in the discourse already. $$$$$ References by pronouns are closely related to the topic or the center of the discourse.

Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ This program differs from earlier work in its almost complete lack of hand-crafting, relying instead on a very small corpus of Penn Wall Street Journal Tree-bank text (Marcus et al., 1993) that has been marked with co-reference information.
Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ Nor do we use the gender/animiticity information gathered from the much smaller hand-marked text, both because we were interested in seeing what unsupervised learning could accomplish, and because we were concerned with inheriting strong biases from the limited hand-marked data.

 $$$$$ Selectively applying the chain rule results in equations (3) and (4).
 $$$$$ The authors would like to thank Mark Johnson and other members of the Brown NLP group for many useful ideas and NSF and ONR for support (NSF grants IRI-9319516 and SBR9720368, ONR grant N0014-96-1-0549).

Ge et al (1998)'s probabilistic approach combines three factors (aside from the agreement filter) $$$$$ We also observe that the position of a pronoun in a story influences the mention count of its referent.
Ge et al (1998)'s probabilistic approach combines three factors (aside from the agreement filter) $$$$$ We measure position by the sentence number, j.

The choice of entities may reasonably be considered to be independent given the mixing weights, but how we realize an entity is strongly dependent on context (Ge et al, 1998). $$$$$ When viewed in this way, a can be regarded as an index into these vectors that specifies which value is relevant to the particular choice of antecedent.
The choice of entities may reasonably be considered to be independent given the mixing weights, but how we realize an entity is strongly dependent on context (Ge et al, 1998). $$$$$ The more frequently an entity is repeated, the more likely it is to be the topic of the story and thus to be a candidate for pronominalization.

Ge et al (1998) exploit a similar idea to assign gender to proper mentions. $$$$$ The idea is similar to that used in the centering approach (Brennan et al., 1987) where a continued topic is the highest-ranked candidate for pronominalization.
Ge et al (1998) exploit a similar idea to assign gender to proper mentions. $$$$$ The mention information gives the system some idea of the story's focus.

Implementation of constraints and preferences can be based on empirical insight (Lappin and Leass, 1994), or machine learning from a reference annotated corpus (Ge et al, 1998). $$$$$ Mitkov (1997) describes an approach that uses a set of factors as constraints and preferences.
Implementation of constraints and preferences can be based on empirical insight (Lappin and Leass, 1994), or machine learning from a reference annotated corpus (Ge et al, 1998). $$$$$ Lappin and Leass (1994) report on a (essentially non-statistical) approach that relies on salience measures derived from syntactic structure and a dynamic model of attentional state.

There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (Ge et al, 1998), or contextual role-knowledge (Bean and Riloff, 2004). $$$$$ A Statistical Approach To Anaphora Resolution
There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (Ge et al, 1998), or contextual role-knowledge (Bean and Riloff, 2004). $$$$$ This indicates that syntax does play a very important role in anaphora resolution.

Incorporating context only through the governing constituent was also done in (Ge et al, 1998). $$$$$ To this end, we ran the program &quot;incrementally&quot;, each time incorporating one more probability.
Incorporating context only through the governing constituent was also done in (Ge et al, 1998). $$$$$ We hoped that the knowledge about the governing constituent would, like gender and animaticity, make a large contribution.

Ge et al (1998) describe a supervised probabilistic pronoun resolution algorithm which is based on complete syntactic information. $$$$$ This paper presents an algorithm for identifying pronominal anaphora and two experiments based upon this algorithm.
Ge et al (1998) describe a supervised probabilistic pronoun resolution algorithm which is based on complete syntactic information. $$$$$ There are many factors, both syntactic and semantic, upon which a pronoun resolution system relies.

Their factors are taken from Ge et al (1998), with two exceptions. $$$$$ There are many factors, both syntactic and semantic, upon which a pronoun resolution system relies.
Their factors are taken from Ge et al (1998), with two exceptions. $$$$$ We are also interested in finding the relative importance of each probability (i.e. each of the four factors in equation (8) in pronoun resolution.
