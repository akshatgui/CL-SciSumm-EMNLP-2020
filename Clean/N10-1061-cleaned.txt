These abstract notions (lexical association, proximity, tendencies towards few or many relations, and allowing for unassociated items) play an important role in many relation-detection tasks (e.g., co-reference resolution, Haghighi and Klein 2010). $$$$$ In this work, we take a primarily unsupervised approach to coreference resolution, broadly similar to Haghighi and Klein (2007), which addresses this issue.
These abstract notions (lexical association, proximity, tendencies towards few or many relations, and allowing for unassociated items) play an important role in many relation-detection tasks (e.g., co-reference resolution, Haghighi and Klein 2010). $$$$$ We also compared to the strong deterministic system of Haghighi and Klein (2009).10 Across all data sets, our model, despite being largely unsupervised, consistently outperforms these systems, which are the best previously reported results on end-to-end coreference resolution (i.e. including mention detection).

Many other existing systems applied supervised or unsupervised (Haghighi and Klein, 2010) learning models. $$$$$ In general, coreference errors in state-of-theart systems are frequently due to poor models of semantic compatibility (Haghighi and Klein, 2009).
Many other existing systems applied supervised or unsupervised (Haghighi and Klein, 2010) learning models. $$$$$ We compared to two state-of-the-art supervised coreference systems.

However, such structured knowledge bases are of limited scope, and, while Haghighi and Klein (2010) self-acquires knowledge about coreference, it does so only via reference constructions and on a limited scale. $$$$$ However, to our knowledge, this is the first work to incorporate such a model into an entity reference process.
However, such structured knowledge bases are of limited scope, and, while Haghighi and Klein (2010) self-acquires knowledge about coreference, it does so only via reference constructions and on a limited scale. $$$$$ Because only certain semantic types were annotated under the arbitrary ACE guidelines, there are many mentions which do not fall into those limited categories.

Altogether, our final system produces the best numbers reported to date on end-to-end coreference resolution (with automatically detected system mentions) on multiple data sets (ACE 2004 and ACE2005) and metrics (MUC and B3), achieving significant improvements over the Reconcile DT baseline and over the state-of-the-art results of Haghighi and Klein (2010). $$$$$ Despite being almost entirely unsupervised, our model yields the best reported end-to-end results on a range of standard coreference data sets.
Altogether, our final system produces the best numbers reported to date on end-to-end coreference resolution (with automatically detected system mentions) on multiple data sets (ACE 2004 and ACE2005) and metrics (MUC and B3), achieving significant improvements over the Reconcile DT baseline and over the state-of-the-art results of Haghighi and Klein (2010). $$$$$ We also compared to the strong deterministic system of Haghighi and Klein (2009).10 Across all data sets, our model, despite being largely unsupervised, consistently outperforms these systems, which are the best previously reported results on end-to-end coreference resolution (i.e. including mention detection).

In ACE04 and ACE05, we have only the newswire portion (of the original ACE 2004 and 2005 training sets) and use the standard train/test splits reported in Stoyanov et al (2009) and Haghighi and Klein (2010). $$$$$ For evaluation, we used standard coreference data sets derived from the ACE corpora

In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ As an example of nominal headword compatibility, a “president” can be a “leader” but cannot be not an “increase.” Past systems have often computed the compatibility of specific headword pairs, extracted either from lexical resources (Ng, 2007; Bengston and Roth, 2008; Rahman and Ng, 2009), web statistics (Yang et al., 2005), or surface syntactic patterns (Haghighi and Klein, 2009).
In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ The Stoyanov et al. (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahman and Ng (2009) numbers represent their highestperforming cluster ranking model.

 $$$$$ Each entity E is generated independently and consists of a type indicator T, as well as a collection {Lr}rE7Z of word lists for each property.
 $$$$$ 11See nlp.cs.berkeley.edu and aria42.com/software.html for software release.

Our main comparison is against Haghighi and Klein (2010), a mostly-unsupervised generative approach that models latent entity types, which generate specific entities that in turn render individual mentions. $$$$$ Our semantic representation first hypothesizes an underlying set of latent which generate specific entities that in turn render individual mentions.
Our main comparison is against Haghighi and Klein (2010), a mostly-unsupervised generative approach that models latent entity types, which generate specific entities that in turn render individual mentions. $$$$$ Entities

For the ACE05 and ACE05-ALL datasets, we revert to the 'AllPairs' (AP) setting of Reconcile because this gives us baselines competitive with Haghighi and Klein (2010). $$$$$ We also trained on the following much larger unlabeled datasets utilized in Haghighi and Klein (2009)

Our submission was a reduced version of the system described in Haghighi and Klein (2010), with extensions to improve mention detection to suit the OntoNotes annotation scheme. $$$$$ Formally, this process is described as

Unlike previous work, we did not use the Bllip or Wikipedia data described in Haghighi and Klein (2010). $$$$$ We utilized no coreference annotation during training, but did use minimal prototype information to prime the learning of entity types (Section 5.3).
Unlike previous work, we did not use the Bllip or Wikipedia data described in Haghighi and Klein (2010). $$$$$ Rather than relying on fully supervised data, we took the approach of Haghighi and Klein (2006).

The specific update methods vary for each set of parameters; for details see Section 4 of Haghighi and Klein (2010). $$$$$ For example, the ri factor update takes the standard mean field form

Unlike Haghighi and Klein (2010), no extra data from Wikipedia or Bllip was used, a restriction that was necessary to be eligible for the closed part of the task. $$$$$ For evaluation, we used standard coreference data sets derived from the ACE corpora

Generative models are also used in unsupervised coreference (Haghighi and Klein, 2010). $$$$$ In general, coreference errors in state-of-theart systems are frequently due to poor models of semantic compatibility (Haghighi and Klein, 2009).
Generative models are also used in unsupervised coreference (Haghighi and Klein, 2010). $$$$$ We now describe our generative model.

While early approaches focused on surface-level methods such as wrapper induction (Kushmerick et al, 1997), more recent work in this area includes Bayesian nonparametrics to select the number of rows in the database (Haghighi and Klein, 2010a). $$$$$ For nominal and pronoun mentions, there are several well-studied anaphora cues, including centering (Grosz et al., 1995), nearness (Hobbs, 1978), and deterministic constraints, which have all been utilized in prior coreference work (Soon et al., 1999; Ng and Cardie, 2002).
While early approaches focused on surface-level methods such as wrapper induction (Kushmerick et al, 1997), more recent work in this area includes Bayesian nonparametrics to select the number of rows in the database (Haghighi and Klein, 2010a). $$$$$ We utilized MUC (Vilain et al., 1995), B3All (Stoyanov et al., 2009), B3None (Stoyanov et al., 2009), and Pairwise F1.

The best coreference systems depend on carefully crafted, problem-specific linguistic features (Bengtson and Roth, 2008) and external knowledge (Haghighi and Klein, 2010b). $$$$$ As an example of nominal headword compatibility, a “president” can be a “leader” but cannot be not an “increase.” Past systems have often computed the compatibility of specific headword pairs, extracted either from lexical resources (Ng, 2007; Bengston and Roth, 2008; Rahman and Ng, 2009), web statistics (Yang et al., 2005), or surface syntactic patterns (Haghighi and Klein, 2009).
The best coreference systems depend on carefully crafted, problem-specific linguistic features (Bengtson and Roth, 2008) and external knowledge (Haghighi and Klein, 2010b). $$$$$ Most linguistic inquiry characterizes NP anaphora by the pairwise relations that hold between a mention and its antecedent (Hobbs, 1979; Kehler et al., 2008).

This knowledge could be especially helpful for cross document coreference resolution systems (Haghighi and Klein, 2010), which actually represent concepts and track mentions of them across documents. $$$$$ Coreference Resolution in a Modular Entity-Centered Model
This knowledge could be especially helpful for cross document coreference resolution systems (Haghighi and Klein, 2010), which actually represent concepts and track mentions of them across documents. $$$$$ In this work, we take a primarily unsupervised approach to coreference resolution, broadly similar to Haghighi and Klein (2007), which addresses this issue.

 $$$$$ Each entity E is generated independently and consists of a type indicator T, as well as a collection {Lr}rE7Z of word lists for each property.
 $$$$$ 11See nlp.cs.berkeley.edu and aria42.com/software.html for software release.

For instance, Haghighi and Klein (2010) include the governor of the head of nominal mentions as features in their model. $$$$$ We will often describe proper and nominal mentions together as referring mentions.
For instance, Haghighi and Klein (2010) include the governor of the head of nominal mentions as features in their model. $$$$$ We set αr to 1 for pronoun heads as well as for the governor of the head properties.

Daume III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. $$$$$ We now describe our generative model.
Daume III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. $$$$$ Rather than relying on fully supervised data, we took the approach of Haghighi and Klein (2006).
