We use the model of Liang et al (2009) to automatically induce the correspondences between words in the text and the actual database records mentioned. $$$$$ For example, in the NFL domain, 70% of scoring records are mentioned whereas only 1% of punting records are mentioned.
We use the model of Liang et al (2009) to automatically induce the correspondences between words in the text and the actual database records mentioned. $$$$$ We have presented a generative model of correspondences between a world state and an unsegmented stream of text.

We achieved a BLEU score of 51.5 on the combined task of content selection and generation, which is more than a two-fold improvement over a model similar to that of Liang et al (2009). $$$$$ The segmentation aspect of our model is similar to that of Grenager et al. (2005) and Eisenstein and Barzilay (2008), but in those two models, the segments are clustered into topics rather than grounded to a world state.
We achieved a BLEU score of 51.5 on the combined task of content selection and generation, which is more than a two-fold improvement over a model similar to that of Liang et al (2009). $$$$$ Model 2’ achieved an F1 of 39.9, an improvement over Model 1, which attained 32.8.

We used the dataset created by Liang et al (2009). $$$$$ The second domain is weather forecasts, for which we created a new dataset.
We used the dataset created by Liang et al (2009). $$$$$ We used the dataset created by Chen and Mooney (2008), which contains 1919 scenarios from the 2001–2004 Robocup finals.

By defining features on the entire field set, we can capture any correlation structure over the fields; in contrast, Liang et al (2009) generates a sequence of fields in which a field can only depend on the previous one. $$$$$ The field type determines the way we expect the field value to be rendered in words

In particular, a word is chosen from the parameters learned in the model of Liang et al (2009). $$$$$ Table 2 shows the top words for each of these field values learned by our model.
In particular, a word is chosen from the parameters learned in the model of Liang et al (2009). $$$$$ Many of the remaining errors are due to the garbage collection phenomenon familiar from word alignment models (Moore, 2004; Liang et al., 2006).

We use the model of Liang et al (2009) to impute the decisions. $$$$$ We use the term scenario to refer to such a (w, s) pair.
We use the model of Liang et al (2009) to impute the decisions. $$$$$ Model 1 easily mistakes pink10 for the recipient of a pass record because decisions are made independently for each word.

We found that using the unsupervised model of Liang et al (2009) to automatically produce aligned training scenarios (Section 4.3.1) was less effective than it was in the other two domains due to two factors $$$$$ Furthermore, in some of our examples, much of the world state is not referenced at all in the text, and, conversely, the text references things which are not represented in our world state.
We found that using the unsupervised model of Liang et al (2009) to automatically produce aligned training scenarios (Section 4.3.1) was less effective than it was in the other two domains due to two factors $$$$$ Unless otherwise specified, performance is reported on all scenarios, which were also used for training.

Liang et al (2009) introduces a generative model of the text given the world state, and in some ways is similar in spirit to our model. $$$$$ The segmentation aspect of our model is similar to that of Grenager et al. (2005) and Eisenstein and Barzilay (2008), but in those two models, the segments are clustered into topics rather than grounded to a world state.
Liang et al (2009) introduces a generative model of the text given the world state, and in some ways is similar in spirit to our model. $$$$$ We have presented a generative model of correspondences between a world state and an unsegmented stream of text.

On the other hand, Liang et al (2009) introduced a probabilistic generative model for learning semantic correspondences in ambiguous training data consisting of sentences paired with observed world states. $$$$$ Learning Semantic Correspondences with Less Supervision
On the other hand, Liang et al (2009) introduced a probabilistic generative model for learning semantic correspondences in ambiguous training data consisting of sentences paired with observed world states. $$$$$ A more flexible direction is grounded language acquisition

On the other hand, Liang et al (2009) proposed a probabilistic generative approach to produce a Viterbi alignment between NL and MRs. They use a hierarchical semi-Markov generative model that first determines which facts to discuss and then generates words from the predicates and arguments of the chosen facts. $$$$$ In this less restricted data setting, we must resolve multiple ambiguities

Chen et al (2010) recently reported results on utilizing the improved alignment produced by Liang et al (2009)'s model to initialize their own iterative retraining method. $$$$$ We also compare our model to the results of Chen and Mooney (2008) in Table 4.
Chen et al (2010) recently reported results on utilizing the improved alignment produced by Liang et al (2009)'s model to initialize their own iterative retraining method. $$$$$ Many of the remaining errors are due to the garbage collection phenomenon familiar from word alignment models (Moore, 2004; Liang et al., 2006).

Motivated by this prior research, our approach combines the generative alignment model of Liang et al (2009) with the generative semantic parsing model of Lu et al (2008) in order to fully exploit the NL syntax and its relationship to the MR semantics. $$$$$ Our model combines segmentation with alignment.
Motivated by this prior research, our approach combines the generative alignment model of Liang et al (2009) with the generative semantic parsing model of Lu et al (2008) in order to fully exploit the NL syntax and its relationship to the MR semantics. $$$$$ DeNero et al. (2008) perform joint segmentation and word alignment for machine translation, but the nature of that task is different from ours.

 $$$$$ Fortunately, most of the fields are integer fields or string fields (generally names or brief descriptions), which provide important anchor points for learning the correspondences.
 $$$$$ By having a joint model of salience, coherence, and segmentation, as well as a detailed rendering of the values in the world state into words in the text, we are able to cope with the increased ambiguity that arises in this new data setting, successfully pushing the limits of unsupervision.


The natural language generation model covers the roles of both the field choice model and word choice models of Liang et al (2009). $$$$$ Each record type t E T has a separate field choice model, which specifies a distribution over a sequence of fields.
The natural language generation model covers the roles of both the field choice model and word choice models of Liang et al (2009). $$$$$ Conditioned on the fields f, the words w are generated independently

We also tried using a Markov model to order arguments like Liang et al (2009), but preliminary experimental results showed that this additional component actually decreased performance rather than improving it. $$$$$ The parameters of this hierarchical hidden semi-Markov model can be estimated efficiently using EM.
We also tried using a Markov model to order arguments like Liang et al (2009), but preliminary experimental results showed that this additional component actually decreased performance rather than improving it. $$$$$ Table 6 shows our results.

 $$$$$ Fortunately, most of the fields are integer fields or string fields (generally names or brief descriptions), which provide important anchor points for learning the correspondences.
 $$$$$ By having a joint model of salience, coherence, and segmentation, as well as a detailed rendering of the values in the world state into words in the text, we are able to cope with the increased ambiguity that arises in this new data setting, successfully pushing the limits of unsupervision.

In particular, our proposed model outperforms the generative alignment model of Liang et al (2009), indicating that the extra linguistic information and MR grammatical structure used by Lu et al (2008)'s generative language model make our overall model more effective than a simple Markov+ bag-of-words model for language generation. $$$$$ Furthermore, the complexity of the language used in the recap is far greater than what we can represent using our simple model.
In particular, our proposed model outperforms the generative alignment model of Liang et al (2009), indicating that the extra linguistic information and MR grammatical structure used by Lu et al (2008)'s generative language model make our overall model more effective than a simple Markov+ bag-of-words model for language generation. $$$$$ We did not experiment with Model 3 since the discourse structure on records in this domain is not at all governed by a simple Markov model on record types—indeed, most regions do not refer to any records at all.

Compared to Liang et al (2009), our more accurate (i.e. higher F-measure) matchings provide a clear improvement in both semantic parsing and tactical generation. $$$$$ Learning Semantic Correspondences with Less Supervision
Compared to Liang et al (2009), our more accurate (i.e. higher F-measure) matchings provide a clear improvement in both semantic parsing and tactical generation. $$$$$ Model 2’ achieved an F1 of 39.9, an improvement over Model 1, which attained 32.8.

In particular, we showed that our alignments provide a better foundation for learning accurate semantic parsers and tactical generators compared to those of Liang et al (2009), whose generative model is limited by a simple bag-of-words assumption. $$$$$ Learning Semantic Correspondences with Less Supervision
In particular, we showed that our alignments provide a better foundation for learning accurate semantic parsers and tactical generators compared to those of Liang et al (2009), whose generative model is limited by a simple bag-of-words assumption. $$$$$ We arrive at the final component of our model, which governs how the information about a particular field of a record is rendered into words.
