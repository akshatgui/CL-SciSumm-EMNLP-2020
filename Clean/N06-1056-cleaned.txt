We compared our system's performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser. $$$$$ In this paper, we present a novel statistical approach to semantic parsing which can handle MRs with a nested structure, based on previous work on semantic parsing using transformation rules (Kate et al., 2005).
We compared our system's performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser. $$$$$ Figure 6 shows the performance of WASP compared to four other algorithms: SILT (Kate et al., 2005), COCKTAIL (Tang and Mooney, 2001), SCISSOR (Ge and Mooney, 2005) and Zettlemoyer and Collins (2005).

We use a maximum-entropy model similar to that of Zettlemoyer and Collins (2005) and Wong and Mooney (2006). $$$$$ A similar feature set is used by Zettlemoyer and Collins (2005).
We use a maximum-entropy model similar to that of Zettlemoyer and Collins (2005) and Wong and Mooney (2006). $$$$$ Figure 6 shows the performance of WASP compared to four other algorithms: SILT (Kate et al., 2005), COCKTAIL (Tang and Mooney, 2001), SCISSOR (Ge and Mooney, 2005) and Zettlemoyer and Collins (2005).

Following Wong and Mooney (2006), only candidate predicates and composition rules that are used in the best semantic derivations for the training set are retained for testing. $$$$$ Following Zettlemoyer and Collins (2005), only rules that are used in the best parses for the training set are retained in the final lexicon.
Following Wong and Mooney (2006), only candidate predicates and composition rules that are used in the best semantic derivations for the training set are retained for testing. $$$$$ A semantic parser was learned from the training set.

WASP (Wong and Mooney, 2006) is a system motivated by statistical machine translation techniques. $$$$$ Learning For Semantic Parsing With Statistical Machine Translation
WASP (Wong and Mooney, 2006) is a system motivated by statistical machine translation techniques. $$$$$ Statistical machine translation by parsing.

To make our system directly comparable to previous systems, all our experiments were based on identical training and test data splits of both corpora as reported in the experiments of Wong and Mooney (2006). $$$$$ The number of features is quite modest (less than 3,000 in our experiments).
To make our system directly comparable to previous systems, all our experiments were based on identical training and test data splits of both corpora as reported in the experiments of Wong and Mooney (2006). $$$$$ Standard 10-fold cross validation was used in our experiments.

Executable system actions include access to databases such as the GEOQUERY database on U.S. geography (Wong and Mooney (2006), inter alia), the ATIS travel planning database (Zettlemoyer and Collins (2009), inter alia), robotic control in simulated navigation tasks (Chen and Mooney (2011), interalia), databases of simulated card games (Goldwasser and Roth (2013), interalia), or the user-generated contents of FREEBASE (Cai and Yates (2013), inter alia). $$$$$ The second domain is GEOQUERY, where a functional, variable-free query language is used for querying a small database on U.S. geography (Zelle and Mooney, 1996; Kate et al., 2005).
Executable system actions include access to databases such as the GEOQUERY database on U.S. geography (Wong and Mooney (2006), inter alia), the ATIS travel planning database (Zettlemoyer and Collins (2009), inter alia), robotic control in simulated navigation tasks (Chen and Mooney (2011), interalia), databases of simulated card games (Goldwasser and Roth (2013), interalia), or the user-generated contents of FREEBASE (Cai and Yates (2013), inter alia). $$$$$ A similar feature set is used by Zettlemoyer and Collins (2005).

 $$$$$ The right-hand side (RHS) of an SCFG rule is a pair of strings, (α, Q), where the non-terminals in 0 are a permutation of the non-terminals in α.
 $$$$$ This research was supported by Defense Advanced Research Projects Agency under grant HR0011-041-0007.

In our previous work (Wong and Mooney, 2006), semantic parsing is cast as a machine translation task, where an SCFG is used to model the translation of an NL into a formal meaning-representation language (MRL). $$$$$ Our work shows that ideas from compiler theory (SCFG) and machine translation (word alignment models) can be successfully applied to semantic parsing, a closelyrelated task whose goal is to translate a natural language into a formal language.
In our previous work (Wong and Mooney, 2006), semantic parsing is cast as a machine translation task, where an SCFG is used to model the translation of an NL into a formal meaning-representation language (MRL). $$$$$ Statistical machine translation by parsing.

For some domains, this problem can be avoided by transforming a logical language into a variable-free, functional language (e.g. the GEOQUERY functional query language in Wong and Mooney (2006)). $$$$$ The second domain is GEOQUERY, where a functional, variable-free query language is used for querying a small database on U.S. geography (Zelle and Mooney, 1996; Kate et al., 2005).
For some domains, this problem can be avoided by transforming a logical language into a variable-free, functional language (e.g. the GEOQUERY functional query language in Wong and Mooney (2006)). $$$$$ To build a corpus for GEOQUERY, 880 English questions were gathered from various sources, which were manually translated into the functional GEOQUERY language (Tang and Mooney, 2001).

Our work is based on the WASP semantic parsing algorithm (Wong and Mooney, 2006), which translates NL sentences into MRs using an SCFG. $$$$$ The algorithm learns a semantic parser given a set of NL sentences annotated with their correct MRs.
Our work is based on the WASP semantic parsing algorithm (Wong and Mooney, 2006), which translates NL sentences into MRs using an SCFG. $$$$$ Our algorithm is called WASP, short for Word Alignment-based Semantic Parsing.

While WASP works well for target MRLs that are free of logical variables such as CLANG (Wong and Mooney, 2006), it cannot easily handle various kinds of logical forms used in computational semantics, such as predicate logic. $$$$$ It requires no prior knowledge of the NL syntax, although it assumes that an unambiguous, context-free grammar (CFG) of the target MRL is available.
While WASP works well for target MRLs that are free of logical variables such as CLANG (Wong and Mooney, 2006), it cannot easily handle various kinds of logical forms used in computational semantics, such as predicate logic. $$$$$ The second domain is GEOQUERY, where a functional, variable-free query language is used for querying a small database on U.S. geography (Zelle and Mooney, 1996; Kate et al., 2005).

We use the maximum-entropy model proposed in Wong and Mooney (2006), which defines a conditional probability distribution over derivations given an observed NL sentence. $$$$$ We propose a maximum-entropy model that defines a conditional probability distribution over derivations (d) given the observed NL string (e): where fi is a feature function, and Zλ(e) is a normalizing factor.
We use the maximum-entropy model proposed in Wong and Mooney (2006), which defines a conditional probability distribution over derivations given an observed NL sentence. $$$$$ The maximum conditional likelihood criterion is used for estimating the model parameters, Ai.

For details regarding non-isomorphic NL/MR parse trees, removal of bad links from alignments, and extraction of word gaps (e.g. the token (1) in the last rule of Figure 3), see Wong and Mooney (2006). $$$$$ Below are some SCFG rules that can be used for generating the parse trees in Figure 3: Each SCFG rule X → (α, Q) is a combination of a production of the NL semantic grammar, X → α, and a production of the MRL grammar, X → Q.
For details regarding non-isomorphic NL/MR parse trees, removal of bad links from alignments, and extraction of word gaps (e.g. the token (1) in the last rule of Figure 3), see Wong and Mooney (2006). $$$$$ Given an alignment, a, we count the number of links that would prevent a rule from being extracted for each production in the MR parse.

The larger GEOQUERY corpus consists of 880 English questions gathered from various sources (Wong and Mooney, 2006). $$$$$ For each of these productions, X —* Q, a rule X —* (α, Q) is extracted such that α consists of the words to which the production is linked, e.g.
The larger GEOQUERY corpus consists of 880 English questions gathered from various sources (Wong and Mooney, 2006). $$$$$ To build a corpus for GEOQUERY, 880 English questions were gathered from various sources, which were manually translated into the functional GEOQUERY language (Tang and Mooney, 2001).

We also compare the MT-based semantic parsers to several recently published ones: WASP (Wong and Mooney, 2006), which like the hierarchical model described here learns a SCFG to translate between NL and MRL. $$$$$ It is also similar to the hierarchical phrase-based model of Chiang (2005), in which hierarchical phrase pairs, essentially SCFG rules, are learned through the use of a simpler, phrase-based alignment model.
We also compare the MT-based semantic parsers to several recently published ones: WASP (Wong and Mooney, 2006), which like the hierarchical model described here learns a SCFG to translate between NL and MRL. $$$$$ In the future, we would like to develop a word-based alignment model that is aware of the MRL syntax, so that better lexicons can be learned.

Like the hybrid tree semantic parser (Lu et al, 2008) and the synchronous grammar based WASP (Wong and Mooney, 2006), our model simultaneously generates the input MR tree and the output NL string. $$$$$ , ((bowner our {4}) (do our {6} (pos (left (half our)))))) Here the MR string is said to be a translation of the NL string.
Like the hybrid tree semantic parser (Lu et al, 2008) and the synchronous grammar based WASP (Wong and Mooney, 2006), our model simultaneously generates the input MR tree and the output NL string. $$$$$ The semantic parsing model of WASP thus consists of an SCFG, G, and a probabilistic model, parameterized by A, that takes a possible derivation, d, and returns its likelihood of being correct given an input sentence, e. The output translation, f*, for a sentence, e, is defined as: where m(d) is the MR string that a derivation d yields, and D(G

WASP (Wong and Mooney, 2006) is an example of the former perspective, coupling the generation of the MR and NL with a synchronous grammar, a formalism closely related to tree transducers. $$$$$ To describe the semantic parsing model of WASP, it is best to start with an example.
WASP (Wong and Mooney, 2006) is an example of the former perspective, coupling the generation of the MR and NL with a synchronous grammar, a formalism closely related to tree transducers. $$$$$ Note that the structure of a parse tree is preserved through linearization, and for each MR there is a unique linearized parse, since the MRL grammar is unambiguous.

We evaluate the system on GeoQuery (Wong and Mooney, 2006), a parallel corpus of 880 English questions and database queries about United States geography, 250 of which were translated into Spanish, Japanese, and Turkish. $$$$$ To build a corpus for GEOQUERY, 880 English questions were gathered from various sources, which were manually translated into the functional GEOQUERY language (Tang and Mooney, 2001).
We evaluate the system on GeoQuery (Wong and Mooney, 2006), a parallel corpus of 880 English questions and database queries about United States geography, 250 of which were translated into Spanish, Japanese, and Turkish. $$$$$ 250 of the queries were also translated into Spanish, Japanese and Turkish, resulting in a smaller, multilingual data set.

WASP (Wong and Mooney, 2006) and the hybrid tree (Lu et al, 2008) are chosen to represent tree transformation based approaches, and, while this comparison is our primary focus, we also report UBL-S (Kwiatkowski et al, 2010) as a non tree based top-performing system. $$$$$ Prior research in semantic parsing has mainly focused on relatively simple domains such as ATIS (Air Travel Information Service) (Miller et al., 1996; Papineni et al., 1997; Macherey et al., 2001), in which a typcial MR is only a single semantic frame.
WASP (Wong and Mooney, 2006) and the hybrid tree (Lu et al, 2008) are chosen to represent tree transformation based approaches, and, while this comparison is our primary focus, we also report UBL-S (Kwiatkowski et al, 2010) as a non tree based top-performing system. $$$$$ Each rule corresponds to a transformation rule in Kate et al. (2005).

A recent SMT-based semantic parser, WASP (Wong and Mooney, 2006), in order to produce a more effective generation system. $$$$$ A semantic parser was learned from the training set.
A recent SMT-based semantic parser, WASP (Wong and Mooney, 2006), in order to produce a more effective generation system. $$$$$ WASP also outperforms SILT in terms of recall, where lexical learning is done by a local bottom-up search, which is much less effective than the wordalignment-based algorithm in WASP.
