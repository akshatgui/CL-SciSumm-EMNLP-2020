The pseudo-projective approach (Nivre and Nilsson, 2005) $$$$$ Non-projective dependencies are captured indirectly by projectivizing the training data for the classifiers and applying an inverse transformation to the output of the parser.
The pseudo-projective approach (Nivre and Nilsson, 2005) $$$$$ To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.

Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006). $$$$$ Table 2 shows final test results for each language and for the twelve required languages together.
Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006). $$$$$ This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.

Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences. $$$$$ This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.
Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences. $$$$$ By contrast, Turkish (Oflazer et al., 2003; Atalay et al., 2003) exhibits high root accuracy but consistently low attachment scores (about 88% for length 1 and 68% for length 2).

Firstto Third-Order Features The feature templates of first to third-order features are mainly drawn from previous work on graph based parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al, 2006) and dual decomposition-based parsing (Martins et al, 2011). $$$$$ The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).
Firstto Third-Order Features The feature templates of first to third-order features are mainly drawn from previous work on graph based parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al, 2006) and dual decomposition-based parsing (Martins et al, 2011). $$$$$ Features of the type DEPREL have a special status in that they are extracted during parsing from the partially built dependency graph and may therefore contain errors, whereas all the other features have gold standard values during both training and parsing.2 Based on previous research, we defined a base model to be used as a starting point for languagespecific feature selection.

includes the most accurate parsers among Nivre et al (2006), McDonald et al (2006), Martins et al (2010), Martins et al (2011), Martins et al (2013), Koo et al (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al (2013). $$$$$ Typical examples are Bulgarian (Simov et al., 2005; Simov and Osenova, 2003), Chinese (Chen et al., 2003), Danish (Kromann, 2003), and Swedish (Nilsson et al., 2005).
includes the most accurate parsers among Nivre et al (2006), McDonald et al (2006), Martins et al (2010), Martins et al (2011), Martins et al (2013), Koo et al (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al (2013). $$$$$ This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.

Both methods are sometimes combined (Nivre et al, 2006b). $$$$$ Typical examples are Bulgarian (Simov et al., 2005; Simov and Osenova, 2003), Chinese (Chen et al., 2003), Danish (Kromann, 2003), and Swedish (Nilsson et al., 2005).
Both methods are sometimes combined (Nivre et al, 2006b). $$$$$ This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.

We represented features with a parameter format partly inspired by MaltParser (Nivre et al, 2006a). $$$$$ Our methodology for performing this task is based on four essential components

These parameters are identical to Nivre et al (2006b) to enable a comparison of the scores. We evaluated the feature candidates on a development set using the labeled and unlabeled attachment scores (LAS and UAS) that we computed with the eval.pl script from CoNLL-X. $$$$$ This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.
These parameters are identical to Nivre et al (2006b) to enable a comparison of the scores. We evaluated the feature candidates on a development set using the labeled and unlabeled attachment scores (LAS and UAS) that we computed with the eval.pl script from CoNLL-X. $$$$$ By contrast, Turkish (Oflazer et al., 2003; Atalay et al., 2003) exhibits high root accuracy but consistently low attachment scores (about 88% for length 1 and 68% for length 2).

Following (Nivre et al, 2006), the encoding scheme called Head in (Nivre and Nilsson, 2005) was used to encode the original non-projective dependencies in the labels of the projectivized dependency tree. $$$$$ To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.
Following (Nivre et al, 2006), the encoding scheme called Head in (Nivre and Nilsson, 2005) was used to encode the original non-projective dependencies in the labels of the projectivized dependency tree. $$$$$ We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label rTh, where r is the original label and h is the label of the original head in the nonprojective dependency graph.

We used the base feature model defined in (Nivre et al, 2006) for all the languages but Arabic, Chinese, Czech, and Turkish. $$$$$ Features of the type DEPREL have a special status in that they are extracted during parsing from the partially built dependency graph and may therefore contain errors, whereas all the other features have gold standard values during both training and parsing.2 Based on previous research, we defined a base model to be used as a starting point for languagespecific feature selection.
We used the base feature model defined in (Nivre et al, 2006) for all the languages but Arabic, Chinese, Czech, and Turkish. $$$$$ The base model contains twenty features, but note that the fields LEMMA, CPOS and FEATS are not available for all languages.

For Arabic, Chinese, and Czech, we used the same feature models used in the CoNLL-X 948 shared task by (Nivre et al, 2006), and for Turkish we used again the base feature model but extended it with a single feature $$$$$ The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).
For Arabic, Chinese, and Czech, we used the same feature models used in the CoNLL-X 948 shared task by (Nivre et al, 2006), and for Turkish we used again the base feature model but extended it with a single feature $$$$$ The number of features in the optimized models varies from 16 (Turkish) to 30 (Spanish), but the models use all fields available for a given language, except that FORM is not used for Turkish (only LEMMA).

Talbanken05 is a Swedish tree bank converted to dependency format, containing both written and spoken language (Nivre et al, 2006a). For each token, Talbanken05 contains information on word form, part of speech, head and dependency relation, as well as various morphosyntactic and/orlexical semantic features. $$$$$ The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).
Talbanken05 is a Swedish tree bank converted to dependency format, containing both written and spoken language (Nivre et al, 2006a). For each token, Talbanken05 contains information on word form, part of speech, head and dependency relation, as well as various morphosyntactic and/orlexical semantic features. $$$$$ The number of features in the optimized models varies from 16 (Turkish) to 30 (Spanish), but the models use all fields available for a given language, except that FORM is not used for Turkish (only LEMMA).

As our baseline, we use the settings optimized for Swedish in the CoNLL-X shared task (Nivre et al,2006b), where this parser was the best performing parser for Swedish. $$$$$ The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data.
As our baseline, we use the settings optimized for Swedish in the CoNLL-X shared task (Nivre et al,2006b), where this parser was the best performing parser for Swedish. $$$$$ We have the best reported score for Japanese, Swedish and Turkish, and the score for Arabic, Danish, Dutch, Portuguese, Spanish, and overall does not differ significantly from the best one.

MaltParser (Nivre et al, 2006) is a language independent system for data-driven dependency parsing which is freely available. It is based on a deterministic parsing strategy in combination with tree bank-induced classifiers for predicting parsing actions. $$$$$ The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).
MaltParser (Nivre et al, 2006) is a language independent system for data-driven dependency parsing which is freely available. It is based on a deterministic parsing strategy in combination with tree bank-induced classifiers for predicting parsing actions. $$$$$ The evaluation shows that labeled pseudo-projective dependency parsing, using a deterministic parsing algorithm and SVM classifiers, gives competitive parsing accuracy for all languages involved in the 7Given that the average IG count of a word is 1.26 in the treebank, this means that they are normally adjacent to the head word. shared task, although the level of accuracy varies considerably between languages.

For the training of the Malt parser model that we use in the stacking experiments, we use learner and parser settings identical to the ones optimized for German in the CoNLL-X shared task (Nivre et al, 2006). $$$$$ The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data.
For the training of the Malt parser model that we use in the stacking experiments, we use learner and parser settings identical to the ones optimized for German in the CoNLL-X shared task (Nivre et al, 2006). $$$$$ Our methodology for performing this task is based on four essential components

We use Nivre et al, (2006)'s dependency parser. $$$$$ The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004).
We use Nivre et al, (2006)'s dependency parser. $$$$$ This is noticeable for German (Brants et al., 2002) and Portuguese (Afonso et al., 2002), which still have high overall accuracy thanks to very high attachment scores, but much more conspicuous for Czech (B¨ohmov´a et al., 2003), Dutch (van der Beek et al., 2002) and Slovene (Dˇzeroski et al., 2006), where root precision drops more drastically to about 69%, 71% and 41%, respectively, and root recall is also affected negatively.

Unigram label information has been used in MaltParser (Nivre et al, 2006a; Nivre, 2006). $$$$$ Our methodology for performing this task is based on four essential components

In principle, it is restricted to projective dependency forests, but it can be used in conjunction with the pseudo-projective transformation (Nivre et al2006) in order to capture a restricted subset of non projective forests. $$$$$ Labeled Pseudo-Projective Dependency Parsing With Support Vector Machines
In principle, it is restricted to projective dependency forests, but it can be used in conjunction with the pseudo-projective transformation (Nivre et al2006) in order to capture a restricted subset of non projective forests. $$$$$ To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.

Table 4 $$$$$ To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.
Table 4 $$$$$ Non-projective dependencies can be recovered by applying an inverse transformation to the output of the parser, using a left-to-right, top-down, breadthfirst search, guided by the extended arc labels rTh assigned by the parser.

To further put the obtained results into context, Table 4 compares the performance of the arc-eager parser with the projective buffer transition most suitable for each dataset with the results obtained by the parser with the pseudo-projective transformation by Nivre et al2006) in the CoNLL-X shared task, one of the top two performing systems in that event. $$$$$ To avoid too small training sets, we pool together categories that have a frequency below a certain threshold t. Pseudo-projective parsing was proposed by Nivre and Nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser.
To further put the obtained results into context, Table 4 compares the performance of the arc-eager parser with the projective buffer transition most suitable for each dataset with the results obtained by the parser with the pseudo-projective transformation by Nivre et al2006) in the CoNLL-X shared task, one of the top two performing systems in that event. $$$$$ Non-projective dependencies can be recovered by applying an inverse transformation to the output of the parser, using a left-to-right, top-down, breadthfirst search, guided by the extended arc labels rTh assigned by the parser.
