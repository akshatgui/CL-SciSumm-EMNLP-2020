 $$$$$ This criterion is naturally extended to a k-way normalized cut: where A1 ... Ak form a partition of the graph, and V −Ak is the set difference between the entire graph and partition k. C [i, k] is the normalized cut value of the optimal segmentation of the first k sentences into i segments.
 $$$$$ We also would like to acknowledge the MIT NLP and Speech Groups, the three annotators, and the three anonymous reviewers for valuable comments, suggestions, and help.

 $$$$$ This criterion is naturally extended to a k-way normalized cut: where A1 ... Ak form a partition of the graph, and V −Ak is the set difference between the entire graph and partition k. C [i, k] is the normalized cut value of the optimal segmentation of the first k sentences into i segments.
 $$$$$ We also would like to acknowledge the MIT NLP and Speech Groups, the three annotators, and the three anonymous reviewers for valuable comments, suggestions, and help.

 $$$$$ This criterion is naturally extended to a k-way normalized cut: where A1 ... Ak form a partition of the graph, and V −Ak is the set difference between the entire graph and partition k. C [i, k] is the normalized cut value of the optimal segmentation of the first k sentences into i segments.
 $$$$$ We also would like to acknowledge the MIT NLP and Speech Groups, the three annotators, and the three anonymous reviewers for valuable comments, suggestions, and help.

Our model for disentanglement fits into the general class of graph partitioning algorithms (Roth and Yih, 2004) which have been used for a variety of tasks in NLP, including the related task of meeting segmentation (Malioutov and Barzilay, 2006). $$$$$ We formalize segmentation as a graph-partitioning task that optimizes the normalized cut criterion.
Our model for disentanglement fits into the general class of graph partitioning algorithms (Roth and Yih, 2004) which have been used for a variety of tasks in NLP, including the related task of meeting segmentation (Malioutov and Barzilay, 2006). $$$$$ Synthetic Corpus Also as part of our analysis, we used the synthetic corpus created by Choi (2000) which is commonly used in the evaluation of segmentation algorithms.

In our problem, however, the solution is constrained by the linearity of segmentation on transcripts, similar to that in (Malioutov and Barzilay, 2006). $$$$$ Fortunately, we can find an exact solution due to the linearity constraint on text segmentation.
In our problem, however, the solution is constrained by the linearity of segmentation on transcripts, similar to that in (Malioutov and Barzilay, 2006). $$$$$ However, in our case, the multi-way cut is constrained to preserve the linearity of the segmentation.

Malioutov and Barzilay (2006) describe a dynamic programming algorithm to conduct topic segmentation for spoken documents. $$$$$ We tested our algorithm on a corpus of spoken lectures.
Malioutov and Barzilay (2006) describe a dynamic programming algorithm to conduct topic segmentation for spoken documents. $$$$$ The time complexity of the dynamic programming algorithm is O(KN2), where K is the number of partitions and N is the number of nodes in the graph or sentences in the transcript.

Malioutov and Barzilay (2006) optimize a normalized minimum-cut criteria based on a variation of the cosine similarity between sentences. $$$$$ Minimum Cut Model For Spoken Lecture Segmentation
Malioutov and Barzilay (2006) optimize a normalized minimum-cut criteria based on a variation of the cosine similarity between sentences. $$$$$ Table 5 shows that the Minimum Cut algorithm consistently outperforms the similarity-based baseline on all the lecture datasets.

This is common practice for this task, as the desired number of segments may be determined by the user (Malioutov and Barzilay, 2006). $$$$$ In contrast to previous approaches, the homogeneity of a segment is determined not only by the similarity of its words, but also by their relation to words in other segments of the text.
This is common practice for this task, as the desired number of segments may be determined by the user (Malioutov and Barzilay, 2006). $$$$$ We intentionally did not provide the subjects with the target number of boundaries, since we wanted to see if the annotators would converge on a common segmentation granularity.

We use the evaluation source code provided by Malioutov and Barzilay (2006). $$$$$ In the formulation above we use sentences as our nodes.
We use the evaluation source code provided by Malioutov and Barzilay (2006). $$$$$ They were provided with recorded audio of the lectures and the corresponding text transcriptions.

Our corpora do not include development sets, so tuning was performed using the lecture transcript corpus described by Malioutov and Barzilay (2006). $$$$$ We also include segmentation results on Physics ASR transcripts.
Our corpora do not include development sets, so tuning was performed using the lecture transcript corpus described by Malioutov and Barzilay (2006). $$$$$ We used the publicly available implementation of the system that does not require parameter tuning on a heldout development set.

We evaluate the performance of APS on three tasks: finding topical boundaries in transcripts of course lectures (Malioutov and Barzilay, 2006), identifying sections in medical textbooks (Eisen stein and Barzilay, 2008) and identifying chapter breaks in novels. $$$$$ We evaluate our segmentation algorithm on three sets of data.
We evaluate the performance of APS on three tasks: finding topical boundaries in transcripts of course lectures (Malioutov and Barzilay, 2006), identifying sections in medical textbooks (Eisen stein and Barzilay, 2008) and identifying chapter breaks in novels. $$$$$ This segmentation conveys the high-level topical structure of the lectures.

We compare APS with two recent systems: the Minimum Cut segmenter (Malioutov and Barzilay, 2006) and the Bayesian segmenter (Eisenstein and Barzilay, 2008). $$$$$ Minimum Cut Model For Spoken Lecture Segmentation
We compare APS with two recent systems: the Minimum Cut segmenter (Malioutov and Barzilay, 2006) and the Bayesian segmenter (Eisenstein and Barzilay, 2008). $$$$$ Figure 3: ROC plot for the Minimum Cut Segmenter on thirty Physics Lectures, with edge cutoffs set at five and hundred sentences.

Malioutov and Barzilay (2006) show that the knowledge about long-range similarities between sentences improves segmentation quality. $$$$$ Long-range dependencies do not improve the performance on the synthetic dataset.
Malioutov and Barzilay (2006) show that the knowledge about long-range similarities between sentences improves segmentation quality. $$$$$ In this paper we studied the impact of long-range dependencies on the accuracy of text segmentation.

The first, compiled by Malioutov and Barzilay (2006), consists of manually transcribed and segmented lectures on Artificial Intelligence, 3 development files and 19 test files. $$$$$ Artificial Intelligence Lectures Our second lecture corpus differs in subject matter, lecturing style, and segmentation granularity.
The first, compiled by Malioutov and Barzilay (2006), consists of manually transcribed and segmented lectures on Artificial Intelligence, 3 development files and 19 test files. $$$$$ The graduate Artificial Intelligence class has, on average, twelve segments per lecture, and a typical segment is about half of a page.

We compare the performance of APS with that of two state-of-the-art segmenters: the Minimum Cut segmenter (Malioutov and Barzilay, 2006) and the Bayesian segmenter (EisensteinandBarzilay, 2008). $$$$$ Figure 3: ROC plot for the Minimum Cut Segmenter on thirty Physics Lectures, with edge cutoffs set at five and hundred sentences.
We compare the performance of APS with that of two state-of-the-art segmenters: the Minimum Cut segmenter (Malioutov and Barzilay, 2006) and the Bayesian segmenter (EisensteinandBarzilay, 2008). $$$$$ Comparison with local dependency models We compare our system with the state-of-the-art similarity-based segmentation system developed by Choi (2000).

In situations where the document boundaries are unavailable or when finer segmentation is desired, automatic techniques for document segmentation may be applied (Malioutov and Barzilay, 2006). $$$$$ We have access both to manual transcriptions of these lectures and also output from an automatic speech recognition system.
In situations where the document boundaries are unavailable or when finer segmentation is desired, automatic techniques for document segmentation may be applied (Malioutov and Barzilay, 2006). $$$$$ Annotators B and C operated at much finer levels of discrimination with 18.4 and 13.8 segments per lecture on average.

 $$$$$ This criterion is naturally extended to a k-way normalized cut: where A1 ... Ak form a partition of the graph, and V −Ak is the set difference between the entire graph and partition k. C [i, k] is the normalized cut value of the optimal segmentation of the first k sentences into i segments.
 $$$$$ We also would like to acknowledge the MIT NLP and Speech Groups, the three annotators, and the three anonymous reviewers for valuable comments, suggestions, and help.

(Malioutov and Barzilay, 2006) uses the minimum cut model to segment spoken lectures (i.e., monologue). $$$$$ Minimum Cut Model For Spoken Lecture Segmentation
(Malioutov and Barzilay, 2006) uses the minimum cut model to segment spoken lectures (i.e., monologue). $$$$$ We tested our algorithm on a corpus of spoken lectures.

Segmentation may be particularly beneficial when working with documents without overt structure: speech transcripts (Malioutov and Barzilay, 2006), newswire (Misra et al, 2011) or novels (Kazantseva and Szpakowicz, 2011). $$$$$ This is evident in the performance of existing unsupervised algorithms on less structured datasets, such as spoken meeting transcripts (Galley et al., 2003).
Segmentation may be particularly beneficial when working with documents without overt structure: speech transcripts (Malioutov and Barzilay, 2006), newswire (Misra et al, 2011) or novels (Kazantseva and Szpakowicz, 2011). $$$$$ This segmentation conveys the high-level topical structure of the lectures.

Malioutov and Barzilay (2006) created a corpus of course lectures segmented by four annotators, noting that the annotators operated at different levels of granularity. $$$$$ As part of our human segmentation analysis, we asked three annotators to segment the Physics lecture corpus.
Malioutov and Barzilay (2006) created a corpus of course lectures segmented by four annotators, noting that the annotators operated at different levels of granularity. $$$$$ Annotators B and C operated at much finer levels of discrimination with 18.4 and 13.8 segments per lecture on average.
