Translation Edit Rate (TER, Snover et al (2006)) based alignment proposed in Sim et al (2007) is often taken as the baseline, and a couple of other approaches, such as the Indirect Hidden Markov Model (IHMM, He et al (2008)) and the ITG-based alignment (Karakos et al. (2008)), were recently proposed with better results reported. $$$$$ Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).
Translation Edit Rate (TER, Snover et al (2006)) based alignment proposed in Sim et al (2007) is often taken as the baseline, and a couple of other approaches, such as the Indirect Hidden Markov Model (IHMM, He et al (2008)) and the ITG-based alignment (Karakos et al. (2008)), were recently proposed with better results reported. $$$$$ Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.

Our incremental alignment approaches adopt the same heuristics for alignment normalization stated in He et al (2008). $$$$$ Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.
Our incremental alignment approaches adopt the same heuristics for alignment normalization stated in He et al (2008). $$$$$ (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005).

The various parameters in the IHMM model are set as the optimal values found in He et al (2008). $$$$$ Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.
The various parameters in the IHMM model are set as the optimal values found in He et al (2008). $$$$$ In the IHMM-based method, the smoothing factor for surface similarity model is set to ρ = 3, the interpolation factor of the overall similarity model is set to α = 0.3, and the controlling factor of the distance-based distortion parameters is set to K=2.

The comparison between the two pair-wise alignment methods shows that IHMM gives a 0.7 BLEU point gain over TER, which is a bit smaller than the difference reported in He et al (2008). $$$$$ There have been other hypothesis alignment methods.
The comparison between the two pair-wise alignment methods shows that IHMM gives a 0.7 BLEU point gain over TER, which is a bit smaller than the difference reported in He et al (2008). $$$$$ It shows that the IHMMbased method is still about 1 BLEU point better than the TER-based method.

 $$$$$ If the target language uses alphabetic orthography, as English does, we treat words as letter sequences and the similarity measure can be the length of the longest matched prefix (LMP) or the length of the longest common subsequence (LCS) between them.
 $$$$$ The authors are grateful to Chris Quirk, Arul Menezes, Kristina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Necip Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and discussions.

To compute scores for word pairs, we perform pair-wise hypothesis alignment using the indirect HMM (He et al 2008) for every pair of input hypotheses. $$$$$ Matusov et al. (2006) proposed using GIZA++ to align words between different MT hypotheses, where all hypotheses of the test corpus are collected to create hypothesis pairs for GIZA++ training.
To compute scores for word pairs, we perform pair-wise hypothesis alignment using the indirect HMM (He et al 2008) for every pair of input hypotheses. $$$$$ Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.

The baselines include a pair-wise hypothesis alignment approach using the indirect HMM (IHMM) proposed by He et al (2008), and an incremental hypothesis alignment approach using the incremental HMM (IncHMM) proposed by Li et al (2009). $$$$$ Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.
The baselines include a pair-wise hypothesis alignment approach using the indirect HMM (IHMM) proposed by He et al (2008), and an incremental hypothesis alignment approach using the incremental HMM (IncHMM) proposed by Li et al (2009). $$$$$ (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005).

He et al (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. $$$$$ Unlike traditional HMMs whose parameters are trained via maximum likelihood estimation (MLE), the of the IHMM are estimated a variety of sources including word semantic similarity, word surface similarity, and a distance-based distortion penalty.
He et al (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. $$$$$ Unlike traditional HMMs whose parameters are trained via maximum likelihood estimation (MLE), the parameters of the IHMM are estimated indirectly from a variety of sources including word semantic similarity, word surface similarity, and a distancebased distortion penalty, without using large amount of training data.

We compute the association score from a linear combination of two clues: surface similarity computed as Equation (2) and position difference based distortion score by following (He et al, 2008). $$$$$ Since both words are in the same language, the similarity model can be derived based on both semantic similarity and surface similarity, and the overall similarity model is a linear interpolation of the two: where and reflect the semantic and surface similarity between and e; , respectively, and α is the interpolation factor.
We compute the association score from a linear combination of two clues: surface similarity computed as Equation (2) and position difference based distortion score by following (He et al, 2008). $$$$$ In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections.

IHMM-based: He et al (2008) propose an indirect hidden Markov model (IHMM) for hypothesis alignment. $$$$$ An indirect hidden Markov model (IHMM) is proposed to address the synonym matching and word ordering issues in hypothesis alignment.
IHMM-based: He et al (2008) propose an indirect hidden Markov model (IHMM) for hypothesis alignment. $$$$$ In this paper, we propose an indirect hidden Markov model (IHMM) for MT hypothesis alignment.

We compute the distortion model by following (He et al, 2008) for IHMM and CLA-based methods. $$$$$ The two main hypothesis alignment methods for system combination in the previous literature are GIZA++ and TER-based methods.
We compute the distortion model by following (He et al, 2008) for IHMM and CLA-based methods. $$$$$ There have been other hypothesis alignment methods.

We compared our approach with the state-of-the-art confusion-network-based system (He et al, 2008) and achieved a significant absolute improvement of 1.23 BLEU points on the NIST 2005 Chinese-to-English test set and 0.93 BLEU point on the NIST 2008 Chinese-to-English test set. $$$$$ In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track of the 2008 NIST Open MT Evaluation (NIST, 2008).
We compared our approach with the state-of-the-art confusion-network-based system (He et al, 2008) and achieved a significant absolute improvement of 1.23 BLEU points on the NIST 2005 Chinese-to-English test set and 0.93 BLEU point on the NIST 2008 Chinese-to-English test set. $$$$$ The test set is the MT08 Chinese-to-English “current” test set, which includes 1357 sentences from both newswire and web-data genres.

Since the candidate hypotheses are aligned using Indirect-HMM-based (IHMM-based) alignment method (He et al, 2008) in both direction, we briefly review the IHMM-based alignment method first. $$$$$ Compared to the TER-based method, the IHMM-based method is about 1.5 BLEU points better.
Since the candidate hypotheses are aligned using Indirect-HMM-based (IHMM-based) alignment method (He et al, 2008) in both direction, we briefly review the IHMM-based alignment method first. $$$$$ In this paper, an IHMM-based method is proposed for hypothesis alignment.

 $$$$$ If the target language uses alphabetic orthography, as English does, we treat words as letter sequences and the similarity measure can be the length of the longest matched prefix (LMP) or the length of the longest common subsequence (LCS) between them.
 $$$$$ The authors are grateful to Chris Quirk, Arul Menezes, Kristina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Necip Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and discussions.

On NIST MT05 test set, the lattice-based system gave better results with an absolute improvement of 1.23 BLEU points over the confusion network-based system (He et al, 2008) and 3.73 BLEU points over the best single system. $$$$$ Compared to the TER-based method, the IHMM-based method is about 1.5 BLEU points better.
On NIST MT05 test set, the lattice-based system gave better results with an absolute improvement of 1.23 BLEU points over the confusion network-based system (He et al, 2008) and 3.73 BLEU points over the best single system. $$$$$ It outperformed the best single system by 4.7 BLEU points and the TER-based system combination by 1.0 BLEU points.

Aligning translation hypotheses can be challenging and has a substantial effect on combination performance (He et al, 2008). $$$$$ Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).
Aligning translation hypotheses can be challenging and has a substantial effect on combination performance (He et al, 2008). $$$$$ In confusion-network-based system combination for SMT, a major difficulty is aligning hypotheses to the backbone.

 $$$$$ If the target language uses alphabetic orthography, as English does, we treat words as letter sequences and the similarity measure can be the length of the longest matched prefix (LMP) or the length of the longest common subsequence (LCS) between them.
 $$$$$ The authors are grateful to Chris Quirk, Arul Menezes, Kristina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Necip Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and discussions.

Aligning translation hypotheses accurately can be challenging, and has a substantial effect on combination performance (He et al, 2008). $$$$$ Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).
Aligning translation hypotheses accurately can be challenging, and has a substantial effect on combination performance (He et al, 2008). $$$$$ In confusion-network-based system combination for SMT, a major difficulty is aligning hypotheses to the backbone.

He et al (2008) proposed using an indirect hidden Markov model (IHMM) for pairwise alignment of system outputs. $$$$$ An indirect hidden Markov model (IHMM) is proposed to address the synonym matching and word ordering issues in hypothesis alignment.
He et al (2008) proposed using an indirect hidden Markov model (IHMM) for pairwise alignment of system outputs. $$$$$ In this paper, we propose an indirect hidden Markov model (IHMM) for MT hypothesis alignment.
