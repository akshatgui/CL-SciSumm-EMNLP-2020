 $$$$$ In a significant departure from previous work, each model in our framework gets (possibly incomplete) clustering information for each mention from the earlier coreference models in the multi-pass system.
 $$$$$ We also thank Nicholas Rizzolo and Dan Roth for helping us replicate their experimental setup, and Heng Ji and Dekang Lin for providing their gender lexicon.

Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ A Multi-Pass Sieve for Coreference Resolution
Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ Recent work on coreference resolution has shown that a rich feature space that models lexical, syntactic, semantic, and discourse phenomena is crucial to successfully address the task (Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010).

Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ A Multi-Pass Sieve for Coreference Resolution
Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ To measure the contribution of our multi-pass system, we also present results from a single-pass variant of our system that uses all applicable features from the multi-pass system (marked as “single pass” in the table).

In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ One exception to this rule is the model deployed in the first pass; it only links mentions if their entire extents match exactly.
In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ Our sieve architecture applies a battery of deterministic coreference models one at a time from highest to lowest precision, where each model builds on the previous model’s cluster output.

We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ This theory is known by different names in many NLP applications: Brown et al. (1993) used simple models as “stepping stones” for more complex word alignment models; Collins (1999) used “cautious” decision list learning for named entity classification; Spitkovsky et al.
We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ Subjects are more probable antecedents for pronouns (Kertz et al., 2006).

Please see (Raghunathan et al, 2010) for more details. $$$$$ This theory is known by different names in many NLP applications: Brown et al. (1993) used simple models as “stepping stones” for more complex word alignment models; Collins (1999) used “cautious” decision list learning for named entity classification; Spitkovsky et al.
Please see (Raghunathan et al, 2010) for more details. $$$$$ Subjects are more probable antecedents for pronouns (Kertz et al., 2006).

The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ A Multi-Pass Sieve for Coreference Resolution
The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ With one exception (Pass 2), all the previous coreference models focus on nominal coreference resolution.

Proper Head Word Match: This sieve marks two mentions headed by proper nouns as coreferent if they have the same head word and satisfy the following constraints: Not i-within-i same as Raghunathan et al (2010). $$$$$ To address this issue, this pass implements several features that must all be matched in order to yield a link: Cluster head match – the mention head word matches any head word in the antecedent cluster.
Proper Head Word Match: This sieve marks two mentions headed by proper nouns as coreferent if they have the same head word and satisfy the following constraints: Not i-within-i same as Raghunathan et al (2010). $$$$$ This pass relaxes the cluster head match heuristic by allowing the mention head to match any word in the cluster of the candidate antecedent.

The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ This guarantees syntactic salience and also favors document proximity.
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ This model is triggered for all nominal mentions regardless of discourse salience, because it is possible that indefinite mentions are repeated in a document when concepts are discussed but not instantiated, e.g., a sports bar below: We now describe the coreference models implemented in the sieve.

By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ We implemented all components in our approach using only deterministic models.
By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ For clarity, we summarize them in Table 1 and show the cumulative performance as they are added to the sieve in Table 2.

Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ For clarity, we summarize them in Table 1 and show the cumulative performance as they are added to the sieve in Table 2.
Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ This pass relaxes the cluster head match heuristic by allowing the mention head to match any word in the cluster of the candidate antecedent.

We incorporate lexicalized feature sets into two different coreference architectures: Reconcile (Stoyanov et al, 2010), a pairwise coreference classifier, and Sieve (Raghunathan et al, 2010), a rule-based system. $$$$$ A Multi-Pass Sieve for Coreference Resolution
We incorporate lexicalized feature sets into two different coreference architectures: Reconcile (Stoyanov et al, 2010), a pairwise coreference classifier, and Sieve (Raghunathan et al, 2010), a rule-based system. $$$$$ This theory is known by different names in many NLP applications: Brown et al. (1993) used simple models as “stepping stones” for more complex word alignment models; Collins (1999) used “cautious” decision list learning for named entity classification; Spitkovsky et al.

There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ A Multi-Pass Sieve for Coreference Resolution
There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ Like us, they use a rich set of features and deterministic decisions.

Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ Additionally, the deterministic models in our tiered model are significantly simpler, yet perform generally better than the complex inference models proposed in these works.
Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ This theory is known by different names in many NLP applications: Brown et al. (1993) used simple models as “stepping stones” for more complex word alignment models; Collins (1999) used “cautious” decision list learning for named entity classification; Spitkovsky et al.

This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ Additionally, we propose several simple, yet powerful, new features.
This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ This flexibility is in sharp contrast to supervised classifiers that require their models to be retrained on labeled data, and unsupervised systems that do not offer a clear insertion point for new features.

This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ Gender – we assign gender attributes from static lexicons from (Bergsma and Lin, 2006; Ji and Lin, 2009).
This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ We exclude from this analysis two notable works that report results only on a version of the task that includes finding mentions (Haghighi and Klein, 2010; Stoyanov, 2010).

Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects: (a) our sieves are machine-learning classifiers, (b) the same pair of mentions can fall into multiple sieves, (c) later sieves can override the decisions made by earlier sieves, allowing to recover from errors as additional evidence becomes available. $$$$$ A Multi-Pass Sieve for Coreference Resolution
Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects: (a) our sieves are machine-learning classifiers, (b) the same pair of mentions can fall into multiple sieves, (c) later sieves can override the decisions made by earlier sieves, allowing to recover from errors as additional evidence becomes available. $$$$$ For proper nouns, 50% of recall errors are due to mention lengthening, mentions that are longer than their earlier mentions.

(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ To the best of our knowledge, we are the first to apply this theory to coreference resolution.
(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ We exclude from this analysis two notable works that report results only on a version of the task that includes finding mentions (Haghighi and Klein, 2010; Stoyanov, 2010).

The ordering should be such that (a) maximum amount of information is injected at early stages (b) the precision at the early stages is as high as possible (Raghunathan et al 2010). $$$$$ Instead, in each of our models, we exploit the cluster information received from the previous stages by resolving only mentions that are currently first in textual order in their cluster.
The ordering should be such that (a) maximum amount of information is injected at early stages (b) the precision at the early stages is as high as possible (Raghunathan et al 2010). $$$$$ For instance, once a new high precision feature (or group of features) is inserted as its own stage, it will benefit later stages with more precise clusters, but it will not interfere with their particular algorithmic decisions.

Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ The intuition behind this heuristic is two-fold.
Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ On the corpora where our model is not best, it ranks a close second.
