Shallow semantic representations, bearing a more compact information, can prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ On the contrary, shallow semantic representations, bearing a more “compact” information, could prevent the sparseness of deep structural approaches and the weakness of BOW models.
Shallow semantic representations, bearing a more compact information, can prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ Our experiments with SVMs and the above models suggest that syntactic information helps tasks such as question classification whereas semantic information contained in PAS and PASN gives promising results in answer classification.

There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). $$$$$ The typical QA system architecture consists of three phases

Shallow semantic representations, bearing a more compact information, could prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ On the contrary, shallow semantic representations, bearing a more “compact” information, could prevent the sparseness of deep structural approaches and the weakness of BOW models.
Shallow semantic representations, bearing a more compact information, could prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ Our experiments with SVMs and the above models suggest that syntactic information helps tasks such as question classification whereas semantic information contained in PAS and PASN gives promising results in answer classification.

(Moschitti et al, 2007) solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a ST. $$$$$ We solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a PAS.
(Moschitti et al, 2007) solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a ST. $$$$$ 1, gives the new Shallow Semantic Tree Kernel.

 $$$$$ A tree kernel (TK) function which computes the number of common subtrees between two syntactic parse trees has been given in (Collins and Duffy, 2002).
 $$$$$ Alessandro Moschitti would like to thank the AMI2 lab at the University of Trento and the EU project LUNA “spoken Language UNderstanding in multilinguAl communication systems” contract no 33549 for supporting part of his research.

Counting the number of matched dependencies is essentially a simplified tree kernel for QA (e.g., see (Moschitti et al, 2007)) matching only trees of depth 2. $$$$$ A tree kernel (TK) function which computes the number of common subtrees between two syntactic parse trees has been given in (Collins and Duffy, 2002).
Counting the number of matched dependencies is essentially a simplified tree kernel for QA (e.g., see (Moschitti et al, 2007)) matching only trees of depth 2. $$$$$ In the next section we describe a new kernel derived from the above tree kernel, able to evaluate the meaningful substructures for PAS trees.

In particular, in (Moschitti et al, 2007) kernels for the processing of PASs (in PropBank1 format (Kingsbury and Palmer, 2002)) extracted from question/answer pairs were proposed. $$$$$ The typical QA system architecture consists of three phases

Then, we design a novel shallow semantic kernel which is far more efficient and also more accurate than the one proposed in (Moschitti et al, 2007). $$$$$ Such annotation can be used to design a shallow semantic representation that can be matched against other semantically similar sentences, e.g.
Then, we design a novel shallow semantic kernel which is far more efficient and also more accurate than the one proposed in (Moschitti et al, 2007). $$$$$ 1, gives the new Shallow Semantic Tree Kernel.

To overcome this problem, a Shallow Semantic Tree Kernel (SSTK) was designed in (Moschitti et al, 2007). $$$$$ We solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a PAS.
To overcome this problem, a Shallow Semantic Tree Kernel (SSTK) was designed in (Moschitti et al, 2007). $$$$$ 1, gives the new Shallow Semantic Tree Kernel.

Thus, ? can recursively be an SRK (and evaluate Nested PASs (Moschitti et al, 2007)) or any other potential kernel (over the arguments). $$$$$ PASs whose arguments are other predicates (Section 2).
Thus, ? can recursively be an SRK (and evaluate Nested PASs (Moschitti et al, 2007)) or any other potential kernel (over the arguments). $$$$$ Moreover, we define new kernel functions to exploit PASs, which we automatically derive with our SRL system (Moschitti et al., 2005) (Section 3).

The result is 89.05? 1.25 and 83.73? 1.61 for 6 and 50 classes, which outperforms the best result of 86.1? 1.1 for 6 classes as reported in (Moschitti et al, 2007). $$$$$ Question processing is often centered on question classification, which selects one of k expected answer classes.
The result is 89.05? 1.25 and 83.73? 1.61 for 6 and 50 classes, which outperforms the best result of 86.1? 1.1 for 6 classes as reported in (Moschitti et al, 2007). $$$$$ (i) The TK on PT and the linear kernel on BOW produce a very high result, i.e. about 90.5%.

In (Moschitti et al, 2007) it was shown that the use of TK improves QC of 1.2 percent points, i.e. from 90.6 to 91.8 $$$$$ When the task requires the use of more complex semantics, the above approaches are often inadequate to perform fine-level textual analysis.
In (Moschitti et al, 2007) it was shown that the use of TK improves QC of 1.2 percent points, i.e. from 90.6 to 91.8 $$$$$ A first solution is to use all its possible substructures as features.

In (Moschitti et al, 2007), we proposed the Shallow Semantic Tree Kernel (SSTK) designed to encode PASs1 in SVMs. $$$$$ 1, gives the new Shallow Semantic Tree Kernel.
In (Moschitti et al, 2007), we proposed the Shallow Semantic Tree Kernel (SSTK) designed to encode PASs1 in SVMs. $$$$$ (Zhang and Lee, 2003; Moschitti, 2006), by testing a set of previously designed kernels and their combination with our new Shallow Semantic Tree Kernel.

Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ On the contrary, the SSTK applied to one PAS extracted from a text fragment may not be meaningful since its representation needs to take into account all the PASs that it contains.
Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ However, PT does not seem to provide additional information to BOW when used for question representation.

Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ On the contrary, the SSTK applied to one PAS extracted from a text fragment may not be meaningful since its representation needs to take into account all the PASs that it contains.
Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ However, PT does not seem to provide additional information to BOW when used for question representation.

In future work, we intend to expand our analysis of both the gold-standard answer and the student answers beyond the bag-of-words paradigm by considering basic logical features in the text (i.e., AND, OR, NOT) as well as the existence of shallow grammatical features such as predicate argument structure (Moschitti et al, 2007) as well as semantic classes for words. $$$$$ Here, too, the syntactic structure of a sentence appears to provide more useful information than a bag of words (Chen et al., 2006), although the correct way to exploit it is still an open problem.
In future work, we intend to expand our analysis of both the gold-standard answer and the student answers beyond the bag-of-words paradigm by considering basic logical features in the text (i.e., AND, OR, NOT) as well as the existence of shallow grammatical features such as predicate argument structure (Moschitti et al, 2007) as well as semantic classes for words. $$$$$ In this paper, we extensively study new structural representations, encoding parse trees, bag-of-words, POS tags and predicate argument structures (PASs) for question classification and answer re-ranking.
