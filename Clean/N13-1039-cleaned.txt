POS tagger in this work, we note that taggers optimized specifically for social media are now available and would likely have resulted in higher tagging accuracy (e.g. Owoputi et al (2013)). $$$$$ 2 for word clusters corresponding to some of these words. is preliminary work on social media part-of-speech (POS) tagging (Gimpel et al., 2011), named entity recognition (Ritter et al., 2011; Liu et al., 2011), and parsing (Foster et al., 2011), but accuracy rates are still significantly lower than traditional well-edited genres like newswire.
POS tagger in this work, we note that taggers optimized specifically for social media are now available and would likely have resulted in higher tagging accuracy (e.g. Owoputi et al (2013)). $$$$$ Our tagger achieves substantially higher accuracy than Gimpel et al. (2011).17 Feature ablation.

To test this, we train a CRF model (Lafferty et al, 2001) with simple orthographic features and word clusters (Owoputi et al, 2013) on the annotated Twitter data described in Gimpel et al (2011). $$$$$ 2 for word clusters corresponding to some of these words. is preliminary work on social media part-of-speech (POS) tagging (Gimpel et al., 2011), named entity recognition (Ritter et al., 2011; Liu et al., 2011), and parsing (Foster et al., 2011), but accuracy rates are still significantly lower than traditional well-edited genres like newswire.
To test this, we train a CRF model (Lafferty et al, 2001) with simple orthographic features and word clusters (Owoputi et al, 2013) on the annotated Twitter data described in Gimpel et al (2011). $$$$$ 2Although when compared to CRFs, MEMMs theoretically suffer from the “label bias” problem (Lafferty et al., 2001), our system substantially outperforms the CRF-based taggers of previous work; and when comparing to Gimpel et al. system with similar feature sets, we observed little difference in accuracy.

For NER, we use standard features, including POS tags (from the previous experiments), indicators for hyphens, digits, single quotes, upper/lowercase, 3-character prefix and suffix information, and Brown word cluster features 6 with 2,4,8,16 bit string prefixes estimated from a large Twitter corpus (Owoputi et al, 2013). $$$$$ Since Brown clusters are hierarchical in a binary tree, each word is associated with a tree path represented as a bitstring with length < 16; we use prefixes of the bitstring as features (for all prefix lengths E 12, 4, 6,... ,16}).
For NER, we use standard features, including POS tags (from the previous experiments), indicators for hyphens, digits, single quotes, upper/lowercase, 3-character prefix and suffix information, and Brown word cluster features 6 with 2,4,8,16 bit string prefixes estimated from a large Twitter corpus (Owoputi et al, 2013). $$$$$ Compared to the tagger in Gimpel et al., most of our feature changes are in the new lexical features described in §3.5.20 We do not reuse the other lexical features from the previous work, including a phonetic normalizer (Metaphone), a name list consisting of words that are frequently capitalized, and distributional features trained on a much smaller unlabeled corpus; they are all worse than our new lexical features described here.

We use the CMU Twitter Part-of-Speech Tagger (Owoputi et al, 2013) to select only instances in the verb sense. $$$$$ To tackle the challenge of novel words and constructions, we create a new Twitter part-of-speech tagger—building on previous work by Gimpel et al. (2011)—that includes new large-scale distributional features.
We use the CMU Twitter Part-of-Speech Tagger (Owoputi et al, 2013) to select only instances in the verb sense. $$$$$ Ritter et al.’s CRFbased tagger had 85.3% accuracy, and their best tagger, trained on a concatenation of PTB, IRC, and Twitter, achieved 88.3% (Table 4).

Part-of-speech tags are assigned based on Owoputi et al's tweet POS system (Owoputi et al, 2013). $$$$$ 2 for word clusters corresponding to some of these words. is preliminary work on social media part-of-speech (POS) tagging (Gimpel et al., 2011), named entity recognition (Ritter et al., 2011; Liu et al., 2011), and parsing (Foster et al., 2011), but accuracy rates are still significantly lower than traditional well-edited genres like newswire.
Part-of-speech tags are assigned based on Owoputi et al's tweet POS system (Owoputi et al, 2013). $$$$$ 20Details on the exact feature set are available in a technical report (Owoputi et al., 2012), also available on the website.
