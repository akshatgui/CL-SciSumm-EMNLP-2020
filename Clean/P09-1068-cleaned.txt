Second, recent work by Chambers and Jurafsky (2009) has induced narrative chains, i.e., likely sequences of events, by their use of similar head words. $$$$$ Our previous work (Chambers and Jurafsky, 2008) relied on the intuition that in a coherent text, any two events that are about the same participants are likely to be part of the same story or narrative.
Second, recent work by Chambers and Jurafsky (2009) has induced narrative chains, i.e., likely sequences of events, by their use of similar head words. $$$$$ Unlike in (Chambers and Jurafsky, 2008), we lemmatize verbs and argument head words.

Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing co referring arguments, followed by temporal classification to induce partial order. $$$$$ Narrative Event Chains are partially ordered sets of events that all involve the same shared participant, the protagonist (Chambers and Jurafsky, 2008).
Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing co referring arguments, followed by temporal classification to induce partial order. $$$$$ A chain is a tuple (L, O) where L is a set of event slots and O is a partial (temporal) ordering.

Chambers and Jurafsky (2009, 2008) propose an unsupervised method for learning narrative schemas, chains of events whose arguments are filled with participant semantic roles defined over words. $$$$$ We describe an unsupervised system for learncoherent sequences or sets events whose arguments are filled with participant semantic roles defined over words jury, Unlike most previous work in event structure or semantic role learning, our system does not use supervised techniques, hand-built knowledge, or predefined classes of events or roles.
Chambers and Jurafsky (2009, 2008) propose an unsupervised method for learning narrative schemas, chains of events whose arguments are filled with participant semantic roles defined over words. $$$$$ How can this unsupervised method of learning roles be evaluated?

Inspired by Chambers and Jurafsky (2009) we acquire story plots automatically by recording events, their participants, and their precedence relationships as at tested in a training corpus. $$$$$ Our previous work (Chambers and Jurafsky, 2008) relied on the intuition that in a coherent text, any two events that are about the same participants are likely to be part of the same story or narrative.
Inspired by Chambers and Jurafsky (2009) we acquire story plots automatically by recording events, their participants, and their precedence relationships as at tested in a training corpus. $$$$$ Figures 3 and 4 show two criminal schemas learned completely automatically from the NYT portion of the Gigaword Corpus (Graff, 2002).

Our narrative schemas differ slightly from Chambers and Jurafsky (2009). $$$$$ They differ in that schemas focus on events in a narrative, while frames focus on events that share core participants.
Our narrative schemas differ slightly from Chambers and Jurafsky (2009). $$$$$ The test set is the same as in (Chambers and Jurafsky, 2008).

The unsupervised setting has also been considering for the related problem of learning narrative schemas (Chambers and Jurafsky, 2009). $$$$$ Unsupervised Learning of Narrative Schemas and their Participants
The unsupervised setting has also been considering for the related problem of learning narrative schemas (Chambers and Jurafsky, 2009). $$$$$ How can this unsupervised method of learning roles be evaluated?

Our previous work (Chambers and Jurafsky, 2009) learned situation-specific roles over narrative schemas, similar to frame roles in FrameNet (Baker et al, 1998). $$$$$ In this paper we extend this work to represent sets of situation-specific events not unlike scripts, caseframes (Bean and Riloff, 2004), and FrameNet frames (Baker et al., 1998).
Our previous work (Chambers and Jurafsky, 2009) learned situation-specific roles over narrative schemas, similar to frame roles in FrameNet (Baker et al, 1998). $$$$$ Most work on semantic role labeling, however, is supervised, using Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998) or VerbNet (Kipper et al., 2000) as gold standard roles and training data.

Inducing narrative schemas (Chambers and Jurafsky, 2009) may be viewed as a possible next step in a narrative induction pipeline, subsequent to disentangling the text comprising individual narrative threads. $$$$$ The first step in describing a narrative schema is to extend the definition of a narrative chain to include argument types.
Inducing narrative schemas (Chambers and Jurafsky, 2009) may be viewed as a possible next step in a narrative induction pipeline, subsequent to disentangling the text comprising individual narrative threads. $$$$$ Whereas a narrative chain is a set of event slots, a Narrative Schema is a set of typed narrative chains.

Similar observations can be made with respect to Chambers and Jurafsky (2009) and Kasch and Oates (2010), who also study a single discourse relation (narration), and are thus more limited in scope than the approach described here. $$$$$ As just described, Chambers and Jurafsky (2008) offers an unsupervised approach to event learning (goal 1), but lacks semantic role knowledge (goal 2).
Similar observations can be made with respect to Chambers and Jurafsky (2009) and Kasch and Oates (2010), who also study a single discourse relation (narration), and are thus more limited in scope than the approach described here. $$$$$ The test set is the same as in (Chambers and Jurafsky, 2008).

It thus represents the basis for further experiments, e.g., with respect to the enrichment the BKB with information provided by Riaz and Girju (2010), Chambers and Jurafsky (2009) and Kasch and Oates (2010). $$$$$ Knowledge structures such as these provided the interpreter rich information about many aspects of meaning.
It thus represents the basis for further experiments, e.g., with respect to the enrichment the BKB with information provided by Riaz and Girju (2010), Chambers and Jurafsky (2009) and Kasch and Oates (2010). $$$$$ Second, the model only represents one participant (the protagonist).

Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. $$$$$ As just described, Chambers and Jurafsky (2008) offers an unsupervised approach to event learning (goal 1), but lacks semantic role knowledge (goal 2).
Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. $$$$$ This chain will be part of a larger narrative schema, described in section 3.4.

Our system is based on a cluster-ranking model proposed by Rahman and Ng (2009), with novel semantic features based on recent research on narrative event schema (Chambers and Jurafsky, 2009). $$$$$ Chain learning and clustering is based only on the frequency with which two verbs share arguments, ignoring any features of the arguments themselves.
Our system is based on a cluster-ranking model proposed by Rahman and Ng (2009), with novel semantic features based on recent research on narrative event schema (Chambers and Jurafsky, 2009). $$$$$ In Chambers and Jurafsky (2008), narrative chains add the best (e, d) based on the following: where m is the number of seen event slots in the corpus and (vj, gj) is the jth such possible event slot.

Chambers and Jurafsky (2009) present an unsupervised method for learning narrative schemas from news, i.e., coherent sets of events that involve specific entity types (semantic roles). $$$$$ Narrative Event Chains are partially ordered sets of events that all involve the same shared participant, the protagonist (Chambers and Jurafsky, 2008).
Chambers and Jurafsky (2009) present an unsupervised method for learning narrative schemas from news, i.e., coherent sets of events that involve specific entity types (semantic roles). $$$$$ How can this unsupervised method of learning roles be evaluated?

McIntyre and Lapata (2010) create a story generation system that draws on earlier work on narrative schemas (Chambers and Jurafsky, 2009). $$$$$ Our previous work (Chambers and Jurafsky, 2008) relied on the intuition that in a coherent text, any two events that are about the same participants are likely to be part of the same story or narrative.
McIntyre and Lapata (2010) create a story generation system that draws on earlier work on narrative schemas (Chambers and Jurafsky, 2009). $$$$$ The test set is the same as in (Chambers and Jurafsky, 2008).

Event structures in open domain texts are frequently highly complex and nested: a "crime" event can cause an "investigation" event, which can lead to an "arrest"event (Chambers and Jurafsky, 2009). $$$$$ This paper addresses two areas of work in event semantics, narrative event chains and semantic role labeling.
Event structures in open domain texts are frequently highly complex and nested: a "crime" event can cause an "investigation" event, which can lead to an "arrest"event (Chambers and Jurafsky, 2009). $$$$$ Narrative chains incorrectly favor (fly X) because it is observed during training with all five event slots, although not frequently with any one of them.
