Fung and Yee (1998) demonstrated that the associations between a word and its context seed words are preserved in comparable texts of different languages. $$$$$ Among these, (Rapp, 1995) proposes that the association between a word and its close collocate is preserved in any language. and (Fung and McKeown, 1997) suggests that the associations between a word and many seed words are also preserved in another language.
Fung and Yee (1998) demonstrated that the associations between a word and its context seed words are preserved in comparable texts of different languages. $$$$$ In this paper, we have demonstrated that the associations between a word and its context seed words are well-preserved in nonparallel, comparable texts of different languages.

The material for the present experiments consists of comparable medical corpora in French and English and a French-English medical lexicon (Fung and Yee (1998) call its words seed words?). $$$$$ Most importantly, we can assume that the word boundaries are similar in French and English.
The material for the present experiments consists of comparable medical corpora in French and English and a French-English medical lexicon (Fung and Yee (1998) call its words seed words?). $$$$$ This algorithm can be applied to other language pairs such as English-French or English-German.

 $$$$$ In these cases, since the languages are more similar linguistically and the seed word lexicon is more reliable, the algorithm should yield better results.
 $$$$$ This algorithm can also be applied in an iterative fashion where high-ranking bilingual word pairs can be added to the seed word list, which in turn can yield more new bilingual word pairs.

An additional difference with Fung and Yee (1998) is that they look for translational equivalents only among words that are unknown in both corpora. $$$$$ The unknown Chinese words and their English counterparts, as well as the occurrence frequencies of these words in HKStandard/Mingpao are shown in Table 4.
An additional difference with Fung and Yee (1998) is that they look for translational equivalents only among words that are unknown in both corpora. $$$$$ Disregarding all entries with a * in the above table, we apply the algorithm to the rest of the Chinese unknown words and the 118 English unknown words from HKStandard.

Comparable corpora have primarily been used to build bilingual lexical resources (Fung and Yee, 1998). $$$$$ Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts.
Comparable corpora have primarily been used to build bilingual lexical resources (Fung and Yee, 1998). $$$$$ These word pairs are used as seed words.

One approach that can, in principle, better exploit both alignments from bitextsand make use of non-parallel corpora is the distributional collocational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999). $$$$$ An IR Approach for Translating New Words from Nonparallel Comparable Texts
One approach that can, in principle, better exploit both alignments from bitextsand make use of non-parallel corpora is the distributional collocational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999). $$$$$ It remains to be seen how we can also make use of the multilingual texts as NLP resources.

Beside simple co occurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetzeand Pedersen, 1997), chi-square test, and the log likelihood ratio (Dunning, 1993). $$$$$ They are mostly based on the Cosine Measure of two vectors.
Beside simple co occurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetzeand Pedersen, 1997), chi-square test, and the log likelihood ratio (Dunning, 1993). $$$$$ Attempts at exploring nonparallel corpora for terminology translation are very few (Rapp, 1995; Fung, 1995a; Fung and McKeown, 1997).

A variety of subsequent work has extended the original idea either by exploring different measures of vector similarity (Fung and Yee, 1998) or by proposing other ways of measuring similarity beyond co-occurence within a context window. $$$$$ All similarity measures S3 — S7 are used in the experiment for finding a translation for ME •
A variety of subsequent work has extended the original idea either by exploring different measures of vector similarity (Fung and Yee, 1998) or by proposing other ways of measuring similarity beyond co-occurence within a context window. $$$$$ S6 and S7 appear to be the best similarity measures.

 $$$$$ In these cases, since the languages are more similar linguistically and the seed word lexicon is more reliable, the algorithm should yield better results.
 $$$$$ This algorithm can also be applied in an iterative fashion where high-ranking bilingual word pairs can be added to the seed word list, which in turn can yield more new bilingual word pairs.

Here, a standard technique of estimating bilingual term correspondences from comparable corpora (e.g., Fung and Yee (1998) and Rapp (1999)) is employed. $$$$$ This leads us to use the term frequency(TF) measure.
Here, a standard technique of estimating bilingual term correspondences from comparable corpora (e.g., Fung and Yee (1998) and Rapp (1999)) is employed. $$$$$ Attempts at exploring nonparallel corpora for terminology translation are very few (Rapp, 1995; Fung, 1995a; Fung and McKeown, 1997).

For example, Rapp (1999) filtered out bilingual term pairs with low monolingual frequencies (those below 100 times), while Fung and Yee (1998) restricted candidate bilingual term pairs to be pairs of the most frequent 118 unknown words. $$$$$ These word pairs are used as seed words.
For example, Rapp (1999) filtered out bilingual term pairs with low monolingual frequencies (those below 100 times), while Fung and Yee (1998) restricted candidate bilingual term pairs to be pairs of the most frequent 118 unknown words. $$$$$ This algorithm can also be applied in an iterative fashion where high-ranking bilingual word pairs can be added to the seed word list, which in turn can yield more new bilingual word pairs.

Fung and Yee (1998) also use a vector space approach, but use TF/IDF values in the vector components and experiment with different vector similarity measures for ranking the translation candidates. $$$$$ All similarity measures S3 — S7 are used in the experiment for finding a translation for ME •
Fung and Yee (1998) also use a vector space approach, but use TF/IDF values in the vector components and experiment with different vector similarity measures for ranking the translation candidates. $$$$$ Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons (Salton and Buckley, 1988; Salton and Yang, 1973; Croft, 1984; Turtle and Croft, 1992; Bookstein, 1983; Korfhage, 1995; Jones, 1979).

Paststatistical methods for non-parallel corpora (Fung and Yee, 1998) are not valid for finding translations of words or expressions with low frequency. $$$$$ All similarity measures S3 — S7 are used in the experiment for finding a translation for ME •
Paststatistical methods for non-parallel corpora (Fung and Yee, 1998) are not valid for finding translations of words or expressions with low frequency. $$$$$ In fact, almost all unambiguous Chinese new words find their translations in the first 100 of the ranked list.

Following standard practice in bilingual lexicon extraction from comparable corpora, we rely on the approach proposed by Fung and Yee (1998). $$$$$ An IR Approach for Translating New Words from Nonparallel Comparable Texts
Following standard practice in bilingual lexicon extraction from comparable corpora, we rely on the approach proposed by Fung and Yee (1998). $$$$$ We use the lexicon of the MT system to &quot;bridge&quot; all bilingual word pairs in the corpora.

 $$$$$ In these cases, since the languages are more similar linguistically and the seed word lexicon is more reliable, the algorithm should yield better results.
 $$$$$ This algorithm can also be applied in an iterative fashion where high-ranking bilingual word pairs can be added to the seed word list, which in turn can yield more new bilingual word pairs.

Some treated context words equally regardless of their positions (Fung and Yee, 1998), while others treated the words separately for each position (Rapp, 1999). $$$$$ (Rapp, 1995; Fung and McKeown, 1997) suggest that a content word is closely associated with some words in its context.
Some treated context words equally regardless of their positions (Fung and Yee, 1998), while others treated the words separately for each position (Rapp, 1999). $$$$$ As a tutorial example, we postulate that the words which appear in the context ofMet, Iliougan should be similar to the words appearing in the context of its English translation, flu.

Fung and Yee (1998), for example, proposed to represent the contexts of a word or phrase with a real-valued vector (e.g., a TF-IDF vector), in which one element corresponds to one word in the contexts. $$$$$ So the first clue to the similarity between a word and its translation number of common words in their contexts.
Fung and Yee (1998), for example, proposed to represent the contexts of a word or phrase with a real-valued vector (e.g., a TF-IDF vector), in which one element corresponds to one word in the contexts. $$$$$ Hence, for every context seed word i, we assign a word weighting factor (Salton and Buckley, 1988) w = TFiw x IDFi where TFiw is the TF of word i in the context of word W. The updated vector space model of word W has wi in its i-th dimension.

Fung and Yee (1998) point out that not only the number of common words in context gives some similarity clue to a word and its translation, but the actual ranking of the context word frequencies also provides important clue to the similarity between a bilingual word pair. $$$$$ So the first clue to the similarity between a word and its translation number of common words in their contexts.
Fung and Yee (1998) point out that not only the number of common words in context gives some similarity clue to a word and its translation, but the actual ranking of the context word frequencies also provides important clue to the similarity between a bilingual word pair. $$$$$ The flu example illustrates that the actual ranking of the context word frequencies provides a second clue to the similarity between a bilingual word pair.

This fact has motivated Fung and Yee (1998) to use tfidf weighting to compute the vectors. $$$$$ Next, a ranking algorithm is needed to match the unknown word vectors to their counterparts in the other language.
This fact has motivated Fung and Yee (1998) to use tfidf weighting to compute the vectors. $$$$$ They are mostly based on the Cosine Measure of two vectors.
