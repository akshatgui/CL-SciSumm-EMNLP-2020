Superficially, the architecture of our system conforms to the standard emerged in natural anguage generation (NLG) (as expressed, for instance in Reiter, 1994) in that it includes the stages of content specification, text planning and surface generation (realization). $$$$$ Content determination takes the initial input to the generation system, which may be, for example, a query to be answered or an intention to be satisfied, and produces from it a 'semantic form', 'conceptual representation', or 'list of propositions', i.e., a specification of the meaning content of the output text.
Superficially, the architecture of our system conforms to the standard emerged in natural anguage generation (NLG) (as expressed, for instance in Reiter, 1994) in that it includes the stages of content specification, text planning and surface generation (realization). $$$$$ The papers I read were not very clear on this issue, but I believe that while most of the systems surveyed use the first acceptable reduction found, FUF in some cases searches for an optimal reduction. choice from surface realization The consensus architecture clearly separates lexical choice of content words (done during sentence planning) from syntactic processing (performed during surface generation).

This separation is now fairly standard and most implementations encapsulate each task in a separate module (Robin 1995), (Reiter 1994). $$$$$ Surface Generation

The summarizer's architecture follows the consensus NLG architecture (Reiter, 1994), including the stages of content calculation and content planning. $$$$$ I also compare this 'consensus architecture' among applied NLG systems with psycholinguistic knowledge about how humans speak, and argue that at least some aspects of the consensus architecture seem to be in agreement with what is known about human language production, despite the fact that psycholinguistic plausibility was not in general a goal of the developers of the surveyed systems.
The summarizer's architecture follows the consensus NLG architecture (Reiter, 1994), including the stages of content calculation and content planning. $$$$$ Sentence Planning.

This assumes the existence of a separate higher-level process to produce such a representation, following the canonical pipeline architecture of a full generation system (Reiter, 1994). $$$$$ The existence of such agreement among the surveyed systems is especially surprising because in some cases the theoretical backgrounds of the systems examined argue against some aspects of the consensus architecture.
This assumes the existence of a separate higher-level process to produce such a representation, following the canonical pipeline architecture of a full generation system (Reiter, 1994). $$$$$ The consensus architecture divides the generation process into multiple modules, with information flowing in a 'pipeline' fashion from one module to the next.

In the community of NLG, there is a broad consensus that the generation of natural language should be done in three major steps [Reiter, 1994]. $$$$$ I also compare this 'consensus architecture' among applied NLG systems with psycholinguistic knowledge about how humans speak, and argue that at least some aspects of the consensus architecture seem to be in agreement with what is known about human language production, despite the fact that psycholinguistic plausibility was not in general a goal of the developers of the surveyed systems.
In the community of NLG, there is a broad consensus that the generation of natural language should be done in three major steps [Reiter, 1994]. $$$$$ I also compare the consensus architecture to psycholinguistic knowledge about language generation in human speakers.

Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. $$$$$ Morphology

Sequential processing has also been used in several NLG systems (e.g. Reiter (1994), Reiter& amp; Dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. Buchholz et al (1999), Soon et al (2001)) .In this paper we address the problem of aggregating the outputs of classifiers solving different NLP tasks. $$$$$ In other words, it does not use an integrated `lexicogrammar', which systemic theorists in particular (e.g., [Matthiessen, 19911) have argued for, and which is implicit in some unification-based approaches, such as the semantic head-driven algorithm [Shieber et al., 19901.
Sequential processing has also been used in several NLG systems (e.g. Reiter (1994), Reiter& amp; Dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. Buchholz et al (1999), Soon et al (2001)) .In this paper we address the problem of aggregating the outputs of classifiers solving different NLP tasks. $$$$$ Surface generation has been used to mean many different things in the literature.

Narratological aspects influence on all architectural modules [Reiter, 1994] or representation levels [Cahill et al, 2000] of NLG. $$$$$ The argument against pipelines and modules is almost always some variant of 'there are linguistic phenomena that can only be properly handled by looking at constraints from different levels (intentional, semantic, syntactic, morphological), and this is difficult to do in a pipeline system.'
Narratological aspects influence on all architectural modules [Reiter, 1994] or representation levels [Cahill et al, 2000] of NLG. $$$$$ In other words, it does not use an integrated `lexicogrammar', which systemic theorists in particular (e.g., [Matthiessen, 19911) have argued for, and which is implicit in some unification-based approaches, such as the semantic head-driven algorithm [Shieber et al., 19901.

The RAGS project initially set out to develop a reference architecture based on the three-stage pipeline suggested by Reiter (Reiter, 1994). $$$$$ Many names have been used for this process; here I use one suggested by Rambow and Korelsky [1992].
The RAGS project initially set out to develop a reference architecture based on the three-stage pipeline suggested by Reiter (Reiter, 1994). $$$$$ Despite these theoretical arguments, none of the systems examined used an integrated lexicogrammar, including unification-based FUF and systemic-based PENMAN.3 In contrast, earlier unification-based sys'Even though I have previously argued against structure-mapping because it does not do a good job of handling lexical preferences [Reiter, 1991], I nevertheless ended up using this technique when I moved from my Ph.D research to the more applications-oriented IDAS project.

In the classic natural language generation (NLG) architecture (Reiter, 1994), sentence boundary decisions are made during the sentence planning stage in which the syntactic structure and wording of sentences are decided. $$$$$ Sentence Planning.
In the classic natural language generation (NLG) architecture (Reiter, 1994), sentence boundary decisions are made during the sentence planning stage in which the syntactic structure and wording of sentences are decided. $$$$$ The papers I read were not very clear on this issue, but I believe that while most of the systems surveyed use the first acceptable reduction found, FUF in some cases searches for an optimal reduction. choice from surface realization The consensus architecture clearly separates lexical choice of content words (done during sentence planning) from syntactic processing (performed during surface generation).

Although most generation systems pipeline decisions (Reiter, 1994), we believe the most efficient and flexible way to integrate constraints in sentence planning is to synchronize the decisions. $$$$$ Sentence Planning.
Although most generation systems pipeline decisions (Reiter, 1994), we believe the most efficient and flexible way to integrate constraints in sentence planning is to synchronize the decisions. $$$$$ I do not mean by 'pipeline' that generation must be incremental in the sense that, say, syntactic processing of the first sentence is done at the same time as semantic processing of the second; I believe most of the systems examined could in fact do this, but they have not bothered to do so (probably because it would not be of much benefit to the applications programs of interest).

Most generation systems pipeline pragmatic, semantic, lexical and syntactic decisions (Reiter, 1994). $$$$$ There is psychological evidence that at least some lexical processing is separated from syntactic processing, e.g., the patient mentioned in Section 4.1.1 who was able to perform content-determination and syntactic generation but had a very restricted speaking vocabulary.
Most generation systems pipeline pragmatic, semantic, lexical and syntactic decisions (Reiter, 1994). $$$$$ None of the systems use the semantic head-driven generation algorithm [Shieber et at., 1990], although this is probably the single best-known algorithm for surface generation; Elhadad [1992, chapter 4] claims that such an algorithm is only necessary for systems that attempt to simultaneously perform both lexical choice and surface generation, which none of the examined systems do.

Furthermore, Reiter (1994), who reviews the architecture of some models of natural language generation, shows that psycholinguistic and engineering approaches often result in systems, which are similar in crucial respects. $$$$$ I also compare the consensus architecture to psycholinguistic knowledge about language generation in human speakers.
Furthermore, Reiter (1994), who reviews the architecture of some models of natural language generation, shows that psycholinguistic and engineering approaches often result in systems, which are similar in crucial respects. $$$$$ It furthermore examines the plausibility of these decisions from a psycholinguistic perspective, and argues that in many respects they agree with what is known about how humans generate text.

In this paper we ground on two of these common aspects, namely the distinction between what-to-say and how-tosay (De Smedt, Horacek& amp; Zock, 1996) and the use of a pipeline architecture, which divides the generation process& quot; into multiple modules, with information flowing in a &apos; pipeline &apos; fashion from one module to the next& quot; (Reiter, 1994). $$$$$ It is therefore quite interesting that they all seem to have ended up with broadly similar architectures, in that they break up the generation process into a similar set of modules, and they all use a pipeline architecture to connect the modules; i.e., the modules are linearly ordered, and information flows from each module to its successor in the pipeline, with no feedback from later modules to earlier modules.
In this paper we ground on two of these common aspects, namely the distinction between what-to-say and how-tosay (De Smedt, Horacek& amp; Zock, 1996) and the use of a pipeline architecture, which divides the generation process& quot; into multiple modules, with information flowing in a &apos; pipeline &apos; fashion from one module to the next& quot; (Reiter, 1994). $$$$$ The consensus architecture divides the generation process into multiple modules, with information flowing in a 'pipeline' fashion from one module to the next.

There has also been a rethinking of the traditional modular NLG architecture (Reiter, 1994). $$$$$ I also compare this 'consensus architecture' among applied NLG systems with psycholinguistic knowledge about how humans speak, and argue that at least some aspects of the consensus architecture seem to be in agreement with what is known about human language production, despite the fact that psycholinguistic plausibility was not in general a goal of the developers of the surveyed systems.
There has also been a rethinking of the traditional modular NLG architecture (Reiter, 1994). $$$$$ In other words, despite different theoretical claims, there is a remarkable level of similarity in how these systems 'really work'; that is, a de facto 'consensus architecture' seems to be emerging for how applied NLG systems should generate text.
