(Kozareva et al, 2008) proposed the use of a doubly-anchored hyponym pattern and a graph to represent the links between hyponym occurrences in these patterns. $$$$$ We present two algorithms that use hyponym pattern linkage graphs (HPLGs) to represent popularity and productivity information.
(Kozareva et al, 2008) proposed the use of a doubly-anchored hyponym pattern and a graph to represent the links between hyponym occurrences in these patterns. $$$$$ We will refer to these as hyponym patterns.

We are particularly interested in the usage of recursive patterns for the learning of semantic relations not only because it is a novel method, but also because recursive patterns of the DAP fashion are known to: (1) learn concepts with high precision compared to singly-anchored pat terns (Kozareva et al, 2008), (2) use only one seed instance for the discovery of new previously unknown terms, and (3) harvest knowledge with minimal supervision. $$$$$ Each new class member is then used as a seed instance in the bootstrapping loop.
We are particularly interested in the usage of recursive patterns for the learning of semantic relations not only because it is a novel method, but also because recursive patterns of the DAP fashion are known to: (1) learn concepts with high precision compared to singly-anchored pat terns (Kozareva et al, 2008), (2) use only one seed instance for the discovery of new previously unknown terms, and (3) harvest knowledge with minimal supervision. $$$$$ Combining hyponym patterns with pattern linkage graphs is an effective way to produce a highly accurate semantic class learner that requires truly minimal supervision: just the class name and one class member as a seed.

With the same goal, Kozareva et al (2008) apply similar textual patterns to the web. $$$$$ The KnowItAll system (Etzioni et al., 2005) also uses hyponym patterns to extract class instances from the web and then evaluates them further by computing mutual information scores based on web queries.
With the same goal, Kozareva et al (2008) apply similar textual patterns to the web. $$$$$ Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.

Similarly, (Kozareva et al,2008) evaluated only a small number (a few hundreds) of harvested instances. $$$$$ These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.
Similarly, (Kozareva et al,2008) evaluated only a small number (a few hundreds) of harvested instances. $$$$$ We evaluated our algorithms on four semantic categories: U.S. states, countries, singers, and fish.

In our experiments, we use the doubly-anchored lexico-syntactic patterns and bootstrapping algorithm introduced by (Kozareva et al., 2008) and (Hovy et al, 2009). $$$$$ Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.
In our experiments, we use the doubly-anchored lexico-syntactic patterns and bootstrapping algorithm introduced by (Kozareva et al., 2008) and (Hovy et al, 2009). $$$$$ Our popularity-based algorithm was very effective and is practical to use.

In response, many automatic and semi-automatic methods of creating sets of named entities have been proposed, some are supervised (Zhou and Su, 2001), unsupervised (Pantel and Lin 2002, Nadeau et al 2006), and others semi-supervised (Kozareva et al 2008). $$$$$ Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user.
In response, many automatic and semi-automatic methods of creating sets of named entities have been proposed, some are supervised (Zhou and Su, 2001), unsupervised (Pantel and Lin 2002, Nadeau et al 2006), and others semi-supervised (Kozareva et al 2008). $$$$$ These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.

Approaches in the first category use lexical-syntactic formulation to define patterns, either manually (Kozareva et al, 2008) or automatically (Girju et al, 2006), and apply those patterns to mine instances of the patterns. $$$$$ We will refer to these as hyponym patterns.
Approaches in the first category use lexical-syntactic formulation to define patterns, either manually (Kozareva et al, 2008) or automatically (Girju et al, 2006), and apply those patterns to mine instances of the patterns. $$$$$ Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.

One approach for taxonomy deduction is to use explicit expressions (Iwaska et al, 2000) or lexical and semantic patterns such as is a (Snow et al, 2004), similar usage (Kozareva et al, 2008), synonyms and antonyms (Lin et al, 2003), purpose (Cimiano and Wenderoth, 2007), and employed by (Bunescu and Mooney, 2007) to extract and organize terms. $$$$$ Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003).
One approach for taxonomy deduction is to use explicit expressions (Iwaska et al, 2000) or lexical and semantic patterns such as is a (Snow et al, 2004), similar usage (Kozareva et al, 2008), synonyms and antonyms (Lin et al, 2003), purpose (Cimiano and Wenderoth, 2007), and employed by (Bunescu and Mooney, 2007) to extract and organize terms. $$$$$ These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.

(Kozareva et al., 2008) introduced a bootstrapping scheme using the doubly-anchored pattern (DAP) that is guided through graph ranking. $$$$$ We describe this pattern as being doubly-anchored because it is instantiated with both the name of the semantic class as well as a class member.
(Kozareva et al., 2008) introduced a bootstrapping scheme using the doubly-anchored pattern (DAP) that is guided through graph ranking. $$$$$ To evaluate the performance of the doubly-anchored pattern, we began by using the pattern to search the web and embedded this process in a simple bootstrapping loop, which is presented in Figure 1.

To assess how well our algorithm compares with previous semantic class learning methods, we compared our results to those of (Kozareva et al, 2008). $$$$$ Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs
To assess how well our algorithm compares with previous semantic class learning methods, we compared our results to those of (Kozareva et al, 2008). $$$$$ A variety of methods have been developed for automatic semantic class identification, under the rubrics of lexical acquisition, hyponym acquisition, semantic lexicon induction, semantic class learning, and web-based information extraction.

Consequently, we can compare the results produced by the first iteration of our algorithm (before intermediate concepts are learned) to those of (Kozareva et al, 2008) for the Animal and People categories, and then compare again after 10 bootstrapping iterations of intermediate concept learning. $$$$$ It can be difficult to compare the results of different semantic class learners because there is no standard set of benchmark categories, so researchers report results for different classes.
Consequently, we can compare the results produced by the first iteration of our algorithm (before intermediate concepts are learned) to those of (Kozareva et al, 2008) for the Animal and People categories, and then compare again after 10 bootstrapping iterations of intermediate concept learning. $$$$$ For the state and country categories, however, we can compare our results with that of other web-based semantic class learners such as Pasca (Pas¸ca, 2007a) and the KnowItAll system (Etzioni et al., 2005).

Bootstrapping with intermediate concepts produces nearly 5 times as many basic-level concepts and instances than (Kozareva et al, 2008) obtain, while maintaining similar levels of precision. $$$$$ High precision is achieved only with low levels of recall for countries.
Bootstrapping with intermediate concepts produces nearly 5 times as many basic-level concepts and instances than (Kozareva et al, 2008) obtain, while maintaining similar levels of precision. $$$$$ (Pas¸ca, 2007a) reports results of 100% precision for the first 25 instances generated, and 82% precision for the first 150 instances generated.

To group adjectives, we use a bootstrapping technique (Kozareva et al 2008) that learns which adjectives tend to co-occur, and groups these together to form an at tribute class. $$$$$ Pasca also developed a second technique (Pas¸ca, 2007b) that creates context vectors for a group of seed instances by searching web query logs, and uses them to learn similar instances.
To group adjectives, we use a bootstrapping technique (Kozareva et al 2008) that learns which adjectives tend to co-occur, and groups these together to form an at tribute class. $$$$$ Intuitively, we expect true class members to occur frequently in pattern contexts with other class members.

Kozareva et al (2008) use a boot strapping approach that extends the fixed-pattern approach of Hearst (1992) in two intriguing ways. $$$$$ (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around the pattern.
Kozareva et al (2008) use a boot strapping approach that extends the fixed-pattern approach of Hearst (1992) in two intriguing ways. $$$$$ Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.

The approach we describe here is most similar to that of Kozareva et al (2008). $$$$$ These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.
The approach we describe here is most similar to that of Kozareva et al (2008). $$$$$ In the next section, we present a new approach that creates a Hyponym Pattern Linkage Graph to steer bootstrapping and improve accuracy.

Kozareva et al (2008) test their approach on relatively simple and objective categories like states, countries (both closed sets), singers and fish (both open, the former more so than the latter), but not on complex categories in which members are tied both to a general category, like food, and to a stereotypical property, like sweet (Veale and Hao, 2007). $$$$$ We evaluated our algorithms on four semantic categories: U.S. states, countries, singers, and fish.
Kozareva et al (2008) test their approach on relatively simple and objective categories like states, countries (both closed sets), singers and fish (both open, the former more so than the latter), but not on complex categories in which members are tied both to a general category, like food, and to a stereotypical property, like sweet (Veale and Hao, 2007). $$$$$ The singers and fish categories are much larger, open classes.

Following Kozareva et al (2008), we can either indulge in reckless bootstrapping, which ignores the question of noise until all bootstrapping is finished, or we can apply a noise filter after each incremental step. $$$$$ We will refer to this process as reckless bootstrapping because there are no checks of any kind.
Following Kozareva et al (2008), we can either indulge in reckless bootstrapping, which ignores the question of noise until all bootstrapping is finished, or we can apply a noise filter after each incremental step. $$$$$ First, we perform reckless bootstrapping for a class name and seed until no new instances are generated.

Kozareva et al (2008) and Navigli et al (2011) both develop systems that create taxonomies end to-end, i.e., discover the terms, their relations, and how these are hierarchically organized. $$$$$ Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003).
Kozareva et al (2008) and Navigli et al (2011) both develop systems that create taxonomies end to-end, i.e., discover the terms, their relations, and how these are hierarchically organized. $$$$$ These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.

Similarly to Kozareva et al (2008) and Navigli et al (2011), our model operates over a graph whose nodes represent terms and edges their relationships. $$$$$ The Out-degree (outD) score for vertex v is the weighted sum of v’s outgoing edges, normalized by the number of other nodes in the graph.
Similarly to Kozareva et al (2008) and Navigli et al (2011), our model operates over a graph whose nodes represent terms and edges their relationships. $$$$$ The Total-degree (totD) score for vertex v is the weighted sum of both incoming and outgoing edges, normalized by the number of other nodes in the graph.

We apply boot strapping (Kozareva et al 2008) on the word graphs by manually selecting 10 seeds for concrete and abstract words (see Table 10). $$$$$ A candidate word is productive if it frequently leads to the discovery of other words.
We apply boot strapping (Kozareva et al 2008) on the word graphs by manually selecting 10 seeds for concrete and abstract words (see Table 10). $$$$$ We experimented with three scoring functions for selecting nodes.
