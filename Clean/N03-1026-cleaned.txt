Furthermore, we consider an F-score measure that is adapted from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al,2003). $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
Furthermore, we consider an F-score measure that is adapted from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al,2003). $$$$$ Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al. (2002).

The intrinsic evaluation measures used in our experiments are the well-known BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) metrics, and an F-score measure that adapts evaluation techniques from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al, 2003) to machine translation. $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
The intrinsic evaluation measures used in our experiments are the well-known BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) metrics, and an F-score measure that adapts evaluation techniques from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al, 2003) to machine translation. $$$$$ (2001) for evaluation of machine translation systems.

We stand in a marked contrast to previous 'grafting' approaches which more or less rely on an ad-hoc collection of transformation rules to generate candidates (Riezler et al, 2003). $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
We stand in a marked contrast to previous 'grafting' approaches which more or less rely on an ad-hoc collection of transformation rules to generate candidates (Riezler et al, 2003). $$$$$ Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al. (2002).

 $$$$$ Evaluation of quality of sentence condensation systems, and of text summarization and simplification systems in general, has mostly been conducted as intrinsic evaluation by human experts.
 $$$$$ This will eventually lead to a system whose components work on packed representations of all or n-best solutions, but completely avoid costly unpacking of representations.

Our results show that grammatical relations based F-score (Riezler et al 2003) correlates reliably with human judgements and could thus be used to measure compression performance automatically. $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
Our results show that grammatical relations based F-score (Riezler et al 2003) correlates reliably with human judgements and could thus be used to measure compression performance automatically. $$$$$ These results show a close correspondence between automatically produced evaluation results and human judgments on the quality of generated condensed strings.

Riezler et al (2003) present a discriminative sentence compressor over the output of an LFG parser that is a packed representation of possible compressions. $$$$$ In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al. (2002)).
Riezler et al (2003) present a discriminative sentence compressor over the output of an LFG parser that is a packed representation of possible compressions. $$$$$ For example, one possible post-transfer output of the sentence in Fig.

It is an important and growing field of natural language processing with applications in areas such as transfer based machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al, 2003). $$$$$ The transfer component for the sentence condensation system is based on a component previously used in a machine translation system (see Frank (1999)).
It is an important and growing field of natural language processing with applications in areas such as transfer based machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al, 2003). $$$$$ (2001) for evaluation of machine translation systems.

Riezler et al (2003) applied linguistically rich LFG grammars to a sentence compression system. $$$$$ In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al. (2002)).
Riezler et al (2003) applied linguistically rich LFG grammars to a sentence compression system. $$$$$ We presented an approach to sentence condensation that employs linguistically rich LFG grammars in a parsing/generation-based stochastic sentence condensation system.

One of the most widely used automatic metrics is the F1 measure over grammatical relations of the gold standard compressions (Riezler et al, 2003). $$$$$ Given such a gold standard, summarization quality of a system can be evaluated automatically and repeatedly by matching the structures of the system output against the gold standard structures.
One of the most widely used automatic metrics is the F1 measure over grammatical relations of the gold standard compressions (Riezler et al, 2003). $$$$$ The standard metrics of precision, recall, and F-score from statistical parsing can be used as evaluation metrics for measuring matching quality: Precision measures the number of matching structural items in the parses of the system output and the gold standard, out of all structural items in the system output’s parse; recall measures the number of matches, out of all items in the gold standard’s parse.

As an automated metric of quality, we compute F-score based on grammatical relations (relational F1, or RelF1) (Riezler et al, 2003). $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
As an automated metric of quality, we compute F-score based on grammatical relations (relational F1, or RelF1) (Riezler et al, 2003). $$$$$ Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al. (2002).

We also report results using F1 computed over grammatical relations (Riezler et al, 2003). $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
We also report results using F1 computed over grammatical relations (Riezler et al, 2003). $$$$$ The third rows report compression ratios.

The first evaluation is dependency base devaluation same as Riezler et al (2003). $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
The first evaluation is dependency base devaluation same as Riezler et al (2003). $$$$$ Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al. (2002).
