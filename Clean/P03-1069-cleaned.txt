Furthermore, to provide some assessment of the quality of the predicted orderings themselves, we follow Lapata (2003) in employing Kendall's t, which is a measure of how much an ordering differs from the OSO --- the underlying assumption is that most reasonable sentence orderings should be fairly similar to it. $$$$$ The average distance in the orderings produced by our subjects is .58.
Furthermore, to provide some assessment of the quality of the predicted orderings themselves, we follow Lapata (2003) in employing Kendall's t, which is a measure of how much an ordering differs from the OSO --- the underlying assumption is that most reasonable sentence orderings should be fairly similar to it. $$$$$ This way they ensured that orderings were not influenced by mistakes their system could have made.

 $$$$$ The model in Section 2.1 was trained on the BLLIP corpus (30 M words), a collection of texts from the Wall Street Journal (years 1987-89).
 $$$$$ Thanks also to Stephen Clark, Nikiforos Karamanis, Frank Keller, Alex Lascarides, Katja Markert, and Miles Osborne for helpful comments and suggestions.

 $$$$$ The model in Section 2.1 was trained on the BLLIP corpus (30 M words), a collection of texts from the Wall Street Journal (years 1987-89).
 $$$$$ Thanks also to Stephen Clark, Nikiforos Karamanis, Frank Keller, Alex Lascarides, Katja Markert, and Miles Osborne for helpful comments and suggestions.

The same data and similar methods were used by Barzilay and Lee (2004) to compare their probabilistic approach for ordering sentences with that of Lapata (2003). $$$$$ Probabilistic Text Structuring: Experiments With Sentence Ordering
The same data and similar methods were used by Barzilay and Lee (2004) to compare their probabilistic approach for ordering sentences with that of Lapata (2003). $$$$$ Finally, we assess whether this model can be used for multi-document summarization using data from Barzilay et al. (2002).

It is typically applicable in the text generation field, both for concept-to-text generation and text-to text generation (Lapata, 2003), such as multiple document summarization (MDS), question answering and so on. $$$$$ The problem of finding an acceptable ordering does not arise solely in concept-to-text generation but also in the emerging field of text-to-text generation (Barzilay, 2003).
It is typically applicable in the text generation field, both for concept-to-text generation and text-to text generation (Lapata, 2003), such as multiple document summarization (MDS), question answering and so on. $$$$$ This simplification is reasonable if one has text-to-text generation mind.

For works taking no use of source document, Lapata (2003) proposed a probabilistic model which learns constraints on sentence ordering from a corpus of texts. $$$$$ We describe a model that learns constraints on sentence order from a corpus of domainspecific texts and an algorithm that yields the most likely order among several alternatives.
For works taking no use of source document, Lapata (2003) proposed a probabilistic model which learns constraints on sentence ordering from a corpus of texts. $$$$$ In this paper we introduce an unsupervised probabilistic model for text structuring that learns ordering constraints from a large corpus.

The probability model originates from (Lapata, 2003), and we implement the model with four features of lemmatized noun, verb, adjective or adverb, and verb and noun related dependency. $$$$$ Note that the noun and verb features do not capture the structure of the sentences to be ordered.
The probability model originates from (Lapata, 2003), and we implement the model with four features of lemmatized noun, verb, adjective or adverb, and verb and noun related dependency. $$$$$ Table 3 gives the average i (T) for all 20 test texts when the following features are used: lemmatized verbs (VL), tensed verbs (VT), lemmatized nouns (NL), lemmatized verbs and nouns (VLNL), tensed verbs and lemmatized nouns (VTNL), verb-related dependencies (VD), noun-related dependencies (ND), verb and noun dependencies (VDND), and all available dependencies (AD).

In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). $$$$$ Marcu (1997) argues that global coherence can be achieved if constraints on local coherence are satisfied.
In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). $$$$$ Investigations into the interpretation of narrative discourse (Asher and Lascarides, 2003) have shown that specific lexical information (e.g., verbs, adjectives) plays an important role in determining the discourse relations between propositions.

 $$$$$ The model in Section 2.1 was trained on the BLLIP corpus (30 M words), a collection of texts from the Wall Street Journal (years 1987-89).
 $$$$$ Thanks also to Stephen Clark, Nikiforos Karamanis, Frank Keller, Alex Lascarides, Katja Markert, and Miles Osborne for helpful comments and suggestions.

 $$$$$ The model in Section 2.1 was trained on the BLLIP corpus (30 M words), a collection of texts from the Wall Street Journal (years 1987-89).
 $$$$$ Thanks also to Stephen Clark, Nikiforos Karamanis, Frank Keller, Alex Lascarides, Katja Markert, and Miles Osborne for helpful comments and suggestions.

In contrast, the greedy algorithm of Lapata (2003) makes grave search errors. $$$$$ The input to the the greedy algorithm (see Section 2.2) was a text with a randomized sentence ordering.
In contrast, the greedy algorithm of Lapata (2003) makes grave search errors. $$$$$ The greedy algorithm implements a search procedure with a beam of width one.

The genetic algorithms of Mellish et al (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. $$$$$ As in the case of Mellish et al. (1998) we construct an acceptable ordering rather than the best possible one.
The genetic algorithms of Mellish et al (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. $$$$$ Fortunately, they propose a simple greedy algorithm that provides an approximate solution which can be easily modified for our task (see also Barzilay et al. 2002).

Adjacency of sentences has been previously used to model local coherence (Lapata, 2003). $$$$$ Marcu (1997) argues that global coherence can be achieved if constraints on local coherence are satisfied.
Adjacency of sentences has been previously used to model local coherence (Lapata, 2003). $$$$$ Subjects were recruited via postings to local between the model and each of the subjects for all features used in Experiment 1.

Corpus-based methods inspired by the notion of schemata have been explored in the past by Lapata (2003) and Barzilay and Lee (2004) for ordering sentences extracted in a multi-document summarisation application. $$$$$ Although in single document summarization the position of a sentence in a document can provide cues with respect to its ordering in the summary, this is not the case in multidocument summarization where sentences are selected from different documents and must be somehow ordered so as to produce a coherent summary (Barzilay et al., 2002).
Corpus-based methods inspired by the notion of schemata have been explored in the past by Lapata (2003) and Barzilay and Lee (2004) for ordering sentences extracted in a multi-document summarisation application. $$$$$ Finally, we assess whether this model can be used for multi-document summarization using data from Barzilay et al. (2002).

In this respect, this is similar to work by Lapata (2003), who builds a conditional model of words across adjacent sentences, focusing on words in particular semantic roles. $$$$$ The model in Section 2.1 was trained on the BLLIP corpus (30 M words), a collection of texts from the Wall Street Journal (years 1987-89).
In this respect, this is similar to work by Lapata (2003), who builds a conditional model of words across adjacent sentences, focusing on words in particular semantic roles. $$$$$ Several improvements can take place with respect to the model.

Lapata (2003) has suggested a probabilistic model of text structuring and its application to the sentence ordering. $$$$$ Probabilistic Text Structuring: Experiments With Sentence Ordering
Lapata (2003) has suggested a probabilistic model of text structuring and its application to the sentence ordering. $$$$$ In this paper we introduce an unsupervised probabilistic model for text structuring that learns ordering constraints from a large corpus.

Even though we could not compare our experiment with the probabilistic approach (Lapata, 2003) directly due to the difference of the text corpora, the Kendall coefficient reported higher agreement than Lapata's experiment (Kendall=0.48 with lemmatized nouns and Kendall=0.56 with verb-noun dependencies). $$$$$ Table 3 gives the average i (T) for all 20 test texts when the following features are used: lemmatized verbs (VL), tensed verbs (VT), lemmatized nouns (NL), lemmatized verbs and nouns (VLNL), tensed verbs and lemmatized nouns (VTNL), verb-related dependencies (VD), noun-related dependencies (ND), verb and noun dependencies (VDND), and all available dependencies (AD).
Even though we could not compare our experiment with the probabilistic approach (Lapata, 2003) directly due to the difference of the text corpora, the Kendall coefficient reported higher agreement than Lapata's experiment (Kendall=0.48 with lemmatized nouns and Kendall=0.56 with verb-noun dependencies). $$$$$ In this experiment we compare our model’s performance against human judges.

Lapata (2003) proposed an algorithm that computes the probability of two sentences being adjacent for ordering sentences. $$$$$ We express the probability of a text made up of sentences S1...Sn as shown in (1).
Lapata (2003) proposed an algorithm that computes the probability of two sentences being adjacent for ordering sentences. $$$$$ The algorithm starts by assigning each vertex v  V a probability.

Lapata (2003) employed the probability of two sentences being adjacent as determined from a corpus. $$$$$ In the training phase our model will learn these constraints from adjacent sentences represented by a set of informative features.
Lapata (2003) employed the probability of two sentences being adjacent as determined from a corpus. $$$$$ We express the probability of a text made up of sentences S1...Sn as shown in (1).

As the features, Lapata (2003) proposed the Cartesian product of content words in adjacent sentences. $$$$$ We will assume that these features are independent and that P(Si
