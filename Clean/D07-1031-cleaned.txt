[vbhmm] $$$$$ and Variational Bayes A Bayesian estimator combines a likelihood termP(x

We fixed the and parameters to 0.1, values that appeared to be reasonable based on Johnson (2007), and which were also used by Graca et al (2009). $$$$$ However, in the ad hoc approach the expected count plus ??1 may be less than zero,resulting in a value of zero for the corresponding parameter (Johnson et al, 2007; Goldwater and Grif fiths, 2007).
We fixed the and parameters to 0.1, values that appeared to be reasonable based on Johnson (2007), and which were also used by Graca et al (2009). $$$$$ (2002) and Teh et al (2006).

We evaluate on a 1-to-1 mapping between unsupervised tags and gold labels, as well as many-to-1 (M-to-1), corresponding to the evaluation mappings used in Johnson (2007). $$$$$ This section describes how we evaluate how well thesesequences of hidden states correspond to the gold standard POS tags for the training corpus (here, the PTB POS tags).
We evaluate on a 1-to-1 mapping between unsupervised tags and gold labels, as well as many-to-1 (M-to-1), corresponding to the evaluation mappings used in Johnson (2007). $$$$$ Wecan understand these results by comparing the dis tribution of words to hidden states to the distribution of words to POS tags in the gold-standard evaluation corpus.

These figures are the MCMC settings that provided the best results in Johnson (2007). $$$$$ MCMC en compasses a broad range of sampling techniques, including component-wise Gibbs sampling, which is the MCMC technique we used here (Robert and Casella, 2004; Bishop, 2006).
These figures are the MCMC settings that provided the best results in Johnson (2007). $$$$$ Interestingly, we obtained our best per formance on 1-to-1 accuracy when the Dirchlet prior?x = 0.1, a relatively large number, but best per formance on many-to-1 accuracy was achieved with a much lower value for the Dirichlet prior, namely ?x = 10?4.

There is much potential for further work in this direction, experimenting with more training data or more estimation iterations, or even looking at different estimators as suggested in Johnson (2007) and Ravi et al (2010b). $$$$$ However, in the ad hoc approach the expected count plus ??1 may be less than zero,resulting in a value of zero for the corresponding parameter (Johnson et al, 2007; Goldwater and Grif fiths, 2007).
There is much potential for further work in this direction, experimenting with more training data or more estimation iterations, or even looking at different estimators as suggested in Johnson (2007) and Ravi et al (2010b). $$$$$ (2002) and Teh et al (2006).

The overall POS tag distribution learnt by EM is relatively uniform, as noted by Johnson (2007), and it tends to assign equal number of tokens to each tag label whereas the real tag distribution is highly skewed. $$$$$ We find that the HMMs es timated by EM generally assign a roughlyequal number of word tokens to each hid den state, while the empirical distribution of tokens to POS tags is highly skewed.
The overall POS tag distribution learnt by EM is relatively uniform, as noted by Johnson (2007), and it tends to assign equal number of tokens to each tag label whereas the real tag distribution is highly skewed. $$$$$ We suggest that onereason for the apparent failure of EM for POS tagging is that it tends to assign relatively equal numbers of tokens to each hidden state, while the em pirical distribution of POS tags is highly skewed, like many linguistic (and non-linguistic) phenomena(Mitzenmacher, 2003).

Johnson (2007) and Gao & Johnson (2008) assume that words are generated by a hidden Markov model and find that the resulting states strongly correlate with POS tags. $$$$$ We call this themany-to-1 accuracy of the hidden state sequence be cause several hidden states may map to the same POS tag (and some POS tags may not be mapped to by any hidden states at all).
Johnson (2007) and Gao & Johnson (2008) assume that words are generated by a hidden Markov model and find that the resulting states strongly correlate with POS tags. $$$$$ This mapping is found by greedily assigning hidden states to POS tags until either the hidden states or POS tags are exhausted (note that if the number ofhidden states and POS tags differ, some will be unas signed).

Johnson (2007) reports results for different numbers of hidden states but it is unclear how to make this choice a priori, while Goldwater & Griffiths (2007) leave this question as future work. $$$$$ Goldwater and Griffiths (2007) propose using the Variation of Information (VI) metric described byMeila?
Johnson (2007) reports results for different numbers of hidden states but it is unclear how to make this choice a priori, while Goldwater & Griffiths (2007) leave this question as future work. $$$$$ 6 Conclusion and future work.

As Johnson (2007) clearly explained, training the HMM with EM leads to poor results in PoS tagging. $$$$$ This paper investigates why the HMMs es timated by Expectation-Maximization (EM) produce such poor results as Part-of-Speech(POS) taggers.
As Johnson (2007) clearly explained, training the HMM with EM leads to poor results in PoS tagging. $$$$$ This paper studied why EM seems to do so badly in HMM estimation for unsupervised POS tagging.

The fact that different authors use different versions of the same gold standard to evaluate similar experiments (e.g. Goldwate & Griffiths (2007) versus Johnson (2007)) supports this claim. $$$$$ This section describes how we evaluate how well thesesequences of hidden states correspond to the gold standard POS tags for the training corpus (here, the PTB POS tags).
The fact that different authors use different versions of the same gold standard to evaluate similar experiments (e.g. Goldwate & Griffiths (2007) versus Johnson (2007)) supports this claim. $$$$$ Goldwater and Griffiths (2007) propose using the Variation of Information (VI) metric described byMeila?

In particular, Toutanova and Johnson (2007) demonstrate good performance on unsupervised part-of-speech tagging (using a dictionary) with a Bayesian model similar to our own. $$$$$ Why Doesn't EM Find Good HMM POS-Taggers?
In particular, Toutanova and Johnson (2007) demonstrate good performance on unsupervised part-of-speech tagging (using a dictionary) with a Bayesian model similar to our own. $$$$$ Toutanova etal.

Johnson (2007) observed that EM tends to create word clusters of uniform size, which does not reflect the way words cluster into parts of speech in natural languages. $$$$$ Here m is the number of possible observations (i.e., the size of the vocabulary), s is the number of hidden states and I(?)
Johnson (2007) observed that EM tends to create word clusters of uniform size, which does not reflect the way words cluster into parts of speech in natural languages. $$$$$ Then we noted the distribution of words to hidden states found by EM is relatively uniform, comparedto the distribution of words to POS tags in the eval uation corpus.

We evaluated POS tagging accuracy using the lenient many-to-1 evaluation approach (Johnson, 2007). $$$$$ In this setting we show that EM performs poorlywhen evaluated using a ?1-to-1 accuracy?
We evaluated POS tagging accuracy using the lenient many-to-1 evaluation approach (Johnson, 2007). $$$$$ We call the accuracy of the POS sequence obtained using this map its 1-to-1 accuracy.

This mapping technique is based on the many-to-one scheme used for evaluating unsupervised part-of-speech induction (Johnson, 2007). $$$$$ (This ap proach cannot be used in an unsupervised setting since the empirical tag distribution is not available).
This mapping technique is based on the many-to-one scheme used for evaluating unsupervised part-of-speech induction (Johnson, 2007). $$$$$ Cross-validation, i.e., identifying themany-to-1 mapping and evaluating on different subsets of the data, would answer many of these objections.

In related fields of NLP lately Dirichlet priors have been investigated, e.g. (Johnson, 2007). $$$$$ Also, the Bayesian framework permits a wide variety of different priors besides Dirichlet priors explored here.
In related fields of NLP lately Dirichlet priors have been investigated, e.g. (Johnson, 2007). $$$$$ For example, it should be possible to encode linguistic knowledge such markedness preferences in a prior, and there are other linguistically uninformative priors, such the ?entropic priors?

 $$$$$ Since we evaluatedthe accuracy of the estimated tags after each iteration, it was important that decoding be done effi ciently as well.
 $$$$$ 303

 $$$$$ Since we evaluatedthe accuracy of the estimated tags after each iteration, it was important that decoding be done effi ciently as well.
 $$$$$ 303

 $$$$$ Since we evaluatedthe accuracy of the estimated tags after each iteration, it was important that decoding be done effi ciently as well.
 $$$$$ 303

For instance, on unsupervised part-of speech tagging, EM requires over 100 iterations to reach its peak performance on the Wall-Street Journal (Johnson, 2007). $$$$$ All of the experiments described below have the same basic structure

(Johnson, 2007) criticizes the standard EM based HMM approaches because of their poor performance on the unsupervised POS tagging and their tendency to assign equal number of words to each hidden state. $$$$$ We suggest that onereason for the apparent failure of EM for POS tagging is that it tends to assign relatively equal numbers of tokens to each hidden state, while the em pirical distribution of POS tags is highly skewed, like many linguistic (and non-linguistic) phenomena(Mitzenmacher, 2003).
(Johnson, 2007) criticizes the standard EM based HMM approaches because of their poor performance on the unsupervised POS tagging and their tendency to assign equal number of words to each hidden state. $$$$$ This paper studied why EM seems to do so badly in HMM estimation for unsupervised POS tagging.
