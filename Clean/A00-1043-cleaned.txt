 $$$$$ Input to the reduction system includes extracted sentences, as well as the original document.
 $$$$$ Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.

In fact, professional abstractors tend to use these operations to transform selected sentences from an article into the corresponding summary sentences (Jing, 2000). $$$$$ It is one of the most effective operations that can be used to edit the extracted sentences.
In fact, professional abstractors tend to use these operations to transform selected sentences from an article into the corresponding summary sentences (Jing, 2000). $$$$$ The program uses a corpus consisting of sentences reduced by human professionals and their corresponding original sentences to compute how likely humans remove a certain phrase.

For example, Jing (2000) trained her system on a set of 500 sentences from the Benton Foundation (http: //www.benton.org) and their reduced forms written by humans. $$$$$ We collected 500 sentences and their corresponding reduced forms written by humans, and found that humans reduced the length of these 500 sentences by 44.2% on average.
For example, Jing (2000) trained her system on a set of 500 sentences from the Benton Foundation (http: //www.benton.org) and their reduced forms written by humans. $$$$$ The human-written abstracts were collected from the free daily news service &quot;Communicationsrelated headlines&quot;, provided by the Benton Foundation (http://www.benton.org).

Examples include text summarisation (Jing 2000), subtitle generation from spoken transcripts (Vandeghinste and Pan 2004) and information retrieval (Olivers and Dolan 1999). $$$$$ (Corston-Oliver and Dolan, 1999) proposed to remove clauses in sentences before indexing documents for Information Retrieval.
Examples include text summarisation (Jing 2000), subtitle generation from spoken transcripts (Vandeghinste and Pan 2004) and information retrieval (Olivers and Dolan 1999). $$$$$ (Corston-Oliver and Dolan, 1999) proposed to remove clauses in sentences before indexing documents for Information Retrieval.

Jing (2000) was perhaps the first to tackle the sentence compression problem. $$$$$ We analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences (Jing and McKeown, 1999; Jing and McKeown, 2000).
Jing (2000) was perhaps the first to tackle the sentence compression problem. $$$$$ Other researchers worked on the text simplification problem, which usually involves in simplifying text but not removing any phrases.

Our constraints are linguistically and semantically motivated in a similar fashion to the grammar checking component of Jing (2000). $$$$$ We use the English Slot Grammar(ESG) parser developed at IBM (McCord, 1990) to analyze the syntactic structure of an input sentence and produce a sentence parse tree.
Our constraints are linguistically and semantically motivated in a similar fashion to the grammar checking component of Jing (2000). $$$$$ Step 2: Grammar checking.

Jing and McKeown (H. Jing, 2000) studied a new method to remove extraneous phrase from sentences by using multiple source of knowledge to decide which phrase in the sentences can be removed. $$$$$ We analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences (Jing and McKeown, 1999; Jing and McKeown, 2000).
Jing and McKeown (H. Jing, 2000) studied a new method to remove extraneous phrase from sentences by using multiple source of knowledge to decide which phrase in the sentences can be removed. $$$$$ Besides computing the probability that a phrase is removed, we also compute two other types of probabilities: the probability that a phrase is reduced (i.e., the phrase is not removed as a whole, but some components in the phrase are removed), and the probability that a phrase is unchanged at all (i.e., neither removed nor reduced).

Sentence compression is the task of producing a shorter form of a single given sentence, so that the new form is grammatical and retains the most important information of the original one (Jing, 2000). $$$$$ The deleted phrases can be prepositional phrases, clauses, to-infinitives, or gerunds, and multiple phrases can be removed form a single sentence.
Sentence compression is the task of producing a shorter form of a single given sentence, so that the new form is grammatical and retains the most important information of the original one (Jing, 2000). $$$$$ The following example shows an original sentence and its reduced form written by a human professional: Original sentence: When it arrives sometime next year in new TV sets, the V-chip will give parents a new and potentially revolutionary device to block out programs they don't want their children to see.

Sentence compression is the task of summarizing a sentence while retaining most of the informational content and remaining grammatical (Jing, 2000). $$$$$ We analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences (Jing and McKeown, 1999; Jing and McKeown, 2000).
Sentence compression is the task of summarizing a sentence while retaining most of the informational content and remaining grammatical (Jing, 2000). $$$$$ In this step, we determine which components of a sentence must not be deleted to keep the sentence grammatical.

Sentence compression is the task of producing a shorter form of a grammatical source (input) sentence, so that the new form will still be grammatical and it will retain the most important information of the source (Jing, 2000). $$$$$ The following example shows an original sentence and its reduced form written by a human professional: Original sentence: When it arrives sometime next year in new TV sets, the V-chip will give parents a new and potentially revolutionary device to block out programs they don't want their children to see.
Sentence compression is the task of producing a shorter form of a grammatical source (input) sentence, so that the new form will still be grammatical and it will retain the most important information of the source (Jing, 2000). $$$$$ In this step, we determine which components of a sentence must not be deleted to keep the sentence grammatical.

The evaluation of sentence reduction (see (Jing, 2000) for details) used a corpus of 500 sentences and their reduced forms in human-written abstracts. $$$$$ We also created a corpus consisting of 500 sentences and their reduced forms produced by human professionals, and used this corpus for training and testing the system.
The evaluation of sentence reduction (see (Jing, 2000) for details) used a corpus of 500 sentences and their reduced forms in human-written abstracts. $$$$$ We also created a corpus consisting of 500 sentences and their reduced forms produced by human professionals, and used this corpus for training and testing the system.

To overcome this problem, linguistic parsing and generation systems are used in the sentence condensation approaches of Knight and Marcu (2000) and Jing (2000). $$$$$ We analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences (Jing and McKeown, 1999; Jing and McKeown, 2000).
To overcome this problem, linguistic parsing and generation systems are used in the sentence condensation approaches of Knight and Marcu (2000) and Jing (2000). $$$$$ For example, PP attachment is a difficult problem in parsing and it is not rare that a PP is wrongly attached.

Jing (2000) was perhaps the first to tackle the sentence compression problem. $$$$$ We analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences (Jing and McKeown, 1999; Jing and McKeown, 2000).
Jing (2000) was perhaps the first to tackle the sentence compression problem. $$$$$ Other researchers worked on the text simplification problem, which usually involves in simplifying text but not removing any phrases.

Table 5 shows a 5 sentence summary created using algorithm 1 for the paper A00-1043 (Jing, 2000). $$$$$ In the next section, we describe the sentence reduction algorithm in details.
Table 5 shows a 5 sentence summary created using algorithm 1 for the paper A00-1043 (Jing, 2000). $$$$$ This corpus was created using an automatic program we have developed to automatically analyze human-written abstracts.

To overcome this problem, linguistic parsing and generation systems are used in the sentence condensation approaches of Knight and Marcu (2000) and Jing (2000). In these approaches, decisions about which material to include/delete in the sentence summaries do not rely on relative frequency information on words, but rather on probability models of subtree deletions that are learned from a corpus of parses for sentences and their summaries. $$$$$ Current automatic summarizers usually rely on sentence extraction to produce summaries.
To overcome this problem, linguistic parsing and generation systems are used in the sentence condensation approaches of Knight and Marcu (2000) and Jing (2000). In these approaches, decisions about which material to include/delete in the sentence summaries do not rely on relative frequency information on words, but rather on probability models of subtree deletions that are learned from a corpus of parses for sentences and their summaries. $$$$$ Output of reduction are reduced forms of the extracted sentences, which can either be used to produce summaries directly, or be merged with other sentences.

In addition, an automatic evaluation method based on context-free deletion decisions has been proposed by Jing (2000). $$$$$ Sentence Reduction For Automatic Text Summarization
In addition, an automatic evaluation method based on context-free deletion decisions has been proposed by Jing (2000). $$$$$ We implemented an automatic sentence reduction system.

Sentence compression produces a summary of a single sentence that retains the most important information while remaining grammatical (Jing, 2000). $$$$$ In this step, we determine which components of a sentence must not be deleted to keep the sentence grammatical.
Sentence compression produces a summary of a single sentence that retains the most important information while remaining grammatical (Jing, 2000). $$$$$ The reduction algorithm we present assumes generic summarization; that is, we want to generate a summary that includes the most important information in an article.

A syntactic approach considers the alignment over parse trees (Jing, 2000), and a similar technique has been used with dependency trees to evaluate the quality of sentence fusions (Marsi and Krahmer, 2005). $$$$$ It then marked which subtrees in these parse trees (i.e., phrases in the sentences) were removed by humans.
A syntactic approach considers the alignment over parse trees (Jing, 2000), and a similar technique has been used with dependency trees to evaluate the quality of sentence fusions (Marsi and Krahmer, 2005). $$$$$ Using this corpus of marked parse trees, we can compute how likely a subtree is removed from its parent node.
