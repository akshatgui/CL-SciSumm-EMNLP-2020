Besides the increasing availability of an notation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al, 2003b)), the community has also organized three successful evaluation workshops TempEval1 (Verhagen et al, 2009), -2 (Verhagen et al, 2010), and-3 (Uzzaman et al, 2013). $$$$$ The 2007 SemEval task, TempEval-1 (Verhagen et al., 2007; Verhagen et al., 2009), was an initial evaluation exercise based on three limited temporal ordering and anchoring tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.1 TempEval-2 is based on TempEval-1, but is more elaborate in two respects

Following the "divide-and-conquer" approach described in Verhagen et al (2010), results from the three temporal processing steps $$$$$ F. Determine the temporal relation between two events where one event syntactically dominates the other event.
Following the "divide-and-conquer" approach described in Verhagen et al (2010), results from the three temporal processing steps $$$$$ All corpora include event and timex annotation.

We evaluate our model on all six languages in the TempEval2 Task A dataset (Verhagen et al, 2010), comparing against state-of-the-art systems for English and Spanish. $$$$$ The 2007 SemEval task, TempEval-1 (Verhagen et al., 2007; Verhagen et al., 2009), was an initial evaluation exercise based on three limited temporal ordering and anchoring tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.1 TempEval-2 is based on TempEval-1, but is more elaborate in two respects

Part of our task is similar to task C of TempEval-2 (Verhagen et al 2010), determining the temporal relation between an event and a time expression in the same sentence. $$$$$ Task participants could choose to either do all tasks, focus on the time expression task, focus on the event task, or focus on the four temporal relation tasks.
Part of our task is similar to task C of TempEval-2 (Verhagen et al 2010), determining the temporal relation between an event and a time expression in the same sentence. $$$$$ However, we had expected that for TempEval-2 the systems would score better on task C since we added the restriction that the event and time expression had to be syntactically adjacent.

We also evaluated our system on TempEval 2 (Verhagen et al 2010) for better comparison to the state-of-the-art. $$$$$ The 2007 SemEval task, TempEval-1 (Verhagen et al., 2007; Verhagen et al., 2009), was an initial evaluation exercise based on three limited temporal ordering and anchoring tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.1 TempEval-2 is based on TempEval-1, but is more elaborate in two respects

We evaluate our model against current state-of-the art systems for temporal resolution on the English portion of the TempEval-2 Task A dataset (Verhagen et al, 2010). $$$$$ SemEval-2010 Task 13

This task is based on task A in the TempEval-2 challenge (Verhagen et al, 2010). $$$$$ SemEval-2010 Task 13

There has been much work addressing the problems of temporal expression extraction and normalization, i.e. the systems developed in TempEval-2 challenge (Verhagen et al, 2010). $$$$$ However, addressing this aim is beyond the scope of an evaluation challenge and a more modest approach is appropriate.
There has been much work addressing the problems of temporal expression extraction and normalization, i.e. the systems developed in TempEval-2 challenge (Verhagen et al, 2010). $$$$$ The 2007 SemEval task, TempEval-1 (Verhagen et al., 2007; Verhagen et al., 2009), was an initial evaluation exercise based on three limited temporal ordering and anchoring tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.1 TempEval-2 is based on TempEval-1, but is more elaborate in two respects

In recent years a renewed interest in temporal processing has spread in the NLP community, thanks to the success of the TimeML annotation scheme (Pustejovsky et al, 2003a) and to the availability of annotated resources, such as the English and French TimeBanks (Pustejovsky et al., 2003b; Bittar, 2010) and the TempEval corpora (Verhagen et al, 2010). $$$$$ The 2007 SemEval task, TempEval-1 (Verhagen et al., 2007; Verhagen et al., 2009), was an initial evaluation exercise based on three limited temporal ordering and anchoring tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.1 TempEval-2 is based on TempEval-1, but is more elaborate in two respects

TempEval (Verhagen et al 2007), in 2007, and more recently TempEval-2 (Verhagen et al 2010), in 2010, were concerned with this problem. $$$$$ The 2007 SemEval task, TempEval-1 (Verhagen et al., 2007; Verhagen et al., 2009), was an initial evaluation exercise based on three limited temporal ordering and anchoring tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.1 TempEval-2 is based on TempEval-1, but is more elaborate in two respects

The results of TempEval-2 are fairly similar (Verhagen et al 2010), but the data used are similar but not identical. $$$$$ The 2007 SemEval task, TempEval-1 (Verhagen et al., 2007; Verhagen et al., 2009), was an initial evaluation exercise based on three limited temporal ordering and anchoring tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.1 TempEval-2 is based on TempEval-1, but is more elaborate in two respects
