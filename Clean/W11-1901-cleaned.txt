This paper describes our entry to the 2011 CoNLL closed task (Pradhan et al, 2011) on modeling unrestricted coreference in OntoNotes. $$$$$ CoNLL-2011 Shared Task

We have updated the publicly available CoNLL coreference scorer 1 with the proposed BLANC, and used it to compute the proposed BLANC scores for all the CoNLL 2011 (Pradhan et al, 2011) and 2012 (Pradhan et al, 2012) participant sin the official track, where participants had to automatically predict the mentions. $$$$$ The CoNLL-2005 scorer was used to generate the scores.
We have updated the publicly available CoNLL coreference scorer 1 with the proposed BLANC, and used it to compute the proposed BLANC scores for all the CoNLL 2011 (Pradhan et al, 2011) and 2012 (Pradhan et al, 2012) participant sin the official track, where participants had to automatically predict the mentions. $$$$$ Very recently BLANC (BiLateral Assessment of NounPhrase Coreference) measure (Recasens and Hovy, 17as is the case in this evaluation with Gold Mentions 2011) has been proposed as well.

The proposed BLANC is highly positively correlated with the 1http $$$$$ One of the many goals of the OntoNotes project2 (Hovy et al., 2006; Weischedel et al., 2011) is to explore whether it can fill this void and help push the progress further – not only in coreference, but with the various layers of semantics that it tries to capture.
The proposed BLANC is highly positively correlated with the 1http $$$$$ It can seem to be a very hard problem (Soon et al., 2001) or one that is somewhat easier (Culotta et al., 2007).

We follow the CoNLL2011 scheme to select TRAIN, DEV and TEST datasets (Pradhan et al,2011). $$$$$ It can seem to be a very hard problem (Soon et al., 2001) or one that is somewhat easier (Culotta et al., 2007).
We follow the CoNLL2011 scheme to select TRAIN, DEV and TEST datasets (Pradhan et al,2011). $$$$$ Since there are no previously reported numbers on the full version of OntoNotes, we had to create a train/development/test partition.

(Pradhan et al, 2011) presents challenges that go beyond previous definitions of the task. $$$$$ Section 2 presents an overview of the OntoNotes corpus.
(Pradhan et al, 2011) presents challenges that go beyond previous definitions of the task. $$$$$ It can seem to be a very hard problem (Soon et al., 2001) or one that is somewhat easier (Culotta et al., 2007).

An overview of all systems participating in the CONLL-2011 shared task and their results is provided by Pradhan et al (2011). $$$$$ CoNLL-2011 Shared Task

In this paper we present SUCRE (Kobdani and Schutze, 2010) that is a modular coreference resolution system participating in theCoNLL-2011 Shared Task $$$$$ CoNLL-2011 Shared Task

This paper describes our coreference resolution system participating in the close track of CoNLL 2011 shared task (Pradhan et al, 2011). $$$$$ CoNLL-2011 Shared Task

The most frequent one is the constituent's head that solvers need then to extract using ad-hoc rules; see the CoNLL 2011 shared task (Pradhan et al, 2011), for instance. $$$$$ CoNLL-2011 Shared Task

Our system builds on an earlier system that we evaluated in the CoNLL 2011 shared task (Pradhan et al, 2011), where we optimized significantly the solver code, most notably the mention detection step and the feature design. $$$$$ CoNLL-2011 Shared Task

The CoNLL 2011 Shared Task (Pradhan et al,2011) is dedicated to modeling unrestricted coreference in OntoNotes. $$$$$ CoNLL-2011 Shared Task

Both the CoNLL-2011 (Pradhan et al, 2011) and CoNLL 2012 (Pradhan et al, 2012) shared tasks focus on resolving coreference on the OntoNotes corpus. $$$$$ CoNLL-2011 Shared Task

a) Non-anaphoric detection modules b) Pronominal resolution module The data used for training as well as testing was provided CoNLL-2001 shared task (Pradhan et al, 2011), (Pradhan et al, 2007) organizers. $$$$$ Significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (Morton, 2000; Harabagiu et al., 2001; McCallum and Wellner, 2004; Culotta et al., 2007; Denis and Baldridge, 2007; Rahman and Ng, 2009; Haghighi and Klein, 2010).
a) Non-anaphoric detection modules b) Pronominal resolution module The data used for training as well as testing was provided CoNLL-2001 shared task (Pradhan et al, 2011), (Pradhan et al, 2007) organizers. $$$$$ It can seem to be a very hard problem (Soon et al., 2001) or one that is somewhat easier (Culotta et al., 2007).

Plenty of machine learning algorithms such as Decision tree (Ng and Cardie,2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. Meanwhile, the CoNLL-2011 shared task on English language show that a well-designed rule-based approach can achieve a comparable performance as a statistical one (Pradhan et al, 2011). $$$$$ CoNLL-2011 Shared Task

This paper describes the coreference resolution system used by Stanford at the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ CoNLL-2011 Shared Task

This was the official metric in the CoNLL-2011 shared task (Pradhan et al2011). We followed the CoNLL-2011 evaluation methodology, that is, we removed all singleton clusters, and apposition/copular relations before scoring. We evaluated the systems on three different settings $$$$$ CoNLL-2011 Shared Task

While models other than mention-pair have been proposed (Culotta et al, 2007), none performs clearly better as evidenced by recent shared evaluations such as SemEval 2010 (Recasens et al, 2010) and CoNLL 2011 (Pradhan et al, 2011). $$$$$ A small portion of this corpus from the newswire and broadcast news genres (-120k) was recently used for a SEMEVAL task (Recasens et al., 2010).
While models other than mention-pair have been proposed (Culotta et al, 2007), none performs clearly better as evidenced by recent shared evaluations such as SemEval 2010 (Recasens et al, 2010) and CoNLL 2011 (Pradhan et al, 2011). $$$$$ It can seem to be a very hard problem (Soon et al., 2001) or one that is somewhat easier (Culotta et al., 2007).

We applied this solver to the closed track of the CoNLL 2011 shared task (Pradhan et al,2011). $$$$$ CoNLL-2011 Shared Task

This task (Pradhan et al, 2011) has set a harder challenge by only considering exact matches to be correct. $$$$$ One of the many goals of the OntoNotes project2 (Hovy et al., 2006; Weischedel et al., 2011) is to explore whether it can fill this void and help push the progress further – not only in coreference, but with the various layers of semantics that it tries to capture.
This task (Pradhan et al, 2011) has set a harder challenge by only considering exact matches to be correct. $$$$$ It can seem to be a very hard problem (Soon et al., 2001) or one that is somewhat easier (Culotta et al., 2007).

In this paper, we present a learning approach to coreference resolution of named entities (NE), pronouns (PRP), noun phrases (NP) in unrestricted text according to the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ CoNLL-2011 Shared Task
