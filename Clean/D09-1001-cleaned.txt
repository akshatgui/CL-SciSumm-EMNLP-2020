Take the following example from Poon and Domingos (2009), in which the same semantic relation can be expressed by a transitive verb or an attributive prepositional phrase: (1) Utah borders Idaho. $$$$$ For example, the aforementioned sentence can be rephrased as “Utah is next to Idaho,”“Utah shares a border with Idaho,” etc.
Take the following example from Poon and Domingos (2009), in which the same semantic relation can be expressed by a transitive verb or an attributive prepositional phrase: (1) Utah borders Idaho. $$$$$ For example, to express the meaning that Utah borders Idaho, we can use any form in the cluster representing the next-to relation (e.g., “borders”, “shares a border with”), any form in the cluster representing the state of Utah (e.g., “the beehive state”), and any form in the cluster representing the state of Idaho (e.g., “Idaho”).

To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ Unsupervised Semantic Parsing
To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic.

We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ The second one (KW-SYN) is informed by syntax: the answer is extracted from the subject or object of the verb, depending on the question.
We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ It obtained the highest accuracy at 88%, and the number of correct answers it extracted is three times that of the second highest system.

More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ Even an efficient sampler like MC-SAT (Poon and Domingos, 2006), as used in Poon & Domingos (2008), would have a hard time generating accurate estimates within a reasonable amount of time.
More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ RESOLVER: RESOLVER (Yates and Etzioni, 2009) inputs TextRunner triples and collectively resolves coreferent relation and argument strings.

On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ Unsupervised Semantic Parsing
On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ This paper introduces the first unsupervised approach to learning semantic parsers.

Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ The semantic parse of a sentence is derived by starting with logical forms in the lexical entries and recursively composing the meaning of larger fragments from their parts.
Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ In particular, lexical entries are no longer limited to be adjacent words as in Zettlemoyer and Collins (2005), but can be arbitrary fragments in a dependency tree.

Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ To model distributions over lambda forms, we introduce the predicates Form(p, f!) and ArgForm(p, i, f!
Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ The first formula models the mixture of core forms given the cluster, and the others model the mixtures of argument forms, argument types, and argument numbers, respectively, given the argument type.

In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets: for example, the MLN model induces 18,543 distinct clusters from 18,471 sentences of the GENIA corpus (Poon and Domingos, 2009). $$$$$ Each lambda-form cluster may contain some number of argument types, which cluster distinct forms of the same argument in a relation.
In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets: for example, the MLN model induces 18,543 distinct clusters from 18,471 sentences of the GENIA corpus (Poon and Domingos, 2009). $$$$$ On the GENIA data, using the default parameters, RESOLVER produces only a few trivial relation clusters and no argument clusters.

In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ We evaluate our approach by using it to extract a knowledge base from biomedical abstracts and answer questions.
In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ In this paper, we applied USP to extracting knowledge from biomedical abstracts and evaluated its performance in answering a set of questions that simulate the information needs of biomedical researchers.

Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in (Poon and Domingos, 2009). $$$$$ Compared to phrase-structure syntax, dependency trees are the more appropriate starting point for semantic processing, as they already exhibit much of the relation-argument structure at the lexical level.
Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in (Poon and Domingos, 2009). $$$$$ The first formula models the mixture of core forms given the cluster, and the others model the mixtures of argument forms, argument types, and argument numbers, respectively, given the argument type.

Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them.
Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ Lambda-form clusters abstract away syntactic variations of the same meaning.

The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ In this paper we develop the first unsupervised approach to semantic parsing, using Markov logic (Richardson and Domingos, 2006).
The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ One of the most powerful representations for this is Markov logic, which is a probabilistic extension of first-order logic (Richardson and Domingos, 2006).

In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ To address this problem, we impose local normalization constraints on specific groups of formulas that are mutually exclusive and exhaustive, i.e., in each group, we require that Eki=1 ewi = 1, where wi are the weights of formulas in the group.
In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ Specifically, for the rule p E +c n Form(p,+f), all instances given a fixed c form a group; for each of the remaining three rules, all instances given a fixed a form a group.

We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task.
We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ Finally, we present our experiments and results.

Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ The standard language for formal meaning representation is first-order logic.
Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ Existing approaches differ in the meaning representation languages they use and the amount of annotation required.

USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic.
USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ In this paper we develop the first unsupervised approach to semantic parsing, using Markov logic (Richardson and Domingos, 2006).

Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ We then describe our Markov logic network for unsupervised semantic parsing, and the learning and inference algorithms we used.
Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ Finally, we present the Markov logic network (MLN) used by USP.

Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ In general, this is a difficult open problem that only recently has started to receive some attention (Mohammad et al., 2008).
Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ Resolving this is not the focus of this paper, but we describe a general heuristic for fixing this problem.

Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ Unsupervised approaches have been applied to shallow semantic tasks (e.g., paraphrasing (Lin and Pantel, 2001), information extraction (Banko et al., 2007)), but not to semantic parsing.
Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ In the past, unsupervised approaches have been applied to some semantic tasks, but not to semantic parsing.

Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ For larger k and m, this is very expensive.
Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ To simulate the real information need, we sample the relations from the 100 most frequently used verbs (excluding the auxiliary verbs be, have, and do), and sample the entities from those annotated in GENIA, both according to their numbers of occurrences.
