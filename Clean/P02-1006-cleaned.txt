Ravichandran and Hovy (2002) present an alternative ontology for type preference and describe a method for using this alternative ontology to extract particular answers using surface text patterns. $$$$$ Learning Surface Text Patterns For A Question Answering System
Ravichandran and Hovy (2002) present an alternative ontology for type preference and describe a method for using this alternative ontology to extract particular answers using surface text patterns. $$$$$ Using a named entity tagger and/or an ontology would enable the system to use the knowledge that “background” is not a location.

The benefit of utilizing template-based inference rules between predicates was demonstrated in NLP tasks such as Question Answering (QA) (Ravichandran and Hovy, 2002) and Information Extraction (IE) (Shinyama and Sekine, 2006). $$$$$ Learning Surface Text Patterns For A Question Answering System
The benefit of utilizing template-based inference rules between predicates was demonstrated in NLP tasks such as Question Answering (QA) (Ravichandran and Hovy, 2002) and Information Extraction (IE) (Shinyama and Sekine, 2006). $$$$$ Similar techniques have been investigated extensively in the field of information extraction (Riloff, 96).

Automatic pattern derivation is more appealing (Ravichandran and Hovy, 2002). $$$$$ We describe the pattern-learning algorithm with an example.
Automatic pattern derivation is more appealing (Ravichandran and Hovy, 2002). $$$$$ The pattern table for each of these question types was constructed using Algorithm 1.

Ravichandran and Hovy (2002) presents a method that learns patterns from online data using some seed questions and answer anchors. $$$$$ Using the patterns to answer a new question we employ the following algorithm:
Ravichandran and Hovy (2002) presents a method that learns patterns from online data using some seed questions and answer anchors. $$$$$ Since the answer patterns used in this method are learned using only a small number of manual training terms, one can rapidly learn patterns for new languages, assuming the web search engine is appropriately switched.

Indeed, many researchers have recently tapped the Web as a data-source for improving performance on NLP tasks (e.g., Resnik (1999), Ravichandran and Hovy (2002), Keller and Lapata (2003)). $$$$$ The results indicate that the system performs better on the Web data than on the TREC corpus.
Indeed, many researchers have recently tapped the Web as a data-source for improving performance on NLP tasks (e.g., Resnik (1999), Ravichandran and Hovy (2002), Keller and Lapata (2003)). $$$$$ The abundance of data on the web makes it easier for the system to locate answers with high precision scores (the system finds many examples of correct answers among the top 20 when using the Web as the input source).

Other work such as Ravichandran and Hovy (2002) and Pantel and Pennacchiotti (2006) use the same formalism of learning regular expressions over words and part-of-speech tags to discover patterns indicating a variety of relations. $$$$$ In this paper we present an approach for automatically learning such regular expressions (along with determining their precision) from the web, for given types of questions.
Other work such as Ravichandran and Hovy (2002) and Pantel and Pennacchiotti (2006) use the same formalism of learning regular expressions over words and part-of-speech tags to discover patterns indicating a variety of relations. $$$$$ It cannot work for types of question that require multiple words from the question to be in the answer sentence, possibly apart from each other.

To do so, Espresso uses a slight modification of the state of the art algorithm described in (Ravichandran and Hovy, 2002). $$$$$ We describe the pattern-learning algorithm with an example.
To do so, Espresso uses a slight modification of the state of the art algorithm described in (Ravichandran and Hovy, 2002). $$$$$ The precision of the patterns obtained from one QA-pair example in algorithm 1 is calculated from the documents obtained in algorithm 2 for other examples of the same question type.

Ravichandran and Hovy (2002) proposed automatically learning surface text patterns for answer extraction. $$$$$ Learning Surface Text Patterns For A Question Answering System
Ravichandran and Hovy (2002) proposed automatically learning surface text patterns for answer extraction. $$$$$ In order to obtain an optimal set of patterns, we have developed a method for learning such patterns automatically.

But it is almost impossible to learn such surface text patterns following (Ravichandran and Hovy, 2002). $$$$$ Learning Surface Text Patterns For A Question Answering System
But it is almost impossible to learn such surface text patterns following (Ravichandran and Hovy, 2002). $$$$$ To learn from such variations, in step 1 of Algorithm 1 we specify the various ways in which the question term could be specified in the text.

For the special case of Rote extractors, a more attractive alternative has been proposed by Brin (1998), Agichtein and Gravano (2000), and Ravichandran and Hovy (2002). $$$$$ In the first case, the TREC corpus was used as the input source and IR was performed by the IR component of our QA system (Lin, 2002).
For the special case of Rote extractors, a more attractive alternative has been proposed by Brin (1998), Agichtein and Gravano (2000), and Ravichandran and Hovy (2002). $$$$$ In the second case, the web was the input source and the IR was performed by the AltaVista search engine.

 $$$$$ Since the answer patterns used in this method are learned using only a small number of manual training terms, one can rapidly learn patterns for new languages, assuming the web search engine is appropriately switched.
 $$$$$ This work was supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program under contract number MDA908-02-C-0007.

Most approaches to automatic pattern generation have focused on precision, e.g., Ravichandran and Hovy (2002) report results in the Text Retrieval Conference (TREC) Question Answering track, where extracting one text of a relation instance can be sufficient, rather than detecting all texts. $$$$$ Learning Surface Text Patterns For A Question Answering System
Most approaches to automatic pattern generation have focused on precision, e.g., Ravichandran and Hovy (2002) report results in the Text Retrieval Conference (TREC) Question Answering track, where extracting one text of a relation instance can be sufficient, rather than detecting all texts. $$$$$ Using the TREC-10 question set, we report results for two cases: answers determined from the TREC-10 corpus and from the web.

 $$$$$ Since the answer patterns used in this method are learned using only a small number of manual training terms, one can rapidly learn patterns for new languages, assuming the web search engine is appropriately switched.
 $$$$$ This work was supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program under contract number MDA908-02-C-0007.

Inference rules for predicates have been identified as an important component in semantic applications, such as Question Answering (QA) (Ravichandran and Hovy, 2002) and Information Extraction (IE) (Shinyama and Sekine, 2006). $$$$$ Learning Surface Text Patterns For A Question Answering System
Inference rules for predicates have been identified as an important component in semantic applications, such as Question Answering (QA) (Ravichandran and Hovy, 2002) and Information Extraction (IE) (Shinyama and Sekine, 2006). $$$$$ In the first case, the TREC corpus was used as the input source and IR was performed by the IR component of our QA system (Lin, 2002).

Ravichandran and Hovy (2002) focus on scaling relation extraction to the Web. $$$$$ Similar techniques have been investigated extensively in the field of information extraction (Riloff, 96).
Ravichandran and Hovy (2002) focus on scaling relation extraction to the Web. $$$$$ The abundance of data on the web makes it easier for the system to locate answers with high precision scores (the system finds many examples of correct answers among the top 20 when using the Web as the input source).

We chose the state of the art algorithm described in (Ravichandran and Hovy 2002) with the following slight modification. $$$$$ A table of patterns is constructed for each individual question type by the following procedure (Algorithm 1).
We chose the state of the art algorithm described in (Ravichandran and Hovy 2002) with the following slight modification. $$$$$ Using the patterns to answer a new question we employ the following algorithm:

In (Ravichandran and Hovy 2002), a frequency threshold on the patterns in P is set to select the final patterns. $$$$$ In order to obtain an optimal set of patterns, we have developed a method for learning such patterns automatically.
In (Ravichandran and Hovy 2002), a frequency threshold on the patterns in P is set to select the final patterns. $$$$$ We then test the patterns learned by our system on new unseen questions from the TREC-10 set and evaluate their results to determine the precision of the patterns.

RH02: The algorithm by Ravichandran and Hovy (2002) described in Section 2. $$$$$ We describe the pattern-learning algorithm with an example.
RH02: The algorithm by Ravichandran and Hovy (2002) described in Section 2. $$$$$ The precision of the patterns obtained from one QA-pair example in algorithm 1 is calculated from the documents obtained in algorithm 2 for other examples of the same question type.

These patterns could be manually generated, such as the ones described here, or learned from text, as described in Ravichandran and Hovy (2002). $$$$$ Learning Surface Text Patterns For A Question Answering System
These patterns could be manually generated, such as the ones described here, or learned from text, as described in Ravichandran and Hovy (2002). $$$$$ The rather long list of patterns obtained would have been very difficult for any human to come up with manually.

Ravichandran and Hovy (2002) used seed instances of a relation to automatically obtain surface patterns by querying the web. $$$$$ Learning Surface Text Patterns For A Question Answering System
Ravichandran and Hovy (2002) used seed instances of a relation to automatically obtain surface patterns by querying the web. $$$$$ In order to obtain an optimal set of patterns, we have developed a method for learning such patterns automatically.
