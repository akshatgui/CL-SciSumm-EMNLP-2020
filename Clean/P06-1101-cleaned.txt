Recently, Snow, Jurafsky and Ng (2005) generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet (Snow et al, 2006). $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
Recently, Snow, Jurafsky and Ng (2005) generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet (Snow et al, 2006). $$$$$ First, we identify the set of all the word pairs (i, j) over which we have hypernym and/or coordinate evidence, and which might represent additions of a novel hyponym to the WordNet 2.1 taxonomy (i.e., that has a known noun hypernym and an unknown hyponym, or has a known noun coordinate term and an unknown coordinate term).

Following Snow et al (2006), we derive two types of evidence from these patterns $$$$$ For example, evidence for the hypernym relation EHij might be the set of all observed lexico-syntactic patterns containing i and j in all sentences in some corpus.
Following Snow et al (2006), we derive two types of evidence from these patterns $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).

 $$$$$ Rion Snow is supported by an NDSEG Fellowship sponsored by the DOD and AFOSR.
 $$$$$ This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.

Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al, 2006), tools and corpora. $$$$$ We evaluate the quality of our acquired hyponyms by direct judgment.
Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al, 2006), tools and corpora. $$$$$ In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).

We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). $$$$$ In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).

Snow et al (Snow et al, 2006) use known hypernym / hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns. $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
Snow et al (Snow et al, 2006) use known hypernym / hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns. $$$$$ In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).

Snow (Snow et al, 2006) has extended the Word Net 2.1 by adding thousands of entries (synsets) at a relatively high precision. $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
Snow (Snow et al, 2006) has extended the Word Net 2.1 by adding thousands of entries (synsets) at a relatively high precision. $$$$$ We see that our joint algorithm strongly outperforms the baseline, and has high precision for predicting novel hyponyms up to 10,000 links.

 $$$$$ Rion Snow is supported by an NDSEG Fellowship sponsored by the DOD and AFOSR.
 $$$$$ This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.

Snow et al (2006) add novel terms by greedily maximizing the conditional probability of a set of relational evidence given a taxonomy. $$$$$ In section 2.1 we introduce our definitions for taxonomies, relations, and the taxonomic constraints that enforce dependencies between relations; in section 2.2 we give a probabilistic model for defining the conditional probability of a set of relational evidence given a taxonomy; in section 2.3 we formulate a local search algorithm to find the taxonomy maximizing this conditional probability; and in section 2.4 we extend our framework to deal with lexical ambiguity.
Snow et al (2006) add novel terms by greedily maximizing the conditional probability of a set of relational evidence given a taxonomy. $$$$$ Applying these two independence assumptions we may express the conditional probability of our evidence given the taxonomy

Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hyponyms (Hearst, 1992), meronyms (Girju, 2003), synonyms (Lin et al., 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al., 2003).
Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).

The work by Snow et al (2006) is the most similar to ours because they also took an incremental approach to construct taxonomies. $$$$$ Past work on semantic taxonomy induction includes the noun hypernym hierarchy created in (Caraballo, 2001), the part-whole taxonomies in (Girju, 2003), and a great deal of recent work described in (Buitelaar et al., 2005).
The work by Snow et al (2006) is the most similar to ours because they also took an incremental approach to construct taxonomies. $$$$$ In that work an efficient randomized algorithm is derived for computing clusters of similar nouns.

We compare system performance between (Snow et al, 2006) and our framework in Section 5. $$$$$ In section 2.1 we introduce our definitions for taxonomies, relations, and the taxonomic constraints that enforce dependencies between relations; in section 2.2 we give a probabilistic model for defining the conditional probability of a set of relational evidence given a taxonomy; in section 2.3 we formulate a local search algorithm to find the taxonomy maximizing this conditional probability; and in section 2.4 we extend our framework to deal with lexical ambiguity.
We compare system performance between (Snow et al, 2006) and our framework in Section 5. $$$$$ We measured the performance of both our inferred taxonomies and WordNet against this test set.8 The performance and comparison of the best WordNet classifier vs. our taxonomies is given in Table 4.


An extension to WordNet was presented by (Snow et al, 2006). $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
An extension to WordNet was presented by (Snow et al, 2006). $$$$$ We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.

Snow et al (2006) use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, whose training examples are derived automatically from WordNet. $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
Snow et al (2006) use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, whose training examples are derived automatically from WordNet. $$$$$ The labeled training set is constructed by labeling the collected feature vectors as positive “known hypernym” or negative “known non-hypernym” examples using WordNet 2.0; 49,922 feature vectors were labeled as positive training examples, and 800,828 noun pairs were labeled as negative training examples.

Following the spirit of the fine-grained human evaluation in (Snow et al, 2006), we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above. $$$$$ Finally, in section 4.5 we evaluate the taxonomies inferred by our algorithm directly against the WordNet 2.1 taxonomy; we perform this evaluation by testing each taxonomy on a set of human judgments of hypernym and non-hypernym noun pairs sampled from newswire text.
Following the spirit of the fine-grained human evaluation in (Snow et al, 2006), we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above. $$$$$ In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).

We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al, 2006)). $$$$$ Further, we assume that each item of observed evidence ERij depends on the taxonomy T only by way of the corresponding relation Rij, i.e., For example, if our evidence EHij is a set of observed lexico-syntactic patterns indicative of hypernymy between two words i and j, we assume that whatever dependence the relations in T have on our observations may be explained entirely by dependence on the existence or non-existence of the single hypernym relation H(i, j).
We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al, 2006)). $$$$$ From the resulting dependency trees the evidence EHij for each word pair (i, j) is constructed; the evidence takes the form of a vector of counts of occurrences that each labeled syntactic dependency path was found as the shortest path connecting i and j in some dependency tree.

For example, (Snow et al 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
For example, (Snow et al 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. $$$$$ As an example of sense disambiguation in practice, consider our example of continental.

More recently, Snow et al (2005) and Snow et al (2006) have described a method of hypernymy extraction using machine learning of 53 patterns. $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
More recently, Snow et al (2005) and Snow et al (2006) have described a method of hypernymy extraction using machine learning of 53 patterns. $$$$$ In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).

Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al, 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)). $$$$$ Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).
Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al, 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)). $$$$$ We evaluate the quality of our acquired hyponyms by direct judgment.
