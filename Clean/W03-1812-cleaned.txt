Baldwin et al (2003) use LSA as a technique foranalysing the compositionality (or decomposability) of a given MWE. $$$$$ McCarthy et al. (2003) also targeted verb-particles for a study on compositionality, and judged compositionality according to the degree of overlap in the N most similar words to the verbparticle and head verb, e.g., to determine compositionality.
Baldwin et al (2003) use LSA as a technique foranalysing the compositionality (or decomposability) of a given MWE. $$$$$ The particular reference lexicon we use to evaluate our technique is WordNet 1.7 (Miller et al., 1990), due to its public availability, hierarchical structure and wide coverage.

Some of these are mutual information (Church and Hanks, 1989), distributed frequency (Tapanainen et al, 1998) and Latent Semantic Analysis (LSA) model (Baldwin et al, 2003). $$$$$ Multiword expressions (MWEs) are defined to be cohesive lexemes that cross word boundaries (Sag et al., 2002; Copestake et al., 2002; Calzolari et al., 2002).
Some of these are mutual information (Church and Hanks, 1989), distributed frequency (Tapanainen et al, 1998) and Latent Semantic Analysis (LSA) model (Baldwin et al, 2003). $$$$$ The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990).

Some of them are Frequency, Point-wise mutual information (Church and Hanks, 1989), Distributed frequency of object (Tapanainen et al, 1998), Distributed frequency of object using verb information (Venkatapathyand Joshi, 2005), Similarity of object in verb object pair using the LSA model (Baldwin et al,2003), (Venkatapathy and Joshi, 2005) and Lexical and Syntactic fixedness (Fazly and Stevenson, 2006). $$$$$ Our hypothesis of lesser instances of hyponymy for lower similarities is thus supported for low-frequency items but not for high-frequency items, suggesting that LSA similarities are more brittle over high-frequency items for this particular task.
Some of them are Frequency, Point-wise mutual information (Church and Hanks, 1989), Distributed frequency of object (Tapanainen et al, 1998), Distributed frequency of object using verb information (Venkatapathyand Joshi, 2005), Similarity of object in verb object pair using the LSA model (Baldwin et al,2003), (Venkatapathy and Joshi, 2005) and Lexical and Syntactic fixedness (Fazly and Stevenson, 2006). $$$$$ It remains to be determined why LSA should perform better over low-frequency items, although the higher polysemy of high-frequency items is one potential cause.

For example, Baldwin et al (2003) studied vector extraction for phrases because they were interested in the decomposability of multi word expressions. $$$$$ Multiword expressions (MWEs) are defined to be cohesive lexemes that cross word boundaries (Sag et al., 2002; Copestake et al., 2002; Calzolari et al., 2002).
For example, Baldwin et al (2003) studied vector extraction for phrases because they were interested in the decomposability of multi word expressions. $$$$$ The major point of divergence from this research is that Schone and Jurafsky focused specifically on MWE extraction, whereas we are interested in the downstream task of semantically classifying attested MWEs.

According to Baldwin et al (2003), divergences in VPC and head verb semantics are often reflected in differing selectional preferences, as manifested in patterns of noun co-occurrence. $$$$$ McCarthy et al. (2003) also targeted verb-particles for a study on compositionality, and judged compositionality according to the degree of overlap in the N most similar words to the verbparticle and head verb, e.g., to determine compositionality.
According to Baldwin et al (2003), divergences in VPC and head verb semantics are often reflected in differing selectional preferences, as manifested in patterns of noun co-occurrence. $$$$$ In the case of the verb-particle data, WordNet has no classification of prepositions or particles, so we can only calculate the similarity between the head verb and verbparticle (VPC(head)).

Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSAto distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ Melamed (1997)), there has been little work on detecting “non-compositional” (i.e. non-decomposable and idiosyncratically decomposable) items of variable syntactic type in monolingual corpora.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSAto distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ Bannard et al. (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not.

Some of these are Frequency, Mutual Information (Church and Hanks, 1989), distributed frequency of object (Tapanainen et al, 1998) and LSA model (Baldwin et al, 2003) (Schutze, 1998). $$$$$ The LSA model we built is similar to that described in (Sch¨utze, 1998).
Some of these are Frequency, Mutual Information (Church and Hanks, 1989), distributed frequency of object (Tapanainen et al, 1998) and LSA model (Baldwin et al, 2003) (Schutze, 1998). $$$$$ Our hypothesis of lesser instances of hyponymy for lower similarities is thus supported for low-frequency items but not for high-frequency items, suggesting that LSA similarities are more brittle over high-frequency items for this particular task.

An interesting way of quantifying the relative compositionality of a MWE is proposed by Baldwin, Bannard, Tanaka and Widdows (Baldwin et al, 2003). $$$$$ Bannard et al. (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not.
An interesting way of quantifying the relative compositionality of a MWE is proposed by Baldwin, Bannard, Tanaka and Widdows (Baldwin et al, 2003). $$$$$ McCarthy et al. (2003) also targeted verb-particles for a study on compositionality, and judged compositionality according to the degree of overlap in the N most similar words to the verbparticle and head verb, e.g., to determine compositionality.

They evaluate their model on English NN compounds and verb-particles, and showed that the model correlated moderately well with the Word net based decomposability theory (Baldwin et al, 2003). $$$$$ We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet.
They evaluate their model on English NN compounds and verb-particles, and showed that the model correlated moderately well with the Word net based decomposability theory (Baldwin et al, 2003). $$$$$ We evaluated the method over English NN compounds and verbparticles, and showed it to correlate moderately with WordNet-based hyponymy values.

The LSA model we built is similar to that described in (Schutze, 1998) and (Baldwin et al, 2003). $$$$$ The LSA model we built is similar to that described in (Sch¨utze, 1998).
The LSA model we built is similar to that described in (Schutze, 1998) and (Baldwin et al, 2003). $$$$$ The similarity measures described above calculate the similarity between a pair of senses.

 $$$$$ We are not the first to consider applying LSA to MWEs.
 $$$$$ We would like to thank the anonymous reviewers for their valuable input on this research.

Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990).
Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ For this purpose, we used latent semantic analysis (LSA) to build a vector space model in which term-term similarities could be measured.

(Baldwin et al, 2003) use WordNet $$$$$ We use latent semantic analysis to determine the similarity between a multiword expression and its constituent words, and claim that higher similarities indicate greater decomposability.
(Baldwin et al, 2003) use WordNet $$$$$ The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990).

Baldwin et al (2003) proposed a LSA-based model for measuring the decomposability of MWEs by examining the similarity between them and their constituent words, with higher similarity indicating the greater decomposability. $$$$$ We use latent semantic analysis to determine the similarity between a multiword expression and its constituent words, and claim that higher similarities indicate greater decomposability.
Baldwin et al (2003) proposed a LSA-based model for measuring the decomposability of MWEs by examining the similarity between them and their constituent words, with higher similarity indicating the greater decomposability. $$$$$ To summarise, we have proposed a constructioninspecific empirical model of MWE decomposability, based on latent semantic analysis.

Baldwin et al (2003) investigate semantic decomposability of noun-noun compounds and verb constructions. $$$$$ We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet.
Baldwin et al (2003) investigate semantic decomposability of noun-noun compounds and verb constructions. $$$$$ The results for NN(mod) are more erratic for both low- and highfrequency terms, that is the modifier noun is not as strong a predictor of decomposability as the head noun.

In the above model, if a=0 and b=1, the resulting model is similar to that of Baldwin et al (2003). $$$$$ An Empirical Model Of Multiword Expression Decomposability
In the above model, if a=0 and b=1, the resulting model is similar to that of Baldwin et al (2003). $$$$$ The LSA model we built is similar to that described in (Sch¨utze, 1998).

Baldwin et al, (2003) focus more narrowly on distinguishing English noun-noun compound sand verb-particle constructions which are compositional from those which are not compositional. $$$$$ We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet.
Baldwin et al, (2003) focus more narrowly on distinguishing English noun-noun compound sand verb-particle constructions which are compositional from those which are not compositional. $$$$$ Bannard et al. (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not.

To compare our method with that proposed by Baldwin et al (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to theMWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE. $$$$$ The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990).
To compare our method with that proposed by Baldwin et al (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to theMWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE. $$$$$ LSA is a method for representing words as points in a vector space, whereby words which are related in meaning should be represented by points which are near to one another, first developed as a method for improving the vector model for information retrieval (Deerwester et al., 1990).

There is some evidence (Baldwin et al, 2003) that part of speech tagging might improve results in this kind of task. $$$$$ Bannard et al. (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not.
There is some evidence (Baldwin et al, 2003) that part of speech tagging might improve results in this kind of task. $$$$$ The appropriate granularity of syntactic classifications is an open question for this kind of research

Other approaches use Latent Semantic Analysis (LSA) to determine the similarity between a potential idiom and its components (Baldwin et al, 2003). $$$$$ We use latent semantic analysis to determine the similarity between a multiword expression and its constituent words, and claim that higher similarities indicate greater decomposability.
Other approaches use Latent Semantic Analysis (LSA) to determine the similarity between a potential idiom and its components (Baldwin et al, 2003). $$$$$ The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990).
