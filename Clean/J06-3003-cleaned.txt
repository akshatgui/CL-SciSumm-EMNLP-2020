Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ LRA achieves an accuracy of about 56%.
Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ In contrast with the corpus-based approach of Turney and Littman (2005), Veale (2004) applied a lexicon-based approach to the same 374 SAT questions, attaining a score of 43%.

The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ Cognitive scientists distinguish words that are semantically associated (bee–honey) from words that are semantically similar (deer–pony), although they recognize that some words are both associated and similar (doctor–nurse) (Chiarello et al. 1990).
The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ Two words were judged to be highly similar when they tended to have the same kinds of grammatical relations with the same sets of words.

Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ In step 2, introducing alternate pairs multiplies the number of pairs by four, resulting in 8,976 pairs.
Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ In step 2, introducing alternate pairs multiplies the number of pairs by four, resulting in 2,400 pairs.

Turney (2006) used a corpus-based algorithm. $$$$$ In contrast with the corpus-based approach of Turney and Littman (2005), Veale (2004) applied a lexicon-based approach to the same 374 SAT questions, attaining a score of 43%.
Turney (2006) used a corpus-based algorithm. $$$$$ Barker and Szpakowicz (1998) tried a corpus-based approach that explicitly used a measure of relational similarity, but their measure was based on literal matching, which limited its ability to generalize.

The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ LRA achieves an accuracy of about 56%.
The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ Always guessing the majority class would result in an accuracy of 8.2% (49/600).

The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ The average performance of collegebound senior high school students on verbal SAT questions corresponds to an accuracy of about 57%.
The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ The average performance of college-bound senior high school students on verbal SAT questions corresponds to a recall (percent correct) of about 57% (Turney and Littman 2005).

PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ Thus a phrase with n words generates 2(n−2) patterns.
PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ (We use max phrase = 5, so a phrase generates at most eight patterns.)

The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ It may be interesting to see how many of the manually generated patterns appear within the automatically generated patterns.
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ Both of these patterns are included in the 4,000 patterns automatically generated by LRA.

The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ Algorithms for measuring attributional similarity can be lexicon-based (Lesk 1986; Budanitsky and Hirst 2001; Banerjee and Pedersen 2003), corpus-based (Lesk 1969; Landauer and Dumais 1997; Lin 1998a; Turney 2001), or a hybrid of the two (Resnik 1995; Jiang and Conrath 1997; Turney et al. 2003).
The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ Turney et al. (2003) combined 13 independent modules to answer SAT questions.

Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ On the other hand, since measures of relational similarity are not as well developed as measures of attributional similarity, the potential applications of relational similarity are not as well known.
Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ LRA, like VSM, is a corpus-based approach to measuring relational similarity.

This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ Turney and Littman (2005) used the AltaVista search engine to obtain the frequency information required to build vectors for the VSM.
This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ The average performance of college-bound senior high school students on verbal SAT questions corresponds to a recall (percent correct) of about 57% (Turney and Littman 2005).

Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ Similarity of Semantic Relations
Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ LRA, like VSM, is a corpus-based approach to measuring relational similarity.

On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). $$$$$ For example, the word pair mason:stone is analogous to the pair carpenter:wood.
On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). $$$$$ We know a priori that, if A:B::C:D, then B:A::D:C. For example, mason is to stone as carpenter is to wood implies stone is to mason as wood is to carpenter.

We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ Turney (2005) introduced Latent Relational Analysis (LRA), an enhanced version of the VSM approach, which reached 56% on the 374 SAT questions.
We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ This is interesting work, but it is not directly applicable to SAT analogies, because it discovers analogies between clusters of words rather than individual words.

We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ A measure of relational similarity is applicable to this task.
We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ As the measure of nearness, we use LRA to calculate the relational similarity between the testing pair and the training pairs.

The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ Table 3 shows the best performance on the TOEFL questions for each type of attributional similarity algorithm.
The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ The performance of LRA is significantly better than the lexicon-based approach of Veale (2004) (see Section 3.1) and the best performance using attributional similarity (see Section 2.3), with 95% confidence, according to the Fisher Exact Test (Agresti 1990).

In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ When two pairs of words have a high degree of relational similarity, we say that their relations are analogous.
In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ The amount of relational similarity between two pairs of words, A:B and C:D, depends on the degree of correspondence between the relations between A and B and the relations between C and D. A measure of relational similarity is a function that maps two pairs, A:B and C:D, to a real number, simr(A:B,C:D) E R. The more correspondence there is between the relations of A:B and C:D, the greater their relational similarity.

Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ Measures of attributional similarity have been studied extensively, due to their applications in problems such as recognizing synonyms (Landauer and Dumais 1997), information retrieval (Deerwester et al. 1990), determining semantic orientation (Turney 2002), grading student essays (Rehder et al.
Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ Turney et al. (2003) combined 13 independent modules to answer SAT questions.

The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ On the other hand, since measures of relational similarity are not as well developed as measures of attributional similarity, the potential applications of relational similarity are not as well known.
The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ The term semantic similarity is misleading, because it refers to a type of attributional similarity, yet relational similarity is not any less semantic than attributional similarity.

Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ This article introduces Latent Relational Analysis (LRA), a method for measuring relational similarity.
Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ This article introduces Latent Relational Analysis (LRA), a method for measuring relational similarity.
