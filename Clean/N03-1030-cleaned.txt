SEE allowed the judges to step through predefined units of the model summary (elementary discourse units/EDUs) (Soricut and Marcu, 2003) and for each unit of that summary, mark the sentences in the peer summary that expressed [all (4), most (3), some (2), hardly any (1) or none (0)] of the content in the current model summary unit. $$$$$ In this section, we present a discourse segmentation algorithm that deals with segmenting sentences into elementary discourse units.
SEE allowed the judges to step through predefined units of the model summary (elementary discourse units/EDUs) (Soricut and Marcu, 2003) and for each unit of that summary, mark the sentences in the peer summary that expressed [all (4), most (3), some (2), hardly any (1) or none (0)] of the content in the current model summary unit. $$$$$ The discourse segmenter proposed here takes as input a sentence and outputs its elementary discourse unit boundaries.

Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing. $$$$$ In the present work, elementary discourse units are taken to be clauses or clauselike units that are unequivocally the NUCLEUS or SATELLITE of a rhetorical relation that holds between two adjacent spans of text (see (Carlson et al., 2003) for details).
Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing. $$$$$ This mapping leads to the notion of a dominance set over a discourse segmented lexicalized syntactic tree.

Our model was trained and tested on RST-DT (2002) and achieves a performance of up to 86.12% F-Score, which is comparable to Soricut and Marcu (2003). $$$$$ The (RST-DT, 2002) corpus uses 110 different rhetorical relations.
Our model was trained and tested on RST-DT (2002) and achieves a performance of up to 86.12% F-Score, which is comparable to Soricut and Marcu (2003). $$$$$ This is even more remarkable given that the discourse corpus (RST-DT, 2002) was built with no syntactic theory in mind.

Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003). $$$$$ Sentence Level Discourse Parsing Using Syntactic And Lexical Information
Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003). $$$$$ Another interesting finding is that the performance of current state-of-the-art syntactic parsers (Charniak, 2000) is not a bottleneck for coming up with a good solution to the sentence-level discourse parsing problem.

Since segmentation is the first stage of discourse parsing, quality discourse segments are critical to building quality discourse representations (Soricut and Marcu, 2003). $$$$$ We break down the problem of building sentence-level discourse trees into two sub-problems: discourse segmentation and discourse parsing.
Since segmentation is the first stage of discourse parsing, quality discourse segments are critical to building quality discourse representations (Soricut and Marcu, 2003). $$$$$ The discourse parsing model uses syntactic trees produced by Charniak’s parser (2000) and discourse segments produced by the algorithm described in Section 3.

Soricut and Marcu (2003) construct a statistical discourse segmenter as part of their sentence-level discourse parser (SPADE), the only implementation available for our comparison. $$$$$ Our statistical approach to sentence segmentation uses two components: a statistical model which assigns a probability to the insertion of a discourse boundary after each word in a sentence, and a segmenter, which uses the probabilities computed by the model for inserting discourse boundaries.
Soricut and Marcu (2003) construct a statistical discourse segmenter as part of their sentence-level discourse parser (SPADE), the only implementation available for our comparison. $$$$$ The metric we use to evaluate the discourse segmenter records the accuracy of the discourse segmenter with respect to its ability to insert inside-sentence discourse boundaries.

Soricut and Marcu (2003) use syntactic features to identify sentence-internal RST structure. $$$$$ The models use syntactic and lexical features.
Soricut and Marcu (2003) use syntactic features to identify sentence-internal RST structure. $$$$$ We denote such node , and the features we use are node , its parent , and the siblings of .

The test set includes only sentences for which our English parser (Soricut and Marcu, 2003) could produce a parse tree, which effectively excluded a few very long sentences. $$$$$ The remaining 5% of the sentences cannot be used in our approach, as no well-formed discourse tree can be associated with these sentences.
The test set includes only sentences for which our English parser (Soricut and Marcu, 2003) could produce a parse tree, which effectively excluded a few very long sentences. $$$$$ For this evaluation, we re-trained Charniak’s parser (2000) such that the test sentences from the discourse corpus were not seen by the syntactic parser during training.

One exception is Marcu's work (Marcu, 1997, 1999) (see also Soricut and Marcu (2003) for constructing discourse structures for individual sentences). $$$$$ In our experiments we used as discourse structures only the discourse sub-trees spanning over individual sentences.
One exception is Marcu's work (Marcu, 1997, 1999) (see also Soricut and Marcu (2003) for constructing discourse structures for individual sentences). $$$$$ Yet, they built discourse structures at sentence level that are not only consistent with the syntactic structures of sentences, but also derivable from them.

Within Rhetorical Structure Theory (RST), Soricut and Marcu (2003) have developed two probabilistic models for identifying clausal elementary discourse units and generating discourse trees at the sentence level. $$$$$ We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.
Within Rhetorical Structure Theory (RST), Soricut and Marcu (2003) have developed two probabilistic models for identifying clausal elementary discourse units and generating discourse trees at the sentence level. $$$$$ In this paper, we introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.

Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003). $$$$$ Sentence Level Discourse Parsing Using Syntactic And Lexical Information
Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003). $$$$$ Another interesting finding is that the performance of current state-of-the-art syntactic parsers (Charniak, 2000) is not a bottleneck for coming up with a good solution to the sentence-level discourse parsing problem.

their relation edges are obtained from the Spade system described in Soricut and Marcu (2003). $$$$$ Tuple ENABLEMENT-NS[2,2,3] has a score of 0.40, obtained ATTRIBUTION-SN[1,1,3] has a score of 0.37 for the structure, and a score of 0.009 for the relation.
their relation edges are obtained from the Spade system described in Soricut and Marcu (2003). $$$$$ We also compute the agreement between human annotators on the discourse segmentation task ( ), using the doubly-annotated discourse corpus mentioned in Section 2. described in this paper ( ) using syntactic trees produced by Charniak’s parser (2000), in comparison with the results obtained by the algorithm described in (Marcu, 2000) ( ), and baseline algorithms and , on the same test set.

Soricut and Marcu (2003) also build up RST sentential trees to use in discourse parsing. $$$$$ We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.
Soricut and Marcu (2003) also build up RST sentential trees to use in discourse parsing. $$$$$ The annotators used by Carlson et al. (2003) were not instructed to build discourse trees that were consistent with the syntax of the sentences.

Though statistical methods have been used to induce such trees (Soricut and Marcu, 2003), they are not used for ordering and other text-structuring tasks. $$$$$ Once we have the segmenting probabilities given by the statistical model, a straightforward algorithm is used to implement the segmenter.
Though statistical methods have been used to induce such trees (Soricut and Marcu, 2003), they are not used for ordering and other text-structuring tasks. $$$$$ The annotators used by Carlson et al. (2003) were not instructed to build discourse trees that were consistent with the syntax of the sentences.

(Soricut and Marcu, 2003) and (Polanyi et al., 2004) implement models to perform discourse parsing. $$$$$ In this paper, we describe probabilistic models and algorithms that exploit the discourseannotated corpus produced by Carlson et al. (2003).
(Soricut and Marcu, 2003) and (Polanyi et al., 2004) implement models to perform discourse parsing. $$$$$ (See (Carlson et al., 2003) for details concerning the corpus and the annotation process.)

A discourse tree (Soricut and Marcu, 2003). $$$$$ An example of a discourse structure is the tree given in Figure 1.
A discourse tree (Soricut and Marcu, 2003). $$$$$ The overall probability of a discourse tree is obtained multiplying the structural probabilities and the relational probabilities for all the tuples in the discourse tree.

Soricut and Marcu (2003) introduce a statistical discourse segmenter, which is trained on RST DT to label words with boundary or no-boundary labels. $$$$$ Our statistical model assigns a segmenting probability for each word , where boundary, no-boundary .
Soricut and Marcu (2003) introduce a statistical discourse segmenter, which is trained on RST DT to label words with boundary or no-boundary labels. $$$$$ Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.

Like Soricut and Marcu (2003), they formulate the discourse segmentation task as a binary classification problem of deciding whether a word is the boundary or no-boundary of EDUs. $$$$$ Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.
Like Soricut and Marcu (2003), they formulate the discourse segmentation task as a binary classification problem of deciding whether a word is the boundary or no-boundary of EDUs. $$$$$ Given a syntactic tree , the algorithm inserts a boundary after each word for which boundary .

Soricut and Marcu (2003) and Subba and Di Eugenio (2007) use boundary labels, which are assigned to words at the end of EDUs. $$$$$ Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.
Soricut and Marcu (2003) and Subba and Di Eugenio (2007) use boundary labels, which are assigned to words at the end of EDUs. $$$$$ As mentioned in Section 2, we use both 18 labels and 110 labels for the discourse relations.

SPADE is the work of Soricut and Marcu (2003). $$$$$ In the present work, elementary discourse units are taken to be clauses or clauselike units that are unequivocally the NUCLEUS or SATELLITE of a rhetorical relation that holds between two adjacent spans of text (see (Carlson et al., 2003) for details).
SPADE is the work of Soricut and Marcu (2003). $$$$$ Recent work on Tree Adjoining Grammar-based lexicalized models of discourse (Forbes et al., 2001) has already shown how to exploit within a single framework lexical, syntactic, and discourse cues.
