For instance, Chodorow and Leacock (2000) point out that the word concentrate is usually used as a noun in a general corpus whereas it is a verb 91% of the time in essays written by non-native learners of English. $$$$$ ALEK also looks for sequences that are common in general but unusual in the word specific corpus (e.g., the singular determiner a preceding a singular noun is common in English but rare when the noun is specific corpora, we tried to minimize the mismatch between the domains of newspapers and TOEFL essays.
For instance, Chodorow and Leacock (2000) point out that the word concentrate is usually used as a noun in a general corpus whereas it is a verb 91% of the time in essays written by non-native learners of English. $$$$$ For example, in the newspaper domain, concentrate is usually used as a noun, as in orange juice concentrate but in TOEFL essays it is a verb 91% of the time.

Chodorow and Leacock (2000) try to identify errors on the basis of context, as we do here, and more specifically a 2 word window around the word of interest, from which they consider function words and POS tags. $$$$$ They identify the intended sense of a word in a novel sentence by extracting its contextual cues and selecting the most similar word sense model (e.g., Leacock, Chodorow and Miller (1998), Yarowsky (1993)).
Chodorow and Leacock (2000) try to identify errors on the basis of context, as we do here, and more specifically a 2 word window around the word of interest, from which they consider function words and POS tags. $$$$$ It uses two kinds of contextual cues in a ±2 word window around the target word: function words (closed-class items) and part-of-speech tags (Brill, 1994).

N-gram-based approaches to the problem of error detection have been proposed and implemented in various forms by Atwell (1987), Bigert and Knutsson (2002), and Chodorow and Leacock (2000) amongst others. $$$$$ We take a different approach, initially viewing error detection as an extension of the word sense disambiguation (WSD) problem.
N-gram-based approaches to the problem of error detection have been proposed and implemented in various forms by Atwell (1987), Bigert and Knutsson (2002), and Chodorow and Leacock (2000) amongst others. $$$$$ Unfortunately, this approach was not effective for error detection.

Chodorow and Leacock (2000) use a mutual information measure in addition to raw frequency of n grams. $$$$$ From the general corpus, ALEK computes a mutual information measure to determine which sequences of part-of-speech tags and function words are unusually rare and are, therefore, likely to be ungrammatical in English (e.g., singular determiner preceding plural noun, as in *a desks).
Chodorow and Leacock (2000) use a mutual information measure in addition to raw frequency of n grams. $$$$$ Here we use this measure for the opposite purpose — to find combinations that occur less often than expected.

Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. $$$$$ We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora.
Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. $$$$$ Instead, we train ALEK on a general corpus of English and on edited text containing example uses of the target word.

For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and part-of-speech (PoS) tags, while Sun et al (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. $$$$$ It uses two kinds of contextual cues in a ±2 word window around the target word: function words (closed-class items) and part-of-speech tags (Brill, 1994).
For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and part-of-speech (PoS) tags, while Sun et al (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. $$$$$ Other function words and tags in the +1 position have much lower conditional probability, so for example, a knowledge is will not be treated as an exception to the error.

For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al, 2008) and (Gamon and Leacock, 2010) use Web as a corpus. $$$$$ ALEK also uses mutual information to compare the distributions of tags and function words in the word-specific corpus to the distributions that are expected based on the general corpus.
For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al, 2008) and (Gamon and Leacock, 2010) use Web as a corpus. $$$$$ In addition to bigram and trigram measures, ALEK compares the target word's part-ofspeech tag in the word-specific corpus and in the general corpus.

Chodorow and Leacock (2000) and Chodorow et al (2007) argue that precision-oriented is better, but they do not give any concrete reason. $$$$$ They identify the intended sense of a word in a novel sentence by extracting its contextual cues and selecting the most similar word sense model (e.g., Leacock, Chodorow and Miller (1998), Yarowsky (1993)).
Chodorow and Leacock (2000) and Chodorow et al (2007) argue that precision-oriented is better, but they do not give any concrete reason. $$$$$ Precision and recall for the three words are shown below.

The grammar feature covers errors such as sentence fragments, verb form errors and pronoun errors (Chodorow and Leacock, 2000). $$$$$ ALEK recognizes all of these types of errors.
The grammar feature covers errors such as sentence fragments, verb form errors and pronoun errors (Chodorow and Leacock, 2000). $$$$$ Since these errors are not indicative of one's ability to use the target word, they were not considered as errors unless they caused the judge to misanalyze the sentence.

An example is the error detection method (Chodorow and Leacock, 2000), which identifies unnatural sequences of POSs as grammatical errors in the writing of learners. $$$$$ An Unsupervised Method For Detecting Grammatical Errors
An example is the error detection method (Chodorow and Leacock, 2000), which identifies unnatural sequences of POSs as grammatical errors in the writing of learners. $$$$$ We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora.

Our method outperforms Microsoft Word03 and ALEK (Chodorow and Leacock, 2000) from Educational Testing Service (ETS) in some cases. $$$$$ ALEK has been developed using the Test of English as a Foreign Language (TOEFL) administered by the Educational Testing Service.
Our method outperforms Microsoft Word03 and ALEK (Chodorow and Leacock, 2000) from Educational Testing Service (ETS) in some cases. $$$$$ In both cases, the system recognizes that the target is in the wrong syntactic environment.

An unsupervised method (Chodorow and Leacock, 2000) is employed to detect grammatical errors by inferring negative evidence from TOEFL administrated by ETS. $$$$$ An Unsupervised Method For Detecting Grammatical Errors
An unsupervised method (Chodorow and Leacock, 2000) is employed to detect grammatical errors by inferring negative evidence from TOEFL administrated by ETS. $$$$$ We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora.

In addition, we compared our technique with two other methods of checking errors, Microsoft Word03 and ALEK method (Chodorow and Leacock, 2000). $$$$$ An Unsupervised Method For Detecting Grammatical Errors
In addition, we compared our technique with two other methods of checking errors, Microsoft Word03 and ALEK method (Chodorow and Leacock, 2000). $$$$$ Given this limitation, we compared ALEK's performance to a widely used grammar checker, the one incorporated in Microsoft's Word97.

In this paper, we compare our technique with the grammar checker of Microsoft Word03 and the ALEK (Chodorow and Leacock, 2000) method used by ETS. $$$$$ Given this limitation, we compared ALEK's performance to a widely used grammar checker, the one incorporated in Microsoft's Word97.
In this paper, we compare our technique with the grammar checker of Microsoft Word03 and the ALEK (Chodorow and Leacock, 2000) method used by ETS. $$$$$ However, its techniques could be incorporated into a grammar checker for native speakers.

Chodorow and Leacock (2000) utilized mutual information and chi-square statistics to identify typical contexts for a small set of targeted words from a large well-formed corpus. $$$$$ Mutual information has often been used to detect combinations of words that occur more frequently than we would expect based on the assumption that the words are independent.
Chodorow and Leacock (2000) utilized mutual information and chi-square statistics to identify typical contexts for a small set of targeted words from a large well-formed corpus. $$$$$ ALEK also uses mutual information to compare the distributions of tags and function words in the word-specific corpus to the distributions that are expected based on the general corpus.

The filter-based system combines unsupervised detection of a set of possible errors (Chodorow and Leacock, 2000) with hand-crafted filters designed to reduce this set to the largest subset of correctly flagged errors and the smallest possible number of false positives. $$$$$ To reduce the number of false positives, no candidate found by the MI measures is considered an error if it appears in the word-specific corpus at least two times.
The filter-based system combines unsupervised detection of a set of possible errors (Chodorow and Leacock, 2000) with hand-crafted filters designed to reduce this set to the largest subset of correctly flagged errors and the smallest possible number of false positives. $$$$$ The E-set contained 8.3% of the pollution sentences and the C-set had the remaining 91.7%.

Chodorow and Leacock (2000) found that low-frequency bigrams (sequences of two lexical categories with a negative log-likelihood) are quite reliable predictors of grammatical errors. $$$$$ The mutual information measures provide candidate errors, but this approach overgenerates — it finds rare, but still quite grammatical, sequences.
Chodorow and Leacock (2000) found that low-frequency bigrams (sequences of two lexical categories with a negative log-likelihood) are quite reliable predictors of grammatical errors. $$$$$ If low probability n-grams signal grammatical errors, then we would expect TOEFL essays that received lower scores to have more of these ngrams.
