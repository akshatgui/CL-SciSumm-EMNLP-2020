Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ As a point of comparison, the supervised method of Gildea and Jurafsky (2002) achieved 82.1% accuracy on identified arguments using general thematic roles.
Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ Using an unsupervised algorithm for semantic role labelling, we have achieved 90% correct on identified arguments, well over an informed baseline of 77%, and have achieved 87% correct on all slots (64% baseline).

VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ Because of the importance of this task, a number of recent methods have been proposed for automatic semantic role labelling (e.g., Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Fleischman et al., 2003; Hacioglu et al., 2003; Thompson et al., 2003).
VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ In semantic role labelling using VerbNet, they are particularly relevant since the classes are based on a commonality of role-labelled syntactic frames (Kipper et al., 2000).

Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Unsupervised Semantic Role Labeling
Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Supervised approaches to this task have thus far used the predicate lexicon of FrameNet, or the verb lexicon of PropBank, since each has an associated labelled corpus for training.

There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ (Indeed, in comparing the use of FrameNet roles to general thematic roles, Gildea and Jurafsky (2002) found very little difference in performance.)
There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ As a point of comparison, the supervised method of Gildea and Jurafsky (2002) achieved 82.1% accuracy on identified arguments using general thematic roles.

To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ Table 1) that are the best syntactic matches with the chunker output.
To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ Set to and set to .

There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ Unsupervised Semantic Role Labeling
There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ Because of the importance of this task, a number of recent methods have been proposed for automatic semantic role labelling (e.g., Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Fleischman et al., 2003; Hacioglu et al., 2003; Thompson et al., 2003).

For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ Unsupervised Semantic Role Labeling
For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ We instead make use of VerbNet (Kipper et al., 2000), a manually developed hierarchical verb lexicon based on the verb classification of Levin (1993).

Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ We then iteratively: create a probability model based on the currently annotated semantic roles, use this probability model to assign roles that are deemed to have sufficient evidence, and add the newly labelled arguments to our annotated set.
Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ In our approach, all previously annotated slots are used in the iterative training of the probability model.

Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ Unsupervised Semantic Role Labeling
Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ We present an unsupervised method for labelling the arguments of verbs with their semantic roles.

Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ Unsupervised Semantic Role Labeling
Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ Also, the unsupervised nature of the approach highlights an intermediate step of determining the set of possible roles for each argument.

Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ Unsupervised Semantic Role Labeling
Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ To our knowledge, this is the first unsupervised semantic role labelling system applied to general semantic roles in a domain-general corpus.

Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ We instead make use of VerbNet (Kipper et al., 2000), a manually developed hierarchical verb lexicon based on the verb classification of Levin (1993).
Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ In semantic role labelling using VerbNet, they are particularly relevant since the classes are based on a commonality of role-labelled syntactic frames (Kipper et al., 2000).

Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ Our bootstrapping algorithm makes initial unambiguous role assignments, and then iteratively updates the probability model on which future assignments are based.
Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ Set to and set to .

Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ Unsupervised Semantic Role Labeling
Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ To our knowledge, this is the first unsupervised semantic role labelling system applied to general semantic roles in a domain-general corpus.

This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ Throughout the paper we use the term “frame” to refer to a syntactic frame—the set of syntactic arguments of a verb—possibly labelled with roles, as exemplified in the VerbNet entry in Table 1.
This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ We align the slots of each frame with the chunked slots, and compute the portion %Frame of frame slots that can be mapped to a chunked slot, and the portion %Chunks of chunked slots that can be mapped to the frame.

For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ All that remains is to specify the parameters that guide the iterative use of the probability model to assign roles.
For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ Algorithm 1 shows the bootstrapping algorithm.

For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ From the set of target verbs, we derived an extended verb set that comprises all of the original target verbs as well as any verb that shares a class with one of those target verbs.
For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ This gives us a set of 1159 verbs to observe in total, and increases the likelihood that some verb class information is available for each of the possible classes of the target verbs.

As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ We have described the frame matcher that produces a set of slots with candidate role lists (some unambiguous), and our backoff probability model.
As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ As a point of comparison, the supervised method of Gildea and Jurafsky (2002) achieved 82.1% accuracy on identified arguments using general thematic roles.

Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Unsupervised Semantic Role Labeling
Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Supervised approaches to this task have thus far used the predicate lexicon of FrameNet, or the verb lexicon of PropBank, since each has an associated labelled corpus for training.
