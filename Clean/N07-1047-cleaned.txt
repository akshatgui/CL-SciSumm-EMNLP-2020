To explore this, we tested our model in conjunction with a recent L2P system that has been shown to predict phonemes with state-of-the-art word accuracy (Jiampojamarn et al, 2007). $$$$$ We also apply an HMM method in conjunction with a local classification model to predict a global phoneme sequence given a word.
To explore this, we tested our model in conjunction with a recent L2P system that has been shown to predict phonemes with state-of-the-art word accuracy (Jiampojamarn et al, 2007). $$$$$ Our system achieves state-of-the-art performance on several languages and data sets.

We would like to use features that look at wide context on the input side, which is inexpensive (Jiampojamarn et al, 2007). $$$$$ Our approach is to use an instance-based learning technique as a local predictor to generate a set of phoneme candidates for each letter chunk, given its context in a word.
We would like to use features that look at wide context on the input side, which is inexpensive (Jiampojamarn et al, 2007). $$$$$ We plan to explore other sequence prediction approaches, such as discriminative training methods (Collins, 2004), and sequence tagging with Support Vector Machines (SVM-HMM) (Altun et al., 2003) to incorporate more features (context information) into the phoneme generation model.

Our system employs the many-to-many alignment described in (Jiampojamarn et al, 2007). $$$$$ Previous work has generally assumed one-to-one alignment for simplicity (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005).
Our system employs the many-to-many alignment described in (Jiampojamarn et al, 2007). $$$$$ We show results comparing the one-to-one aligner described in Section 2.1 and the one-to-one aligner provided by the PRONALSYL challenge.

We use the many-to-many letter phoneme alignment algorithm (Jiampojamarn et al, 2007) to map each letter to multiple phonemes (1-to-2 alignment). $$$$$ We describe the letter-phoneme alignment methods including a standard one-to-one alignment method and our many-to-many approach in Section 2.
We use the many-to-many letter phoneme alignment algorithm (Jiampojamarn et al, 2007) to map each letter to multiple phonemes (1-to-2 alignment). $$$$$ The alignment provided by the PRONALSYS one-to-one alignments is

The M2M-aligner (Jiampojamarn et al, 2007) is based on the expectation maximization (EM) algorithm. $$$$$ An expectation maximization (EM) based algorithm (Dempster et al., 1977) is applied to train the aligners.
The M2M-aligner (Jiampojamarn et al, 2007) is based on the expectation maximization (EM) algorithm. $$$$$ For each grapheme-/phoneme-sequence pair (x, y), the EM-many2many function (Algorithm 1) calls the Expectation-many2many function (Algorithm 2) to collect partial counts.

Our input string representation for a candidate pair is formed by first aligning the source and target words using M2M-aligner (Jiampojamarn et al., 2007). $$$$$ Since the candidate set is from the classifier, the search space is limited to a small number of candidate phonemes (1 to 5 phonemes in most cases).
Our input string representation for a candidate pair is formed by first aligning the source and target words using M2M-aligner (Jiampojamarn et al., 2007). $$$$$ For the English Celex data, we removed duplicate words as well as words shorter than four letters.

DIRECTL+ (Jiampojamarn et al, 2010a) is an online discriminative training system that incorporates joint n-gram features and many-to-many alignments, which are generated by M2M-ALIGNER (Jiampojamarn et al, 2007). $$$$$ Previous work has generally assumed one-to-one alignment for simplicity (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005).
DIRECTL+ (Jiampojamarn et al, 2010a) is an online discriminative training system that incorporates joint n-gram features and many-to-many alignments, which are generated by M2M-ALIGNER (Jiampojamarn et al, 2007). $$$$$ We plan to explore other sequence prediction approaches, such as discriminative training methods (Collins, 2004), and sequence tagging with Support Vector Machines (SVM-HMM) (Altun et al., 2003) to incorporate more features (context information) into the phoneme generation model.

Advanced L2P approaches, including the joint n-gram models (Bisani and Ney, 2008) and the joint discriminative approach (Jiampojamarn et al., 2007) eliminate the one-to-one constraint entirely, allowing for linking of multiple letters to multiple phonemes. $$$$$ We describe the letter-phoneme alignment methods including a standard one-to-one alignment method and our many-to-many approach in Section 2.
Advanced L2P approaches, including the joint n-gram models (Bisani and Ney, 2008) and the joint discriminative approach (Jiampojamarn et al., 2007) eliminate the one-to-one constraint entirely, allowing for linking of multiple letters to multiple phonemes. $$$$$ Normalization can be done over the whole table to create a joint distribution or per grapheme to create a conditional distribution.

M2M-aligner (Jiampojamarn et al, 2007) is a many-to-many (M-M) alignment algorithm based on EM that allows for mapping of multiple letters to multiple phonemes. $$$$$ An expectation maximization (EM) based algorithm (Dempster et al., 1977) is applied to train the aligners.
M2M-aligner (Jiampojamarn et al, 2007) is a many-to-many (M-M) alignment algorithm based on EM that allows for mapping of multiple letters to multiple phonemes. $$$$$ The method applies the EM algorithm to estimate the probability of mapping a letter l to a phoneme p, P(l, p).

Extensions to this model are possible, for example the use of many-to-many alignments which have been shown to be very effective in letter-to-phoneme alignment tasks (Jiampojamarn et al 2007). $$$$$ Once we have our many-to-many alignments, we use that data to train a prediction model.
Extensions to this model are possible, for example the use of many-to-many alignments which have been shown to be very effective in letter-to-phoneme alignment tasks (Jiampojamarn et al 2007). $$$$$ For both alignments, we use instancebased learning as the prediction model.

In our lexicon, the graphemes and phonemes of each word are aligned according to the method of Jiampojamarn et al (2007). $$$$$ Given a set of words and their phonemes, alignments are made across graphemes and phonemes.
In our lexicon, the graphemes and phonemes of each word are aligned according to the method of Jiampojamarn et al (2007). $$$$$ Once many-to-many alignments are built across graphemes and phonemes, each word contains a set of letter chunks, each consisting of one or two letters aligned with phonemes.


In order to extract source-target character mappings, we use m2m-aligner (Jiampojamarn et al, 2007), which implements a forward-backward algorithm to sum over probabilities of possible character sequence mappings, and uses Expectation Maximization to learn mapping probabilities. $$$$$ Partial counts are counts of all possible mappings from letters to phonemes that are collected in the -y table, while mapping probabilities (initially uniform) are maintained in the S table.
In order to extract source-target character mappings, we use m2m-aligner (Jiampojamarn et al, 2007), which implements a forward-backward algorithm to sum over probabilities of possible character sequence mappings, and uses Expectation Maximization to learn mapping probabilities. $$$$$ Expectation-many2many first calls the two functions to fill the Î± and Q tables, and then uses the probabilities to calculate partial counts for every possible mapping in the sequence pair.

One of the most popular alignment tools is m2maligner (Jiampojamarn et al, 2007), which is released as an open source software. $$$$$ Previous work has generally assumed one-to-one alignment for simplicity (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005).
One of the most popular alignment tools is m2maligner (Jiampojamarn et al, 2007), which is released as an open source software. $$$$$ For all of our experiments, our local classifier for predicting phonemes is the instance-based learning IB1 algorithm (Aha et al., 1991) implemented in the TiMBL package (Daelemans et al., 2004).

To establish the substring alignment between katakana and Latin alphabet strings, we use the probabilistic model proposed by (Jiampojamarn et al., 2007). $$$$$ Once we have our many-to-many alignments, we use that data to train a prediction model.
To establish the substring alignment between katakana and Latin alphabet strings, we use the probabilistic model proposed by (Jiampojamarn et al., 2007). $$$$$ For both alignments, we use instancebased learning as the prediction model.

To balance cost and benefit for English-to-Chinese (E2C) transliteration, this work compares the one-stage method with the two-stage one, using additional features of AV (Feng et al, 2004) and M2M-aligner as an initial alignment (Jiampojamarn et al, 2007), to explore where the best investment reward is. $$$$$ Previous work has generally assumed one-to-one alignment for simplicity (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005).
To balance cost and benefit for English-to-Chinese (E2C) transliteration, this work compares the one-stage method with the two-stage one, using additional features of AV (Feng et al, 2004) and M2M-aligner as an initial alignment (Jiampojamarn et al, 2007), to explore where the best investment reward is. $$$$$ For all of our experiments, our local classifier for predicting phonemes is the instance-based learning IB1 algorithm (Aha et al., 1991) implemented in the TiMBL package (Daelemans et al., 2004).

For the alignment of supplemental data with candidate outputs, we apply M2M ALIGNER (Jiampojamarn et al, 2007). $$$$$ Previous work has generally assumed one-to-one alignment for simplicity (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005).
For the alignment of supplemental data with candidate outputs, we apply M2M ALIGNER (Jiampojamarn et al, 2007). $$$$$ Since the candidate set is from the classifier, the search space is limited to a small number of candidate phonemes (1 to 5 phonemes in most cases).

The second hybrid approach (Jiampojamarn et al, 2007) also extends instance-based classification. $$$$$ In our system, a bigram letter chunking prediction automatically discovers double letters based on instance-based learning (Aha et al., 1991).
The second hybrid approach (Jiampojamarn et al, 2007) also extends instance-based classification. $$$$$ For all of our experiments, our local classifier for predicting phonemes is the instance-based learning IB1 algorithm (Aha et al., 1991) implemented in the TiMBL package (Daelemans et al., 2004).

In the pipeline approach (Figure 1b), the input word is segmented into letter substrings by an instance-based classifier (Aha et al, 1991), which learns a letter segmentation model from many-to-many alignments (Jiampojamarn et al, 2007). $$$$$ In our system, a bigram letter chunking prediction automatically discovers double letters based on instance-based learning (Aha et al., 1991).
In the pipeline approach (Figure 1b), the input word is segmented into letter substrings by an instance-based classifier (Aha et al, 1991), which learns a letter segmentation model from many-to-many alignments (Jiampojamarn et al, 2007). $$$$$ For all of our experiments, our local classifier for predicting phonemes is the instance-based learning IB1 algorithm (Aha et al., 1991) implemented in the TiMBL package (Daelemans et al., 2004).

We ignored one-to-one alignments included in the PRONALSYL data sets, and instead induced many-to-many alignments using the method of Jiampojamarn et al (2007). $$$$$ Overall, our one-to-one alignments outperform the alignments provided by the data sets for all corpora.
We ignored one-to-one alignments included in the PRONALSYL data sets, and instead induced many-to-many alignments using the method of Jiampojamarn et al (2007). $$$$$ On several languages and data sets, using the many-to-many alignments, word accuracy improvements ranged from 2.7% to 7.6%, as compared to one-to-one alignments.
