The first four lines show the token-level accuracy for standard POS tagging tools trained and evaluated on the BulTreeBank $$$$$ Most work on statistical methods has used n-gram models or Hidden Markov Model-based taggers (e.g.
The first four lines show the token-level accuracy for standard POS tagging tools trained and evaluated on the BulTreeBank $$$$$ An approach based on k-nn methods (such as memory-based and case-based methods) is a statistical approach, but it uses a different kind of statistics than Markov model-based approaches.

We use the Memory Based Tagger (Daelemans et al, 1996) System Headline Source Florida executes notorious serial killer PBMT Serial killer executed in Florida Word Sub. $$$$$ We use IGTrees (Daelemans et al. 1996) to compress the memory.
We use the Memory Based Tagger (Daelemans et al, 1996) System Headline Source Florida executes notorious serial killer PBMT Serial killer executed in Florida Word Sub. $$$$$ For a detailed discussion, see Daelemans et al. (1996).

To investigate the effect of using automatically assigned tags, we trained MBT, a memory-based tagger (Daelemans et al,1996), on the training portions of our 10-fold cross validation experiment for the maximal data and let it predict tags for the test material. $$$$$ Where possible, we used a 10-fold cross-validation approach.
To investigate the effect of using automatically assigned tags, we trained MBT, a memory-based tagger (Daelemans et al,1996), on the training portions of our 10-fold cross validation experiment for the maximal data and let it predict tags for the test material. $$$$$ Training set size is on the X-axis, generalization performance as measured in a 10-fold cross-validation experiment is on the Y-axis. the 'error' range indicate averages plus and minus one standard deviation on each 10-fold cross-validation experiment.'

In that table, TBL stands for Brill &apos; s transformation-based error-driven tagget (Brill, 1995), ME stands for a tagger based on the maximum entropy modelling (Ratnaparkhi, 1996), SPATTER stands for a statistical parser based on decision trees (Magerman, 1996), IGTREE stands for the memory-based tagger by Daelemans et al (1996), and, finally, TComb stands for a tagger that works by combination of a statistical trigram-based tagger, 59 Tagger TBL ME SPATTER IGTREE TComb STT+ (CPD+ENS) Train Test 950 Kw 150 Kw. $$$$$ MBT

The English data was automatically labeled with part-of-speech and chunk tags from the memory-based tagger and chunker (Daelemans et al, 1996), and the German data was labelled with the decision-tree-based TreeTagger (Schmidt, 1994). $$$$$ MBT

Direct feedback loops that copy a predicted output label to the input representation of the next example have been used in symbolic machine-learning architectures such as the the maximum-entropy tagger described by Ratnaparkhi (1996) and the memory-based tagger (MBT) proposed by Daelemans et al (1996). $$$$$ MBT

Comparison of generalization performances in terms of F-score of MBL on the three test sets, with and without a feedback loop, and the error reduction attained by the feedback-loop method, the F-score of the trigram-class method, and the F-score of the combination of the two methods. approach was proposed in the context of memory based learning for part-of-speech tagging as MBT (Daelemans et al, 1996). $$$$$ MBT

For the part of speech tagging, the memory-based tagger MBT (Daelemans et al, 1996), trained on the Wall Street Journal corpus2, was used. $$$$$ MBT

The CoNLL data differs slightly from the original Alpino tree bank as the corpus has been part-of-speech tagged using a Memory-Based-Tagger (Daelemans et al, 1996). $$$$$ MBT

The annotator has followed the MITRE and SAIC guidelines for named entity recognition (Chinchor et al, 1999) as well as possible. The data consists of words, entity tags and part of-speech tags which have been derived by a Dutch part-of-speech tagger (Daelemans et al, 1996). $$$$$ We use IGTrees (Daelemans et al. 1996) to compress the memory.
The annotator has followed the MITRE and SAIC guidelines for named entity recognition (Chinchor et al, 1999) as well as possible. The data consists of words, entity tags and part of-speech tags which have been derived by a Dutch part-of-speech tagger (Daelemans et al, 1996). $$$$$ For a detailed discussion, see Daelemans et al. (1996).

We used the provided POS annotation in Dutch (Daelemans et al, 1996) and a minimally supervised tagger (Yarowsky and Cucerzan, 2002) for Spanish to restrict the space of words accepted by the discriminators (e.g .is_B_candidate rejects prepositions, conjunctions, pronouns, adverbs, and those determiners that are the first word in the sentence). $$$$$ For a detailed discussion, see Daelemans et al. (1996).
We used the provided POS annotation in Dutch (Daelemans et al, 1996) and a minimally supervised tagger (Yarowsky and Cucerzan, 2002) for Spanish to restrict the space of words accepted by the discriminators (e.g .is_B_candidate rejects prepositions, conjunctions, pronouns, adverbs, and those determiners that are the first word in the sentence). $$$$$ E.g. once would get a new tag, representing the category of words which can be both adverbs and prepositions/conjunctions (RB-IN).

We employ MBT, a memory-based tagger-generator and tagger (Daelemans et al, 1996) to produce apart-of-speech (PoS) tagger based on the ATB1corpus2. $$$$$ MBT

A particular instantiation, MBT, was proposed in (Daelemans et al, 1996). $$$$$ We use IGTrees (Daelemans et al. 1996) to compress the memory.
A particular instantiation, MBT, was proposed in (Daelemans et al, 1996). $$$$$ For a detailed discussion, see Daelemans et al. (1996).

We use the Memory-Based Tagger (Daelemans et al, 1996) trained on the Brown corpus to compute the part-of speech tags. $$$$$ MBT

Memory-based learning has been applied to a wide range of natural language processing tasks including part-of-speech tagging (Daelemans et al, 1996), dependency parsing (Nivre, 2003) and word sense disambiguation (Kubler and Zhekova, 2009). $$$$$ We introduce a memory-based approach to part of speech tagging.
Memory-based learning has been applied to a wide range of natural language processing tasks including part-of-speech tagging (Daelemans et al, 1996), dependency parsing (Nivre, 2003) and word sense disambiguation (Kubler and Zhekova, 2009). $$$$$ We use IGTrees (Daelemans et al. 1996) to compress the memory.

This fact prohibits the feeding of the training algorithms with patterns that have the form $$$$$ We use IGTrees (Daelemans et al. 1996) to compress the memory.
This fact prohibits the feeding of the training algorithms with patterns that have the form $$$$$ For a detailed discussion, see Daelemans et al. (1996).

Comparing our tree-induction algorithm and IGTREE, the algorithm used in MBT (Daelemans et al, 1996), their main difference is that IGTREE produces oblivious decision trees by supplying an a priori ordered list of best features instead of re-computing the best feature during each branching, which is our case. $$$$$ IGTree is a heuristic approximation of the IB-IG algorithm.
Comparing our tree-induction algorithm and IGTREE, the algorithm used in MBT (Daelemans et al, 1996), their main difference is that IGTREE produces oblivious decision trees by supplying an a priori ordered list of best features instead of re-computing the best feature during each branching, which is our case. $$$$$ In each case, output is a best guess of the category for the word in its current context.

The MBT POS tagger (Daelemans et al, 1996) is used to provide POS information. $$$$$ We use IGTrees (Daelemans et al. 1996) to compress the memory.
The MBT POS tagger (Daelemans et al, 1996) is used to provide POS information. $$$$$ For a detailed discussion, see Daelemans et al. (1996).

This material was POS-tagged using MBT (Memory Based Tagger) (Daelemans et al,1996). $$$$$ MBT

Its original PoS tag set is very coarse and the PoS and the word stem information is not very reliable. We therefore decided to retag the tree bank automatically using the Memory-Based Tagger (MBT) (Daelemans et al, 1996) which uses a very fine-grained tag set. $$$$$ In rule-based approaches, words are assigned a tag based on a set of rules and a lexicon.
Its original PoS tag set is very coarse and the PoS and the word stem information is not very reliable. We therefore decided to retag the tree bank automatically using the Memory-Based Tagger (MBT) (Daelemans et al, 1996) which uses a very fine-grained tag set. $$$$$ The architecture takes the form of a tagger generator given a corpus tagged with the desired tag set, a POS tagger is generated which maps the words of new text to tags in this tag set according to the same systematicity.
