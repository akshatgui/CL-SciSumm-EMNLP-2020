In particular, for this study we employ the MSR Paraphrase Corpus (Quirk et al, 2004). $$$$$ Koehn et al. 2003).
In particular, for this study we employ the MSR Paraphrase Corpus (Quirk et al, 2004). $$$$$ The raters were presented with an input sentence and an output paraphrase from each system in random order to prevent bias toward any particular judgment.

However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase pat terns are long or complicated (Quirk et al, 2004). $$$$$ Monolingual Machine Translation For Paraphrase Generation
However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase pat terns are long or complicated (Quirk et al, 2004). $$$$$ Changing a single content word is a legitimate form of paraphrase, and the ability to paraphrase across an arbitrarily large sentence set and arbitrary domains is a desideratum of paraphrase research.

Researchers employ the existing SMT models for PG (Quirk et al, 2004). $$$$$ Other researchers have sought to identify patterns in large unannotated monolingual corpora.
Researchers employ the existing SMT models for PG (Quirk et al, 2004). $$$$$ Koehn et al. 2003).

Baseline-1 follows the method pro posed in (Quirk et al, 2004), which generates paraphrases using typical SMT tools. $$$$$ We apply statistical machine translation (SMT) tools to generate novel paraphrases of input sentences in the same language.
Baseline-1 follows the method pro posed in (Quirk et al, 2004), which generates paraphrases using typical SMT tools. $$$$$ Moreover, PR generates at least five (and often hundreds more) distinct paraphrases for each test sentence.

Quirk et al (2004) also generate sentential paraphrases using a monolingual corpus. $$$$$ To generate paraphrases of a given input, a standard SMT decoding approach was used; this is described in more detail below.
Quirk et al (2004) also generate sentential paraphrases using a monolingual corpus. $$$$$ We showed that this approach can be used to generate paraphrases that are preferred by humans to sentence-level paraphrases produced by other techniques.

A similar approach to our sentence reconstruction method has been developed by Quirk et al (2004) for paraphrase generation. $$$$$ Monolingual Machine Translation For Paraphrase Generation
A similar approach to our sentence reconstruction method has been developed by Quirk et al (2004) for paraphrase generation. $$$$$ We approach this problem as one of statistical machine translation (SMT), within the noisy channel model of Brown et al. (1993).

As sentential paraphrasing is more likely to alter meaning, Quirk et al (Quirk et al, 2004) approached paraphrasing as a monotonous decoding by a phrase-based SMT system. $$$$$ Recent work in SMT has shown that simple phrase-based MT systems can outperform more sophisticated word-based systems (e.g.
As sentential paraphrasing is more likely to alter meaning, Quirk et al (Quirk et al, 2004) approached paraphrasing as a monotonous decoding by a phrase-based SMT system. $$$$$ Koehn et al. 2003).

Most paraphrase generation tools use some standard SMT decoding algorithms (Quirk et al., 2004) or some off-the-shelf decoding tools like Moses (Koehn et al, 2007). $$$$$ Koehn et al. 2003).
Most paraphrase generation tools use some standard SMT decoding algorithms (Quirk et al., 2004) or some off-the-shelf decoding tools like Moses (Koehn et al, 2007). $$$$$ To generate paraphrases of a given input, a standard SMT decoding approach was used; this is described in more detail below.

Quirk et al (2004) built a paraphrase generation model from a monolingual comparable corpus based on a statistical machine translation framework, where the language model assesses the grammaticality of the translations ,i.e., generated expressions. $$$$$ Monolingual Machine Translation For Paraphrase Generation
Quirk et al (2004) built a paraphrase generation model from a monolingual comparable corpus based on a statistical machine translation framework, where the language model assesses the grammaticality of the translations ,i.e., generated expressions. $$$$$ We approach this problem as one of statistical machine translation (SMT), within the noisy channel model of Brown et al. (1993).

Most paraphrase generators use some standard SMT decoding algorithms (Quirk et al, 2004) or some off-the-shelf decoding tools like MOSES. $$$$$ To generate paraphrases of a given input, a standard SMT decoding approach was used; this is described in more detail below.
Most paraphrase generators use some standard SMT decoding algorithms (Quirk et al, 2004) or some off-the-shelf decoding tools like MOSES. $$$$$ To begin the decoding process, we first constructed a lattice of all possible paraphrases of the source sentence based on our phrasal translation database.

Another piece of related work, (Quirk et al, 2004), starts off with parallel inputs and uses monolingual Statistical Machine Translation techniques to align them and generate novel sentences. $$$$$ Monolingual Machine Translation For Paraphrase Generation
Another piece of related work, (Quirk et al, 2004), starts off with parallel inputs and uses monolingual Statistical Machine Translation techniques to align them and generate novel sentences. $$$$$ We apply statistical machine translation (SMT) tools to generate novel paraphrases of input sentences in the same language.

Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ Koehn et al. 2003).
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ For example

Quirk et al (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events. $$$$$ The system is trained on large volumes of sentence pairs automatically extracted from clustered news articles available on the World Wide Web.
Quirk et al (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events. $$$$$ We held out a set of news clusters from our training data and extracted a set of 250 sentence pairs for blind evaluation.

Quirk et al (2004) present an end-to-end paraphrasing system inspired by phrase-based machine translation that can both ac quire paraphrases and use them to generate new strings. $$$$$ Monolingual Machine Translation For Paraphrase Generation
Quirk et al (2004) present an end-to-end paraphrasing system inspired by phrase-based machine translation that can both ac quire paraphrases and use them to generate new strings. $$$$$ We apply statistical machine translation (SMT) tools to generate novel paraphrases of input sentences in the same language.

Although there is a greater supply of paraphrasing corpora, such as the Multiple-Translation Chinese (MTC) corpus 1 and the Microsoft Research (MSR) Paraphrase Corpus (Quirk et al, 2004),. $$$$$ In more detail, we first gathered lexical translation probabilities of the form P(s

Outside of NLI, prior research has also explored the task of monolingual word alignment using extensions of statistical MT (Quirk et al, 2004) and multi-sequence alignment (Barzilay and Lee, 2002). $$$$$ Recent research has treated paraphrase acquisition and generation as a machine learning problem (Barzilay & McKeown, 2001; Lin & Pantel, 2002; Shinyama et al, 2002, Barzilay & Lee, 2003, Pang et al., 2003).
Outside of NLI, prior research has also explored the task of monolingual word alignment using extensions of statistical MT (Quirk et al, 2004) and multi-sequence alignment (Barzilay and Lee, 2002). $$$$$ These are accompanied by paraphrases generated by their Multi-Sequence Alignment (MSA) system and a baseline employing WordNet (Fellbaum 1998), along with human judgments for each output by 2-3 raters.

For other SMT methods, see Quirk et al (2004) and Bannard and Callison-Burch (2005) among others. $$$$$ Koehn et al. 2003).
For other SMT methods, see Quirk et al (2004) and Bannard and Callison-Burch (2005) among others. $$$$$ We accomplished this by using methods from the field of SMT, which is oriented toward learning and generating exactly the sorts of alternations encountered in monolingual paraphrase.

Paraphrase generation can be viewed as monolingual machine translation (Quirk et al, 2004), which typically includes a translation model and a language model. $$$$$ Monolingual Machine Translation For Paraphrase Generation
Paraphrase generation can be viewed as monolingual machine translation (Quirk et al, 2004), which typically includes a translation model and a language model. $$$$$ We approach this problem as one of statistical machine translation (SMT), within the noisy channel model of Brown et al. (1993).

Quirk et al (2004) first recast paraphrase generation as monolingual SMT. $$$$$ Monolingual Machine Translation For Paraphrase Generation
Quirk et al (2004) first recast paraphrase generation as monolingual SMT. $$$$$ Recent research has treated paraphrase acquisition and generation as a machine learning problem (Barzilay & McKeown, 2001; Lin & Pantel, 2002; Shinyama et al, 2002, Barzilay & Lee, 2003, Pang et al., 2003).

The SMT-based paraphrasing model used by Quirk et al (2004) was the noisy channel model of Brown et al (1993), which identified the optimal paraphrase T of a sentence S by finding. $$$$$ We approach this problem as one of statistical machine translation (SMT), within the noisy channel model of Brown et al. (1993).
The SMT-based paraphrasing model used by Quirk et al (2004) was the noisy channel model of Brown et al (1993), which identified the optimal paraphrase T of a sentence S by finding. $$$$$ That is, we seek to identify the optimal paraphrase T* of a sentence S by finding
