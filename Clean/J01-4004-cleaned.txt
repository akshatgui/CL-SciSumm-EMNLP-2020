Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0). $$$$$ The work of Aone and Bennett (1995), McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996) employed decision tree learning.
Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0). $$$$$ The RESOLVE system is presented in McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996).

It was criticized (Soon et al, 2001) that the features used by McCarthy and Lehnert (1995) are highly idiosyncratic and applicable only to one particular domain. $$$$$ The RESOLVE system is described in three papers: McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996).
It was criticized (Soon et al, 2001) that the features used by McCarthy and Lehnert (1995) are highly idiosyncratic and applicable only to one particular domain. $$$$$ The RESOLVE system is presented in McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996).

Soon et al (2001) use twelve features (see Table 1). $$$$$ Table 3 and Table 4 show the results of the experiment.
Soon et al (2001) use twelve features (see Table 1). $$$$$ RESOLVE makes use of 39 features, considerably more than our system's 12 features.

Soon et al (2001) include all noun phrases returned by their NP identifier and report an F-measure of 62.6% for MUC-6 data and 60.4% for MUC-7 data. $$$$$ Since these features are highly informative, we were curious to see how much they contribute to our MUC-6 and MUC-7 results of 62.6% and 60.4%, respectively.
Soon et al (2001) include all noun phrases returned by their NP identifier and report an F-measure of 62.6% for MUC-6 data and 60.4% for MUC-7 data. $$$$$ We evaluated our approach on common data sets, namely, the MUC-6 and MUC-7 coreference corpora.

Features like the string ident and substring match features were used by other researchers (Soon et al, 2001), while the features ante med and ana med were used by Strube et al (2002) in order to improve the performance for definite NPs. $$$$$ One factor that affects the performance of a machine learning approach is the set of features used.
Features like the string ident and substring match features were used by other researchers (Soon et al, 2001), while the features ante med and ana med were used by Strube et al (2002) in order to improve the performance for definite NPs. $$$$$ The features used were slightly changed for this domain.

However, reference resolution algorithms based on these classifiers achieve reasonable performance of about 60 to 63% F-measure (Soon et al, 2001). $$$$$ However, its F-measure is comparable to that of STR_MATCH.
However, reference resolution algorithms based on these classifiers achieve reasonable performance of about 60 to 63% F-measure (Soon et al, 2001). $$$$$ For MUC-7, there is no drop in F-measure; for MUC-6, the F-measure dropped slightly.

While the second best system (Bjorkelund and Farkas, 2012) followed the widely used baseline of Soon et al (2001), the winning system (Fernandes et al, 2012) proposed the use of a tree representation. $$$$$ C5 is a commonly used decision tree learning algorithm and thus it may be considered as a baseline method against which other learning algorithms can be compared.
While the second best system (Bjorkelund and Farkas, 2012) followed the widely used baseline of Soon et al (2001), the winning system (Fernandes et al, 2012) proposed the use of a tree representation. $$$$$ Fisher et al. (1995) adapted RESOLVE to work in MUC-6.

For instance, the popular pairwise instance creation method suggested by Soon et al (2001) assumes non-branching trees, where the antecedent of every mention is its linear predecessor (i.e., he b 2 is the antecedent of Gary Wilber b 3). $$$$$ For each j, the algorithm considers every markable i before j as a potential antecedent.
For instance, the popular pairwise instance creation method suggested by Soon et al (2001) assumes non-branching trees, where the antecedent of every mention is its linear predecessor (i.e., he b 2 is the antecedent of Gary Wilber b 3). $$$$$ A coreferring antecedent is found if the classifier returns true.

By using a simple co-reference resolution tool adapted from (Soon et al, 2001), we add all the mentions referring to the target into the extended target set. $$$$$ Our result is encouraging since it indicates that a learning approach using relatively shallow features can achieve scores comparable to those of systems built using nonlearning approaches.
By using a simple co-reference resolution tool adapted from (Soon et al, 2001), we add all the mentions referring to the target into the extended target set. $$$$$ Fisher et al. (1995) adapted RESOLVE to work in MUC-6.

Instances are created following Soon et al (2001). $$$$$ The following two subsections describe the errors in more detail.
Instances are created following Soon et al (2001). $$$$$ Fisher et al. (1995) adapted RESOLVE to work in MUC-6.

Following Ng & Cardie (2002), our baseline system reimplements the Soon et al (2001) system. $$$$$ Other baseline systems that are used are ONE_CHAIN, ONE_WRD, and HD_WRD (Cardie and Wagstaff 1999).
Following Ng & Cardie (2002), our baseline system reimplements the Soon et al (2001) system. $$$$$ The following two subsections describe the errors in more detail.

We start with a baseline system using all the features from Soon et al (2001) that were not removed in the feature selection process (i.e. DISTANCE). $$$$$ The distance feature has different effects on different noun phrases.
We start with a baseline system using all the features from Soon et al (2001) that were not removed in the feature selection process (i.e. DISTANCE). $$$$$ In terms of absolute Fmeasure, the difference between using these three features and using all features is 2.3% for MUC-6 and 1% for MUC-7; in other words, the other nine features contribute just 2.3% and 1% more for each of the MUC years.

It supports both local (Soon et al (2001)-style) and global (ILP, Denis and Baldridge (2007)-style) models of coreference. $$$$$ We also implemented a module that recognizes MUC-style named entities, that is, organization, person, location, date, time, money, and percent.
It supports both local (Soon et al (2001)-style) and global (ILP, Denis and Baldridge (2007)-style) models of coreference. $$$$$ On the other hand, the markables extracted by our system include nested noun phrases, MUC-style named entity types (money, percent, date, etc.

Our local model of coreference is a reimplementation of the algorithm, proposed by Soon et al (2001) with an extended feature set. $$$$$ RESOLVE's feature set includes the two highly informative features, ALIAS and STR_MATCH.
Our local model of coreference is a reimplementation of the algorithm, proposed by Soon et al (2001) with an extended feature set. $$$$$ Fisher et al. (1995) adapted RESOLVE to work in MUC-6.

PAIRWISE: as in the work by Soon et al (2001), antecedent identification and anaphoricity determination are simultaneously executed by a single classifier. $$$$$ A coreferring antecedent is found if the classifier returns true.
PAIRWISE: as in the work by Soon et al (2001), antecedent identification and anaphoricity determination are simultaneously executed by a single classifier. $$$$$ Fisher et al. (1995) adapted RESOLVE to work in MUC-6.

Our event-anaphora resolution system adopts the common learning-based model for object anaphora resolution, as employed by (Soon et al, 2001) and (Ng and Cardie, 2002a). $$$$$ A Machine Learning Approach To Coreference Resolution Of Noun Phrases
Our event-anaphora resolution system adopts the common learning-based model for object anaphora resolution, as employed by (Soon et al, 2001) and (Ng and Cardie, 2002a). $$$$$ We adopt a corpus-based, machine learning approach to noun phrase coreference resolution.

We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al, 2001). $$$$$ A Machine Learning Approach To Coreference Resolution Of Noun Phrases
We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al, 2001). $$$$$ Such knowledge sources are commonly used for the task of determining coreference.

Soon et al (2001) use the Closest-Link method: They select as an antecedent the closest preceding mention that is predicted coreferential by a pairwise coreference module; this is equivalent to choosing the closest mention whose pc value is above a threshold. $$$$$ Since WordNet orders the senses of a noun by their frequency, this is equivalent to choosing the most frequent sense as the semantic class for each noun.
Soon et al (2001) use the Closest-Link method: They select as an antecedent the closest preceding mention that is predicted coreferential by a pairwise coreference module; this is equivalent to choosing the closest mention whose pc value is above a threshold. $$$$$ We use the same method to generate coreference chains for both MUC-6 and MUC7, except for the following.

Distance features are important for a system that makes links based on the best pairwise coreference value rather than implicitly incorporating distance by linking only the closest pair whose score is above a threshold, as done by e.g. Soon et al (2001). $$$$$ One important factor is the distance between the two markables.
Distance features are important for a system that makes links based on the best pairwise coreference value rather than implicitly incorporating distance by linking only the closest pair whose score is above a threshold, as done by e.g. Soon et al (2001). $$$$$ We include the distance feature so that the learning algorithm can best decide the distribution for different classes of noun phrases.

The remaining predicates in Table 1 are a subset of features used by other coreference resolution systems (cf. Soon et al., 2001). $$$$$ Table 3 and Table 4 show the results of the experiment.
The remaining predicates in Table 1 are a subset of features used by other coreference resolution systems (cf. Soon et al., 2001). $$$$$ Systems ALIAS_STR and ALIAS_STR_APPOS in Table 3 and Table 4 show the results of the experiment.
