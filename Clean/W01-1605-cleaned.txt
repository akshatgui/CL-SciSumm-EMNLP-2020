The additional two systems were $$$$$ We decided to use RST for three reasons

We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RSTDTB) (Carlsonetal., 2001) distributed by the Linguistic Data Consortium (LDC). $$$$$ Two essential considerations from the outset were that the corpus needed to be consistently annotated, and that it would be made publicly available through the Linguistic Data Consortium for a nominal fee to cover distribution costs.
We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RSTDTB) (Carlsonetal., 2001) distributed by the Linguistic Data Consortium (LDC). $$$$$ In selecting these documents, we partnered with the Linguistic Data Consortium to select Penn Treebank texts for which the syntactic bracketing was known to be of high caliber.

Two of the main corpora with discourse annotations are the RST Discourse Treebank (RSTDT) (Carlson et al., 2001) and the Penn Discourse Treebank (PDTB) (Prasad et al, 2008a), which are both based on the Wall Street Journal (WSJ) corpus. $$$$$ The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.
Two of the main corpora with discourse annotations are the RST Discourse Treebank (RSTDT) (Carlson et al., 2001) and the Penn Discourse Treebank (PDTB) (Prasad et al, 2008a), which are both based on the Wall Street Journal (WSJ) corpus. $$$$$ The RST Corpus consists of 385 Wall Street Journal articles from the Penn Treebank, representing over 176,000 words of text.

Fortunately, RST Discourse Treebank (RSTDT) (Carlson et al, 2001) is an available resource to help with. $$$$$ In this paper, we recount our experience in developing a large resource with discourse-level annotation for NLP research.
Fortunately, RST Discourse Treebank (RSTDT) (Carlson et al, 2001) is an available resource to help with. $$$$$ The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.

In the Cause versus Contrast case, their reported performance exceeds ours significantly; however, in a subset of their experiments which test Cause versus Contrast on instances from the human annotated RSTBank corpus (Carlson et al., 2001) where no cue phrase is present, they report only 63% accuracy over a 56% baseline (the baseline is $$$$$ The 78 relations used in annotating the corpus can be partitioned into 16 classes that share some type of rhetorical meaning

 $$$$$ In addition, three relations are used to impose structure on the tree

For the first, the labelled/unlabelled relations f scores are 50.3% /73.0% and for the latter, they are 75.3% /84.0% $$$$$ So far, the annotation of discourse structure of documents has been applied primarily to identifying topical segments (Hearst, 1997), inter-sentential relations (Nomoto and Matsumoto, 1999; Tsâ€™ou et al., 2000), and hierarchical analyses of small corpora (Moser and Moore, 1995; Marcu et al., 1999).
For the first, the labelled/unlabelled relations f scores are 50.3% /73.0% and for the latter, they are 75.3% /84.0% $$$$$ More extensive analysis of the final tagged corpus will demonstrate the extent to which individual relations that are similar in semantic content were distinguished consistently during the tagging process.

The generator is informed by a corpus study of embedded discourse units on two discourse annotated corpora $$$$$ The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.
The generator is informed by a corpus study of embedded discourse units on two discourse annotated corpora $$$$$ A growing number of groups have developed or are developing discourse-annotated corpora for text.

We evaluate DPLP on the RST Discourse Tree bank (Carlson et al, 2001), comparing against state-of-the-art results. $$$$$ Syntactic checking involved ensuring that the tree had a single root node and comparing the tree to the document to check for missing sentences or fragments from the end of the text.
We evaluate DPLP on the RST Discourse Tree bank (Carlson et al, 2001), comparing against state-of-the-art results. $$$$$ These scores reflect very strong agreement and represent a significant improvement over previously reported results on annotating multiple texts in the RST framework (Marcu et al., 1999).

To compare with previous works on RSTDT, we use the 18 coarse-grained relations defined in (Carlson et al, 2001). $$$$$ The kappa coefficient (Siegel and Castellan, 1988) has been used extensively in previous empirical studies of discourse (Carletta et al., 1997; Flammia and Zue, 1995; Passonneau and Litman, 1997).
To compare with previous works on RSTDT, we use the 18 coarse-grained relations defined in (Carlson et al, 2001). $$$$$ Because the RST theory does not differentiate between different levels of the tree structure, a fairly fine-grained set of relations operates between EDUs and EDU clusters at the macrolevel.

(Carlson et al 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion. $$$$$ We tracked inter-annotator agreement during each phase of the project, using a method developed by Marcu et al. (1999) for computing kappa statistics over hierarchical structures.
(Carlson et al 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion. $$$$$ Results are based on pre-segmented documents.

To demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the RST parsed Wall Street Journal corpus as input (Carlson et al, 2001). $$$$$ Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).
To demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the RST parsed Wall Street Journal corpus as input (Carlson et al, 2001). $$$$$ The RST Corpus consists of 385 Wall Street Journal articles from the Penn Treebank, representing over 176,000 words of text.

In Discourse Tree Bank (Carlson et al, 2001) only 26% of Contrast relations were indicated by cue phrases while in NTC-7 about 70% of Contrast were indicated by cue phrases. $$$$$ We opted for consistency in segmenting, sacrificing some potentially discourse-relevant phrases in the process.
In Discourse Tree Bank (Carlson et al, 2001) only 26% of Contrast relations were indicated by cue phrases while in NTC-7 about 70% of Contrast were indicated by cue phrases. $$$$$ ]26 wsj_1111 The discourse sub-tree for this text fragment is given in Figure 1.

They use the RST corpus (Carlson et al,2001), which contains 385 Wall Street Journal articles annotated following the Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ Our annotation work is grounded in the Rhetorical Structure Theory (RST) framework (Mann and Thompson, 1988).
They use the RST corpus (Carlson et al,2001), which contains 385 Wall Street Journal articles annotated following the Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ The RST Corpus consists of 385 Wall Street Journal articles from the Penn Treebank, representing over 176,000 words of text.

(Soricut and Marcu, 2003) parsed the discourse structures of sentences on RST Bank data set (Carlson et al, 2001) which is annotated based on Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ Our annotation work is grounded in the Rhetorical Structure Theory (RST) framework (Mann and Thompson, 1988).
(Soricut and Marcu, 2003) parsed the discourse structures of sentences on RST Bank data set (Carlson et al, 2001) which is annotated based on Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).

The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), is a corpus annotated in the framework of RST. $$$$$ The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.
The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), is a corpus annotated in the framework of RST. $$$$$ Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).

In the corpus of Rhetorical Structure trees built by Carlson et al (2001), for example, we have observed that only 61 of 238 CONTRAST relation sand 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase. $$$$$ Once the elementary units of discourse have been determined, adjacent spans are linked together via rhetorical relations creating a hierarchical structure.
In the corpus of Rhetorical Structure trees built by Carlson et al (2001), for example, we have observed that only 61 of 238 CONTRAST relation sand 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase. $$$$$ Multinuclear relations hold among two or more spans of equal weight in the discourse structure.

However, empirical work of Marcu (2000) and Carlson et al (2001) suggests that the majority of occurrences of but, for example, do signal CONTRAST relations. $$$$$ We decided to use RST for three reasons

To test this, we used the corpus of discourse trees built in the style of RST by Carlson et al (2001). $$$$$ We decided to use RST for three reasons

If no cue phrases are used to signal the relation between two elementary discourse units, an automatic discourse labeler can at best guess that an ELABORATION relation holds between the units, because ELABORATION relations are the most frequently used relations (Carlson et al, 2001). $$$$$ Once the elementary units of discourse have been determined, adjacent spans are linked together via rhetorical relations creating a hierarchical structure.
If no cue phrases are used to signal the relation between two elementary discourse units, an automatic discourse labeler can at best guess that an ELABORATION relation holds between the units, because ELABORATION relations are the most frequently used relations (Carlson et al, 2001). $$$$$ In addition, three relations are used to impose structure on the tree
