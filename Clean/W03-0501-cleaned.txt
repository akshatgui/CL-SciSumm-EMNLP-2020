A more common, extractive approach operates top-down, by starting from an extracted sentence that is compressed (Dorr et al, 2003) and annotated with additional information (Zajic et al, 2004). $$$$$ Other researchers have investigated the topic of automatic generation of abstracts, but the focus has been different, e.g., sentence extraction (Edmundson, 1969; Johnson et al, 1993; Kupiec et al., 1995; Mann et al., 1992; Teufel and Moens, 1997; Zechner, 1995), processing of structured templates (Paice and Jones, 1993), sentence compression (Hori et al., 2002; Knight and Marcu, 2001; Grefenstette, 1998, Luhn, 1958), and generation of abstracts from multiple sources (Radev and McKeown, 1998).
A more common, extractive approach operates top-down, by starting from an extracted sentence that is compressed (Dorr et al, 2003) and annotated with additional information (Zajic et al, 2004). $$$$$ This approach has been explored in (Zajic et al., 2002) and (Banko et al., 2000).

HedgeTrimmer is our implementation of the Hedge Trimer system (Dorr et al, 2003), and Topiary is our implementation of the Topiary system (Zajicet al, 2004). $$$$$ Other researchers have investigated the topic of automatic generation of abstracts, but the focus has been different, e.g., sentence extraction (Edmundson, 1969; Johnson et al, 1993; Kupiec et al., 1995; Mann et al., 1992; Teufel and Moens, 1997; Zechner, 1995), processing of structured templates (Paice and Jones, 1993), sentence compression (Hori et al., 2002; Knight and Marcu, 2001; Grefenstette, 1998, Luhn, 1958), and generation of abstracts from multiple sources (Radev and McKeown, 1998).
HedgeTrimmer is our implementation of the Hedge Trimer system (Dorr et al, 2003), and Topiary is our implementation of the Topiary system (Zajicet al, 2004). $$$$$ This approach has been explored in (Zajic et al., 2002) and (Banko et al., 2000).

For this reason, most early headline generation work focused on either extracting and reordering n-grams from the document to be summarized (Banko et al., 2000), or extracting one or two informative sentences from the document and performing linguistically-motivated transformations to them in order to reduce the summary length (Dorr et al., 2003). $$$$$ Finally, we evaluate Hedge Trimmer by comparing it to our earlier work on headline generation, a probabilistic model for automatic headline generation (Zajic et al, 2002).
For this reason, most early headline generation work focused on either extracting and reordering n-grams from the document to be summarized (Banko et al., 2000), or extracting one or two informative sentences from the document and performing linguistically-motivated transformations to them in order to reduce the summary length (Dorr et al., 2003). $$$$$ This approach has been explored in (Zajic et al., 2002) and (Banko et al., 2000).

Hedge Trimmer (Dorr et al, 2003) is a system that creates a headline for an English newspaper story using linguistically-motivated heuristics to choose a potential headline. $$$$$ In this paper we present Hedge Trimmer, a HEaDline GEneration system that creates a headline for a newspaper story by removing constituents from a parse tree of the first sentence until a length threshold has been reached.
Hedge Trimmer (Dorr et al, 2003) is a system that creates a headline for an English newspaper story using linguistically-motivated heuristics to choose a potential headline. $$$$$ However, we use linguistically motivated heuristics for shortening the sentence; there is no statistical model, which means we do not require any prior training on a large corpus of story/headline pairs.

The algorithm used by Dorr et al (2003) removes subordinate clauses, to name one example. $$$$$ The BBN parser has been used successfully for the task of information extraction in the SIFT system (Miller et al., 2000).
The algorithm used by Dorr et al (2003) removes subordinate clauses, to name one example. $$$$$ This approach has been explored in (Zajic et al., 2002) and (Banko et al., 2000).

 $$$$$ Step 2 of our algorithm eliminates low-content units.
 $$$$$ We would like to thank Naomi Chang and Jon Teske for generating reference headlines.

 $$$$$ Step 2 of our algorithm eliminates low-content units.
 $$$$$ We would like to thank Naomi Chang and Jon Teske for generating reference headlines.
