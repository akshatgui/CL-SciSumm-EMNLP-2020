Bikel et al (Bikel et al, 1997) report on Nymble, an HMM-based name tagging system operating in English and Spanish. $$$$$ More recently, the natural language processing community has effectively employed these models for part-ofspeech tagging, as in the seminal (Church, 1988) and other, more recent efforts (Weischedel et al., 1993).
Bikel et al (Bikel et al, 1997) report on Nymble, an HMM-based name tagging system operating in English and Spanish. $$$$$ We report the results for English and for Spanish and then the results of a set of experiments to determine the impact of the training set size on the algorithm's performance in both English and Spanish.

Most commonly, feature-based classifiers use a set of capitalisation features and a sentence-initial feature (Bikel et al, 1997). $$$$$ The word feature is the one part of this model which is language-dependent.
Most commonly, feature-based classifiers use a set of capitalisation features and a sentence-initial feature (Bikel et al, 1997). $$$$$ We then expanded the feature set to its current state in order to capture more subtleties related mostly to numbers; due to increased performance (although not entirely dramatic) on every test, we kept the enlarged feature set.

Nymble (Bikel et al, 1997) uses statistical learning to acquire a Hidden Markov Model (HMM) that recognises NEs in text. $$$$$ Nymble

(Bikelet al, 1997) are other examples of the use of HMMs. $$$$$ Within each of the name-class states, we use a statistical bigram language model, with the usual one-word-per-state emission.
(Bikelet al, 1997) are other examples of the use of HMMs. $$$$$ Contrary to our expectations (which were based on our experience with English), Spanish contained many examples of lower-case words in organization and location names.

Our chunk-based system takes the last word of the chunk as its head word for the purposes of predicting roles, but does not make use of the identities of the chunk's other words or the intervening words between a chunk and the predicate, unlike Hidden Markov Model-like systems such as Bikel et al (1997), McCallum et al (2000) and Laerty et al (2001). $$$$$ In order to generate the first word, we must make a transition from one name-class to another, as well as calculate the likelihood of that word.
Our chunk-based system takes the last word of the chunk as its head word for the purposes of predicting roles, but does not make use of the identities of the chunk's other words or the intervening words between a chunk and the predicate, unlike Hidden Markov Model-like systems such as Bikel et al (1997), McCallum et al (2000) and Laerty et al (2001). $$$$$ Unlike a traditional HMM, the probability of generating a particular word is 1 for each word-state inside each of the name-class states.

We were already using a generative statistical model for part-of-speech tagging (Weischedel et al 1993), and more recently, had begun using a generative statistical model for name finding (Bikel et al 1997). $$$$$ This paper presents a statistical, learned approach to finding names and other nonrecursive entities in text (as per the MUC-6 definition of the NE task), using a variant of the standard hidden Markov model.
We were already using a generative statistical model for part-of-speech tagging (Weischedel et al 1993), and more recently, had begun using a generative statistical model for name finding (Bikel et al 1997). $$$$$ More recently, the natural language processing community has effectively employed these models for part-ofspeech tagging, as in the seminal (Church, 1988) and other, more recent efforts (Weischedel et al., 1993).

The HMM tagger generally follows the Nymble model (Bikel et al 1997), and uses best-first search to generate N-Best hypotheses for each input sentence. $$$$$ To our knowledge, Nymble out-performs the best published results of any other learning name-finder.
The HMM tagger generally follows the Nymble model (Bikel et al 1997), and uses best-first search to generate N-Best hypotheses for each input sentence. $$$$$ Table 4.1 illustrates Nymble's performance as compared to the best reported scores for each category.

The base system is an HMM based tagger, similar to (Bikel et al, 1997). $$$$$ We would now propose that HMM's have successfully been applied to the problem of name-finding.
The base system is an HMM based tagger, similar to (Bikel et al, 1997). $$$$$ To our knowledge, our learned name-finding system has achieved a higher F-measure than any other learned system when compared to state-of-the-art manual (rule-based) systems on similar data.

The alternative to true casing text is to destroy case information in the training material SNORIFY procedure in (Bikel et al, 1997). $$$$$ Given this maximum size of training available to us, we successfully divided the training material in half until we were using only one eighth of the original training set size or a training set of 50,000 words for the smallest experiment.
The alternative to true casing text is to destroy case information in the training material SNORIFY procedure in (Bikel et al, 1997). $$$$$ We also measured the performance of the system with half the training data or slightly more than 100,000 words of text.

The typical machine learning approaches for English NE are transformation-based learning [Aberdeen et al 1995], hidden Markov model [Bikel et al. 1997], maximum entropy model [Borthwick, 1999], support vector machine learning [Eunji Yi et al 2004], unsupervised model [Collins et al 1999] and etc. $$$$$ (2.2) Previous approaches have typically used manually constructed finite state patterns (Weischodel, 1995, Appelt et al., 1995).
The typical machine learning approaches for English NE are transformation-based learning [Aberdeen et al 1995], hidden Markov model [Bikel et al. 1997], maximum entropy model [Borthwick, 1999], support vector machine learning [Eunji Yi et al 2004], unsupervised model [Collins et al 1999] and etc. $$$$$ In addition to these finitestate pattern approaches, a variant of Brill rules has been applied to the problem, as outlined in (Aberdeen et al., 1995).

Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al, 1997), the dictionary HMM model (Kouetal., 2005) and Maximum Entropy Markov Mod els (MEMMs) (Finkel et al, 2004). $$$$$ In the past decade, the speech recognition community has had huge successes in applying hidden Markov models, or HMM's to their problems.
Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al, 1997), the dictionary HMM model (Kouetal., 2005) and Maximum Entropy Markov Mod els (MEMMs) (Finkel et al, 2004). $$$$$ (2.2) Previous approaches have typically used manually constructed finite state patterns (Weischodel, 1995, Appelt et al., 1995).

These include rule-based systems [Krupka 1998], Hidden Markov Models (HMM) [Bikel et al 1997] and Maximum Entropy Models (MaxEnt) [Borthwick 1998]. $$$$$ In the past decade, the speech recognition community has had huge successes in applying hidden Markov models, or HMM's to their problems.
These include rule-based systems [Krupka 1998], Hidden Markov Models (HMM) [Bikel et al 1997] and Maximum Entropy Models (MaxEnt) [Borthwick 1998]. $$$$$ We will describe the various models employed, the methods for training these models and the method for &quot;decoding&quot; on test data (the term &quot;decoding&quot; borrowed from the speech recognition community, since one goal of traversing an HMM is to recover the hidden state sequence).

constrained HMM Our original HMM is similar to the Nymble [Bikel et al 1997] system that is based on bigram statistics. $$$$$ We would now propose that HMM's have successfully been applied to the problem of name-finding.
constrained HMM Our original HMM is similar to the Nymble [Bikel et al 1997] system that is based on bigram statistics. $$$$$ We have built a named-entity (NE) recognition system using a slightly-modified version of an HMM; we call our system &quot;Nymble&quot;.

In addition, an automatic named entity tagger (Bikel et al, 1997) was run on the sentences to map proper nouns to a small set of semantic classes. $$$$$ We have built a named-entity (NE) recognition system using a slightly-modified version of an HMM; we call our system &quot;Nymble&quot;.
In addition, an automatic named entity tagger (Bikel et al, 1997) was run on the sentences to map proper nouns to a small set of semantic classes. $$$$$ Although the part-of-speech tagger used capitalization to help it determine proper-noun tags, this feature was only implicit in the model, and then only after two levels of back-off!

A. wide variety of machine learning methods have been applied to this problem, including Hidden Markov Models (Bikel et al 1997), Maximum Entropy methods (Borthwick et al 1998, Chieu and Ng 2002), Decision Trees (Sekine et al 1998), Conditional Random Fields (McCallum and Li 2003), Class-based Language Model (Sun et al 2002), Agent-based Approach (Ye et al 2002) and Support Vector Machines. $$$$$ More recently, the natural language processing community has effectively employed these models for part-ofspeech tagging, as in the seminal (Church, 1988) and other, more recent efforts (Weischedel et al., 1993).
A. wide variety of machine learning methods have been applied to this problem, including Hidden Markov Models (Bikel et al 1997), Maximum Entropy methods (Borthwick et al 1998, Chieu and Ng 2002), Decision Trees (Sekine et al 1998), Conditional Random Fields (McCallum and Li 2003), Class-based Language Model (Sun et al 2002), Agent-based Approach (Ye et al 2002) and Support Vector Machines. $$$$$ In addition to these finitestate pattern approaches, a variant of Brill rules has been applied to the problem, as outlined in (Aberdeen et al., 1995).

Another related work is (Bikel et al, 1997) which used HMMs as part of its modelling for the name finding problem in information extraction. $$$$$ We would now propose that HMM's have successfully been applied to the problem of name-finding.
Another related work is (Bikel et al, 1997) which used HMMs as part of its modelling for the name finding problem in information extraction. $$$$$ The atomic elements of information extraction— indeed, of language as a whole—could be considered the who, where, when and how much in a sentence.

A common approach is to extract word-internal features from unknown words, for example suffix, capitalization, or punctuation features (Mikheev, 1997, Wacholder et al, 1997, Bikel et al, 1997). $$$$$ Also, most of the word features are used to distinguish types of numbers, which are language-independent.2 The rationale for having such features is clear

Our baseline name tagger is based on an HMM that generally follows the Nymble model (Bikel et al 1997). $$$$$ We have built a named-entity (NE) recognition system using a slightly-modified version of an HMM; we call our system &quot;Nymble&quot;.
Our baseline name tagger is based on an HMM that generally follows the Nymble model (Bikel et al 1997). $$$$$ More generally how does performance vary as the training set size is increased or decreased?

As hidden Markov models have been used both for name finding (Bikel et al (1997)) and tokenization (Cutting et al. $$$$$ In the past decade, the speech recognition community has had huge successes in applying hidden Markov models, or HMM's to their problems.
As hidden Markov models have been used both for name finding (Bikel et al (1997)) and tokenization (Cutting et al. $$$$$ (2.2) Previous approaches have typically used manually constructed finite state patterns (Weischodel, 1995, Appelt et al., 1995).

In addition, an automatic named entity tagger (Bikel et al, 1997) was run on the sentences to map proper nouns to a small set of semantic classes. $$$$$ We have built a named-entity (NE) recognition system using a slightly-modified version of an HMM; we call our system &quot;Nymble&quot;.
In addition, an automatic named entity tagger (Bikel et al, 1997) was run on the sentences to map proper nouns to a small set of semantic classes. $$$$$ Although the part-of-speech tagger used capitalization to help it determine proper-noun tags, this feature was only implicit in the model, and then only after two levels of back-off!
