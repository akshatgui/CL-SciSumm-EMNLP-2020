In our experiments, we implement the feature-enriched tree kernel by extending the SVMlight (Joachims, 1998) with the proposed tree kernel function (Moschitti, 2004). $$$$$ It is worth noting that even if the above equations define a kernel function similar to the one proposed in (Collins and Duffy, 2002), the substructures on which it operates are different from the parse-tree kernel.
In our experiments, we implement the feature-enriched tree kernel by extending the SVMlight (Joachims, 1998) with the proposed tree kernel function (Moschitti, 2004). $$$$$ The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations.

The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ The resulting set of kernels used in the experiments is the following

 $$$$$ The circled substructures in (a), (b) and (c) are our semantic objects associated with the three arguments of the verb to deliver, i.e.
 $$$$$ Other studies may relate to the use of SCF to generate verb clusters.

We used support vector machines (Vapnik, 1995) with (a) polynomial kernels to learn the semantic role classification and (b) Tree Kernels (Moschitti, 2004) for learning both frame and ILC classification. $$$$$ Support Vector Machines (SVMs), using a combination of such kernels and the flat feature kernel, classify Prop- Bank predicate arguments with accuracy higher the current argument classification state- Additionally, experiments on FrameNet data have shown that SVMs are appealing for the classification of semantic roles even if the proposed kernels do not produce any improvement.
We used support vector machines (Vapnik, 1995) with (a) polynomial kernels to learn the semantic role classification and (b) Tree Kernels (Moschitti, 2004) for learning both frame and ILC classification. $$$$$ Experiments on Support Vector Machines using the above kernels show an improvement of the state-of-the-art for PropBank argument classification.

 $$$$$ The circled substructures in (a), (b) and (c) are our semantic objects associated with the three arguments of the verb to deliver, i.e.
 $$$$$ Other studies may relate to the use of SCF to generate verb clusters.

The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ The resulting set of kernels used in the experiments is the following

 $$$$$ The circled substructures in (a), (b) and (c) are our semantic objects associated with the three arguments of the verb to deliver, i.e.
 $$$$$ Other studies may relate to the use of SCF to generate verb clusters.

As shown in (Moschitti, 2004), we can label semantic roles by classifying the smallest subtree that includes the predicate with one of its arguments, i.e. the so called PAF structure. $$$$$ Frame elements or semantic roles are arguments of predicates called target words.
As shown in (Moschitti, 2004), we can label semantic roles by classifying the smallest subtree that includes the predicate with one of its arguments, i.e. the so called PAF structure. $$$$$ The smallest sub-structure which includes one predicate with only one of its arguments defines our structural feature.

 $$$$$ The circled substructures in (a), (b) and (c) are our semantic objects associated with the three arguments of the verb to deliver, i.e.
 $$$$$ Other studies may relate to the use of SCF to generate verb clusters.

For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). $$$$$ The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations.
For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). $$$$$ To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light.

In (Moschitti, 2004), an alternative to the SCF extraction was proposed, i.e. the SCF kernel (SK). $$$$$ Second, SCF improves the polynomial kernel (d = 3), i.e. the current state-of-the-art, of about 3 percent points on PropBank (column SCFÂ·P).
In (Moschitti, 2004), an alternative to the SCF extraction was proposed, i.e. the SCF kernel (SK). $$$$$ No kernel combinations with both PAF and SCF produce an improvement.

A preliminary study on the benefit of such kernels was measured on the classification accuracy of semantic arguments in (Moschitti, 2004). $$$$$ Support Vector Machines (SVMs), using a combination of such kernels and the flat feature kernel, classify Prop- Bank predicate arguments with accuracy higher the current argument classification state- Additionally, experiments on FrameNet data have shown that SVMs are appealing for the classification of semantic roles even if the proposed kernels do not produce any improvement.
A preliminary study on the benefit of such kernels was measured on the classification accuracy of semantic arguments in (Moschitti, 2004). $$$$$ To study the impact of our structural kernels we firstly derived the maximal accuracy reachable with standard features along with polynomial kernels.

The convolution kernel that we have experimented was devised in (Moschitti, 2004) and is characterized by two aspects $$$$$ (PAF) We consider the predicate argument structures annotated in PropBank or FrameNet as our semantic space.
The convolution kernel that we have experimented was devised in (Moschitti, 2004) and is characterized by two aspects $$$$$ In this paper, we have experimented with SVMs using the two novel convolution kernels PAF and SCF which are designed for the semantic structures derived from PropBank and FrameNet corpora.

The evaluations were carried out with the SVMlight-TK software (Moschitti, 2004) available at http $$$$$ The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations.
The evaluations were carried out with the SVMlight-TK software (Moschitti, 2004) available at http $$$$$ To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light.

Here we use the same convolution parse tree kernel as described in Collins and Duffy (2001) for syntactic parsing and Moschitti (2004) for semantic role labeling. $$$$$ Given the semantic objects defined in the previous section, we design a convolution kernel in a way similar to the parse-tree kernel proposed in (Collins and Duffy, 2002).
Here we use the same convolution parse tree kernel as described in Collins and Duffy (2001) for syntactic parsing and Moschitti (2004) for semantic role labeling. $$$$$ It is worth noting that even if the above equations define a kernel function similar to the one proposed in (Collins and Duffy, 2002), the substructures on which it operates are different from the parse-tree kernel.

In our implementation, we use the binary SVMLight (Joachims, 1998) and Tree Kernel Tools (Moschitti, 2004). $$$$$ The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations.
In our implementation, we use the binary SVMLight (Joachims, 1998) and Tree Kernel Tools (Moschitti, 2004). $$$$$ On 10Unfortunately the use of a polynomial kernel on top the tree fragments to generate the XOR functions seems not successful. the contrary, the performance decreases, suggesting that the classifier is confused by this syntactic information.

For all trees we first extract their Path Enclosed Tree, which is the smallest common subtree that contains the two target entities (Moschitti, 2004). $$$$$ For example, the Parse Tree Path feature represents the path in the parse-tree between a predicate node and one of its argument nodes.
For all trees we first extract their Path Enclosed Tree, which is the smallest common subtree that contains the two target entities (Moschitti, 2004). $$$$$ For example, the Parse Tree Path is very sensible to small changes of parse-trees, e.g. two predicates, expressed in different tenses, generate two different Path features.

Moschitti (2004) and Che et al (2006) used a convolution tree kernel (Collins and Duffy, 2001) for semantic role classification. $$$$$ Given the semantic objects defined in the previous section, we design a convolution kernel in a way similar to the parse-tree kernel proposed in (Collins and Duffy, 2002).
Moschitti (2004) and Che et al (2006) used a convolution tree kernel (Collins and Duffy, 2001) for semantic role classification. $$$$$ (Gildea and Jurasfky, 2002; Surdeanu et al., 2003; Hacioglu et al., 2003).

Of special interest here, Moschitti (2004) proposed Predicate Argument Feature (PAF) kernel for SRL under the framework of convolution tree kernel. $$$$$ Given the semantic objects defined in the previous section, we design a convolution kernel in a way similar to the parse-tree kernel proposed in (Collins and Duffy, 2002).
Of special interest here, Moschitti (2004) proposed Predicate Argument Feature (PAF) kernel for SRL under the framework of convolution tree kernel. $$$$$ It is worth noting that even if the above equations define a kernel function similar to the one proposed in (Collins and Duffy, 2002), the substructures on which it operates are different from the parse-tree kernel.

In our implementation, we use the binary SVMLight (Joachims, 1998) and modify the Tree Kernel Tools (Moschitti, 2004) to a grammar driven one. $$$$$ The classifier evaluations were carried out using the SVM-light software (Joachims, 1999) available at svmlight.joachims.org with the default polynomial kernel for standard feature evaluations.
In our implementation, we use the binary SVMLight (Joachims, 1998) and modify the Tree Kernel Tools (Moschitti, 2004) to a grammar driven one. $$$$$ On 10Unfortunately the use of a polynomial kernel on top the tree fragments to generate the XOR functions seems not successful. the contrary, the performance decreases, suggesting that the classifier is confused by this syntactic information.
