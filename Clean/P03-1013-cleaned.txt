Experiments described in Section 4.3 used the same development and test sets but files 200-959 of WSJ as a smaller training set; for NEGRA we followed Dubey and Keller (2003) in using the first 18,602 sentences for training, the last 1,000 for development, and the previous 1,000 for testing. $$$$$ Of the remaining 2,000 sentences, the first 1,000 served as the test set, and the last 1000 as the development set.
Experiments described in Section 4.3 used the same development and test sets but files 200-959 of WSJ as a smaller training set; for NEGRA we followed Dubey and Keller (2003) in using the first 18,602 sentences for training, the last 1,000 for development, and the previous 1,000 for testing. $$$$$ The poor performance of the lexicalized models could be due to a lack of sufficient training data: our Negra training set contains approximately 18,000 sentences, and is therefore significantly smaller than the Penn Treebank training set (about 40,000 sentences).

 $$$$$ Another prediction was that adding Negra-specific information to the models will increase parsing performance.
 $$$$$ Testing our sister-head model on these languages is a topic for future research.

Additionally, we show a limited number of results on the Negra corpus, using the standard training/development/test splits, defined in (Dubey and Keller, 2003). $$$$$ The aim of the present paper is to test if this finding carries over to German and to the Negra corpus.
Additionally, we show a limited number of results on the Negra corpus, using the standard training/development/test splits, defined in (Dubey and Keller, 2003). $$$$$ Again, we give results obtained using TnT tags and using perfect tags.

However, Dubey and Keller (2003) have demonstrated that lexicalization does not help a Collins-style parser that is trained on this corpus, and Levy and Manning (2004) have shown that its context-free representation is a poor approximation to the underlying dependency structure. $$$$$ Lexicalization has been shown to improve parsing performance for the Penn Treebank (e.g., Carroll and Rooth 1998; Charniak 1997, 2000; Collins 1997).
However, Dubey and Keller (2003) have demonstrated that lexicalization does not help a Collins-style parser that is trained on this corpus, and Levy and Manning (2004) have shown that its context-free representation is a poor approximation to the underlying dependency structure. $$$$$ The Collins (1997) model does not use context-free rules, but generates the next category using zeroth order Markov chains (see Section 3.3), hence no information about the previous sisters is included.

It turns out, however, that lexicalization is not unproblematic: First, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains (Dubey and Keller, 2003). $$$$$ Lexicalization requires that each rule in a grammar has one of the categories on its righthand side annotated as the head.
It turns out, however, that lexicalization is not unproblematic: First, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains (Dubey and Keller, 2003). $$$$$ Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages.

There are even studies showing that lexicalization can be harmful when parsing richly inflected languages like German (Dubey and Keller, 2003) and Turkish (Eryigit and Oflazer, 2006). $$$$$ There is some research on treebank-based parsing of languages other than English.
There are even studies showing that lexicalization can be harmful when parsing richly inflected languages like German (Dubey and Keller, 2003) and Turkish (Eryigit and Oflazer, 2006). $$$$$ Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages.

Efforts have been made to adapt existing CFG models to German (Dubey and Keller, 2003), but the results still don't compare to state-of-the art parsing of English. $$$$$ We observe that existing lexicalized parsing models using head-head dependencies, while successful for English, fail to outperform an unlexicalized baseline model for German.
Efforts have been made to adapt existing CFG models to German (Dubey and Keller, 2003), but the results still don't compare to state-of-the art parsing of English. $$$$$ On the whole, the results of Experiment 2 are at odds with what is known about parsing for English.

Dubey and Keller (2003) analyze the difficulties that Germanim poses on parsing. $$$$$ Probabilistic Parsing For German Using Sister-Head Dependencies
Dubey and Keller (2003) analyze the difficulties that Germanim poses on parsing. $$$$$ Treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g., Collins 1997; Charniak 2000).

Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al, 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra's flat constituent structures. $$$$$ The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al., 1997), a syntactically annotated corpus for German.
Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al, 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra's flat constituent structures. $$$$$ The annotation scheme (Skut et al., 1997) is modeled to a certain extent on that of the Penn Treebank (Marcus et al., 1993), with crucial differences.

Relevant, in principle, to our discussion here, are also the results obtained with tree bank grammars for German: (Dubey and Keller, 2003) have trained a PCFG on the Negra corpus (Skut et al, 1998), reporting labelled precision and recall between 70 and 75%. $$$$$ The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al., 1997), a syntactically annotated corpus for German.
Relevant, in principle, to our discussion here, are also the results obtained with tree bank grammars for German: (Dubey and Keller, 2003) have trained a PCFG on the Negra corpus (Skut et al, 1998), reporting labelled precision and recall between 70 and 75%. $$$$$ The results show that the baseline model achieves a performance of up to 73% recall and 70% precision.

This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al, 1999) and Chinese (Bikel and Chiang, 2000). $$$$$ Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000).
This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al, 1999) and Chinese (Bikel and Chiang, 2000). $$$$$ The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese.

The learning curves over increasing training data (e.g., for German (Dubey and Keller, 2003)) show that tree bank size can not be the sole factor to account for the inferior performance. $$$$$ Learning curves show that this effect is not due to lack of training data.
The learning curves over increasing training data (e.g., for German (Dubey and Keller, 2003)) show that tree bank size can not be the sole factor to account for the inferior performance. $$$$$ Learning curves show that the poor performance of the lexicalized models is not due to lack of training data.

 $$$$$ Another prediction was that adding Negra-specific information to the models will increase parsing performance.
 $$$$$ Testing our sister-head model on these languages is a topic for future research.

 $$$$$ Another prediction was that adding Negra-specific information to the models will increase parsing performance.
 $$$$$ Testing our sister-head model on these languages is a topic for future research.

 $$$$$ Another prediction was that adding Negra-specific information to the models will increase parsing performance.
 $$$$$ Testing our sister-head model on these languages is a topic for future research.

The comparison of the experiments with (line 2) and without grammatical functions (line 1) confirms the findings of Dubeyand Keller (2003) that the task of assigning correct grammatical functions is harder than mere constituent-based parsing. $$$$$ Adding grammatical functions reduces both figures slightly, and coverage drops by about 15%.
The comparison of the experiments with (line 2) and without grammatical functions (line 1) confirms the findings of Dubeyand Keller (2003) that the task of assigning correct grammatical functions is harder than mere constituent-based parsing. $$$$$ Perfect tagging results in a performance increase of over 10% for the models with grammatical functions.

To allow comparisons with earlier work on NEGRA parsing, we use the same split of training, development and testing data as used in Dubey and Keller (2003). $$$$$ The row ‘Split PP’ contains the performance figures obtained by including split PPs in both the training and in the testing set.
To allow comparisons with earlier work on NEGRA parsing, we use the same split of training, development and testing data as used in Dubey and Keller (2003). $$$$$ However, we observed that LR and LP are artificially inflated if split PPs are used for testing.

Overall, the best-performing model, using Brants smoothing, achieves a labelled bracketing F-score of 76.2, higher than earlier results reported by Dubey and Keller (2003) and Schiehlen (2004). $$$$$ Performance using perfect tags (an upper bound of model performance) is 2–3% higher for the baseline and for the C&R model.
Overall, the best-performing model, using Brants smoothing, achieves a labelled bracketing F-score of 76.2, higher than earlier results reported by Dubey and Keller (2003) and Schiehlen (2004). $$$$$ The results show that the baseline model achieves a performance of up to 73% recall and 70% precision.

 $$$$$ Another prediction was that adding Negra-specific information to the models will increase parsing performance.
 $$$$$ Testing our sister-head model on these languages is a topic for future research.

able 4 lists the result of the best model presented here against the earlier work on NEGRA parsing described in Dubey and Keller (2003) and Schiehlen (2004). $$$$$ We presented the first probabilistic full parsing model for German trained on Negra, a syntactically annotated corpus.
able 4 lists the result of the best model presented here against the earlier work on NEGRA parsing described in Dubey and Keller (2003) and Schiehlen (2004). $$$$$ The best performance was obtained for a model that uses sister-head dependencies for all categories.
