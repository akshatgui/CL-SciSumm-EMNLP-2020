A previous work that used structured kernels in Sentiment Analysis is the approach of Wu et al (2009). $$$$$ Previous works on mining opinions can be divided into two directions: sentiment classification and sentiment related information extraction.
A previous work that used structured kernels in Sentiment Analysis is the approach of Wu et al (2009). $$$$$ Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).

The results showed by Wu et al (2009) suggest that tree kernels on dependency trees are a good approach but we also plan to employ string kernels on this task. $$$$$ Dependency tree kernels has been proposed by (Culotta and Sorensen, 2004).
The results showed by Wu et al (2009) suggest that tree kernels on dependency trees are a good approach but we also plan to employ string kernels on this task. $$$$$ Experimental results show that our approach improved the performances of the mining task.

We compared our aspect identification approach against two baselines: a) the method proposed by Hu and Liu (2004), which was based on the association rule mining, and b) the method proposed by Wu et al (2009), which was based on a dependency parser. $$$$$ Dependency tree kernels has been proposed by (Culotta and Sorensen, 2004).
We compared our aspect identification approach against two baselines: a) the method proposed by Hu and Liu (2004), which was based on the association rule mining, and b) the method proposed by Wu et al (2009), which was based on a dependency parser. $$$$$ However, in other domains, directly adjacent method is better than the learning based methods.

Afterwards, Wu et al (2009) utilized the dependency parser to extract the noun phrases and verb phrases from the reviews as the aspect candidates. $$$$$ A phrase dependency tree is defined as T = (V , E ), where V is the set of phrases, E is the dependency relations among the phrases in V representing by direct edges.
Afterwards, Wu et al (2009) utilized the dependency parser to extract the noun phrases and verb phrases from the reviews as the aspect candidates. $$$$$ While prepositional phrases (PPs) and adjectival phrases (ADJPs) are excluded.

Phrase dependency grammars have recently been used by Wu et al (2009) for feature extraction for opinion mining. $$$$$ Phrase Dependency Parsing for Opinion Mining
Phrase dependency grammars have recently been used by Wu et al (2009) for feature extraction for opinion mining. $$$$$ Opinion mining has recently received considerable attention.

For a monolingual task, Wu et al (2009) used a shallow parser to convert lexical dependencies from a dependency parser into phrase dependencies. $$$$$ To construct phrase dependency tree, we propose a method which combines results from an existing shallow parser and a lexical dependency parser.
For a monolingual task, Wu et al (2009) used a shallow parser to convert lexical dependencies from a dependency parser into phrase dependencies. $$$$$ Fig.2(a) is the result of the lexical dependency parser.

We compared our approach against two state-of-the art methods: a) the method proposed by Hu and Liu (2004), which is based on the association rule mining, and b) the method proposed by Wu et al (2009), which is based on the dependency parser. $$$$$ Dependency tree kernels has been proposed by (Culotta and Sorensen, 2004).
We compared our approach against two state-of-the art methods: a) the method proposed by Hu and Liu (2004), which is based on the association rule mining, and b) the method proposed by Wu et al (2009), which is based on the dependency parser. $$$$$ However, in other domains, directly adjacent method is better than the learning based methods.

For example, Wu et al (2009) identified aspects based on the features explored by dependency parser. $$$$$ The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).
For example, Wu et al (2009) identified aspects based on the features explored by dependency parser. $$$$$ Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).

A wide spectrum of tasks have been studied under review mining, ranging from coarse-grained document-level polarity classification (Pang et al,2002) to fine-grained extraction of opinion expressions and their targets (Wu et al, 2009). $$$$$ The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).
A wide spectrum of tasks have been studied under review mining, ranging from coarse-grained document-level polarity classification (Pang et al,2002) to fine-grained extraction of opinion expressions and their targets (Wu et al, 2009). $$$$$ Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).

 $$$$$ The other phrase is called dependent, which modifies the head.
 $$$$$ The authors would like to thank the reviewers for their useful comments.

For MaxEnt training, we tried three labeled data sets: one that was taken from the restaurant data set and manually annotated by us, and two from the annotated data set used in (Wu et al., 2009). $$$$$ Then for each product feature, they annotated the opinion expression which has relation with it.
For MaxEnt training, we tried three labeled data sets: one that was taken from the restaurant data set and manually annotated by us, and two from the annotated data set used in (Wu et al., 2009). $$$$$ The other domains are used as testing set.

To test this hypothesis, we tried two quite different training data sets, one from the cell phone domain and the other from the DVD player domain, both used in (Wu et al, 2009). $$$$$ Our corpus is selected from them, which contains customer reviews of 11 products belong to 5 categories(Diaper, Cell Phone, Digital Camera, DVD Player, and MP3 Player).
To test this hypothesis, we tried two quite different training data sets, one from the cell phone domain and the other from the DVD player domain, both used in (Wu et al, 2009). $$$$$ We use the digital camera and cell phone domain as training set.

Wu et al (2009) proposed a phrase level dependency parsing for mining aspects and features of products. $$$$$ Phrase Dependency Parsing for Opinion Mining
Wu et al (2009) proposed a phrase level dependency parsing for mining aspects and features of products. $$$$$ The novelties of our work included: 1) we defined the phrase dependency parsing and proposed an approach to construct the phrase dependency trees; 2) we proposed a new tree kernel function to model the phrase dependency trees.

 $$$$$ The other phrase is called dependent, which modifies the head.
 $$$$$ The authors would like to thank the reviewers for their useful comments.

In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al, 2009) and CRFs (Li et al, 2010). $$$$$ The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).
In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al, 2009) and CRFs (Li et al, 2010). $$$$$ Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).

They regarded it as a sequence labeling task, where several classical models were used, such as CRFs (Li et al, 2010) and SVM (Wu et al, 2009). $$$$$ The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).
They regarded it as a sequence labeling task, where several classical models were used, such as CRFs (Li et al, 2010) and SVM (Wu et al, 2009). $$$$$ Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).
