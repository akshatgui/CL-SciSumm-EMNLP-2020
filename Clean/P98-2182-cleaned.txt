We chose three clusters produced by a program similar to Roark and Charniak (1998) except that it is based on a generative probability model and tries to classify all nouns rather than just those in pre-selected clusters. $$$$$ For the final ranking, we chose the log likelihood statistic outlined in Dunning (1993), which is based upon the co-occurrence counts of all nouns (see Dunning for details).
We chose three clusters produced by a program similar to Roark and Charniak (1998) except that it is based on a generative probability model and tries to classify all nouns rather than just those in pre-selected clusters. $$$$$ Whereas the R&S algorithm produced just 11 terms not already present in Wordnet for the two categories combined, our algorithm produced 106, or over 3 for every 5 valid terms produced.

This problem is addressed by Riloff and Shepherd (1997), Roark and Charniak (1998) and more recently by Widdows and Dorow (2002). $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
This problem is addressed by Riloff and Shepherd (1997), Roark and Charniak (1998) and more recently by Widdows and Dorow (2002). $$$$$ The solution to this problem is to make the initial seed word selection from among the most frequent head nouns in the corpus.

Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used co occurrence statistics in local context to discover sibling relations. $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used co occurrence statistics in local context to discover sibling relations. $$$$$ In our algorithm, co-occurrence is only counted within a noun phrase, between head nouns that are separated by a comma or conjunction.

Rilo and Shepherd (Rilo and Shepherd, 1997) developed a bootstrap ping algorithm that exploits lexical co-occurrence statistics, and Roark and Charniak (Roark and Charniak, 1998) re ned this algorithm to focus more explicitly on certain syntactic structures. $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
Rilo and Shepherd (Rilo and Shepherd, 1997) developed a bootstrap ping algorithm that exploits lexical co-occurrence statistics, and Roark and Charniak (Roark and Charniak, 1998) re ned this algorithm to focus more explicitly on certain syntactic structures. $$$$$ It is for this reason that we are billing our algorithm as something that could enhance existing broadcoverage resources with domain-specific lexical information.

The main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular category, such as vehicles or weapons (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998). $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
The main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular category, such as vehicles or weapons (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998). $$$$$ If one of those weapons occurs frequently enough, the scores for the words that it co-occurs with may exceed those of any vehicles, and this effect may be strong enough that no vehicles are selected in any future iteration.

Roark and Charniak describe a "generic algorithm" for extracting such lists of similar words using the notion of semantic similarity, as follows (Roark and Charniak, 1998). $$$$$ To identify conjunctions, lists, and appositives, we first parsed the corpus, using an efficient statistical parser (Charniak et al., 1998), trained on the Penn Wall Street Journal Treebank (Marcus et al., 1993).
Roark and Charniak describe a "generic algorithm" for extracting such lists of similar words using the notion of semantic similarity, as follows (Roark and Charniak, 1998). $$$$$ The algorithm then proceeds as follows

Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ R&S reported a ratio of .17 valid to total entries for both the vehicle and weapon categories (see table 2).

Since lists are usually comprised of objects which are similar in some way, these relationships have been used to extract lists of nouns with similar properties (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
Since lists are usually comprised of objects which are similar in some way, these relationships have been used to extract lists of nouns with similar properties (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). $$$$$ This is similar to the figure of merit used in R&S, and also tends to promote low frequency nouns.

Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ R&S reported a ratio of .17 valid to total entries for both the vehicle and weapon categories (see table 2).

The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ We ran our algorithm against both the MUC-4 corpus and the Wall Street Journal (WSJ) corpus for a variety of categories, beginning with the categories of vehicle and weapon, both included in the five categories that Rk,S investigated in their paper.
The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ Even more valid terms were generated for appropriate categories using the Wall Street Journal.

The high accuracy achieved thus questions the conclusion drawn by Roark and Charniak (1998) that parsing is invaluable. $$$$$ In addition, because it promotes high frequency terms, such a statistic tends to have the same effect as a minimum occurrence cutoff, i.e. few if any low frequency words get added.
The high accuracy achieved thus questions the conclusion drawn by Roark and Charniak (1998) that parsing is invaluable. $$$$$ To this end, parsing is invaluable.

Roark and Charniak (1998) used the co-occurrence of words as features to classify nouns. $$$$$ R&S used the same figure of merit both for selecting new seed words and for ranking words in the final output.
Roark and Charniak (1998) used the co-occurrence of words as features to classify nouns. $$$$$ Co-Occurrence bigrams are collected for head nouns according to the notion of co-occurrence outlined above.

The goal of extracting semantic information from text is well-established, and has encouraged work on lexical acquisition (Roark and Charniak, 1998), information extraction (Cardie, 1997), and ontology engineering (Hahn and Schnattinger, 1998). $$$$$ Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation (Schiitze, 1992; Gale et al., 1992; Yarowsky, 1995).
The goal of extracting semantic information from text is well-established, and has encouraged work on lexical acquisition (Roark and Charniak, 1998), information extraction (Cardie, 1997), and ontology engineering (Hahn and Schnattinger, 1998). $$$$$ It is for this reason that we are billing our algorithm as something that could enhance existing broadcoverage resources with domain-specific lexical information.

This may be explained by the fact that words appearing in conjunctions are often taxonomically similar (Roark and Charniak, 1998) and that taxonomic information is particularly useful for compound interpretation, as evidenced by the success of WordNet-based methods (see Section 5). $$$$$ All compound nouns in the former constructions are represented by the head of the compound.
This may be explained by the fact that words appearing in conjunctions are often taxonomically similar (Roark and Charniak, 1998) and that taxonomic information is particularly useful for compound interpretation, as evidenced by the success of WordNet-based methods (see Section 5). $$$$$ A simple probability does not capture this fact.

To select seed words, we used the procedure proposed by Roark and Charniak (1998), ranking all of the head nouns in the training corpus by frequency and manually selecting the first 10 nouns that unambiguously belong to each category. $$$$$ R&S used the same figure of merit both for selecting new seed words and for ranking words in the final output.
To select seed words, we used the procedure proposed by Roark and Charniak (1998), ranking all of the head nouns in the training corpus by frequency and manually selecting the first 10 nouns that unambiguously belong to each category. $$$$$ The simple ratio used to select new seed words will tend not to select higher frequency words in the category.

 $$$$$ If the sentence had read

For example, Hearst (Hearst, 1992) learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as NP, NP, and other NPs, and Roarkand Charniak (Roark and Charniak, 1998) generated semantically related words by applying statistical measures to syntactic contexts involving appositives, lists, and conjunctions. $$$$$ To identify conjunctions, lists, and appositives, we first parsed the corpus, using an efficient statistical parser (Charniak et al., 1998), trained on the Penn Wall Street Journal Treebank (Marcus et al., 1993).
For example, Hearst (Hearst, 1992) learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as NP, NP, and other NPs, and Roarkand Charniak (Roark and Charniak, 1998) generated semantically related words by applying statistical measures to syntactic contexts involving appositives, lists, and conjunctions. $$$$$ Related words (e.g. crash for the category vehicle) did not count.

In previous research on semantic lexicon induction, Roark and Charniak (Roark and Charniak, 1998) showed that 3 of every 5 words learned by their system were not present in WordNet. $$$$$ Noun-Phrase Co-occurrence Statistics for Semi-Automatic Semantic Lexicon Construction
In previous research on semantic lexicon induction, Roark and Charniak (Roark and Charniak, 1998) showed that 3 of every 5 words learned by their system were not present in WordNet. $$$$$ We have outlined an algorithm in this paper that, as it stands, could significantly speed up the task of building a semantic lexicon.

Roark and Charniak (Roark and Charniak, 1998) followed up on this work by using a parser to explicitly capture these structures. $$$$$ To identify conjunctions, lists, and appositives, we first parsed the corpus, using an efficient statistical parser (Charniak et al., 1998), trained on the Penn Wall Street Journal Treebank (Marcus et al., 1993).
Roark and Charniak (Roark and Charniak, 1998) followed up on this work by using a parser to explicitly capture these structures. $$$$$ A simple probability does not capture this fact.

Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. $$$$$ To identify conjunctions, lists, and appositives, we first parsed the corpus, using an efficient statistical parser (Charniak et al., 1998), trained on the Penn Wall Street Journal Treebank (Marcus et al., 1993).
Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. $$$$$ Table 1 shows the seed words that were used for some of the categories tested.
