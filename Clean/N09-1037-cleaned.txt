Compared with the disappointing results of joint learning on syntactic and semantic parsing, Miller et al (2000) and Finkel and Manning (2009) showed the effectiveness of joint learning on syntactic parsing and some simple NLP tasks, such as information extraction and name entity recognition. $$$$$ Joint Parsing and Named Entity Recognition
Compared with the disappointing results of joint learning on syntactic and semantic parsing, Miller et al (2000) and Finkel and Manning (2009) showed the effectiveness of joint learning on syntactic parsing and some simple NLP tasks, such as information extraction and name entity recognition. $$$$$ Most work on joint parsing and semantic role labeling (SRL) has been disappointing, despite obvious connections between the two tasks.

We built a joint model of parsing and named entity recognition (Finkel and Manning, 2009b), which had small gains on parse performance and moderate gains on named entity performance, when compared with single-task models trained on the same data. $$$$$ Joint Parsing and Named Entity Recognition
We built a joint model of parsing and named entity recognition (Finkel and Manning, 2009b), which had small gains on parse performance and moderate gains on named entity performance, when compared with single-task models trained on the same data. $$$$$ We presented a discriminatively trained joint model of parsing and named entity recognition, which improved performance on both tasks.

 $$$$$ It would be computationally infeasible to allow any word to have any part of speech tag.
 $$$$$ We also wish to thank the creators of OntoNotes, without which this project would not have been possible.

Our base joint model for parsing and named entity recognition is the same as (Finkel and Manning, 2009b), which is also based on the discriminative parser discussed in the previous section. $$$$$ Joint Parsing and Named Entity Recognition
Our base joint model for parsing and named entity recognition is the same as (Finkel and Manning, 2009b), which is also based on the discriminative parser discussed in the previous section. $$$$$ We begin to address this problem with a joint model of parsing and named entity recognition, based on a discriminative feature-based constituency parser.

Our baseline experiments were modeled after those in (Finkel and Manning, 2009b), and while our results were not identical (we updated to a newer release of the data), we had similar results and found the same general trends with respect to how the joint model improved on the single models. $$$$$ Despite these earlier results, we found that combining parsing and named entity recognition modestly improved performance on both tasks.
Our baseline experiments were modeled after those in (Finkel and Manning, 2009b), and while our results were not identical (we updated to a newer release of the data), we had similar results and found the same general trends with respect to how the joint model improved on the single models. $$$$$ The full results can be found in Table 2.

We used OntoNotes 3.0 (Hovy et al, 2006), and made the same data modifications as (Finkel and Manning, 2009b) to ensure consistency between the parsing and named entity annotations. $$$$$ For our experiments we used the LDC2008T04 OntoNotes Release 2.0 corpus (Hovy et al., 2006).
We used OntoNotes 3.0 (Hovy et al, 2006), and made the same data modifications as (Finkel and Manning, 2009b) to ensure consistency between the parsing and named entity annotations. $$$$$ Previous work on linguistic annotation pipelines (Finkel et al., 2006; Hollingshead and Roark, 2007) has enforced consistency from one stage to the next.

These approaches have been shown to be successful for tasks such as parsing and named entity recognition in newswire data (Finkel and Manning, 2009) or semantic role labeling in the Penn Treebank and Brown corpus (Toutanova et al, 2008). $$$$$ The CoNLL 2008 shared task (Surdeanu et al., 2008) was intended to be about joint dependency parsing and semantic role labeling, but the top performing systems decoupled the tasks and outperformed the systems which attempted to learn them jointly.
These approaches have been shown to be successful for tasks such as parsing and named entity recognition in newswire data (Finkel and Manning, 2009) or semantic role labeling in the Penn Treebank and Brown corpus (Toutanova et al, 2008). $$$$$ Most work on joint parsing and semantic role labeling (SRL) has been disappointing, despite obvious connections between the two tasks.

Finkel and Manning (2009) proposed a discriminative feature based constituency parser for joint named entity recognition and parsing. $$$$$ Joint Parsing and Named Entity Recognition
Finkel and Manning (2009) proposed a discriminative feature based constituency parser for joint named entity recognition and parsing. $$$$$ We begin to address this problem with a joint model of parsing and named entity recognition, based on a discriminative feature-based constituency parser.

However, most of the mentioned approaches are task-specific (e.g., (Toutanova et al, 2008) for semantic role labeling, and (Finkel and Manning, 2009) for parsing and NER), and they can hardly be applicable to other NLP tasks. $$$$$ The CoNLL 2008 shared task (Surdeanu et al., 2008) was intended to be about joint dependency parsing and semantic role labeling, but the top performing systems decoupled the tasks and outperformed the systems which attempted to learn them jointly.
However, most of the mentioned approaches are task-specific (e.g., (Toutanova et al, 2008) for semantic role labeling, and (Finkel and Manning, 2009) for parsing and NER), and they can hardly be applicable to other NLP tasks. $$$$$ Most work on joint parsing and semantic role labeling (SRL) has been disappointing, despite obvious connections between the two tasks.

It has been used in some natural language processing tasks, such as joint parsing and named entity recognition (Finkel and Manning, 2009), and word sense disambiguation (Zhong et al, 2008). $$$$$ Joint Parsing and Named Entity Recognition
It has been used in some natural language processing tasks, such as joint parsing and named entity recognition (Finkel and Manning, 2009), and word sense disambiguation (Zhong et al, 2008). $$$$$ The CoNLL 2008 shared task (Surdeanu et al., 2008) was joint dependency parsing and SRL, but the top performing systems decoupled the tasks, rather than building joint models.

Alternative approaches are that of Finkel and Manning (2009) on joint parsing and named entity recognition and the work of (Wehrli et al, 2010) which uses collocation information to rank competing hypotheses in a symbolic parser. $$$$$ Joint Parsing and Named Entity Recognition
Alternative approaches are that of Finkel and Manning (2009) on joint parsing and named entity recognition and the work of (Wehrli et al, 2010) which uses collocation information to rank competing hypotheses in a symbolic parser. $$$$$ While other work has utilized the OntoNotes corpus (Pradhan et al., 2007; Yu et al., 2008), this is the first work to our knowledge to simultaneously model the multiple levels of annotation available.

For example, constraining a parser to respect the boundaries of known entities is standard practice not only in joint modeling of (constituent) parsing and NER (Finkel and Manning, 2009), but also in higher-level NLP tasks, such as relation extraction (Mintz et al, 2009), that couple chunking with (dependency) parsing. $$$$$ For named entities, the joint model should help with boundaries.
For example, constraining a parser to respect the boundaries of known entities is standard practice not only in joint modeling of (constituent) parsing and NER (Finkel and Manning, 2009), but also in higher-level NLP tasks, such as relation extraction (Mintz et al, 2009), that couple chunking with (dependency) parsing. $$$$$ The CoNLL 2008 shared task (Surdeanu et al., 2008) was joint dependency parsing and SRL, but the top performing systems decoupled the tasks, rather than building joint models.

Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. $$$$$ Joint Parsing and Named Entity Recognition
Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. $$$$$ We begin to address this problem with a joint model of parsing and named entity recognition, based on a discriminative feature-based constituency parser.

In the same spirit, Finkel and Manning (2009) merged the syntactic annotations and the named entity annotations of the OntoNotes corpus (Hovy et al, 2006) and trained a discriminative parsing model for the joint problem of syntactic parsing and named entity recognition. $$$$$ Joint Parsing and Named Entity Recognition
In the same spirit, Finkel and Manning (2009) merged the syntactic annotations and the named entity annotations of the OntoNotes corpus (Hovy et al, 2006) and trained a discriminative parsing model for the joint problem of syntactic parsing and named entity recognition. $$$$$ For our experiments we used the LDC2008T04 OntoNotes Release 2.0 corpus (Hovy et al., 2006).

Finkel and Manning (2009b) also proposed a parsing model for the extraction of nested named entity mentions, which, like this work, parses just the corresponding semantic annotations. $$$$$ Joint Parsing and Named Entity Recognition
Finkel and Manning (2009b) also proposed a parsing model for the extraction of nested named entity mentions, which, like this work, parses just the corresponding semantic annotations. $$$$$ In the future, we would like to add other levels of annotation available in the OntoNotes corpus to our model, including word sense disambiguation and semantic role labeling.

For instance, performing named entity recognition (NER) jointly with constituent parsing has been shown to improve performance on both tasks, but the only aspect of the syntax which is leveraged by the NER component is the location of noun phrases (Finkel and Manning, 2009). $$$$$ Joint Parsing and Named Entity Recognition
For instance, performing named entity recognition (NER) jointly with constituent parsing has been shown to improve performance on both tasks, but the only aspect of the syntax which is leveraged by the NER component is the location of noun phrases (Finkel and Manning, 2009). $$$$$ An example from the data where the joint model helped improve both parse structure and named entity recognition is shown in Figure 4.

Finkel and Manning (2009) modeled the task of named entity recognition together with parsing. $$$$$ Joint Parsing and Named Entity Recognition
Finkel and Manning (2009) modeled the task of named entity recognition together with parsing. $$$$$ We presented a discriminatively trained joint model of parsing and named entity recognition, which improved performance on both tasks.

To avoid overfitting, we employed an implementation from previous literature (Finkel and Manning,2009). $$$$$ For parse features, we used the exact same features as described in (Finkel and Manning, 2008).
To avoid overfitting, we employed an implementation from previous literature (Finkel and Manning,2009). $$$$$ Previous work on linguistic annotation pipelines (Finkel et al., 2006; Hollingshead and Roark, 2007) has enforced consistency from one stage to the next.

The spirit of this work more closely resembles that of Finkel and Manning (2009), which improves both parsing and named entity recognition by combining the two tasks. $$$$$ Joint Parsing and Named Entity Recognition
The spirit of this work more closely resembles that of Finkel and Manning (2009), which improves both parsing and named entity recognition by combining the two tasks. $$$$$ Despite these earlier results, we found that combining parsing and named entity recognition modestly improved performance on both tasks.

The idea of jointly training parsers to optimize multiple objectives is related to joint learning and inference for tasks like information extraction (Finkeland Manning, 2009) and machine translation (Burkett et al, 2010). $$$$$ The CoNLL 2008 shared task (Surdeanu et al., 2008) was intended to be about joint dependency parsing and semantic role labeling, but the top performing systems decoupled the tasks and outperformed the systems which attempted to learn them jointly.
The idea of jointly training parsers to optimize multiple objectives is related to joint learning and inference for tasks like information extraction (Finkeland Manning, 2009) and machine translation (Burkett et al, 2010). $$$$$ While other work has utilized the OntoNotes corpus (Pradhan et al., 2007; Yu et al., 2008), this is the first work to our knowledge to simultaneously model the multiple levels of annotation available.
