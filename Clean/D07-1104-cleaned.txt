Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ Due to space constraints, details and proof of correctness are available in Lopez (2007a).
Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ 8 Searching for a?b is potentially very expensive, so we put all available information to work.

However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ However, in machine translation most fea tures can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b).
However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ Recently, Lopez and Resnik (2006) showed that most of the features used in standard phrase-based models do not help very much.

We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ of the sentence in the suffix array.
We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ using the phrase extraction method of Koehn et al (2003).

We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ We believe that the latter approach has several important applications (?7).So far, these techniques have focused on phrase based models using contiguous phrases (Koehn et al., 2003; Och and Ney, 2004).
We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ To generate alignments,we used GIZA++ (Och and Ney, 2003).

Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ Load the source training text F , the suffix array.
Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ On-the-fly lookup using suffix arrays involves an added complication when the rules are in form uXv or uXvXw.

Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ Some recent models permit discontiguous phrases (Chiang, 2007; Quirket al, 2005; Simard et al, 2005).
Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ using the phrase extraction method of Koehn et al (2003).

The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ Load the source training text F , the suffix array.
The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ of the sentence in the suffix array.

In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ We believe that the latter approach has several important applications (?7).So far, these techniques have focused on phrase based models using contiguous phrases (Koehn et al., 2003; Och and Ney, 2004).
In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ To generate alignments,we used GIZA++ (Och and Ney, 2003).

We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ A major difference between contiguous phrase based models and hierarchical phrase-based models is the number of rules that potentially apply to an input sentence.
We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ To generate alignments,we used GIZA++ (Och and Ney, 2003).

The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ Hierarchical Phrase-Based Translation with Suffix Arrays
The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ We consider the hierarchical translation model ofChiang (2007).

Besides storing the whole grammar locally in memory, other approaches have been developed, such as suffix arrays, which lookup and extract rules on the fly from the phrase table (Lopez, 2007). $$$$$ In phrase-based models, this prob lem can be addressed by storing the training data in memory and using a suffix array asan efficient index to quickly lookup and extract rules on the fly.
Besides storing the whole grammar locally in memory, other approaches have been developed, such as suffix arrays, which lookup and extract rules on the fly from the phrase table (Lopez, 2007). $$$$$ On-the-fly lookup using suffix arrays involves an added complication when the rules are in form uXv or uXvXw.

The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ We consider the hierarchical translation model ofChiang (2007).
The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ Formally, this model is a syn chronous context-free grammar.

This data structure has been used similarly to index whole training sentences for efficient retrieval (Lopez, 2007). $$$$$ In phrase-based models, this prob lem can be addressed by storing the training data in memory and using a suffix array asan efficient index to quickly lookup and extract rules on the fly.
This data structure has been used similarly to index whole training sentences for efficient retrieval (Lopez, 2007). $$$$$ 7 This approach requires a separate inverted index for each n, up to the maximum n used by the model.

(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ 3 For the purposes of this paper, we adhere to therestrictions described by Chiang (2007) for rules ex tracted from the training data.
(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ However, it cannot be used for discontiguous substrings.

 $$$$$ Theoreti cally, the worst case for this algorithm occurs when all elements of both sets resolve to the same hash bucket, and we must compare all elements of one set with all elements of the other set.
 $$$$$ 984

The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ Binary search enables fast lookup of contiguous substrings.
The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ However, it cannot be used for discontiguous substrings.

There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ Binary search enables fast lookup of contiguous substrings.
There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ However, it cannot be used for discontiguous substrings.

This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ Zens and Ney (2007) use a disk-based prefix tree, enabling efficient access to phrase tables much too large to fit in main memory.
This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ 5.4.3 Prefix Trees and Suffix Links Our search optimizations are easily captured in a prefix tree data structure augmented with suffix links.Formally, a prefix tree is an unminimized determin istic finite-state automaton that recognizes all of thepatterns in some set.

This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ 5.2 Fast Intersection.
This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ This results in a superlinear algorithm for intersection.

In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ For collocations of frequent and rare patterns, we use a fast set intersection method for sorted sets called double binary search (Baeza-Yates, 2004).
In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ Detailed analysis and empirical results on an information retrieval task are reported in Baeza-Yates (2004) and Baeza-Yates and Salinger (2005).
