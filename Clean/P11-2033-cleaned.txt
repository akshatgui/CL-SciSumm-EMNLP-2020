The present paper deals with five parsers evaluated within the translation frame work: three genuine dependency parsers, namely the parsers described in (McDonald et al, 2005), (Nivre et al, 2007), and (Zhang and Nivre, 2011), and two constituency parsers (Charniak and Johnson, 2005) and (Klein and Manning, 2003), whose outputs we reconverted to dependency structures by Penn Converter (Johansson and Nugues, 2007). $$$$$ Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser (Nivre et al., 2006b; McDonald et al., 2005; McDonald and Nivre, 2007).
The present paper deals with five parsers evaluated within the translation frame work: three genuine dependency parsers, namely the parsers described in (McDonald et al, 2005), (Nivre et al, 2007), and (Zhang and Nivre, 2011), and two constituency parsers (Charniak and Johnson, 2005) and (Klein and Manning, 2003), whose outputs we reconverted to dependency structures by Penn Converter (Johansson and Nugues, 2007). $$$$$ Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing (Zhang and Clark, 2009; Wang et al., 2006), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser (Nivre et al., 2006a).

ZPar - Zpar parser which is basically an alternative implementation of the Malt parser, employing a richer set of non-local features as described by Zhang and Nivre (2011). $$$$$ Transition-based Dependency Parsing with Rich Non-local Features
ZPar - Zpar parser which is basically an alternative implementation of the Malt parser, employing a richer set of non-local features as described by Zhang and Nivre (2011). $$$$$ Table 5 shows the results of our final parser, the pure transition-based parser of Zhang and Clark (2008), and the parser of Huang and Sagae (2010) on Chinese.

The dependency parsing features are taken from the work of Zhang and Nivre (2011), and the features for joint word segmentation and POS-tagging are taken from Zhang and Clark (2010). $$$$$ These features are mostly taken from Zhang and Clark (2008) and Huang and Sagae (2010), and our parser reproduces the same accuracies as reported by both papers.
The dependency parsing features are taken from the work of Zhang and Nivre (2011), and the features for joint word segmentation and POS-tagging are taken from Zhang and Clark (2010). $$$$$ The distance between S0 and N0 will correspond to the distance between a pair of head and modifier when an LeftArc action is taken, for example, but not when a Shift action is taken.

 $$$$$ Denoting the top of stack w – word; p – POS-tag; vl, vr – valency; l – dependency label, sl, sr – labelset. with S0, the front items from the queue with N0, N1, and N2, the head of S0 (if any) with S0h, the leftmost and rightmost modifiers of S0 (if any) with S0l and S0r, respectively, and the leftmost modifier of N0 (if any) with N0l, the baseline features are shown in Table 1.
 $$$$$ Our scores for this test set are the best reported so far and significantly better than the previous systems.

 $$$$$ Denoting the top of stack w – word; p – POS-tag; vl, vr – valency; l – dependency label, sl, sr – labelset. with S0, the front items from the queue with N0, N1, and N2, the head of S0 (if any) with S0h, the leftmost and rightmost modifiers of S0 (if any) with S0l and S0r, respectively, and the leftmost modifier of N0 (if any) with N0l, the baseline features are shown in Table 1.
 $$$$$ Our scores for this test set are the best reported so far and significantly better than the previous systems.

Our results are better than most systems on this data split, except Zhang and Nivre (2011), Li et al (2012) and Chen et al (2009). $$$$$ Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing (Zhang and Clark, 2009; Wang et al., 2006), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser (Nivre et al., 2006a).
Our results are better than most systems on this data split, except Zhang and Nivre (2011), Li et al (2012) and Chen et al (2009). $$$$$ Unigram label information has been used in MaltParser (Nivre et al., 2006a; Nivre, 2006).

Python implementation for the labeled arc-eager system with the rich feature set of Zhang and Nivre (2011) is available on the first author's homepage. $$$$$ Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003; Huang and Sagae, 2010) process.
Python implementation for the labeled arc-eager system with the rich feature set of Zhang and Nivre (2011) is available on the first author's homepage. $$$$$ We include information of third order dependency arcs in our new feature templates, when available.

ArcS use feature set of Huang and Sagae (2010) (50 templates), and ArcE that of Zhang and Nivre (2011) (72 templates). $$$$$ Such use is exemplified by the feature templates “from three words” in Table 1.
ArcS use feature set of Huang and Sagae (2010) (50 templates), and ArcE that of Zhang and Nivre (2011) (72 templates). $$$$$ We include information of third order dependency arcs in our new feature templates, when available.

Li11 refers to the second-order graph-based model of Li et al (2011), whereas Z&N11 is the feature-rich transition-based model of Zhang and Nivre (2011). $$$$$ Transition-based Dependency Parsing with Rich Non-local Features
Li11 refers to the second-order graph-based model of Li et al (2011), whereas Z&N11 is the feature-rich transition-based model of Zhang and Nivre (2011). $$$$$ It is worth noticing that the use of distance information in our transition-based model is different from that in a typical graph-based parser such as MSTParser.

More efficient decoding would also allow the use of the look-ahead features (Hatori et al, 2011) and richer parsing features (Zhang and Nivre, 2011). $$$$$ Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing (Zhang and Clark, 2009; Wang et al., 2006), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser (Nivre et al., 2006a).
More efficient decoding would also allow the use of the look-ahead features (Hatori et al, 2011) and richer parsing features (Zhang and Nivre, 2011). $$$$$ We further use their word and POS-tag information as “unigram” features in Table 2.

Additionally, we look at higher-order dependency arc label features, which is novel to graph-based parsing, though commonly exploited in transition-based parsing (Zhang and Nivre, 2011). $$$$$ Transition-based Dependency Parsing with Rich Non-local Features
Additionally, we look at higher-order dependency arc label features, which is novel to graph-based parsing, though commonly exploited in transition-based parsing (Zhang and Nivre, 2011). $$$$$ Third-order features of S0 and N0 Higher-order context features have been used by graph-based dependency parsers to improve accuracies (Carreras, 2007; Koo and Collins, 2010).

The speed of our parser is 220 tokens per second, which is over 4 times faster than an exact third-order parser that at Figure 1: Example Sentence.tains UAS of 92.81% and comparable to the state-of the-art transition-based system of Zhang and Nivre (2011) that employs beam search. $$$$$ In standard experiments using the Penn Treebank, our parser gets an unlabeled attachment score of 92.9%, which is the best result achieved with a transition-based parser and comparable to the state of the art.
The speed of our parser is 220 tokens per second, which is over 4 times faster than an exact third-order parser that at Figure 1: Example Sentence.tains UAS of 92.81% and comparable to the state-of the-art transition-based system of Zhang and Nivre (2011) that employs beam search. $$$$$ The speed of our baseline parser was 50 sentences per second.

We compare our method to a state-of-the-art graph-based parser (Koo and Collins, 2010) as well as a state-of-the-art transition-based parser that uses a beam (Zhang and Nivre, 2011) and the dynamic programming transition-based parser of Huang and Sagae (2010). Additionally, we compare to our own implementation of exact first to third-order graph-based parsing and the transition-based system of Zhang and Nivre (2011) with varying beam sizes. $$$$$ Again, the use of valency information in our transition-based parser is different from the aforementioned graph-based models.
We compare our method to a state-of-the-art graph-based parser (Koo and Collins, 2010) as well as a state-of-the-art transition-based parser that uses a beam (Zhang and Nivre, 2011) and the dynamic programming transition-based parser of Huang and Sagae (2010). Additionally, we compare to our own implementation of exact first to third-order graph-based parsing and the transition-based system of Zhang and Nivre (2011) with varying beam sizes. $$$$$ Table 5 shows the results of our final parser, the pure transition-based parser of Zhang and Clark (2008), and the parser of Huang and Sagae (2010) on Chinese.

We also report results for a re-implementation of exact first to third-order graph-based parsing and a re-implementation of Zhang and Nivre (2011) in order to compare parser speed. $$$$$ Third-order features of S0 and N0 Higher-order context features have been used by graph-based dependency parsers to improve accuracies (Carreras, 2007; Koo and Collins, 2010).
We also report results for a re-implementation of exact first to third-order graph-based parsing and a re-implementation of Zhang and Nivre (2011) in order to compare parser speed. $$$$$ Table 5 shows the results of our final parser, the pure transition-based parser of Zhang and Clark (2008), and the parser of Huang and Sagae (2010) on Chinese.

Second, at a similar toks/sec parser speed, our method achieves better performance than the transition-based model of Zhang and Nivre (2011) with a beam of 256. $$$$$ We include similar information in our model.
Second, at a similar toks/sec parser speed, our method achieves better performance than the transition-based model of Zhang and Nivre (2011) with a beam of 256. $$$$$ The speed of our baseline parser was 50 sentences per second.

Here we use the identical training/validation/evaluation splits and experimental set-up as Zhang and Nivre (2011). $$$$$ Such use is exemplified by the feature templates “from three words” in Table 1.
Here we use the identical training/validation/evaluation splits and experimental set-up as Zhang and Nivre (2011). $$$$$ For all experiments, we set the beam size to 64 for the parser, and report unlabeled and labeled attachment scores (UAS, LAS) and unlabeled exact match (UEM) for evaluation.

Here we compare to our re-implementations of Zhang and Nivre (2011), exact first to third-order parsing and Rush and Petrov (2012) for the data sets in which they reported results. $$$$$ In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall.
Here we compare to our re-implementations of Zhang and Nivre (2011), exact first to third-order parsing and Rush and Petrov (2012) for the data sets in which they reported results. $$$$$ Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003; Huang and Sagae, 2010) process.

Zhang and Nivre is a reimplementation of Zhang and Nivre (2011) with beams of size 64 and 256. $$$$$ Unigram label information has been used in MaltParser (Nivre et al., 2006a; Nivre, 2006).
Zhang and Nivre is a reimplementation of Zhang and Nivre (2011) with beams of size 64 and 256. $$$$$ For all experiments, we set the beam size to 64 for the parser, and report unlabeled and labeled attachment scores (UAS, LAS) and unlabeled exact match (UEM) for evaluation.

For reference, Zhang and Nivre (2011) report 86.0/84.4, which is previously the best result reported on this data set. $$$$$ For the Chinese Treebank, our parser gets a score of 86.0%, the best reported result so far.
For reference, Zhang and Nivre (2011) report 86.0/84.4, which is previously the best result reported on this data set. $$$$$ Our scores for this test set are the best reported so far and significantly better than the previous systems.

Our feature template is an extended version of the feature template of Zhang and Nivre (2011), originally developed for the arc-eager model. $$$$$ Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003; Huang and Sagae, 2010) process.
Our feature template is an extended version of the feature template of Zhang and Nivre (2011), originally developed for the arc-eager model. $$$$$ For example, S0pN0wp represents the feature template that takes the word and POS-tag of N0, and combines it with the word of S0.
