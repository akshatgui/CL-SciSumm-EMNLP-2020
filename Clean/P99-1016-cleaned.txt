See Caraballo (1999) for a detailed description of a method to construct such a hierarchy. $$$$$ Compute the similarity between each pair of nodes using the cosine method.
See Caraballo (1999) for a detailed description of a method to construct such a hierarchy. $$$$$ For each internal node of the tree, we construct a vector of hypernyms by adding together the vectors of its children.

In Caraballo (1999), we construct a hierarchy of nouns, including hypernym relations. $$$$$ For example, we have a cluster including many forms of currency, but because there is little data for these particular words, the only hypernym found was &quot;product&quot;.
In Caraballo (1999), we construct a hierarchy of nouns, including hypernym relations. $$$$$ Their clustering is based on verb-object relations rather than on the noun-noun relations that we use.

Caraballo (1999) proposed the first attempt, which used conjunction and apposition features to build noun clusters. $$$$$ A vector is created for each noun containing counts for how many times each other noun appears in a conjunction or appositive with it.
Caraballo (1999) proposed the first attempt, which used conjunction and apposition features to build noun clusters. $$$$$ Pereira et al. (1993) used clustering to build an unlabeled hierarchy of nouns.

Caraballo (1999) uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns. $$$$$ The first stage in constructing our hierarchy is to build an unlabeled hierarchy of nouns using bottom-up clustering methods (see, e.g., Brown et al. (1992)).
Caraballo (1999) uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns. $$$$$ Pereira et al. (1993) used clustering to build an unlabeled hierarchy of nouns.

The built-in ambiguity in the hyponymy hierarchy presented in (Caraballo, 1999) is primarily an effect of the fact that all information is composed into one tree. $$$$$ This work goes a step further by automatically creating not just clusters of related words, but a hierarchy of nouns and their hypernyms, akin to the hand-built hierarchy in WordNet.
The built-in ambiguity in the hyponymy hierarchy presented in (Caraballo, 1999) is primarily an effect of the fact that all information is composed into one tree. $$$$$ Because the tree is built in a binary fashion, when, e.g., three clusters should all be distinct children of a common parent, two of them must merge first, giving an artificial intermediate level in the tree.

As was also reported by Caraballo (1999), the judges sometimes found proper nouns (as hyponyms) hard to evaluate. $$$$$ Three human judges were asked to evaluate for each noun and each of the (up to) three hypernyms listed as &quot;best&quot; for that cluster, whether they were actually in a hyponym-hypernym relation.
As was also reported by Caraballo (1999), the judges sometimes found proper nouns (as hyponyms) hard to evaluate. $$$$$ Some nouns, especially proper nouns, were not recognized by the judges.

It is difficult to compare these results with results from other studies such as that of Caraballo (1999), as the data used is not the same. $$$$$ The &quot;Hypernym 1/any&quot; column can be used to compare results to Riloff and Shepherd (1997).
It is difficult to compare these results with results from other studies such as that of Caraballo (1999), as the data used is not the same. $$$$$ Unfortunately it is difficult to compare their results to ours since their evaluation is based on the verb-object relations.

Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy that had at least twenty descendants. $$$$$ There are 20,014 leaves (nouns) and 654 internal nodes in the final tree (reduced from 20,013 internal nodes in the uncompressed tree).
Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy that had at least twenty descendants. $$$$$ To evaluate the hierarchy, 10 internal nodes dominating at least 20 nouns were selected at random.

In Section 4, we show how correctly extracted relationships can be used as "seed-cases" to extract several more relationships, thus improving recall; this work shares some similarities with that of Caraballo (1999). $$$$$ Because of the method of selecting hypernyms, the hypernyms may be synonyms of each other, have hypernym-hyponym relationships of their own, or be completely unrelated.)
In Section 4, we show how correctly extracted relationships can be used as "seed-cases" to extract several more relationships, thus improving recall; this work shares some similarities with that of Caraballo (1999). $$$$$ Hearst (1992) introduced the idea of learning hypernym-hyponym relationships from text and gives several examples of patterns that can be used to detect these relationships including those used here, along with an algorithm for identifying new patterns.

Another definition is given by Caraballo (1999). $$$$$ In our current tree, the best hypernym for the entire tree is &quot;product&quot;; however, many times nodes deeper in the tree are given this label also.
Another definition is given by Caraballo (1999). $$$$$ As noted in the previous section, one major spurious result is a cluster of 51 nouns, mainly people, which is given the hypernym &quot;conductor&quot;.

First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in (Caraballo, 1999), perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node. $$$$$ We can then compute the new node's similarity to each other node by computing a weighted average of the similarities between each of its children and the other node.
First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in (Caraballo, 1999), perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node. $$$$$ In our current tree, the best hypernym for the entire tree is &quot;product&quot;; however, many times nodes deeper in the tree are given this label also.

As stated in (Caraballo, 1999), WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts. $$$$$ The purpose of this work is to build something like the hypernym-labeled noun hierarchy of WordNet (Fellbaum, 1998) automatically from text using no other lexical resources.
As stated in (Caraballo, 1999), WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts. $$$$$ WordNet has been an important research tool, but it is insufficient for domainspecific text, such as that encountered in the MUCs (Message Understanding Conferences).

So, many attempts have been made to automatically produce taxonomies (Grefenstette, 1994), but (Caraballo, 1999) is certainly the first work which proposes a complete overview of the problem by (1) automatically building a hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A. $$$$$ The internal nodes of the resulting tree are then labeled with hypernyms for the nouns clustered underneath them, also based on data extracted from the Wall Street Journal.
So, many attempts have been made to automatically produce taxonomies (Grefenstette, 1994), but (Caraballo, 1999) is certainly the first work which proposes a complete overview of the problem by (1) automatically building a hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A. $$$$$ We have shown that hypernym hierarchies of nouns can be constructed automatically from text with similar performance to semantic lexicons built automatically for hand-selected hypernyms.

Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters. $$$$$ Their clustering is based on verb-object relations rather than on the noun-noun relations that we use.
Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters. $$$$$ Roark and Charniak (1998) built on that work by actually using conjunction and appositive data for noun clustering, as we do here.

(Caraballo, 1999B) also used contextual information to determine the specificity of nouns. $$$$$ Since the lowest-frequency nouns are clustered based on very little information and have a greater tendency to be clustered badly, we chose to filter some of these out.
(Caraballo, 1999B) also used contextual information to determine the specificity of nouns. $$$$$ Pereira et al. (1993) used clustering to build an unlabeled hierarchy of nouns.

Contrary, domain specific terms don't tend to be modified by other words, because they have sufficient information in themselves (Caraballo, 1999B). $$$$$ Not every node has sufficient data to be assigned a hypernym.
Contrary, domain specific terms don't tend to be modified by other words, because they have sufficient information in themselves (Caraballo, 1999B). $$$$$ It would be useful to try to identify terms made up of multiple words, rather than just using the head nouns of the noun phrases.

 $$$$$ We then assign a hypernym to this node by simply choosing the hypernym with the largest value in this vector; that is, the hypernym which appeared with the largest number of the node's descendant nouns.
 $$$$$ This research is supported in part by NSF grant IRI-9319516 and by ONR grant N0014-96-1-0549.

Caraballo (1999) uses conjunction and appositive annotations in the vector representation. $$$$$ Nouns are clustered based on conjunction and appositive data collected from the Wall Street Journal corpus.
Caraballo (1999) uses conjunction and appositive annotations in the vector representation. $$$$$ A vector is created for each noun containing counts for how many times each other noun appears in a conjunction or appositive with it.

Other approaches use natural language data, sometimes just by analyzing the corpus (Sanderson and Croft 1999), (Caraballo 1999) or by learning to expand WordNet with clusters of terms from a corpus, e.g., (Girju et al 2003). $$$$$ Our work develops a labeled hierarchy based on a text corpus.
Other approaches use natural language data, sometimes just by analyzing the corpus (Sanderson and Croft 1999), (Caraballo 1999) or by learning to expand WordNet with clusters of terms from a corpus, e.g., (Girju et al 2003). $$$$$ Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998).

For example, based on (Caraballo 1999), each parent of a leaf node could be viewed as a cluster label for its children, with the weight of a parent-child link being determined based on how strongly the child is associated with the cluster. $$$$$ If the child is itself an internal node, and it either has no best hypernym or the same three best hypernyms as its parent, delete this child and make its children into children of the parent instead.
For example, based on (Caraballo 1999), each parent of a leaf node could be viewed as a cluster label for its children, with the weight of a parent-child link being determined based on how strongly the child is associated with the cluster. $$$$$ If we knew that &quot;product&quot; was a hypernym of &quot;currency&quot;, we could detect that the parent node's label is more specific and simply absorb the child node into the parent.
