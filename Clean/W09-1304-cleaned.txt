The BioScope corpus has been used to train and evaluate automatic classifiers (e.g. Ozgur and Radev (2009) and Morante and Daelemans (2009)) with promising results. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
The BioScope corpus has been used to train and evaluate automatic classifiers (e.g. Ozgur and Radev (2009) and Morante and Daelemans (2009)) with promising results. $$$$$ We have used the same features used for the system that finds the scope of negation.

Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a supervised sequence labeling approach while Ozgur and Radev (2009) developed a rule-based system that exploits syntactic patterns. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a supervised sequence labeling approach while Ozgur and Radev (2009) developed a rule-based system that exploits syntactic patterns. $$$$$ In Section 3, we describe the corpus on which the system has been developed.

Most systems following Morante and Daelemans (2009) used three class labels (F) IRST, (L) AST and NONE. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
Most systems following Morante and Daelemans (2009) used three class labels (F) IRST, (L) AST and NONE. $$$$$ We have used the same features used for the system that finds the scope of negation.

The following summarizes the steps we took to achieve this goal. Similarly to previous work in hedge cue detection (Morante and Daelemans, 2009), we first convert the task into a sequential labeling task based on the BIO scheme, where each word in a hedge cue is labeled as B-CUE, I-CUE, or O, indicating respectively the labeled word is at the beginning of a cue, inside of a cue, or outside of a hedge cue; this is similar to the tagging scheme from the CoNLL-2001 shared task. $$$$$ In this phase, a classifier predicts for all tokens in a sentence whether a token is the first token of a hedge cue (B-cue), inside a hedge cue (I-cue), or outside of it (O-cue).
The following summarizes the steps we took to achieve this goal. Similarly to previous work in hedge cue detection (Morante and Daelemans, 2009), we first convert the task into a sequential labeling task based on the BIO scheme, where each word in a hedge cue is labeled as B-CUE, I-CUE, or O, indicating respectively the labeled word is at the beginning of a cue, inside of a cue, or outside of a hedge cue; this is similar to the tagging scheme from the CoNLL-2001 shared task. $$$$$ For sentence (3) the system assigns the B-cue class to indicate, the I-cue class to that and the O-cue class to the rest of tokens.

To tackle the hedge cue detection problem posed by the CoNLL-2010 shared task, we utilized a classifier for sequential labeling following previous work (Morante and Daelemans, 2009). $$$$$ In this phase, a classifier predicts for all tokens in a sentence whether a token is the first token of a hedge cue (B-cue), inside a hedge cue (I-cue), or outside of it (O-cue).
To tackle the hedge cue detection problem posed by the CoNLL-2010 shared task, we utilized a classifier for sequential labeling following previous work (Morante and Daelemans, 2009). $$$$$ Hedge cues are those that have been classified as such in the previous phase.

In Morante and Daelemans (2009), the hedge detection task is solved as two consecutive classification tasks. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
In Morante and Daelemans (2009), the hedge detection task is solved as two consecutive classification tasks. $$$$$ We model this task in the same way that we modelled the task for finding the scope of negation (Morante and Daelemans, 2009), i.e., as two consecutive classification tasks

As the baseline classifier, we use the Cue Dictionary proposed in Morante and Daelemans (2009), classifying each occurrence of those words as a cue. $$$$$ Finding the scope of a hedge cue means determining at sentence level which words in the sentence are affected by the hedge cue.
As the baseline classifier, we use the Cue Dictionary proposed in Morante and Daelemans (2009), classifying each occurrence of those words as a cue. $$$$$ In this phase, a classifier predicts for all tokens in a sentence whether a token is the first token of a hedge cue (B-cue), inside a hedge cue (I-cue), or outside of it (O-cue).

Also, the task of hedge detection (Morante and Daelemans, 2009) can be solved separately, in the original sentences, after the interacting pairs have been found. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
Also, the task of hedge detection (Morante and Daelemans, 2009) can be solved separately, in the original sentences, after the interacting pairs have been found. $$$$$ We model this task in the same way that we modelled the task for finding the scope of negation (Morante and Daelemans, 2009), i.e., as two consecutive classification tasks

Parts of the system are similar to that of Morante and Daelemans (2009) both make use of machine learning to tag tokens as being in a cue or a scope. $$$$$ In this paper we present a machine learning system that finds the scope of hedge cues in biomedical texts.
Parts of the system are similar to that of Morante and Daelemans (2009) both make use of machine learning to tag tokens as being in a cue or a scope. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).

The presence of potential clause ending words, used by Morante and Daelemans (2009), is included as a feature type with values $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
The presence of potential clause ending words, used by Morante and Daelemans (2009), is included as a feature type with values $$$$$ We have used the same features used for the system that finds the scope of negation.

Vincze et al (2008) created a publicly available annotated corpus of biomedical papers, abstracts and clinical data called BioScope, parts of which were also used as training data for the CoNLL10 shared task, building on the dataset and annotation scheme used for evaluation by Medlock and Briscoe (2007). Morante and Daelemans (2009) use the BioScope corpus to approach the problem of identifying cues and scopes via supervised machine learning. $$$$$ The system has been developed using the BioScope corpus (Szarvas et al., 2008; Vincze et al., 2008)2, a freely available resource that consists of medical and biological texts.
Vincze et al (2008) created a publicly available annotated corpus of biomedical papers, abstracts and clinical data called BioScope, parts of which were also used as training data for the CoNLL10 shared task, building on the dataset and annotation scheme used for evaluation by Medlock and Briscoe (2007). Morante and Daelemans (2009) use the BioScope corpus to approach the problem of identifying cues and scopes via supervised machine learning. $$$$$ The cues that are not present in the training data cannot be learned in the test data and the same applies to their scope.

Morante and Daelemans (2009) presented a meta-learning system that finds the scope of hedge cues in biomedical texts. $$$$$ Learning the Scope of Hedge Cues in Biomedical Texts
Morante and Daelemans (2009) presented a meta-learning system that finds the scope of hedge cues in biomedical texts. $$$$$ In this paper we present a machine learning system that finds the scope of hedge cues in biomedical texts.

Shallow linguistic features are introduced in their experiments. Morante and Daelemans (2009) present their research on identifying hedge cues and their scopes. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
Shallow linguistic features are introduced in their experiments. Morante and Daelemans (2009) present their research on identifying hedge cues and their scopes. $$$$$ We performed two experiments.

More experiments could be found in their paper (Morante and Daelemans, 2009). $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
More experiments could be found in their paper (Morante and Daelemans, 2009). $$$$$ We performed two experiments.

The main difference between the two systems is that Morante and Daelemans (2009) perform the second phase with a machine learner, whereas Ozgur and Radev (2009) perform the second phase witha rule-based system that exploits syntactic information. $$$$$ We are not aware of other systems that perform this task.
The main difference between the two systems is that Morante and Daelemans (2009) perform the second phase with a machine learner, whereas Ozgur and Radev (2009) perform the second phase witha rule-based system that exploits syntactic information. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).

The approach to resolving the scopes of hedge cues that we present in this paper is similar to the approach followed in Morante and Daelemans (2009) in that the task is modelled in the same way. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
The approach to resolving the scopes of hedge cues that we present in this paper is similar to the approach followed in Morante and Daelemans (2009) in that the task is modelled in the same way. $$$$$ We model this task in the same way that we modelled the task for finding the scope of negation (Morante and Daelemans, 2009), i.e., as two consecutive classification tasks

A difference between the two systems is that this system uses only one classifier to solve Task 2, whereas the system described in Morante and Daelemans (2009) used three classifiers and a metalearner. $$$$$ We are not aware of other systems that perform this task.
A difference between the two systems is that this system uses only one classifier to solve Task 2, whereas the system described in Morante and Daelemans (2009) used three classifiers and a metalearner. $$$$$ A fourth classifier is a metalearner that uses the predictions of the three classifiers to predict the scope classes.

Another difference is that the system in Morante and Daelemans (2009) used shallow syntactic features, whereas this system uses features from both shallow and dependency syntax. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
Another difference is that the system in Morante and Daelemans (2009) used shallow syntactic features, whereas this system uses features from both shallow and dependency syntax. $$$$$ We have used the same features used for the system that finds the scope of negation.

It is not really possible to compare the scores obtained in this task to existing research previous to the CoNLL-2010 Shared Task, namely the results obtained by Ozgur and Radev (2009) on the BioScope corpus with a rule-based system and byMorante and Daelemans (2009) on the same corpus with a combination of classifiers. $$$$$ The system is based on a similar system that finds the scope of negation cues (Morante and Daelemans, 2009).
It is not really possible to compare the scores obtained in this task to existing research previous to the CoNLL-2010 Shared Task, namely the results obtained by Ozgur and Radev (2009) on the BioScope corpus with a rule-based system and byMorante and Daelemans (2009) on the same corpus with a combination of classifiers. $$$$$ This can be explained by the results obtained in the cues finding phase, where the clinical subcorpus obtained only 41.92% F1.

Morante and Daelemans (2009) report percentage of correct scopes for the full text data set (42.37), obtained by training on the abstracts data set, whereas the results presented in Table 5 are reported in Fmeasures and obtained in by training and testing on other corpora. $$$$$ The results provided for the abstracts part of the corpus have been obtained by performing 10-fold cross validation experiments, whereas the results provided for papers and clinical reports have been obtained by training on the full abstracts subcorpus and testing on the papers and clinical reports subcorpus.
Morante and Daelemans (2009) report percentage of correct scopes for the full text data set (42.37), obtained by training on the abstracts data set, whereas the results presented in Table 5 are reported in Fmeasures and obtained in by training and testing on other corpora. $$$$$ The cues that are not present in the training data cannot be learned in the test data and the same applies to their scope.
