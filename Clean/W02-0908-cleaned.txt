Curran and Moens (2002b) evaluate thesaurus extractors based on several different models of context on large corpora. $$$$$ Our previous work (Curran and Moens, 2002) has evaluated thesaurus extraction performance and efficiency using several different context models.
Curran and Moens (2002b) evaluate thesaurus extractors based on several different models of context on large corpora. $$$$$ This approximation algorithm is dramatically faster than simple pairwise comparison, with only a small performance penalty, which means that complete thesaurus extraction on large corpora is now feasible.

All the systems use the JACCARD similarity metric and TTEST weighting function that were found to be most effective for thesaurus extraction by Curran and Moens (2002a). $$$$$ Vector-space thesaurus extraction systems can be separated into two components.
All the systems use the JACCARD similarity metric and TTEST weighting function that were found to be most effective for thesaurus extraction by Curran and Moens (2002a). $$$$$ Table 7 presents the example term results using the techniques we have described: JACCARD measure and TTEST weight functions; minimum cutoff of 30; and approximation algorithm with canonical vector size of 100 with TTESTLOG weighting.

Curran and Moens (2002b) have demonstrated that more complex and constrained contexts can yield superior performance, since the correlation between context and target term is stronger than simple window methods. $$$$$ Most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into a vector-space representation of the contexts that each target term appears in (Pereira et al., 1993; Ruge, 1997; Lin, 1998b).
Curran and Moens (2002b) have demonstrated that more complex and constrained contexts can yield superior performance, since the correlation between context and target term is stronger than simple window methods. $$$$$ Some systems define the context as a window of words surrounding each thesaurus term (McDonald, 2000).

We worked with an implementation of the log likelihood ratio (g-Score) as proposed by Dunning (1993) and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of Curran and Moens (2002). $$$$$ 1 5 + 128, and with at most 200 synonyms, the maximum INVR score is 5.878.
We worked with an implementation of the log likelihood ratio (g-Score) as proposed by Dunning (1993) and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of Curran and Moens (2002). $$$$$ As an example, with a maximum cutoff of 10,000 and a canonical vector size of 70, the total DIRECT score of 1841 represents a 3.9% performance penalty over full extraction, for an 89% reduction in execution time.

Another venue of research may be to exploit different thesauri, such as the ones automatically derived as in (Curran and Moens, 2002). $$$$$ There is a clear need for methods to extract thesauri automatically or tools that assist in the manual creation and updating of these semantic resources.
Another venue of research may be to exploit different thesauri, such as the ones automatically derived as in (Curran and Moens, 2002). $$$$$ Our previous work (Curran and Moens, 2002) has evaluated thesaurus extraction performance and efficiency using several different context models.

Several researchers (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)) have used large monolingual corpora to extract distributionally similar words. $$$$$ Many systems extract grammatical relations using either a broad coverage parser (Lin, 1998a) or shallow statistical tools (Grefenstette, 1994; Curran and Moens, 2002).
Several researchers (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)) have used large monolingual corpora to extract distributionally similar words. $$$$$ Early experiments in thesaurus extraction (Grefenstette, 1994) suffered from the limited size of available corpora, but more recent experiments have used much larger corpora with greater success (Lin, 1998a).

Monolingual syntax-based distributional similarity is used in many proposals to find semantically related words (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)). $$$$$ Alternatively, some systems are based on the observation that related terms appear together in particular contexts.
Monolingual syntax-based distributional similarity is used in many proposals to find semantically related words (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)). $$$$$ Other measures, such as LIN and JACCARD have previously been used for thesaurus extraction (Lin, 1998a; Grefenstette, 1994).

Curran and Moens (2002) report on a large scale evaluation experiment, where they evaluated the performance of various commonly used methods. $$$$$ Our previous work (Curran and Moens, 2002) has evaluated thesaurus extraction performance and efficiency using several different context models.
Curran and Moens (2002) report on a large scale evaluation experiment, where they evaluated the performance of various commonly used methods. $$$$$ We would also like to expand our evaluation to include direct methods used by others (Lin, 1998a) and using the extracted thesaurus in NLP tasks.

Vander Plas and Bouma (2005) present a similar experiment for Dutch, in which they tested most of the best performing measures according to Curran and Moens (2002). $$$$$ Finally, we have generalised some set measures using similar reasoning to Grefenstette (1994).
Vander Plas and Bouma (2005) present a similar experiment for Dutch, in which they tested most of the best performing measures according to Curran and Moens (2002). $$$$$ The best performance across all measures was shared by JACCARD and DICE†, which produced identical results for the 70 words.

Curran and Moens (2002) show that synonymy extraction for lexical semantic resources using distributional similarity produces continuing gains in accuracy as the volume of input data increases. $$$$$ The use of semantic resources is comin modern but methods to extract lexical semantics have only recently begun to perform well enough for practical use.
Curran and Moens (2002) show that synonymy extraction for lexical semantic resources using distributional similarity produces continuing gains in accuracy as the volume of input data increases. $$$$$ Our previous work (Curran and Moens, 2002) has evaluated thesaurus extraction performance and efficiency using several different context models.

Curran and Moens (2002) introduces a vector of canonical attributes (of bounded length k m), selected from the full vector, to represent the term. $$$$$ We can do this by introducing another, much shorter vector of canonical attributes, with a bounded length k. If our approximate comparison returns at most p positive results for each term, then the time complexity becomes O(n2k + npm), which, since k is constant, is O(n2 + npm).
Curran and Moens (2002) introduces a vector of canonical attributes (of bounded length k m), selected from the full vector, to represent the term. $$$$$ The canonical vector must contain attributes that best describe the thesaurus term in a bounded number of entries.

Comparisons made with these low frequency terms are unreliable (Curran and Moens, 2002). $$$$$ Introducing a minimum cutoff that ignores low frequency potential synonyms can eliminate many unnecessary comparisons.
Comparisons made with these low frequency terms are unreliable (Curran and Moens, 2002). $$$$$ In fact, using a cutoff increases the average value of m across the terms because it removes low frequency terms with few attributes.

Recently, there has been much interest in finding words which are distribution ally similar e.g., Lin (1998), Lee (1999), Curran and Moens (2002), Weeds (2003) and Geffet and Dagan (2004). $$$$$ Our previous work (Curran and Moens, 2002) has evaluated thesaurus extraction performance and efficiency using several different context models.
Recently, there has been much interest in finding words which are distribution ally similar e.g., Lin (1998), Lee (1999), Curran and Moens (2002), Weeds (2003) and Geffet and Dagan (2004). $$$$$ Many systems extract grammatical relations using either a broad coverage parser (Lin, 1998a) or shallow statistical tools (Grefenstette, 1994; Curran and Moens, 2002).

In these experiments we have used a variant of Dice, proposed by Curran and Moens (2002). $$$$$ Our previous work (Curran and Moens, 2002) has evaluated thesaurus extraction performance and efficiency using several different context models.
In these experiments we have used a variant of Dice, proposed by Curran and Moens (2002). $$$$$ In these experiments we have proposed new measure and weight functions that, as our evaluation has shown, significantly outperform existing similarity functions.

Pereira et al (1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. $$$$$ Most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into a vector-space representation of the contexts that each target term appears in (Pereira et al., 1993; Ruge, 1997; Lin, 1998b).
Pereira et al (1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. $$$$$ This consists of four passes over the sentence, associating each noun with the modifiers and verbs from the syntactic contexts they appear in: The relation tuple is then converted to root form using the Sussex morphological analyser (Minnen et al., 2000) and the POS tags are removed.

Also, because it has been shown (Curran and Moens, 2002) that negative PMI values worsen the distributional similarity performance, we bound PMI so that PMI (wi, cj)= 0 if PMI (wi, cj) < 0. $$$$$ Our previous work (Curran and Moens, 2002) has evaluated thesaurus extraction performance and efficiency using several different context models.
Also, because it has been shown (Curran and Moens, 2002) that negative PMI values worsen the distributional similarity performance, we bound PMI so that PMI (wi, cj)= 0 if PMI (wi, cj) < 0. $$$$$ In these experiments we have proposed new measure and weight functions that, as our evaluation has shown, significantly outperform existing similarity functions.

A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002). $$$$$ Much of the existing work on thesaurus extraction and word clustering is based on the observation that related terms will appear in similar contexts.
A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002). $$$$$ Vector-space thesaurus extraction systems can be separated into two components.

Curran and Moens (2002b) have demonstrated that dramatically increasing the quantity of text used to extract contexts significantly improves synonym quality. $$$$$ The first component extracts the contexts from raw text and compiles them into a statistical description of the contexts each potential thesaurus term appears in.
Curran and Moens (2002b) have demonstrated that dramatically increasing the quantity of text used to extract contexts significantly improves synonym quality. $$$$$ Each measure is averaged over the extracted synonym lists for all 70 thesaurus terms.

For these experiments we use the JACCARD (1) measure and the TTEST (2) weight, as Curran and Moens (2002a) found them to have the best performance in their comparison of many distance measures. $$$$$ Therefore, we have evaluated the weight functions using the JACCARD measure, and evaluated the measure functions using the TTEST weight because they produced the best results in our previous experiments.
For these experiments we use the JACCARD (1) measure and the TTEST (2) weight, as Curran and Moens (2002a) found them to have the best performance in their comparison of many distance measures. $$$$$ The best performance across all measures was shared by JACCARD and DICE†, which produced identical results for the 70 words.

Curran and Moens (2002a) propose an initial heuristic comparison to reduce the number of full O(m) vector comparisons. $$$$$ Curran and Moens (2002)), which would increase both number of attributes for each term and the total number of terms above the minimum cutoff, this is not nearly fast enough.
Curran and Moens (2002a) propose an initial heuristic comparison to reduce the number of full O(m) vector comparisons. $$$$$ However, what is needed is some algorithmic reduction that bounds the number of full O(m) vector comparisons performed.
