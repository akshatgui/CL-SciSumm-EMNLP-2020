 $$$$$ 3.2.5 The CLARIFY Move.
 $$$$$ We would like to thank our anonymous reviewers for their comments on the draft manuscript.

These strategies can be seen as transactions made up of conversational games (Carletta et al., 1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
These strategies can be seen as transactions made up of conversational games (Carletta et al., 1997). $$$$$ Subjective coding has been described for three different levels of task-oriented dialogue structure, called conversational moves, games, and transactions, and the reliability of all three kinds of coding discussed.

Each dialogue is divided into short, clearly defined dialogue acts Initiations I and Acknowledgments A based on the top of the hierarchy given in Carletta et al (1997). $$$$$ Alexandersson et al. (1995) devise a set of 17 &quot;speech acts&quot; that occur in dialogues between people setting the date for a business meeting; some of these speech acts are task-specific.
Each dialogue is divided into short, clearly defined dialogue acts Initiations I and Acknowledgments A based on the top of the hierarchy given in Carletta et al (1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).

This is an empirically very well-founded distinction $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
This is an empirically very well-founded distinction $$$$$ Krippendorff also points out that where one coding distinction relies on the results of another, the second distinction cannot be reasonable unless the first also is.

As indicated in Table 9, the unanimous agreement of just 16.6% and 19.5% in the ad hoc and categorization tasks respectively is low $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
As indicated in Table 9, the unanimous agreement of just 16.6% and 19.5% in the ad hoc and categorization tasks respectively is low $$$$$ In any categorization, there is a trade-off between usefulness and ease or consistency of coding.

To put Table 8 in perspective, note that expert human coders achieved= 0.83 on DA classification for MapTask, but also had available the speech source (Carletta et al, 1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
To put Table 8 in perspective, note that expert human coders achieved= 0.83 on DA classification for MapTask, but also had available the speech source (Carletta et al, 1997). $$$$$ Note that the expert interacted minimally with the coders, and therefore differences were not due to training.

We also compared the confusion matrix from (Carletta et al, 1997) with the confusion matrix we obtained for our best result on MapTask (FLSA using Game+ Speaker). $$$$$ This confusion was general, suggesting that it might be useful to think more carefully about the difference between answering a question and providing further information.
We also compared the confusion matrix from (Carletta et al, 1997) with the confusion matrix we obtained for our best result on MapTask (FLSA using Game+ Speaker). $$$$$ There was also confusion about whether a game with an agreed beginning was embedded or not (K = .46).

The same type of structures is also used in the analysis of dialogues, e.g. (Carletta et al., 1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
The same type of structures is also used in the analysis of dialogues, e.g. (Carletta et al., 1997). $$$$$ Combining categories, agreement was also very good (K = .89) for whether a move was an initiation type or a response or ready type.

Another common agreement metric is the kappa coefficient which normalises token level accuracy by chance, e.g. Carletta et al (1997). $$$$$ F

Other tagging schemes, such as the Maptask scheme (Carletta et al., 1997), are also too general for our purposes. $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
Other tagging schemes, such as the Maptask scheme (Carletta et al., 1997), are also too general for our purposes. $$$$$ This is a general problem for discourse and dialogue segmentation.

For dialog act labeling, we built models from our corpus and from the Maptask (Carletta et al, 1997). $$$$$ The purpose of this paper is to introduce and describe the reliability of a scheme of dialogue coding distinctions that have been developed for use on the Map Task Corpus (Anderson et al. 1991).
For dialog act labeling, we built models from our corpus and from the Maptask (Carletta et al, 1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).

This kind of multi-level assessment corresponds to that described and used in Carletta et al, (1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
This kind of multi-level assessment corresponds to that described and used in Carletta et al, (1997). $$$$$ F

Many such models focus on other aspects of a dialog such as coordinated activities ,i.e. turn-taking and grounding, (Traum and Hinkelman, 1992) and regular patterns in the dialog (Carletta et al, 1997) rather than the domain-specific information communicated by participants. $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
Many such models focus on other aspects of a dialog such as coordinated activities ,i.e. turn-taking and grounding, (Traum and Hinkelman, 1992) and regular patterns in the dialog (Carletta et al, 1997) rather than the domain-specific information communicated by participants. $$$$$ They are also quite often questions that serve to focus the attention of the partner on a particular part of the map or that ask for domain or task information where the speaker does not think that information can be inferred from the dialogue context.

Note that we are interested in the process of designing a domain-specific tag set from the definitions of task, subtask, and concept provided by the framework, not in the process of using an existing tag set to annotate data (see for example (Carletta et al, 1997)). $$$$$ Alexandersson et al. (1995) devise a set of 17 &quot;speech acts&quot; that occur in dialogues between people setting the date for a business meeting; some of these speech acts are task-specific.
Note that we are interested in the process of designing a domain-specific tag set from the definitions of task, subtask, and concept provided by the framework, not in the process of using an existing tag set to annotate data (see for example (Carletta et al, 1997)). $$$$$ This includes questions that ask the partner to choose one alternative from a set, as long as the set is not yes and no.

Again, according to the work of Carletta et al (1997), a minimum kappa score of 0.67 is required to draw tentative conclusions. $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
Again, according to the work of Carletta et al (1997), a minimum kappa score of 0.67 is required to draw tentative conclusions. $$$$$ Using a, a generalized version of kappa, which also works for ordinal, interval, and ratio-scaled data, he remarks that a reasonable rule of thumb for associations between two variables that both rely on subjective distinctions is to require a
Again, according to the work of Carletta et al (1997), a minimum kappa score of 0.67 is required to draw tentative conclusions. $$$$$  .8, with .67 < a < .8 allowing tentative conclusions to be drawn.

This position was taken by other computational linguists as well (Carletta et al, 1997, p. 25). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
This position was taken by other computational linguists as well (Carletta et al, 1997, p. 25). $$$$$ The move categories themselves have been incorporated into a computational model of move goals within a spoken dialogue system in order to help the system predict what move the user is making (Lewin et al. 1993).

For example, Carletta et al (1997) computed agreement on a coarse segmentation level that was constructed on the top of finer segments, by determining how well coders agreed on where the coarse segments started, and, for agreed starts, by computing how coders agreed on where coarse segments ended. $$$$$ Note that it is only possible to measure reliability of move classification over move segments where the boundaries were agreed.
For example, Carletta et al (1997) computed agreement on a coarse segmentation level that was constructed on the top of finer segments, by determining how well coders agreed on where the coarse segments started, and, for agreed starts, by computing how coders agreed on where coarse segments ended. $$$$$ Using just the games for which all four coders agreed on the beginning, the coders reached 65% pairwise percent agreement on where the game ended.

Redo our experiments on other corpora, such as Map Task (Carletta et al., 1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
Redo our experiments on other corpora, such as Map Task (Carletta et al., 1997). $$$$$ In the Map Task, these questions are most often about what the partner has on the map.

The monologue side has been annotated with discourse relations, using an adaptation of the annotation guidelines of Carlson and Marcu (2001), whereas the dialogue side has been marked up with dialogue acts, using tags inspired by the schemes of Bunt (2000), Carletta et al. (1997) and Core and Allen (1997). $$$$$ All levels of the dialogue coding are described in detail in Carletta et al. (1996).
The monologue side has been annotated with discourse relations, using an adaptation of the annotation guidelines of Carlson and Marcu (2001), whereas the dialogue side has been marked up with dialogue acts, using tags inspired by the schemes of Bunt (2000), Carletta et al. (1997) and Core and Allen (1997). $$$$$ This is a general problem for discourse and dialogue segmentation.
