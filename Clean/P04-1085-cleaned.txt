Galley et al (2004) describe a system that identifies agreement and disagreement occurring in human-to-human multi-party conversations. $$$$$ The ICSI Meeting corpus (Janin et al., 2003) is a collection of 75 meetings collected at the International Computer Science Institute (ICSI), one among the growing number of corpora of humanto-human multi-party conversations.
Galley et al (2004) describe a system that identifies agreement and disagreement occurring in human-to-human multi-party conversations. $$$$$ This definition will help our multi-party analyses of agreement and disagreement behaviors.

An adjacent pair is said to consist of two parts that are ordered, adjacent, and produced by different speakers (Galley et al, 2004). $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).
An adjacent pair is said to consist of two parts that are ordered, adjacent, and produced by different speakers (Galley et al, 2004). $$$$$ An adjacency pair is said to consist of two parts (later referred to as A and B) that are ordered, adjacent, and produced by different speakers.

Using them, Galley et al (2004) report an 8% increase in speaker identification. $$$$$ Our approach achieves 86.9% accuracy, a 4.9% increase over previous work.
Using them, Galley et al (2004) report an 8% increase in speaker identification. $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).

Galley et al 2004 show the value of using durational and structural features for identifying agreement and disagreement in spoken conversational speech. $$$$$ Identifying Agreement And Disagreement In Conversational Speech

More sophisticated approaches have been proposed (Hillard et al, 2003), including an extension that, in an interesting reversal of our problem, makes use of sentiment polarity indicators within speech segments (Galley et al, 2004). $$$$$ Our accuracy for classifying agreements and disagreements is 86.9%, which is a 4.9% improvement over (Hillard et al., 2003).
More sophisticated approaches have been proposed (Hillard et al, 2003), including an extension that, in an interesting reversal of our problem, makes use of sentiment polarity indicators within speech segments (Galley et al, 2004). $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).

Classifying agree/disagree opinions in conversational debates using Bayesian networks was presented in (Galley et al, 2004). $$$$$ Identifying Agreement And Disagreement In Conversational Speech

Other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration, F0, speech rate) (Hillard et al, 2003) and structural information (e.g., the previous and following speaker) (Galley et al, 2004). $$$$$ Many of the local features described in this subsection are similar in spirit to the ones used in the previous work of (Hillard et al., 2003).
Other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration, F0, speech rate) (Hillard et al, 2003) and structural information (e.g., the previous and following speaker) (Galley et al, 2004). $$$$$ Second, the table corroborates the findings of (Hillard et al., 2003) that lexical information make the most helpful local features.

This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al, 2004), and of the level of involvement of conversational participants (Gatica-Perez et al, 2005). $$$$$ Previous work in automatic identification of agreement/disagreement (Hillard et al., 2003) demonstrates that this is a feasible task when various textual, durational, and acoustic features are available.
This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al, 2004), and of the level of involvement of conversational participants (Gatica-Perez et al, 2005). $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).

 $$$$$ We define the problem of AP identification as follows

 $$$$$ We define the problem of AP identification as follows

The contrast classifier is also competitive with the best case result in (Galley et al, 2004) (last entry), which adds speaker change, segment duration, and adjacency pair sequence dependency features using a dynamic Bayesian network. $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).
The contrast classifier is also competitive with the best case result in (Galley et al, 2004) (last entry), which adds speaker change, segment duration, and adjacency pair sequence dependency features using a dynamic Bayesian network. $$$$$ Table 7 summarizes the performance of our classifier with the different feature sets in this classification task, distinguishing the case where the four label-dependency pragmatic features are available during decoding from the case where they are not.

The experiments here kept the feature set fixed, but results of (Galley et al, 2004) suggest that further gains can be achieved by augmenting the feature set. $$$$$ In the first set of experiments, we reproduced the experimental setting of (Hillard et al., 2003), a three-way classification (BACKCHANNEL and OTHER are merged) using hand-labeled data of a single meeting as a test set and the remaining data as training material; for this experiment, we used the same training set as (Hillard et al., 2003).
The experiments here kept the feature set fixed, but results of (Galley et al, 2004) suggest that further gains can be achieved by augmenting the feature set. $$$$$ First, the analysis of our results shows that with our three local feature sets only, we obtain substantially better results than (Hillard et al., 2003).

Galley et al (2004) proposed the use of Bayesian networks to model pragmatic dependencies of previous agreement or disagreement on the current utterance. $$$$$ Identifying Agreement And Disagreement In Conversational Speech

It is to be expected that the a-part provides a useful cue for identification of addressee of the b-part (Galley et al, 2004). $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).
It is to be expected that the a-part provides a useful cue for identification of addressee of the b-part (Galley et al, 2004). $$$$$ Contextual information about agreements and disagreements can also provide useful cues regarding who is the addressee of a given utterance.

Identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (Galley et al, 2004), addressee detection (op den Akker and Traum, 2009), and real-world applications, such as customer service conversations (Kim et al, 2010). $$$$$ Previous work in automatic identification of agreement/disagreement (Hillard et al., 2003) demonstrates that this is a feasible task when various textual, durational, and acoustic features are available.
Identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (Galley et al, 2004), addressee detection (op den Akker and Traum, 2009), and real-world applications, such as customer service conversations (Kim et al, 2010). $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).

To find these pairs automatically, we trained a non-sequential log-linear model that achieves a .902 accuracy (Galley et al, 2004). $$$$$ The annotation of the corpus with adjacency pairs is described in (Shriberg et al., 2004; Dhillon et al., 2004).
To find these pairs automatically, we trained a non-sequential log-linear model that achieves a .902 accuracy (Galley et al, 2004). $$$$$ Since tag sequences are known during training, the inference of a model for sequence labels is no more difficult than inferring a model in a non-sequential case.

 $$$$$ We define the problem of AP identification as follows
