A word link extension algorithm similar to the one presented in this paper is given in (Koehn et al, 2003). $$$$$ Phrase translation clearly helps, as we will also show with the experiments in this paper.
A word link extension algorithm similar to the one presented in this paper is given in (Koehn et al, 2003). $$$$$ The extraction heuristic is similar to the one used in the alignment template work by Och et al. [1999].

Following phrase-based methods in statistical machine translation (Koehn et al., 2003). $$$$$ Statistical Phrase-Based Translation
Following phrase-based methods in statistical machine translation (Koehn et al., 2003). $$$$$ Och et al. [1999]’s alignment template model can be reframed as a phrase translation system; Yamada and Knight [2001] use phrase translation in a syntaxbased translation system; Marcu and Wong [2002] introduced a joint-probability model for phrase translation; and the CMU and IBM word-based statistical machine translation systems' are augmented with phrase translation capability.

Modern phrasal SMT systems such as (Koehn et al., 2003) derive much of their power from being able to memorize and use long phrases. $$$$$ Learning only syntactically motivated phrases degrades the performance of our systems.
Modern phrasal SMT systems such as (Koehn et al., 2003) derive much of their power from being able to memorize and use long phrases. $$$$$ How long do phrases have to be to achieve high performance?

We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al, 2003), and our tree let system. $$$$$ First, we compared the performance of the three methods for phrase extraction head-on, using the same decoder (Section 2) and the same trigram language model.
We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al, 2003), and our tree let system. $$$$$ We also included in the figure the performance of an IBM Model 4 wordbased translation system (M4), which uses a greedy decoder [Germann et al., 2001].


All conditions use word alignments produced by sequential iterations of IBM model 1, HMM, and IBM model 4 in GIZA++ , followed by 'diag-and' symmetrization (Koehn et al., 2003). $$$$$ As the first method, we learn phrase alignments from a corpus that has been word-aligned by a training toolkit for a word-based translation model

We obtained word alignments of training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule "grow-diag-final-and" (Koehn et al., 2003). $$$$$ As the first method, we learn phrase alignments from a corpus that has been word-aligned by a training toolkit for a word-based translation model

Koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. $$$$$ Allowing for longer phrases increases the phrase translation table size (see Table 2).
Koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. $$$$$ It matters how phrases are extracted.

we achieved results similar to Koehn et al (2003a). $$$$$ Our experiments show that high levels of performance can be achieved with fairly simple means.
we achieved results similar to Koehn et al (2003a). $$$$$ The extraction heuristic is similar to the one used in the alignment template work by Och et al. [1999].

Recent work in SMT has shown that simple phrase-based MT systems can outperform more sophisticated word-based systems (e.g. Koehn et al. 2003). $$$$$ Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models.
Recent work in SMT has shown that simple phrase-based MT systems can outperform more sophisticated word-based systems (e.g. Koehn et al. 2003). $$$$$ All systems improve with more data.

We apply STIR as a pre-ordering step in a state of-the-art phrase-based translation system from English to Japanese (Koehn et al, 2003). $$$$$ Statistical Phrase-Based Translation
We apply STIR as a pre-ordering step in a state of-the-art phrase-based translation system from English to Japanese (Koehn et al, 2003). $$$$$ Och et al. [1999]’s alignment template model can be reframed as a phrase translation system; Yamada and Knight [2001] use phrase translation in a syntaxbased translation system; Marcu and Wong [2002] introduced a joint-probability model for phrase translation; and the CMU and IBM word-based statistical machine translation systems' are augmented with phrase translation capability.

This paper proposes a method for building a bilingual lexicon through a pivot language by using phrase-based statistical machine translation (SMT) (Koehn et al, 2003). $$$$$ Statistical Phrase-Based Translation
This paper proposes a method for building a bilingual lexicon through a pivot language by using phrase-based statistical machine translation (SMT) (Koehn et al, 2003). $$$$$ Och et al. [1999]’s alignment template model can be reframed as a phrase translation system; Yamada and Knight [2001] use phrase translation in a syntaxbased translation system; Marcu and Wong [2002] introduced a joint-probability model for phrase translation; and the CMU and IBM word-based statistical machine translation systems' are augmented with phrase translation capability.

This system is based on phrase-based statistical machine transliteration (SMT) (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al, 2003), where the SMT system's log-linear model is augmented with a set of features specifically suited to the task of transliteration. $$$$$ Statistical Phrase-Based Translation
This system is based on phrase-based statistical machine transliteration (SMT) (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al, 2003), where the SMT system's log-linear model is augmented with a set of features specifically suited to the task of transliteration. $$$$$ Och et al. [1999]’s alignment template model can be reframed as a phrase translation system; Yamada and Knight [2001] use phrase translation in a syntaxbased translation system; Marcu and Wong [2002] introduced a joint-probability model for phrase translation; and the CMU and IBM word-based statistical machine translation systems' are augmented with phrase translation capability.

In addition to the most popular techniques such as Phrase-Based Machine Transliteration (Koehnet al, 2003), CRF, re-ranking, DirecTL-pde coder, Non-Parametric Bayesian Co-segmentation (Finch et al, 2011), and Multi-to-Multi Joint Source Channel Model (Chen et al, 2011) in the News 2011, we are delighted to see that several new techniques have been proposed and explored with promising results reported, including RNN-based LM (Finch et al, 2012), English Segmentation algorithm (Zhang et al, 2012), JLIS reranking method (Wu et al, 2012) ,improved m2m-aligner (Okuno, 2012), multiple reference optimized CRF (Ammar et al, 2012), language dependent adaptation (Kondrak et al, 2012) and two-stage CRF (Kuo et al, 2012). $$$$$ We recombine search hypotheses as done by Och et al. [2001].
In addition to the most popular techniques such as Phrase-Based Machine Transliteration (Koehnet al, 2003), CRF, re-ranking, DirecTL-pde coder, Non-Parametric Bayesian Co-segmentation (Finch et al, 2011), and Multi-to-Multi Joint Source Channel Model (Chen et al, 2011) in the News 2011, we are delighted to see that several new techniques have been proposed and explored with promising results reported, including RNN-based LM (Finch et al, 2012), English Segmentation algorithm (Zhang et al, 2012), JLIS reranking method (Wu et al, 2012) ,improved m2m-aligner (Okuno, 2012), multiple reference optimized CRF (Ammar et al, 2012), language dependent adaptation (Kondrak et al, 2012) and two-stage CRF (Kuo et al, 2012). $$$$$ For more information on these models, please refer to Brown et al. [1993].

 $$$$$ With our decoder, translating 1755 sentence of length 5-15 words takes about 10 minutes on a 2 GHz Linux system.
 $$$$$ The results suggest that choosing the right alignment heuristic is more important than which model is used to create the initial word alignments.

Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al, 2003). $$$$$ Note that this approach is consistent with the approach taken by Marcu and Wong themselves, who use conditional models during decoding.
Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al, 2003). $$$$$ We remedy this problem with a heuristic approach.

Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al, 2003). $$$$$ Again, we use the heuristics from the Section 4.5 to reconcile the mono-directional alignments obtained through training parameters using models of increasing complexity.
Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al, 2003). $$$$$ Using different expansion heuristics during symmetrizing the word alignments has a bigger effect.

The translation quality of statistical phrase-based systems (Koehn et al, 2003) is heavily dependent on the quality of the translation and reordering models generated during the phrase extraction algorithm (Ling et al, 2010). $$$$$ Statistical Phrase-Based Translation
The translation quality of statistical phrase-based systems (Koehn et al, 2003) is heavily dependent on the quality of the translation and reordering models generated during the phrase extraction algorithm (Ling et al, 2010). $$$$$ Various researchers have improved the quality of statistical machine translation system with the use of phrase translation.

As for the SMT system, we use a standard log-linear PB-SMT model (Och and Ney, 2002) $$$$$ Och et al. [1999]’s alignment template model can be reframed as a phrase translation system; Yamada and Knight [2001] use phrase translation in a syntaxbased translation system; Marcu and Wong [2002] introduced a joint-probability model for phrase translation; and the CMU and IBM word-based statistical machine translation systems' are augmented with phrase translation capability.
As for the SMT system, we use a standard log-linear PB-SMT model (Och and Ney, 2002) $$$$$ As the first method, we learn phrase alignments from a corpus that has been word-aligned by a training toolkit for a word-based translation model

 $$$$$ With our decoder, translating 1755 sentence of length 5-15 words takes about 10 minutes on a 2 GHz Linux system.
 $$$$$ The results suggest that choosing the right alignment heuristic is more important than which model is used to create the initial word alignments.
