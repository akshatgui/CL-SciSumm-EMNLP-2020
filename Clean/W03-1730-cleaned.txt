(Note that the top participant of CTBc (Zhang et al, 2003) used additional named entity knowledge/data in their word segmenter). $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.
(Note that the top participant of CTBc (Zhang et al, 2003) used additional named entity knowledge/data in their word segmenter). $$$$$ Except for some named entity corpus, we could not get any more sources related to CTB standard.

ICTCLAS Segmenter $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.
ICTCLAS Segmenter $$$$$ According to named entities in the given corpus, we could train both class-based segmentation HMM and rolebased HMM model for unknown word recognition.

ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. $$$$$ ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.
ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. $$$$$ Before the bakeoff, BIG5-coded word segmentation has never been researched in our institute.

Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al, 2003) to extract named entities, noun phrases and events. $$$$$ HHMM-Based Chinese Lexical Analyzer ICTCLAS
Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al, 2003) to extract named entities, noun phrases and events. $$$$$ According to named entities in the given corpus, we could train both class-based segmentation HMM and rolebased HMM model for unknown word recognition.

HMMsegmenter (Zhang et al, 2003) that uses the specifications of PKU. $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.
HMMsegmenter (Zhang et al, 2003) that uses the specifications of PKU. $$$$$ Actually, PKU standard is very different from CTB one though they seemed similar.

Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al,2003). $$$$$ HHMM-Based Chinese Lexical Analyzer ICTCLAS
Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al,2003). $$$$$ 2 HHMM-based Chinese lexical analysis

Its segmentation model is a 3The query set and relevance judgements are available at http $$$$$ According to named entities in the given corpus, we could train both class-based segmentation HMM and rolebased HMM model for unknown word recognition.
Its segmentation model is a 3The query set and relevance judgements are available at http $$$$$ As is shown in Table 1, It could also be concluded that class-based segmentation HMM is effective.

Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine. $$$$$ In this HMM, the original symbol is observation while the atom is state.
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine. $$$$$ As is shown in Table 1, It could also be concluded that class-based segmentation HMM is effective.

Decrease in H (XjX n) for Chinese characters when n is increased software such as (Zhang et al, 2003) whose performance is also high. $$$$$ Evaluation on ICTCLAS shows that its performance is competitive.
Decrease in H (XjX n) for Chinese characters when n is increased software such as (Zhang et al, 2003) whose performance is also high. $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.

Hence the need for automatic word segmentation systems (Zhang et al, 2003). $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.
Hence the need for automatic word segmentation systems (Zhang et al, 2003). $$$$$ Then, the Compared with other systems, ICTCLAS especially GB-coded version is competitive.

Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004). $$$$$ In this HMM, the original symbol is observation while the atom is state.
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004). $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.

Then for every path of the N+1paths4 (N best paths and the atom path), we perform a process of Roles Tagging with HMM model (Zhang et al 2003). $$$$$ Any word is made up of an atom or more.
Then for every path of the N+1paths4 (N best paths and the atom path), we perform a process of Roles Tagging with HMM model (Zhang et al 2003). $$$$$ POS tagging and role tagging using Viterbi are also skipped because they are classic application of HMM.

The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al, 2003). $$$$$ Through the first bakeoff, we could learn more about the development in Chinese word segmentation and become more confident on our HHMM-based approach.
The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al, 2003). $$$$$ Through the first bakeoff, we have learn more about the development in Chinese word segmentation and become more confident on our HHMMbased approach.

Both ICTCLAS and Stanford segmenters utilise machine learning techniques, with Hidden Markov Models for ICT (Zhang et al, 2003) and conditional random fields for the Stanford segmenter (Tseng et al, 2005). $$$$$ ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.
Both ICTCLAS and Stanford segmenters utilise machine learning techniques, with Hidden Markov Models for ICT (Zhang et al, 2003) and conditional random fields for the Stanford segmenter (Tseng et al, 2005). $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.

In this work, we resort to ICTCLAS (Zhang et al, 2003), a widely used tool in the literature. $$$$$ HHMM-Based Chinese Lexical Analyzer ICTCLAS
In this work, we resort to ICTCLAS (Zhang et al, 2003), a widely used tool in the literature. $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.

The posts were then part-of speech tagged using a Chinese word segmentation tool named ICTCLAS (Zhang et al, 2003). $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.
The posts were then part-of speech tagged using a Chinese word segmentation tool named ICTCLAS (Zhang et al, 2003). $$$$$ Hence the best choice W# of word segmentation is easy to find using Djikstra's algorithm.

Their system only does IWR, using the CWS and POS tagging output of the ICTCLAS segmenter (Zhang et al, 2003) as in put. $$$$$ POS tagging and role tagging using Viterbi are also skipped because they are classic application of HMM.
Their system only does IWR, using the CWS and POS tagging output of the ICTCLAS segmenter (Zhang et al, 2003) as in put. $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.

 $$$$$ Atom segmentation, the bottom level of HHMM, is an initial step.
 $$$$$ We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.

ICTCLAS is developed by Chinese Academy of Science, the precision of which is 97.58% on tagging general words (Huaping Zhang et al, 2003). $$$$$ ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.
ICTCLAS is developed by Chinese Academy of Science, the precision of which is 97.58% on tagging general words (Huaping Zhang et al, 2003). $$$$$ Excepted for CTB, IV Recall is over 97%.

The Chinese word segmentation tool is ICTCLAS (Zhang et al 2003) and Google Translator is the MT for the source language. $$$$$ Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.
The Chinese word segmentation tool is ICTCLAS (Zhang et al 2003) and Google Translator is the MT for the source language. $$$$$ After transformation through class-based HMM, word segmentation becomes single-source shortest paths problem.
