Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ (Zhang et al., 2002).

However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ (Zhang et al., 2002).
However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ Hence, we used the output of these pre-existing taggers and used them as additional feature streams for the mention detection models.

We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ (Zhang et al., 2002).
We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ Good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (Zhang et al., 2002; Jing et al., 2003; Ittycheriah et al., 2003).

In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ We selected two methods which satisfy these criteria: a linear classifier – the Robust Risk Minimization classifier – and a log-linear classifier – the Maximum Entropy classifier.
In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ As it is the case with with mention detection approach presented in Section 2, most features used here are language-independent and are instantiated from the training data, while some are language-specific, but mostly because the resources were not available for the specific language.

In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ (Zhang et al., 2002).
In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ As described in Section 2.6, the mention detection systems make use of a large set of features.

In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ For instance, a pre-existing tagger may identify dates or occupation mentions (not used in ACE), among other types.
In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ As described in Section 2.6, the mention detection systems make use of a large set of features.

Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ (Zhang et al., 2002).
Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ Both methods can integrate arbitrary types of information and make a classification decision by aggregating all information available for a given classification.

This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ Good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (Zhang et al., 2002; Jing et al., 2003; Ittycheriah et al., 2003).

Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ This approach allows the system to automatically correlate the (different) mention types to the desired output.
Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ As described in Section 2.6, the mention detection systems make use of a large set of features.

In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ In addition, the mention detection model crucially uses feature streams derived from different named entity classifiers.
In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ The English mention detection model is similar to the system described in (Ittycheriah et al., 2003)7.The following is a list of additional features (again, is the current token): Shallow parsing information associated with the tokens in window of 3; Prefixes/suffixes of length up to 4; A capitalization/word-type flag (similar to the ones described by Bikel et al. (1997)); Gazetteer information: a handful of location (55k entries) person names (30k) and organizations (5k) dictionaries; A combination of gazetteer, POS and capitalization information, obtained as follows: if the word is a closed-class word — select its class, else if it’s in a dictionary — select that class, otherwise back-off to its capitalization information; we call this feature gap; WordNet information (the synsets and hypernyms of the two most frequent senses of the word); The outputs of three systems (HMM, RRM and MaxEnt) trained on a 32-category named entity data, the output of an RRM system trained on the MUC-6 data, and the output of RRM model identifying 49 categories.

The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ (Zhang et al., 2002).
The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ Good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (Zhang et al., 2002; Jing et al., 2003; Ittycheriah et al., 2003).

Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004). $$$$$ Entity detection and tracking is a relatively new addition to the repertoire of natural language tasks.
Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004). $$$$$ Good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (Zhang et al., 2002; Jing et al., 2003; Ittycheriah et al., 2003).

These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ (Zhang et al., 2002).

We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ (Zhang et al., 2002).

Finally we note that while Blitzer et al (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al (2004). $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
Finally we note that while Blitzer et al (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al (2004). $$$$$ (Zhang et al., 2002).

Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ For instance, a pre-existing tagger may identify dates or occupation mentions (not used in ACE), among other types.
Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ At training time, the action is known to us, and at testing time, both hypotheses will be kept during search.

Each instance represents w i, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al (1999) and Florian et al (2004), as described below. $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
Each instance represents w i, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al (1999) and Florian et al (2004), as described below. $$$$$ (Zhang et al., 2002).

For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ Our entity tracking system currently cannot resolve the coreference of pronouns very accurately.

Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ Section 4 describes the experimental framework and the systems’ results for Arabic, Chinese and English on the data from the latest ACE evaluation (September 2003), an investigation of the effect of using different feature types, as well as a discussion of the results.
Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ Good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (Zhang et al., 2002; Jing et al., 2003; Ittycheriah et al., 2003).

These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ The Entity Detection and Tracking task (EDT henceforth) has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (Bikel et al., 1997; Borthwick et al., 1998; Mikheev et al., 1999; Miller et al., 1998; Aberdeen et al., 1995; Ng and Cardie, 2002; Soon et al., 2001), and have been at the center of several evaluations: MUC-6, MUC-7, CoNLL’02 and CoNLL’03 shared tasks.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ (Zhang et al., 2002).
