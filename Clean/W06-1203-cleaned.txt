They measure compositionality as a combination of two similarity values $$$$$ Their hypothesis is that high LSA-based similarity between the MWE and each of its constituent parts is indicative of compositionality.
They measure compositionality as a combination of two similarity values $$$$$ The resulting cosine similarity values range from 0.01 to 0.80.

Katz and Giesbrecht (2006) devise a supervised method in which they compute the meaning vectors for the literal and non literal usages of a given expression in the trainning data. $$$$$ We also compared the literal and non-literal vectors for ins Wasser fallen from the first experiment with the composed vector, computed out of the meaning vectors for Wasser and for fallen.9 The difference isn’t large, but nevertheless the composed vector is more similar to the literal vector (cosine of 0.2937) than to the non-literal vector (cosine of 0.1733).
Katz and Giesbrecht (2006) devise a supervised method in which they compute the meaning vectors for the literal and non literal usages of a given expression in the trainning data. $$$$$ A second problem concerns the relationship between the literal and the non-literal meaning.

The few token-based approaches include a study by Katz and Giesbrecht (2006), who devise a supervised method in which they compute the meaning vectors for the literal and non-literal usages of a given expression in the training data. $$$$$ We also compared the literal and non-literal vectors for ins Wasser fallen from the first experiment with the composed vector, computed out of the meaning vectors for Wasser and for fallen.9 The difference isn’t large, but nevertheless the composed vector is more similar to the literal vector (cosine of 0.2937) than to the non-literal vector (cosine of 0.1733).
The few token-based approaches include a study by Katz and Giesbrecht (2006), who devise a supervised method in which they compute the meaning vectors for the literal and non-literal usages of a given expression in the training data. $$$$$ A second problem concerns the relationship between the literal and the non-literal meaning.

The few token-based approaches include a study by Katz and Giesbrecht (2006), who devise a supervised method in which they compute the meaning vectors for the literal and non-literal us ages of a given expression in the training data. $$$$$ We also compared the literal and non-literal vectors for ins Wasser fallen from the first experiment with the composed vector, computed out of the meaning vectors for Wasser and for fallen.9 The difference isn’t large, but nevertheless the composed vector is more similar to the literal vector (cosine of 0.2937) than to the non-literal vector (cosine of 0.1733).
The few token-based approaches include a study by Katz and Giesbrecht (2006), who devise a supervised method in which they compute the meaning vectors for the literal and non-literal us ages of a given expression in the training data. $$$$$ A second problem concerns the relationship between the literal and the non-literal meaning.

Supervised classifiers have been used be fore for this task, notably by Katz and Giesbrecht (2006). $$$$$ Our next task was to investigate whether this difference could be used in particular cases to determine what the intended use of an MWE in a particular context was.
Supervised classifiers have been used be fore for this task, notably by Katz and Giesbrecht (2006). $$$$$ To summarize Experiment I, which is a variant of a supervised phrase sense disambiguation task, demonstrates that we can use LSA to distinguish between literal and the idiomatic usage of an MWE by using local linguistic context.

Note that our results are noticeably higher than those reported by Cook et al (2007), Fazly et al (To appear) and Katz and Giesbrecht (2006) for similar supervised classifiers. $$$$$ Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (Sag et al., 2002), and significant attention has been paid to practical methods for solving this problem in recent years (Lin, 1999; Baldwin et al., 2003; Villada Moir´on and Tiedemann, 2006).
Note that our results are noticeably higher than those reported by Cook et al (2007), Fazly et al (To appear) and Katz and Giesbrecht (2006) for similar supervised classifiers. $$$$$ There is some evidence (Baldwin et al., 2003) that part of speech tagging might improve results in this kind of task.

Katz and Giesbrecht (2006) used a supervised learning method to distinguish between compositional and non-compositional uses of an expression (in German text) by using contextual information in the form of Latent Semantic Analy sis (LSA) vectors. $$$$$ Automatic Identification Of Non-Compositional Multi-Word Expressions Using Latent Semantic Analysis
Katz and Giesbrecht (2006) used a supervised learning method to distinguish between compositional and non-compositional uses of an expression (in German text) by using contextual information in the form of Latent Semantic Analy sis (LSA) vectors. $$$$$ If the meanings are similar, it is likely that local context will be inadequate to distinguish a compositional from a non-compositional use of the expression.

There are several studies relevant to detecting compositionality of noun-noun, verb-particle and light verb constructions and verb noun pairs (e.g. Katz and Giesbrecht (2006)). $$$$$ Baldwin et al., (2003) focus more narrowly on distinguishing English noun-noun compounds and verb-particle constructions which are compositional from those which are not compositional.
There are several studies relevant to detecting compositionality of noun-noun, verb-particle and light verb constructions and verb noun pairs (e.g. Katz and Giesbrecht (2006)). $$$$$ In his comparison among a number of different heuristics for identifying non-compositional noun-noun compounds, Zhai did his evaluation by applying each heuristic to a corpus of items hand-classified as to their compositionality.

Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. $$$$$ In the first experiment we seek to confirm that the local context of a known idiom can reliably distinguish idiomatic uses from non-idiomatic uses.
Katz and Giesbrecht (2006) compared the word vector of an idiom in context and that of the constituent words of the idiom using LSA in order to determine if the expression is idiomatic. $$$$$ We calculated the estimated compositional meaning vector by taking it to be the sum of the meaning vector of the parts, i.e., the compositional meaning of an expression w1w2 consisting of two words is taken to be sum of the meaning vectors for the constituent words.6 In order to maximize the independent contribution of the constituent words, the meaning vectors for these words were always computed from contexts in which they appear alone (that is, not in the local context of the other constituent).

The performance of the supervised one is obtained by the method of Katz and Giesbrecht (2006). $$$$$ His method was to compare the mutual information measure of the constituents parts of an MWE with the mutual information of similar expressions obtained by substituting one of the constituents with a related word obtained by thesaurus lookup.
The performance of the supervised one is obtained by the method of Katz and Giesbrecht (2006). $$$$$ This kind of dimensionality reduction has been shown to improve performance in a number of text-based domains (Berry et al., 1999).

Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ Automatic Identification Of Non-Compositional Multi-Word Expressions Using Latent Semantic Analysis
Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ In our experiments we make use of lexical semantic analysis (LSA) as a model of contextsimilarity (Deerwester et al., 1990).

For example, the method used in (Katz and Giesbrecht, 2006) relies primarily on local co-occurrence lexicon to construct feature vectors for each target token. $$$$$ This can be illustrated by considering, for example, the MWE fire breathing.
For example, the method used in (Katz and Giesbrecht, 2006) relies primarily on local co-occurrence lexicon to construct feature vectors for each target token. $$$$$ Our technique relies on these meaning being highly distinct.

Among the earliest studies on token-based classification were the ones by Hashimoto et al (2006) on Japanese and Katz and Giesbrecht (2006) on German. $$$$$ Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (Sag et al., 2002), and significant attention has been paid to practical methods for solving this problem in recent years (Lin, 1999; Baldwin et al., 2003; Villada Moir´on and Tiedemann, 2006).
Among the earliest studies on token-based classification were the ones by Hashimoto et al (2006) on Japanese and Katz and Giesbrecht (2006) on German. $$$$$ This kind of dimensionality reduction has been shown to improve performance in a number of text-based domains (Berry et al., 1999).

Katz and Giesbrecht (2006) compute meaning vectors for literal and non-literal examples in the training set and then classify test instances based on the closeness of their meaning vectors to those of the training examples. $$$$$ To evaluate this, we did a 10-fold cross-validation study, calculating the literal and idiomatic vectors for ins Wasser fallen on the basis of the training data and doing a simple nearest neighbor classification of each memember of the test set on the basis of the meaning vectors computed from its local context (the 30 word window).
Katz and Giesbrecht (2006) compute meaning vectors for literal and non-literal examples in the training set and then classify test instances based on the closeness of their meaning vectors to those of the training examples. $$$$$ We also compared the literal and non-literal vectors for ins Wasser fallen from the first experiment with the composed vector, computed out of the meaning vectors for Wasser and for fallen.9 The difference isn’t large, but nevertheless the composed vector is more similar to the literal vector (cosine of 0.2937) than to the non-literal vector (cosine of 0.1733).

Such techniques either do not use any information regarding the linguistic properties of MWEs (Birkeand Sarkar, 2006), or mainly focus on their non compositionality (Katz and Giesbrecht, 2006). $$$$$ Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutualinformation measures identify such phrases, Baldwin et al. (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moir´on & Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts.
Such techniques either do not use any information regarding the linguistic properties of MWEs (Birkeand Sarkar, 2006), or mainly focus on their non compositionality (Katz and Giesbrecht, 2006). $$$$$ Schone & Jurafsky (2001) applied LSA to MWE identification, althought they did not focus on distinguishing compositional from non-compositional MWEs.

In supervised approaches, such as that of Katz and Giesbrecht (2006), co-occurrence vectors for literal and idiomatic meanings are formed from manually annotated training data. $$$$$ To evaluate this, we did a 10-fold cross-validation study, calculating the literal and idiomatic vectors for ins Wasser fallen on the basis of the training data and doing a simple nearest neighbor classification of each memember of the test set on the basis of the meaning vectors computed from its local context (the 30 word window).
In supervised approaches, such as that of Katz and Giesbrecht (2006), co-occurrence vectors for literal and idiomatic meanings are formed from manually annotated training data. $$$$$ Indeed of the MWEs with a similarity values of under 0.1, just over half are MWEs which were hand-annotated to have non-literal uses.10 It used in their idiomatic sense (apparently for humorous effect) particularly frequently in contexts in which elements of the literal meaning were also present.11 is clear then that the technique described is, prima facie, capable of detecting idiomatic MWEs.

However, this approach follows that of Katz and Giesbrecht (2006) in assuming that literal meanings are compositional. $$$$$ To accomplish this task we took the following approach.
However, this approach follows that of Katz and Giesbrecht (2006) in assuming that literal meanings are compositional. $$$$$ If the meanings are similar, it is likely that local context will be inadequate to distinguish a compositional from a non-compositional use of the expression.

We also compare our unsupervised methods against the supervised method proposed by Katz and Giesbrecht (2006). $$$$$ To compare our method with that proposed by Baldwin et al. (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to the MWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE.
We also compare our unsupervised methods against the supervised method proposed by Katz and Giesbrecht (2006). $$$$$ There are a number of issues that complicate the workability of the unsupervised technique described here.

Our results using 1NN, 72 $$$$$ Even in the case of the nouns, however, the results are, for the most part, markedly inferior to the results we achieved using the composed vectors.
Our results using 1NN, 72 $$$$$ Rather promising results were attained using only local context, however.

L-NCF depends highly on the accuracy of the automatically acquired canonical forms, it is not surprising that these two methods perform 5This was also noted by Katz and Giesbrecht (2006) in their second experiment. $$$$$ As noted by Sag et al. (2002) many MWEs are simply “institutionalized phrases” whose meanings are perfectly compositional, but whose frequency of use (or other non-linguistic factors) make them highly salient.
L-NCF depends highly on the accuracy of the automatically acquired canonical forms, it is not surprising that these two methods perform 5This was also noted by Katz and Giesbrecht (2006) in their second experiment. $$$$$ Our technique relies on these meaning being highly distinct.
