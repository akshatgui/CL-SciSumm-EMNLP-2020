Another similar work is that of (Xu et al, 2009). They created a pre-ordering rule set for dependency parsers from English to several SOV languages. $$$$$ These children have some relative ordering that is typically fixed for SOV languages.
Another similar work is that of (Xu et al, 2009). They created a pre-ordering rule set for dependency parsers from English to several SOV languages. $$$$$ They also focus on either Chinese to English (Zhang et.al., 2007; Li et.al., 2007) or English to Danish (Elming, 2008), which arguably have less long distance reordering than between English and SOV languages.

It is true that tree-based reordering cannot cover all word movement operations in language translation, previous work showed that this method is still very effective in practice (Xu et al., 2009, Visweswariah et al, 2010). $$$$$ It has been shown that direct modeling of target language constituents movement in either constituency trees (Yamada and Knight, 2001; Galley et.al., 2006; Zollmann et.al., 2008) or dependency trees (Quirk, et.al., 2005) can result in significant improvements in translation quality for translating languages like Chinese and Arabic into English.
It is true that tree-based reordering cannot cover all word movement operations in language translation, previous work showed that this method is still very effective in practice (Xu et al., 2009, Visweswariah et al, 2010). $$$$$ Syntactical analysis of source language can be used to deterministically reorder input sentences (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007), or to provide multiple orderings as weighted options (Zhang et.al., 2007; Li et.al., 2007; Elming, 2008).

In addition, a pre-reorder system using manual rules as (Xu et al, 2009) is included for the English to-Japanese experiment (ManR-PR). $$$$$ PR is our proposed approach in this paper.
In addition, a pre-reorder system using manual rules as (Xu et al, 2009) is included for the English to-Japanese experiment (ManR-PR). $$$$$ To see this, we carried out a controlled experiment, using Korean as an example.

Xu et al (2009) designed a clever precedence reordering rule set for translation from English to several SOV languages. $$$$$ They also focus on either Chinese to English (Zhang et.al., 2007; Li et.al., 2007) or English to Danish (Elming, 2008), which arguably have less long distance reordering than between English and SOV languages.
Xu et al (2009) designed a clever precedence reordering rule set for translation from English to several SOV languages. $$$$$ One of our motivations of using the precedence reordering rules is that English will look like SOV languages in word order after reordering.

Recently, Xu et al (2009) and Hong et al (2009) proposed rule-based preprocessing methods for SOV languages. $$$$$ Studies most similar to ours are those preprocessing reordering approaches (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007).
Recently, Xu et al (2009) and Hong et al (2009) proposed rule-based preprocessing methods for SOV languages. $$$$$ They all perform reordering during preprocessing based on either automatically extracted syntactic rules (Xia and McCord, 2004; Habash, 2007) or manually written rules (Collins et.al., 2005; Wang et.al., 2007).

Hong et al (2009) used Stanford parser (de Marneffe et al, 2006), which outputs semantic head based dependencies; Xu et al (2009) also used the same representation. $$$$$ It has been shown that direct modeling of target language constituents movement in either constituency trees (Yamada and Knight, 2001; Galley et.al., 2006; Zollmann et.al., 2008) or dependency trees (Quirk, et.al., 2005) can result in significant improvements in translation quality for translating languages like Chinese and Arabic into English.
Hong et al (2009) used Stanford parser (de Marneffe et al, 2006), which outputs semantic head based dependencies; Xu et al (2009) also used the same representation. $$$$$ Syntactical analysis of source language can be used to deterministically reorder input sentences (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007), or to provide multiple orderings as weighted options (Zhang et.al., 2007; Li et.al., 2007; Elming, 2008).

Xu et al (2009) used a semantic head-based dependency parser for a similar purpose. $$$$$ Studies most similar to ours are those preprocessing reordering approaches (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007).
Xu et al (2009) used a semantic head-based dependency parser for a similar purpose. $$$$$ In this paper, we present a novel precedence reordering approach based on a dependency parser.

Reversing the children order (Xu et al, 2009) reconnects is and popular. $$$$$ The type of order is only used when we have multiple children with the same weight, while the weight is used to determine the relative order of the children, going from largest to smallest.
Reversing the children order (Xu et al, 2009) reconnects is and popular. $$$$$ The order type NORMAL means we preserve the original order of the children, while REVERSE means we flip the order.

We obtained four more sets of alignments from the Berkeley aligner (BA) (Liang et al, 2006), the HMM aligner (HA) (Vogel et al, 1996), the alignment based on partial words (PA), and alignment based on dependency based reordering (DA) (Xu et al,2009). $$$$$ Along this line of research, discriminative reordering models based on a maximum entropy classifier (Zens and Ney, 2006; Xiong, et.al., 2006) also showed improvements over the distance based distortion model.
We obtained four more sets of alignments from the Berkeley aligner (BA) (Liang et al, 2006), the HMM aligner (HA) (Vogel et al, 1996), the alignment based on partial words (PA), and alignment based on dependency based reordering (DA) (Xu et al,2009). $$$$$ Syntactical analysis of source language can be used to deterministically reorder input sentences (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007), or to provide multiple orderings as weighted options (Zhang et.al., 2007; Li et.al., 2007; Elming, 2008).

(Xu et al, 2009) showed that translation between subject-verb-object (English) and subject-object-verb (Pashto) languages can be improved by reordering the source side of the parallel data. $$$$$ Using a Dependency Parser to Improve SMT for Subject-Object-Verb Languages
(Xu et al, 2009) showed that translation between subject-verb-object (English) and subject-object-verb (Pashto) languages can be improved by reordering the source side of the parallel data. $$$$$ However, when phrase-based systems are used between languages with very different word orders, such as between subject-verb-object (SVO) and subject-object-verb (SOV) languages, long distance reordering becomes one of the key weaknesses.

Using the rules and algorithm described in (Xu et al, 2009) we reordered all of the source side and used GIZA++ to align the sentences. $$$$$ Syntactical analysis of source language can be used to deterministically reorder input sentences (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007), or to provide multiple orderings as weighted options (Zhang et.al., 2007; Li et.al., 2007; Elming, 2008).
Using the rules and algorithm described in (Xu et al, 2009) we reordered all of the source side and used GIZA++ to align the sentences. $$$$$ In these approaches, input source sentences are reordered based on syntactic analysis and some reordering rules at preprocessing step.

Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject-object verb language (Xu et al, 2009). $$$$$ For a set of five subject-object-verb (SOV) order languages, we show significant improvements in BLEU scores when translating from English, compared to other reordering approaches, in state-of-the-art phrase-based SMT systems.
Compared with flat phrases, syntactic rules are good at capturing global reordering, which has been reported to be essential for translating between languages with substantial structural differences, such as English and Japanese, which is a subject-object verb language (Xu et al, 2009). $$$$$ Compared to these approaches, our work has a few differences.

Xu et al (2009) utilized a dependency parser with several hand-labeled precedence rules for reordering English to subject-object-verb order like Korean and Japanese. $$$$$ Using a Dependency Parser to Improve SMT for Subject-Object-Verb Languages
Xu et al (2009) utilized a dependency parser with several hand-labeled precedence rules for reordering English to subject-object-verb order like Korean and Japanese. $$$$$ In order to implement the precedence rules, we need a dependency parser.

The work by Xu et al (2009) is the closest to our approach. $$$$$ Syntactical analysis of source language can be used to deterministically reorder input sentences (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007), or to provide multiple orderings as weighted options (Zhang et.al., 2007; Li et.al., 2007; Elming, 2008).
The work by Xu et al (2009) is the closest to our approach. $$$$$ Compared to these approaches, our work has a few differences.

Our approach is a true tree-to-string model and differs from (Xu et al, 2009), which uses trees only as an intermediate representation to rearrange the original sentences. $$$$$ Fourth, we use dependency parse trees rather than constituency trees.
Our approach is a true tree-to-string model and differs from (Xu et al, 2009), which uses trees only as an intermediate representation to rearrange the original sentences. $$$$$ Along this line of research, we think some kind of tree-to-string model (Liu et.al., 2006) could be interesting directions to pursue.

We use a superset of the reordering rules proposed by Xu et al (2009), which flatten a dependency tree into SOV word order that is suitable for all three languages. $$$$$ In order to describe this kind of ordering, we propose precedence reordering rules based on a dependency parse tree.
We use a superset of the reordering rules proposed by Xu et al (2009), which flatten a dependency tree into SOV word order that is suitable for all three languages. $$$$$ One of our motivations of using the precedence reordering rules is that English will look like SOV languages in word order after reordering.

On Web text, Xu et al (2009) report significant improvements applying one set of hand-crafted rules to translation from English to each of five SOV languages: Korean, Japanese, Hindi, Urdu and Turkish. $$$$$ Then, we show experimental results of applying this approach to phrasebased SMT systems for translating from English to five SOV languages (Korean, Japanese, Hindi, Urdu and Turkish).
On Web text, Xu et al (2009) report significant improvements applying one set of hand-crafted rules to translation from English to each of five SOV languages: Korean, Japanese, Hindi, Urdu and Turkish. $$$$$ We successfully applied this approach to systems translating English to 5 SOV languages: Korean, Japanese, Hindi, Urdu and Turkish.

Following Collins et al (2005a) and Wang (2007), Xu et al (2009) showed that when translating from English to Japanese (and to other SOV languages such as Korean and Turkish) applying reordering as a preprocessing step that manipulates a source sentence parse tree can significantly outperform state-of-the-art phrase-based and hierarchical machine translation systems. $$$$$ Studies most similar to ours are those preprocessing reordering approaches (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007).
Following Collins et al (2005a) and Wang (2007), Xu et al (2009) showed that when translating from English to Japanese (and to other SOV languages such as Korean and Turkish) applying reordering as a preprocessing step that manipulates a source sentence parse tree can significantly outperform state-of-the-art phrase-based and hierarchical machine translation systems. $$$$$ They all perform reordering during preprocessing based on either automatically extracted syntactic rules (Xia and McCord, 2004; Habash, 2007) or manually written rules (Collins et.al., 2005; Wang et.al., 2007).

During both training and testing, the system reorders source-language sentences in a preprocessing step using a set of rules written in the framework proposed by (Xu et al, 2009) that reorder an English dependency tree into target word order. $$$$$ In these approaches, input source sentences are reordered based on syntactic analysis and some reordering rules at preprocessing step.
During both training and testing, the system reorders source-language sentences in a preprocessing step using a set of rules written in the framework proposed by (Xu et al, 2009) that reorder an English dependency tree into target word order. $$$$$ In this work, a global word order model is proposed based on features including word bigram of the target sentence, displacements and POS tags on both source and target sides.

R5 Superset of rules from (Xu et al., 2009). $$$$$ Syntactical analysis of source language can be used to deterministically reorder input sentences (Xia and McCord, 2004; Collins et.al., 2005; Wang et.al., 2007; Habash, 2007), or to provide multiple orderings as weighted options (Zhang et.al., 2007; Li et.al., 2007; Elming, 2008).
R5 Superset of rules from (Xu et al., 2009). $$$$$ They all perform reordering during preprocessing based on either automatically extracted syntactic rules (Xia and McCord, 2004; Habash, 2007) or manually written rules (Collins et.al., 2005; Wang et.al., 2007).
