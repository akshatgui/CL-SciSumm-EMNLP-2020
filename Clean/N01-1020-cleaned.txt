There is work on lexicon induction using string distance or other phonetic/orthographic comparison techniques, such as Mann and Yarowsky (2001). $$$$$ Multipath Translation Lexicon Induction Via Bridge Languages
There is work on lexicon induction using string distance or other phonetic/orthographic comparison techniques, such as Mann and Yarowsky (2001). $$$$$ Learning string distance.

Moreover, while some techniques (e.g., Mann and Yarowsky (2001)) use multiple languages, the languages used have resources such as dictionaries between some language pairs. $$$$$ Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.
Moreover, while some techniques (e.g., Mann and Yarowsky (2001)) use multiple languages, the languages used have resources such as dictionaries between some language pairs. $$$$$ Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.

Mann and Yarowsky (2001) present a method for inducing translation lexicons based on trasduction modules of cognate pairs via bridge languages. $$$$$ In this paper, we explore ways of using cognate pairs to create translation lexicons.
Mann and Yarowsky (2001) present a method for inducing translation lexicons based on trasduction modules of cognate pairs via bridge languages. $$$$$ In this paper, we explore ways of using cognate pairs to create translation lexicons.

Similarly to Mann and Yarowsky (2001), we show that languages are often close enough to others within their language family so that cognate pairs between the two are common, and significant portions of the translation lexicon can be induced with high accuracy where no bilingual dictionary or parallel corpora may exist. $$$$$ Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.
Similarly to Mann and Yarowsky (2001), we show that languages are often close enough to others within their language family so that cognate pairs between the two are common, and significant portions of the translation lexicon can be induced with high accuracy where no bilingual dictionary or parallel corpora may exist. $$$$$ Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.

Mann and Yarowsky (2001) applied the stochastic transducer of Ristad and Yianilos (1998) for inducing translation lexicons between two languages, but found that in some cases it offered no improvement over Levenshtein distance. $$$$$ Machine transliter- Linguistics, E. Ristad and P. Yianilos.
Mann and Yarowsky (2001) applied the stochastic transducer of Ristad and Yianilos (1998) for inducing translation lexicons between two languages, but found that in some cases it offered no improvement over Levenshtein distance. $$$$$ Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition.

LLW stands for Levenshtein with learned weights, which is a modification of RY proposed by Mann and Yarowsky (2001). $$$$$ Also, empirical evidence suggests that the best method is achieved through learning weights with stochastic transducers and then using these weights in the L-S framework. for each word o E 0 for each bridge language B Translate o b E B Vt E T, Calculate D(b,t) Rank t by D(b,t) Score t using information from all bridges Select highest scored t Produce mapping o t Two scoring methods were investigated for the above algorithm: one based on rank and the other on distance.
LLW stands for Levenshtein with learned weights, which is a modification of RY proposed by Mann and Yarowsky (2001). $$$$$ The rank-based scoring method takes each proposed target and combines the rank of that proposal across all classifiers, and chooses the translation with the lowest resulting rank (rank 1 is the best proposed translation).

As mentioned in (Mann and Yarowsky, 2001), it appears that there are significant differences between the pronunciation task and the cognate identification task. $$$$$ This is a more difficult task than that used for direct induction (selecting between 100 and 900 potential translation candidates for each sourcelanguage word), so the system's performance is lower than the Section 3 results.
As mentioned in (Mann and Yarowsky, 2001), it appears that there are significant differences between the pronunciation task and the cognate identification task. $$$$$ Dictionaries for Russian and Ukrainian were converted into romanized pronunciation dictionaries.

Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer's probabilities into different weight classes to better approximate Edit Distance. $$$$$ within an edit-distance of 3) from the remaining word-pairs as training data.
Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer's probabilities into different weight classes to better approximate Edit Distance. $$$$$ The weights in these two systems were produced by filtering the probabilities obtained from the stochastic transducer into three weight classes: 0.5, 0.75, and 1.

For example, Mann and Yarowsky (2001) define a word pair (e, f) to be cognate if they are a translation pair (same meaning) and their Edit Distance is less than three (same form). $$$$$ within an edit-distance of 3) from the remaining word-pairs as training data.
For example, Mann and Yarowsky (2001) define a word pair (e, f) to be cognate if they are a translation pair (same meaning) and their Edit Distance is less than three (same form). $$$$$ For L-S, the cost matrix was separately trained for each language pair, and for L-A, it was trained collectively over all the Romance languages.

The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related "bridge" languages that have more resources (Mann and Yarowsky, 2001). $$$$$ Using cognates to align sentences in bilingual corpora.
The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related "bridge" languages that have more resources (Mann and Yarowsky, 2001). $$$$$ Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak).

Mann and Yarowsky (2001) investigated the induction of translation lexicons via bridge languages. $$$$$ Multipath Translation Lexicon Induction Via Bridge Languages
Mann and Yarowsky (2001) investigated the induction of translation lexicons via bridge languages. $$$$$ As a final note, Table 9 shows the cross-language translation rates for some of the investigated languages.

Mann and Yarowsky (2001) developed yet another model, which outperformed all other similarity measures. $$$$$ Various machine learning techniques, including co-training and mutual bootstrapping, could employ these additional measures in creating better estimates.
Mann and Yarowsky (2001) developed yet another model, which outperformed all other similarity measures. $$$$$ Various machine learning techniques, including co-training and mutual bootstrapping, could employ these additional measures in creating better estimates.

The HMM model of (Mann and Yarowsky, 2001) is of distinctly different design than our PHMM model. $$$$$ The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2.
The HMM model of (Mann and Yarowsky, 2001) is of distinctly different design than our PHMM model. $$$$$ While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates.

Mann and Yarowsky (2001) present a method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages. $$$$$ In this paper, we explore ways of using cognate pairs to create translation lexicons.
Mann and Yarowsky (2001) present a method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages. $$$$$ In this paper, we explore ways of using cognate pairs to create translation lexicons.

Our work is inspired by Mann and Yarowsky (2001). $$$$$ 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition.
Our work is inspired by Mann and Yarowsky (2001). $$$$$ In both cases, the great potential of this work is the ability to leverage a single bilingual dictionary into translation lexicons for its entire language family, without any additional resources beyond raw wordlists for the other languages in the family.

Mann and Yarowsky (2001) distinguish between static metrics, which are sufficiently general to be applied to any language pair, and adaptive metrics, which are adapted to a specific language pair. $$$$$ The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2.
Mann and Yarowsky (2001) distinguish between static metrics, which are sufficiently general to be applied to any language pair, and adaptive metrics, which are adapted to a specific language pair. $$$$$ For L-S, the cost matrix was separately trained for each language pair, and for L-A, it was trained collectively over all the Romance languages.

Mann and Yarowsky (2001) use variants of Levenshtein distance as a static metric, and a Hidden Markov Model (HMM) and a stochastic transducer trained with the Expectation-Maximisation (EM) algorithm as adaptive metrics. $$$$$ The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2.
Mann and Yarowsky (2001) use variants of Levenshtein distance as a static metric, and a Hidden Markov Model (HMM) and a stochastic transducer trained with the Expectation-Maximisation (EM) algorithm as adaptive metrics. $$$$$ Two adaptively trained variants, L-S and L-A, are shown in the last two lines of Table 1.

Mann and Yarowsky (2001) consider a word pair as cognate if the Levenshtein distance between the two words is less than 3. $$$$$ As can be observed from Table 1, pure Levenshtein distance (L) works surprisingly well.
Mann and Yarowsky (2001) consider a word pair as cognate if the Levenshtein distance between the two words is less than 3. $$$$$ In Table 8 &quot;Cvg&quot; or cognate coverage is the percentage words in the source language for which any of the bridge languages contains a cognate to the target translation.

This finding is consistent with the results of Mann and Yarowsky (2001), although our experiments show more clear-cut differences. $$$$$ Trends across subsets are relatively consistent.
This finding is consistent with the results of Mann and Yarowsky (2001), although our experiments show more clear-cut differences. $$$$$ Trends across subsets are relatively consistent.

Using the same models, Mann and Yarowsky (2001) induced over 90% of the Spanish-Portuguese cognate vocabulary. $$$$$ When there is a drop in accuracy on the cognate vocabulary by adding an additional bridge language there tends to be an improvement in accuracy on the full vocabulary due to significantly more cognate pathways (yielding greater coverage).
Using the same models, Mann and Yarowsky (2001) induced over 90% of the Spanish-Portuguese cognate vocabulary. $$$$$ In Table 6, we present the results obtained by applying different combination algorithms for the pathway from English to Portuguese using one of the other Romance languages (Spanish, Italian, French, and Romanian) as bridges and compare with the single best path (English-Spanish-Portuguese).
