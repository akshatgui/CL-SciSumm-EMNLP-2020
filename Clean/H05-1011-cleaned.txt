(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ In this paper, we take a different approach to word alignment, based on discriminative training of a weighted linear combination of a small number of features.
(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ Weinitially explored limiting the number of associations considered for each word type simply as an ef ficiency heuristic, but we were surprised to discover that the most extreme form of such pruning actually reduced alignment error rate over any less restrictive form or not pruning on this basis at all.

LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ We compute LLR scores using the following formula presented by Moore (2004): LLR(f, e) = ? f??{f,?f} ? e??{e,?e} C(f?, e?)
LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ Adding a link for a new pair of words can affect the nonmonotonicity scores, the one-to-many score, and the unlinked word score differently, depending on 2The conditional link probabilities used in the current work are those used in Method 4 of the earlier work.

A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ In this paper, we demonstrate a discriminative approachto training simple word alignment mod els that are comparable in accuracy tothe more complex generative models nor mally used.
A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ We iterate this pro cedure until a local optimum is found.Next, we used a fixed weight of 1.0 for the wordassociation feature, which we expect to be most im portant feature in the model.

In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ The LLR score for a pair of words is high if the words have either a strong positive association or a strong negative association.
In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ Never theless, we have found a beam-search procedure that seems highly effective in finding good alignments when used with these models.For each sentence pair, we create a list of associa tion types and their corresponding scores, consisting of the associations for which we have determined ascore and for which the words involved in the asso ciation type occur in the sentence pair.3 We sort the resulting list of association types from best to worst according to their scores.

Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ The LLR score for a pair of words is high if the words have either a strong positive association or a strong negative association.
Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ We collected link counts and co-occurrence counts from these alignments for estimating conditional link probabilities.

We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ A Discriminative Framework For Bilingual Word Alignment
We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ We used one ofthese subsets as a development set for parameter op timization, and held out the other for a final test set.We report the performance of our alignment mod els in terms of precision, recall, and alignment error rate (AER) as defined by Och and Ney (2003): recall =

As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ In this paper, we take a different approach to word alignment, based on discriminative training of a weighted linear combination of a small number of features.
As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ When the first version of this paper was submitted for review, we could honestly state, ?We are not aware of any previous work on discriminative word alignment models.?

Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ Since evaluating each combina tion of parameter values in this way can take hours to days on a large training corpus, it seems safe to say that these parameters are rarely if ever truly jointly optimized for a particular alignment task.
Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ In practice, however, effective discriminative models for word alignment require only a few parameters, which can be optimized on a set of annotated sentence pairs comparable in size to what is needed to tune the free parameters used in the generative approach.

 $$$$$ Full details are provided in the reference.what other links are present in the alignment.
 $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.

d is an absolute discount parameter as in (Moore, 2005). $$$$$ We find itbetter, however, to adjust these probabilities by sub tracting a small fixed discount from the link count: LPd(f, e) = links 1 (f, e)?
d is an absolute discount parameter as in (Moore, 2005). $$$$$ We trained CLP-based models from these counts for a range of values for the discount used in the conditional link probability estimation, finding a value of 0.4 to be a roughly optimal value of the discount parameter for the development set.

(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ We optimize the model weights using a modified version of averaged perceptron learning as describedby Collins (2002).
(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ We optimize the feature weights using a modified version of averaged perceptron learning as described by Collins (2002).

2) Conditional link probability (Moore, 2005). $$$$$ 2.2 The Conditional-Link-Probability-Based.
2) Conditional link probability (Moore, 2005). $$$$$ We collected link counts and co-occurrence counts from these alignments for estimating conditional link probabilities.

For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ In our first model, we use a log-likelihood-ratio (LLR) statistic as our measure of word association.
For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ Liu et al (2005) also develop a log-linear model,based on IBM Model 3.

d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ We compute LLR scores using the following formula presented by Moore (2004): LLR(f, e) = ? f??{f,?f} ? e??{e,?e} C(f?, e?)
d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ Allowing all weights tovary allows many equivalent sets of weights that dif fer only by a constant scale factor.

Moore (2005) proposes a similar framework, but with more features and a different search method. $$$$$ A Discriminative Framework For Bilingual Word Alignment
Moore (2005) proposes a similar framework, but with more features and a different search method. $$$$$ In this paper, we take a different approach to word alignment, based on discriminative training of a weighted linear combination of a small number of features.

In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ We sort the word pairs in the alignment, first by source word position, and then by target word position.
In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ Liu et al (2005) also develop a log-linear model,based on IBM Model 3.

These models are roughly clustered into two groups: generative models, such as those pro posed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative models, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006). $$$$$ The standard approach to word alignment makes use of various com binations of five generative models developed at IBM by Brown et al (1993), sometimes augmented by an HMM-based model or Och and Ney?s ?Model 6?
These models are roughly clustered into two groups: generative models, such as those pro posed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative models, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006). $$$$$ Liu et al (2005) also develop a log-linear model,based on IBM Model 3.

Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ Generative models require a generative ?story?
Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ To model this explicitly, they had to come up with a different generative story.

Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ For example, suppose we have the sorted alignment ((1,1)(2,4)(2,5)(3,2)(5,6)).
Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ The results of our work and other recent efforts on discriminatively trained alignment models showthat results comparable to or better than those ob tained with the IBM models are possible within aframework that makes it easy to add arbitrary ad ditional features.

 $$$$$ Full details are provided in the reference.what other links are present in the alignment.
 $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.
