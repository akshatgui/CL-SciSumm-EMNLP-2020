We follow Kruengkrai et al (2009) and split the CTB 5 into training, development testing and testing sets, as shown in Table 3. $$$$$ In the testing phase, we can use a dynamic programming algorithm to search for the most likely path out of all candidate paths.
We follow Kruengkrai et al (2009) and split the CTB 5 into training, development testing and testing sets, as shown in Table 3. $$$$$ In this paper, we used CTB 5.0 (LDC2005T01) as our main corpus, defined the training, development and test sets according to (Jiang et al., 2008a; Jiang et al., 2008b), and designed our experiments to explore the impact of the training corpus size on our approach.

Kruengkrai et al (2009) made use of character type knowledge for spaces, numerals, symbols, alphabets, Chinese and other characters. $$$$$ Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.
Kruengkrai et al (2009) made use of character type knowledge for spaces, numerals, symbols, alphabets, Chinese and other characters. $$$$$ For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).

Kruengkrai et al (2009) and Zhang and Clark (2008) are the most similar to our system among related work. $$$$$ Zhang and Clark (2008) (Z&C08) generated CTB 3.0 from CTB 4.0.
Kruengkrai et al (2009) and Zhang and Clark (2008) are the most similar to our system among related work. $$$$$ For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).

The work of Kruengkrai et al (2009) is based on Nakagawa and Uchimoto (2007), which separates the processing of known words and unknown words, and uses a set of segmentation tags to represent the segmentation of characters. $$$$$ We represent the search space with a lattice based on the word-character hybrid model (Nakagawa and Uchimoto, 2007).
The work of Kruengkrai et al (2009) is based on Nakagawa and Uchimoto (2007), which separates the processing of known words and unknown words, and uses a set of segmentation tags to represent the segmentation of characters. $$$$$ Maximum entropy models are widely used for word segmentation and POS tagging tasks (Uchimoto et al., 2001; Ng and Low, 2004; Nakagawa, 2004; Nakagawa and Uchimoto, 2007) since they only need moderate training times while they provide reasonable performance.

Our learning and decoding algorithms are also different from Kruengkrai et al (2009). $$$$$ The total number of words is the same, but the different policies yield different balances between the known and artificial unknown words for learning the hybrid model.
Our learning and decoding algorithms are also different from Kruengkrai et al (2009). $$$$$ Our experiment on the large training corpus is identical to that of Jiang et al. (Jiang et al., 2008a; Jiang et al., 2008b).

 $$$$$ Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.
 $$$$$ We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.

K2009 is the result of Kruengkrai et al (2009). $$$$$ As a result, we cannot directly use the 0/1 loss.
K2009 is the result of Kruengkrai et al (2009). $$$$$ Our experiment on the large training corpus is identical to that of Jiang et al. (Jiang et al., 2008a; Jiang et al., 2008b).

 $$$$$ Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.
 $$$$$ We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.

Therefore, it's natural that we evaluate the accuracy of joint Chinese word segmentation and part of speech tagging, as reported in previous literature (Kruengkrai et al 2009). $$$$$ An Error-Driven Word-Character Hybrid Model for Joint Chinese Word Segmentation and POS Tagging
Therefore, it's natural that we evaluate the accuracy of joint Chinese word segmentation and part of speech tagging, as reported in previous literature (Kruengkrai et al 2009). $$$$$ Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.

For ordinary word segmentation, the best result is reported to be around 97% F1 on CTB 5.0 (Kruengkrai et al, 2009), while our parser performs at 97.3%, though we should remember that the result concerns flat words only. $$$$$ As a result, we cannot directly use the 0/1 loss.
For ordinary word segmentation, the best result is reported to be around 97% F1 on CTB 5.0 (Kruengkrai et al, 2009), while our parser performs at 97.3%, though we should remember that the result concerns flat words only. $$$$$ The result of our error-driven model is superior to previous reported results for both Seg and Seg & Tag, and the result of our baseline model compares favorably to the others.

Because the tasks of word segmentation and POS tagging have strong interactions, many studies have been devoted to the task of joint word segmentation and POS tagging for languages such as Chinese (e.g. Kruengkrai et al (2009)). $$$$$ An Error-Driven Word-Character Hybrid Model for Joint Chinese Word Segmentation and POS Tagging
Because the tasks of word segmentation and POS tagging have strong interactions, many studies have been devoted to the task of joint word segmentation and POS tagging for languages such as Chinese (e.g. Kruengkrai et al (2009)). $$$$$ Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.

"Kruengkrai+ '09" is a lattice-based model by Kruengkrai et al (2009). $$$$$ Nakagawa (2004) described a training method based on a word-based Markov model and a character-based maximum entropy model that can be completed in a reasonable time.
"Kruengkrai+ '09" is a lattice-based model by Kruengkrai et al (2009). $$$$$ We represent the search space with a lattice based on the word-character hybrid model (Nakagawa and Uchimoto, 2007).

We applied morphological analysis and part-of-speech tagging by using TreeTagger (Schmid, 1994) for English, JUMAN for Japanese, and mma (Kruengkrai et al, 2009) for Chinese, respectively. $$$$$ In Chinese, word segmentation and part-of-speech (POS) tagging are indispensable steps for higherlevel NLP tasks.
We applied morphological analysis and part-of-speech tagging by using TreeTagger (Schmid, 1994) for English, JUMAN for Japanese, and mma (Kruengkrai et al, 2009) for Chinese, respectively. $$$$$ Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.

We used the MMA system (Kruengkrai et al, 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline parser to parse all the sentences in the data. $$$$$ Using just the surface forms can overfit the training data and lead to poor predictions on the test data.
We used the MMA system (Kruengkrai et al, 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline parser to parse all the sentences in the data. $$$$$ For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).

Firstly, the Chinese sentences are segmented, POS tagged and parsed by the tools described in Kruengkrai et al (2009) and Cao et al (2007), both of which are trained on the Penn Chinese Treebank 6.0. $$$$$ We conducted our experiments on Penn Chinese Treebank (Xia et al., 2000) and compared our approach with the best previous approaches reported in the literature.
Firstly, the Chinese sentences are segmented, POS tagged and parsed by the tools described in Kruengkrai et al (2009) and Cao et al (2007), both of which are trained on the Penn Chinese Treebank 6.0. $$$$$ Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.

On the Chinese side, we used the morphological analyzer described in (Kruengkrai et al, 2009) trained on the training data of CTBtp to perform word segmentation and POS tagging and used the first-order Parsers to parse all the sentences in the data. $$$$$ Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.
On the Chinese side, we used the morphological analyzer described in (Kruengkrai et al, 2009) trained on the training data of CTBtp to perform word segmentation and POS tagging and used the first-order Parsers to parse all the sentences in the data. $$$$$ For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).

 $$$$$ Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.
 $$$$$ We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.

 $$$$$ Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.
 $$$$$ We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.

 $$$$$ Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.
 $$$$$ We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.

We used the MMA system (Kruengkrai et al, 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline Parser to parse all the sentences in the data. $$$$$ Using just the surface forms can overfit the training data and lead to poor predictions on the test data.
We used the MMA system (Kruengkrai et al, 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline Parser to parse all the sentences in the data. $$$$$ For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).
