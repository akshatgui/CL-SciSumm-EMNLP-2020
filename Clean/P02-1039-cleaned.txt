In comparison, in (Yamada and Knight, 2002), which was a phrasal structure based statistical MT system for Chinese to English translation, the Bleu score reported for short sentences (less than 14 words) is 0.099 to 0.102. $$$$$ A Decoder For Syntax-Based Statistical MT
In comparison, in (Yamada and Knight, 2002), which was a phrasal structure based statistical MT system for Chinese to English translation, the Bleu score reported for short sentences (less than 14 words) is 0.099 to 0.102. $$$$$ We selected 347 short sentences (less than 14 words in the reference English translation) from the held-out portion of the corpus, and they were used for evaluation.

Here, we used a model defined by Yamada and Knight (2001) and Yamada and Knight (2002). Internally, the model performs three types of operations on each node of a parse tree. $$$$$ This paper describes a decoding algorithm for a syntax-based translation model (Yamada and Knight, 2001).
Here, we used a model defined by Yamada and Knight (2001) and Yamada and Knight (2002). Internally, the model performs three types of operations on each node of a parse tree. $$$$$ The syntax-based TM defined by (Yamada and Knight, 2001) assumes an English parse tree as a channel input.

The model is further extended to incorporate phrasal translations performed at each node of the input parse tree (Yamada and Knight, 2002). $$$$$ The model has been extended to incorporate phrasal translations as presented here.
The model is further extended to incorporate phrasal translations performed at each node of the input parse tree (Yamada and Knight, 2002). $$$$$ The translation model was extended to incorporate phrasal translations.

While (Yamada and Knight, 2002) represent syntactical information in the decoding process through a series of transformation operations, we operate directly at the phrase level. $$$$$ This paper describes a decoding algorithm for a syntax-based translation model (Yamada and Knight, 2001).
While (Yamada and Knight, 2002) represent syntactical information in the decoding process through a series of transformation operations, we operate directly at the phrase level. $$$$$ See (Yamada, 2002) for details.

The syntactically supervised model has been found to outperform the IBM word-level alignment models of Brown et al (1993) for translation by Yamada and Knight (2002). $$$$$ For the IBM models defined by a pioneering paper (Brown et al., 1993), a decoding algorithm based on a left-to-right search was described in (Berger et al., 1996).
The syntactically supervised model has been found to outperform the IBM word-level alignment models of Brown et al (1993) for translation by Yamada and Knight (2002). $$$$$ Recently (Yamada and Knight, 2001) introduced a syntax-based TM which utilized syntactic structure in the channel input, and showed that it could outperform the IBM model in alignment quality.

(Yamada and Knight, 2002) propose a syntax-based decoder that restrict word reordering based on reordering operations on syntactic parse-trees of the input sentence. $$$$$ The syntax-based TM defined by (Yamada and Knight, 2001) assumes an English parse tree as a channel input.
(Yamada and Knight, 2002) propose a syntax-based decoder that restrict word reordering based on reordering operations on syntactic parse-trees of the input sentence. $$$$$ Therefore, the TM could not take advantage of syntactic reordering operations.

Yamada and Knight (2002) presents a decoder for syntax-based MT that uses so-called phrasal translation units that correspond to blocks. $$$$$ A Decoder For Syntax-Based Statistical MT
Yamada and Knight (2002) presents a decoder for syntax-based MT that uses so-called phrasal translation units that correspond to blocks. $$$$$ This paper describes a decoding algorithm for a syntax-based translation model (Yamada and Knight, 2001).

As an alternative option to our verb-modifier experiments, structured language models (Chelba and Jelinek, 1998) might be considered to improve clause coherence, until full-featured syntax-based MT models (Yamada and Knight (2002), Eisner (2003), Chiang (2005) among many others) are tested when translating to morphologically rich languages. $$$$$ A Decoder For Syntax-Based Statistical MT
As an alternative option to our verb-modifier experiments, structured language models (Chelba and Jelinek, 1998) might be considered to improve clause coherence, until full-featured syntax-based MT models (Yamada and Knight (2002), Eisner (2003), Chiang (2005) among many others) are tested when translating to morphologically rich languages. $$$$$ In contrast to the IBM models, which are word-to-word models, the syntax-based model works on a syntactic parse tree, so the decoder builds up an English parse tree given a sentencein a foreign language.

It follows the decoding-as-parsing idea exemplified by Wu (1996) and Yamada and Knight (2002). $$$$$ Section 4 presents the basic idea for decoding.
It follows the decoding-as-parsing idea exemplified by Wu (1996) and Yamada and Knight (2002). $$$$$ See (Yamada, 2002) for details.

This model is then decoded as described in (Yamada and Knight, 2002). $$$$$ This paper describes a decoding algorithm for a syntax-based translation model (Yamada and Knight, 2001).
This model is then decoded as described in (Yamada and Knight, 2002). $$$$$ See (Yamada, 2002) for details.

For reasons of speed, Yamada and Knight (2002) limited training to sentences of length 30, and were able to use only one fifth of the available Chinese-English parallel corpus. $$$$$ We used a Chinese-English translation corpus for the experiment.
For reasons of speed, Yamada and Knight (2002) limited training to sentences of length 30, and were able to use only one fifth of the available Chinese-English parallel corpus. $$$$$ To find good pairs of sentences in the corpus, we used the following: 1) Both English and Chinese sentences end with a period.

One way to approach reordering is by extending the translation model, either by adding extra models, such as lexicalized (Koehn et al, 2005) or discriminative (Zens and Ney, 2006) reordering models or by directly modelling reordering in hierarchical (Chiang, 2007) or syntactical translation models (Yamada and Knight, 2002). $$$$$ This is because the reordering probability is always 1.
One way to approach reordering is by extending the translation model, either by adding extra models, such as lexicalized (Koehn et al, 2005) or discriminative (Zens and Ney, 2006) reordering models or by directly modelling reordering in hierarchical (Chiang, 2007) or syntactical translation models (Yamada and Knight, 2002). $$$$$ Third, it uses more frequent node reordering than it should.
