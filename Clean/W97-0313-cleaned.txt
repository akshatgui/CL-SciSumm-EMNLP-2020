Our approach builds upon earlier work on corpus-based methods for generating extraction patterns (Riloff, 1996b) and semantic lexicons (Riloff and Shepherd, 1997). $$$$$ A Corpus-Based Approach For Building Semantic Lexicons
Our approach builds upon earlier work on corpus-based methods for generating extraction patterns (Riloff, 1996b) and semantic lexicons (Riloff and Shepherd, 1997). $$$$$ Our corpus-based approach is designed to support fast semantic lexicon construction.

The corpus-based algorithm that we used to build the semantic lexicon (Riloff and Shepherd, 1997) requires five seed words as input for each semantic category, and produces a ranked list of words that are statistically associated with each category. $$$$$ The output is a ranked list of words that are associated with the category.
The corpus-based algorithm that we used to build the semantic lexicon (Riloff and Shepherd, 1997) requires five seed words as input for each semantic category, and produces a ranked list of words that are statistically associated with each category. $$$$$ Our approach is geared toward fast semantic lexicon construction

For more details of this algorithm, see (Riloff and Shepherd, 1997). $$$$$ In the first section, we describe the statistical bootstrapping algorithm for identifying candidate category words and ranking them.
For more details of this algorithm, see (Riloff and Shepherd, 1997). $$$$$ The algorithm is clearly sensitive to the initial seed words, but the degree of sensitivity is unknown.

In addition, we exploit syntactic constructions shown to be useful by other studies - lists and conjunctions (Roark and Charniak, 1998), and adjacent words (Riloff and Shepherd, 1997). $$$$$ As an example, the seed word lists used in our experiments are shown below.
In addition, we exploit syntactic constructions shown to be useful by other studies - lists and conjunctions (Roark and Charniak, 1998), and adjacent words (Riloff and Shepherd, 1997). $$$$$ For each category, we began with the seed word lists shown in Figure 1.

(Hearst, 1992), Snowball (Agichtein and Gravano, 2000), AutoSlog (Riloff and Shepherd, 1997), and Junto (Talukdar, 2010) among others, also have similarities to our approach. $$$$$ A Corpus-Based Approach For Building Semantic Lexicons
(Hearst, 1992), Snowball (Agichtein and Gravano, 2000), AutoSlog (Riloff and Shepherd, 1997), and Junto (Talukdar, 2010) among others, also have similarities to our approach. $$$$$ Note that our context window is much narrower than those used by other researchers (Yarowsky, 1992).

Riloff and Shepherd (1997) used a semi automatic method for discovering similar words using a few seed examples by using pattern-based techniques and human supervision. $$$$$ In this paper, we present a corpus-based method that can be used to build semantic lexicons for specific categories.
Riloff and Shepherd (1997) used a semi automatic method for discovering similar words using a few seed examples by using pattern-based techniques and human supervision. $$$$$ In general, we found that additional seed words tend to improve performance, but the results were not substantially different using five seed words or using ten.

For example, Riloff and Shepherd (Riloff and Shepherd, 1997) developed a statistical co-occurrence model for semantic lexicon induction that was designed with these structures in mind. $$$$$ Most of the time semantic knowledge is defined manually for the target application, but several techniques have been developed for generating semantic knowledge automatically.
For example, Riloff and Shepherd (Riloff and Shepherd, 1997) developed a statistical co-occurrence model for semantic lexicon induction that was designed with these structures in mind. $$$$$ Our corpus-based approach is designed to support fast semantic lexicon construction.

Many of the successful methods follow the unsupervised iterative bootstrapping framework (Riloff and Shepherd, 1997). $$$$$ In the first section, we describe the statistical bootstrapping algorithm for identifying candidate category words and ranking them.
Many of the successful methods follow the unsupervised iterative bootstrapping framework (Riloff and Shepherd, 1997). $$$$$ We ran the bootstrapping algorithm for eight iterations, adding five new words to the seed word list after each cycle.

NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ As an example, the seed word lists used in our experiments are shown below.
NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ To our knowledge, our system is the first one aimed at building semantic lexicons from raw text without using any additional semantic knowledge.

The idea here is that nouns in conjunctions or appositives tend to be semantically related, as discussed in Riloff and Shepherd (1997) and Roark and Charniak (1998). $$$$$ We presented the words in random order so that the user had no idea how our system had ranked the words.
The idea here is that nouns in conjunctions or appositives tend to be semantically related, as discussed in Riloff and Shepherd (1997) and Roark and Charniak (1998). $$$$$ But it is worth noting that this category achieved good results, presumably because location names often cluster together in appositives, conjunctions, and nominal compounds.

Both Hearst (1992) and Riloff and Shepherd (1997) use unparsed text. $$$$$ The MUC-4 development corpus (1700 texts) was used as the text corpus (MUC-4 Proceedings, 1992).
Both Hearst (1992) and Riloff and Shepherd (1997) use unparsed text. $$$$$ We'll use the category ANIMAL as an example.

Riloff and Shepherd (1997) suggested using conjunction and appositive data to cluster nouns; however, they approximated this data by just looking at the nearest NP on each side of a particular NP. $$$$$ The remaining nouns are sorted by category score and ranked so that the nouns most strongly associated with the category appear at the top.
Riloff and Shepherd (1997) suggested using conjunction and appositive data to cluster nouns; however, they approximated this data by just looking at the nearest NP on each side of a particular NP. $$$$$ In general, we found that additional seed words tend to improve performance, but the results were not substantially different using five seed words or using ten.

The main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular category, such as vehicles or weapons (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). $$$$$ Our system uses a text corpus and a small set of seed words for a category to identify other words that also belong to the category.
The main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular category, such as vehicles or weapons (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). $$$$$ We performed experiments with five categories to evaluate the effectiveness and generality of our approach

Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ As an example, the seed word lists used in our experiments are shown below.
Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ It is also apparent that a few additional heuristics could be used to remove many of the extraneous words.

Since lists are usually comprised of objects which are similar in some way, these relationships have been used to extract lists of nouns with similar properties (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998). $$$$$ As an example, the seed word lists used in our experiments are shown below.
Since lists are usually comprised of objects which are similar in some way, these relationships have been used to extract lists of nouns with similar properties (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998). $$$$$ For each category, we began with the seed word lists shown in Figure 1.

These conditions are at least as stringent as those of previous experiments, particularly those of Riloff and Shepherd (1997) who also give credit for words associated with but not belonging to a particular category. $$$$$ The output is a ranked list of words that are associated with the category.
These conditions are at least as stringent as those of previous experiments, particularly those of Riloff and Shepherd (1997) who also give credit for words associated with but not belonging to a particular category. $$$$$ If a word refers to something that can be associated with members of the category, but is also associated with many other types of things, then it deserves a 2.

Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ We presented the words in random order so that the user had no idea how our system had ranked the words.
Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ For the five categories reported in this paper, we arbitrarily chose a few words that were central members of the category.

The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ The MUC-4 development corpus (1700 texts) was used as the text corpus (MUC-4 Proceedings, 1992).
The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ The Location category performed very well using seed words such as city, town, and province.

Riloff and Shepherd (1997) presented a corpus based method that can be used to build semantic lexicons for specific categories. $$$$$ A Corpus-Based Approach For Building Semantic Lexicons
Riloff and Shepherd (1997) presented a corpus based method that can be used to build semantic lexicons for specific categories. $$$$$ In this paper, we present a corpus-based method that can be used to build semantic lexicons for specific categories.

Following the work of (Riloff and Shepherd, 1997), we adopted the following evaluation setting. $$$$$ CRITERIA
