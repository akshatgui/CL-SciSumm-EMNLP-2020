Finally, Huang et al (2009) use features, somewhat like QG configurations, on the shift-reduce actions in a monolingual, target language parser. $$$$$ We show specifically how to enhance a shift-reduce dependency parser with alignment features to resolve shift-reduce conflicts.
Finally, Huang et al (2009) use features, somewhat like QG configurations, on the shift-reduce actions in a monolingual, target language parser. $$$$$ We show in Section 5.3 that these features do correlate with the correct shift/reduce actions in practice.

The first consists of a joint segmentation and POS-tagging model (Zhang and Clark, 2010) and a word-based dependency parsing model using the arc-standard algorithm (Huang et al, 2009). $$$$$ Most subsequent works on shift-reduce or “transition-based” dependency parsing followed “arc-eager” (Nivre and Scholz, 2004; Zhang and Clark, 2008), which now becomes the dominant style.
The first consists of a joint segmentation and POS-tagging model (Zhang and Clark, 2010) and a word-based dependency parsing model using the arc-standard algorithm (Huang et al, 2009). $$$$$ As we will see in Section 5.1, this simpler arc-standard system performs equally well with a state-of-the-art arc-eager system (Zhang and Clark, 2008) on standard English Treebank parsing (which is never shown before).

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

Please refer to page 573 of (Huang et al, 2009b) for more details about how to convert tree-to-string rules to SCFG rules. $$$$$ To make things worse, languages are non-isomorphic, i.e., there is no 1to-1 mapping between tree nodes, thus in practice one has to use more expressive formalisms such as synchronous tree-substitution grammars (Eisner, 2003; Galley et al., 2004).
Please refer to page 573 of (Huang et al, 2009b) for more details about how to convert tree-to-string rules to SCFG rules. $$$$$ The bilingual data we use is the translated portion of the Penn Chinese Treebank (CTB) (Xue et al., 2002), corresponding to articles 1-325 of PTB, which have English translations with goldstandard parse trees (Bies et al., 2007).

We follow Huang et al (2009b) to keep the probabilities of a natural rule unchanged and set those of a virtual rule to 1. $$$$$ Ambiguity resolution is a central task in Natural Language Processing.
We follow Huang et al (2009b) to keep the probabilities of a natural rule unchanged and set those of a virtual rule to 1. $$$$$ For example, Smith and Smith (2004) and Burkett and Klein (2008) show that joint parsing (or reranking) on a bitext improves accuracies on either or both sides by leveraging bilingual constraints, which is very promising for syntax-based machine translation which requires (good-quality) parse trees for rule extraction (Galley et al., 2004; Mi and Huang, 2008).

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

Huang et al (2009) presented a method to train a source-language parser by using the reordering information on words between the sentences on two sides. $$$$$ We basically M(·) is maps a source span to the target language, and M−1(·) is the reverse operation mapping back to the source language. map a source span sp to its target span M(sp), and check whether its reverse image back onto the source language M−1(M(sp)) falls inside the allowed span ap.
Huang et al (2009) presented a method to train a source-language parser by using the reordering information on words between the sentences on two sides. $$$$$ Following this idea, Ganchev et al. (2009) and Smith and Eisner (2009) use constrained EM and parser adaptation techniques, respectively, to perform more principled projection, and both achieve encouraging results.

Huang et al (2009) proposed features based on reordering between languages for a shift-reduce parser. $$$$$ We show specifically how to enhance a shift-reduce dependency parser with alignment features to resolve shift-reduce conflicts.
Huang et al (2009) proposed features based on reordering between languages for a shift-reduce parser. $$$$$ We implement our baseline monolingual parser (in C++) based on the shift-reduce algorithm in Section 2, with feature templates from Table 2.

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

Table 7 lists the results, where Huang 2009 refers to the result of Huang et al (2009), Chen2010BI refers to the result of using bilingual features in Chen et al (2010), and Chen2010ALL refers to the result of using all of the features in Chen et al (2010). $$$$$ On both English and Chinese, the addition of bilingual features improves dependency arc accuracies by +0.6%, which is mildly significant using the Z-test of Collins et al. (2005).
Table 7 lists the results, where Huang 2009 refers to the result of Huang et al (2009), Chen2010BI refers to the result of using bilingual features in Chen et al (2010), and Chen2010ALL refers to the result of using all of the features in Chen et al (2010). $$$$$ The result is worse than our baseline on English, but better than our bilingual parser on Chinese.

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

For the transition-based parsers, we used the arc-eager (ARCE) variant of the freely available MALT parser (Nivre et al,2006), and our own implementation of an arc standard parser (ARCS) as described in (Huang et al., 2009). $$$$$ The three action system was originally described by Yamada and Matsumoto (2003) (although their methods require multiple passes over the input), and then appeared as “arc-standard” in Nivre (2004), but was argued against in comparison to the four-action “arc-eager” variant.
For the transition-based parsers, we used the arc-eager (ARCE) variant of the freely available MALT parser (Nivre et al,2006), and our own implementation of an arc standard parser (ARCS) as described in (Huang et al., 2009). $$$$$ Most subsequent works on shift-reduce or “transition-based” dependency parsing followed “arc-eager” (Nivre and Scholz, 2004; Zhang and Clark, 2008), which now becomes the dominant style.

The semantics of the system is described in (Huang et al, 2009). $$$$$ But we argue that “arc-standard” is preferable because

Fossum and Knight (2008) and Huang et al (2009) improve English prepositional phrase attachment using features from an unparsed Chinese sentence. $$$$$ For example, prepositional phrase (PP) attachment is (notoriously) ambiguous in English (and related European languages), but is strictly unambiguous in Chinese and largely unambiguous Japanese; see two languages for better disambiguation, which has been applied not only to this PP-attachment problem (Fossum and Knight, 2008; Schwartz et al., 2003), but also to the more fundamental problem of syntactic parsing which subsumes the former as a subproblem.
Fossum and Knight (2008) and Huang et al (2009) improve English prepositional phrase attachment using features from an unparsed Chinese sentence. $$$$$ On both English and Chinese, the addition of bilingual features improves dependency arc accuracies by +0.6%, which is mildly significant using the Z-test of Collins et al. (2005).

In fact, it is worse than the deterministic parser of Huang et al (2009), which uses (almost) the same set of features. $$$$$ This could be explained by the fact that beam-search is more robust than the deterministic mode, where in the latter, if our bilingual features misled the parser into a mistake, there is no chance of getting back, while in the former multiple configurations are being pursued in parallel.
In fact, it is worse than the deterministic parser of Huang et al (2009), which uses (almost) the same set of features. $$$$$ The result is worse than our baseline on English, but better than our bilingual parser on Chinese.

 $$$$$ Pseudocode 1 illustrates the algorithm, where we keep an agenda V of the current active configurations, and at each step try to extend them by applying one of the three actions.
 $$$$$ 2006AA010108.

Then we parse the English sentences to generate a string-to-dependency word-aligned corpus using the parser (Huang et al, 2009). $$$$$ The only thing we are sure of in a shift action is that st and wi will be combined before st−1 and st are combined (Aho and Ullman, 1972), so we can tolerate any target word aligned to source word still in the queue, but do not allow any target word aligned to an already recognized source word.
Then we parse the English sentences to generate a string-to-dependency word-aligned corpus using the parser (Huang et al, 2009). $$$$$ On both English and Chinese, the addition of bilingual features improves dependency arc accuracies by +0.6%, which is mildly significant using the Z-test of Collins et al. (2005).
