In a sense this is encouraging, as it motivates our most exciting future work: augmenting this simple model to explicitly capture complementary information such as distributional semantics (Blei et al, 2003), diathesis alternations (McCarthy, 2000) and selectional preferences (OSeaghdha, 2010). $$$$$ Preferences for the target slots are compared using a measure of distributional similarity.
In a sense this is encouraging, as it motivates our most exciting future work: augmenting this simple model to explicitly capture complementary information such as distributional semantics (Blei et al, 2003), diathesis alternations (McCarthy, 2000) and selectional preferences (OSeaghdha, 2010). $$$$$ And Ribas (1995) showed that selectional preferences acquired using alternations performed better on a word sense disambiguation task compared to preferences acquired without alternations.

In contrast to comparing head nouns directly, McCarthy (2000) instead compares the selectional preferences for each of the two slots (captured by a probability distribution over WordNet). $$$$$ The method uses selectional preferences acquired as probability distributions over WordNet.
In contrast to comparing head nouns directly, McCarthy (2000) instead compares the selectional preferences for each of the two slots (captured by a probability distribution over WordNet). $$$$$ In this experiment, we used a similarity score on the argument heads directly, instead of generalizing the argument heads to WordNet classes.

The approach of McCarthy (2000), on the other hand, addresses the generalization problem by comparing probability distributions over WordNet. $$$$$ The method uses selectional preferences acquired as probability distributions over WordNet.
The approach of McCarthy (2000), on the other hand, addresses the generalization problem by comparing probability distributions over WordNet. $$$$$ Our approach, whilst being applicable only to RsAs, does not require human input specific to the alternation at hand.

As mentioned above, McCarthy (2000) suggested the use of selectional profiles to capture generalizations over argument slots, so that two argument slots could be effectively compared for detecting alternations. $$$$$ Preferences for the target slots are compared using a measure of distributional similarity.
As mentioned above, McCarthy (2000) suggested the use of selectional profiles to capture generalizations over argument slots, so that two argument slots could be effectively compared for detecting alternations. $$$$$ The sum of the costs for the two target slots was compared to the cost of a TCM for encoding the union of the argument head data over the two slots.

 $$$$$ WordNet classes are displayed in boxes with a label which best reflects the sense of the class.
 $$$$$ We also acknowledge Gerald Gazdar for his helpful comments on this paper.

In the first method (that of McCarthy, 2000), the two profiles become identical. $$$$$ It is these alternations that our method applies to.
In the first method (that of McCarthy, 2000), the two profiles become identical. $$$$$ McCarthy and Korhonen (1998) proposed a method for identifying asAs using MDL.

We evaluate our method on the causative alternation in order for comparison to the earlier methods of McCarthy (2000) and Merlo and Stevenson (2001). $$$$$ Recently, there has been interest in corpus-based methods to identify alternations (McCarthy and Korhonen, 1998; Lapata, 1999), and associated verb classifications (Stevenson and Merlo, 1999).
We evaluate our method on the causative alternation in order for comparison to the earlier methods of McCarthy (2000) and Merlo and Stevenson (2001). $$$$$ Stevenson and Merlo used four linguistically motivated features to distinguish these groups.

This means that the kind of straightforward propagation method used by McCarthy (2000) is not applicable to selectional profiles of this type. $$$$$ The method uses selectional preferences acquired as probability distributions over WordNet.
This means that the kind of straightforward propagation method used by McCarthy (2000) is not applicable to selectional profiles of this type. $$$$$ Although we have reported results on only two RSAS, our method is applicable to other such alternations.

The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ Selectional preferences are acquired using the method devised by Li and Abe (1995).
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ McCarthy and Korhonen (1998) proposed a method for identifying asAs using MDL.

By comparison, McCarthy (2000) attained 73% accuracy on her set of hand-selected test verbs in a similar task; however, when applied to our various sets of randomly selected verbs, our replication of her method performed very poorly, rarely reaching above chance performance. $$$$$ We selected candidate verbs which occurred with 10 or more nominal argument heads at the target slots.
By comparison, McCarthy (2000) attained 73% accuracy on her set of hand-selected test verbs in a similar task; however, when applied to our various sets of randomly selected verbs, our replication of her method performed very poorly, rarely reaching above chance performance. $$$$$ From these, verbs were selected which had 75% or more agreement, i.e. three or more judges giving the same yes or no decision for the verb.

The mapping for the dependents in the alternation can be taken from existing lexical resources (Dorr, 1997), learned from corpora (McCarthy, 2000) or learned from existing lexicons (Bond et al, 2002). $$$$$ Levin's classification has been extended by other NLP researchers (Dorr and Jones, 1996; Dang et al., 1998).
The mapping for the dependents in the alternation can be taken from existing lexical resources (Dorr, 1997), learned from corpora (McCarthy, 2000) or learned from existing lexicons (Bond et al, 2002). $$$$$ We use the SCF acquisition system of Briscoe and Carroll (1997), with a probabilistic LR parser (Inui et al., 1997) for syntactic processing.

As in McCarthy (2000), we cast argument alternation detection as a comparison of sense profiles across two different argument positions of a verb. $$$$$ He used alternations to indicate where the argument head data from different slots can be combined since it occupies the same semantic relationship with the predicate.
As in McCarthy (2000), we cast argument alternation detection as a comparison of sense profiles across two different argument positions of a verb. $$$$$ In this experiment, we used a similarity score on the argument heads directly, instead of generalizing the argument heads to WordNet classes.

Similarly, McCarthy (2000) uses skew divergence (a variant of KL divergence proposed by Lee, 1999) to compare the sense profile of one argument of a verb (e.g., the subject position of the intransitive) to another argument of the same verb (e.g., the object position of the transitive), to determine if the verb participates in an argument alternation involving the two positions. $$$$$ In this alternation, the object of the transitive variant can also appear as the subject of the intransitive variant.
Similarly, McCarthy (2000) uses skew divergence (a variant of KL divergence proposed by Lee, 1999) to compare the sense profile of one argument of a verb (e.g., the subject position of the intransitive) to another argument of the same verb (e.g., the object position of the transitive), to determine if the verb participates in an argument alternation involving the two positions. $$$$$ The UBC is at the classes B, C and D. To quantify the similarity between the probability distributions for the target slots we use the a-skew divergence (asp) proposed by Lee (1999).

Because we demonstrate our new SPD measure on the same problem as McCarthy (2000), we provide more detail of her method here, for comparison. $$$$$ The polysemy of the verbs may provide another explanation for the large quantity of false positives.
Because we demonstrate our new SPD measure on the same problem as McCarthy (2000), we provide more detail of her method here, for comparison. $$$$$ For this feature, a measure similar to our LO measure was used.

In McCarthy (2000), an error analysis reveals that the best method has more false positives than false negatives - some slots are considered overly similar because the sense profiles are compared at a coarse-grained level, losing fine semantic distinctions. $$$$$ For both base cuts, there are a larger number of false positives than false negatives when the mean is used.
In McCarthy (2000), an error analysis reveals that the best method has more false positives than false negatives - some slots are considered overly similar because the sense profiles are compared at a coarse-grained level, losing fine semantic distinctions. $$$$$ The scFs and data of different senses should not ideally be combined, at least not for coarse grained sense distinctions.

In McCarthy (2000), the distributions are propagated to the lowest common subsumers (i.e., the nodes labelled B, C, and D). $$$$$ The method uses selectional preferences acquired as probability distributions over WordNet.
In McCarthy (2000), the distributions are propagated to the lowest common subsumers (i.e., the nodes labelled B, C, and D). $$$$$ Since the probability distributions may be at different levels of WordNet, we map the Tcms at the target slots to a common tree cut, a &quot;base cut&quot;.

In the first method (that of McCarthy, 2000), the two profiles become identical. $$$$$ It is these alternations that our method applies to.
In the first method (that of McCarthy, 2000), the two profiles become identical. $$$$$ McCarthy and Korhonen (1998) proposed a method for identifying asAs using MDL.

We evaluate our method on the causative alternation in order for comparison to the earlier method of McCarthy (2000). $$$$$ An example of the causative alternation is given in (1) below.
We evaluate our method on the causative alternation in order for comparison to the earlier method of McCarthy (2000). $$$$$ It is these alternations that our method applies to.

This means that the kind of straightforward propagation method used by McCarthy (2000) is not applicable to sense profiles of this type. $$$$$ The fully automatic method outlined here is applied to the causative and conative alternations, but is applicable to other RSAS.
This means that the kind of straightforward propagation method used by McCarthy (2000) is not applicable to sense profiles of this type. $$$$$ Although we have reported results on only two RSAS, our method is applicable to other such alternations.

The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ Selectional preferences are acquired using the method devised by Li and Abe (1995).
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ McCarthy and Korhonen (1998) proposed a method for identifying asAs using MDL.
