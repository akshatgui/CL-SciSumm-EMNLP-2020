On the one hand machine learning is used to automate as much as possible the tasks an IE expert would perform in application development (Cardie 1997) (Yangarber et al 2000). $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
On the one hand machine learning is used to automate as much as possible the tasks an IE expert would perform in application development (Cardie 1997) (Yangarber et al 2000). $$$$$ So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).

learned, otherwise go to step 4 Previous algorithms which use this approach include those described by Yangarber et al (2000) and Stevenson and Greenwood (2005). $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
learned, otherwise go to step 4 Previous algorithms which use this approach include those described by Yangarber et al (2000) and Stevenson and Greenwood (2005). $$$$$ use of extraction systenls.

The extraction patterns used by both Yangarber et al (2000) and Stevenson and Greenwood (2005) were based on SVO tuples extracted from dependency trees. $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
The extraction patterns used by both Yangarber et al (2000) and Stevenson and Greenwood (2005) were based on SVO tuples extracted from dependency trees. $$$$$ A non-t)rojectivc dependency parser.

Yangarber et al (2000) suggested a method where patterns were compared based on their distribution across documents in a corpus. $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
Yangarber et al (2000) suggested a method where patterns were compared based on their distribution across documents in a corpus. $$$$$ However, the review and augmenta- tion process took little time, as compared to the manual corpus analysis and development of the pattern base.

Yangarber et al (2000) proposed an algorithm for learning extraction patterns for a small number of examples which greatly reduced the burden on the application developer and reduced the knowledge acquisition bottleneck. $$$$$ However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.
Yangarber et al (2000) proposed an algorithm for learning extraction patterns for a small number of examples which greatly reduced the burden on the application developer and reduced the knowledge acquisition bottleneck. $$$$$ So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).

Yangarber et al (2000) chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns. $$$$$ We stm:t with a large, corlms of documents in the domain (which have not been anne- 941 tared or classified in any way) and an initial "seed" of scenario patterns selected by the user - -  a small set of patterns whose pres- ence reliably indicates thai; the document is relevant o the scenario.
Yangarber et al (2000) chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns. $$$$$ The pattern set is used to divide the cor- tins U into a set of relewmt documents, R (which contain at; least one instance of one of the patterns), and a set of non-relevant documents R = U - R. 2.

This approach has been shown to successfully acquire useful extraction patterns which, when added to an IE system, improved its performance (Yangarber et al, 2000). $$$$$ This approach as been evalu- ated on actual event extraction scenarios.
This approach has been shown to successfully acquire useful extraction patterns which, when added to an IE system, improved its performance (Yangarber et al, 2000). $$$$$ So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).

Architecture This architecture has been inspired by several existing seed-oriented minimally supervised ma chine learning systems, in particular by Snowball (Agichtein and Gravano, 2000) and ExDisco (Yangarber et al, 2000). $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
Architecture This architecture has been inspired by several existing seed-oriented minimally supervised ma chine learning systems, in particular by Snowball (Agichtein and Gravano, 2000) and ExDisco (Yangarber et al, 2000). $$$$$ ExDIscO attains values within the range of the MUC participald;S, all of which were either heavily-supervised or m~mually coded systems.

ExDisco (Yangarber et al,2000) uses a bootstrapping mechanism to find new extraction patterns using unannotated texts and some seed patterns as the initial input. $$$$$ Search tbr new candidate patterns: ?
ExDisco (Yangarber et al,2000) uses a bootstrapping mechanism to find new extraction patterns using unannotated texts and some seed patterns as the initial input. $$$$$ These patterns were left in Proteus for all the runs, and they make some contribu- tion to the relatively high baseline scores obtained using just the seed event patterns.

For example, the AutoSlog system (Riloff, 1993) uses pat terns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while Yangarber et al (2000) use subject-verb object tuples derived from a dependency parse. $$$$$ 3.3 General izat ion and Concept Classes Because tuples may not repeat with sufficient frequency to obtain reliable statistics, each tu- ple is reduced to a set of pints: e.g., a verb- object pair, a subject-object pair, etc.
For example, the AutoSlog system (Riloff, 1993) uses pat terns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while Yangarber et al (2000) use subject-verb object tuples derived from a dependency parse. $$$$$ ExDIsco  was seeded with lninimal pattern sets, namely: Subject Verb Direct Object C-Company C-At)point C-Person C-Person C-Resign ibr the Mmmgement task, and Subject Verb Direct Object * C-Buy C-Conlt)any C-Company merge * for Acquisitions.

To reduce the knowledge engineering burden on the user in constructing and porting an IE system, unsupervised learning has been utilized ,e.g. Riloff (1996), Yangarber et al (2000), and Sekine (2006). $$$$$ However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.
To reduce the knowledge engineering burden on the user in constructing and porting an IE system, unsupervised learning has been utilized ,e.g. Riloff (1996), Yangarber et al (2000), and Sekine (2006). $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).

Bootstrapping approaches are employed in (Riloff, 1996), (Yangarber et al, 2000), (Yangarber, 2003), and (Stevenson and Greenwood, 2005) in order to find IE patterns for domain-specific event extraction. $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
Bootstrapping approaches are employed in (Riloff, 1996), (Yangarber et al, 2000), (Yangarber, 2003), and (Stevenson and Greenwood, 2005) in order to find IE patterns for domain-specific event extraction. $$$$$ So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).

For example, EXDISCO (Yangarber et al., 2000) used Wall Street Journal articles for training. $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
For example, EXDISCO (Yangarber et al., 2000) used Wall Street Journal articles for training. $$$$$ We used a corlms of 9,224 articles from the Wall Street; Journal.

meets the density criterion (as defined in (Yangarber et al, 2000)). $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
meets the density criterion (as defined in (Yangarber et al, 2000)). $$$$$ So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).

AutoSlog TS, does not require a pre-annotated corpus, but does require one that has been split into subsets that are relevant vs. non-relevant subsets to the scenario. (Yangarber et al, 2000) attempts to find extraction patterns, without a pre-classified corpus, starting from a set of seed patterns. $$$$$ However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.
AutoSlog TS, does not require a pre-annotated corpus, but does require one that has been split into subsets that are relevant vs. non-relevant subsets to the scenario. (Yangarber et al, 2000) attempts to find extraction patterns, without a pre-classified corpus, starting from a set of seed patterns. $$$$$ Use the new pattern set; to induce a new split of the corpus into relevant and non- relevant documents.

We first present the basic algorithm for pattern acquisition, similar to that presented in (Yangarber et al., 2000). $$$$$ Sections 2 and 3 describe our algorithm for pattern dis- covery; section 4 describes our experimental re- sults.
We first present the basic algorithm for pattern acquisition, similar to that presented in (Yangarber et al., 2000). $$$$$ (Optionally, at this point, we may present he pattern to the user for review.)

 $$$$$ ~ "~ I I  (1 - ~,.~,.c~(p))"", (5) ~c K(d) where t;11(, weights ,wp arc (tetint;d using the tel- ewm(:(: of the (loeuments, a,s the total  SUl)l)or(; which the pa, I;I;ern p receives: % = log ~ l;.d,(d) dE 11 (p) and ;,7 is (;11( largest weight.
 $$$$$ Co~@ on Applied Nataral Langaage Process- tug (ANLP-NAACL), Seattle, WA.

For an indirect evaluation of the quality of the learned patterns, we employ the text-filtering evaluation strategy, as in (Yangarber et al, 2000). $$$$$ We have evaluated ExDIsco by manually incorporating the discovered pat- terns into the Proteus knowledge bases and run- ning a full MUC-style evaluation.
For an indirect evaluation of the quality of the learned patterns, we employ the text-filtering evaluation strategy, as in (Yangarber et al, 2000). $$$$$ We started with our extraction system, Pro- tens, which was used in MUC-6 in 1995, and has undergone continual improvements since the MUC evaluation.

Information Extraction (IE) systems typically use extraction patterns (e.g., Soderland et al (1995), Riloff (1996), Yangarber et al (2000), Califf and Mooney (2003)) or classifiers (e.g., Freitag (1998), Freitag and McCallum (2000), Chieu et al (2003), Bunescu and Mooney (2004)) to extract role fillers for events. $$$$$ The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).
Information Extraction (IE) systems typically use extraction patterns (e.g., Soderland et al (1995), Riloff (1996), Yangarber et al (2000), Califf and Mooney (2003)) or classifiers (e.g., Freitag (1998), Freitag and McCallum (2000), Chieu et al (2003), Bunescu and Mooney (2004)) to extract role fillers for events. $$$$$ So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).

We have chosen this evaluation strategy because this indirect approach was shown to correlate well with a direct evaluation, where the learned patterns were used to customize an IE system (Yangarberet al, 2000). $$$$$ We have evaluated ExDIsco by manually incorporating the discovered pat- terns into the Proteus knowledge bases and run- ning a full MUC-style evaluation.
We have chosen this evaluation strategy because this indirect approach was shown to correlate well with a direct evaluation, where the learned patterns were used to customize an IE system (Yangarberet al, 2000). $$$$$ We started with our extraction system, Pro- tens, which was used in MUC-6 in 1995, and has undergone continual improvements since the MUC evaluation.
