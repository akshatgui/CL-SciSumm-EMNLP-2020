We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (Collins 2002a)). $$$$$ We used the following features (several of the features were inspired by the approach of (Bikel et. al 1999), an HMM model which gives excellent results on named entity extraction): The word being tagged, the previous word, and the next word.
We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (Collins 2002a)). $$$$$ The previous tag, and the previous two tags (bigram and trigram features).

For related work on the voted perceptron algorithm applied to NLP problems, see (Collins 2002a) and (Collins 2002b). $$$$$ We applied the voted perceptron and boosting algorithms to the data described in section 2.3.
For related work on the voted perceptron algorithm applied to NLP problems, see (Collins 2002a) and (Collins 2002b). $$$$$ See (Collins 2002) for additional work using perceptron algorithms to train tagging models, and a more thorough description of the theory underlying the perceptron algorithm applied to ranking problems.

(Collins 2002a) describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels. $$$$$ This paper describes algorithms which rerank the top N hypotheses from a maximum-entropy tagger, the application being the recovery of named-entity boundaries in a corpus of web data.
(Collins 2002a) describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels. $$$$$ (Collins and Duffy 2002) describe the voted perceptron applied to the named-entity data in this paper, but using kernel-based features rather than the explicit features described in this paper.

 $$$$$ For example, G.M. would be mapped to A.A., and Animal would be mapped to Aaaaaa.
 $$$$$ Thanks also to Nigel Duffy, Rob Schapire and Yoram Singer for several useful discussions.

 $$$$$ For example, G.M. would be mapped to A.A., and Animal would be mapped to Aaaaaa.
 $$$$$ Thanks also to Nigel Duffy, Rob Schapire and Yoram Singer for several useful discussions.

The true segmentation can now be compared with the N-best list in order to train an averaged perceptron algorithm (Collins, 2002a). $$$$$ The voted perceptron algorithm can be considerably more efficient to train, at some cost in computation on test examples.
The true segmentation can now be compared with the N-best list in order to train an averaged perceptron algorithm (Collins, 2002a). $$$$$ See (Collins 2002) for additional work using perceptron algorithms to train tagging models, and a more thorough description of the theory underlying the perceptron algorithm applied to ranking problems.

However, due to the computational issues with the voted perceptron, the averaged perceptron algorithm (Collins, 2002a) is used instead. $$$$$ The second approach uses the voted perceptron algorithm.
However, due to the computational issues with the voted perceptron, the averaged perceptron algorithm (Collins, 2002a) is used instead. $$$$$ (Freund & Schapire 1999) describe a refinement of the perceptron, the voted perceptron.

To reduce the time complexity, we adapted the lazy update proposed in (Collins, 2002b), which was also used in (Zhang and Clark, 2007). $$$$$ This will generate a feature string for each of the entities in a candidate, this time using the values rather than .
To reduce the time complexity, we adapted the lazy update proposed in (Collins, 2002b), which was also used in (Zhang and Clark, 2007). $$$$$ The boosting algorithm chooses the feature/update pair which is optimal in terms of minimizing the loss function, i.e., and then makes the update .

For all objectives, we use the same standard set of feature templates, following Kazama and Torisawa (2007) with additional token shape like those in Collins (2002b) and simple gazetteer features. $$$$$ We will use “feature templates” to describe the features that we used.
For all objectives, we use the same standard set of feature templates, following Kazama and Torisawa (2007) with additional token shape like those in Collins (2002b) and simple gazetteer features. $$$$$ We define We assume a set of additional features, for .

 $$$$$ For example, G.M. would be mapped to A.A., and Animal would be mapped to Aaaaaa.
 $$$$$ Thanks also to Nigel Duffy, Rob Schapire and Yoram Singer for several useful discussions.

This approach has been used earlier by (Collins, 2002). $$$$$ The second approach uses the voted perceptron algorithm.
This approach has been used earlier by (Collins, 2002). $$$$$ Another attractive property of the voted perceptron is that it can be used with kernels, for example the kernels over parse trees described in (Collins and Duffy 2001; Collins and Duffy 2002).

This result is used to explain the convergence of weighted or voted perceptron algorithms (Collins, 2002a). $$$$$ Ranking Algorithms For Named Entity Extraction: Boosting And The Voted Perceptron
This result is used to explain the convergence of weighted or voted perceptron algorithms (Collins, 2002a). $$$$$ We applied the voted perceptron and boosting algorithms to the data described in section 2.3.

The detailed algorithm can be found in (Collins, 2002). $$$$$ The first algorithm we consider is the boosting algorithm for ranking described in (Collins 2000).
The detailed algorithm can be found in (Collins, 2002). $$$$$ See (Collins 2002) for additional work using perceptron algorithms to train tagging models, and a more thorough description of the theory underlying the perceptron algorithm applied to ranking problems.

Collins (2002) augmented a baseline NE tagger with a re-ranker that used only local, NE-oriented features. $$$$$ As a baseline model we used a maximum entropy tagger, very similar to the ones described in (Ratnaparkhi 1996; Borthwick et.
Collins (2002) augmented a baseline NE tagger with a re-ranker that used only local, NE-oriented features. $$$$$ Thus the maximumentropy tagger we used represents a serious baseline for the task.

 $$$$$ For example, G.M. would be mapped to A.A., and Animal would be mapped to Aaaaaa.
 $$$$$ Thanks also to Nigel Duffy, Rob Schapire and Yoram Singer for several useful discussions.

 $$$$$ For example, G.M. would be mapped to A.A., and Animal would be mapped to Aaaaaa.
 $$$$$ Thanks also to Nigel Duffy, Rob Schapire and Yoram Singer for several useful discussions.

Collins (2002) includes a number of interesting contextual predicates for NER. $$$$$ Conceptually, the candidate is represented by a large number of features for where is the number of distinct feature strings in training data.
Collins (2002) includes a number of interesting contextual predicates for NER. $$$$$ Also define to be the number of upper cased words within the quotes, to be the number of lower case words, and to be if , otherwise.

Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes. $$$$$ We take the entity to span words inclusive in the candidate. is seen from words to inclusive in a segmentation.
Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes. $$$$$ Also define to be the number of upper cased words within the quotes, to be the number of lower case words, and to be if , otherwise.

Using a wider context window than 2 words may improve performance; a reranking phase using global features may also improve performance (Collins, 2002). $$$$$ (Collins and Duffy 2002) describe the voted perceptron applied to the named-entity data in this paper, but using kernel-based features rather than the explicit features described in this paper.
Using a wider context window than 2 words may improve performance; a reranking phase using global features may also improve performance (Collins, 2002). $$$$$ This example also illustrates why this approach is unlikely to improve the performance of the maximum-entropy tagger.

Each shape replaces characters by their types (case sensitive letters, digits, and punctuation), and deletes repeated types - e.g., Confidence and 2,664,098 are respectively mapped to Aa and 0,0+,0+ (Collins, 2002b). $$$$$ The word with each character mapped to its type, but repeated consecutive character types are not repeated in the mapped string.
Each shape replaces characters by their types (case sensitive letters, digits, and punctuation), and deletes repeated types - e.g., Confidence and 2,664,098 are respectively mapped to Aa and 0,0+,0+ (Collins, 2002b). $$$$$ Each character in the word is mapped to its , but repeated consecutive character types are not repeated in the mapped string.
