 $$$$$ Accordingly, verb v will be considered to be a feature of noun n if the probability of their cooccurrence is greater than would be expected if verbs and nouns occurred independently.
 $$$$$ We would like to thank John Carroll for the use of his parser, Adam Kilgarriff and Bill Keller for valuable discussions and the UK EPSRC for its studentship to the first author.

(Weeds and Weir, 2003)) measure of Lin (1998) as a representative case, and utilized it for our analysis and as a starting point for improvement. $$$$$ Application-based evaluation tasks have been proposed, yet it is not clear (Weeds and Weir, 2003) whether there is or should be one distributional similarity measure which outperforms all other distributional similarity measures on all tasks and for all words.
(Weeds and Weir, 2003)) measure of Lin (1998) as a representative case, and utilized it for our analysis and as a starting point for improvement. $$$$$ Since we use the same data and methodology as in earlier work, some detail is omitted in the subsequent discussion but full details and rationale can be found in Weeds and Weir (2003).

 $$$$$ Accordingly, verb v will be considered to be a feature of noun n if the probability of their cooccurrence is greater than would be expected if verbs and nouns occurred independently.
 $$$$$ We would like to thank John Carroll for the use of his parser, Adam Kilgarriff and Bill Keller for valuable discussions and the UK EPSRC for its studentship to the first author.

However, it is not at all obvious that one universally best measure exists for all applications (Weeds and Weir, 2003). $$$$$ Further, there is no clear way of deciding which is the best measure.
However, it is not at all obvious that one universally best measure exists for all applications (Weeds and Weir, 2003). $$$$$ Application-based evaluation tasks have been proposed, yet it is not clear (Weeds and Weir, 2003) whether there is or should be one distributional similarity measure which outperforms all other distributional similarity measures on all tasks and for all words.

 $$$$$ Accordingly, verb v will be considered to be a feature of noun n if the probability of their cooccurrence is greater than would be expected if verbs and nouns occurred independently.
 $$$$$ We would like to thank John Carroll for the use of his parser, Adam Kilgarriff and Bill Keller for valuable discussions and the UK EPSRC for its studentship to the first author.

Weeds and Weir (2003) proposed a general framework for distributional similarity that mainly consists of the notions of what they call Precision and Recall. $$$$$ A General Framework For Distributional Similarity
Weeds and Weir (2003) proposed a general framework for distributional similarity that mainly consists of the notions of what they call Precision and Recall. $$$$$ Application-based evaluation tasks have been proposed, yet it is not clear (Weeds and Weir, 2003) whether there is or should be one distributional similarity measure which outperforms all other distributional similarity measures on all tasks and for all words.

title=Textual_Entailment_Resource_Pool 69 To date, most distributional similarity research concentrated on symmetric measures, such as the widely cited and competitive (as shown in (Weeds and Weir, 2003)) LIN measure (Lin, 1998): LIN (u, v)=? f? FV u? FV v [w u (f)+ w v (f)]? f? FV u w u (f)+? f? FV v w v (f) where FV x is the feature vector of a word x and w x (f) is the weight of the feature f in that word? s vector, set to their point wise mutual information. $$$$$ Lin (1998)) to propose that distributional similarity might be used as a predictor of semantic similarity.
title=Textual_Entailment_Resource_Pool 69 To date, most distributional similarity research concentrated on symmetric measures, such as the widely cited and competitive (as shown in (Weeds and Weir, 2003)) LIN measure (Lin, 1998): LIN (u, v)=? f? FV u? FV v [w u (f)+ w v (f)]? f? FV u w u (f)+? f? FV v w v (f) where FV x is the feature vector of a word x and w x (f) is the weight of the feature f in that word? s vector, set to their point wise mutual information. $$$$$ Application-based evaluation tasks have been proposed, yet it is not clear (Weeds and Weir, 2003) whether there is or should be one distributional similarity measure which outperforms all other distributional similarity measures on all tasks and for all words.

 $$$$$ Accordingly, verb v will be considered to be a feature of noun n if the probability of their cooccurrence is greater than would be expected if verbs and nouns occurred independently.
 $$$$$ We would like to thank John Carroll for the use of his parser, Adam Kilgarriff and Bill Keller for valuable discussions and the UK EPSRC for its studentship to the first author.

For this reason, a new approach could be envisaged for this task, in the direction of the work by (Weeds and Weir, 2003), by building rankings of similarity for each verb. $$$$$ Application-based evaluation tasks have been proposed, yet it is not clear (Weeds and Weir, 2003) whether there is or should be one distributional similarity measure which outperforms all other distributional similarity measures on all tasks and for all words.
For this reason, a new approach could be envisaged for this task, in the direction of the work by (Weeds and Weir, 2003), by building rankings of similarity for each verb. $$$$$ Since we use the same data and methodology as in earlier work, some detail is omitted in the subsequent discussion but full details and rationale can be found in Weeds and Weir (2003).

As a case study, we used our evaluation methodology to compare four methods for learning entailment rules between predicates: DIRT (Lin and Pantel,2001), Cover (Weeds and Weir, 2003), BInc (Szpek tor and Dagan, 2008) and Berant et al (2010). $$$$$ Application-based evaluation tasks have been proposed, yet it is not clear (Weeds and Weir, 2003) whether there is or should be one distributional similarity measure which outperforms all other distributional similarity measures on all tasks and for all words.
As a case study, we used our evaluation methodology to compare four methods for learning entailment rules between predicates: DIRT (Lin and Pantel,2001), Cover (Weeds and Weir, 2003), BInc (Szpek tor and Dagan, 2008) and Berant et al (2010). $$$$$ Since we use the same data and methodology as in earlier work, some detail is omitted in the subsequent discussion but full details and rationale can be found in Weeds and Weir (2003).
