The use of predicate-argument structure has been explored by Ponzetto and Strube (2006b; 2006a). $$$$$ Kehler et al. (2004) observe no significant improvement due to predicate argument statistics.
The use of predicate-argument structure has been explored by Ponzetto and Strube (2006b; 2006a). $$$$$ Binarizing the features — i.e. do REi and REj have the same argument or predicate label with respect to their closest predicate?

This last conjecture is somewhat validated by Ponzetto and Strube (2006b), who reported that including predicate argument pairs as features improved the performance of a coreference resolver. $$$$$ Kehler et al. (2004) observe no significant improvement due to predicate argument statistics.
This last conjecture is somewhat validated by Ponzetto and Strube (2006b), who reported that including predicate argument pairs as features improved the performance of a coreference resolver. $$$$$ Binarizing the features — i.e. do REi and REj have the same argument or predicate label with respect to their closest predicate?

Also, on WS-353, our hybrid sense-filtered variants and word-cos-ll obtained a correlation score higher than published results using WordNet-based measures (Jarmasz and Szpakowicz, 2003) (.33 to .35) and Wikipedia based methods (Ponzetto and Strube, 2006) (.19 to .48); and very close to the results obtained by thesaurus-based (Jarmasz and Szpakowicz, 2003) (.55) and LSA-based methods (Finkelstein et al, 2002) (.56). $$$$$ We enrich the semantic information available to the classifier by using semantic similarity measures based on the WordNet taxonomy (Pedersen et al., 2004).
Also, on WS-353, our hybrid sense-filtered variants and word-cos-ll obtained a correlation score higher than published results using WordNet-based measures (Jarmasz and Szpakowicz, 2003) (.33 to .35) and Wikipedia based methods (Ponzetto and Strube, 2006) (.19 to .48); and very close to the results obtained by thesaurus-based (Jarmasz and Szpakowicz, 2003) (.55) and LSA-based methods (Finkelstein et al, 2002) (.56). $$$$$ Therefore, the Wikipedia-based measures are to be taken as semantic relatedness measures.

However, the use of related verbs is similar in spirit to Bean and Riloff's (2004) use of patterns for inducing contextual role knowledge, and the use of semantic roles is also discussed in Ponzetto and Strube (2006). $$$$$ We investigate the use of the WordNet and Wikipedia taxonomies for extracting semantic similarity and relatedness measures, as well as semantic parsing information in terms of semantic role labeling (Gildea & Jurafsky, 2002, SRL henceforth).
However, the use of related verbs is similar in spirit to Bean and Riloff's (2004) use of patterns for inducing contextual role knowledge, and the use of semantic roles is also discussed in Ponzetto and Strube (2006). $$$$$ Additionally, we use the Wikipedia category graph.

Note that there has been a recent surge of interest in extracting world knowledge from online encyclopedias such as Wikipedia (e.g., Ponzetto and Strube (2006, 2007), Poesio et al). $$$$$ However, the literature emphasizes since the very beginning the relevance of world knowledge and inference for coreference resolution (Charniak, 1973).
Note that there has been a recent surge of interest in extracting world knowledge from online encyclopedias such as Wikipedia (e.g., Ponzetto and Strube (2006, 2007), Poesio et al). $$$$$ Luo et al. (2004), Kehler et al.

Our baseline coreference system implements the standard machine learning approach to coreference resolution (see Ng and Cardie (2002b), Ponzetto and Strube (2006), Yang and Su (2007), for instance), which consists of probabilistic classification and clustering, as described below. $$$$$ The last years have seen a boost of work devoted to the development of machine learning based coreference resolution systems (Soon et al., 2001; Ng & Cardie, 2002; Yang et al., 2003; Luo et al., 2004, inter alia).
Our baseline coreference system implements the standard machine learning approach to coreference resolution (see Ng and Cardie (2002b), Ponzetto and Strube (2006), Yang and Su (2007), for instance), which consists of probabilistic classification and clustering, as described below. $$$$$ More specifically, whether a machine learning based approach to coreference resolution can be improved and which phenomena are affected by such information.

Traditional learning-based coreference resolvers operate by training a model for classifying whether two mentions are co-referring or not (e.g., Soon et al (2001), Ng and Cardie (2002b), Kehler et al (2004), Ponzetto and Strube (2006)). $$$$$ The last years have seen a boost of work devoted to the development of machine learning based coreference resolution systems (Soon et al., 2001; Ng & Cardie, 2002; Yang et al., 2003; Luo et al., 2004, inter alia).
Traditional learning-based coreference resolvers operate by training a model for classifying whether two mentions are co-referring or not (e.g., Soon et al (2001), Ng and Cardie (2002b), Kehler et al (2004), Ponzetto and Strube (2006)). $$$$$ Luo et al. (2004), Kehler et al.

Given that WordNet is a static ontology and as such has limitation on coverage, more recently, there have been successful attempts to utilize information from much larger, collaboratively built resources such as Wikipedia (Ponzetto and Strube, 2006). $$$$$ Wikipedia mining works as follows (for an indepth description of the methods for computing semantic relatedness in Wikipedia see Strube & Ponzetto (2006))

The use of semantic knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al, 2011), and (Rahman and Ng, 2011). $$$$$ The last years have seen a boost of work devoted to the development of machine learning based coreference resolution systems (Soon et al., 2001; Ng & Cardie, 2002; Yang et al., 2003; Luo et al., 2004, inter alia).
The use of semantic knowledge for coreference resolution has been studied before in a number of works, among them (Ponzetto and Strube, 2006), (Bengtson and Roth, 2008), (Lee et al, 2011), and (Rahman and Ng, 2011). $$$$$ This is in contrast to other related works in coreference resolution (e.g.

Semantic features $$$$$ These features represent knowledge mined from WordNet and Wikipedia, as well as information about semantic role labels.
Semantic features $$$$$ Given a potential antecedent REi and a potential anaphor REQ the features are computed as follows3. those; else F. NUMBER T if both REi and REQ agree in number; else F. GENDER U if either REi or REQ have an undefined gender.

Recently, Ponzetto and Strube (2006) suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet. $$$$$ Wikipedia mining works as follows (for an indepth description of the methods for computing semantic relatedness in Wikipedia see Strube & Ponzetto (2006))

Some researchers simply use the first sense (Soon et al, 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). $$$$$ Instances are created following Soon et al. (2001).
Some researchers simply use the first sense (Soon et al, 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). $$$$$ In order to overcome the sense disambiguation problem, we factorise over all possible sense pairs

Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)). $$$$$ These features represent knowledge mined from WordNet and Wikipedia, as well as information about semantic role labels.
Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)). $$$$$ Wikipedia mining works as follows (for an indepth description of the methods for computing semantic relatedness in Wikipedia see Strube & Ponzetto (2006))

Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al, 2005), semantic roles (Ponzetto and Strube, 2006b; Kong et al, 2009), and animacy (Orasan and Evans, 2007) have also been exploited to improve coreference resolution. $$$$$ Employing SRL is closer in spirit to Ji et al. (2005), who explore the employment of the ACE 2004 relation ontology as a semantic filter.
Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al, 2005), semantic roles (Ponzetto and Strube, 2006b; Kong et al, 2009), and animacy (Orasan and Evans, 2007) have also been exploited to improve coreference resolution. $$$$$ Luo et al. (2004), Kehler et al.

We use Wikipedia differently from (Ponzetto and Strube, 2006) who focus on using WikiRelate, a Wikipedia-based relatedness metric (Strube and Ponzetto, 2006). $$$$$ Wikipedia mining works as follows (for an indepth description of the methods for computing semantic relatedness in Wikipedia see Strube & Ponzetto (2006))

 $$$$$ During testing each text is processed from left to right

As a result, researchers have re-adopted the once-popular knowledge-rich approach ,investigating a variety of semantic knowledge sources for common noun resolution, such as the semantic relations between two NPs (e.g., Ji et al (2005)), their semantic similarity as computed using WordNet (e.g., Poesio et al (2004)) or Wikipedia (Ponzetto and Strube, 2006), and the contextual role played by an NP (see Bean and Riloff (2004)). $$$$$ Luo et al. (2004), Kehler et al.
As a result, researchers have re-adopted the once-popular knowledge-rich approach ,investigating a variety of semantic knowledge sources for common noun resolution, such as the semantic relations between two NPs (e.g., Ji et al (2005)), their semantic similarity as computed using WordNet (e.g., Poesio et al (2004)) or Wikipedia (Ponzetto and Strube, 2006), and the contextual role played by an NP (see Bean and Riloff (2004)). $$$$$ We enrich the semantic information available to the classifier by using semantic similarity measures based on the WordNet taxonomy (Pedersen et al., 2004).

Following Ponzetto and Strube (2006), we consider an anaphoric reference, NPi, correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition. $$$$$ Negative instances are obtained by pairing the anaphoric REs with any RE occurring between the anaphor and the antecedent.
Following Ponzetto and Strube (2006), we consider an anaphoric reference, NPi, correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition. $$$$$ A RE is said to be correctly resolved when both it and its direct antecedent are placed by the key in the same coreference class.

Following previous work (e.g., Soon et al (2001) and Ponzetto and Strube (2006)), we generate training instances as follows $$$$$ Instances are created following Soon et al. (2001).
Following previous work (e.g., Soon et al (2001) and Ponzetto and Strube (2006)), we generate training instances as follows $$$$$ We create a positive training instance from each pair of adjacent coreferent REs.

In alternative, it has been recently shown that Wikipedia can be a promising source of semantic knowledge for coreference resolution between nominals (Ponzetto and Strube, 2006). $$$$$ Exploiting Semantic Role Labeling WordNet And Wikipedia For Coreference Resolution
In alternative, it has been recently shown that Wikipedia can be a promising source of semantic knowledge for coreference resolution between nominals (Ponzetto and Strube, 2006). $$$$$ This paper explores whether coreference resolution can benefit from semantic knowledge sources.
