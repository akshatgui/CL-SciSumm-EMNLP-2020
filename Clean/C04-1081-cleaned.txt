A simple approach would be to let a character be a token (i.e., character-based Begin/Inside tagging) so that boundary ambiguity never occur (Peng et al, 2004). $$$$$ The open features include a large word list (containing single and multiple-character words), a character list, and additional topic or part-of-speech character lexicons obtained from various sources.
A simple approach would be to let a character be a token (i.e., character-based Begin/Inside tagging) so that boundary ambiguity never occur (Peng et al, 2004). $$$$$ unit character (e.g.,G,?)

Peng et al (2004) uses the CRFs to address this issue. $$$$$ Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.
Peng et al (2004) uses the CRFs to address this issue. $$$$$ Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.

In last part of the experiments, the generality of the datasets and the toughness of our system are tested (Peng et al, 2004). $$$$$ See Peng and McCallum (2004) for more details and further experiments.
In last part of the experiments, the generality of the datasets and the toughness of our system are tested (Peng et al, 2004). $$$$$ The list of lexicons used in our experiments is shown in Figure 1.

The superiority of CRFs on Chinese information processing was also demonstrated in word segmentation (Peng et al 2004). $$$$$ Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.
The superiority of CRFs on Chinese information processing was also demonstrated in word segmentation (Peng et al 2004). $$$$$ These beneficialproperties suggests that CRFs are a promising ap proach for Chinese word segmentation.New word detection is one of the most impor tant problems in Chinese information processing.Many machine learning approaches have been pro posed (Chen and Bai, 1998; Wu and Jiang, 2000; Nie et al, 1995).

Different from (Peng et al, 2004), we represent the positions of a hanzi (Chinese character) with four different tags: B for a hanzi that starts a word, I for a hanzi that continues the word, F for a hanzi that ends the word, S for a hanzi that occurs as a single-character word. $$$$$ The open features include a large word list (containing single and multiple-character words), a character list, and additional topic or part-of-speech character lexicons obtained from various sources.
Different from (Peng et al, 2004), we represent the positions of a hanzi (Chinese character) with four different tags: B for a hanzi that starts a word, I for a hanzi that continues the word, F for a hanzi that ends the word, S for a hanzi that occurs as a single-character word. $$$$$ These datasets represent four different segmentation standards.

CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of Peng et al (2004). $$$$$ Chinese Segmentation And New Word Detection Using Conditional Random Fields
CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of Peng et al (2004). $$$$$ This indicates that CRFs are a viable model for robust Chinese word segmentation.

A popular discriminative model that have been used for this task is the conditional random fields (CRFs) (Lafferty et al, 2001), starting with the model of Peng et al (2004). $$$$$ Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.
A popular discriminative model that have been used for this task is the conditional random fields (CRFs) (Lafferty et al, 2001), starting with the model of Peng et al (2004). $$$$$ Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al, 2001).

Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al, 2004), (Tseng et al, 2005), (Low et al., 2005), (Zhao et al, 2006). $$$$$ Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.
Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al, 2004), (Tseng et al, 2005), (Low et al., 2005), (Zhao et al, 2006). $$$$$ S01 is one of the best segmentation systems in mainland China (Zhang et al., 2003).

CRF is a statistical sequence modeling framework introduced by Lafferty et al (2001), and was first used for the Chinese word segmentation task by Peng et al (2004), who treated word segmentation as a binary decision task. $$$$$ Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.
CRF is a statistical sequence modeling framework introduced by Lafferty et al (2001), and was first used for the Chinese word segmentation task by Peng et al (2004), who treated word segmentation as a binary decision task. $$$$$ Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al, 2001).

We follow the format from Peng et al (2004). $$$$$ See Peng and McCallum (2004) for more details and further experiments.
We follow the format from Peng et al (2004). $$$$$ S01 is one of the best segmentation systems in mainland China (Zhang et al., 2003).

represents the CRF model from Peng et al (2004), and the last row represents our model. $$$$$ Zhang et al (2003) use a hierarchical hidden Markov Model to incorporate lexical knowledge.
represents the CRF model from Peng et al (2004), and the last row represents our model. $$$$$ Our results are in the last row.

RMNs are the special case of Conditional Markov Networks (or Conditional Random Fields) in which graph structure and parameter tying are determined by SQL-like form. As for the marginal probability to use as a confidence measure shown in Figure 4, Peng et al (2004) has applied linear-chain CRFs to Chinese word segmentation. $$$$$ Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.
RMNs are the special case of Conditional Markov Networks (or Conditional Random Fields) in which graph structure and parameter tying are determined by SQL-like form. As for the marginal probability to use as a confidence measure shown in Figure 4, Peng et al (2004) has applied linear-chain CRFs to Chinese word segmentation. $$$$$ Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al, 2001).

Aiming to improve both tasks, work by Peng et al (2004) and Sun et al (2012) conduct segmentation and detection sequentially, but in an iterative manner rather than joint. $$$$$ We consider here new word detection as an integral part of segmentation, aimingto improve both segmentation and new word detec tion: detected new words are added to the word list lexicon in order to improve segmentation; improved segmentation can potentially further improve new word detection.
Aiming to improve both tasks, work by Peng et al (2004) and Sun et al (2012) conduct segmentation and detection sequentially, but in an iterative manner rather than joint. $$$$$ S01 is one of the best segmentation systems in mainland China (Zhang et al., 2003).

Work by Peng et al (2004) first used this framework for Chinese word segmentation by treating it as a binary decision task, such that each character is labeled either as the beginning of a word or the continuation of one. $$$$$ Un fortunately, building a Chinese word segmentation system is complicated by the fact that there is no standard definition of word boundaries in Chinese.
Work by Peng et al (2004) first used this framework for Chinese word segmentation by treating it as a binary decision task, such that each character is labeled either as the beginning of a word or the continuation of one. $$$$$ Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.

3.2.1 Results on Sighanbakeoff 2003 Experiments done while developing this system showed that its performance was significantly better than that of Peng et al (2004). $$$$$ See Peng and McCallum (2004) for more details and further experiments.
3.2.1 Results on Sighanbakeoff 2003 Experiments done while developing this system showed that its performance was significantly better than that of Peng et al (2004). $$$$$ The quality of lexicons can affect the performance of CRFs significantly.

 $$$$$ L? = ? i logP?(yi

Peng et al (2004) defined the word segmentation problem as labeling each character as whether or not the previous character boundary of the current character is a word boundary. $$$$$ unit character (e.g.,G,?)
Peng et al (2004) defined the word segmentation problem as labeling each character as whether or not the previous character boundary of the current character is a word boundary. $$$$$ Figure 1: Lexicons used in our experiments C?2: second previous character in lexicon C?1: previous character in lexicon C1: next character in lexicon C2: second next character in lexicon C0C1: current and next character in lexicon C?1C0: current and previous character in lexicon C?2C?1: previous two characters in lexicon C?1C0C1: previous, current, and next character in the lexicon Figure 2: Feature conjunctions used in experiments use feature conjunctions in both the open and closed tests, as listed Figure 2.

We also used lexical features consulting a dictionary: one is to check if any of the above defined character n-grams appear in a dictionary (Peng et al, 2004), and the other is to check if there are any words in the dictionary that start or end at the current character boundary. $$$$$ Approaches to Chinese segmentation fall roughly into two categories: heuristic dictionary-based methods and statistical machine learning methods.In dictionary-based methods, a predefined dictio nary is used along with hand-generated rules for segmenting input sequence (Wu, 1999).
We also used lexical features consulting a dictionary: one is to check if any of the above defined character n-grams appear in a dictionary (Peng et al, 2004), and the other is to check if there are any words in the dictionary that start or end at the current character boundary. $$$$$ Figure 1: Lexicons used in our experiments C?2: second previous character in lexicon C?1: previous character in lexicon C1: next character in lexicon C2: second next character in lexicon C0C1: current and next character in lexicon C?1C0: current and previous character in lexicon C?2C?1: previous two characters in lexicon C?1C0C1: previous, current, and next character in the lexicon Figure 2: Feature conjunctions used in experiments use feature conjunctions in both the open and closed tests, as listed Figure 2.

text chunking model (Ramshaw and Marcus, 1995), which has been previously applied to Chinese segmentation (Peng et al, 2004). $$$$$ These beneficialproperties suggests that CRFs are a promising ap proach for Chinese word segmentation.New word detection is one of the most impor tant problems in Chinese information processing.Many machine learning approaches have been pro posed (Chen and Bai, 1998; Wu and Jiang, 2000; Nie et al, 1995).
text chunking model (Ramshaw and Marcus, 1995), which has been previously applied to Chinese segmentation (Peng et al, 2004). $$$$$ This indicates that CRFs are a viable model for robust Chinese word segmentation.

Different from (Peng et al, 2004), we represent the positions of a hanzi (Chinese character) with four different tags: B for a hanzi 196 that starts a word, I for a hanzi that continues the word, F for a hanzi that ends the word, S for a hanzi that occurs as a single-character word. $$$$$ The open features include a large word list (containing single and multiple-character words), a character list, and additional topic or part-of-speech character lexicons obtained from various sources.
Different from (Peng et al, 2004), we represent the positions of a hanzi (Chinese character) with four different tags: B for a hanzi 196 that starts a word, I for a hanzi that continues the word, F for a hanzi that ends the word, S for a hanzi that occurs as a single-character word. $$$$$ These datasets represent four different segmentation standards.
