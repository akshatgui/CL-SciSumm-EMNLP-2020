The concept of compatible coverage vectors for the locations of translated words becomes the notion of reachability between frontier nodes in the lattice (Dyer et al, 2008). $$$$$ For example, assuming the third lattice in Figure 1 is our input, if the edge with word a is translated, this will cover two untranslated nodes [0,1] in the coverage vector, even though it is only a single word.
The concept of compatible coverage vectors for the locations of translated words becomes the notion of reachability between frontier nodes in the lattice (Dyer et al, 2008). $$$$$ In the sentence decoder, any translation of any span of untranslated words is an allowable extension of a partial translation hypothesis, provided that the coverage vectors of the extension and the partial hypothesis do not intersect.

We also plan to jointly optimize MT and name tagging by propagating multiple word segmentation and name annotation hypotheses in lattice structure to statistical MT and conduct lattice based decoding (Dyer et al, 2008). $$$$$ Chinese word segmentation.
We also plan to jointly optimize MT and name tagging by propagating multiple word segmentation and name annotation hypotheses in lattice structure to statistical MT and conduct lattice based decoding (Dyer et al, 2008). $$$$$ Lattice Translation.

In applications like the one described by Dyer et al (2008), where several different segmenters for Chinese are combined to create the lattice, this is not possible. $$$$$ Although the number of source phrases in a word lattice can be exponential in the number of nodes, enumerating the possible translations of every span in a lattice is in practice tractable, as described by Bertoldi et al. (2007).
In applications like the one described by Dyer et al (2008), where several different segmenters for Chinese are combined to create the lattice, this is not possible. $$$$$ Figure 5 illustrates a lattice based on three different segmentations.

Dyer et al (2008) use it to encode different Chinese word segmentations or Arabic morphological analyses. $$$$$ Arabic morphological variation.
Dyer et al (2008) use it to encode different Chinese word segmentations or Arabic morphological analyses. $$$$$ Dyer (2007) uses confusion networks to encode morphological alternatives in Czech-English translation, and Xu et al. (2005) takes an approach very similar to ours for Chinese-English translation and encodes multiple word segmentations in a lattice, but which is decoded with a conventionally trained translation model and without a sophisticated reordering model.

Our work differs from (Dyer et al, 2008) in that we explicitly distinguish the various preprocessing types in the lattice so that we can define specific path features and lexicalize the lattice path probabilities within the phrase model. $$$$$ In phrase based translation, distortion is modeled explicitly.
Our work differs from (Dyer et al, 2008) in that we explicitly distinguish the various preprocessing types in the lattice so that we can define specific path features and lexicalize the lattice path probabilities within the phrase model. $$$$$ Lattice Translation.

It was noted by Dyer et al (2008) that the standard distance-based reordering model needs to be redefined for lattice input. $$$$$ We present a description of the decoding process for a word lattice using a representative FST model, the phrase-based translation model described in Koehn et al. (2003).
It was noted by Dyer et al (2008) that the standard distance-based reordering model needs to be redefined for lattice input. $$$$$ Additionally, we have shown that although word lattices complicate modeling of word reordering, a simple heuristic offers good performance and enables many standard distortion models to be used directly with lattice input.

Using the shortest path within the lattice is reported to have better performance in (Dyer et al, 2008), however we did not implement it due to time constraints. $$$$$ Since this function is not dependent on the exact path chosen, it can be computed in advance of decoding using an allpairs shortest path algorithm (Cormen et al., 1989).
Using the shortest path within the lattice is reported to have better performance in (Dyer et al, 2008), however we did not implement it due to time constraints. $$$$$ Saleem et al. (2005) and Bertoldi et al.

Our word lattices are similar to those used by Dyer et al (2008) for handling word segmentation in Chinese and Arabic. $$$$$ We tested the effect of the distance metric on translation quality using Chinese word segmentation lattices (Section 4.1, below) using both a hierarchical and phrase-based system modified to translate word lattices.
Our word lattices are similar to those used by Dyer et al (2008) for handling word segmentation in Chinese and Arabic. $$$$$ Chinese word segmentation.

Recent studies have shown that SMT systems can benefit from widening the annotation pipeline: using packed forests instead of 1-best trees (Mi and Huang,2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and weighted alignment matrices instead of 1-best alignments (Liu et al, 2009). $$$$$ The ‘noisier channel’ model of machine translation has been widely used in spoken language translation as an alternative to selecting the single-best hypothesis from an ASR system and translating it (Ney, 1999; Casacuberta et al., 2004; Zhang et al., 2005; Saleem et al., 2005; Matusov et al., 2005; Bertoldi et al., 2007; Mathias, 2007).
Recent studies have shown that SMT systems can benefit from widening the annotation pipeline: using packed forests instead of 1-best trees (Mi and Huang,2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and weighted alignment matrices instead of 1-best alignments (Liu et al, 2009). $$$$$ Saleem et al. (2005) and Bertoldi et al.

Lattice represent the system implemented as Dyer et al, (2008). $$$$$ The ‘noisier channel’ model of machine translation has been widely used in spoken language translation as an alternative to selecting the single-best hypothesis from an ASR system and translating it (Ney, 1999; Casacuberta et al., 2004; Zhang et al., 2005; Saleem et al., 2005; Matusov et al., 2005; Bertoldi et al., 2007; Mathias, 2007).
Lattice represent the system implemented as Dyer et al, (2008). $$$$$ Saleem et al. (2005) and Bertoldi et al.

Same as Dyer et al, (2008), we also extracted rules from a combined bilingual corpus which contains three copies from different segmenters. $$$$$ For an additional datapoint, we added a lexicalized reordering model that models the probability of each phrase pair appearing in three different orientations (swap, monotone, other) in the training corpus (Koehn et al., 2005).
Same as Dyer et al, (2008), we also extracted rules from a combined bilingual corpus which contains three copies from different segmenters. $$$$$ Saleem et al. (2005) and Bertoldi et al.

Du et al (2010), in this proceedings, explore the use of source paraphrases without targeting apparent mistranslations, using lattice translation (Dyer et al, 2008) to efficiently represent and decode the resulting very large space of paraphrase alternatives. $$$$$ The ‘noisier channel’ model of machine translation has been widely used in spoken language translation as an alternative to selecting the single-best hypothesis from an ASR system and translating it (Ney, 1999; Casacuberta et al., 2004; Zhang et al., 2005; Saleem et al., 2005; Matusov et al., 2005; Bertoldi et al., 2007; Mathias, 2007).
Du et al (2010), in this proceedings, explore the use of source paraphrases without targeting apparent mistranslations, using lattice translation (Dyer et al, 2008) to efficiently represent and decode the resulting very large space of paraphrase alternatives. $$$$$ Saleem et al. (2005) and Bertoldi et al.

Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al, 2008) in order to allow a compact representation of alternative inputs to an SMT system. $$$$$ Lattices allow the decoder to make decisions about what granularity of segmentation to use subsententially.
Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al, 2008) in order to allow a compact representation of alternative inputs to an SMT system. $$$$$ Finally, the system described by Zhang et al. (2005) uses IBM Model 4 features to translate lattices.

All of the systems we present use the lattice input format to Moses (Dyer et al, 2008), including the baselines which do not need them. $$$$$ We adapted the Moses phrase-based decoder to translate word lattices (Koehn et al., 2007).
All of the systems we present use the lattice input format to Moses (Dyer et al, 2008), including the baselines which do not need them. $$$$$ Bertoldi et al. (2007) solve the problem by requiring that their input be in the format of a confusion network, which enables the standard distortion penalty to be used.

Recently, several studies have shown that offering more alternatives of annotations to SMT systems will result in significant improvements, such as replacing 1-best trees with packed forests (Miet al, 2008) and replacing 1-best word segmentations with word lattices (Dyer et al, 2008). $$$$$ Today, virtually all statistical translation systems seek the best hypothesis e for a given input f in the source language, according to consider all possibilities for f by encoding the alternatives compactly as a confusion network or lattice (Bertoldi et al., 2007; Bertoldi and Federico, 2005; Koehn et al., 2007).
Recently, several studies have shown that offering more alternatives of annotations to SMT systems will result in significant improvements, such as replacing 1-best trees with packed forests (Miet al, 2008) and replacing 1-best word segmentations with word lattices (Dyer et al, 2008). $$$$$ The ‘noisier channel’ model of machine translation has been widely used in spoken language translation as an alternative to selecting the single-best hypothesis from an ASR system and translating it (Ney, 1999; Casacuberta et al., 2004; Zhang et al., 2005; Saleem et al., 2005; Matusov et al., 2005; Bertoldi et al., 2007; Mathias, 2007).

Recent studies has shown that SMT systems can benefit from making the annotation pipeline wider: using packed forests instead of 1-best trees (Mi et al, 2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and n-best alignments instead of 1-best alignments (Venugopal et al, 2008). $$$$$ The ‘noisier channel’ model of machine translation has been widely used in spoken language translation as an alternative to selecting the single-best hypothesis from an ASR system and translating it (Ney, 1999; Casacuberta et al., 2004; Zhang et al., 2005; Saleem et al., 2005; Matusov et al., 2005; Bertoldi et al., 2007; Mathias, 2007).
Recent studies has shown that SMT systems can benefit from making the annotation pipeline wider: using packed forests instead of 1-best trees (Mi et al, 2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and n-best alignments instead of 1-best alignments (Venugopal et al, 2008). $$$$$ Saleem et al. (2005) and Bertoldi et al.

As lattice is a more general form of confusion network (Dyer et al, 2008), we expect that replacing confusion networks with lattices will further improve system combination. $$$$$ Today, virtually all statistical translation systems seek the best hypothesis e for a given input f in the source language, according to consider all possibilities for f by encoding the alternatives compactly as a confusion network or lattice (Bertoldi et al., 2007; Bertoldi and Federico, 2005; Koehn et al., 2007).
As lattice is a more general form of confusion network (Dyer et al, 2008), we expect that replacing confusion networks with lattices will further improve system combination. $$$$$ Bertoldi et al. (2007) solve the problem by requiring that their input be in the format of a confusion network, which enables the standard distortion penalty to be used.

Our implementation's runtime and memory overhead is proportional to the size of the lattice, rather than the number of paths in the lattice (Dyer et al, 2008). $$$$$ Although the number of source phrases in a word lattice can be exponential in the number of nodes, enumerating the possible translations of every span in a lattice is in practice tractable, as described by Bertoldi et al. (2007).
Our implementation's runtime and memory overhead is proportional to the size of the lattice, rather than the number of paths in the lattice (Dyer et al, 2008). $$$$$ Lattice Translation.

Lattice parsing is not new to translation (Dyer et al, 2008), but to our knowledge it has not been used in this way. $$$$$ Lattice Translation.
Lattice parsing is not new to translation (Dyer et al, 2008), but to our knowledge it has not been used in this way. $$$$$ The ‘noisier channel’ model of machine translation has been widely used in spoken language translation as an alternative to selecting the single-best hypothesis from an ASR system and translating it (Ney, 1999; Casacuberta et al., 2004; Zhang et al., 2005; Saleem et al., 2005; Matusov et al., 2005; Bertoldi et al., 2007; Mathias, 2007).

Dyer et al (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. $$$$$ Our experiments evaluating the approach demonstrate substantial gains for Chinese- English and Arabic-English translation.
Dyer et al (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. $$$$$ Lattice Translation.
