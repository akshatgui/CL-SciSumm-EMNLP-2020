Recent studies have also developed approaches to summarize conversations (Murray and Carenini, 2008) and to model conversation structures (dialogue acts) from online Twitter conversations (Ritter et al, 2010). $$$$$ Unsupervised Modeling of Twitter Conversations
Recent studies have also developed approaches to summarize conversations (Murray and Carenini, 2008) and to model conversation structures (dialogue acts) from online Twitter conversations (Ritter et al, 2010). $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).

Ritter et al (2010) extends LMHMM to allow words to be emitted from two additional sources: the topic of current dialogue, or a background LM shared across all dialogues. $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).
Ritter et al (2010) extends LMHMM to allow words to be emitted from two additional sources: the topic of current dialogue, or a background LM shared across all dialogues. $$$$$ Rather than attempt to set them using an expensive grid search, we treat the concentration parameters as additional hidden variables and sample each in turn, conditioned on the current assignment to all other variables.

Ritter et al (2010) finds these alternate sources are important in non-task-oriented domains, where events are diffuse and fleeting. $$$$$ Automatic detection of dialogue structure is an important first step toward deep understanding of human conversations.
Ritter et al (2010) finds these alternate sources are important in non-task-oriented domains, where events are diffuse and fleeting. $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).

Ritter et al (2010) proposes an evaluation based on rank correlation coefficient, which measures the degree of similarity between any two orderings over sequential data. $$$$$ Therefore, we also propose a novel quantitative evaluation that measures the intrinsic quality of a conversation model by its ability to predict the ordering of posts in a conversation.
Ritter et al (2010) proposes an evaluation based on rank correlation coefficient, which measures the degree of similarity between any two orderings over sequential data. $$$$$ The Kendall r rank correlation coefficient measures the similarity between two permutations based on their agreement in pairwise orderings: where n+ is the number of pairs that share the same order in both permutations, and n_ is the number that do not.

Ritter et al (2010) limits their dataset by choosing Twitter dialogues containing 3 to 6 posts (utterances), making it tractable to enumerate all permutations. $$$$$ The resulting corpus consists of about 1.3 million conversations, with each conversation containing between 2 and 243 posts.
Ritter et al (2010) limits their dataset by choosing Twitter dialogues containing 3 to 6 posts (utterances), making it tractable to enumerate all permutations. $$$$$ For each conversation in the test set, we generate all n! permutations of the posts.

To overcome this, we plan to use an unsupervised learning approach to discover dialogue acts (Ritter et al, 2010). $$$$$ We propose the first unsupervised approach to the problem of modeling dialogue acts in an open domain.
To overcome this, we plan to use an unsupervised learning approach to discover dialogue acts (Ritter et al, 2010). $$$$$ We propose two models to discover dialogue acts in an unsupervised manner.

To date, our paper most closely relates to works on semantic role labeling (SRL) on social media (Liu et al., 2010) and conversation modeling (Ritter et al, 2010). $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).
To date, our paper most closely relates to works on semantic role labeling (SRL) on social media (Liu et al., 2010) and conversation modeling (Ritter et al, 2010). $$$$$ Dialogue act tagging has traditionally followed an annotate-train-test paradigm, which begins with the design of annotation guidelines, followed by the collection and labeling of corpora (Jurafsky et al., 1997; Dhillon et al., 2004).

On a different ground, Ritter et al (2010) propose a probabilistic model to discover dialogue acts in Twitter conversations and to classify tweets in a conversation according to those acts. $$$$$ We propose two models to discover dialogue acts in an unsupervised manner.
On a different ground, Ritter et al (2010) propose a probabilistic model to discover dialogue acts in Twitter conversations and to classify tweets in a conversation according to those acts. $$$$$ Our goals are not so different: we wish to discover the sequential dialogue structure of conversation.

Twitter also provides a wealth of user dialog, and a variety of dialog acts have been observed (Ritter et al, 2010) and predicted (Ritter et al, 2011). $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).
Twitter also provides a wealth of user dialog, and a variety of dialog acts have been observed (Ritter et al, 2010) and predicted (Ritter et al, 2011). $$$$$ Only then can one train a tagger to automatically recognize dialogue acts (Stolcke et al., 2000).

Examples of such approaches include methods for conversation structure analysis (Ritter et al, 2010) and exploration of geographic language variation (Eisenstein et al, 2010) from Twitter messages. $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).
Examples of such approaches include methods for conversation structure analysis (Ritter et al, 2010) and exploration of geographic language variation (Eisenstein et al, 2010) from Twitter messages. $$$$$ Similar datasets include the NUS SMS corpus (How and Kan, 2005), several IRC chat corpora (Elsner and Charniak, 2008; Forsyth and Martell, 2007), and blog datasets (Yano et al., 2009; Gamon et al., 2008), which can display conversational structure in the blog comments.

Second, we employ a MIRA-based binary classifier (Ritter et al, 2010) to predict whether a message mentions a concert event. $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).
Second, we employ a MIRA-based binary classifier (Ritter et al, 2010) to predict whether a message mentions a concert event. $$$$$ As computing this probability exactly is intractable in our model, we employ a recently proposed Chibbstyle estimator (Murray and Salakhutdinov, 2008; Wallach et al., 2009).

Twitter has previously been proposed as a candidate for modeling conversations, see for example Ritter et al (2010). $$$$$ Unsupervised Modeling of Twitter Conversations
Twitter has previously been proposed as a candidate for modeling conversations, see for example Ritter et al (2010). $$$$$ As computing this probability exactly is intractable in our model, we employ a recently proposed Chibbstyle estimator (Murray and Salakhutdinov, 2008; Wallach et al., 2009).

In the context of Twitter conversations, Ritter et al (2010) suggests using dialogue act tags as a middle layer towards conversation reconstruction. $$$$$ Unsupervised Modeling of Twitter Conversations
In the context of Twitter conversations, Ritter et al (2010) suggests using dialogue act tags as a middle layer towards conversation reconstruction. $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).

Specifically, we build off the Bayesian block HMMs used by Ritter et al (2010) for modeling Twitter conversations, which will be our primary baseline. $$$$$ Unsupervised Modeling of Twitter Conversations
Specifically, we build off the Bayesian block HMMs used by Ritter et al (2010) for modeling Twitter conversations, which will be our primary baseline. $$$$$ These acts are useful in many applications, including conversational agents (Wilks, 2006), dialogue systems (Allen et al., 2007), dialogue summarization (Murray et al., 2006), and flirtation detection (Ranganath et al., 2009).

We show that M4 increases thread reconstruction accuracy by up to 15% compared to the HMM of Ritter et al (2010), and we reduce variation of information against speech act annotations by an average of 18% from HMM and LDA baselines. $$$$$ The Twitter API provides a link from each reply to the post it is responding to, allowing accurate thread reconstruction without requiring a conversation disentanglement step (Elsner and Charniak, 2008).
We show that M4 increases thread reconstruction accuracy by up to 15% compared to the HMM of Ritter et al (2010), and we reduce variation of information against speech act annotations by an average of 18% from HMM and LDA baselines. $$$$$ There is reason to believe that integrating out multinomials and using sparse priors will improve the performance of the conversation model, as improvements have been observed when using a Bayesian HMM for unsupervised part-of-speech tagging (Goldwater and Griffiths, 2007).

Under the block HMM, as utilized by Ritter et al (2010), messages in a conversation flow according to a Markov process, where the words of messages are generated according to language models associated with a state in a hidden Markov model. $$$$$ Woszczyna and Waibel (1994) propose an unsupervised Hidden Markov Model (HMM) for dialogue structure in a meeting scheduling domain, but model dialogue state at the word level.
Under the block HMM, as utilized by Ritter et al (2010), messages in a conversation flow according to a Markov process, where the words of messages are generated according to language models associated with a state in a hidden Markov model. $$$$$ A news story is modeled by first generating a sequence of hidden topics according to a Markov model, with each topic generating an observed sentence according to a topic-specific language model.

If it is desired to have a large number of latent topics as is common in LDA, this model could be combined with a standard topic model without sequential dependencies, as explored by Ritter et al (2010). $$$$$ A news story is modeled by first generating a sequence of hidden topics according to a Markov model, with each topic generating an observed sentence according to a topic-specific language model.
If it is desired to have a large number of latent topics as is common in LDA, this model could be combined with a standard topic model without sequential dependencies, as explored by Ritter et al (2010). $$$$$ To that end, we adopt a Latent Dirichlet Allocation, or LDA, framework (Blei et al., 2003) similar to approaches used recently in summarization (Daum´e III and Marcu, 2006; Haghighi and Vanderwende, 2009).

Unsupervised HMMs were applied to conversational data by Ritter et al (2010) who experimented with Twitter conversations. $$$$$ Unsupervised Modeling of Twitter Conversations
Unsupervised HMMs were applied to conversational data by Ritter et al (2010) who experimented with Twitter conversations. $$$$$ We have presented an approach that allows the unsupervised induction of dialogue structure from naturally-occurring open-topic conversational data.

Second, we use the Twitter data set created by Ritter et al (2010). $$$$$ An initial conversation model can be created by simply applying the content modeling framework to conversation data.
Second, we use the Twitter data set created by Ritter et al (2010). $$$$$ Smoothing parameters are set using grid search on a development set.

Our work is motivated by the Bayesian HMM approach of Ritter et al (2010) - the model we refer to as the block HMM (BHMM) - and we consider this our primary baseline. $$$$$ Woszczyna and Waibel (1994) propose an unsupervised Hidden Markov Model (HMM) for dialogue structure in a meeting scheduling domain, but model dialogue state at the word level.
Our work is motivated by the Bayesian HMM approach of Ritter et al (2010) - the model we refer to as the block HMM (BHMM) - and we consider this our primary baseline. $$$$$ There is reason to believe that integrating out multinomials and using sparse priors will improve the performance of the conversation model, as improvements have been observed when using a Bayesian HMM for unsupervised part-of-speech tagging (Goldwater and Griffiths, 2007).
