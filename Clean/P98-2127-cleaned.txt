 $$$$$ For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.
 $$$$$ This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.

Amongst the many proposals for distributional similarity measures, (Lin, 1998) is maybe the most widely used one, while (Weeds et al, 2004) provides a typical example for recent research. $$$$$ The similarity measure can then be used to create a thesaurus.
Amongst the many proposals for distributional similarity measures, (Lin, 1998) is maybe the most widely used one, while (Weeds et al, 2004) provides a typical example for recent research. $$$$$ The measures simeosine, simdice and SiMJacard are versions of similarity measures commonly used in information retrieval (Frakes and Baeza-Yates, 1992).

This scheme utilizes the symmetric similarity measure of (Lin, 1998) to induce improved feature weights via bootstrapping. $$$$$ The similarity measure simwN is based on the proposal in (Lin, 1997).
This scheme utilizes the symmetric similarity measure of (Lin, 1998) to induce improved feature weights via bootstrapping. $$$$$ The similarity between two words is then defined as the cosine coefficient of the two feature vectors.

We will take advantage of the flexibility provided by our framework and use syntax based measure of similarity in the computation of the verb vectors, following (Lin, 1998). $$$$$ We first define a word similarity measure based on the distributional pattern of words.
We will take advantage of the flexibility provided by our framework and use syntax based measure of similarity in the computation of the verb vectors, following (Lin, 1998). $$$$$ The similarity measure simwN is based on the proposal in (Lin, 1997).

Chantree et al (2005) applied the distributional similarity proposed by Lin (1998) to coordination disambiguation. $$$$$ It was shown in (Dagan et al., 1997) that a similarity-based smoothing method achieved much better results than backoff smoothing methods in word sense disambiguation.
Chantree et al (2005) applied the distributional similarity proposed by Lin (1998) to coordination disambiguation. $$$$$ In (Dagan et al., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time.

Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). $$$$$ Bootstrapping semantics from text is one of the greatest challenges in natural language learning.
Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). $$$$$ Another application of automatically extracted similar words is to help solve the problem of data sparseness in statistical natural language processing (Dagan et al., 1994; Essen and Steinbiss, 1992).

 $$$$$ For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.
 $$$$$ This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.

 $$$$$ For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.
 $$$$$ This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.

Lin (1998) created a thesaurus using syntactic relationships with other words. $$$$$ The measure simHindiâ€ž is the same as sim H indle except that all types of dependency relationships are used, instead of just subject and object relationships.
Lin (1998) created a thesaurus using syntactic relationships with other words. $$$$$ The results show that our automatically created thesaurus is significantly closer to WordNet than Roget Thesaurus is.

Like McCarthy et al (2004) we use k= 50 and obtain our thesaurus using the distributional similarity metric described by Lin (1998). $$$$$ The similarity measure allows us to construct a thesaurus using a parsed corpus.
Like McCarthy et al (2004) we use k= 50 and obtain our thesaurus using the distributional similarity metric described by Lin (1998). $$$$$ In (Dagan et al., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time.

The thesaurus was acquired using the method described by Lin (1998). $$$$$ The similarity measure allows us to construct a thesaurus using a parsed corpus.
The thesaurus was acquired using the method described by Lin (1998). $$$$$ This paper presents a method for making this first step.

For every pair of nouns, where each noun had a total frequency in the triple data of 10 or more, we computed their distributional similarity using the measure given by Lin (1998). $$$$$ We first define a word similarity measure based on the distributional pattern of words.
For every pair of nouns, where each noun had a total frequency in the triple data of 10 or more, we computed their distributional similarity using the measure given by Lin (1998). $$$$$ We computed the pairwise similarity between all the nouns, all the verbs and all the adjectives/adverbs, using the above similarity measure.

 $$$$$ For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.
 $$$$$ This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.

As in (Lin, 1998) or (Cur ran and Moens, 2002a), this building is based on the definition of a semantic similarity measure from a corpus. $$$$$ We first define a word similarity measure based on the distributional pattern of words.
As in (Lin, 1998) or (Cur ran and Moens, 2002a), this building is based on the definition of a semantic similarity measure from a corpus. $$$$$ The similarity measure simwN is based on the proposal in (Lin, 1997).

This seems to be a reasonable compromise between the approach of (Freitag et al, 2005), in which none normalization of words is done, and the more widespread use of syntactic parsers in work such as (Lin, 1998). $$$$$ Section 4 briefly discuss future work in clustering similar words.
This seems to be a reasonable compromise between the approach of (Freitag et al, 2005), in which none normalization of words is done, and the more widespread use of syntactic parsers in work such as (Lin, 1998). $$$$$ In (Dagan et al., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time.

Finally, the results of Table 2 are compatible with those of (Lin, 1998) for instance (R-prec. = 11.6 and MAP = 8.1 with WM as reference for all entries of the thesaurus at http://webdocs.cs.ualberta.ca/lindek/Downloads/sim.tgz) if we take into account the fact that the thesaurus of Lin was built from a much larger corpus and with syntactic co-occurrences. $$$$$ The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is.
Finally, the results of Table 2 are compatible with those of (Lin, 1998) for instance (R-prec. = 11.6 and MAP = 8.1 with WM as reference for all entries of the thesaurus at http://webdocs.cs.ualberta.ca/lindek/Downloads/sim.tgz) if we take into account the fact that the thesaurus of Lin was built from a much larger corpus and with syntactic co-occurrences. $$$$$ Suppose two thesaurus entries for the same word are as follows: For example, (5) is the entry for &quot;brief (noun)&quot; in our automatically generated thesaurus and (6) and (7) are corresponding entries in WordNet thesaurus and Roget thesaurus.

For example, one of the 8 senses of company in WordNet is a visitor/visitant, which is a hyponym of person (Lin, 1998). $$$$$ For example, one of the 8 senses of &quot;company&quot; in WordNet 1.5 is a &quot;visitor/visitant&quot;, which is a hyponym of &quot;person&quot;.
For example, one of the 8 senses of company in WordNet is a visitor/visitant, which is a hyponym of person (Lin, 1998). $$$$$ For example, one can go a step further by constructing a tree structure among the most similar words so that different senses of a given word can be identified with different subtrees.

For instance, Lin (1998) used dependency relation as word features to compute word similarities from large corpora, and compared the thesaurus created in such a way with WordNet and Roget classes. $$$$$ Ours is similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed.
For instance, Lin (1998) used dependency relation as word features to compute word similarities from large corpora, and compared the thesaurus created in such a way with WordNet and Roget classes. $$$$$ The results show that our automatically created thesaurus is significantly closer to WordNet than Roget Thesaurus is.

One of the most important approaches is Lin (1998). $$$$$ It has been argued that similarity plays an important role in word acquisition (Gentner, 1982).
One of the most important approaches is Lin (1998). $$$$$ There have been many approaches to automatic detection of similar words from text corpora.

 $$$$$ For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.
 $$$$$ This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.
