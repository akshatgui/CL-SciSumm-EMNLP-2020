 $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion

On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ For this goal, we put aside the anaphoricity classifier and focus on the pairwise classifier and transitivity constraints.
On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ We build a pairwise logistic classifier, trained on all pairs of mentions, and then at test time we use an ILP solver equipped with transitivity constraints to find the most likely legal assignment to the variables which represent the pairwise decisions.1 Our results show a significant improvement compared to the naive use of the pairwise classifier.

One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ However, when encoding constraints into their ILP solver, they did not enforce transitivity.
One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ When using the MUC scorer, the ILP system always did worse than the D&B-STYLE baseline.

Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ Enforcing Transitivity in Coreference Resolution
Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ However, coreference resolution is a clustering task, and many cluster scorers already exist.

As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ For this goal, we put aside the anaphoricity classifier and focus on the pairwise classifier and transitivity constraints.
As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.

Second, we compare our cut-based approach with the five aforementioned approaches to anaphoricity determination (namely, Ng and Cardie (2002a), Ng (2004), Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008)) in terms of their effectiveness in improving a learning-based coreference system. $$$$$ Much work that followed improved upon this strategy, by improving the features (Ng and Cardie, 2002b), the type of classifier (Denis and Baldridge, 2007), and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (Ng and Cardie, 2002b).
Second, we compare our cut-based approach with the five aforementioned approaches to anaphoricity determination (namely, Ng and Cardie (2002a), Ng (2004), Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008)) in terms of their effectiveness in improving a learning-based coreference system. $$$$$ Ng and Cardie (2002a) and Ng (2004) highlight the problem of determining whether or not common noun phrases are anaphoric.

It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ When describing our model, we build upon the notation used by Denis and Baldridge (2007).
It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ For comparison, we also give the results of the COREFILP system of Denis and Baldridge (2007), which was also based on a naive pairwise classifier.

 $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion

Duplicated Finkel and Manning (2008) baseline. $$$$$ Our baseline systems are based on a logistic classifier over pairs of mentions.
Duplicated Finkel and Manning (2008) baseline. $$$$$ When using the MUC scorer, the ILP system always did worse than the D&B-STYLE baseline.

Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ However, coreference resolution is a clustering task, and many cluster scorers already exist.
Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ For all three corpora, the ILP model beat both baselines for the cluster f-score, Rand index, and variation of information metrics.

Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ More recently, Denis and Baldridge (2007) utilized an integer linear programming (ILP) solver to better combine the decisions made by these two complementary classifiers, by finding the globally optimal solution according to both classifiers.
Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ The COREF-ILP model of Denis and Baldridge (2007) took a different approach at test time

 $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion

 $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion

Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs. $$$$$ When describing our model, we build upon the notation used by Denis and Baldridge (2007).
Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs. $$$$$ Our D&B-STYLE baseline used the same test time method as Denis and Baldridge (2007), however at training time we created data for all mention pairs.

Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ However, when encoding constraints into their ILP solver, they did not enforce transitivity.
Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ The goal of the present work is simply to show that transitivity constraints are a useful source of information, which can and should be incorporated into an ILP-based coreference system.

Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ However, when encoding constraints into their ILP solver, they did not enforce transitivity.
Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ The goal of the present work is simply to show that transitivity constraints are a useful source of information, which can and should be incorporated into an ILP-based coreference system.

Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ Enforcing Transitivity in Coreference Resolution
Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ Transitive closure in this model was done implicitly.

Transitivity was also used as an information source in other fields of NLP $$$$$ Enforcing Transitivity in Coreference Resolution
Transitivity was also used as an information source in other fields of NLP $$$$$ The goal of the present work is simply to show that transitivity constraints are a useful source of information, which can and should be incorporated into an ILP-based coreference system.

see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ This is equivalent to finding the most likely assignment to each x(i,j) in Equation 2.
see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ They used an ILP solver to find an assignment for the variables, but as they note at the end of Section 5.1, it is equivalent to taking all links for which the classifier returns a probability
see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$  0.5, and so the ILP solver is not really necessary.

The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ Enforcing Transitivity in Coreference Resolution
The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ Transitive closure in this model was done implicitly.
