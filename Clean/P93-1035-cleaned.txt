Second, there is a class of techniques for learning rules from text, a recent example being Brill 1993. $$$$$ In (BM92a), distributional analysis techniques are applied to a large corpus to learn a context-free grammar.
Second, there is a class of techniques for learning rules from text, a recent example being Brill 1993. $$$$$ In this paper, we have described a new approach for learning a grammar to automatically parse text.

Other works describe systems that induce structures from corpora, but they use tagged corpora (Brill, 1993), or grammatical informations (Brent, 1993), or work with artificial samples (Elman, 1990). $$$$$ While the numbers presented above allow us to compare the transformation learner with systems trained and tested on comparable corpora, these results are all based upon the assumption that the test data is tagged fairly reliably (manually tagged text was used in all of these experiments, as well in the experiments of (PS92, SR093).)
Other works describe systems that induce structures from corpora, but they use tagged corpora (Brill, 1993), or grammatical informations (Brent, 1993), or work with artificial samples (Elman, 1990). $$$$$ We also plan to experiment with other scoring functions and control strategies for finding transformations and to use this system as a postprocessor to other grammar induction systems, learning transformations to improve their performance.

Transformation-based tagging as introduced by Brill (1993) also requires a handtagged text for training. $$$$$ Automatic Grammar Induction And Parsing Free Text

This idea is not new, but as far as we know it has been implemented in rule-based taggers and parsers, such as (Brill, 1993a), (Brill, 1993b), (Brill, 1993c) and (Ribarov, 1996), but not in models based on probability distributions. $$$$$ TRANSFORMATION-BASED
This idea is not new, but as far as we know it has been implemented in rule-based taggers and parsers, such as (Brill, 1993a), (Brill, 1993b), (Brill, 1993c) and (Ribarov, 1996), but not in models based on probability distributions. $$$$$ Unlike learners based on the inside-outside algorithm which attempt to find a grammar to maximize the probability of the training corpus in hope that this grammar will match the grammar that provides the most accurate structural descriptions, the transformation-based learner can readily use any desired success measure in learning.

 $$$$$ 4The twelve transformations can be decomposed into two structural transformations, that shown here and its converse, along with six triggering environments.
 $$$$$ We hope these future paths will lead to a trainable and very accurate parser for free text.
