The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ The extraordinary accuracy of verb detection — within a tiny fraction of the rate achieved by trained human taggers — and it's relatively low efficiency are consistent with the priorities laid out in Section 1.2.
The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ Once again, the high accuracy and low efficiency are consistent with the priorities of Section 1.2.

Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ The following two sections describe and evaluate the verb detection module and the SF detection module, respectively; the decision module, which is still being refined, will be described in a subsequent paper.
Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ The methods described above solve several important problems that had stood in the way of that goal.

Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ It might be interesting to try building a verb categorization scheme based on Church's mutual information measure, but to the best of our knowledge no such work has been reported.
Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ The ultimate goal of this work is to provide the NLP community with a substantially complete, automatically updated dictionary of sub categorization frames.

Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ Ultimately, I expect to provide a large SF dictionary to the NLP community and to train dictionaries for specific corpora.
Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ Interest in extracting lexical and especially collocational information from text has risen dramatically in the last two years, as sufficiently large corpora and sufficiently cheap computation have become available.
