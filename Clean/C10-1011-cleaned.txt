In this paper, we use the following baseline parsers: MaltParser (Nivre et al, 2007) for transition-based parsing; MSTParser (McDonald et al, 2005) (with sibling 2-edge factors) and Bohnet Parser (Bohnet, 2010) (with general 2-edge factors) for graph-based parsing; and BerkeleyParser (Petrov et al, 2006) for constituency-based parsing. $$$$$ et al, 2009).
In this paper, we use the following baseline parsers: MaltParser (Nivre et al, 2007) for transition-based parsing; MSTParser (McDonald et al, 2005) (with sibling 2-edge factors) and Bohnet Parser (Bohnet, 2010) (with general 2-edge factors) for graph-based parsing; and BerkeleyParser (Petrov et al, 2006) for constituency-based parsing. $$$$$ We combined thisparsing algorithm with the passive-aggressive perceptron algorithm (Crammer et al, 2003; McDon ald et al, 2005; Crammer et al, 2006).

Parser: We used the second-order graph-based parser available in Mate-tools12 (Bohnet, 2010). $$$$$ used cores.
Parser: We used the second-order graph-based parser available in Mate-tools12 (Bohnet, 2010). $$$$$ However, the parser would have ranked second for these languages.

 $$$$$ It updates ??v as well, whereby the algorithm additionally weights the updates by ?.
 $$$$$ 96

This version was produced with the dependency parser by Bohnet (2010), trained on the dependency conversion of TIGER by Seeker and Kuhn (2012). $$$$$ To determine why, we analyzed thetime usage of a dependency parser.
This version was produced with the dependency parser by Bohnet (2010), trained on the dependency conversion of TIGER by Seeker and Kuhn (2012). $$$$$ Maximum spanning tree dependency based parsers decomposes a dependency structure into parts known as ?factors?.

We also implement the feature mapping function as a hash kernel (Bohnet, 2010) and apply averaging (Collins, 2002), though for brevity we omit this from the pseudo code. $$$$$ Algorithm 3 shows the training algorithm forthe Hash Kernel in pseudo code.
We also implement the feature mapping function as a hash kernel (Bohnet, 2010) and apply averaging (Collins, 2002), though for brevity we omit this from the pseudo code. $$$$$ Algorithm 4 shows the paral lel feature extraction in pseudo code.

It is difficult to compare our system for LAS because most systems evaluate on gold data (part-of-speech, lemmas and morphological information) like Bohnet (2010). $$$$$ {} // thread-save data list for w1 ? 1 to

we compare our system with the MATE parser (Bohnet, 2010), an improvement over the MST parser (McDonald et al, 2005) with hash kernels, using the MELT part-of-speech tagger (Denis and Sagot, 2009) and our own lemma tiser. $$$$$ et al, 2009).
we compare our system with the MATE parser (Bohnet, 2010), an improvement over the MST parser (McDonald et al, 2005) with hash kernels, using the MELT part-of-speech tagger (Denis and Sagot, 2009) and our own lemma tiser. $$$$$ (2009), and (4) Ren et al (2009); LAS of the baseline parser and the parser with Hash Kernel.

Bohnet (2010) showed that the Hash Kernel improves parsing speed and accuracy since the parser uses additionally negative features. $$$$$ The Hash Kernel substantially improves the parsing times and takes into account thefeatures of negative examples built dur ing the training.
Bohnet (2010) showed that the Hash Kernel improves parsing speed and accuracy since the parser uses additionally negative features. $$$$$ To gain even faster parsing times, it may be possible to trade accuracy against speed.

The dependency labels were provided by the Bohnet parser (Bohnet, 2010) for English and by magyarlanc 2.0 (Zsibrita et al, 2013) for Hungarian. $$$$$ et al, 2009).
The dependency labels were provided by the Bohnet parser (Bohnet, 2010) for English and by magyarlanc 2.0 (Zsibrita et al, 2013) for Hungarian. $$$$$ We combined thisparsing algorithm with the passive-aggressive perceptron algorithm (Crammer et al, 2003; McDon ald et al, 2005; Crammer et al, 2006).

For POS tagging and lemmatization, we use TreeTagger (Schmid, 1994) and determine grammatical gender with the morphological layer of the MATE Tools (Bohnet, 2010). $$$$$ To determine why, we analyzed thetime usage of a dependency parser.
For POS tagging and lemmatization, we use TreeTagger (Schmid, 1994) and determine grammatical gender with the morphological layer of the MATE Tools (Bohnet, 2010). $$$$$ 4 4We provide the Parser and Hash Kernel as open source for download from http://code.google.com/p/mate-tools.

It uses an approximate exhaustive search for unlabeled parsing, then a separate arc label classifier is applied to label each arc. The Mateparser (Bohnet, 2010) is an efficient second order dependency parser that models the interaction between siblings as well as grandchildren (Carreras, 2007). $$$$$ The factors of the first order maximum spanning tree parsing algorithm are edges consisting of the head, the dependent (child) and the edge label.
It uses an approximate exhaustive search for unlabeled parsing, then a separate arc label classifier is applied to label each arc. The Mateparser (Bohnet, 2010) is an efficient second order dependency parser that models the interaction between siblings as well as grandchildren (Carreras, 2007). $$$$$ The second order algorithm of Carreras (2007) uses in addition to McDonald and Pereira (2006) the child of the dependent occurring in the sentence between the head and the dependent, and the an edge to a grandchild.

The three dependency parsers are: MaltParser (Nivre et al, 2006), Mate (Bohnet, 2010) 2 and MSTParser (McDonald and Pereira, 2006). $$$$$ The baseline parser resembles the architec ture of McDonald and Pereira (2006).
The three dependency parsers are: MaltParser (Nivre et al, 2006), Mate (Bohnet, 2010) 2 and MSTParser (McDonald and Pereira, 2006). $$$$$ ??u return ??w , ??v al., 2006).

For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0.We conducted our dependency-based pre ordering experiments on the Berkeley Parser and the Mate Parser (Bohnet, 2010), which were shown to be the two best parsers for Stanford typed dependencies (Che et al, 2012). $$$$$ For a transition based parser, Gesmundo et al (2009) reported run times between 2.2 days for English and 4.7 days forCzech for the joint training of syntactic and se mantic dependencies.
For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0.We conducted our dependency-based pre ordering experiments on the Berkeley Parser and the Mate Parser (Bohnet, 2010), which were shown to be the two best parsers for Stanford typed dependencies (Che et al, 2012). $$$$$ (2009), and (4) Ren et al (2009); LAS of the baseline parser and the parser with Hash Kernel.

The three methods outperformed the baseline (the state of the art parser for French which is a second order graph based method) (Bohnet, 2010). $$$$$ This is 3.5 times faster than the baseline parser.
The three methods outperformed the baseline (the state of the art parser for French which is a second order graph based method) (Bohnet, 2010). $$$$$ However, the parser would have ranked second for these languages.

For syntactic features, we adopt those of Bohnet (2010) which include two categories corresponding to the two types of scoring subtrees in Fig. $$$$$ is the set of training examples where an example is a pair (xi, yi) of a sentence and the corresponding dependency structure.
For syntactic features, we adopt those of Bohnet (2010) which include two categories corresponding to the two types of scoring subtrees in Fig. $$$$$ We will call the features built due to the training examples positive features and the rest negative features.

Please refer to Table 4 of Bohnet (2010) for the complete feature list. $$$$$ Table 6 shows.
Please refer to Table 4 of Bohnet (2010) for the complete feature list. $$$$$ This procedure is repeated until the list is empty.

We add for each verb in VerbNet and for each noun in CoreLex its base class or basic type as an additional feature where words tagged by the mate tagger (Bohnet, 2010) as NN.* are treated as nouns and words tagged as VB.* as verbs. $$$$$ (n? 1) ? I + i ? = E ? I ? k + 2 // passive-aggressive weight tsr,k; A = read-features-and-calc-arrays(i,??w ) ; ter,k tsp,k; yp = predicte-projective-parse-tree(A);tep,k tsa,k; ya = non-projective-approx.(yp ,A); tea,k update ??w , ??v according to ?(yp, yi) and ? w = v/(E ? I) // average dren ?h,d,g where h, d, g, and s are the indexes of the words included in xi.
We add for each verb in VerbNet and for each noun in CoreLex its base class or basic type as an additional feature where words tagged by the mate tagger (Bohnet, 2010) as NN.* are treated as nouns and words tagged as VB.* as verbs. $$$$$ l represents the label, h the head, d the dependent, s a sibling, and g a grandchild, d(x,y,[,z]) the order of words, and r(x,y) the distance.

 $$$$$ It updates ??v as well, whereby the algorithm additionally weights the updates by ?.
 $$$$$ 96

Our system not only out performs the best single system (Bjorkelundetal., 2013) by 1.4%, but it also tops the ensemble system that combines three powerful parsers: the Mate parser (Bohnet, 2010), the Easy-First parser (Goldberg and Elhadad, 2010) and the Turbo parser (Martins et al, 2013) Impact of Sampling Methods We compare two sampling methods introduced in Section 3.2 with respect to their decoding efficiency. $$$$$ Parsing and training times can be improved by methods that maintain the accuracy level, or methods that trade accuracy against better parsing times.
Our system not only out performs the best single system (Bjorkelundetal., 2013) by 1.4%, but it also tops the ensemble system that combines three powerful parsers: the Mate parser (Bohnet, 2010), the Easy-First parser (Goldberg and Elhadad, 2010) and the Turbo parser (Martins et al, 2013) Impact of Sampling Methods We compare two sampling methods introduced in Section 3.2 with respect to their decoding efficiency. $$$$$ (2009), and (4) Ren et al (2009); LAS of the baseline parser and the parser with Hash Kernel.

As a result, the hash kernel often improves accuracy as well as efficiency compared to traditional techniques that only make use of features that occur in gold standard parses (Bohnet, 2010). $$$$$ Algorithm 3: Training ? Hash Kernel for n?
As a result, the hash kernel often improves accuracy as well as efficiency compared to traditional techniques that only make use of features that occur in gold standard parses (Bohnet, 2010). $$$$$ The Hash Kernel shares values when collisions occur that can be considered as an approximation of the kernel function, because a weight might be adapted due to more than one feature.
