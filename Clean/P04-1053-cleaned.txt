Hasegawa, et al put forward an unsupervised approach for relation extraction from large text corpora (Hasegawa et al, 2004). $$$$$ We propose a new approach to relation discovery from large text corpora.
Hasegawa, et al put forward an unsupervised approach for relation extraction from large text corpora (Hasegawa et al, 2004). $$$$$ We proposed an unsupervised method for relation discovery from large corpora.

For Hasegawa's method (Hasegawa et al, 2004), we set the cluster number to be identical with the number of ground truth classes. $$$$$ We show the types of classes and the number in each class in Table 1.
For Hasegawa's method (Hasegawa et al, 2004), we set the cluster number to be identical with the number of ground truth classes. $$$$$ We show the larger clusters for each domain, along with the ratio of the number of pairs bearing the major relation to the total number of pairs in each cluster, on the left in Table 3.

 $$$$$ These words, which are stemmed, could be regarded as the context of the pair of named entities.
 $$$$$ We would like to thank Dr. Yoshihiko Hayashi at Nippon Telegraph and Telephone Corporation, currently at Osaka University, who gave one of us (T.H.) an opportunity to conduct this research.

 $$$$$ These words, which are stemmed, could be regarded as the context of the pair of named entities.
 $$$$$ We would like to thank Dr. Yoshihiko Hayashi at Nippon Telegraph and Telephone Corporation, currently at Osaka University, who gave one of us (T.H.) an opportunity to conduct this research.

One approach for Open IE is based on clustering of entity pairs to produce relations, as introduced by Hasegawa et al (Hasegawa et al, 2004). $$$$$ Our approach is based on context based clustering of pairs of entities.
One approach for Open IE is based on clustering of entity pairs to produce relations, as introduced by Hasegawa et al (Hasegawa et al, 2004). $$$$$ For example, Sekine proposed 150 types of named entities (Sekine et al., 2002).

Fully unsupervised Open IE systems are mainly based on clustering of entity pair contexts to produce clusters of entity pairs that share the same relations, as introduced by Hasegawa et al (Hasegawa et al, 2004). $$$$$ Our approach is based on context based clustering of pairs of entities.
Fully unsupervised Open IE systems are mainly based on clustering of entity pair contexts to produce clusters of entity pairs that share the same relations, as introduced by Hasegawa et al (Hasegawa et al, 2004). $$$$$ Our proposed method is fully unsupervised.

 $$$$$ These words, which are stemmed, could be regarded as the context of the pair of named entities.
 $$$$$ We would like to thank Dr. Yoshihiko Hayashi at Nippon Telegraph and Telephone Corporation, currently at Osaka University, who gave one of us (T.H.) an opportunity to conduct this research.

 $$$$$ These words, which are stemmed, could be regarded as the context of the pair of named entities.
 $$$$$ We would like to thank Dr. Yoshihiko Hayashi at Nippon Telegraph and Telephone Corporation, currently at Osaka University, who gave one of us (T.H.) an opportunity to conduct this research.

Hasegawa et al (2004) performs unsupervised hierarchical clustering over a simple set of features. $$$$$ We do not know how many clusters we should make in advance, so we adopt hierarchical clustering.
Hasegawa et al (2004) performs unsupervised hierarchical clustering over a simple set of features. $$$$$ Many clustering methods were proposed for hierarchical clustering, but we adopt complete linkage because it is conservative in making clusters.

Unfortunately, this number is often unavailable in in formation extraction tasks in general (Hasegawa et al, 2004), and attribute extraction in particular. $$$$$ The concept of relation extraction was introduced as part of the Template Element Task, one of the information extraction tasks in the Sixth Message Understanding Conference (MUC-6) (Defense Advanced Research Projects Agency, 1995).
Unfortunately, this number is often unavailable in in formation extraction tasks in general (Hasegawa et al, 2004), and attribute extraction in particular. $$$$$ Following MUC, the Automatic Content Extraction (ACE) meetings (National Institute of Standards and Technology, 2000) are pursuing information extraction.

(Hasegawa et al 2004) used large corpora and an Extended Named Entity tagger to find novel relations and their participants. $$$$$ Discovering Relations Among Named Entities From Large Corpora
(Hasegawa et al 2004) used large corpora and an Extended Named Entity tagger to find novel relations and their participants. $$$$$ We use an extended named entity tagger (Sekine, 2001) in order to detect useful relations between extended named entities.

Some existing studies use corpus-based statistics for relation extraction (Hasegawa et al, 2004). $$$$$ Our approach is based on context based clustering of pairs of entities.
Some existing studies use corpus-based statistics for relation extraction (Hasegawa et al, 2004). $$$$$ Instead of them, we use a named entity (NE) tagger.

Hasegawa et al (2004) described a paraphrase discovery approach based on clustering concurrent name pairs. $$$$$ We propose a new approach to relation discovery from large text corpora.
Hasegawa et al (2004) described a paraphrase discovery approach based on clustering concurrent name pairs. $$$$$ Our approach is based on context based clustering of pairs of entities.

Compared with supervised and semi-supervised methods, Hasegawa et al (2004)'s unsupervised approach for relation extraction can overcome the difficulties on requirement of a large amount of labeled data and enumeration of all class labels. $$$$$ Most of approaches to the ACE RDC task involved supervised learning such as kernel methods (Zelenko et al., 2002) and need richly annotated corpora which are tagged with relation instances.
Compared with supervised and semi-supervised methods, Hasegawa et al (2004)'s unsupervised approach for relation extraction can overcome the difficulties on requirement of a large amount of labeled data and enumeration of all class labels. $$$$$ Some previous work adopted a weakly supervised learning approach.

Hasegawa et al (2004)'s method is to use a hierarchical clustering method to cluster pairs of named entities according to the similarity of context words intervening between the named entities. $$$$$ The key idea is clustering pairs of named entities according to the similarity of context words intervening between the named entities.
Hasegawa et al (2004)'s method is to use a hierarchical clustering method to cluster pairs of named entities according to the similarity of context words intervening between the named entities. $$$$$ The key idea was clustering of pairs of named entities according to the similarity of the context words intervening between the named entities.

It also does not need to pre-define the number of the context clusters or pre-specify the similarity threshold for the clusters as Hasegawa et al (2004)'s method. $$$$$ So, we also define a norm threshold in advance to eliminate short context vectors.
It also does not need to pre-define the number of the context clusters or pre-specify the similarity threshold for the clusters as Hasegawa et al (2004)'s method. $$$$$ After we calculate the similarity among context vectors of NE pairs, we make clusters of NE pairs based on the similarity.

 $$$$$ These words, which are stemmed, could be regarded as the context of the pair of named entities.
 $$$$$ We would like to thank Dr. Yoshihiko Hayashi at Nippon Telegraph and Telephone Corporation, currently at Osaka University, who gave one of us (T.H.) an opportunity to conduct this research.

In (Hasegawa et al, 2004), they preformed unsupervised relation extraction based on hierarchical clustering and they only used word features between entity mention pairs to construct context vectors. $$$$$ Our approach is based on context based clustering of pairs of entities.
In (Hasegawa et al, 2004), they preformed unsupervised relation extraction based on hierarchical clustering and they only used word features between entity mention pairs to construct context vectors. $$$$$ We also used stop words when context vectors are made.

We reported the clustering results using the same clustering strategy as Hasegawa et al (2004) proposed. $$$$$ For example, Sekine proposed 150 types of named entities (Sekine et al., 2002).
We reported the clustering results using the same clustering strategy as Hasegawa et al (2004) proposed. $$$$$ Many clustering methods were proposed for hierarchical clustering, but we adopt complete linkage because it is conservative in making clusters.

In Table 5, Hasegawa's Method1 means the test used the word feature as Hasegawa et al (2004) while Hasegawa's Method2 means the test used the same feature set as our method. $$$$$ We also used the patterns, “,.
In Table 5, Hasegawa's Method1 means the test used the word feature as Hasegawa et al (2004) while Hasegawa's Method2 means the test used the same feature set as our method. $$$$$ A threshold just above 0 means that each combination of NE pairs in the same cluster shares at least one word in common — and most of these common words were pertinent to the relations.
