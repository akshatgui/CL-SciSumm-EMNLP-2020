Comparing the latter half of the experimental results with those on parsing (Miyao and Tsujii, 2005), we investigated similarities and differences between probabilistic models for parsing and generation. $$$$$ Probabilistic Disambiguation Models For Wide-Coverage HPSG Parsing
Comparing the latter half of the experimental results with those on parsing (Miyao and Tsujii, 2005), we investigated similarities and differences between probabilistic models for parsing and generation. $$$$$ To our knowledge, this work provides the first results of extensive experiments of parsing Penn Treebank with a probabilistic HPSG.

The atomic features and their combinations are imported from the previous work on HPSG parsing (Miyao and Tsujii, 2005). $$$$$ In this paper, we investigate combinations of the atomic features listed in Table 1.
The atomic features and their combinations are imported from the previous work on HPSG parsing (Miyao and Tsujii, 2005). $$$$$ The accuracy was measured by removing some of the atomic features from the final model.

Similar results are reported in parsing (Miyao and Tsujii, 2005) while the accuracy saturated around 16,000 sentences. $$$$$ This results from the HPSG grammar having stricter feature constraints and the parser not being able to produce parse results for around one percent of the sentences.
Similar results are reported in parsing (Miyao and Tsujii, 2005) while the accuracy saturated around 16,000 sentences. $$$$$ High accuracy was attained even with small data, and the accuracy seemed to be saturated.

These results are different from those in parsing reported by Miyao and Tsujii (2005) where COMMA and SPAN especially contributed to the accuracy. $$$$$ This method reduces the time for RULE the name of the applied schema DIST the distance between the head words of the daughters COMMA whether a comma exists between daughters and/or inside of daughter phrases SPAN the number of words dominated by the phrase SYM the symbol of the phrasal category (e.g.
These results are different from those in parsing reported by Miyao and Tsujii (2005) where COMMA and SPAN especially contributed to the accuracy. $$$$$ The results indicate that DIST, COMMA, SPAN, WORD, and POS features contributed to the final accuracy, although the differences were slight.

 $$$$$ The above method allows for the tractable estimation of log-linear models on exponentially-many HPSG parse trees.
 $$$$$ Future work includes the investigation of such features, as well as the abstraction of lexical dependencies like semantic classes.

In this paper, we use an HPSG parser developed by Miyao and Tsujii (2005). $$$$$ This paper reports the development of loglinear models for the disambiguation in wide-coverage HPSG parsing.
In this paper, we use an HPSG parser developed by Miyao and Tsujii (2005). $$$$$ Actually, in our previous study (Miyao et al., 2003), we successfully developed a probabilistic model including features on nonlocal predicate-argument dependencies.

In addition, the HPSG grammar is extracted from the HPSG Treebank using a corpus based procedure, and it does not necessarily cover all possible grammatical phenomena in unseen text (Miyao and Tsujii, 2005). $$$$$ Recently, a wide-coverage grammar and a large treebank have become available for English HPSG (Miyao et al., 2004).
In addition, the HPSG grammar is extracted from the HPSG Treebank using a corpus based procedure, and it does not necessarily cover all possible grammatical phenomena in unseen text (Miyao and Tsujii, 2005). $$$$$ Although it is true to some extent, this does not necessarily mean the impossibility of incorporating features on nonlocal dependencies into the model.

 $$$$$ The above method allows for the tractable estimation of log-linear models on exponentially-many HPSG parse trees.
 $$$$$ Future work includes the investigation of such features, as well as the abstraction of lexical dependencies like semantic classes.

By running the HPSG parser described in section 2.2 on the development data without dependency constraints, we obtain similar values of LP (86.8%) and LR (85.6%) as those reported by Miyao and Tsujii (Miyao and Tsujii, 2005). $$$$$ The F-score is the harmonic mean of LP and LR.
By running the HPSG parser described in section 2.2 on the development data without dependency constraints, we obtain similar values of LP (86.8%) and LR (85.6%) as those reported by Miyao and Tsujii (Miyao and Tsujii, 2005). $$$$$ Our results cannot be strictly compared with other grammar formalisms because each formalism represents predicate-argument dependencies differently; for reference, our results are competitive with the corresponding measures reported for Combinatory Categorial Grammar (CCG) (LP/LR = 86.6/86.3) (Clark and Curran, 2004b).

 $$$$$ The above method allows for the tractable estimation of log-linear models on exponentially-many HPSG parse trees.
 $$$$$ Future work includes the investigation of such features, as well as the abstraction of lexical dependencies like semantic classes.

We examined 100 sentences using a phrase structure parser (Charniak and Johnson, 2005) and an HPSG parser (Miyao and Tsujii, 2005). $$$$$ For the training, we eliminated sentences with no less than 40 words and for which the parser could not produce the correct parse.
We examined 100 sentences using a phrase structure parser (Charniak and Johnson, 2005) and an HPSG parser (Miyao and Tsujii, 2005). $$$$$ This results from the HPSG grammar having stricter feature constraints and the parser not being able to produce parse results for around one percent of the sentences.

We first apply a deep parser (Miyao and Tsujii, 2005) and a dictionary-based term recognizer (Tsuruoka and Tsujii, 2004) to MEDLINE and obtain annotations of predicate argument structures and ontological identifiers of genes, gene products, diseases, and events. $$$$$ We apply two techniques for reducing the training cost.
We first apply a deep parser (Miyao and Tsujii, 2005) and a dictionary-based term recognizer (Tsuruoka and Tsujii, 2004) to MEDLINE and obtain annotations of predicate argument structures and ontological identifiers of genes, gene products, diseases, and events. $$$$$ We measured the accuracy of predicate-argument dependencies output by the parser.

In addition, parsers that compute deeper analyses, such as predicate argument structures, have become available for the processing of real-world sentences (Miyao and Tsujii, 2005). $$$$$ A series of experiments empirically evaluated the estimation techniques, and also examined the performance of the disambiguation models on the parsing of real-world sentences.
In addition, parsers that compute deeper analyses, such as predicate argument structures, have become available for the processing of real-world sentences (Miyao and Tsujii, 2005). $$$$$ Sentences with at least 10 words are necessary to properly evaluate the performance of parsing real-world texts.

We first parsed all sentences using an HPSG parser (Miyao and Tsujii, 2005) to obtain their predicate argument structures. $$$$$ Actually, in our previous study (Miyao et al., 2003), we successfully developed a probabilistic model including features on nonlocal predicate-argument dependencies.
We first parsed all sentences using an HPSG parser (Miyao and Tsujii, 2005) to obtain their predicate argument structures. $$$$$ We measured the accuracy of predicate-argument dependencies output by the parser.

 $$$$$ The above method allows for the tractable estimation of log-linear models on exponentially-many HPSG parse trees.
 $$$$$ Future work includes the investigation of such features, as well as the abstraction of lexical dependencies like semantic classes.

The HPSG parser used in this study is Ninomiya et al (2006), which is based on Enju (Miyao and Tsujii, 2005). $$$$$ Discriminative log-linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing (Johnson et al., 1999; Riezler et al., 2002; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Clark and Curran, 2004b; Kaplan et al., 2004).
The HPSG parser used in this study is Ninomiya et al (2006), which is based on Enju (Miyao and Tsujii, 2005). $$$$$ We used an HPSG grammar derived from Penn Treebank (Marcus et al., 1994) Section 02-21 (39,832 sentences) by our method of grammar development (Miyao et al., 2004).

 $$$$$ The above method allows for the tractable estimation of log-linear models on exponentially-many HPSG parse trees.
 $$$$$ Future work includes the investigation of such features, as well as the abstraction of lexical dependencies like semantic classes.

 $$$$$ The above method allows for the tractable estimation of log-linear models on exponentially-many HPSG parse trees.
 $$$$$ Future work includes the investigation of such features, as well as the abstraction of lexical dependencies like semantic classes.

In the hybrid model, the probabilities of the previous model are multiplied by the super tagging probabilities instead of a preliminary probabilistic model, which is introduced to help the process of estimation by filtering unlikely lexical entries (Miyao and Tsujii, 2005). $$$$$ The preliminary model in this study is a unigram model, p(tIs) = FJwEs p(1I w), where w E s is a word in the sentence s, and 1 is a lexical entry assigned to w. This model can be estimated without parsing a treebank.
In the hybrid model, the probabilities of the previous model are multiplied by the super tagging probabilities instead of a preliminary probabilistic model, which is introduced to help the process of estimation by filtering unlikely lexical entries (Miyao and Tsujii, 2005). $$$$$ However, the model combined with a preliminary model achieved sufficient accuracy.

In the experiments, we compared our model with the probabilistic HPSG model of Miyao and Tsujii (2005). $$$$$ The preliminary model in this study is a unigram model, p(tIs) = FJwEs p(1I w), where w E s is a word in the sentence s, and 1 is a lexical entry assigned to w. This model can be estimated without parsing a treebank.
In the experiments, we compared our model with the probabilistic HPSG model of Miyao and Tsujii (2005). $$$$$ However, the model combined with a preliminary model achieved sufficient accuracy.
