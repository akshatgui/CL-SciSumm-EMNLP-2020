For more information on the TE system described in this section, please see (Hickl et al, 2006b) and (Harabagiu and Hickl, 2006). $$$$$ As in (Hickl et al., 2006), we used a twostep approach to obtain sufficient training data for the Alignment Classifier.
For more information on the TE system described in this section, please see (Hickl et al, 2006b) and (Harabagiu and Hickl, 2006). $$$$$ The performance of the TE system described in Section 3 was first evaluated in the 2006 PASCAL RTE Challenge.

Following (Harabagiu and Hickl, 2006), we used TE information in order to filter answers identified by the Q/A system that were not entailed by the user's original question. $$$$$ Table 2

While it has been shown that paraphrasing methods are useful for question answering (Harabagiu and Hickl, 2006) and relation extraction (Romano et al, 2006), this is, to the best of our knowledge, the first paper to perform semantic parsing through paraphrasing. $$$$$ Methods For Using Textual Entailment In Open-Domain Question Answering
While it has been shown that paraphrasing methods are useful for question answering (Harabagiu and Hickl, 2006) and relation extraction (Romano et al, 2006), this is, to the best of our knowledge, the first paper to perform semantic parsing through paraphrasing. $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including

In order to improve QA systems' performance many research focus on different structures such as question processing (Huang et al., 2008), information retrieval (Clarke et al., 2006), information extraction (Saggion and Gaizauskas, 2006), textual entailment (TE) (Harabagiu and Hickl, 2006) for ranking, answer extraction, etc. $$$$$ As in (Hickl et al., 2006), we used a twostep approach to obtain sufficient training data for the Alignment Classifier.
In order to improve QA systems' performance many research focus on different structures such as question processing (Huang et al., 2008), information retrieval (Clarke et al., 2006), information extraction (Saggion and Gaizauskas, 2006), textual entailment (TE) (Harabagiu and Hickl, 2006) for ranking, answer extraction, etc. $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including

Implementation of different TE models has previously shown to improve the QA task using supervised learning methods (Harabagiu and Hickl, 2006). $$$$$ Methods For Using Textual Entailment In Open-Domain Question Answering
Implementation of different TE models has previously shown to improve the QA task using supervised learning methods (Harabagiu and Hickl, 2006). $$$$$ In this section, we describe three different methods for integrating a textual entailment (TE) system into the architecture of an open-domain Q/A system.

Instead of matching headline and first sentence of the document as in (Harabagiu and Hickl, 2006), we followed a different approach. $$$$$ As in (Hickl et al., 2006), we used a twostep approach to obtain sufficient training data for the Alignment Classifier.
Instead of matching headline and first sentence of the document as in (Harabagiu and Hickl, 2006), we followed a different approach. $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including

In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al, 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. $$$$$ As described in (Hickl et al., 2006), the Preprocessing module is used to syntactically parse texts, identify the semantic dependencies of predicates, label named entities, normalize temporal and spatial expressions, resolve instances of coreference, and annotate predicates with polarity, tense, and modality information.
In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al, 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including

Recent work on textual entailment has shown improvements on QA results (Harabagiu and Hickl, 2006), (Celikyilmaz et al, 2009), when used for filtering and ranking answers. $$$$$ As in (Hickl et al., 2006), we used a twostep approach to obtain sufficient training data for the Alignment Classifier.
Recent work on textual entailment has shown improvements on QA results (Harabagiu and Hickl, 2006), (Celikyilmaz et al, 2009), when used for filtering and ranking answers. $$$$$ Features derived from the entailment confidence were then combined with the keyword- and relation-based features described in (Harabagiu et al., 2005a) in order to produce a final ranking of candidate answers.

For the task of Question Answering, (Harabagiu and Hickl, 2006) applied a TE component to rerank candidate answers returned by a retrieval step. $$$$$ We believe that systems developed specifically for this task can provide current question-answering systems with valuable semantic information that can be leveraged to identify exact answers from ranked lists of candidate answers.
For the task of Question Answering, (Harabagiu and Hickl, 2006) applied a TE component to rerank candidate answers returned by a retrieval step. $$$$$ Under this approach, candidate answers were initially ranked using features derived from entailment classifications performed between (1) the original question and each candidate answer and (2) the original question and the AGQ generated from each candidate answer.

Techniques developed for RTE have now been successfully applied in the domains of Question Answering (Harabagiu and Hickl, 2006) and Machine Translation (Pado et al, 2009), (Mirkin et al, 2009). $$$$$ (Prager et al., 2004)).
Techniques developed for RTE have now been successfully applied in the domains of Question Answering (Harabagiu and Hickl, 2006) and Machine Translation (Pado et al, 2009), (Mirkin et al, 2009). $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including

This includes finding question answer pairs (Cong et al, 2008) from online forums, auto-answering queries on a technical forum (Feng et al, 2006), ranking answers (Harabagiu and Hickl, 2006) etc. $$$$$ As in (Hickl et al., 2006), we used a twostep approach to obtain sufficient training data for the Alignment Classifier.
This includes finding question answer pairs (Cong et al, 2008) from online forums, auto-answering queries on a technical forum (Feng et al, 2006), ranking answers (Harabagiu and Hickl, 2006) etc. $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including

Being a challenging task, it has been shown that it is helpful to applications like question answering (Harabagiu and Hickl, 2006). $$$$$ Methods For Using Textual Entailment In Open-Domain Question Answering
Being a challenging task, it has been shown that it is helpful to applications like question answering (Harabagiu and Hickl, 2006). $$$$$ We believe that systems developed specifically for this task can provide current question-answering systems with valuable semantic information that can be leveraged to identify exact answers from ranked lists of candidate answers.

The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as question answering (Harabagiu and Hickl, 2006), information retrieval (Clinchant et al, 2006), information extraction (Romano et al, 2006), and document summarization (Lloret et al, 2008). $$$$$ (Prager et al., 2004)).
The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as question answering (Harabagiu and Hickl, 2006), information retrieval (Clinchant et al, 2006), information extraction (Romano et al, 2006), and document summarization (Lloret et al, 2008). $$$$$ As in (Hickl et al., 2006), we used a twostep approach to obtain sufficient training data for the Alignment Classifier.

TE has been successfully applied to a variety of natural language processing applications, including information extraction (Romano et al, 2006) and question answering (Harabagiu and Hickl, 2006). $$$$$ In previous work (Harabagiu et al., 2005b), we have described techniques that can be used to automatically generate well-formed natural language questions from the text of paragraphs retrieved by a PR module.
TE has been successfully applied to a variety of natural language processing applications, including information extraction (Romano et al, 2006) and question answering (Harabagiu and Hickl, 2006). $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including

Knowledge about entailment is beneficial for NLP tasks such as Question Answering (Harabagiu and Hickl, 2006). $$$$$ Methods For Using Textual Entailment In Open-Domain Question Answering
Knowledge about entailment is beneficial for NLP tasks such as Question Answering (Harabagiu and Hickl, 2006). $$$$$ Section 2 describes the three methods of using textual entailment in open-domain question answering that we have identified, while Section 3 presents the textual entailment system we have used.

Algorithms for computing semantic textual similarity (STS) are relevant for a variety of applications, including information extraction (Szpektor and Dagan, 2008), question answering (Harabagiu and Hickl, 2006) and machine translation (Mirkin et al, 2009). $$$$$ Recently, the task of automatically recognizing one form of semantic inference – textual entailment – has received much attention from groups participating in the 2005 and 2006 PASCAL Recognizing Textual Entailment (RTE) Challenges (Dagan et al., 2005).
Algorithms for computing semantic textual similarity (STS) are relevant for a variety of applications, including information extraction (Szpektor and Dagan, 2008), question answering (Harabagiu and Hickl, 2006) and machine translation (Mirkin et al, 2009). $$$$$ Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including
