The authors later explored the difference between prior and contextual polarity (Wilson et al, 2009) $$$$$ Also, quite often words that are positive or negative out of context are neutral in context, meaning they are not even being used to express a sentiment.
The authors later explored the difference between prior and contextual polarity (Wilson et al, 2009) $$$$$ Out of context, we would consider both of these words to be positive.1 In context, the word reason is being negated, changing its polarity from positive to negative.

Other studies such as Na et al (2004), Ding et al (2008), and Wilson et al (2009) also explore negation shifting and achieve some improvements. $$$$$ Morinaga et al. (2002), Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al.
Other studies such as Na et al (2004), Ding et al (2008), and Wilson et al (2009) also explore negation shifting and achieve some improvements. $$$$$ Morinaga et al. only consider the positive or negative clue instance in each sentence that is closest to some target reference; Kim and Hovy, Hu and Liu, and Grefenstette et al. multiply or count the prior polarities of clue instances in the sentence.

Wilson et al (2009) use conjunctive and dependency relations among polarity words. $$$$$ As we do, Popescu and Etzioni use features that represent conjunctions and dependency relations between polarity words.
Wilson et al (2009) use conjunctive and dependency relations among polarity words. $$$$$ Takamura et al. (2005) use negation words and phrases, including phrases such as lack of that are members in our lists of polarity shifters, and conjunctive expressions that they collect from corpora.

In the research on recognizing contextual polarity done by Wilson et al (2009) a rich prior-polarity lexicon and dependency parsing technique were employed to detect and analyze subjectivity on phrasal level, taking into account all the power of context, captured through such features as negation, polarity modification and polarity shifters. $$$$$ As before, if the sibling is not in the Wilson, Wiebe, and Hoffmann Recognizing Contextual Polarity lexicon, its prior polarity is neutral.
In the research on recognizing contextual polarity done by Wilson et al (2009) a rich prior-polarity lexicon and dependency parsing technique were employed to detect and analyze subjectivity on phrasal level, taking into account all the power of context, captured through such features as negation, polarity modification and polarity shifters. $$$$$ These researchers also consider local negation to reverse polarity, with Morinaga et al. also taking into account the negating effect of words like insufficient.

Wilson et al (2009) proposed a two-step approach to classify word polarity out of context firstly, and then to classify word polarity in context with a wide variety of features. $$$$$ We call the polarity that would be listed for a word in a lexicon the word’s prior polarity, and we call the polarity of the expression in which a word appears, considering the context of the sentence and document, the word’s contextual polarity.
Wilson et al (2009) proposed a two-step approach to classify word polarity out of context firstly, and then to classify word polarity in context with a wide variety of features. $$$$$ For the second step of recognizing contextual polarity, we classify the polarity of all clue instances identified as polar in step one.

Domain $$$$$ Contextual polarity may also be influenced by the domain or topic.
Domain $$$$$ Document Feature There is one document feature representing the topic or domain of the document.

This is significantly different from the previous input structure methods, which consider the linguistic structure as heuristic rules (Ding and Liu, 2007) or input features for classification (Wilson et al 2009). $$$$$ Morinaga et al. only consider the positive or negative clue instance in each sentence that is closest to some target reference; Kim and Hovy, Hu and Liu, and Grefenstette et al. multiply or count the prior polarities of clue instances in the sentence.
This is significantly different from the previous input structure methods, which consider the linguistic structure as heuristic rules (Ding and Liu, 2007) or input features for classification (Wilson et al 2009). $$$$$ Gamon (2004) achieves his best results for document classification using a wide variety of features, including rich linguistic features, such as features that capture constituent structure, features that combine part-of-speech and semantic relations (e.g., sentence subject or negated context), and features that capture tense information.

Currently, our input sentiment list exists only of prior sentiment values, however work by Wilson et al (2009) has advanced the notion of contextual polarity lists. $$$$$ To make the relationship between that task and ours clearer, some word lists that are used to evaluate methods for recognizing prior polarity (positive and negative word lists from the General Inquirer [Stone et al. 1966] and lists of positive and negative adjectives created for evaluation by Hatzivassiloglou and McKeown [1997]) are included in the prior-polarity lexicon used in our experiments.
Currently, our input sentiment list exists only of prior sentiment values, however work by Wilson et al (2009) has advanced the notion of contextual polarity lists. $$$$$ Bai et al. (2005) argue that dependencies among key sentiment terms are important for classifying document sentiment.

For the task of classifying the polarity of a given expression, there has been fairly extensive work on suitable classification features (Wilson et al, 2009). $$$$$ However, determining which clue instances are part of the same expression and identifying expression boundaries are not the focus of this work.
For the task of classifying the polarity of a given expression, there has been fairly extensive work on suitable classification features (Wilson et al, 2009). $$$$$ Classifying the sentiment of documents is a very different task than recognizing the contextual polarity of words and phrases.

The first part of each pipeline extracts opinion expressions, and this is followed by a multiclass classifier assigning a polarity to a given opinion expression, similar to that described by Wilson et al (2009). $$$$$ We begin by presenting an annotation scheme for marking sentiment expressions and their contextual polarity in the Multi-perspective Question Answering (MPQA) opinion corpus.
The first part of each pipeline extracts opinion expressions, and this is followed by a multiclass classifier assigning a polarity to a given opinion expression, similar to that described by Wilson et al (2009). $$$$$ For each algorithm, we give the results for the two baseline classifiers, followed by the results for the classifier trained using all the polarity features.

The problem of polarity classification has been studied in detail by Wilson et al (2009), who used a set of carefully devised linguistic features. $$$$$ However, what the polarity of a given word or phrase is when it is used in a particular context is another problem entirely.
The problem of polarity classification has been studied in detail by Wilson et al (2009), who used a set of carefully devised linguistic features. $$$$$ First, we investigate the performance of the polarity features used together for polarity classification under condition 1.

 $$$$$ Either way, this provides strong evidence of the need to be able to disambiguate the contextual polarity of subjectivity and sentiment clues.
 $$$$$ This work was supported in part by an Andrew Mellow Predoctoral Fellowship, by the NSF under grant IIS-0208798, by the Advanced Research and Development Activity (ARDA), and by the European IST Programme through the AMIDA Integrated Project FP6-0033812.

Wilson et al (2009) show that modalities as well as negations are good cues for opinion identification. $$$$$ Negation may be local (e.g., not good), or involve longer-distance dependencies such as the negation of the proposition (e.g., does not look very good) or the negation of the subject (e.g., no one thinks that it’s good).
Wilson et al (2009) show that modalities as well as negations are good cues for opinion identification. $$$$$ The words good and evil are in a conjunction together; thus the conj polarity feature is negative for good and positive for evil.

Wilson et al (2009) also consider negators and in addition distinguish between positive polarity shifters and negative polarity shifters since they only reverse a particular polarity type. $$$$$ General polarity shifters reverse polarity (e.g., little truth, little threat).
Wilson et al (2009) also consider negators and in addition distinguish between positive polarity shifters and negative polarity shifters since they only reverse a particular polarity type. $$$$$ Negative polarity shifters typically make the polarity of an expression negative (e.g., lack of understanding).

Among the few research efforts in this direction, Wilson et al (2009) use a list of modal words. $$$$$ Our work also differs from other research in the variety of features that we use.
Among the few research efforts in this direction, Wilson et al (2009) use a list of modal words. $$$$$ Another direction for future work will be to expand our lexicon using existing techniques for acquiring the prior polarity of words and phrases.

Our treatment of negation goes beyond the approaches of (Wilson et al, 2009) (Taboada et al., 2011) and (Liu and Seneff, 2009) since we propose a specific treatment for negative polarity items and for multiple negatives. $$$$$ Morinaga et al. (2002), Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al.
Our treatment of negation goes beyond the approaches of (Wilson et al, 2009) (Taboada et al., 2011) and (Liu and Seneff, 2009) since we propose a specific treatment for negative polarity items and for multiple negatives. $$$$$ Morinaga et al. only consider the positive or negative clue instance in each sentence that is closest to some target reference; Kim and Hovy, Hu and Liu, and Grefenstette et al. multiply or count the prior polarities of clue instances in the sentence.

Features previously found to be useful for detecting phrase-level contextual polarity (Wilson et al, 2009) are also included. $$$$$ Articles

The polarity of each word in arguments is derived from Multi-perspective Question Answering Opinion Corpus (MPQA) (Wilson et al, 2009). $$$$$ We begin by presenting an annotation scheme for marking sentiment expressions and their contextual polarity in the Multi-perspective Question Answering (MPQA) opinion corpus.
The polarity of each word in arguments is derived from Multi-perspective Question Answering Opinion Corpus (MPQA) (Wilson et al, 2009). $$$$$ Rather than building a corpus from scratch, we chose to add contextual polarity annotations to the existing annotations in the Multi-perspective Question Answering (MPQA) opinion corpus2 (Wiebe, Wilson, and Cardie 2005).

The task has been extended to allow sentences to be annotated as displaying both positive and negative sentiment (Wilson et al, 2009) or indicating the degree of intensity (Thelwall et al, 2010). $$$$$ Morinaga et al. (2002), Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al.
The task has been extended to allow sentences to be annotated as displaying both positive and negative sentiment (Wilson et al, 2009) or indicating the degree of intensity (Thelwall et al, 2010). $$$$$ Morinaga et al. only consider the positive or negative clue instance in each sentence that is closest to some target reference; Kim and Hovy, Hu and Liu, and Grefenstette et al. multiply or count the prior polarities of clue instances in the sentence.

More recently, Wilson et al (2009) distinguish prior and contextual polarity, and thus describe a method to phrase-level sentiment analysis. $$$$$ Articles
