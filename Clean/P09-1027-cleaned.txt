To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. $$$$$ In this study, we focus on the problem of cross-lingual sentiment classification, which leverages only English training data for supervised sentiment classification of Chinese product reviews, without using any Chinese resources.
To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. $$$$$ Wan (2008) focuses on leveraging both Chinese and English lexicons to improve Chinese sentiment analysis by using lexicon-based methods.

To reduce this kind of error introduced by the translator, Wan in (Wan, 2009) applied a co-training scheme. $$$$$ The co-training algorithm is then applied to learn two classifiers and finally the two classifiers are combined into a single sentiment classifier.
To reduce this kind of error introduced by the translator, Wan in (Wan, 2009) applied a co-training scheme. $$$$$ During the bootstrapping process of smoothed co-training, the classifier at each iteration is replaced with a majority voting scheme applied to all classifiers constructed at previous iterations.

But as the conditional distribution can be quite different for the original language and the pseudo language produced by the machine translators, these two strategies give poor performance as reported in (Wan, 2009). $$$$$ SVM, NB), and the classification performance is far from satisfactory because of the language gap between the original language and the translated language.
But as the conditional distribution can be quite different for the original language and the pseudo language produced by the machine translators, these two strategies give poor performance as reported in (Wan, 2009). $$$$$ As shown in our experiments, the above two methods do not perform well for Chinese sentiment classification, either, because the underlying distribution between the original language and the translated language are different.

For comparsion, we use the same data set in (Wan, 2009) $$$$$ The following three datasets were collected and used in the experiments

The features we used are bigrams and unigrams in the two languages as in (Wan, 2009). $$$$$ However, such resources in different languages are very imbalanced.
The features we used are bigrams and unigrams in the two languages as in (Wan, 2009). $$$$$ The English or Chinese features used in this study include both unigrams and bigrams5 and the feature weight is simply set to term frequency6.

We compare our procedure with the co-training scheme reported in (Wan, 2009) $$$$$ In the experiments, we first compare the proposed co-training approach (I=40 and p=n=5) with the eight baseline methods.
We compare our procedure with the co-training scheme reported in (Wan, 2009) $$$$$ Actually, TSVM(ENCN2) is similar to CoTrain because CoTrain also combines the results of two classifiers in the same way.

More recently, Wan (2009) proposed a co training approach to tackle the problem of cross lingual sentiment classification by leveraging an available English corpus for Chinese sentiment classification. $$$$$ Co-Training for Cross-Lingual Sentiment Classification
More recently, Wan (2009) proposed a co training approach to tackle the problem of cross lingual sentiment classification by leveraging an available English corpus for Chinese sentiment classification. $$$$$ This paper focuses on the problem of cross-lingual sentiment classification, which leverages an available English corpus for Chinese sentiment classification by using the English corpus as training data.

Similarly, other multilingual sentiment approaches also require parallel text, often supplied via automatic translation; after the translated text is available, either monolingual analysis (Denecke, 2008) or co-training is applied (Wan, 2009). $$$$$ Google Translate applies statistical learning techniques to build a translation model based on both monolingual text in the target language and aligned text consisting of examples of human translations between the languages.
Similarly, other multilingual sentiment approaches also require parallel text, often supplied via automatic translation; after the translated text is available, either monolingual analysis (Denecke, 2008) or co-training is applied (Wan, 2009). $$$$$ 2) The feature distributions of the translated text and the natural text in the same language are still different due to the inaccuracy of the machine translation service.

A related, yet more sophisticated technique is proposed in (Wan,2009), where a co-training approach is used to leverage resources from both a source and a target language. $$$$$ To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages.
A related, yet more sophisticated technique is proposed in (Wan,2009), where a co-training approach is used to leverage resources from both a source and a target language. $$$$$ In order to overcome the language gap, we must translate one language into another language.

Wan (2009) combined the annotated English reviews, unannotated Chinese reviews and their translations to co-train two separate classifiers for each language, respectively. $$$$$ First, machine translation services are used to translate English training reviews into Chinese reviews and also translate Chinese test reviews and additional unlabeled reviews into English reviews.
Wan (2009) combined the annotated English reviews, unannotated Chinese reviews and their translations to co-train two separate classifiers for each language, respectively. $$$$$ Given the labeled English reviews and unlabeled Chinese reviews, two straightforward methods for addressing the problem are as follows

In the document-level review polarity classification experiment, we used the dataset adopted in (Wan, 2009). $$$$$ In this paper we focus on document sentiment classification.
In the document-level review polarity classification experiment, we used the dataset adopted in (Wan, 2009). $$$$$ The output value of the SVM classifier for a review indicates the confidence level of the review’s classification.

In the review polarity classification experiment, we use unigram, bigram of Chinese words as features which is suggested by (Wan, 2009). $$$$$ In the context of cross-lingual sentiment classification, each labeled English review or unlabeled Chinese review has two views of features

The original annotations 1104 can be produced either manually or automatically. Wan (2009) constructs a multilingual classifier using co-training. $$$$$ The SVM classifier is adopted as the basic classifier in the proposed approach.
The original annotations 1104 can be produced either manually or automatically. Wan (2009) constructs a multilingual classifier using co-training. $$$$$ Wan (2008) focuses on leveraging both Chinese and English lexicons to improve Chinese sentiment analysis by using lexicon-based methods.

Methods which follow this two step approach include the EM-based approach by Rigutini et al (2005), the CCA approach by Fortuna and Shawe-Taylor (2005), the information bottleneck approach by Ling et al (2008), and the co-training approach by Wan (2009). $$$$$ To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007).
Methods which follow this two step approach include the EM-based approach by Rigutini et al (2005), the CCA approach by Fortuna and Shawe-Taylor (2005), the information bottleneck approach by Ling et al (2008), and the co-training approach by Wan (2009). $$$$$ A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bottleneck approach (Ling et al., 2008), the multilingual domain models (Gliozzo and Strapparava, 2005), etc.

The proposed co-regression algorithm can make full use of both the features in the source language and the features in the target language in a unified framework similar to (Wan 2009). $$$$$ The co-training approach can make full use of both the English features and the Chinese features in a unified framework.
The proposed co-regression algorithm can make full use of both the features in the source language and the features in the target language in a unified framework similar to (Wan 2009). $$$$$ In order to overcome the language gap, we must translate one language into another language.

Wan (2009) constructs a multilingual classifier using co-training. $$$$$ The SVM classifier is adopted as the basic classifier in the proposed approach.
Wan (2009) constructs a multilingual classifier using co-training. $$$$$ Wan (2008) focuses on leveraging both Chinese and English lexicons to improve Chinese sentiment analysis by using lexicon-based methods.

Wan (2009) proposes to use ensemble method to train better Chinese sentiment classification model on English labeled data and their Chinese translation. $$$$$ Only English-to-Chinese translation is needed.
Wan (2009) proposes to use ensemble method to train better Chinese sentiment classification model on English labeled data and their Chinese translation. $$$$$ Only Chinese-to-English translation is needed.

SVM $$$$$ The SVM classifier is adopted as the basic classifier in the proposed approach.
SVM $$$$$ In the experiments, the proposed co-training approach (CoTrain) is compared with the following baseline methods

Wan (2009) also leveraged an available English corpus for Chinese sentiment classification by using the co-training approach to make full use of both English and Chinese features in a unified framework. $$$$$ The purpose of our approach is to make use of the annotated English corpus for sentiment polarity identification of Chinese reviews in a supervised framework, without using any Chinese resources.
Wan (2009) also leveraged an available English corpus for Chinese sentiment classification by using the co-training approach to make full use of both English and Chinese features in a unified framework. $$$$$ The co-training approach can make full use of both the English features and the Chinese features in a unified framework.

Sentiment classification can be performed on words, sentences or documents, and is generally categorized into lexicon-based and corpus-based classification method (Wan, 2009). $$$$$ Sentiment classification can be performed on words, sentences or documents.
Sentiment classification can be performed on words, sentences or documents, and is generally categorized into lexicon-based and corpus-based classification method (Wan, 2009). $$$$$ The methods for document sentiment classification can be generally categorized into lexicon-based and corpus-based.
