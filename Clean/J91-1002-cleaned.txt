Paradigmatic similarity is based on association data extracted from thesauri [Morris and Hirst, 1991], psychological experiments [Osgood, 1952], and so on. $$$$$ Of the 16 word association pairs given in Hirst (1987), 14 were found in Roget's Thesaurus (1977).
Paradigmatic similarity is based on association data extracted from thesauri [Morris and Hirst, 1991], psychological experiments [Osgood, 1952], and so on. $$$$$ 3.2.3 Notation and Data Structures.

(Xiong et al, 2013b) incorporated lexical-chain-based models (Morris and Hirst, 1991) into machine translation. $$$$$ Automation was not possible, for lack of a machine-readable copy of the thesaurus.
(Xiong et al, 2013b) incorporated lexical-chain-based models (Morris and Hirst, 1991) into machine translation. $$$$$ A machine-readable thesaurus with automated index searching and lookup is required.

An algorithm for computing lexical chains was first given by (Morris and Hirst, 1991) using the Roget's Thesaurus (Kirkpatrick, 1998). $$$$$ Of the 16 nonsystematic semantic lexical chains given as examples in Halliday and Hasan (1976), 14 were found in Roget's Thesaurus (1977) using the relations given in Section 3.2.2.
An algorithm for computing lexical chains was first given by (Morris and Hirst, 1991) using the Roget's Thesaurus (Kirkpatrick, 1998). $$$$$ Figure 5 shows the generalized algorithm for computing lexical chains.

Morris and Hirst developed an algorithm (Morris and Hirst, 1991) based on lexical cohesion relations (Halliday and Hasan, 1976). $$$$$ Pronominal reference is defined as a type of cohesion (Halliday and Hasan 1976).
Morris and Hirst developed an algorithm (Morris and Hirst, 1991) based on lexical cohesion relations (Halliday and Hasan, 1976). $$$$$ The methods used in this work improve on those from Halliday and Hasan (1976).

Usually a lexical chain is obtained in a bottom-up fashion, by taking each candidate word of a text, and finding an appropriate relation offered by a thesaurus as Rodget (Morris and Hirst, 1991) or WordNet (Barzilay and Elhadad, 1999). $$$$$ These lexical chains are a direct result of units of text being &quot;about the same thing,&quot; and finding text structure involves finding units of text that are about the same thing.
Usually a lexical chain is obtained in a bottom-up fashion, by taking each candidate word of a text, and finding an appropriate relation offered by a thesaurus as Rodget (Morris and Hirst, 1991) or WordNet (Barzilay and Elhadad, 1999). $$$$$ Once the candidate words are chosen, the lexical chains can be formed.

Lexical cohesion analysis has been used in such NLP applications as determining the structure of text (Morris and Hirst, 1991) and automatic text summarization (Barzilay and Elhadad, 1999). $$$$$ Determining the structure of text is an essential step in determining the deep meaning of the text.
Lexical cohesion analysis has been used in such NLP applications as determining the structure of text (Morris and Hirst, 1991) and automatic text summarization (Barzilay and Elhadad, 1999). $$$$$ Section 4 is an analysis of the correspondence between lexical chains and the structure of the text.

Roget's Thesaurus, which was used to form the lexical chains in Morris and Hirst (1991), also gives non classically related word groups. $$$$$ In Section 3, we will show how a thesaurus can be used to find lexical chains in text.
Roget's Thesaurus, which was used to form the lexical chains in Morris and Hirst (1991), also gives non classically related word groups. $$$$$ In the first way, if word a is related to word b, and word b is related to word c, then word a is related to word c. In the second way, if word a is related to word b, and word a is related to word c, then word b is related to word c. But lexical chains are calculated only with respect to the text read so far.

The lexical chains of Morris and Hirst (1991) had no such restriction, and frequently nouns, verbs ,adjectives, adverbs, and verbs were joined together in one chain. $$$$$ The noun paragraphs are grouped at the start of a category, followed by the paragraphs for The structure of Roget's Thesaurus Index entry for the word lid verbs, adjectives, and so on.
The lexical chains of Morris and Hirst (1991) had no such restriction, and frequently nouns, verbs ,adjectives, adverbs, and verbs were joined together in one chain. $$$$$ By definition, lexical chains are chains of semantically related words.

In fact, each column of the matrix corresponds to a lexical chain (Morris and Hirst, 1991) for a particular term across the whole text. $$$$$ }, corresponds to intention 1.1.3.1 (if the unfortunate chain return mentioned in section 3.4.2 is ignored) and chain 4 {conceded, tolerance}, corresponds to intention 1.1.3.2 (expensive houses in Metro Toronto).
In fact, each column of the matrix corresponds to a lexical chain (Morris and Hirst, 1991) for a particular term across the whole text. $$$$$ A boolean matrix is created with words on one axis and categories on the other.

Global context where the semantic measures are employed to derive lexical chains, which are threads of meaning often drawn throughout an en tire text (Morris and Hirst, 1991). $$$$$ In text, lexical cohesion is the result of chains of related words that contribute to the continuity of lexical meaning.
Global context where the semantic measures are employed to derive lexical chains, which are threads of meaning often drawn throughout an en tire text (Morris and Hirst, 1991). $$$$$ The lexical chains also provide a semantic context for interpreting words, concepts, and sentences.

The most closely related method is perhaps the lexical chains algorithm (Morris and Hirst, 1991) where threads of meaning are identified throughout a text. $$$$$ In text, lexical cohesion is the result of chains of related words that contribute to the continuity of lexical meaning.
The most closely related method is perhaps the lexical chains algorithm (Morris and Hirst, 1991) where threads of meaning are identified throughout a text. $$$$$ The lexical chains computed by the algorithm given in Section 3.2.3 correspond closely to the intentional structure produced from the structural analysis method of Grosz and Sidner (1986).

More recently, Clarke and Lapata (2007) use Centering Theory (Grosz et al, 1995) and Lexical Chains (Morris and Hirst, 1991) to identify which information to prune. $$$$$ We will show below that lexical cohesion is computationally feasible to identify.
More recently, Clarke and Lapata (2007) use Centering Theory (Grosz et al, 1995) and Lexical Chains (Morris and Hirst, 1991) to identify which information to prune. $$$$$ Otherwise you could identify it as elaboration.

The idea of using lexical chains as indicators of lexical cohesion goes back to Morris and Hirst (1991). $$$$$ This section details how these lexical chains are formed, using a thesaurus as the main knowledge base.
The idea of using lexical chains as indicators of lexical cohesion goes back to Morris and Hirst (1991). $$$$$ Using our intuition (i.e., common sense and a knowledge of English), we identified the lexical chains in each text.

Two words are WordNet-related if their WordNet distance is less than 4 (this is consistent with works on lexical-cohesion, (Morris and Hirst, 1991)). $$$$$ The five texts were analyzed with respect to distance between clearly related words.
Two words are WordNet-related if their WordNet distance is less than 4 (this is consistent with works on lexical-cohesion, (Morris and Hirst, 1991)). $$$$$ In our work the related words in a chain are seen as indicating structural units of text, and hence distance between words is relevant.

WordNet is the main resource for detecting the cohesive relationships between words and their relevance to a given chain (Morris and Hirst, 1991). $$$$$ The words in chain 6 are cohesive by virtue of being general, but strong, &quot;good&quot; words related by their goodness, rather than by their specific meanings.
WordNet is the main resource for detecting the cohesive relationships between words and their relevance to a given chain (Morris and Hirst, 1991). $$$$$ (The other four texts and their analyses are given in Morris 1988.)

Ever since Morris and Hirst (1991)' s ground breaking paper, topic segmentation has been a steadily growing research area in computational linguistics. $$$$$ This paper will show that lexical chains are a good indication of the linguistic segmentation.
Ever since Morris and Hirst (1991)' s ground breaking paper, topic segmentation has been a steadily growing research area in computational linguistics. $$$$$ The use of lexical chains for ambiguity resolution is a promising area for further research.

Lexical cohesion techniques include similarity measures between adjacent blocks of text, as in TextTiling (Hearst, 1994, 1997) and lexical chains based on recurrences of a term or related terms, as in Morris and Hirst (1991). $$$$$ In text, lexical cohesion is the result of chains of related words that contribute to the continuity of lexical meaning.
Lexical cohesion techniques include similarity measures between adjacent blocks of text, as in TextTiling (Hearst, 1994, 1997) and lexical chains based on recurrences of a term or related terms, as in Morris and Hirst (1991). $$$$$ Halliday and Hasan related words back to the first word to which they are tied, rather than forming explicit lexical chains that include the relationships to intermediate words in the chain.

The relation between entities (noun phrases) in adjacent sentences could be of type center-reference (pronoun reference or reiteration), or based on semantic relatedness (Morris and Hirst,1991). $$$$$ Cohesion is achieved through back-reference, conjunction, and semantic word relations.
The relation between entities (noun phrases) in adjacent sentences could be of type center-reference (pronoun reference or reiteration), or based on semantic relatedness (Morris and Hirst,1991). $$$$$ Pronominal reference is defined as a type of cohesion (Halliday and Hasan 1976).

Morris and Hirst (1991) suggested building lexical chains is important in the resolution of lexical ambiguity and the determination of coherence and discourse structure. $$$$$ 3.2.2 Building Chains.
Morris and Hirst (1991) suggested building lexical chains is important in the resolution of lexical ambiguity and the determination of coherence and discourse structure. $$$$$ The use of lexical chains for ambiguity resolution is a promising area for further research.

Morris and Hirst (1991) were the first to propose the concept of Lexical Chains to explore the discourse structure of a text. $$$$$ Section 4 is an analysis of the correspondence between lexical chains and the structure of the text.
Morris and Hirst (1991) were the first to propose the concept of Lexical Chains to explore the discourse structure of a text. $$$$$ 1.2.2 Cohesion and Discourse Structure.
