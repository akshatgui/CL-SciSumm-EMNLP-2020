Because of these characteristics, Chinese has a rather different set of salient ambiguities from the perspective of statistical parsing (Levy and Manning, 2003). $$$$$ Chinese, as we will show, has a rather different set of salient ambiguities from the perspective of statistical parsing.
Because of these characteristics, Chinese has a rather different set of salient ambiguities from the perspective of statistical parsing (Levy and Manning, 2003). $$$$$ For purposes of statistical parsing, three salient differences distinguish the two languages.

We use the SVM-Light Toolkit version 6.02 (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser version 1.6 (Levy and Manning, 2003) as the constituent parser and the constituent-to-dependency converter. $$$$$ We use the factored parsing model of (Klein and Manning, 2002).
We use the SVM-Light Toolkit version 6.02 (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser version 1.6 (Levy and Manning, 2003) as the constituent parser and the constituent-to-dependency converter. $$$$$ This is an encouraging result for the use of detailed error analysis followed by focused treestructure enhancements to improved parser performance.

To run the DE classifiers, we use the Stanford Chinese parser (Levy and Manning, 2003) to parse the Chinese side of the MT training data, the devset and test set. $$$$$ Is It Harder To Parse Chinese Or The Chinese Treebank?
To run the DE classifiers, we use the Stanford Chinese parser (Levy and Manning, 2003) to parse the Chinese side of the MT training data, the devset and test set. $$$$$ To test the impact of Chinese Treebank N/V tagging practices, we tried training the parser with NN and VV training tags merged.

In this work, we use the Stanford Parser (Levy and Manning 2003). $$$$$ We use the factored parsing model of (Klein and Manning, 2002).
In this work, we use the Stanford Parser (Levy and Manning 2003). $$$$$ This is an encouraging result for the use of detailed error analysis followed by focused treestructure enhancements to improved parser performance.

Levy and Manning (2003) used a factored model that combines an unlexicalized PCFG model with a dependency model. $$$$$ We use the factored parsing model of (Klein and Manning, 2002).
Levy and Manning (2003) used a factored model that combines an unlexicalized PCFG model with a dependency model. $$$$$ In adapting this parsing model to Chinese, we have retained unchanged the dependency model developed for English; the model backs off to tags, and backoff parameters remain the same.3 In all cases, test input to the parser was segmented but untagged.4 Our focus in parser development has been to refine the PCFG model via stepwise refinements informed by major observed ambiguity classes.

While it is uncommon to offer an error analysis for probabilistic parsing, Levy and Manning (2003) argue that a careful error classification can reveal possible improvements. $$$$$ Table 3 gives a breakdown of the major error types found; Figure 4 gives examples of unfamiliar major error types.5 In the next section we describe each major error type, analyze its causes, and suggest simple PCFG enhancements that can be used to address it.
While it is uncommon to offer an error analysis for probabilistic parsing, Levy and Manning (2003) argue that a careful error classification can reveal possible improvements. $$$$$ This is an encouraging result for the use of detailed error analysis followed by focused treestructure enhancements to improved parser performance.

Verb mistagging is also a problem for other languages: Levy and Manning (2003) describe a similar problem in Chinese for noun/verb ambiguity. $$$$$ We briefly explain here why N/V ambiguity is a hard problem in Chinese.
Verb mistagging is also a problem for other languages: Levy and Manning (2003) describe a similar problem in Chinese for noun/verb ambiguity. $$$$$ But the sparse morphology of English and Chinese means that frequently there is noun/verb ambiguity at the word level.

The closest previous work is the detailed manual analysis performed by Levy and Manning (2003). $$$$$ The trends we obtained are different enough from previous work to merit discussion.
The closest previous work is the detailed manual analysis performed by Levy and Manning (2003). $$$$$ This is an encouraging result for the use of detailed error analysis followed by focused treestructure enhancements to improved parser performance.

 $$$$$ Both these differences are noticeable when comparing treebanks.
 $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.

 $$$$$ Both these differences are noticeable when comparing treebanks.
 $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.

See Levy and Manning (2003) for a similar discussion of Chinese and the Penn Chinese Treebank. $$$$$ Is It Harder To Parse Chinese Or The Chinese Treebank?
See Levy and Manning (2003) for a similar discussion of Chinese and the Penn Chinese Treebank. $$$$$ We take advantage of the recently released Penn Chinese Treebank (version 2.0, abbreviated here as CTB; (Xue et al., 2002)) to address these questions for Chinese, a language with less morphology and more mixed headedness than English.

We use the SVM-Light Toolkit (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser (Levy and Manning, 2003) as the parser and the constituent-to-dependency converter. $$$$$ We use the factored parsing model of (Klein and Manning, 2002).
We use the SVM-Light Toolkit (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser (Levy and Manning, 2003) as the parser and the constituent-to-dependency converter. $$$$$ This is an encouraging result for the use of detailed error analysis followed by focused treestructure enhancements to improved parser performance.

Noun/verb mis-taggings are a frequent error case for PCFG parsing on PCTB data, compounded in Chinese by the lack of function words and morphology (Levy and Manning, 2003). $$$$$ First, Chinese makes less use of function words and morphology than English: determinerless nouns are more widespread, plural marking is restricted and rare, and verbs appear in a unique form with few supporting function words.
Noun/verb mis-taggings are a frequent error case for PCFG parsing on PCTB data, compounded in Chinese by the lack of function words and morphology (Levy and Manning, 2003). $$$$$ But the sparse morphology of English and Chinese means that frequently there is noun/verb ambiguity at the word level.

It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). $$$$$ Parsing in this model involves combining two independent parses: one of a non-lexicalized, maximum likelihoodestimated (MLE) PCFG model and another of a constituent-free dependency parse.
It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). $$$$$ Upon manual examination, the asymmetry of N-as-V and V-as-N mistagging frequency seems in line with the global prior over POS tags; the overall N:V ratio in the corpus is 2.5:1.

Levy and Manning (2003) established that properties of Chinese such as noun/verb ambiguity contribute to the difficulty of Chinese parsing. $$$$$ Significantly, this means that attachment ambiguity among a verb's complements, a major source of parsing ambiguity in English, is rare in Chinese.
Levy and Manning (2003) established that properties of Chinese such as noun/verb ambiguity contribute to the difficulty of Chinese parsing. $$$$$ But the sparse morphology of English and Chinese means that frequently there is noun/verb ambiguity at the word level.

greatly affects parsing accuracy (Levy and Manning, 2003). $$$$$ During development, we found the difference in parse accuracy for 1-25 and 301-325 to range around a remarkable 10%.
greatly affects parsing accuracy (Levy and Manning, 2003). $$$$$ We use the factored parsing model of (Klein and Manning, 2002).

We parsed the Chinese text using the Stanford parser (Levy and Manning, 2003) and the English text using TurboParser (Martins et al, 2009). $$$$$ Corpusbased statistical parsing is a leading technique to deal with this extreme ambiguity; the vast bulk of work in this field has been done in English, using the Wall Street Journal section of the English Penn Treebank (ETB).
We parsed the Chinese text using the Stanford parser (Levy and Manning, 2003) and the English text using TurboParser (Martins et al, 2009). $$$$$ We take advantage of the recently released Penn Chinese Treebank (version 2.0, abbreviated here as CTB; (Xue et al., 2002)) to address these questions for Chinese, a language with less morphology and more mixed headedness than English.

Adapting unlexicalized parsers appears to be equally difficult: Levy and Manning (2003) adapt the unlexicalized parser of Klein and Manning (2003) to Chinese, but even after significant efforts on choosing category splits, only modest performance gains are reported. $$$$$ We use the factored parsing model of (Klein and Manning, 2002).
Adapting unlexicalized parsers appears to be equally difficult: Levy and Manning (2003) adapt the unlexicalized parser of Klein and Manning (2003) to Chinese, but even after significant efforts on choosing category splits, only modest performance gains are reported. $$$$$ We are grateful to Dan Klein for valuable input, and for the parser implementation used here.

As pointed out in (Levyand Manning, 2003), there are many linguistic differences between Chinese and English, as well as structural differences between their corresponding tree banks, and some of these make it a harder task to parse Chinese. $$$$$ Is It Harder To Parse Chinese Or The Chinese Treebank?
As pointed out in (Levyand Manning, 2003), there are many linguistic differences between Chinese and English, as well as structural differences between their corresponding tree banks, and some of these make it a harder task to parse Chinese. $$$$$ This section provides background on relevant linguistic differences between Chinese and English, and on relevant tree-structural differences between the two treebanks.

First of all, we adopt the head finding rules for Chinese used in (Levy and Manning, 2003), and this affects sieve 4, 6 and 7 which are all take advantage of the head words. $$$$$ We address this error by taking advantage of the CTB's principled VP annotation practices, marking adjunction, complementation, and coordination VP levels, which builds the flat adjunction constraint back into the structure of the head daughter.
First of all, we adopt the head finding rules for Chinese used in (Levy and Manning, 2003), and this affects sieve 4, 6 and 7 which are all take advantage of the head words. $$$$$ We address this error by taking advantage of the CTB's principled VP annotation practices, marking adjunction, complementation, and coordination VP levels, which builds the flat adjunction constraint back into the structure of the head daughter.
