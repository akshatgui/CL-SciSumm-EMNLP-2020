 $$$$$ The one miselassified case had a low score for all models, indicating a lack of confidence in any classification.
 $$$$$ OF COL1NG-92, NANrFES, AUG. 23-28, 1992

Recently, Yarowsky (1992) has found a way to extend our use of the Bayesian techniques by training on the Roget's Thesaurus (Chapman, 1977) 2 and G-rolier's Encyclopedia (1991) instead of the Canadian Hansards, thus circumventing many of the objections to our use of the Hansards. $$$$$ We use a word-aligned parallel bilingual corpus uch as the French-English Canadian Hansards for this purpose.
Recently, Yarowsky (1992) has found a way to extend our use of the Bayesian techniques by training on the Roget's Thesaurus (Chapman, 1977) 2 and G-rolier's Encyclopedia (1991) instead of the Canadian Hansards, thus circumventing many of the objections to our use of the Hansards. $$$$$ By identifying word correspondences in a bilingual text such as the Canadian Parliamentary Proceedings (Hansards), the translations found fur each English word may serve as sense tags.

Yarowsky (1992) inputs a 100-word context surrounding a polysemous word and scores each of the 1042 Roget Categories by: 1[ P r (w lRoget Categoryi) w in context The program can also be run in a mode where it takes unrestricted text as input and tags each word with its most likely Roget Category. $$$$$ Furthermore, the context indicators for a Roget category (e.g.
Yarowsky (1992) inputs a 100-word context surrounding a polysemous word and scores each of the 1042 Roget Categories by: 1[ P r (w lRoget Categoryi) w in context The program can also be run in a mode where it takes unrestricted text as input and tags each word with its most likely Roget Category. $$$$$ For each of the 1042 Roget Categories: 1.

Table 1 shows the performance of Yarowsky (1992) on twelve words which have been previously discussed in the literature. $$$$$ Eva luat ion The algorithm described above was applied to 12 polysemous words previously discussed in the sense disambignation literature.
Table 1 shows the performance of Yarowsky (1992) on twelve words which have been previously discussed in the literature. $$$$$ Table 1 (previous l~lge) shows the systenls performance.

In fact, both Black (1988) and Yarowsky (1992) report 72% performance on this very same word. $$$$$ Black (1988) has noted that his disfnction for interest is strongly corrected with th?
In fact, both Black (1988) and Yarowsky (1992) report 72% performance on this very same word. $$$$$ Black, Ez~ (1988), "An Experiment in Computational Discrimination of English Word Sea~s."

In fact, Yarowsky (1992) falls below the baseline for one of the twelve words (issue), although perhaps, we needn't be too concerned about this one deviation. $$$$$ taste, issue, duty and sentence).
In fact, Yarowsky (1992) falls below the baseline for one of the twelve words (issue), although perhaps, we needn't be too concerned about this one deviation. $$$$$ (Special Issue).

 $$$$$ The one miselassified case had a low score for all models, indicating a lack of confidence in any classification.
 $$$$$ OF COL1NG-92, NANrFES, AUG. 23-28, 1992

Semantic tags are assigned from on-line thesauras like WordNet (Basili et al 1996) (Resnik, 1995), Roget's categories (Yarowsky 1992) (Chen and Chen, 1996), the Japanese BGH (Utsuro et al 1993), or assigned manually (Basili et al 1992) 1. $$$$$ DUTY (Gale et el, 1992: 96%) Obligation DUTY 347 96% Tax PRICE.Iq:~.
Semantic tags are assigned from on-line thesauras like WordNet (Basili et al 1996) (Resnik, 1995), Roget's categories (Yarowsky 1992) (Chen and Chen, 1996), the Japanese BGH (Utsuro et al 1993), or assigned manually (Basili et al 1992) 1. $$$$$ Others such as Lesk (1986), Walker (1987), Veronis and Ide (1990), and Guthrie et al.

Yarowsky (1992) used Roget's Thesaurus categories as classes for word senses. $$$$$ For the purposes of this study, we will define the senses of a word as the categories li ted for that word in Rogers International Thesaurus (Fourth Edition - Chapman, 1977).
Yarowsky (1992) used Roget's Thesaurus categories as classes for word senses. $$$$$ For each of the 1042 Roget Categories: 1.

 $$$$$ The one miselassified case had a low score for all models, indicating a lack of confidence in any classification.
 $$$$$ OF COL1NG-92, NANrFES, AUG. 23-28, 1992

The best examples of this approach has been the resent work of Yarowsky (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995). $$$$$ Gale, Church and Yarowsky (1992) reported 92% accuracy, also on 2-way distinctions.
The best examples of this approach has been the resent work of Yarowsky (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995). $$$$$ Gale, William, Kenneth Church, and David Yarowsky (1992), "A Method for Disarnbiguating Word S~ses in ?

Much of the research in this area has been compromised by the fact that researchers have focused on lexical ambiguities that are not true word sense distinctions, such as words translated differently across two languages (Gale, Church, and Yarowsky, 1992) or homophones (Yarowsky, 1993). $$$$$ Gale, Church and Yarowsky (1992) reported 92% accuracy, also on 2-way distinctions.
Much of the research in this area has been compromised by the fact that researchers have focused on lexical ambiguities that are not true word sense distinctions, such as words translated differently across two languages (Gale, Church, and Yarowsky, 1992) or homophones (Yarowsky, 1993). $$$$$ Gale, William, Kenneth Church, and David Yarowsky (1992), "A Method for Disarnbiguating Word S~ses in ?

Pragmatic domain codes can be used to disambiguate (usually nominal) senses, as was shown by (Bruce and Guthrie, 1992) and (Yarowsky, 1992). $$$$$ This range was shown by Gale, Church and Yarowsky (1992) to be useful for this type of broad topic classification, in contrast to the relatively narrow (+3-6 word) window used in previous studies (e.g.
Pragmatic domain codes can be used to disambiguate (usually nominal) senses, as was shown by (Bruce and Guthrie, 1992) and (Yarowsky, 1992). $$$$$ Gale, Church and Yarowsky (1992) reported 92% accuracy, also on 2-way distinctions.

 $$$$$ The one miselassified case had a low score for all models, indicating a lack of confidence in any classification.
 $$$$$ OF COL1NG-92, NANrFES, AUG. 23-28, 1992

Some clusters of studies have used common test suites, most notably the 2094-word Hne data of Leacock et al (1993), shared by Lehman (1994) and Mooney (1996) and evaluated on the system of Gale, Church and Yarowsky (1992). $$$$$ This range was shown by Gale, Church and Yarowsky (1992) to be useful for this type of broad topic classification, in contrast to the relatively narrow (+3-6 word) window used in previous studies (e.g.
Some clusters of studies have used common test suites, most notably the 2094-word Hne data of Leacock et al (1993), shared by Lehman (1994) and Mooney (1996) and evaluated on the system of Gale, Church and Yarowsky (1992). $$$$$ Gale, Church and Yarowsky (1992) reported 92% accuracy, also on 2-way distinctions.

Yarowsky (Yarowsky, 1992) used instead thesauri for their experiments. $$$$$ This range was shown by Gale, Church and Yarowsky (1992) to be useful for this type of broad topic classification, in contrast to the relatively narrow (+3-6 word) window used in previous studies (e.g.
Yarowsky (Yarowsky, 1992) used instead thesauri for their experiments. $$$$$ Gale, Church and Yarowsky (1992) reported 92% accuracy, also on 2-way distinctions.

The massive network of inverted semrel structures contained in MindNet invalidates the criticism leveled against dictionary-based methods by Yarowsky (1992) and Ide and Veronis (1993) that LKBs created from MRDs provide spotty coverage of a language at best. $$$$$ Others such as Lesk (1986), Walker (1987), Veronis and Ide (1990), and Guthrie et al.
The massive network of inverted semrel structures contained in MindNet invalidates the criticism leveled against dictionary-based methods by Yarowsky (1992) and Ide and Veronis (1993) that LKBs created from MRDs provide spotty coverage of a language at best. $$$$$ Until more diverse, large bilingual corpora become available, the coverage of these methods will remain limited.

Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts (e.g., Brown et al 1992, Yarowsky 1992), as well as in similar predicate argument structure contexts (e.g., Grishman and Sterling 1994). $$$$$ Collect contexts which are representative of the Roget category 2.
Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts (e.g., Brown et al 1992, Yarowsky 1992), as well as in similar predicate argument structure contexts (e.g., Grishman and Sterling 1994). $$$$$ Similar problems occur with the musical senses of bass.

As in prior work including B&L, we rely on the intuition that the senses of words are hinted at by their contextual information (Yarowsky, 1992). From the perspective of a generative process, neighboring words of a target are generated by the target's underlying sense. $$$$$ list of the words in each category.
As in prior work including B&L, we rely on the intuition that the senses of words are hinted at by their contextual information (Yarowsky, 1992). From the perspective of a generative process, neighboring words of a target are generated by the target's underlying sense. $$$$$ tense classification is based exclusively on otmte~tual information, i dependent of he underlying prd3abillt y of a given Re?el category appearing at any point in the colpos.

 $$$$$ The one miselassified case had a low score for all models, indicating a lack of confidence in any classification.
 $$$$$ OF COL1NG-92, NANrFES, AUG. 23-28, 1992
