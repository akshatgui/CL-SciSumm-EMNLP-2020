Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009).
Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ The first, P(tIm), is the fraction of times the title t is the target page for an anchor text m. This single feature is a very reliable indicator of the correct disambiguation (Fader et al., 2009), and we use it as a baseline in our experiments.

We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ The majority of the terms selected in all summaries refer to the general issues related to China, such as “legalism, reform, military, control, etc.”, while a minority of the terms actually allow disambiguation between the candidates.
We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ We train the coefficients for the ranker features using a linear Ranking Support Vector Machine, using training data gathered from Wikipedia.

The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009).
The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ In this case, all mentions of all the detected named entities are linked.

Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009).
Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ Wikipedia was first explored as an information source for named entity disambiguation and information retrieval by Bunescu and Pasca (2006).

In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.
In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009).

Additionally, while (Rahman and Ng, 2011) uses the union of all possible meanings a mention may have in Wikipedia, we deploy GLOW (Ratinov et al., 2011), a context-sensitive system for disambiguation to Wikipedia. $$$$$ Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009).
Additionally, while (Rahman and Ng, 2011) uses the union of all possible meanings a mention may have in Wikipedia, we deploy GLOW (Ratinov et al., 2011), a context-sensitive system for disambiguation to Wikipedia. $$$$$ In previous work, Cucerzan defined the disambiguation context as the union of disambiguation candidates for all the named entity mentions in the input document (2007).

We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ We train the coefficients for the ranker features using a linear Ranking Support Vector Machine, using training data gathered from Wikipedia.
We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ We train the linker as a separate linear Support Vector Machine.
