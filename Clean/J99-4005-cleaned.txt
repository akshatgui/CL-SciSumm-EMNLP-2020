The bias introduced by TMEMs is a practical alternative to finding optimal translations, which is NP-complete (Knight, 1999). $$$$$ Next we give separate polynomial-time reductions from two NP-complete problems.
The bias introduced by TMEMs is a practical alternative to finding optimal translations, which is NP-complete (Knight, 1999). $$$$$ In that case, finding a legal word ordering is like finding a complete circuit in a graph.

However, as phrase-based decoding usually casts translation as a string concatenation problem and permits arbitrary permutation, it proves to be NP-complete (Knight, 1999). $$$$$ We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence.
However, as phrase-based decoding usually casts translation as a string concatenation problem and permits arbitrary permutation, it proves to be NP-complete (Knight, 1999). $$$$$ We note that Brew (1992) discusses the NPcompleteness of a related problem, that of finding some permutation of a string that is acceptable to a given context-free grammar.

In (Knight,1999) it was proved that the Exact Decoding problem is NP-Hard when the language model is a bigram model. $$$$$ As with tagging, we can assume an alphabet of v source tokens, a bigram source model, a substitution channel model, and an m-token coded text.
In (Knight,1999) it was proved that the Exact Decoding problem is NP-Hard when the language model is a bigram model. $$$$$ If we assume that the channel model offers deterministic, word-for-word translations, then the bigram source model takes responsibility for ordering them.

Note that our results for decoding are sharper than that of (Knight, 1999). $$$$$ We note that Brew (1992) discusses the NPcompleteness of a related problem, that of finding some permutation of a string that is acceptable to a given context-free grammar.
Note that our results for decoding are sharper than that of (Knight, 1999). $$$$$ Both of these results deal with decision problems.

However allowing reordering in translation is computationally expensive and in some cases even provably NP-complete (Knight, 1999). $$$$$ Next we give separate polynomial-time reductions from two NP-complete problems.
However allowing reordering in translation is computationally expensive and in some cases even provably NP-complete (Knight, 1999). $$$$$ Finally, expensive decoding also suggests expensive training from unannotated (monolingual) texts, which presents a challenging bottleneck for extending statistical machine translation to language pairs and domains where large bilingual corpora do not exist.

In theory, this process can be reduced to the Traveling Salesman Problem and thus requires an exponential time algorithm (Knight, 1999). $$$$$ Salesman Problem.
In theory, this process can be reduced to the Traveling Salesman Problem and thus requires an exponential time algorithm (Knight, 1999). $$$$$ To the extent that word ordering is like solving the Traveling Salesman Problem, it is encouraging substantial progress continues to be made on Traveling Salesman algorithms.

Part of the complexity arises from the expressive power of the translation model: for example, a phrase or word-based model with full reordering has exponential complexity (Knight, 1999). $$$$$ Decoding Complexity In Word-Replacement Translation Models
Part of the complexity arises from the expressive power of the translation model: for example, a phrase or word-based model with full reordering has exponential complexity (Knight, 1999). $$$$$ The former is more closely tied to the source model, and the latter to the channel model, though the complexity arises from the interaction of the two.

This approach offers four features absent from IBM-style models: (1) a recursive phrase-based translation, (2) a syntax-based language model, (3) the ability to condition a word's translation on the translation of syntactically related words, and (4) polynomial-time optimal alignment and decoding (Knight, 1999). $$$$$ Decoding Complexity In Word-Replacement Translation Models
This approach offers four features absent from IBM-style models: (1) a recursive phrase-based translation, (2) a syntax-based language model, (3) the ability to condition a word's translation on the translation of syntactically related words, and (4) polynomial-time optimal alignment and decoding (Knight, 1999). $$$$$ We should note that Model 1 is an intentionally simple translation model, one whose primary purpose in machine translation has been to allow bootstrapping into more complex translation models (e.g., IBM Models 2-5).

Both of the two steps are very time-consuming due to the exponential number of translation rules and the complex nature of machine translation as an NP-hard search problem (Knight, 1999). $$$$$ We review it here for purposes of comparison with machine translation.
Both of the two steps are very time-consuming due to the exponential number of translation rules and the complex nature of machine translation as an NP-hard search problem (Knight, 1999). $$$$$ We should note that Model 1 is an intentionally simple translation model, one whose primary purpose in machine translation has been to allow bootstrapping into more complex translation models (e.g., IBM Models 2-5).

If arbitrary re-orderings are allowed, the search problem is NP-complete (Knight, 1999). $$$$$ We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence.
If arbitrary re-orderings are allowed, the search problem is NP-complete (Knight, 1999). $$$$$ We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence.

Under certain restrictions, both algorithms handle MT-related problems efficiently that are generally NP complete (Knight, 1999). $$$$$ Next we give separate polynomial-time reductions from two NP-complete problems.
Under certain restrictions, both algorithms handle MT-related problems efficiently that are generally NP complete (Knight, 1999). $$$$$ It is also possible to devise approximation algorithms like those devised for other NP-complete problems.

In the general case, no efficient search algorithm exists to search all word or phrase reorderings (Knight, 1999). $$$$$ So no Hamilton Circuit exists.
In the general case, no efficient search algorithm exists to search all word or phrase reorderings (Knight, 1999). $$$$$ So far, statistical translation research has either opted for heuristic beam-search algorithms or different channel models.

(Knight, 1999) shows that the decoding problem for SMT as well as some bilingual tiling problems are NP-complete, so no efficient algorithm exists in the general case. $$$$$ Next we give separate polynomial-time reductions from two NP-complete problems.
(Knight, 1999) shows that the decoding problem for SMT as well as some bilingual tiling problems are NP-complete, so no efficient algorithm exists in the general case. $$$$$ So no Hamilton Circuit exists.

Investigation of the computational complexity of translation models has started in (Knight, 1999) for word-to-word models. $$$$$ Decoding Complexity In Word-Replacement Translation Models
Investigation of the computational complexity of translation models has started in (Knight, 1999) for word-to-word models. $$$$$ We should note that Model 1 is an intentionally simple translation model, one whose primary purpose in machine translation has been to allow bootstrapping into more complex translation models (e.g., IBM Models 2-5).

Knight (1999) has shown that even for a simple form of statistical MT models, the decoding problem is NP-complete. $$$$$ We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence.
Knight (1999) has shown that even for a simple form of statistical MT models, the decoding problem is NP-complete. $$$$$ We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence.

in particular (Knight, 1999) has shown that any TSP instance can be mapped to a sub-case of a word-based SMT model, demonstrating NP-hardness of the decoding task. $$$$$ We transform any Hamilton Circuit instance into an M1-DECIDE instance as follows.
in particular (Knight, 1999) has shown that any TSP instance can be mapped to a sub-case of a word-based SMT model, demonstrating NP-hardness of the decoding task. $$$$$ The proofs we presented are based on a worst-case analysis.

As already mentioned, the similarity between SMT decoding and TSP was recognized in (Knight, 1999), who focussed on showing that any TSP can be reformulated as a sub-class of the SMT decoding problem, proving that SMT decoding is NP-hard. $$$$$ Decoding Complexity In Word-Replacement Translation Models
As already mentioned, the similarity between SMT decoding and TSP was recognized in (Knight, 1999), who focussed on showing that any TSP can be reformulated as a sub-class of the SMT decoding problem, proving that SMT decoding is NP-hard. $$$$$ This paper looks at decoding complexity.

Knight (1999) has shown the problem to be NP-complete. $$$$$ We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence.
Knight (1999) has shown the problem to be NP-complete. $$$$$ We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence.

 $$$$$ In the main channel model of Brown et al. (1993), each English word token e, in a source sentence is assigned a &quot;fertility&quot; 0â€ž which dictates how many French words it will produce.
 $$$$$ Finally, expensive decoding also suggests expensive training from unannotated (monolingual) texts, which presents a challenging bottleneck for extending statistical machine translation to language pairs and domains where large bilingual corpora do not exist.

It has been known that phrase-based decoding should be constrained to some extent not only for transferring the NP-hard problem (Knight,1999) into a tractable one in practice but also for improving translation quality. $$$$$ Decoding Complexity In Word-Replacement Translation Models
It has been known that phrase-based decoding should be constrained to some extent not only for transferring the NP-hard problem (Knight,1999) into a tractable one in practice but also for improving translation quality. $$$$$ If word pairs have probabilities attached to them, then word ordering resembles the finding the least-cost circuit, also known as the Traveling Salesman Problem.
