and (2) the relation between predicates, question stem and the words that determine the answer type (Narayanan and Harabagiu, 2004). $$$$$ Question PATTERN: How can X be detected?
and (2) the relation between predicates, question stem and the words that determine the answer type (Narayanan and Harabagiu, 2004). $$$$$ bilogical agents] Possible paths of action Predicate?argument structure PREDICATE: = detect Arg0 (detector) : Answer (1) Arg1 (detected): biological weapons program Arg2 (instrument) ; Answer (2) 2) development ?

Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al, 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al, 2007) and pictorial communication systems (Goldberg et al, 2008). $$$$$ Question PATTERN: How can X be detected?
Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al, 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al, 2007) and pictorial communication systems (Goldberg et al, 2008). $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

In particular, the well-defined semantic role labeling (SRL) task has been drawing increasing attention in recent years due to its importance in natural language processing (NLP) applications, such as question answering (Narayanan and Harabagiu, 2004), information extraction (Surdeanu et al, 2003), and co-reference resolution (Kong et al, 2009). $$$$$ Question PATTERN: How can X be detected?
In particular, the well-defined semantic role labeling (SRL) task has been drawing increasing attention in recent years due to its importance in natural language processing (NLP) applications, such as question answering (Narayanan and Harabagiu, 2004), information extraction (Surdeanu et al, 2003), and co-reference resolution (Kong et al, 2009). $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

Systems for addressing complex information needs are interesting because they provide an opportunity to explore the role of semantic structures in question answering ,e.g., (Narayanan and Harabagiu, 2004). $$$$$ Question PATTERN: How can X be detected?
Systems for addressing complex information needs are interesting because they provide an opportunity to explore the role of semantic structures in question answering ,e.g., (Narayanan and Harabagiu, 2004). $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

For instance, information extraction (Surdeanu et al, 2003), question answering (Narayanan and Harabagiu, 2004) and machine translation (Boas, 2002) could stand to benefit from broad coverage semantic processing. $$$$$ Question PATTERN: How can X be detected?
For instance, information extraction (Surdeanu et al, 2003), question answering (Narayanan and Harabagiu, 2004) and machine translation (Boas, 2002) could stand to benefit from broad coverage semantic processing. $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

In particular, the well-defined semantic role labeling (SRL) task has been drawing more and more attention in recent years due to its importance in deep NLP applications, such as question answering (Narayanan and Harabagiu, 2004), information extraction (Surdeanu et al, 2003), and co-reference resolution (Ponzetto and Strube, 2006). $$$$$ Question PATTERN: How can X be detected?
In particular, the well-defined semantic role labeling (SRL) task has been drawing more and more attention in recent years due to its importance in deep NLP applications, such as question answering (Narayanan and Harabagiu, 2004), information extraction (Surdeanu et al, 2003), and co-reference resolution (Ponzetto and Strube, 2006). $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

Lexical semantic features are known to be helpful in both deep (Tetreault, 2005) and shallow interpretation tasks (Narayanan and Harabagiu,2004). $$$$$ ?9?????9??????2???????????
Lexical semantic features are known to be helpful in both deep (Tetreault, 2005) and shallow interpretation tasks (Narayanan and Harabagiu,2004). $$$$$ ?a???9?s???4???9?????a?s?0??2?a?

Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation ,information extraction (Hirschman et al, 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). $$$$$ Question PATTERN: How can X be detected?
Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation ,information extraction (Hirschman et al, 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). $$$$$ bilogical agents] Possible paths of action Predicate?argument structure PREDICATE: = detect Arg0 (detector) : Answer (1) Arg1 (detected): biological weapons program Arg2 (instrument) ; Answer (2) 2) development ?

Semantic types and role labelling are helpful in both deep (Tetreault, 2005) and shallow interpretation tasks (Narayanan and Harabagiu, 2004). $$$$$ ?9?????9??????2???????????
Semantic types and role labelling are helpful in both deep (Tetreault, 2005) and shallow interpretation tasks (Narayanan and Harabagiu, 2004). $$$$$ ?a???9?s???4???9?????a?s?0??2?a?

One such question answering system (Narayanan and Harabagiu, 2004) takes PropBank/FrameNet annotations as input, uses the PropBank targets to indicate which actions are being described with which arguments and produces an answer using probabilistic models of actions as the tools of inference. $$$$$ Question PATTERN: How can X be detected?
One such question answering system (Narayanan and Harabagiu, 2004) takes PropBank/FrameNet annotations as input, uses the PropBank targets to indicate which actions are being described with which arguments and produces an answer using probabilistic models of actions as the tools of inference. $$$$$ bilogical agents] Possible paths of action Predicate?argument structure PREDICATE: = detect Arg0 (detector) : Answer (1) Arg1 (detected): biological weapons program Arg2 (instrument) ; Answer (2) 2) development ?

Typical tags include Agent, Patient, Source, etc. and some adjuncts such as Temporal, Manner, Extent, etc. Since the arguments can provide useful semantic information, the SRL is crucial to many natural language processing tasks, such as Question and Answering (Narayanan and Harabagiu 2004), Information Extraction (Surdeanu et al 2003), and Machine Translation (Boas 2002). $$$$$ 7KG HEU") MEANS: ?m SOURCE: "in Sovetskaya Gavan" GOODS: "approx.
Typical tags include Agent, Patient, Source, etc. and some adjuncts such as Temporal, Manner, Extent, etc. Since the arguments can provide useful semantic information, the SRL is crucial to many natural language processing tasks, such as Question and Answering (Narayanan and Harabagiu 2004), Information Extraction (Surdeanu et al 2003), and Machine Translation (Boas 2002). $$$$$ 7 KG of HEU" VICTIM: "Russian Navy, Pacific Fleet,Naval Base" PERPETRATOR: ?x:AGENT SOURCE: "in Sovetskaya Gavan" GOODS: "approx.

Harabagiu, 2004) computed automatically from collections of documents relevant to a scenario in order to approximate the semantic content of a scenario, (Narayanan and Harabagiu, 2004) employed formal models of the interrelated events, actions, states, and relations implicit to a scenario in order to produce fine-grained, context sensitive inferences that could be used to answer questions. $$$$$ missiles] Topic relations: [develop ??
Harabagiu, 2004) computed automatically from collections of documents relevant to a scenario in order to approximate the semantic content of a scenario, (Narayanan and Harabagiu, 2004) employed formal models of the interrelated events, actions, states, and relations implicit to a scenario in order to produce fine-grained, context sensitive inferences that could be used to answer questions. $$$$$ program], [produce ??

Examples include information extraction (Surdeanu et al, 2003), question answering (Narayanan and Harabagiu, 2004), machine translation (Boas, 2005), and summarization (Melli et al, 2005). Much progress in the area of semantic role labeling is due to the creation of resources like FrameNet (Fillmore et al, 2003), which document the surface realization of semantic roles in real world corpora. $$$$$ Question PATTERN: How can X be detected?
Examples include information extraction (Surdeanu et al, 2003), question answering (Narayanan and Harabagiu, 2004), machine translation (Boas, 2005), and summarization (Melli et al, 2005). Much progress in the area of semantic role labeling is due to the creation of resources like FrameNet (Fillmore et al, 2003), which document the surface realization of semantic roles in real world corpora. $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

It was shown that the identification of such event frames has a significant contribution for many Natural Language Processing (NLP) applications such as Information Extraction (Surdeanu et al, 2003) and Question Answering (Narayanan and Harabagiu, 2004). $$$$$ Question PATTERN: How can X be detected?
It was shown that the identification of such event frames has a significant contribution for many Natural Language Processing (NLP) applications such as Information Extraction (Surdeanu et al, 2003) and Question Answering (Narayanan and Harabagiu, 2004). $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

Thus, Narayanan and Harabagiu (2004) apply the argument-predicate relationship from PropBank (Palmer et al, 2005) together with the semantic frames from FrameNet (Baker et al, 1998) to create an inference mechanism to improve QA. $$$$$ bilogical agents] Possible paths of action Predicate?argument structure PREDICATE: = detect Arg0 (detector) : Answer (1) Arg1 (detected): biological weapons program Arg2 (instrument) ; Answer (2) 2) development ?
Thus, Narayanan and Harabagiu (2004) apply the argument-predicate relationship from PropBank (Palmer et al, 2005) together with the semantic frames from FrameNet (Baker et al, 1998) to create an inference mechanism to improve QA. $$$$$ FS(Q3): What [GOODS: kind of nuclear materials] were PAS(Q3): What [Arg1: kind of nuclear materials] were [Predicate: stolen] [target?Predicate: stolen] [VICTIM: from the Russian navy]?

Thus, Narayanan and Harabagiu (2004) apply the argument-predicate relationship from PropBank (Palmer et al, 2005) together with the semantic frames from FrameNet (Baker et al, 1998) to create an inference mechanism to improve QA. $$$$$ bilogical agents] Possible paths of action Predicate?argument structure PREDICATE: = detect Arg0 (detector) : Answer (1) Arg1 (detected): biological weapons program Arg2 (instrument) ; Answer (2) 2) development ?
Thus, Narayanan and Harabagiu (2004) apply the argument-predicate relationship from PropBank (Palmer et al, 2005) together with the semantic frames from FrameNet (Baker et al, 1998) to create an inference mechanism to improve QA. $$$$$ FS(Q3): What [GOODS: kind of nuclear materials] were PAS(Q3): What [Arg1: kind of nuclear materials] were [Predicate: stolen] [target?Predicate: stolen] [VICTIM: from the Russian navy]?

The benefit of semantic roles has already been demonstrated for a number of tasks, among others for machine translation (Boas, 2002), information extraction (Surdeanu et al, 2003), and question answering (Narayanan and Harabagiu, 2004). Robust and accurate automatic semantic role assignment, a prerequisite for the wide-range use of semantic roles in NLP, has been investigated in a number of studies and shared tasks. $$$$$ Question PATTERN: How can X be detected?
The benefit of semantic roles has already been demonstrated for a number of tasks, among others for machine translation (Boas, 2002), information extraction (Surdeanu et al, 2003), and question answering (Narayanan and Harabagiu, 2004). Robust and accurate automatic semantic role assignment, a prerequisite for the wide-range use of semantic roles in NLP, has been investigated in a number of studies and shared tasks. $$$$$ Question FOCUS: X = biological weapons program TOPIC MODEL [stockpile ??

Narayanan and Harabagiu (2004) were the first to stress the importance of semantic roles in answering complex questions. $$$$$ ?9?????9??????2???????????
Narayanan and Harabagiu (2004) were the first to stress the importance of semantic roles in answering complex questions. $$$$$ ?a???9?s???4???9?????a?s?0??2?a?
