It is well known that polysemous words usually have only one sense when used as part of a collocation or technical term (Yarowsky 1993). $$$$$ ONE SENSE PER COLLOCATION David Yarowsky* Department  of  Computer  and In format ion Science Univers i ty of  Pennsy lvania Philadelphia, PA 19104 yarowsky@unagi .c is .upenn.edu ABSTRACT Previous work [Gale, Church and Yarowsky, 1992] showed that with high probability a polysemous word has one sense per discourse.
It is well known that polysemous words usually have only one sense when used as part of a collocation or technical term (Yarowsky 1993). $$$$$ In this paper we show that for certain definitions of collocation, a polysemous word exhibits essentially only one sense per collocation.

The procedure for inducing these semantic frames is as follows $$$$$ When based on a single collocation type, such as the object of the verb or word immediately to the left, the pro- cedure is very simple.
The procedure for inducing these semantic frames is as follows $$$$$ In addition, we hope to incorporate class-based techniques, uch as the modeling of verb-argument selectional preferences [Resnik, 1992], as a mechanism for achieving im- proved performance on unfamiliar collocations.

For this merge, we assume one sense per collocation (Yarowsky, 1993) for predicate argument structures. $$$$$ ONE SENSE PER COLLOCATION David Yarowsky* Department  of  Computer  and In format ion Science Univers i ty of  Pennsy lvania Philadelphia, PA 19104 yarowsky@unagi .c is .upenn.edu ABSTRACT Previous work [Gale, Church and Yarowsky, 1992] showed that with high probability a polysemous word has one sense per discourse.
For this merge, we assume one sense per collocation (Yarowsky, 1993) for predicate argument structures. $$$$$ Therefore this method offers advantages over Bayesian classifier techniques which assume independence of the fea- tures used.

 $$$$$ For a more unbalanced observed istribution, such as 10/0, the probability of seeing the minor sense decreases to 2%, giving a cross-validated ntropy of H(.98,.02) = .14 bits.
 $$$$$ Yarowsky, David "Word-Sense Disambiguation Using Statisti- cal Models of Rogets Categories Trained on Large Corpora," in Proceedings, COLING-92, Nantes, France, 1992.

Much of the research in this area has been compromised by the fact that researchers have focussed on lexical ambiguities that are not true word sense distinctions, such as words translated differently across two languages (Gale, Church, and Yarowsky, 1992) or homophones (Yarowsky, 1993). $$$$$ Gale, W., K. Church, and D. Yarowsky, "One Sense Per Dis- course," Proceedings of the 4th DARPA Speech and Natural Language Workshop, 1992.
Much of the research in this area has been compromised by the fact that researchers have focussed on lexical ambiguities that are not true word sense distinctions, such as words translated differently across two languages (Gale, Church, and Yarowsky, 1992) or homophones (Yarowsky, 1993). $$$$$ Gale, W., K. Church, and D. Yarowsky, "A Method for Disam- biguating Word Senses in a Large Corpus," in Computers and the Humanities, 1993.

 $$$$$ For a more unbalanced observed istribution, such as 10/0, the probability of seeing the minor sense decreases to 2%, giving a cross-validated ntropy of H(.98,.02) = .14 bits.
 $$$$$ Yarowsky, David "Word-Sense Disambiguation Using Statisti- cal Models of Rogets Categories Trained on Large Corpora," in Proceedings, COLING-92, Nantes, France, 1992.

 $$$$$ For a more unbalanced observed istribution, such as 10/0, the probability of seeing the minor sense decreases to 2%, giving a cross-validated ntropy of H(.98,.02) = .14 bits.
 $$$$$ Yarowsky, David "Word-Sense Disambiguation Using Statisti- cal Models of Rogets Categories Trained on Large Corpora," in Proceedings, COLING-92, Nantes, France, 1992.

 $$$$$ For a more unbalanced observed istribution, such as 10/0, the probability of seeing the minor sense decreases to 2%, giving a cross-validated ntropy of H(.98,.02) = .14 bits.
 $$$$$ Yarowsky, David "Word-Sense Disambiguation Using Statisti- cal Models of Rogets Categories Trained on Large Corpora," in Proceedings, COLING-92, Nantes, France, 1992.

Following Yarowsky (1993), who explicitly addresses the use of collocations in the WSD work, we adopt his definition, adapted to our purpose $$$$$ DEF IN IT IONS OF  COLLOCATION Collocation means the co-occurrence of two words in some defined relationship.
Following Yarowsky (1993), who explicitly addresses the use of collocations in the WSD work, we adopt his definition, adapted to our purpose $$$$$ It appears that content words (nouns, verbs, adjectives, and adverbs) behave quite differently from function words (other parts of speech); we make use of this distinction in several definitions of collocation.

 $$$$$ For a more unbalanced observed istribution, such as 10/0, the probability of seeing the minor sense decreases to 2%, giving a cross-validated ntropy of H(.98,.02) = .14 bits.
 $$$$$ Yarowsky, David "Word-Sense Disambiguation Using Statisti- cal Models of Rogets Categories Trained on Large Corpora," in Proceedings, COLING-92, Nantes, France, 1992.

These methods consist of simple rules that can reliably assign a sense to certain word categories $$$$$ ONE SENSE PER COLLOCATION David Yarowsky* Department  of  Computer  and In format ion Science Univers i ty of  Pennsy lvania Philadelphia, PA 19104 yarowsky@unagi .c is .upenn.edu ABSTRACT Previous work [Gale, Church and Yarowsky, 1992] showed that with high probability a polysemous word has one sense per discourse.
These methods consist of simple rules that can reliably assign a sense to certain word categories $$$$$ More recent work [Brown et al.

In the early nineties two famous papers claimed that the behavior of word senses in texts adhered to two principles $$$$$ ONE SENSE PER COLLOCATION David Yarowsky* Department  of  Computer  and In format ion Science Univers i ty of  Pennsy lvania Philadelphia, PA 19104 yarowsky@unagi .c is .upenn.edu ABSTRACT Previous work [Gale, Church and Yarowsky, 1992] showed that with high probability a polysemous word has one sense per discourse.
In the early nineties two famous papers claimed that the behavior of word senses in texts adhered to two principles $$$$$ More recent work [Brown et al.

In order to analyze and compare the behavior of several kinds of collocations (cf. Section 3), Yarowsky (1993) used a measure of entropy as well as the results obtained when tagging heldout data with the collocations organized as decision lists (cf. Section 4). $$$$$ The algo- rithm used is based on decision lists [Rivest, 1987], and was discussed in [Sproat, Hirschberg, and Yarowsky 1992].
In order to analyze and compare the behavior of several kinds of collocations (cf. Section 3), Yarowsky (1993) used a measure of entropy as well as the results obtained when tagging heldout data with the collocations organized as decision lists (cf. Section 4). $$$$$ See Section 7.3 for a discussion of the "All Above" result.

Compared to Yarowsky (1993), who also took into account grammatical relations, we only share the content-word-to-left and the content-word-to-right collocations. $$$$$ If we actually build a disambiguation procedure using exclusively the content word to the right as information, such a system performs with 97% precision on new data where a content word appears to the right and for which there is in- formation in the model .3 This is considerably higher than the 3The correlation between these numbers is not a coincidence.
Compared to Yarowsky (1993), who also took into account grammatical relations, we only share the content-word-to-left and the content-word-to-right collocations. $$$$$ On average, the model content- word-to-right could only be applied in 29% of the test samples.

It is not clear how the smoothing technique proposed in (Yarowsky, 1993) could be extended to away ambiguities. $$$$$ As a solution to the data shortages for the above methods, [Gale, Church and Yarowsky 1992b] proposed the use of "pseudo-words," artificial sense ambiguities created by tak- ing two English words with the same part of speech (such as guerilla and reptile), and replacing each instance of both in a corpus with a new polysemous word guerrilla~reptile.
It is not clear how the smoothing technique proposed in (Yarowsky, 1993) could be extended to away ambiguities. $$$$$ For simplicity, in this experiment no secondary smoothing or pruning is done.

Collocations for fine-gained word-senses are sensibly weaker than those reported by Yarowsky (1993) for two-way ambiguous words. $$$$$ Results are itemized by the part of speech of the ambiguous word (not of the collocate).
Collocations for fine-gained word-senses are sensibly weaker than those reported by Yarowsky (1993) for two-way ambiguous words. $$$$$ Gale, W., K. Church, and D. Yarowsky, "A Method for Disam- biguating Word Senses in a Large Corpus," in Computers and the Humanities, 1993.

This paper shows that the one sense per collocation hypothesis is weaker for fine grained word sense distinctions (e.g. those in WordNet) $$$$$ We test his empirical hypothesis for several definitions of sense and collocation, and discover that it holds with 90-99% accuracy for binary ambiguities.
This paper shows that the one sense per collocation hypothesis is weaker for fine grained word sense distinctions (e.g. those in WordNet) $$$$$ One  Sense Per  Co l locat ion For the collocations tudied, it appears that the hypothesis of one sense per collocation holds with high probability for binary ambiguities.

A well-known issue in the WSD area is the one sense per collocation claim (Yarowsky, 1993) stating that the word meanings are strongly associated with the particular collocation in which the word is located. $$$$$ In this paper we show that for certain definitions of collocation, a polysemous word exhibits essentially only one sense per collocation.
A well-known issue in the WSD area is the one sense per collocation claim (Yarowsky, 1993) stating that the word meanings are strongly associated with the particular collocation in which the word is located. $$$$$ Our ex- periments have shown that for several definitions of sense and collocation, an ambiguous word has only one sense in a given collocation with a probability of 90-99%.

We admit here that, while we have been aware of the fact for long time, only after the dissemination of the closely related hypotheses of one sense per discourse (Gale, Church and Yarowsky 1992) and one sense per collocation (Yarowsky 1993), we are able to articulate the hypothesis of one tokenization per source. $$$$$ ONE SENSE PER COLLOCATION David Yarowsky* Department  of  Computer  and In format ion Science Univers i ty of  Pennsy lvania Philadelphia, PA 19104 yarowsky@unagi .c is .upenn.edu ABSTRACT Previous work [Gale, Church and Yarowsky, 1992] showed that with high probability a polysemous word has one sense per discourse.
We admit here that, while we have been aware of the fact for long time, only after the dissemination of the closely related hypotheses of one sense per discourse (Gale, Church and Yarowsky 1992) and one sense per collocation (Yarowsky 1993), we are able to articulate the hypothesis of one tokenization per source. $$$$$ Gale, W., K. Church, and D. Yarowsky, "One Sense Per Dis- course," Proceedings of the 4th DARPA Speech and Natural Language Workshop, 1992.

Yarowsky (1993) indicated that the objects of verbs play a more dominant role than their subjects in WSD and nouns acquire more stable disambiguating information from their noun or adjective modifiers. $$$$$ Verbs, for example, derive more disambiguating information from their objects (.95) than from their subjects (.90).
Yarowsky (1993) indicated that the objects of verbs play a more dominant role than their subjects in WSD and nouns acquire more stable disambiguating information from their noun or adjective modifiers. $$$$$ Verbs appear to be less useful for noun sense disambiguation, although they are relatively better indicators when the noun is their object rather than their subject.
