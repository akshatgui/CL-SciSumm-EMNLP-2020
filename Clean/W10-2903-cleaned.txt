Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available. $$$$$ The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).
Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available. $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.

Recent work by Clarke et al (2010) and Liang et al. $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.
Recent work by Clarke et al (2010) and Liang et al. $$$$$ The direct approach resembles learning a binary classifier over a latent structure (Chang et al., 2010a); while the aggressive approach has similarities with work that uses labeled structures and a binary signal indicating the existence of good structures to improve structured prediction (Chang et al., 2010b).

Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. $$$$$ We automatically generate a set of natural language queries and response pairs {(x, r)} by executing the annotated logical forms on the database.
Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.

In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance. $$$$$ The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).
In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance. $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.

To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments. $$$$$ The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).
To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments. $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.

Due to space consideration, we provide a brief description (see (Clarke et al, 2010) for more details). $$$$$ Due to space limitations we refer the reader to (Zelle and Mooney, 1996) for a detailed description of the Geoquery domain.
Due to space consideration, we provide a brief description (see (Clarke et al, 2010) for more details). $$$$$ The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).

We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al, 2010) for more details). $$$$$ We frame the inference problem as an Integer Linear Programming (ILP) problem (Equation (2)) in which the first-order decisions are governed by αcs, a binary decision variable indicating that constituent c is aligned with logical symbol s. And Qcs,dt capture the second-order decisions indicating the symbol t (associated with constituent d) is an argument to function s (associated with conIt is clear that there are dependencies between the α-variables and Q-variables.
We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al, 2010) for more details). $$$$$ For example, given that Qcs,dt is active, the corresponding αvariables αcs and αdt must also be active.

However, when trained using the noisy supervision, our method achieves substantially more accurate translations than a state-of-the-art semantic parser (Clarke et al, 2010) (specifically, 80.0% in F-Score compared to an F-Score of 66.7%). $$$$$ For example, whether next to and state forms next to(state(·)) or state(next to(·)).
However, when trained using the noisy supervision, our method achieves substantially more accurate translations than a state-of-the-art semantic parser (Clarke et al, 2010) (specifically, 80.0% in F-Score compared to an F-Score of 66.7%). $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.

It continues sampling a specification tree for each text specification until it finds one which successfully reads all of the input examples. The second baseline Aggressive is a state-of the-art semantic parsing framework (Clarke et al, 2010). The framework repeatedly predicts hidden structures (specification trees in our case) using a structure learner, and trains the structure learner based on the execution feedback of its predictions. $$$$$ When a structure is found with positive feedback it is added to the training pool for a structured learner.
It continues sampling a specification tree for each text specification until it finds one which successfully reads all of the input examples. The second baseline Aggressive is a state-of the-art semantic parsing framework (Clarke et al, 2010). The framework repeatedly predicts hidden structures (specification trees in our case) using a structure learner, and trains the structure learner based on the execution feedback of its predictions. $$$$$ Although our framework can also be applied in these settings we do not assume that the text can be grounded in a world state.

As in Clarke et al (2010), we obviate the need for annotated logical forms by considering the end-to-end problem of mapping questions to answers. $$$$$ Current approaches to semantic parsing, the task of converting text to a formal meaning representation, rely on annotated training data mapping sentences to logical forms.
As in Clarke et al (2010), we obviate the need for annotated logical forms by considering the end-to-end problem of mapping questions to answers. $$$$$ Note that for all possible logical forms and alignments there exists a one-to-one mapping to these decisions.

At the same time, representations such as FunQL (Kate et al, 2005), which was used in Clarke et al (2010), are simpler but lack the full expressive power of lambda calculus. $$$$$ The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).
At the same time, representations such as FunQL (Kate et al, 2005), which was used in Clarke et al (2010), are simpler but lack the full expressive power of lambda calculus. $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.

We first compare our system with Clarke et al (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs. $$$$$ Our experiments are designed to answer three questions

One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010). $$$$$ We consider scenarios where the feedback is provided as a binary signal, correct +1 or incorrect −1.
One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010). $$$$$ Analysis over the training data shows that in 66.8% examples both approaches predict a logical form that gives the correct answer.
