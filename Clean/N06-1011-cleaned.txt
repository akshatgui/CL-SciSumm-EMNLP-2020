We follow the recent work of (Klementiev and Roth 2006) who addressed the problem of discovery of transliterated named entities from comparable corpora and suggested that alignment may not be necessary for transliteration. $$$$$ Named Entity Transliteration And Discovery From Multilingual Comparable Corpora
We follow the recent work of (Klementiev and Roth 2006) who addressed the problem of discovery of transliterated named entities from comparable corpora and suggested that alignment may not be necessary for transliteration. $$$$$ In this work, we only consider single word Named Entities.

 $$$$$ The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.
 $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

 $$$$$ The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.
 $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

 $$$$$ The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.
 $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

 $$$$$ The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.
 $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

 $$$$$ The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.
 $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. $$$$$ We use a Discrete Fourier Transform (Arfken, 1985) based metric for computing similarity of time distributions, and we score NEs similarity with a linear transliteration model.
We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. $$$$$ It then uses temporal alignment (with thresholding) to select the best transliteration candidate for the next round of training (lines 8, and 9).

This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ Finally, pairs of NEs and the best candidates are used to iteratively train the transliteration model.
This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ This model is called the infinite attribute model (Blum, 1992) and it follows the perceptron version in SNoW (Roth, 1998).

We adopt a methodology parallel to that of [Klementiev and Roth, 2006], but we focus instead on mining parallel named entity transliteration pairs, using a well-trained linear classifier to identify transliteration pairs. $$$$$ Named Entity Transliteration And Discovery From Multilingual Comparable Corpora
We adopt a methodology parallel to that of [Klementiev and Roth, 2006], but we focus instead on mining parallel named entity transliteration pairs, using a well-trained linear classifier to identify transliteration pairs. $$$$$ Transliteration based approaches require a good model, typically handcrafted or trained on a clean set of transliteration pairs.

Recently, [Klementiev and Roth, 2006] outlined an approach by leveraging the availability of article aligned news corpora between English and Russian, and tools in English, for discovering transliteration pairs between the two languages, and progressively refining the discovery process. $$$$$ We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.
Recently, [Klementiev and Roth, 2006] outlined an approach by leveraging the availability of article aligned news corpora between English and Russian, and tools in English, for discovering transliteration pairs between the two languages, and progressively refining the discovery process. $$$$$ We ran experiments using a bilingual comparable English-Russian news corpus we built by crawling a Russian news web site (www.lenta.ru).

As in [Klementiev and Roth, 2006] no language specific knowledge was used to refine our mining process, making the approach broadly applicable. $$$$$ This approach is specific to Russian morphology, and would have to be altered for other languages.
As in [Klementiev and Roth, 2006] no language specific knowledge was used to refine our mining process, making the approach broadly applicable. $$$$$ We expect that language specific knowledge used to discover accurate equivalence classes would result in performance improvements.

In this section, we outline briefly the methodology presented in [Klementiev and Roth, 2006], and refer interested readers to the source for details. $$$$$ In the rest of the paper, whenever we refer to a Named Entity, we imply an NE equivalence class.
In this section, we outline briefly the methodology presented in [Klementiev and Roth, 2006], and refer interested readers to the source for details. $$$$$ We developed a linear discriminative transliteration model, and presented a method to automatically generate features.

We start with comparable corpora in English and Tamil, similar in size to that used in [Klementiev and Roth, 2006], and using the English side of this corpora, first, we extract all the NEs that occur more than a given threshold parameter, FE, using a standard NER tool. $$$$$ Named Entity Transliteration And Discovery From Multilingual Comparable Corpora
We start with comparable corpora in English and Tamil, similar in size to that used in [Klementiev and Roth, 2006], and using the English side of this corpora, first, we extract all the NEs that occur more than a given threshold parameter, FE, using a standard NER tool. $$$$$ The first observation is that NEs in one language in such corpora tend to co-occur with their counterparts in the other.

While we adopted a methodology similar to that in [Klementiev and Roth, 2006], our focus was on mining parallel NE transliteration pairs, leveraging the availability of comparable corpora and a well-trained linear classifier to identify transliteration pairs. $$$$$ Named Entity Transliteration And Discovery From Multilingual Comparable Corpora
While we adopted a methodology similar to that in [Klementiev and Roth, 2006], our focus was on mining parallel NE transliteration pairs, leveraging the availability of comparable corpora and a well-trained linear classifier to identify transliteration pairs. $$$$$ Transliteration based approaches require a good model, typically handcrafted or trained on a clean set of transliteration pairs.

However, several techniques for mining name transliterations from monolingual and comparable corpora have been studied (Pasternack and Roth, 2009), (Goldwasser and Roth, 2008), (Klementiev and Roth, 2006), (Sproat et al, 2006), (Udupa et al, 2009b). $$$$$ For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and English-Korean generative transliteration models, respectively.
However, several techniques for mining name transliterations from monolingual and comparable corpora have been studied (Pasternack and Roth, 2009), (Goldwasser and Roth, 2008), (Klementiev and Roth, 2006), (Sproat et al, 2006), (Udupa et al, 2009b). $$$$$ The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005).

Character unigrams and bigrams were used as features to learn a discriminative transliteration model and time series similarity was combined with the transliteration similarity model (Klementiev and Roth, 2006). $$$$$ We use a Discrete Fourier Transform (Arfken, 1985) based metric for computing similarity of time distributions, and we score NEs similarity with a linear transliteration model.
Character unigrams and bigrams were used as features to learn a discriminative transliteration model and time series similarity was combined with the transliteration similarity model (Klementiev and Roth, 2006). $$$$$ We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language.

Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al, 2008). $$$$$ Most current approaches employ machine learning techniques and require supervised data.
Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al, 2008). $$$$$ On the other hand, comparable multilingual data (such as multilingual news streams) are increasingly available (see section 4).

The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and English-Korean generative transliteration models, respectively.
The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005).

We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. $$$$$ We use a method called the F-index (Hetland, 2004) to implement the similarity function on line 8 of the algorithm.
We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. $$$$$ We use the perceptron (Rosenblatt, 1958) algorithm to train the model.

Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.
Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ We developed a linear discriminative transliteration model, and presented a method to automatically generate features.
