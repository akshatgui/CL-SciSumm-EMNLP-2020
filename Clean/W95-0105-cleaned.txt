For instance, work on word sense disambiguation i corpora (e.g. Resnik 1995), could lead to an estimate of frequencies for word senses in general, with rule-derived senses simply being a special case. $$$$$ In each case, I give the source of the noun grouping, the grouping itself, and for each word a description of word senses together with their values of y).
For instance, work on word sense disambiguation i corpora (e.g. Resnik 1995), could lead to an estimate of frequencies for word senses in general, with rule-derived senses simply being a special case. $$$$$ For each case, they were given the full set of nouns in the numbered category (as shown above) together with descriptions of the WordNet senses for the word to be disambiguated (as, for example, the list of 25 senses for line given in the previous section, though thankfully few words have that many senses!).

An adaptation of Lesk dictionary-based WSD algorithm has been used to disambiguate adjectives and ad verbs (Banerjee and Pedersen, 2002), an adaptation of the Resnik algorithm has been used to disambiguate nouns (Resnik, 1995), while the algorithm we developed for disambiguating verbs exploits the nouns in the context of the verb as well as the nouns both in the glosses and in the phrases that WordNet utilizes to describe the usage of a verb. $$$$$ Algorithm.
An adaptation of Lesk dictionary-based WSD algorithm has been used to disambiguate adjectives and ad verbs (Banerjee and Pedersen, 2002), an adaptation of the Resnik algorithm has been used to disambiguate nouns (Resnik, 1995), while the algorithm we developed for disambiguating verbs exploits the nouns in the context of the verb as well as the nouns both in the glosses and in the phrases that WordNet utilizes to describe the usage of a verb. $$$$$ First, unlike Sussna's proposal, this algorithm aims to disambiguate groupings of nouns already established (e.g. by clustering, or by manual effort) to be related, as opposed to groupings of nouns that happen to appear near each other in running text (which may or may not reflect relatedness based on meaning).

The procedure is obtained by making some variations to the algorithm designed by Resnik (1995) for disambiguating noun groups. $$$$$ Disambiguating Noun Groupings With Respect To Wordnet Senses
The procedure is obtained by making some variations to the algorithm designed by Resnik (1995) for disambiguating noun groups. $$$$$ Immediate plans include a larger scale version of the experiment presented here, involving thesaurus classes, as well as a similarly designed evaluation of how the algorithm fares when presented with noun groups produced by distributional clustering.

JIGSAW nouns differs from the original algorithm by Resnik (1995) in the similarity measure used to compute relatedness of two senses. $$$$$ Algorithm.
JIGSAW nouns differs from the original algorithm by Resnik (1995) in the similarity measure used to compute relatedness of two senses. $$$$$ Third, unlike Sussna's algorithm, the semantic similarity/distance computation here is not based on path length, but on information content, a choice that I have argued for elsewhere (Resnik, 1993; Resnik, 1995).

Although the assessment of semantic similarity using a dictionary database as knowledge source has been recognized as providing significant cues for word clustering (Resnik 1995b) and the determination of lexical cohesion (Morris& amp; Hirst, 1991), its relevance for word disambiguation in running text remains relatively unexplored. $$$$$ If successful, such an approach has obvious benefits

Resnik (1995a) defines the semantic similarity between two words as the entropy value of the most informative concept subsuming the two words in a hierarchically structured thesaurus. $$$$$ The intuition behind the approach is simple

At present, we are trying to integrate the word sense disambiguation method proposed in (Resnik, 1995) into our system. $$$$$ In this section I present a number of examples for evaluation by inspection.
At present, we are trying to integrate the word sense disambiguation method proposed in (Resnik, 1995) into our system. $$$$$ The group comes from from the thesaurus entry for the word method.

Semantic tags are assigned from on-line thesaura like WordNet (Basili et al 1996) (Resnik, 1995), Roget's categories (Yarowsky 1992) (Chen and Chen, 1996), the Japanese BGH (Utsuro et al 1993), or assigned manually (Basili et al 1992). $$$$$ (Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).
Semantic tags are assigned from on-line thesaura like WordNet (Basili et al 1996) (Resnik, 1995), Roget's categories (Yarowsky 1992) (Chen and Chen, 1996), the Japanese BGH (Utsuro et al 1993), or assigned manually (Basili et al 1992). $$$$$ lActually, this depends on the fine-grainedness of sense distinctions; clearly one could annotate corpora with very high level semantic distinctions For example, Basili et al. (1994) take such a coarse-grained approach, utilizing on the order of 10 to 15 semantic tags for a given domain.

The verbs are tagged with respect to senses in WordNet (Miller 1990), which has become widely used, for example in corpus-annotation projects (Miller et al 1994, Ng& amp; Hian 1996, and Grishman et al 1994) and for performing disambiguation (Resnik 1995 and Leacock et ai. $$$$$ (Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).
The verbs are tagged with respect to senses in WordNet (Miller 1990), which has become widely used, for example in corpus-annotation projects (Miller et al 1994, Ng& amp; Hian 1996, and Grishman et al 1994) and for performing disambiguation (Resnik 1995 and Leacock et ai. $$$$$ It is quite small, by current corpus standards (on the order of hundreds of thousands of words, rather than millions or tens of millions); the direct annotation methodology used to create it is labor intensive (Marcus et al. (1993) found that direct annotation takes twice as long as automatic tagging plus correction, for partof-speech annotation); and the output quality reflects the difficulty of the task (inter-annotator disagreement is on the order of 10%, as contrasted with the approximately 3% error rate reported for part-of-speech annotation by Marcus et al.).

Finally, disambiguating the direct object according to WordNet categories, e.g., Resnik (1995), would improve the accuracy of using these categories to disambiguate verbs. $$$$$ Disambiguating Noun Groupings With Respect To Wordnet Senses
Finally, disambiguating the direct object according to WordNet categories, e.g., Resnik (1995), would improve the accuracy of using these categories to disambiguate verbs. $$$$$ And my own treatment of selectional constraints (Resnik, 1993) provides a way to describe the plausibility of co-occurrence in terms of WordNet's semantic categories, using co-occurrence relationships mediated by syntactic structure.

There have been a number of attempts to combine paradigmatic and syntagmatic similarity strategies (e.g., Hearst and Grefenstette 1992, Resnik 1995). $$$$$ (Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).
There have been a number of attempts to combine paradigmatic and syntagmatic similarity strategies (e.g., Hearst and Grefenstette 1992, Resnik 1995). $$$$$ Third, unlike Sussna's algorithm, the semantic similarity/distance computation here is not based on path length, but on information content, a choice that I have argued for elsewhere (Resnik, 1993; Resnik, 1995).

Eventually, the sense supported by those patterns which are semantically closer to the context in question is selected as the most likely one (see, among others, [Dolan, 1994], [Resnik, 1995a, 1995b], [Agirre and Rigau, 1996], [Sanfilippo, 1997]). $$$$$ Consider, for example, the cluster containing attorney, counsel, trial, court, and judge, used by Brown et al. (1992) to illustrate a &quot;semantically sticky&quot; group of words.
Eventually, the sense supported by those patterns which are semantically closer to the context in question is selected as the most likely one (see, among others, [Dolan, 1994], [Resnik, 1995a, 1995b], [Agirre and Rigau, 1996], [Sanfilippo, 1997]). $$$$$ The word stray probably should be excluded also, since it most likely appears on this list as an adjective (as in &quot;stray bullet&quot;).

Some of them have been fully tested in real size texts (e.g. statistical methods (Yarowsky, 1992), (Yarowsky, 1994), (Miller and Teibel, 1991), knowledge based methods (Sussna, 1993), (Agirre and Rigau, 1996), or mixed methods (Richardson et al, 1994), (Resnik, 1995)). $$$$$ (Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).
Some of them have been fully tested in real size texts (e.g. statistical methods (Yarowsky, 1992), (Yarowsky, 1994), (Miller and Teibel, 1991), knowledge based methods (Sussna, 1993), (Agirre and Rigau, 1996), or mixed methods (Richardson et al, 1994), (Resnik, 1995)). $$$$$ One obvious solution to this problem would be to extend distributional grouping methods to word senses.
