The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ However, instead of simply extracting sentences as current summarizers do, the cut and paste system will &quot;smooth&quot; the extracted sentences by editing them.
The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ The task of the sentence reduction module, described in detail in (Jing, 2000), is to remove extraneous phrases from extracted sentences.

Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ The summarizer edits extracted sentences, using reduction to remove inessential phrases and combination to merge resulting phrases together as coherent sentences.
Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ The task of the sentence reduction module, described in detail in (Jing, 2000), is to remove extraneous phrases from extracted sentences.

Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ Multiple components can be removed.
Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ The phrases we remove from an extracted sentence include clauses, prepositional phrases, gerunds, and to-infinitives.

Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ The decomposition program, see (Jing and McKeown, 1999) for details, is used to analyze the construction of sentences in human-written abstracts.
Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ (Mani et al., 1999) addressed the problem of revising summaries to improve their quality.

Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ We evaluated the decomposition program by two experiments, described in (Jing and McKeown, 1999).
Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ (Mani et al., 1999) addressed the problem of revising summaries to improve their quality.

We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ The task of the sentence reduction module, described in detail in (Jing, 2000), is to remove extraneous phrases from extracted sentences.
We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ We evaluated the decomposition program by two experiments, described in (Jing and McKeown, 1999).

The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ The major components of the system, including sentence reduction, sentence combination, decomposition, and sentence selection, are described in Section 4.
The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ The task of the sentence reduction module, described in detail in (Jing, 2000), is to remove extraneous phrases from extracted sentences.

First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ Related work is discussed in Section 6.
First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ The task of the sentence reduction module, described in detail in (Jing, 2000), is to remove extraneous phrases from extracted sentences.

Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ (5) generalization or specification Replace phrases or clauses with more general or specific descriptions.
Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ Input to the system is a single document from any domain.

Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ We found that reusing article text for summarization is almost universal in the corpus we studied.
Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ We use these heuristic rules to create a Hidden Markov Model.

Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ However, the combination operations and combination rules that we derived from corpus analysis are significantly different from those used in the above system, which mostly came from operations in traditional natural language generation.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ We developed a sentence reduction module that makes reduction decisions using multiple sources of knowledge.

Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ We also describe the six cut and paste operations.
Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ We evaluated the decomposition program by two experiments, described in (Jing and McKeown, 1999).

Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ We also describe the six cut and paste operations.
Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ We manually analyzed 30 articles and their corresponding human-written summaries; the articles and their summaries come from different domains ( 15 general news reports, 5 from the medical domain, 10 from the legal domain) and the summaries were written by professionals from different organizations.
