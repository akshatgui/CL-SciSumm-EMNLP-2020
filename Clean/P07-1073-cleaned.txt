In this section, we show that many relationships are consistently expressed using a compact set of relation-independent lexico-syntactic patterns, and quantify their frequency based on a sample of 500 sentences selected at random from an IE training corpus developed by (Bunescu and Mooney, 2007). $$$$$ The training bags consist of sentences extracted from online documents, using the methodology described in Section 6.
In this section, we show that many relationships are consistently expressed using a compact set of relation-independent lexico-syntactic patterns, and quantify their frequency based on a sample of 500 sentences selected at random from an IE training corpus developed by (Bunescu and Mooney, 2007). $$$$$ Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.

The first two datasets were collected from the Web, and made available by Bunescu and Mooney (2007). $$$$$ Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.
The first two datasets were collected from the Web, and made available by Bunescu and Mooney (2007). $$$$$ We have presented a new approach to relation extraction that leverages the vast amount of information available on the web.

To resolve this problem, Bunescu and Mooney (2007), Riedel et al (2010) and Yao et al (2010) relaxed the DS assumption to the at least-one assumption and employed multi-instance learning techniques to identify wrongly labeled instances. $$$$$ MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005).
To resolve this problem, Bunescu and Mooney (2007), Riedel et al (2010) and Yao et al (2010) relaxed the DS assumption to the at least-one assumption and employed multi-instance learning techniques to identify wrongly labeled instances. $$$$$ Gartner et al. (2002) adapted SVMs to the MIL setting using various multi-instance kernels.

Such data sets have been utilized successfully for relation extraction from the web (Bunescu and Mooney, 2007). $$$$$ Using a limited set of entity pairs (e.g. those in Table 1) and their associated bags as training data, the aim is to induce a relation extraction system that can reliably decide whether two entities mentioned in the same sentence exhibit the target relationship or not.
Such data sets have been utilized successfully for relation extraction from the web (Bunescu and Mooney, 2007). $$$$$ An interesting potential application of our approach is a web relation-extraction system similar to Google Sets, in which the user provides only a handful of pairs of entities known to exhibit or not to exhibit a particular relation, and the system is used to find other pairs of entities exhibiting the same relation.

Bunescu and Mooney (2007) follow a classification-based approach to RE. $$$$$ We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision.
Bunescu and Mooney (2007) follow a classification-based approach to RE. $$$$$ When used for classification, the decision function computed by the learning algorithm is equivalent to a hyperplane in this feature space.

One approach for taxonomy deduction is to use explicit expressions (Iwaska et al, 2000) or lexical and semantic patterns such as is a (Snow et al, 2004), similar usage (Kozareva et al, 2008), synonyms and antonyms (Lin et al, 2003), purpose (Cimiano and Wenderoth, 2007), and employed by (Bunescu and Mooney, 2007) to extract and organize terms. $$$$$ MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005).
One approach for taxonomy deduction is to use explicit expressions (Iwaska et al, 2000) or lexical and semantic patterns such as is a (Snow et al, 2004), similar usage (Kozareva et al, 2008), synonyms and antonyms (Lin et al, 2003), purpose (Cimiano and Wenderoth, 2007), and employed by (Bunescu and Mooney, 2007) to extract and organize terms. $$$$$ A more recent IE system that works by bootstrapping relation extraction patterns from the web is KNOWITALL (Etzioni et al., 2005).

We used the dataset by Bunescu and Mooney (2007), which we selected because it contains multiple realizations of an entity pair in a target semantic relation, unlike similar datasets such as the one by Roth and Yih (2002). $$$$$ In Figure 1, for inMIL problems: the training dataset contains very stance, sentence 53 contains two non-core frame elefew bags, and each bag can be very large.
We used the dataset by Bunescu and Mooney (2007), which we selected because it contains multiple realizations of an entity pair in a target semantic relation, unlike similar datasets such as the one by Roth and Yih (2002). $$$$$ Any pair of entities different from the relation pair is very likely to be a negative example for that relation.

One heuristic is to assume that each candidate mention tuple of a training fact is indeed expressing the corresponding relation (Bunescu and Mooney, 2007). $$$$$ We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision.
One heuristic is to assume that each candidate mention tuple of a training fact is indeed expressing the corresponding relation (Bunescu and Mooney, 2007). $$$$$ Alternatively, implicit negative evidence can be extracted from sentences in positive bags by exploiting the fact that, besides the two relation arguments, a sentence from a positive bag may contain other entity mentions.

Notable exceptions include Rosario and Hearst (2005) and Bunescu and Mooney (2007), who tackle relation classification and extraction tasks by considering the set of contexts in which the members of a candidate relation argument pair co-occur. $$$$$ Any pair of entities different from the relation pair is very likely to be a negative example for that relation.
Notable exceptions include Rosario and Hearst (2005) and Bunescu and Mooney (2007), who tackle relation classification and extraction tasks by considering the set of contexts in which the members of a candidate relation argument pair co-occur. $$$$$ Comparatively, the approach presented in this paper requires only a small number of queries: one query per relation pair, and one query for each relation argument.

The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). $$$$$ We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision.
The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). $$$$$ Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.

Bunescu and Mooney (2007) presented an approach to extract relations from the Web using minimal supervision. $$$$$ Learning to Extract Relations from the Web using Minimal Supervision
Bunescu and Mooney (2007) presented an approach to extract relations from the Web using minimal supervision. $$$$$ We present experimental results demonstrating that our approach is able to accurately extract relations from the web by learning from such weak supervision.

Bunescu and Mooney (2007) connect weak supervision with multi-instance learning and extend their relational extraction kernel to this context. $$$$$ Multiple instance learning (MIL) is a machine learning framework that exploits this sort of weak supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative.
Bunescu and Mooney (2007) connect weak supervision with multi-instance learning and extend their relational extraction kernel to this context. $$$$$ As formulated above, the learning task can be seen as an instance of multiple instance learning.

 $$$$$ The subsequence kernel induces a feature space where each dimension corresponds to a sequence of words.
 $$$$$ This work was supported by grant IIS-0325116 from the NSF, and a gift from Google Inc.

Bunescu and Mooney (2007) and Riedel et al (2010) model distant supervision for relation extraction as a multi-instance single-label problem, which allows multiple mentions for the same tuple but disallows more than one label per object. $$$$$ MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005).
Bunescu and Mooney (2007) and Riedel et al (2010) model distant supervision for relation extraction as a multi-instance single-label problem, which allows multiple mentions for the same tuple but disallows more than one label per object. $$$$$ Gartner et al. (2002) adapted SVMs to the MIL setting using various multi-instance kernels.

As pointed out by (Bunescu and Mooney, 2007), even though the same entities co-occur in multiple sentences, they are not necessarily linked by the same relationship in all of them. $$$$$ Although not all of the sentences for positive pairs will state the desired relationship, many of them will.
As pointed out by (Bunescu and Mooney, 2007), even though the same entities co-occur in multiple sentences, they are not necessarily linked by the same relationship in all of them. $$$$$ We address the task of learning a relation extraction system targeted to a fixed binary relationship R. The only supervision given to the learning algorithm is a small set of pairs of named entities that are known to belong (positive) or not belong (negative) to the given relationship.

One means of combating this is suggested by (Bunescu and Mooney, 2007). $$$$$ In a multi-instance kernel approach, only bags (and not instances) are considered as training examples, which means that the number of support vectors is going to be upper bounded by the number of training bags.
One means of combating this is suggested by (Bunescu and Mooney, 2007). $$$$$ Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.
