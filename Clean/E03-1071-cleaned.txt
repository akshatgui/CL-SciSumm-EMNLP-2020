Implementations of GIS typically use a correction feature, but following Curran and Clark (2003) we do not use such a feature, which simplifies the algorithm. $$$$$ We also investigate how the use of a correction feature affects the performance of ME taggers.
Implementations of GIS typically use a correction feature, but following Curran and Clark (2003) we do not use such a feature, which simplifies the algorithm. $$$$$ This paper has demonstrated, both analytically and empirically, that GIS does not require a correction feature Eliminating the correction feature simplifies further the already very simple estimation algorithm.

Table 3 also gives the results if automatically assigned POS tags are used in the training and testing phases, using the C & C POS tagger (Curran and Clark, 2003). $$$$$ CCG supertagging is more difficult than POS tagging because the set of &quot;tags&quot; assigned by the supertagger is much larger (398 in this implementation, compared with 45 POS tags).
Table 3 also gives the results if automatically assigned POS tags are used in the training and testing phases, using the C & C POS tagger (Curran and Clark, 2003). $$$$$ Table 6 gives results for cutoff values between 1 and 4.

 $$$$$ The parameters o-, are usually collapsed into one parameter which can be set using heldout data.
 $$$$$ Computational Linguistics, 27(2)

When compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). $$$$$ CCG supertagging is more difficult than POS tagging because the set of &quot;tags&quot; assigned by the supertagger is much larger (398 in this implementation, compared with 45 POS tags).
When compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). $$$$$ Following Clark (2002), all categories that occurred at least 10 times in the training data were used, resulting in a tagset of 398 categories.

Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al, 1994). $$$$$ The two taggers used for the experiments are a POS tagger, trained on the WSJ Penn Treebank, and a &quot;supertagger&quot;, which assigns tags from the much larger set of lexical types from Combinatory Categorial Grammar (ccG) (Clark, 2002).
Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al, 1994). $$$$$ A maximum entropy part-ofspeech tagger.

Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger. $$$$$ The contextual predicates used by the two taggers are given in Table 2, where w, is the ith word and ti is the ith tag.
Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger. $$$$$ Table 8 shows the difference in the number of contextual predicates and features between the original and final taggers.

The tagger is very similar to the Maximum Entropy POS tagger described in Curran and Clark (2003). $$$$$ A maximum entropy part-ofspeech tagger.
The tagger is very similar to the Maximum Entropy POS tagger described in Curran and Clark (2003). $$$$$ Enriching the knowledge sources used in a maximum entropy part-of-speech tagger.

Here we use the Maximum Entropy models described in Curran and Clark (2003). $$$$$ Maximum Entropy Models for Natural Language Ambiguity Resolution.
Here we use the Maximum Entropy models described in Curran and Clark (2003). $$$$$ Learning to parse natural language with maximum entropy models.

Curran and Clark (2003) describes the model and explains how Generalised Iterative Scaling, together with a Gaussian prior for smoothing, can be used to set the weights. $$$$$ This paper investigates two elements of Maximum Entropy tagging

The supertagger in Curran and Clark (2003) finds the single most probable category sequence given the sentence, and uses additional features defined in terms of the previously assigned categories. $$$$$ The supertagger uses POS tags as additional features, which Clark (2002) found improved performance significantly, and does not use the morphological features, since the POS tags provide equivalent information.
The supertagger in Curran and Clark (2003) finds the single most probable category sequence given the sentence, and uses additional features defined in terms of the previously assigned categories. $$$$$ The tagger returns the most probable sequence for the sentence.

The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran and Clark (2003) tagger. $$$$$ CCG supertagging is more difficult than POS tagging because the set of &quot;tags&quot; assigned by the supertagger is much larger (398 in this implementation, compared with 45 POS tags).
The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran and Clark (2003) tagger. $$$$$ The supertagger uses POS tags as additional features, which Clark (2002) found improved performance significantly, and does not use the morphological features, since the POS tags provide equivalent information.

The CCG parser results are based on automatically assigned POS tags, using the Curran and Clark (2003) tagger. $$$$$ CCG supertagging is more difficult than POS tagging because the set of &quot;tags&quot; assigned by the supertagger is much larger (398 in this implementation, compared with 45 POS tags).
The CCG parser results are based on automatically assigned POS tags, using the Curran and Clark (2003) tagger. $$$$$ We develop and test our improved POS tagger (c &c) using the standard parser development methodology on the Penn Treebank WSJ corpus.

We investigate whether co-training based upon directly maximising agreement can be successfully applied to a pair of part-of-speech (POS) taggers $$$$$ We also performed 10-fold cross-validation using MXPOST and TNT, a publicly available Markov model PO S tagger (Brants, 2000).
We investigate whether co-training based upon directly maximising agreement can be successfully applied to a pair of part-of-speech (POS) taggers $$$$$ A maximum entropy part-ofspeech tagger.

The modern Bible is tagged using the C & C maximum entropy tagger (Curran and Clark, 2003), and these tags are transferred from source to target through high-confidence alignments aquired from two alignment approaches. $$$$$ Using maximum entropy for text classification.
The modern Bible is tagged using the C & C maximum entropy tagger (Curran and Clark, 2003), and these tags are transferred from source to target through high-confidence alignments aquired from two alignment approaches. $$$$$ A maximum entropy part-ofspeech tagger.

The C & C tagger (Curran and Clark, 2003) was trained on the Wall Street Journal texts in the Penn Treebank and then used to tag the NET Bible (the source text). $$$$$ The two taggers used for the experiments are a POS tagger, trained on the WSJ Penn Treebank, and a &quot;supertagger&quot;, which assigns tags from the much larger set of lexical types from Combinatory Categorial Grammar (ccG) (Clark, 2002).
The C & C tagger (Curran and Clark, 2003) was trained on the Wall Street Journal texts in the Penn Treebank and then used to tag the NET Bible (the source text). $$$$$ We develop and test our improved POS tagger (c &c) using the standard parser development methodology on the Penn Treebank WSJ corpus.

However, it is unclear whether multi-POS tagging will be useful in this context, since our single-tagger POS tagger is highly accurate $$$$$ The two taggers used for the experiments are a POS tagger, trained on the WSJ Penn Treebank, and a &quot;supertagger&quot;, which assigns tags from the much larger set of lexical types from Combinatory Categorial Grammar (ccG) (Clark, 2002).
However, it is unclear whether multi-POS tagging will be useful in this context, since our single-tagger POS tagger is highly accurate $$$$$ We develop and test our improved POS tagger (c &c) using the standard parser development methodology on the Penn Treebank WSJ corpus.

Part-of-speech (POS) tagging is done using the C & C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ 2000.
Part-of-speech (POS) tagging is done using the C & C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ 2000.

We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C & C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ Using maximum entropy for text classification.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C & C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ A maximum entropy part-ofspeech tagger.

We determine weights for the features with a modified version of the Generative Iterative Scaling algorithm (Curran and Clark, 2003). $$$$$ This paper investigates two elements of Maximum Entropy tagging

It is straightforward to apply this in tasks with token-based evaluation, such as part-of-speech tagging (Curran and Clark, 2003). $$$$$ We explore the combination of Gaussian smoothing and a simple cutoff for two tagging tasks.
It is straightforward to apply this in tasks with token-based evaluation, such as part-of-speech tagging (Curran and Clark, 2003). $$$$$ Elimination of the correction feature and use of appropriate smoothing methods result in state of the art performance for both tagging tasks.
