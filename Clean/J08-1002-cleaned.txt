These corpora are automatically parsed by Enju 2.3.1 (Miyao and Tsujii, 2008), and the features are extracted from the parsing results. $$$$$ We describe methods for representing HPSG parse trees and predicate–argument structures using feature forests (Miyao, Ninomiya, and Tsujii 2003; Miyao and Tsujii 2003, 2005).
These corpora are automatically parsed by Enju 2.3.1 (Miyao and Tsujii, 2008), and the features are extracted from the parsing results. $$$$$ In the following experiments, we use Enju 2.1 (Tsujii Laboratory 2004), which is a widecoverage HPSG grammar extracted from the Penn Treebank by the method of Miyao, Ninomiya, and Tsujii (2005).

 $$$$$ Simplified representation of the lexical entry in Figure 10. predicate–argument structure of a phrase/sentence.
 $$$$$ We would also like to thank Takashi Ninomiya and Kenji Sagae for their precious support.

Following our precious work (Wu et al, 2010), we use head-drive phrase structure grammar (HPSG) forests generated by Enju (Miyao and Tsujii, 2008), which is a state-of-the-art HPSG parser for English. $$$$$ In all of the following experiments, we use the HPSG grammar developed by the method of Miyao, Ninomiya, and Tsujii (2005).
Following our precious work (Wu et al, 2010), we use head-drive phrase structure grammar (HPSG) forests generated by Enju (Miyao and Tsujii, 2008), which is a state-of-the-art HPSG parser for English. $$$$$ In the following experiments, we use Enju 2.1 (Tsujii Laboratory 2004), which is a widecoverage HPSG grammar extracted from the Penn Treebank by the method of Miyao, Ninomiya, and Tsujii (2005).

As the syntactic parser, we used the Enju (Miyao and Tsujii, 2008) English HPSG parser. $$$$$ The methods we propose here were applied to an English HPSG parser, Enju (Tsujii Laboratory 2004).
As the syntactic parser, we used the Enju (Miyao and Tsujii, 2008) English HPSG parser. $$$$$ We therefore conclude that the HPSG parser for English is moving toward a practical level of use in real-world applications.

Models based on deep grammars such as CCG (Hockenmaier and Steed man, 2003) and HPSG (Miyao and Tsujii, 2008) could in principle use inflectional morphology, but they currently rely on functional information mainly. $$$$$ We describe methods for representing HPSG parse trees and predicate–argument structures using feature forests (Miyao, Ninomiya, and Tsujii 2003; Miyao and Tsujii 2003, 2005).
Models based on deep grammars such as CCG (Hockenmaier and Steed man, 2003) and HPSG (Miyao and Tsujii, 2008) could in principle use inflectional morphology, but they currently rely on functional information mainly. $$$$$ In all of the following experiments, we use the HPSG grammar developed by the method of Miyao, Ninomiya, and Tsujii (2005).

We also experimented with the ENJU parses (Miyao and Tsujii, 2008) provided by the shared task organizers. $$$$$ We describe methods for representing HPSG parse trees and predicate–argument structures using feature forests (Miyao, Ninomiya, and Tsujii 2003; Miyao and Tsujii 2003, 2005).
We also experimented with the ENJU parses (Miyao and Tsujii, 2008) provided by the shared task organizers. $$$$$ In the following experiments, we use Enju 2.1 (Tsujii Laboratory 2004), which is a widecoverage HPSG grammar extracted from the Penn Treebank by the method of Miyao, Ninomiya, and Tsujii (2005).

We used the C & C parser (Clark and Curran, 2007), ENJU (Miyao and Tsujii, 2008), and a variant of ENJU (Hara et al, 2007) adapted for the biomedical domain (i.e., ENJU-Genia); There were a number of practical issues to consider when using parsers for this task. $$$$$ The methods we propose here were applied to an English HPSG parser, Enju (Tsujii Laboratory 2004).
We used the C & C parser (Clark and Curran, 2007), ENJU (Miyao and Tsujii, 2008), and a variant of ENJU (Hara et al, 2007) adapted for the biomedical domain (i.e., ENJU-Genia); There were a number of practical issues to consider when using parsers for this task. $$$$$ 2006; Chun 2007).

 $$$$$ Simplified representation of the lexical entry in Figure 10. predicate–argument structure of a phrase/sentence.
 $$$$$ We would also like to thank Takashi Ninomiya and Kenji Sagae for their precious support.

This metric is broadly comparable to the predicate-argument dependencies of CCGBank (Hockenmaier and Steed man, 2007) or of the ENJU grammar (Miyao and Tsujii, 2008), and also somewhat similar to the grammatical relations (GR) of the Briscoe and Carroll (2006) version of DepBank. $$$$$ The content of this article is an extended version of our earlier work reported in Miyao and Tsujii (2002, 2003, 2005) and Miyao, Ninomiya, and Tsujii (2003).
This metric is broadly comparable to the predicate-argument dependencies of CCGBank (Hockenmaier and Steed man, 2007) or of the ENJU grammar (Miyao and Tsujii, 2008), and also somewhat similar to the grammatical relations (GR) of the Briscoe and Carroll (2006) version of DepBank. $$$$$ 2006; Chun 2007).

Isozaki et al (2010b) proposed a simple method of Head Finalization, by using an HPSG-based deep parser for English (Miyao and Tsujii, 2008) to obtain phrase structures and head information. $$$$$ We describe methods for representing HPSG parse trees and predicate–argument structures using feature forests (Miyao, Ninomiya, and Tsujii 2003; Miyao and Tsujii 2003, 2005).
Isozaki et al (2010b) proposed a simple method of Head Finalization, by using an HPSG-based deep parser for English (Miyao and Tsujii, 2008) to obtain phrase structures and head information. $$$$$ Recently, the applicability of the HPSG parser to practical applications, such as information extraction and retrieval, has also been demonstrated (Miyao et al. 2006; Yakushiji et al.

Second, input English sentences are parsed by a high-quality parser, Enju (Miyao and Tsujii, 2008), which outputs syntactic heads. $$$$$ The methods we propose here were applied to an English HPSG parser, Enju (Tsujii Laboratory 2004).
Second, input English sentences are parsed by a high-quality parser, Enju (Miyao and Tsujii, 2008), which outputs syntactic heads. $$$$$ The second and the third features are for the other two relations.

We used Enju (Miyao and Tsujii, 2008) v2.4.2 for parsing the English side of the training data. $$$$$ The methods we propose here were applied to an English HPSG parser, Enju (Tsujii Laboratory 2004).
We used Enju (Miyao and Tsujii, 2008) v2.4.2 for parsing the English side of the training data. $$$$$ A method of filtering lexical entries was applied to the parsing of training data (Section 4.4).

For this experiment, we choose the C & C parser (Clark and Curran, 2003) for CCG, Enju parser (Miyao and Tsujii, 2008) for HPSG and pipeline automatic annotator (Cahill et al, 2004) with Charniak parser for LFG. $$$$$ The methods we propose here were applied to an English HPSG parser, Enju (Tsujii Laboratory 2004).
For this experiment, we choose the C & C parser (Clark and Curran, 2003) for CCG, Enju parser (Miyao and Tsujii, 2008) for HPSG and pipeline automatic annotator (Cahill et al, 2004) with Charniak parser for LFG. $$$$$ Applications to CCG parsing (Clark and Curran 2003, 2004b) and LFG parsing (Kaplan et al. 2004; Riezler and Vasserman 2004) demonstrated that feature forest models attained higher accuracy than other models.

Figure 4 shows an example of text conversion and annotation alignment that are required when the Enju parser (Miyao and Tsujii, 2008) needs to be used for the annotation of protein names. $$$$$ Figure 3 shows Ω(Φ) of the feature forest in Figure 1.
Figure 4 shows an example of text conversion and annotation alignment that are required when the Enju parser (Miyao and Tsujii, 2008) needs to be used for the annotation of protein names. $$$$$ The figure shows output from the parser.

For training, we use the feature forest model (Miyao and Tsujii, 2008), which was originally designed as an efficient algorithm for solving maximum entropy models for data with complex structures. $$$$$ Feature forest models are maximum entropy models defined over feature forests.
For training, we use the feature forest model (Miyao and Tsujii, 2008), which was originally designed as an efficient algorithm for solving maximum entropy models for data with complex structures. $$$$$ Feature forest models are maximum entropy models defined over feature forests.

The other deep parser used was the HPSG parser Enju by Miyao and Tsujii (2008), also trained on GTB. $$$$$ The methods we propose here were applied to an English HPSG parser, Enju (Tsujii Laboratory 2004).
The other deep parser used was the HPSG parser Enju by Miyao and Tsujii (2008), also trained on GTB. $$$$$ In the following experiments, we use Enju 2.1 (Tsujii Laboratory 2004), which is a widecoverage HPSG grammar extracted from the Penn Treebank by the method of Miyao, Ninomiya, and Tsujii (2005).

We employed the parser and the supertagger of (Miyao and Tsujii, 2008), specifically, its generalized modules for lexicalized grammars. $$$$$ Probabilistic modeling of lexicalized grammars is difficult because these grammars exploit complicated data structures, such as typed feature structures.
We employed the parser and the supertagger of (Miyao and Tsujii, 2008), specifically, its generalized modules for lexicalized grammars. $$$$$ The model described in this article was first published in Miyao and Tsujii (2002), and has been applied to probabilistic models for parsing with lexicalized grammars.
