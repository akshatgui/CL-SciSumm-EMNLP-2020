The aggregation strategy proposed by Corley and Mihalcea (2005) has been utilized for extending these word-to-word similarity measures for calculating text-to-text similarities. $$$$$ The similarity between the input text segments Ti and Tj is then determined using a scoring function that combines the word-to-word similarities and the word specificity

Most similar to our approach are the methods of Islam and Inkpen (2008) and Corley and Mihalcea (2005), who performed a word-to-word similarity alignment; however, they did not operate at the sense level. $$$$$ While there are several methods previously proposed for finding the semantic similarity of words, to our knowledge the application of these word-oriented methods to text similarity has not been yet explored.
Most similar to our approach are the methods of Islam and Inkpen (2008) and Corley and Mihalcea (2005), who performed a word-to-word similarity alignment; however, they did not operate at the sense level. $$$$$ Starting with each of the two text segments, and for each word in its word class sets, we determine the most similar word from the corresponding set in the other text segment.

Although these implications are uncontroversial, their automatic recognition is complex if we rely on models based on lexical distance (or similarity) between hypothesis and text ,e.g., (Corley and Mihalcea, 2005). $$$$$ There is a relatively large number of word-to-word similarity metrics that were previously proposed in the literature, ranging from distance-oriented measures computed on semantic networks, to metrics based on models of distributional similarity learned from large text collections.
Although these implications are uncontroversial, their automatic recognition is complex if we rely on models based on lexical distance (or similarity) between hypothesis and text ,e.g., (Corley and Mihalcea, 2005). $$$$$ For the task of paraphrase recognition, incorporating semantic information into the text similarity measure increases the likelihood of recognition significantly over the random baseline and over the lexical matching baseline.

 $$$$$ While the specificity of words is already measured to some extent by their depth in the semantic hierarchy, we are reinforcing this factor with a corpus-based measure of word specificity, based on distributional information learned from large corpora.
 $$$$$ Future work will consider the investigation of more sophisticated representations of sentence structure, such as first order predicate logic or semantic parse trees, which should allow for the implementation of more effective measures of text semantic similarity.

 $$$$$ While the specificity of words is already measured to some extent by their depth in the semantic hierarchy, we are reinforcing this factor with a corpus-based measure of word specificity, based on distributional information learned from large corpora.
 $$$$$ Future work will consider the investigation of more sophisticated representations of sentence structure, such as first order predicate logic or semantic parse trees, which should allow for the implementation of more effective measures of text semantic similarity.

Corley and Mihalcea (2005) proposed a hybrid method by combining six existing knowledge-based methods. $$$$$ In this paper, we explore a knowledge-based method for measuring the semantic similarity of texts.
Corley and Mihalcea (2005) proposed a hybrid method by combining six existing knowledge-based methods. $$$$$ While there are several methods previously proposed for finding the semantic similarity of words, to our knowledge the application of these word-oriented methods to text similarity has not been yet explored.

Then, we use this cross-pair similarity with more traditional intra-pair similarities (e.g., (Corley and Mihalcea, 2005)) to define a novel kernel function. $$$$$ For a given pair of text segments, we start by creating sets of open-class words, with a separate set created for nouns, verbs, adjectives, and adverbs.
Then, we use this cross-pair similarity with more traditional intra-pair similarities (e.g., (Corley and Mihalcea, 2005)) to define a novel kernel function. $$$$$ Although our method relies on a bag-of-words approach, as it turns out the use of measures of semantic similarity improves significantly over the traditional lexical matching metrics4.

In line with many other researches (e.g., (Corley and Mihalcea, 2005)), we determine these anchors using different similarity or relatedness dec tors $$$$$ We use the WordNet-based implementation of these metrics, as available in the WordNet

Experimental results lexical similarity siml (T, H) as defined in (Corley and Mihalcea, 2005). $$$$$ For comparison, we also evaluated the corpus-based similarity obtained through LSA; however, the results obtained were below the lexical matching baseline and are not reported here.
Experimental results lexical similarity siml (T, H) as defined in (Corley and Mihalcea, 2005). $$$$$ Both these figures are competitive with the best results achieved during the PASCAL entailment evaluation (Dagan et al., 2005).

First, as observed in (Corley and Mihalcea, 2005) the lexical-based distance kernel Kl shows an accuracy significantly higher than the random baseline ,i.e. 50%. $$$$$ For the task of paraphrase recognition, incorporating semantic information into the text similarity measure increases the likelihood of recognition significantly over the random baseline and over the lexical matching baseline.
First, as observed in (Corley and Mihalcea, 2005) the lexical-based distance kernel Kl shows an accuracy significantly higher than the random baseline ,i.e. 50%. $$$$$ Once again, the combination of similarity metrics gives the highest accuracy, measured at 58.3%, with a slight improvement observed in the supervised setting, where the highest accuracy was measured at 58.9%.

The first backup strategy is a straightforward BoW method that we will not present in this paper (see more details in (Corley and Mihalcea, 2005)). $$$$$ This paper presents a knowledge-based method for measuring the semanticsimilarity of texts.
The first backup strategy is a straightforward BoW method that we will not present in this paper (see more details in (Corley and Mihalcea, 2005)). $$$$$ In this paper, we explore a knowledge-based method for measuring the semantic similarity of texts.

In practice, we implement WBOW by using the text similarity measure defined in (Corley and Mihalcea, 2005) as the single feature in the SVM classifier that, as in BOW, learns the threshold on this single feature. $$$$$ We illustrate the application of the text similarity measure with an example.
In practice, we implement WBOW by using the text similarity measure defined in (Corley and Mihalcea, 2005) as the single feature in the SVM classifier that, as in BOW, learns the threshold on this single feature. $$$$$ For each of the two data sets, we conduct two evaluations, under two different settings

The system performance reported in (CM05; (Corley and Mihalcea, 2005)), which is among the best we are aware of, is also included for comparison. $$$$$ For comparison, we also evaluated the corpus-based similarity obtained through LSA; however, the results obtained were below the lexical matching baseline and are not reported here.
The system performance reported in (CM05; (Corley and Mihalcea, 2005)), which is among the best we are aware of, is also included for comparison. $$$$$ In the unsupervised setting, the best performance is achieved using a method that combines several similarity metrics into one, for an overall accuracy of 68.8%.

This simple feature is the lexical similarity between T and H computed using WordNet-based metrics as in (Corley and Mihalcea, 2005). $$$$$ We use the WordNet-based implementation of these metrics, as available in the WordNet

Otherwise, WordNet (Miller, 1995) similarities (as in (Corley and Mihalcea, 2005)) and different relation between words such as verb entailment and derivational morphology are applied. $$$$$ For entailment identification, since this is a directional relation, we only measure the semantic similarity with respect to the hypothesis (the text that is entailed).
Otherwise, WordNet (Miller, 1995) similarities (as in (Corley and Mihalcea, 2005)) and different relation between words such as verb entailment and derivational morphology are applied. $$$$$ For the entailment data set, although we do not explicitly check for entailment, the directional similarity computed for textual entailment recognition does improve over the random and lexical matching baselines.

Although, there are asymmetric measures such as the Monge-Elkan measure (1996) and the measure proposed by Corley and Mihalcea (Corley and Mihalcea, 2005), they are outnumbered by the symmetric measures. $$$$$ The only exception to this trend is perhaps the latent semantic analysis (LSA) method (Landauer et al., 1998), which represents an improvement over earlier attempts to use measures of semantic similarity for information retrieval (Voorhees, 1993), (Xu and Croft, 1996).
Although, there are asymmetric measures such as the Monge-Elkan measure (1996) and the measure proposed by Corley and Mihalcea (Corley and Mihalcea, 2005), they are outnumbered by the symmetric measures. $$$$$ Unlike traditional similarity measures based on lexical matching, our metric takes into account the semantic similarity of these words, resulting in a more precise measure of text similarity.

Also, we will try different similarity score functions for both the clustering and the anchor approaches, as those surveyed in Corley and Mihalcea (2005). $$$$$ Next, we try to determine pairs of similar words across the sets corresponding to the same open-class in the two text segments.
Also, we will try different similarity score functions for both the clustering and the anchor approaches, as those surveyed in Corley and Mihalcea (2005). $$$$$ Given two text segments, as shown in Figure 1, we want to determine a score that reflects their semantic similarity.

The semantic similarity formula from (Corley and Mihalcea, 2005) defines the similarity of a pair of documents differently depending on with respect to which text it is computed. $$$$$ We do this by combining metrics of word-to-word similarity and language models into a formula that is a potentially good indicator of the semantic similarity of the two input texts.
The semantic similarity formula from (Corley and Mihalcea, 2005) defines the similarity of a pair of documents differently depending on with respect to which text it is computed. $$$$$ We define a directional measure of similarity, which indicates the semantic similarity of a text segment Ti with respect to a text segment Tj.
