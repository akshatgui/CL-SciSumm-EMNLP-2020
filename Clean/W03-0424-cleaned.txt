We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.
We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .

Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ The papers from the CoNLL-2002 shared task which used such methods (e.g.
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ We used three data sets

As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ Some studies found that gazetteers did not improve performance (e.g.
As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ Using a wider context window than 2 words may improve performance; a reranking phase using global features may also improve performance (Collins, 2002).

The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.
The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ The 2003 data uses a variant of IOB-2, IOB-1, in which I-XXX is used for all words in an entity, including the first word, unless the first word separates contiguous entities of the same type, in which case B-XXX is used.

These are based on those found in (Curran and Clark, 2003). $$$$$ The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .
These are based on those found in (Curran and Clark, 2003). $$$$$ Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger.

The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ Thus methods used for part of speech (POS) tagging and chunking can also be used for NER.
The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .

The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain. $$$$$ The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .
The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain. $$$$$ These features have been shown to be useful in other NER systems.

Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.

A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ The tagger uses a Gaussian prior over the weights (Chen et al., 1999) which allows a large number of rare, but informative, features to be used without overfitting.
A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ The additional orthographic features have proved useful in other systems, for example Carreras et al. (2002), Borthwick (1999) and Zhou and Su (2002).

 $$$$$ Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.
 $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.

Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ However, Zhou and Su (2002) have reported state of the art results on the MUC-6 and MUC-7 data using a HMM-based tagger.
Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ Carreras et al. (2002)).

Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ Thus methods used for part of speech (POS) tagging and chunking can also be used for NER.
Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .

We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ Language Independent NER Using A Maximum Entropy Tagger
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ We demonstrate this to be the case by improving on the best Dutch results from CoNLL-2002 using a maximum entropy (ME) tagger.

We use different strategies for the identification of the two classes of entities $$$$$ However, Zhou and Su (2002) have reported state of the art results on the MUC-6 and MUC-7 data using a HMM-based tagger.
We use different strategies for the identification of the two classes of entities $$$$$ We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.

The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .
The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger.

We use different strategies for the identification of the two classes of entities $$$$$ We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.
We use different strategies for the identification of the two classes of entities $$$$$ The use of beam-search tagging means that tags can only be recorded from previous sentences.

For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ This paper demonstrates that a maximum entropy tagger can effectively encode such information and identify named entities with very high accuracy.
For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.

Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ These gazetteers are used for predicates applied to the current, previous and next word in the window.

By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ The first set of features apply to rare words, i.e. those which appear less than 5 times in the training data.
By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ The unigram probabilities are relative frequencies obtained from the training data.

We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .
We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ The tagger uses models of the form
