In this paper, we show that a method for extractive summarization relying on iterative graph-based algorithms, as previously proposed in (Mihalcea and Tarau, 2004) can be applied to the summarization of documents in different languages without any requirements for additional data. $$$$$ Such text-oriented ranking methods can be applied to tasks ranging from automated extraction of keyphrases, to extractive summarization and word sense disambiguation (Mihalcea et al., 2004).
In this paper, we show that a method for extractive summarization relying on iterative graph-based algorithms, as previously proposed in (Mihalcea and Tarau, 2004) can be applied to the summarization of documents in different languages without any requirements for additional data. $$$$$ Finally, another advantage of TextRank over previously proposed methods for building extractive summaries is the fact that it does not require training corpora, which makes it easily adaptable to other languages or domains.

Earlier experiments with graph-based ranking algorithms for text summarization, as previously reported in (Mihalcea and Tarau, 2004) and (Erkanand Radev, 2004), were either limited to single document English summarization, or they were applied to English multi-document summarization, but in conjunction with other extractive summarization techniques that did not allow for a clear evaluation of the impact of the graph algorithms alone. $$$$$ Such text-oriented ranking methods can be applied to tasks ranging from automated extraction of keyphrases, to extractive summarization and word sense disambiguation (Mihalcea et al., 2004).
Earlier experiments with graph-based ranking algorithms for text summarization, as previously reported in (Mihalcea and Tarau, 2004) and (Erkanand Radev, 2004), were either limited to single document English summarization, or they were applied to English multi-document summarization, but in conjunction with other extractive summarization techniques that did not allow for a clear evaluation of the impact of the graph algorithms alone. $$$$$ We evaluate the TextRank sentence extraction algorithm on a single-document summarization task, using 567 news articles provided during the Document Understanding Evaluations 2002 (DUC, 2002).

 $$$$$ In particular, we proposed and evaluated two innovative unsupervised approaches for keyword and sentence extraction, and showed that the accuracy achieved by TextRank in these applications is competitive with that of previously proposed state-of-the-art algorithms.
 $$$$$ An important aspect of TextRank is that it does not require deep linguistic knowledge, nor domain or language specific annotated corpora, which makes it highly portable to other domains, genres, or languages.

 $$$$$ In particular, we proposed and evaluated two innovative unsupervised approaches for keyword and sentence extraction, and showed that the accuracy achieved by TextRank in these applications is competitive with that of previously proposed state-of-the-art algorithms.
 $$$$$ An important aspect of TextRank is that it does not require deep linguistic knowledge, nor domain or language specific annotated corpora, which makes it highly portable to other domains, genres, or languages.

Text Rank (TR) This is a graph-based sum mariser method (Mihalcea and Tarau, 2004) where each word is a vertex. $$$$$ Graph-based ranking algorithms are essentially a way of deciding the importance of a vertex within a graph, based on global information recursively drawn from the entire graph.
Text Rank (TR) This is a graph-based sum mariser method (Mihalcea and Tarau, 2004) where each word is a vertex. $$$$$ For the task of sentence extraction, the goal is to rank entire sentences, and therefore a vertex is added to the graph for each sentence in the text.

TextRank (Mihalcea and Tarau, 2004) is one of the most well-known graph based approaches to key phrase extraction. $$$$$ Graph-based ranking algorithms are essentially a way of deciding the importance of a vertex within a graph, based on global information recursively drawn from the entire graph.
TextRank (Mihalcea and Tarau, 2004) is one of the most well-known graph based approaches to key phrase extraction. $$$$$ In particular, we proposed and evaluated two innovative unsupervised approaches for keyword and sentence extraction, and showed that the accuracy achieved by TextRank in these applications is competitive with that of previously proposed state-of-the-art algorithms.

PageRank score $$$$$ Formally, given two sentences and ,with a sentence being represented by the set of words that appear in the sentence

Note, by the way, that although our graphs are non-weighted and directed, like a graph of web pages and hyper links (and unlike the text graphs in Mihalcea and Tarau (2004), for example), several pairs of nodes may be connected by multiple edges, making a transition between them more probable. $$$$$ For loosely connected graphs, with the number of edges proportional with the number of vertices, undirected graphs tend to have more gradual convergence curves.
Note, by the way, that although our graphs are non-weighted and directed, like a graph of web pages and hyper links (and unlike the text graphs in Mihalcea and Tarau (2004), for example), several pairs of nodes may be connected by multiple edges, making a transition between them more probable. $$$$$ However, in our model the graphs are build from natural language texts, and may include multiple or partial links between the units (vertices) that are extracted from text.

Unsupervised approaches have also been proposed ,e.g. by Mihalcea and Tarau (2004) and Liu et al (2009). $$$$$ HITS (Kleinberg, 1999) or Positional Function (Herings et al., 2001) can be easily integrated into the TextRank model (Mihalcea, 2004).
Unsupervised approaches have also been proposed ,e.g. by Mihalcea and Tarau (2004) and Liu et al (2009). $$$$$ In particular, we proposed and evaluated two innovative unsupervised approaches for keyword and sentence extraction, and showed that the accuracy achieved by TextRank in these applications is competitive with that of previously proposed state-of-the-art algorithms.

In this paper, we adopt a variant of TextRank algorithm (Mihalcea and Tarau, 2004), a graph based ranking model for key word extraction which achieves state-of-the-art accuracy. $$$$$ In this paper, we introduce TextRank – a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications.
In this paper, we adopt a variant of TextRank algorithm (Mihalcea and Tarau, 2004), a graph based ranking model for key word extraction which achieves state-of-the-art accuracy. $$$$$ In particular, we proposed and evaluated two innovative unsupervised approaches for keyword and sentence extraction, and showed that the accuracy achieved by TextRank in these applications is competitive with that of previously proposed state-of-the-art algorithms.

More recently, Mihalcea and Tarau (2004) propose the TextRank model to rank key words based on the co-occurrence links between words. $$$$$ Our system consists of the TextRank approach described in Section 3.1, with a co-occurrence windowsize set to two, three, five, or ten words.
More recently, Mihalcea and Tarau (2004) propose the TextRank model to rank key words based on the co-occurrence links between words. $$$$$ Evaluation takes into account (a) all words; (b) stemmed words; (c) stemmed words, and no stopwords.

If substep 1) is performed on each single document without considering the cluster context, the approach is degenerated into the simple Tex t Rank model (Mihalcea and Tarau, 2004), which is denoted as SingleRank in this paper. $$$$$ In this paper, we introduce TextRank – a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications.
If substep 1) is performed on each single document without considering the cluster context, the approach is degenerated into the simple Tex t Rank model (Mihalcea and Tarau, 2004), which is denoted as SingleRank in this paper. $$$$$ In this paper, we introduce the TextRank graphbased ranking model for graphs extracted from natural language texts.

As in Mihalcea and Tarau (2004), the documents are tagged by a 2 The original words are used without stemming. $$$$$ In the context of Web surfing, it is unusual for a page to include multiple or partial links to another page, and hence the original PageRank definition for graph-based ranking is assuming unweighted graphs.
As in Mihalcea and Tarau (2004), the documents are tagged by a 2 The original words are used without stemming. $$$$$ Evaluation takes into account (a) all words; (b) stemmed words; (c) stemmed words, and no stopwords.

Meanwhile, Mihalcea and Tarau (2004) presented their PageRank variation, called TextRank, in the same year. $$$$$ It is important to notice that although the TextRank applications described in this paper rely on an algorithm derived from Google’s PageRank (Brin and Page, 1998), other graph-based ranking algorithms such as e.g.
Meanwhile, Mihalcea and Tarau (2004) presented their PageRank variation, called TextRank, in the same year. $$$$$ HITS (Kleinberg, 1999) or Positional Function (Herings et al., 2001) can be easily integrated into the TextRank model (Mihalcea, 2004).

As an example of an unsupervised keyphrase extraction approach, the graph-based ranking (Mihalcea and Tarau, 2004) regards key phrase extraction as a ranking task, where a document is represented by a term graph based on term relatedness, and then a graph-based ranking algorithm is used to assign importance scores to each term. $$$$$ Graph-based ranking algorithms are essentially a way of deciding the importance of a vertex within a graph, based on global information recursively drawn from the entire graph.
As an example of an unsupervised keyphrase extraction approach, the graph-based ranking (Mihalcea and Tarau, 2004) regards key phrase extraction as a ranking task, where a document is represented by a term graph based on term relatedness, and then a graph-based ranking algorithm is used to assign importance scores to each term. $$$$$ The text is therefore represented as a weighted graph, and consequently we are using the weighted graph-based ranking formula introduced in Section 2.2.

Existing methods usually use term co occurrences within a specified window size in the given document as an approximation of term relatedness (Mihalcea and Tarau, 2004). $$$$$ The simplest possible approach is perhaps to use a frequency criterion to select the “important” keywords in a document.
Existing methods usually use term co occurrences within a specified window size in the given document as an approximation of term relatedness (Mihalcea and Tarau, 2004). $$$$$ We are using a co-occurrence relation, controlled by the distance between word occurrences

Starting with TextRank (Mihalcea and Tarau,2004), graph-based ranking methods are becoming the most widely used unsupervised approach for key phrase extraction. $$$$$ In this paper, we introduce TextRank – a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications.
Starting with TextRank (Mihalcea and Tarau,2004), graph-based ranking methods are becoming the most widely used unsupervised approach for key phrase extraction. $$$$$ Such text-oriented ranking methods can be applied to tasks ranging from automated extraction of keyphrases, to extractive summarization and word sense disambiguation (Mihalcea et al., 2004).

The dataset is used in both (Hulth, 2003) and (Mihalcea and Tarau, 2004). $$$$$ This is the same test data set as used in the keyword extraction experiments reported in (Hulth, 2003).
The dataset is used in both (Hulth, 2003) and (Mihalcea and Tarau, 2004). $$$$$ We follow the evaluation approach from (Hulth, 2003), and use the uncontrolled set of keywords.

We use the uncontrolled key phrases for evaluation as proposed in (Hulth, 2003) and followed by (Mihalcea and Tarau, 2004). $$$$$ This is the same test data set as used in the keyword extraction experiments reported in (Hulth, 2003).
We use the uncontrolled key phrases for evaluation as proposed in (Hulth, 2003) and followed by (Mihalcea and Tarau, 2004). $$$$$ We follow the evaluation approach from (Hulth, 2003), and use the uncontrolled set of keywords.

In (Mihalcea and Tarau, 2004), due to the unsupervised method, only the test set was used for comparing the performance of Text Rank and Hulth' s method. $$$$$ This is the same test data set as used in the keyword extraction experiments reported in (Hulth, 2003).
In (Mihalcea and Tarau, 2004), due to the unsupervised method, only the test set was used for comparing the performance of Text Rank and Hulth' s method. $$$$$ Since our approach is completely unsupervised, no training/development data is required, and we are only using the test docu2Many thanks to Anette Hulth for allowing us to run our algorithm on the data set used in her keyword extraction experiments, and for making available the training/test/development data split. ments for evaluation purposes.
