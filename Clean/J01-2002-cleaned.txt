This simple idea has been applied to a variety of classification problems ranging from optical character recognition to medical diagnosis, part-of-speech tagging (see Dietterich 1997 and van Halteren et al 2001 for overviews), and notably supervised WSD (Florian et al, 2002). $$$$$ It is based on the classification used in the most popular descriptive grammar of Dutch, the Algemene Nederlandse Spraakkunst (ANS [Geerts et al. 1984]).
This simple idea has been applied to a variety of classification problems ranging from optical character recognition to medical diagnosis, part-of-speech tagging (see Dietterich 1997 and van Halteren et al 2001 for overviews), and notably supervised WSD (Florian et al, 2002). $$$$$ In another recent study, Marquez et al. (1999) investigate several types of ensemble construction in a decision tree learning framework for tagging specific classes of ambiguous words (as opposed to tagging all words).

For example, the state of the art POS tagger is an ensemble of individual taggers (van Halterenet al, 2001), each of which must process the text separately. $$$$$ There are several ways in which an ensemble can be created, both in the selection of the individual classifiers and in the way they are combined.
For example, the state of the art POS tagger is an ensemble of individual taggers (van Halterenet al, 2001), each of which must process the text separately. $$$$$ Their approach is also demonstrated for prepositional phrase attachment, again with results comparable to but not better than state-of-the-art single classifier systems.

Illustrating the negative impact of annotation errors on computational uses of annotated corpora, van Halteren et al (2001) compare taggers trained and tested on the Wall Street Journal (WSJ, Marcus et al, 1993) and the Lancaster-Oslo-Bergen (LOB, Johansson, 1986) corpora and find that the results for the WSJ perform significantly worse. $$$$$ We then switch to Wall Street Journal material (WSJ), tagged with the Penn Treebank II tagset (Marcus, Santorini, and Marcinkiewicz 1993).
Illustrating the negative impact of annotation errors on computational uses of annotated corpora, van Halteren et al (2001) compare taggers trained and tested on the Wall Street Journal (WSJ, Marcus et al, 1993) and the Lancaster-Oslo-Bergen (LOB, Johansson, 1986) corpora and find that the results for the WSJ perform significantly worse. $$$$$ The first data set we use for our experiments consists of the tagged Lancaster-Oslo/Bergen corpus (LOB [Johansson 1986]).

Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation. $$$$$ For example, Rigau, Atserias, and Agirre (1997) combine different heuristics for word sense disambiguation by voting, and Agirre et al. (1998) do the same for spelling correction evaluation heuristics.
Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation. $$$$$ For part-of-speech tagging, a significant increase in accuracy through combining the output of different taggers was first demonstrated in van Halteren, Zavrel, and Daelemans (1998) and Brill and Wu (1998).

Given that the latest literature on POS tagging using Penn Treebank reports an accuracy of around 97% with in-domain training data (van Halteren et al, 2001), we achieve a very reasonable performance, considering these errors. $$$$$ The material is tagged with the Penn Treebank tagset (Marcus, Santorini, and Marcirtkiewicz 1993), which is much smaller than the LOB one.
Given that the latest literature on POS tagging using Penn Treebank reports an accuracy of around 97% with in-domain training data (van Halteren et al, 2001), we achieve a very reasonable performance, considering these errors. $$$$$ For example, on LOB, TagPair produces 2,321 errors (corresponding to an accuracy of 97.98%), which is 17.8% less than HMM's 2,824 errors.

This data set was also used in (van Halteren et al, 2001), therefore the second experiment will allow for a comparison of the results with previous work on tagging Dutch. $$$$$ It is based on the classification used in the most popular descriptive grammar of Dutch, the Algemene Nederlandse Spraakkunst (ANS [Geerts et al. 1984]).
This data set was also used in (van Halteren et al, 2001), therefore the second experiment will allow for a comparison of the results with previous work on tagging Dutch. $$$$$ As we now apply the methods of van Halteren, Zavrel, and Daelemans (1998) to WSJ as well, it is easier to make a comparison.

These sentences received no contextual labels and thus not all of the training data used in (van Halteren et al, 2001) could be used in the Wotan experiment. $$$$$ A tagger using this learning method, MBT, was proposed by Daelemans et al. (1996).18 During the training phase, the training corpus is transformed into two case bases, one which is to be used for known words and one for unknown words.
These sentences received no contextual labels and thus not all of the training data used in (van Halteren et al, 2001) could be used in the Wotan experiment. $$$$$ *c5.0 was not able to cope with the large amount of data involved in all Tags+Word experiments and the Tags+Context experiment with Wotan.

In the Wotan experiment, 36K sentences (628K words) are used for training (compared to 640K words in (van Halteren et al, 2001)), and 4176 sentences (72K words) are used for testing. $$$$$ The training set consists of 640K tokens and the test set of 72K tokens.
In the Wotan experiment, 36K sentences (628K words) are used for training (compared to 640K words in (van Halteren et al, 2001)), and 4176 sentences (72K words) are used for testing. $$$$$ A tagger using this learning method, MBT, was proposed by Daelemans et al. (1996).18 During the training phase, the training corpus is transformed into two case bases, one which is to be used for known words and one for unknown words.

The Wotan data is annotated with a tag set consisting of 345 tags (although a number of 341 is reported in (van Halteren et al, 2001)). $$$$$ The Wotan tagset is not only very large (233 base tags, leading to 341 tags when counting each ditto tag separately), but furthermore contains distinctions that are very difficult for automatic taggers, such as verb transitivity, syntactic use of adjectives, and the recognition of multitoken units.
The Wotan data is annotated with a tag set consisting of 345 tags (although a number of 341 is reported in (van Halteren et al, 2001)). $$$$$ *c5.0 was not able to cope with the large amount of data involved in all Tags+Word experiments and the Tags+Context experiment with Wotan.

This result is very similar to the 92.06% reported by Van Halteren, Zavrel and Daelemans in (van Halteren et al, 2001) who used the TnT trigram tagger (Brants, 2000) on the same training and testing data. $$$$$ One of the best methods for tagger combination in (van Halteren, Zavrel, and Daelemans 1998) is the TagPair method.
This result is very similar to the 92.06% reported by Van Halteren, Zavrel and Daelemans in (van Halteren et al, 2001) who used the TnT trigram tagger (Brants, 2000) on the same training and testing data. $$$$$ The first is the LOB corpus (Johansson 1986), which we used in the earlier experiments as well (van Halteren, Zavrel, and Daelemans 1998) and which has proved to be a good testing ground.

We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected. $$$$$ In Table 6 the results of our experiments with the various combination methods are shown.
We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected. $$$$$ For part-of-speech tagging, a significant increase in accuracy through combining the output of different taggers was first demonstrated in van Halteren, Zavrel, and Daelemans (1998) and Brill and Wu (1998).
