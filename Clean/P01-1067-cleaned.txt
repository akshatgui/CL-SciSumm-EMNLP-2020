Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as input a parsed sentence rather than simple words. $$$$$ Their models are based on a string-to-string noisy channel model.
Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as input a parsed sentence rather than simple words. $$$$$ To incorporate structural aspects of the language, our channel model accepts a parse tree as an input, i.e., the input sentence is preprocessed by a syntactic parser.

Zhu et al. (2010) constructed a parallel corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation (Yamada and Knight, 2001). $$$$$ A Syntax-Based Statistical Translation Model
Zhu et al. (2010) constructed a parallel corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation (Yamada and Knight, 2001). $$$$$ We present a syntax-based statistical translation model.

We refer the reader to (Yamada and Knight, 2001) for more details. $$$$$ Mathematical details are fully described in (Brown et al., 1993).
We refer the reader to (Yamada and Knight, 2001) for more details. $$$$$ Following (Brown et al., 1993) and the other literature in TM, this paper only focuses the details of TM.

Both Yamada and Knight (2001) and Chiang (2005) use SCFGs as the underlying model, so their translation schemata are syntax-directed as in Fig. $$$$$ A Syntax-Based Statistical Translation Model
Both Yamada and Knight (2001) and Chiang (2005) use SCFGs as the underlying model, so their translation schemata are syntax-directed as in Fig. $$$$$ We present a syntax-based statistical translation model.

This example also shows that, one-level SCFG rule, even if informed by the Treebank as in (Yamada and Knight, 2001), is not enough to capture a common construction like this which is five levels deep (from VP to by). $$$$$ We first introduce our translation model with an example.
This example also shows that, one-level SCFG rule, even if informed by the Treebank as in (Yamada and Knight, 2001), is not enough to capture a common construction like this which is five levels deep (from VP to by). $$$$$ That is, a function word like ga is just as likely to be inserted in one place as any other.

In applications such as the syntax based machine translation model of (Yamada and Knight, 2001), a low quality tree might lead to errorenous translation of the sentence. $$$$$ A Syntax-Based Statistical Translation Model
In applications such as the syntax based machine translation model of (Yamada and Knight, 2001), a low quality tree might lead to errorenous translation of the sentence. $$$$$ We have presented a syntax-based translation model that statistically models the translation process from an English parse tree into a foreignlanguage sentence.

Additionally, we present novel on-the-fly variants of these algorithms, and compare their performance on a syntax machine translation cascade based on (Yamada and Knight, 2001). $$$$$ A Syntax-Based Statistical Translation Model
Additionally, we present novel on-the-fly variants of these algorithms, and compare their performance on a syntax machine translation cascade based on (Yamada and Knight, 2001). $$$$$ We present a syntax-based statistical translation model.

We adapt the Japanese-to-English translation model of Yamada and Knight (2001) by transforming it from an English-tree-to-Japanese-string model to an English-tree-to-Japanese-tree model. $$$$$ Therefore, the probability of the Japanese sentence given the English parse tree is the sum of all these probabilities.
We adapt the Japanese-to-English translation model of Yamada and Knight (2001) by transforming it from an English-tree-to-Japanese-string model to an English-tree-to-Japanese-tree model. $$$$$ To experiment, we trained our model on a small English-Japanese corpus.

Yamada and Knight (2001) use a parser in the target language to train probabilities on a set of 609 operations that transform a target parse tree into a source string. $$$$$ Our model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node.
Yamada and Knight (2001) use a parser in the target language to train probabilities on a set of 609 operations that transform a target parse tree into a source string. $$$$$ Note that the output of our model is a string, not a parse tree.

Therefore, we have introduced a variation of the Inside-Outside algorithm as seen in (Yamada and Knight, 2001) for E step computation. $$$$$ We define an alpha probability and a beta probability for each major-node, in analogy with the measures used in the inside-outside algorithm for probabilistic context free grammars (Baker, 1979).
Therefore, we have introduced a variation of the Inside-Outside algorithm as seen in (Yamada and Knight, 2001) for E step computation. $$$$$ Those formulae replace the step 3 (in Section 2.3) for each training pair, and these counts are used in the step 4.

Yamada and Knight (2001) further extended the model to a syntax-to-string translation modeling. $$$$$ A Syntax-Based Statistical Translation Model
Yamada and Knight (2001) further extended the model to a syntax-to-string translation modeling. $$$$$ Their models are based on a string-to-string noisy channel model.

 $$$$$ Suppose we obtained the translations shown in the fourth tree of Figure 1.
 $$$$$ This work was supported by DARPA-ITO grant N66001-00-1-9814.

Yamada and Knight (2001) present an algorithm for estimating probabilistic parameters for a similar model which represents translation as a sequence of re-ordering operations over children of nodes in a syntactic tree, using automatic parser output for the initial tree structures. $$$$$ Model parameters are estimated in polynomial time using an EM algorithm.
Yamada and Knight (2001) present an algorithm for estimating probabilistic parameters for a similar model which represents translation as a sequence of re-ordering operations over children of nodes in a syntactic tree, using automatic parser output for the initial tree structures. $$$$$ Note that the output of our model is a string, not a parse tree.

We begin by summarizing the model of Yamada and Knight (2001), which can be thought of as representing translation as an Alexander Calder mobile. $$$$$ A Syntax-Based Statistical Translation Model
We begin by summarizing the model of Yamada and Knight (2001), which can be thought of as representing translation as an Alexander Calder mobile. $$$$$ A statistical translation model (TM) is a mathematical model in which the process of humanlanguage translation is statistically modeled.

In part to deal with this problem, Yamada and Knight (2001) flatten the trees in a pre-processing step by collapsing nodes with the same lexical head-word. $$$$$ Second, a subtree was flattened if the node’s head-word was the same as the parent’s headword.
In part to deal with this problem, Yamada and Knight (2001) flatten the trees in a pre-processing step by collapsing nodes with the same lexical head-word. $$$$$ Those formulae replace the step 3 (in Section 2.3) for each training pair, and these counts are used in the step 4.

Based on an example from (Yamada and Knight, 2001), we provide a sample SCFG fragment translating from English to Japanese, specified by means of the following synchronous productions. $$$$$ We first introduce our translation model with an example.
Based on an example from (Yamada and Knight, 2001), we provide a sample SCFG fragment translating from English to Japanese, specified by means of the following synchronous productions. $$$$$ The average sentence length was 6.9 for English and 9.7 for Japanese.

Variant of this definition can be found where the input is a single parse tree for w (Yamada and Knight, 2001), or where the output is a single parse tree, chosen according to some specific criteria (Wu and Wong, 1998). $$$$$ Note that the output of our model is a string, not a parse tree.
Variant of this definition can be found where the input is a single parse tree for w (Yamada and Knight, 2001), or where the output is a single parse tree, chosen according to some specific criteria (Wu and Wong, 1998). $$$$$ Here, we instead decide the position on the basis of the nodes of the input parse tree.

Syntax-based Statistical Translation (Yamada and Knight, 2001): This model extends the above by allowing all possible permutations of the RHS of the English rules. $$$$$ A Syntax-Based Statistical Translation Model
Syntax-based Statistical Translation (Yamada and Knight, 2001): This model extends the above by allowing all possible permutations of the RHS of the English rules. $$$$$ We present a syntax-based statistical translation model.

Finally, there are three resulting parameter tables analogous to the r-table; as stated in (Yamada and Knight, 2001), consisting of POS and constituent based patterns allowing for reordering and monotone distortion (examples can be found in Table 5). $$$$$ The probability of reordering it into PRP-VB2-VB1 is 0.723 (the second row in the r-table in Table 1).
Finally, there are three resulting parameter tables analogous to the r-table; as stated in (Yamada and Knight, 2001), consisting of POS and constituent based patterns allowing for reordering and monotone distortion (examples can be found in Table 5). $$$$$ For simplicity, we split the n-table into two: a table for insert positions and a table for words to be inserted (Table 1).

As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or pre ordering (Xia and McCord, 2004). $$$$$ A Syntax-Based Statistical Translation Model
As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or pre ordering (Xia and McCord, 2004). $$$$$ We present a syntax-based statistical translation model.
