This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al, 2008a). $$$$$ First, the source sentence is parsed into a source parse tree.
This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al, 2008a). $$$$$ Next, the source parse tree is detached into two source tree sequences (the left hand side of rules in Fig.

Works that apply the TTT model include Gildea (2003) and Zhang et al (2008). $$$$$ 1 and 3 show how the proposed model works.
Works that apply the TTT model include Gildea (2003) and Zhang et al (2008). $$$$$ For significance test, we used Zhang et al’s implementation (Zhang et al, 2004).

These works mainly try to incorporate non-syntatic phrases into a syntax-based model: while Liu et al (2006) integrates bilingual phrase tables as separate TTS templates, Zhang et al (2008) uses an algorithm to convert leaves in a parse tree to phrases be fore rule extraction. $$$$$ Liu et al. (2006) propose a tree-to-string model.
These works mainly try to incorporate non-syntatic phrases into a syntax-based model: while Liu et al (2006) integrates bilingual phrase tables as separate TTS templates, Zhang et al (2008) uses an algorithm to convert leaves in a parse tree to phrases be fore rule extraction. $$$$$ Unlike previous work, our solution neither requires larger applicability contexts (Galley et al., 2006), nor depends on pseudo nodes (Marcu et al., 2006) or auxiliary rules (Liu et al., 2007).

In particular, I will investigate settings that incorporate non syntactic phrases, using methods similar to Liu et al (2006) and Zhang et al (2008). $$$$$ Liu et al. (2006) propose a tree-to-string model.
In particular, I will investigate settings that incorporate non syntactic phrases, using methods similar to Liu et al (2006) and Zhang et al (2008). $$$$$ Unlike previous work, our solution neither requires larger applicability contexts (Galley et al., 2006), nor depends on pseudo nodes (Marcu et al., 2006) or auxiliary rules (Liu et al., 2007).

For the TTS systems (one for each translation direction), the training set will be lexically aligned using GIZA++ and for the TTT system, its syntactic trees will be aligned using techniques similar to the ones proposed by Gildea (2003) and by Zhang et al (2008). $$$$$ It automatically learns aligned tree sequence pairs with mapping probabilities from word-aligned biparsed parallel texts.
For the TTS systems (one for each translation direction), the training set will be lexically aligned using GIZA++ and for the TTT system, its syntactic trees will be aligned using techniques similar to the ones proposed by Gildea (2003) and by Zhang et al (2008). $$$$$ We model it using our tree sequence-based translation rules.

Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar: STSSG) significantly improves the translation performance (Zhang et al, 2008). $$$$$ A Tree Sequence Alignment-based Tree-to-Tree Translation Model
Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar: STSSG) significantly improves the translation performance (Zhang et al, 2008). $$$$$ In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment.

Synchronous tree-sequence substitution grammar (STSSG) al lows either side of a rule to comprise a sequence of trees instead of a single tree (Zhang et al, 2008). $$$$$ A Tree Sequence Alignment-based Tree-to-Tree Translation Model
Synchronous tree-sequence substitution grammar (STSSG) al lows either side of a rule to comprise a sequence of trees instead of a single tree (Zhang et al, 2008). $$$$$ 1, where r1 is a tree-to-tree rule and r2 is a tree sequence-to-tree sequence rule.

Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al (2008a), Zhang et al (2008b), and Sun et al (2009). $$$$$ Xiong et al. (2006) propose a MaxEnt-based reordering model for BTG (Wu, 1997) while Setiawan et al.
Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al (2008a), Zhang et al (2008b), and Sun et al (2009). $$$$$ For significance test, we used Zhang et al’s implementation (Zhang et al, 2004).

However, Zhang et al (2008b) and Sunet al (2009) demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality. $$$$$ Zhang et al. (2007b) present a STSG-based tree-to-tree translation model.
However, Zhang et al (2008b) and Sunet al (2009) demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality. $$$$$ For significance test, we used Zhang et al’s implementation (Zhang et al, 2004).

A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al (2008a), Zhanget al (2008b), and Sun et al (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. $$$$$ Xiong et al. (2006) propose a MaxEnt-based reordering model for BTG (Wu, 1997) while Setiawan et al.
A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al (2008a), Zhanget al (2008b), and Sun et al (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. $$$$$ For significance test, we used Zhang et al’s implementation (Zhang et al, 2004).

Chiang (2005) and Graehl et al (2008) argue that STSG have sufficient expressive power for syntax based machine translation, but Zhang et al (2008a) show that the additional expressive power of tree sequences helps the translation process. $$$$$ These give our model much more expressive power and flexibility than those previous models.
Chiang (2005) and Graehl et al (2008) argue that STSG have sufficient expressive power for syntax based machine translation, but Zhang et al (2008a) show that the additional expressive power of tree sequences helps the translation process. $$$$$ Zhang et al. (2007b) present a STSG-based tree-to-tree translation model.

Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar: STSSG) significantly improves the translation performance (Zhang et al, 2008). $$$$$ A Tree Sequence Alignment-based Tree-to-Tree Translation Model
Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar: STSSG) significantly improves the translation performance (Zhang et al, 2008). $$$$$ In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment.

 $$$$$ Obviously, tree sequence rules are more powerful than phrases or tree rules as they can capture all phrases (including both syntactic and non-syntactic phrases) with syntactic structure information and allow any tree node operations in a longer span.
 $$$$$ Finally, we would also like to study unsupervised learningbased bilingual parsing for SMT.

Similar to the definition of tree sequence used in a single parse tree defined in Liu et al (2007) and Zhang et al (2008a), a tree sequence in a forest also refers to an ordered sub-tree sequence that covers a continuous phrase without overlapping. $$$$$ A Tree Sequence Alignment-based Tree-to-Tree Translation Model
Similar to the definition of tree sequence used in a single parse tree defined in Liu et al (2007) and Zhang et al (2008a), a tree sequence in a forest also refers to an ordered sub-tree sequence that covers a continuous phrase without overlapping. $$$$$ We go beyond the single sub-tree mapping model to propose a tree sequence alignment-based translation model.

 $$$$$ Obviously, tree sequence rules are more powerful than phrases or tree rules as they can capture all phrases (including both syntactic and non-syntactic phrases) with syntactic structure information and allow any tree node operations in a longer span.
 $$$$$ Finally, we would also like to study unsupervised learningbased bilingual parsing for SMT.

Among them, Zhang et al (2008a) acquire the non-contiguous phrasal rules from the contiguous tree sequence pairs, and find them useless via real syntax-based translation systems. $$$$$ We model it using our tree sequence-based translation rules.
Among them, Zhang et al (2008a) acquire the non-contiguous phrasal rules from the contiguous tree sequence pairs, and find them useless via real syntax-based translation systems. $$$$$ We set three baseline systems: Moses (Koehn et al., 2007), and SCFG-based and STSG-based treeto-tree translation models (Zhang et al., 2007).

In our opinion, the non-contiguous phrasal rules themselves may not play a trivial role, as reported in Zhang et al (2008a). $$$$$ The experimental results are reported in Section 6.
In our opinion, the non-contiguous phrasal rules themselves may not play a trivial role, as reported in Zhang et al (2008a). $$$$$ For significance test, we used Zhang et al’s implementation (Zhang et al, 2004).

tree-to-tree translation model based on tree sequence alignment (Zhang et al 2008a) without losing of generality to most syntactic tree based models. $$$$$ A Tree Sequence Alignment-based Tree-to-Tree Translation Model
tree-to-tree translation model based on tree sequence alignment (Zhang et al 2008a) without losing of generality to most syntactic tree based models. $$$$$ In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment.

By means of the Initial rules, we derive the Abstract rules similarly as in Zhang et al (2008a). $$$$$ Rules are extracted from word-aligned, bi-parsed sentence pairs < T (fJ ), T (e; ), A
By means of the Initial rules, we derive the Abstract rules similarly as in Zhang et al (2008a). $$$$$  , which are classified into two categories: 2) Extracting abstract rules from extracted initial rules with the help of sub initial rules.
By means of the Initial rules, we derive the Abstract rules similarly as in Zhang et al (2008a). $$$$$ We then derive abstract rules from initial rules by removing one or more of its sub initial rules.

ncPR refers to non-contiguous phrasal rules derived from contiguous tree sequence pairs with at least one non-terminal leaf node between two lexicalized leaf nodes (i.e., all non-contiguous rules in STSSG defined as in Zhang et al (2008a). $$$$$ Note that the reordering between lexical words and non-terminal leaf nodes is not considered here) and Discontinuous Phrase Rules (DPR: refers to these rules having at least one non-terminal leaf node between two lexicalized leaf nodes) in our tree sequence-based model (d = 4 and h = 6 ) Table 3 shows the contributions of SRR and DPR.
ncPR refers to non-contiguous phrasal rules derived from contiguous tree sequence pairs with at least one non-terminal leaf node between two lexicalized leaf nodes (i.e., all non-contiguous rules in STSSG defined as in Zhang et al (2008a). $$$$$ These overlapped rules contain at least two non-terminal leaf nodes plus two terminal leaf nodes, which implies that longer rules do not affect performance too much.
