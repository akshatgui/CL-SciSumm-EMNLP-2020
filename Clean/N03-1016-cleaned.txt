In order to take into account competing hypotheses, we can use for our queue discipline not only the inside probability I (ak), but also the outside probability O (ak), the probability of generating all spans other than ak, as in A* search for CFGs (Klein and Manning, 2003), and tic-tac-toe pruning for word based ITGs (Zhang and Gildea, 2005). $$$$$ Let OG(e, s) denote the log-probability of a best inside parse of e (its Viterbi inside score).1 We will drop the G, s, and even e when context permits.
In order to take into account competing hypotheses, we can use for our queue discipline not only the inside probability I (ak), but also the outside probability O (ak), the probability of generating all spans other than ak, as in A* search for CFGs (Klein and Manning, 2003), and tic-tac-toe pruning for word based ITGs (Zhang and Gildea, 2005). $$$$$ So, ‘>’ or ‘better’ will mean higher log-probability.

In other words, the coarse outside score computed by the algorithm plays the same role as a heuristic in standard A* parsing (Klein and Manning, 2003). $$$$$ A close approximation to the F estimate can also be computed online especially quickly during parsing.
In other words, the coarse outside score computed by the algorithm plays the same role as a heuristic in standard A* parsing (Klein and Manning, 2003). $$$$$ In Klein and Manning (2003), we apply a pair of grammar projection estimates to a lexicalized parsing model of a certain factored form.

The search algorithm for the best ITG alignment, a best-first chart parsing (Charniak et al., 1998), was augmented with an A* search heuristic of quadratic complexity (Klein and Manning, 2003), resulting in significant reduction in computational complexity. $$$$$ Chitrao and Grishman (1990), Caraballo and Charniak (1998), Charniak et al. (1998), and Collins (1999) describe best-first parsing, which is intended for a tabular item-based framework.
The search algorithm for the best ITG alignment, a best-first chart parsing (Charniak et al., 1998), was augmented with an A* search heuristic of quadratic complexity (Klein and Manning, 2003), resulting in significant reduction in computational complexity. $$$$$ The complex FOMs in (Charniak et al., 1998) require somewhat more online computation to assemble.

Tsuruoka and Tsujii (2004) explore the frame work developed in Klein and Manning (2003a), and seek ways to minimize the time required by the heap manipulations necessary in this scheme. $$$$$ First, it substantially reduces the work required to parse a sentence, without sacrificing either the optimality of the answer or the worst-case cubic time bounds on the parser.
Tsuruoka and Tsujii (2004) explore the frame work developed in Klein and Manning (2003a), and seek ways to minimize the time required by the heap manipulations necessary in this scheme. $$$$$ The proof of this is very similar to the proof of the uniform-cost case in Klein and Manning (2001a), and so we omit it for space reasons (it can be found in Klein and Manning, 2002).

 $$$$$ First, it must be admissible, meaning that it must not underestimate the actual log-probability required to complete the parse.
 $$$$$ IIS-0085896, by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program, by an NSF Graduate Fellowship to the first author, and by an IBM Faculty Partnership Award to the second author.

 $$$$$ First, it must be admissible, meaning that it must not underestimate the actual log-probability required to complete the parse.
 $$$$$ IIS-0085896, by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program, by an NSF Graduate Fellowship to the first author, and by an IBM Faculty Partnership Award to the second author.

 $$$$$ First, it must be admissible, meaning that it must not underestimate the actual log-probability required to complete the parse.
 $$$$$ IIS-0085896, by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program, by an NSF Graduate Fellowship to the first author, and by an IBM Faculty Partnership Award to the second author.

A specific case of this algorithm is the A* parsing of Klein and Manning (2003) where they achieve significant speed up using carefully designed heuristic functions. $$$$$ The proof of this is very similar to the proof of the uniform-cost case in Klein and Manning (2001a), and so we omit it for space reasons (it can be found in Klein and Manning, 2002).
A specific case of this algorithm is the A* parsing of Klein and Manning (2003) where they achieve significant speed up using carefully designed heuristic functions. $$$$$ In Klein and Manning (2003), we apply a pair of grammar projection estimates to a lexicalized parsing model of a certain factored form.

We intend to explore other methods for pruning the space and agenda-based parsing, in particular A* parsing (Klein and Manning, 2003), which will allow only the most probable parts of the chart to be built, improving efficiency while still ensuring the optimal derivation is found. $$$$$ The proof of this is very similar to the proof of the uniform-cost case in Klein and Manning (2001a), and so we omit it for space reasons (it can be found in Klein and Manning, 2002).
We intend to explore other methods for pruning the space and agenda-based parsing, in particular A* parsing (Klein and Manning, 2003), which will allow only the most probable parts of the chart to be built, improving efficiency while still ensuring the optimal derivation is found. $$$$$ In Klein and Manning (2003), we apply a pair of grammar projection estimates to a lexicalized parsing model of a certain factored form.

In addition to presenting the algorithm, we show experiments in which we extract k-best lists for three different kinds of grammars: the lexicalized grammars of Klein and Manning (2003b), the state-split grammars of Petrov et al (2006), and the tree transducer grammars of Galley et al (2006). $$$$$ However, when dealing with wide-coverage grammars and long sentences, even cubic algorithms can be far too expensive in practice.
In addition to presenting the algorithm, we show experiments in which we extract k-best lists for three different kinds of grammars: the lexicalized grammars of Klein and Manning (2003b), the state-split grammars of Petrov et al (2006), and the tree transducer grammars of Galley et al (2006). $$$$$ The complex FOMs in (Charniak et al., 1998) require somewhat more online computation to assemble.

parsing algorithm of Klein and Manning (2003c) can be formulated in terms of weighted deduction rules (Felzenszwalb and McAllester, 2007). $$$$$ However, the present algorithm and estimates work just as well for top-down chart parsing, given suitable active items as nodes; see (Klein and Manning, 2001a). by some grammar symbol (or state) X.
parsing algorithm of Klein and Manning (2003c) can be formulated in terms of weighted deduction rules (Felzenszwalb and McAllester, 2007). $$$$$ As discussed in Klein and Manning (2001b), the only source of constraint on what edges can be built where is the tags in the rules.

see Klein and Manning (2003c) for details. $$$$$ The proof of this is very similar to the proof of the uniform-cost case in Klein and Manning (2001a), and so we omit it for space reasons (it can be found in Klein and Manning, 2002).
see Klein and Manning (2003c) for details. $$$$$ This is particularly effective when the tree model takes a certain factored form; see Klein and Manning (2003) for details.

If the heuristic is consistent, then A* guarantees that whenever an inside item comes off the agenda, its weight is its true Viterbi inside score (Klein and Manning, 2003c). $$$$$ An inside parse of an edge e = X:[i, j] is a derivation in G from X to iwj.
If the heuristic is consistent, then A* guarantees that whenever an inside item comes off the agenda, its weight is its true Viterbi inside score (Klein and Manning, 2003c). $$$$$ Let OG(e, s) denote the log-probability of a best inside parse of e (its Viterbi inside score).1 We will drop the G, s, and even e when context permits.

We also experimented with the lexicalized parsing model described in Klein and Manning (2003b). $$$$$ This is particularly effective when the tree model takes a certain factored form; see Klein and Manning (2003) for details.
We also experimented with the lexicalized parsing model described in Klein and Manning (2003b). $$$$$ In Klein and Manning (2003), we apply a pair of grammar projection estimates to a lexicalized parsing model of a certain factored form.

 $$$$$ First, it must be admissible, meaning that it must not underestimate the actual log-probability required to complete the parse.
 $$$$$ IIS-0085896, by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program, by an NSF Graduate Fellowship to the first author, and by an IBM Faculty Partnership Award to the second author.

 $$$$$ First, it must be admissible, meaning that it must not underestimate the actual log-probability required to complete the parse.
 $$$$$ IIS-0085896, by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program, by an NSF Graduate Fellowship to the first author, and by an IBM Faculty Partnership Award to the second author.

We used a simple but effective heuristic for these grammars, similar to the FILTER heuristic suggested in Klein and Manning (2003c). $$$$$ The contribution of this paper is to demonstrate effective ways of doing this, by precomputing grammar statistics which can be used as effective A* estimates.
We used a simple but effective heuristic for these grammars, similar to the FILTER heuristic suggested in Klein and Manning (2003c). $$$$$ The proof of this is very similar to the proof of the uniform-cost case in Klein and Manning (2001a), and so we omit it for space reasons (it can be found in Klein and Manning, 2002).

Klein and Manning (2003a) went on to describe admissible heuristics and an A* framework for parsing. $$$$$ The proof of this is very similar to the proof of the uniform-cost case in Klein and Manning (2001a), and so we omit it for space reasons (it can be found in Klein and Manning, 2002).
Klein and Manning (2003a) went on to describe admissible heuristics and an A* framework for parsing. $$$$$ In addition, the minimum (U) of a set of admissible estimates is still an admissible estimate.

The A* heuristics explored by Klein and Manning (2003a) can be seen as resulting from bounding transformations. $$$$$ Edges which seem promising are explored first; others can wait on the agenda indefinitely.
The A* heuristics explored by Klein and Manning (2003a) can be seen as resulting from bounding transformations. $$$$$ The proof of this is very similar to the proof of the uniform-cost case in Klein and Manning (2001a), and so we omit it for space reasons (it can be found in Klein and Manning, 2002).

 $$$$$ First, it must be admissible, meaning that it must not underestimate the actual log-probability required to complete the parse.
 $$$$$ IIS-0085896, by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program, by an NSF Graduate Fellowship to the first author, and by an IBM Faculty Partnership Award to the second author.
