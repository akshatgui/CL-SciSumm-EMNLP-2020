Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available. $$$$$ Our results surprisingly show that without using any annotated meaning representations learning with a weak feedback signal is capable of producing a parser that is competitive with fully supervised parsers.
Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available. $$$$$ Current semantic parsing approaches extract parsing rules mapping NL to their MR, restricting possible interpretations to previously seen syntactic patterns.
Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available. $$$$$ We evaluate our system on the Geoquery domain as described previously.
Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available. $$$$$ We demonstrate the effectiveness of our training paradigm and interpretation model over the Geoquery domain, and show that our model can outperform fully supervised systems.

Recent work by Clarke et al (2010) and Liang et al. $$$$$ Previous approaches to semantic parsing have assumed a fully supervised setting where a training set is available consisting of either: input sentences and logical forms {(xl, zl)}Nl=1 (e.g., (Zettlemoyer and Collins, 2005)) or input sentences, logical forms and a mapping between their constituents {(xl, yl, zl)}Nl=1 (e.g., (Ge and Mooney, 2005)).
Recent work by Clarke et al (2010) and Liang et al. $$$$$ The input sentences x are natural language queries about U.S. geography.
Recent work by Clarke et al (2010) and Liang et al. $$$$$ This paper presents a new learning paradigm aimed at alleviating the supervision burden.
Recent work by Clarke et al (2010) and Liang et al. $$$$$ NOLEARN uses a manually initialized weight vector.

Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. $$$$$ In addition we reformulate the semantic parsing problem to reduce the dependency of the model on syntactic patterns, thus allowing our parser to scale better using less supervision.
Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. $$$$$ Continuing with Example 1, the response generated by executing a database query would be used to provide feedback.
Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. $$$$$ We randomly select 250 sentences for training and 250 sentences for testing.6 We refer to the training set as Response 250 (R250) indicating that each example x in this data set has a corresponding desired database response r. We refer the testing set as Query 250 (Q250) where the examples only contain the natural language queries.

In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance. $$$$$ Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.
In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance. $$$$$ For example, a user can observe the response and provide a judgement.
In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance. $$$$$ We frame the inference problem as an Integer Linear Programming (ILP) problem (Equation (2)) in which the first-order decisions are governed by αcs, a binary decision variable indicating that constituent c is aligned with logical symbol s. And Qcs,dt capture the second-order decisions indicating the symbol t (associated with constituent d) is an argument to function s (associated with conIt is clear that there are dependencies between the α-variables and Q-variables.
In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance. $$$$$ We do not assume the availability of logical forms.

To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments. $$$$$ The feedback function is queried (line 5) and a training example for the binary predictor created using the normalized feature vector from the triple containing the sentence, alignment and logical form as input and the feedback as the label.
To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments. $$$$$ Building a semantic parser involves defining the model (feature function Φ and inference problem) and a learning strategy to obtain weights (w) associated with the model.
To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments. $$$$$ Our learning framework closely follows recent work on learning from indirect supervision.

Due to space consideration, we provide a brief description (see (Clarke et al, 2010) for more details). $$$$$ Analysis over the training data shows that in 66.8% examples both approaches predict a logical form that gives the correct answer.
Due to space consideration, we provide a brief description (see (Clarke et al, 2010) for more details). $$$$$ Semantic Parsing, the process of converting text into a formal meaning representation (MR), is one of the key challenges in natural language processing.
Due to space consideration, we provide a brief description (see (Clarke et al, 2010) for more details). $$$$$ This suggests that an approach which combines DIRECT and AGGRESSIVE may be able to improve even further.
Due to space consideration, we provide a brief description (see (Clarke et al, 2010) for more details). $$$$$ We refer to the arg max above as the inference problem.

We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al, 2010) for more details). $$$$$ We frame our semantic interpretation process as a constrained optimization process, maximizing the objective function defined by Equation 1 which relies on extracting lexical and syntactic features instead of parsing rules.
We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al, 2010) for more details). $$$$$ Due to space limitations we refer the reader to (Zelle and Mooney, 1996) for a detailed description of the Geoquery domain.
We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al, 2010) for more details). $$$$$ Underlying Learning Algorithms In the direct approach the base linear classifier we use is a linear kernel Support Vector Machine with squaredhinge loss.
We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al, 2010) for more details). $$$$$ We refer to the arg max above as the inference problem.

However, when trained using the noisy supervision, our method achieves substantially more accurate translations than a state-of-the-art semantic parser (Clarke et al, 2010) (specifically, 80.0% in F-Score compared to an F-Score of 66.7%). $$$$$ Figure 2 shows the accuracy on the entire training data (R250) at each iteration of learning.
However, when trained using the noisy supervision, our method achieves substantially more accurate translations than a state-of-the-art semantic parser (Clarke et al, 2010) (specifically, 80.0% in F-Score compared to an F-Score of 66.7%). $$$$$ The key to producing a semantic parser involves defining a model and a learning algorithm to obtain w. In order to exemplify these concepts we consider the Geoquery domain.
However, when trained using the noisy supervision, our method achieves substantially more accurate translations than a state-of-the-art semantic parser (Clarke et al, 2010) (specifically, 80.0% in F-Score compared to an F-Score of 66.7%). $$$$$ The alignment y is defined as a set of mappings between constituents and symbols in the domain y = {(c, s)} where s E D. We decompose the construction of an alignment and logical form into two types of decisions: First-order decisions.
However, when trained using the noisy supervision, our method achieves substantially more accurate translations than a state-of-the-art semantic parser (Clarke et al, 2010) (specifically, 80.0% in F-Score compared to an F-Score of 66.7%). $$$$$ Underlying Learning Algorithms In the direct approach the base linear classifier we use is a linear kernel Support Vector Machine with squaredhinge loss.

It continues sampling a specification tree for each text specification until it finds one which successfully reads all of the input examples. The second baseline Aggressive is a state-of the-art semantic parsing framework (Clarke et al, 2010). The framework repeatedly predicts hidden structures (specification trees in our case) using a structure learner, and trains the structure learner based on the execution feedback of its predictions. $$$$$ To answer the second question, we compare a supervised version of our model to existing semantic parsers.
It continues sampling a specification tree for each text specification until it finds one which successfully reads all of the input examples. The second baseline Aggressive is a state-of the-art semantic parsing framework (Clarke et al, 2010). The framework repeatedly predicts hidden structures (specification trees in our case) using a structure learner, and trains the structure learner based on the execution feedback of its predictions. $$$$$ We evaluate our learning approach and model on the well studied Geoquery domain (Zelle and Mooney, 1996; Tang and Mooney, 2001), a database consisting of U.S. geographical information, and natural language questions.

As in Clarke et al (2010), we obviate the need for annotated logical forms by considering the end-to-end problem of mapping questions to answers. $$$$$ However, in the task of semantic parsing, this decision relies on identifying a hidden intermediate representation (or an alignment) that captures the way in which fragments of the text correspond to the meaning representation.
As in Clarke et al (2010), we obviate the need for annotated logical forms by considering the end-to-end problem of mapping questions to answers. $$$$$ This paper presents a new learning paradigm aimed at alleviating the supervision burden.
As in Clarke et al (2010), we obviate the need for annotated logical forms by considering the end-to-end problem of mapping questions to answers. $$$$$ The key contributions of this paper are: Response driven learning for semantic parsing We propose a new learning paradigm for learning semantic parsers without any annotated meaning representations.

At the same time, representations such as FunQL (Kate et al, 2005), which was used in Clarke et al (2010), are simpler but lack the full expressive power of lambda calculus. $$$$$ Learning is then defined over hidden patterns in the training data that associate logical symbols with lexical and syntactic elements.
At the same time, representations such as FunQL (Kate et al, 2005), which was used in Clarke et al (2010), are simpler but lack the full expressive power of lambda calculus. $$$$$ In these settings the target meaning representation is defined by the semantics of the underlying task.
At the same time, representations such as FunQL (Kate et al, 2005), which was used in Clarke et al (2010), are simpler but lack the full expressive power of lambda calculus. $$$$$ Example 1 Geoquery input text and output MR “What is the largest state that borders Texas?” largest(state(next to(const(texas)))) Previous works (Zelle and Mooney, 1996; Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007) employ machine learning techniques to construct a semantic parser.

We first compare our system with Clarke et al (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs. $$$$$ Therefore, we formulate the prediction function as follows: Where b is a feature function that describes the relationships between an input sentence x, alignment y and meaning representation z. w is the weight vector which contains the parameters of the model.
We first compare our system with Clarke et al (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs. $$$$$ While the AGGRESSIVE approach which uses a structured learner sees a bigger improvement, reaching 82.4% and 73.2% respectively.
We first compare our system with Clarke et al (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs. $$$$$ The response driven learning methods perform substantially better than the starting point.
We first compare our system with Clarke et al (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs. $$$$$ In addition we reformulate the semantic parsing problem to reduce the dependency of the model on syntactic patterns, thus allowing our parser to scale better using less supervision.

One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010). $$$$$ Current approaches to semantic parsing, the task of converting text to a formal meaning representation, rely on annotated training data mapping sentences to logical forms.
One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010). $$$$$ Thus, we report accuracy: the percentage of meaning representations which produce the correct response.
One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010). $$$$$ This is only 7% below the fully SUPERVISED upper bound of the model.
One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010). $$$$$ However, in the task of semantic parsing, this decision relies on identifying a hidden intermediate representation (or an alignment) that captures the way in which fragments of the text correspond to the meaning representation.
