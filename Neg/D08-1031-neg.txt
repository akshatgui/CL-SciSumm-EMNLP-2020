 $$$$$ Next, we detect the extent boundaries for each head using a learned classifier.
 $$$$$ In recent years there has been substantial work on the important problem of coreference resolution, most of which has concentrated on the development of new models and algorithmic techniques.
 $$$$$ We show that this produces a state-of-the-art system that outperforms systems built with complex models.
 $$$$$ Looking to examples, we find who in the official, who wished to remain anonymous is properly linked, as is that in nuclear warheads that can befitted to missiles.

To achieve roughly state-of-theart performance, RECONCILEACL09 employs a fairly comprehensive set of 61 features introduced in previous coreference resolution systems (see Bengtson and Roth (2008)). $$$$$ We also studied and demonstrated the relative value of various types of features, showing in particular the importance of distance and apposition features, and showing which features impact precision or recall more.
To achieve roughly state-of-theart performance, RECONCILEACL09 employs a fairly comprehensive set of 61 features introduced in previous coreference resolution systems (see Bengtson and Roth (2008)). $$$$$ Thus, while many structural innovations in the modeling approach have been made, those innovations have generally been tested on systems with features whose strength has not been established, and compared to weak pairwise baselines.
To achieve roughly state-of-theart performance, RECONCILEACL09 employs a fairly comprehensive set of 61 features introduced in previous coreference resolution systems (see Bengtson and Roth (2008)). $$$$$ In all experiments we automatically split words and sentences using our preprocessing tools.4 B-Cubed F-Score We evaluate over the commonly used B-Cubed F-Score (Bagga and Baldwin, 1998), which is a measure of the overlap of predicted clusters and true clusters.

Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ We apply machine learning techniques to learn from examples a function pc that takes as input an ordered pair of mentions (a, m) such that a precedes m in the document, and produces as output a value that is interpreted as the conditional probability that m and a belong in the same equivalence class.
Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ When the entity types match, 13% of examples are positive compared to only 6% of examples in general.
Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.
Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ Entity Type Match This feature checks to see whether the predicted entity types match.

 $$$$$ Culotta et al. (2007) is the best comparable system of which we are aware.
 $$$$$ The MUC F-score is also the harmonic mean of precision and recall.
 $$$$$ For each m, we generate negative examples (a, m) for all mentions a that precede m and are not in the same equivalence class.
 $$$$$ For example, given the sentence (where the head noun of each mention is subscripted) the task is to group the mentions so that those referring to the same entity are placed together into an equivalence class.

 $$$$$ We describe the challenges associated with an end-to-end system, describe our approach, and report results below.
 $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.
 $$$$$ Given a document and a set of mentions, coreference resolution is the task of grouping the mentions into equivalence classes, so that each equivalence class contains exactly those mentions that refer to the same discourse entity.
 $$$$$ For each experiment, we set the parameters of our algorithm to optimize BCubed F-Score using Dev-Tune, and use those parameters to evaluate on the Dev-Eval data.

Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ As a result, it is possible that some modeling innovations may have less impact or applicability when applied to a stronger baseline system.
Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ The number of equivalence classes is not specified in advance, but is bounded by the number of mentions.
Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ Additionally, there are issues with evaluating an end-to-end system against a gold standard corpus, resulting from the possibility of mismatches in mention boundaries, missing mentions, and additional mentions detected, along with the need to align detected mentions to their counterparts in the annotated data.
Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ We also require that no non-pronoun can refer back to a pronoun: If m is not a pronoun, we do not consider pronouns as candidate antecedents.

 $$$$$ The ACE training data provides the equivalence classes for mentions.
 $$$$$ We also studied and demonstrated the relative value of various types of features, showing in particular the importance of distance and apposition features, and showing which features impact precision or recall more.
 $$$$$ Distances have been used in e.g.
 $$$$$ We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al., 2001).

Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. $$$$$ This paper introduces a rather simple but stateof-the-art system, which we intend to be used as a strong baseline to evaluate the impact of structural innovations.
Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. $$$$$ We resolve coreference on unannotated text as follows: First we detect mention heads following a state of the art chunking approach (Punyakanok and Roth, 2001) using standard features.
Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. $$$$$ If only a last name is found, the phrase is considered to refer to a person.

Illinois-Coref follows the architecture used in Bengtson and Roth (2008). $$$$$ The implementations of those features may vary from those of other systems.
Illinois-Coref follows the architecture used in Bengtson and Roth (2008). $$$$$ The paper also presents an ablation study and discusses the relative contributions of various features.
Illinois-Coref follows the architecture used in Bengtson and Roth (2008). $$$$$ Finally, we showed an end-to-end system capable of determining coreference in a plain text document.

For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ We described and evaluated a state-of-the-art coreference system based on a pairwise model and strong features.
For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ Next, we detect the extent boundaries for each head using a learned classifier.
For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ Relative Pronoun Next we investigate the relative pronoun feature.
For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ The implementations of those features may vary from those of other systems.

We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ Learning the pairwise scoring function pc is a crucial issue for the pairwise coreference model.
We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ It is computed as the harmonic mean of precision (P), where cm is the number of mentions appearing both in m’s predicted cluster and in m’s true cluster, pm is the size of the predicted cluster containing m, and tm is the size of m’s true cluster.
We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ We also studied and demonstrated the relative value of various types of features, showing in particular the importance of distance and apposition features, and showing which features impact precision or recall more.
We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ Coreference resolution is the task of grouping all the mentions of entities1 in a document into equivalence classes so that all the mentions in a given class refer to the same discourse entity.

Although its strategy is simple, Bengtson and Roth (2008) show that with a careful design, it can achieve highly competitive performance. $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.
Although its strategy is simple, Bengtson and Roth (2008) show that with a careful design, it can achieve highly competitive performance. $$$$$ We suggest that our system can be used as a baseline for the development of more complex models – which may have less impact when a more robust set of features is used.
Although its strategy is simple, Bengtson and Roth (2008) show that with a careful design, it can achieve highly competitive performance. $$$$$ In order to discover all information about a given entity, textual mentions of that entity must be grouped together.
Although its strategy is simple, Bengtson and Roth (2008) show that with a careful design, it can achieve highly competitive performance. $$$$$ We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al., 2001).

For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ We show that this produces a state-of-the-art system that outperforms systems built with complex models.
For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ Thus coreference is an important prerequisite to such tasks as textual entailment and information extraction, among others.
For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.
For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.

For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ Relative Pronoun Next we investigate the relative pronoun feature.
For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ These works often show that complex models improve over a weak pairwise baseline.
For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ Our model differs from that of Ng and Cardie in that we impose the constraint that non-pronouns cannot refer back to pronouns, and in that we use as training examples all ordered pairs of mentions, subject to the constraint above.
For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ As a result, it is possible that some modeling innovations may have less impact or applicability when applied to a stronger baseline system.

 $$$$$ MUC Score We evaluate the performance of our system using the official MUC score in Table 5.
 $$$$$ This paper introduces a rather simple but stateof-the-art system, which we intend to be used as a strong baseline to evaluate the impact of structural innovations.
 $$$$$ Thus, we learn a separate classifier to detect whether a mention is anaphoric (that is, whether it is not the first mention in its equivalence class), and use that classifier’s output as a feature for the coreference model.
 $$$$$ This work is partly supported by NSF grant SoD-HCER-0613885 and a grant from Boeing.

We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ This paper describes a rather simple pairwise classification model for coreference resolution, developed with a well-designed set of features.
We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ In this paper, we view coreference resolution as a graph problem: Given a set of mentions and their context as nodes, generate a set of edges such that any two mentions that belong in the same equivalence class are connected by some path in the graph.
We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ In order to discover all information about a given entity, textual mentions of that entity must be grouped together.
We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ This results in a 90% F1 head detector.

Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ We also studied and demonstrated the relative value of various types of features, showing in particular the importance of distance and apposition features, and showing which features impact precision or recall more.
Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ Distance features are important for a system that makes links based on the best pairwise coreference value rather than implicitly incorporating distance by linking only the closest pair whose score is above a threshold, as done by e.g.
Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ For the experiments in Section 5, following Culotta et al. (2007), to make experiments more comparable across systems, we assume that perfect mention boundaries and mention type labels are given.
Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ Qualitatively, the entity type prediction correctly recognizes the Gulf region as a geo-political entity, and He as a person, and thus prevents linking the two.

The baseline system applies the strategy in (Bengtson and Roth, 2008, Section 2.2) to learn the pairwise scoring functions using the Averaged Perceptron algorithm. $$$$$ To this end, we combine an effective coreference classification model with a strong set of features, and present an ablation study to show the relative impact of a variety of features.
The baseline system applies the strategy in (Bengtson and Roth, 2008, Section 2.2) to learn the pairwise scoring functions using the Averaged Perceptron algorithm. $$$$$ In recent years there has been substantial work on the important problem of coreference resolution, most of which has concentrated on the development of new models and algorithmic techniques.
The baseline system applies the strategy in (Bengtson and Roth, 2008, Section 2.2) to learn the pairwise scoring functions using the Averaged Perceptron algorithm. $$$$$ This technique permits us to learn to detect some links between mentions while being agnostic about whether other mentions are linked, and yet via the transitive closure of all links we can still determine the equivalence classes.
The baseline system applies the strategy in (Bengtson and Roth, 2008, Section 2.2) to learn the pairwise scoring functions using the Averaged Perceptron algorithm. $$$$$ In Section 6 experiments we do not use any gold annotated input and do not assume mention types or boundaries are given.

Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ This technique permits us to learn to detect some links between mentions while being agnostic about whether other mentions are linked, and yet via the transitive closure of all links we can still determine the equivalence classes.
Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ Distances have been used in e.g.
Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ However, less attention has been given to the importance of selecting strong features to support learning a coreference model.
Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ In recent years there has been substantial work on the important problem of coreference resolution, most of which has concentrated on the development of new models and algorithmic techniques.

Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ Our method does not require determining which equivalence classes should be considered as examples.
Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ This work is partly supported by NSF grant SoD-HCER-0613885 and a grant from Boeing.
Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ In order to discover all information about a given entity, textual mentions of that entity must be grouped together.
Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ Given a document and a set of mentions, coreference resolution is the task of grouping the mentions into equivalence classes, so that each equivalence class contains exactly those mentions that refer to the same discourse entity.
