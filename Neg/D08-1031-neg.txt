 $$$$$ Given a document d and a pairwise coreference scoring function pc that maps an ordered pair of mentions to a value indicating the probability that they are coreferential (see Section 2.2), we generate a coreference graph Gd according to the Best-Link decision model (Ng and Cardie, 2002b) as follows: For each mention m in document d, let B,,t be the set of mentions appearing before m in d. Let a be the highest scoring antecedent: in Section 4.4, we add the edge (a, m) to the coreference graph Gd.
 $$$$$ WordNet Features We check whether any sense of one head noun phrase is a synonym, antonym, or hypernym of any sense of the other.
 $$$$$ Many of our features are similar to those described in Culotta et al. (2007).
 $$$$$ The implementations of those features may vary from those of other systems.

To achieve roughly state-of-theart performance, RECONCILEACL09 employs a fairly comprehensive set of 61 features introduced in previous coreference resolution systems (see Bengtson and Roth (2008)). $$$$$ To evaluate, we align the heads of the detected mentions to the gold standard heads greedily based on number of overlapping words.
To achieve roughly state-of-theart performance, RECONCILEACL09 employs a fairly comprehensive set of 61 features introduced in previous coreference resolution systems (see Bengtson and Roth (2008)). $$$$$ This paper describes a rather simple pairwise classification model for coreference resolution, developed with a well-designed set of features.
To achieve roughly state-of-theart performance, RECONCILEACL09 employs a fairly comprehensive set of 61 features introduced in previous coreference resolution systems (see Bengtson and Roth (2008)). $$$$$ This includes Mention Types, String Relation Features, Gender and Number Match, WordNet Features, Alias, Apposition, Relative Pronoun, and Both Mentions Speak.
To achieve roughly state-of-theart performance, RECONCILEACL09 employs a fairly comprehensive set of 61 features introduced in previous coreference resolution systems (see Bengtson and Roth (2008)). $$$$$ However, less attention has been given to the importance of selecting strong features to support learning a coreference model.

Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ To decide whether two mentions should be linked in the graph, we learn a pairwise coreference function pc that produces a value indicating the probability that the two mentions should be placed in the same equivalence class.
Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ However, we are not aware of any system using the number of compatible mentions as a distance.
Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ We use the term end-toend coreference for a system capable of determining coreference on plain text.
Bengtson and Roth (2008) simply discard twinless CEs, but this solution is likely too lenient - it doles no punishment for mistakes on twinless annotated or extracted CEs and it would be tricked, for example, by a system that extracts only the CEs about which it is most confident. $$$$$ We show that this produces a state-of-the-art system that outperforms systems built with complex models.

 $$$$$ However, for some pairs of mentions from an equivalence class, there is little or no direct evidence in the text that the mentions are coreferential.
 $$$$$ This technique permits us to learn to detect some links between mentions while being agnostic about whether other mentions are linked, and yet via the transitive closure of all links we can still determine the equivalence classes.
 $$$$$ We described and evaluated a state-of-the-art coreference system based on a pairwise model and strong features.
 $$$$$ This work is partly supported by NSF grant SoD-HCER-0613885 and a grant from Boeing.

 $$$$$ Although coreference resolution has received much attention, that attention has not focused on the relative impact of high-quality features.
 $$$$$ Finally, we showed an end-to-end system capable of determining coreference in a plain text document.
 $$$$$ This results in a 90% F1 head detector.
 $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.

Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ This classifier predicts anaphoricity with about 82% accuracy.
Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.
Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ Distances Our distance features measure separation of two mentions in number of compatible mentions (quantized), and whether the mentions are in the same sentence.
Inaddition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art. $$$$$ Given a document d and a pairwise coreference scoring function pc that maps an ordered pair of mentions to a value indicating the probability that they are coreferential (see Section 2.2), we generate a coreference graph Gd according to the Best-Link decision model (Ng and Cardie, 2002b) as follows: For each mention m in document d, let B,,t be the set of mentions appearing before m in d. Let a be the highest scoring antecedent: in Section 4.4, we add the edge (a, m) to the coreference graph Gd.

 $$$$$ This work is partly supported by NSF grant SoD-HCER-0613885 and a grant from Boeing.
 $$$$$ The resulting graph contains connected components, each representing one equivalence class, with all the mentions in the component referring to the same entity.
 $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.
 $$$$$ Luo et al. (2004).

Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. $$$$$ In this paper, we view coreference resolution as a graph problem: Given a set of mentions and their context as nodes, generate a set of edges such that any two mentions that belong in the same equivalence class are connected by some path in the graph.
Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. $$$$$ Recall errors are the number of links that must be removed to ensure that no two mentions referring to different entities are connected in the graph.
Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. $$$$$ This work is partly supported by NSF grant SoD-HCER-0613885 and a grant from Boeing.

Illinois-Coref follows the architecture used in Bengtson and Roth (2008). $$$$$ Additionally, there are issues with evaluating an end-to-end system against a gold standard corpus, resulting from the possibility of mismatches in mention boundaries, missing mentions, and additional mentions detected, along with the need to align detected mentions to their counterparts in the annotated data.
Illinois-Coref follows the architecture used in Bengtson and Roth (2008). $$$$$ At training time, we use a threshold of 0.0, but when evaluating, we select parameters to optimize B-Cubed F-Score on a held-out development set.
Illinois-Coref follows the architecture used in Bengtson and Roth (2008). $$$$$ We report data on Dev-Eval, to avoid the possibility of overfitting by feature selection.

For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ Entity Type Match This feature checks to see whether the predicted entity types match.
For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ Although this evaluation is lenient, given that the mention detection component performs at over 90% F1, we believe it provides a realistic measure for the performance of the end-to-end system and focuses the evaluation on the coreference component.
For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ This work is partly supported by NSF grant SoD-HCER-0613885 and a grant from Boeing.
For the ACE 2004 coreference task, a good performance in mention detection is typically achieved by training a classifier e.g., (Bengtson and Roth, 2008). $$$$$ We hypothesize that proper names and common noun phrases link primarily through apposition, and that apposition is thus a significant feature for good coreference resolution.

We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ Anaphoricity has been proposed as a part of the model in several systems, including Ng and Cardie (2002a), but we are not aware of it being used as a feature for a learning algorithm.
We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ The ultimate goal for a coreference system is to process unannotated text.
We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ The remainder of this section first discusses how this function is used as part of a document-level coreference decision model and then describes how we learn the pc function.
We use the same features as Bengtson and Roth (2008), with the knowledge extracted from the OntoNotes-4.0 annotation. $$$$$ We choose not to impute errors to the coreference system for mentions that were not detected or for spuriously detected mentions (following Ji et al. (2005) and others).

Although its strategy is simple, Bengtson and Roth (2008) show that with a careful design, it can achieve highly competitive performance. $$$$$ Much work has been done on coreference in several languages, but for this work we focus on English text.
Although its strategy is simple, Bengtson and Roth (2008) show that with a careful design, it can achieve highly competitive performance. $$$$$ We train a regularized average perceptron using examples selected as described in Section 2.2.1.
Although its strategy is simple, Bengtson and Roth (2008) show that with a careful design, it can achieve highly competitive performance. $$$$$ The paper also presents an ablation study and discusses the relative contributions of various features.

For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al., 2001).
For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ In this paper, we view coreference resolution as a graph problem: Given a set of mentions and their context as nodes, generate a set of edges such that any two mentions that belong in the same equivalence class are connected by some path in the graph.
For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ We also require that no non-pronoun can refer back to a pronoun: If m is not a pronoun, we do not consider pronouns as candidate antecedents.
For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). $$$$$ Soon et al. (2001).

For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ Being in a window of size two is an approximation to being a syntactic subject of such a verb.
For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ This paper describes a rather simple pairwise classification model for coreference resolution, developed with a well-designed set of features.
For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ We apply machine learning techniques to learn from examples a function pc that takes as input an ordered pair of mentions (a, m) such that a precedes m in the document, and produces as output a value that is interpreted as the conditional probability that m and a belong in the same equivalence class.
For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008). $$$$$ For our ablation study, we further randomly split our development set into two evenly sized parts, Dev-Tune and Dev-Eval.

 $$$$$ Given a document d and a pairwise coreference scoring function pc that maps an ordered pair of mentions to a value indicating the probability that they are coreferential (see Section 2.2), we generate a coreference graph Gd according to the Best-Link decision model (Ng and Cardie, 2002b) as follows: For each mention m in document d, let B,,t be the set of mentions appearing before m in d. Let a be the highest scoring antecedent: in Section 4.4, we add the edge (a, m) to the coreference graph Gd.
 $$$$$ The ultimate goal for a coreference system is to process unannotated text.
 $$$$$ We would like to thank Ming-Wei Chang, Michael Connor, Alexandre Klementiev, Nick Rizzolo, Kevin Small, and the anonymous reviewers for their insightful comments.

We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ The type of a mention indicates whether it is a proper noun, a common noun, or a pronoun.
We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ This paper introduces a rather simple but stateof-the-art system, which we intend to be used as a strong baseline to evaluate the impact of structural innovations.
We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ Many of our features are similar to those described in Culotta et al. (2007).
We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. $$$$$ This feature is a proxy for having similar semantic types.

Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ We split the corpus into three sets: Train, Dev, and Test.
Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ These works often show that complex models improve over a weak pairwise baseline.
Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ However, we are not aware of any system using the number of compatible mentions as a distance.
Note that we solve the above Best-Link inference using an efficient algorithm (Bengtson and Roth, 2008) which runs in time quadratic in the number of mentions. $$$$$ The ultimate goal for a coreference system is to process unannotated text.

The baseline system applies the strategy in (Bengtson and Roth, 2008, Section 2.2) to learn the pairwise scoring functions using the Averaged Perceptron algorithm. $$$$$ For these reasons, we report our results using B-Cubed F-Score.
The baseline system applies the strategy in (Bengtson and Roth, 2008, Section 2.2) to learn the pairwise scoring functions using the Averaged Perceptron algorithm. $$$$$ We also require that no non-pronoun can refer back to a pronoun: If m is not a pronoun, we do not consider pronouns as candidate antecedents.
The baseline system applies the strategy in (Bengtson and Roth, 2008, Section 2.2) to learn the pairwise scoring functions using the Averaged Perceptron algorithm. $$$$$ The ultimate goal for a coreference system is to process unannotated text.

Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ For our experiments in Section 5, we use gold mention types as is done by Culotta et al. (2007) and Luo and Zitouni (2005).
Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ While previous work showed the impact of complex models on a weak pairwise baseline, the applicability and impact of such models on a strong baseline system such as ours remains uncertain.
Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ Anaphoricity has been proposed as a part of the model in several systems, including Ng and Cardie (2002a), but we are not aware of it being used as a feature for a learning algorithm.
Among them the mention pair model (McCarthy and Lehnert, 1995) is one of the most influential ones and can achieve the state of-the-art performance (Bengtson and Roth, 2008). $$$$$ The parameters of the algorithm are chosen to maximize the BCubed F-Score on the Dev-Tune data.

Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ Given a document and a set of mentions, coreference resolution is the task of grouping the mentions into equivalence classes, so that each equivalence class contains exactly those mentions that refer to the same discourse entity.
Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ Many of our features are similar to those described in Culotta et al. (2007).
Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ While previous work showed the impact of complex models on a weak pairwise baseline, the applicability and impact of such models on a strong baseline system such as ours remains uncertain.
Best-first clustering has been previously studied by Ng and Cardie (2002) and Bengtson and Roth (2008) and found to be effective. $$$$$ For example, given the sentence (where the head noun of each mention is subscripted) the task is to group the mentions so that those referring to the same entity are placed together into an equivalence class.
