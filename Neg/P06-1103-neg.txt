Klementiev and Roth (2006) explore the use of a perceptron-based ranking model for the purpose of finding name transliterations across comparable corpora. $$$$$ To this end, we would like to compare the performance of an NER system trained on a corpus tagged using this approach to one trained on a hand-tagged corpus.
Klementiev and Roth (2006) explore the use of a perceptron-based ranking model for the purpose of finding name transliterations across comparable corpora. $$$$$ Each unique word had its own equivalence class for the English side of the corpus, although, in principal, ideas such as in (Li et al., 2004) could be incorporated.
Klementiev and Roth (2006) explore the use of a perceptron-based ranking model for the purpose of finding name transliterations across comparable corpora. $$$$$ Other type of supervision was in the form of a very small bootstrapping transliteration set.
Klementiev and Roth (2006) explore the use of a perceptron-based ranking model for the purpose of finding name transliterations across comparable corpora. $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

 $$$$$ Positive examples used for iterative training are pairs of NEs and their best temporally aligned (thresholded) transliteration candidates.
 $$$$$ Figure 2 shows an example list of NEs and their possible Russian transliterations.
 $$$$$ Named Entity recognition (NER) is an important part of many natural language processing tasks.
 $$$$$ That is not required, however, as the model only needs to be good enough to place the correct transliteration anywhere in the candidate list.

The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ Named Entity recognition (NER) is an important part of many natural language processing tasks.
The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ Note that couplings with the empty string represent insertions/omissions.
The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ That is not required, however, as the model only needs to be good enough to place the correct transliteration anywhere in the candidate list.
The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ The second observation is that NEs often contain or are entirely made up of words that are phonetically transliterated or have a common etymological origin across languages (e.g. parliament in English and , its Russian translation), and thus are phonetically similar.

 $$$$$ If a dictionary is available, transliteration candidate lists on line 6 are augmented with translations.
 $$$$$ For time sequence matching, we used a scoring metric novel in this domain.
 $$$$$ We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anonymous referees for their helpful comments.

Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ To this end, we would like to compare the performance of an NER system trained on a corpus tagged using this approach to one trained on a hand-tagged corpus.
Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ A large amount of previous work exists on transliteration models.
Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ To this end, we would like to compare the performance of an NER system trained on a corpus tagged using this approach to one trained on a hand-tagged corpus.
Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ We first run a Discrete Fourier Transform on a time sequence to extract its Fourier expansion coefficients.

As stated by (Klementiev and Roth, 2006), the projection of NER tags is easier in comparison to projecting other types of annotations such as POS-tags and BPC. $$$$$ We expect that more language specific knowledge used to discover accurate equivalence classes would result in performance improvements.
As stated by (Klementiev and Roth, 2006), the projection of NER tags is easier in comparison to projecting other types of annotations such as POS-tags and BPC. $$$$$ Approaches that attempt to use these two characteristics separately to identify NEs across languages would have significant shortcomings.
As stated by (Klementiev and Roth, 2006), the projection of NER tags is easier in comparison to projecting other types of annotations such as POS-tags and BPC. $$$$$ We extend our preliminary work in (Klementiev and Roth, 2006) to discover multi-word Named Entities and to take advantage of a dictionary (if one exists) to handle NEs which are partially or entirely translated.

 $$$$$ (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English.
 $$$$$ We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anonymous referees for their helpful comments.
 $$$$$ We provided experimental evidence that this metric outperforms other scoring metrics traditionally used.
 $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

The iterative training algorithm described above is adopted from Klementiev and Roth (2006). $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.
The iterative training algorithm described above is adopted from Klementiev and Roth (2006). $$$$$ We provided experimental evidence that this metric outperforms other scoring metrics traditionally used.

(Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. $$$$$ For example, in Russian, depending on a case being used, the same noun may appear with various endings.
(Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. $$$$$ We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.
(Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. $$$$$ We develop an algorithm that exploits both observations iteratively.
(Klementiev and Roth, 2006) bootstrap with a classifier used interchangeably with an unsupervised temporal alignment method. $$$$$ We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anonymous referees for their helpful comments.

Our initial feature extraction scheme follows the one presented in (Klementiev and Roth, 2006), in which the feature space consists of n-gram pairs from the two languages. $$$$$ We achieved the accuracy of about 66%.
Our initial feature extraction scheme follows the one presented in (Klementiev and Roth, 2006), in which the feature space consists of n-gram pairs from the two languages. $$$$$ Thus, in order to rely on the time sequences we obtain, we need to be able to group variants of the same NE into an equivalence class, and collect their aggregate mention counts.
Our initial feature extraction scheme follows the one presented in (Klementiev and Roth, 2006), in which the feature space consists of n-gram pairs from the two languages. $$$$$ The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005).

We evaluated our approach in two settings; first, we compared our system to a baseline system described in (Klementiev and Roth, 2006). $$$$$ We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anonymous referees for their helpful comments.
We evaluated our approach in two settings; first, we compared our system to a baseline system described in (Klementiev and Roth, 2006). $$$$$ Translations will be the correct choice for some NE words (e.g. for queen in Queen Victoria), and transliterations for others (e.g.

Note that one of the models proposed in (Klementiev and Roth, 2006b) takes advantage of the temporal information. $$$$$ Translations will be the correct choice for some NE words (e.g. for queen in Queen Victoria), and transliterations for others (e.g.
Note that one of the models proposed in (Klementiev and Roth, 2006b) takes advantage of the temporal information. $$$$$ Accuracy was computed as the percentage of NEs correctly identified by the algorithm.
Note that one of the models proposed in (Klementiev and Roth, 2006b) takes advantage of the temporal information. $$$$$ For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively.
Note that one of the models proposed in (Klementiev and Roth, 2006b) takes advantage of the temporal information. $$$$$ While generative models are often robust, they tend to make independence assumptions that do not hold in data.

Our best model, the unsupervised learning with all constraints, outperforms both models in (Klementiev and Roth, 2006b), even though we do not use any temporal information. $$$$$ Pair-wise time sequence scoring and transliteration models should give better confidence in NE matches.

The Russian data set, originally introduced in (Klementiev and Roth, 2006b), is comprised of temporally aligned news articles. $$$$$ E.g., Figure 1 shows a histogram of the number of occurrences of the word Hussein and its Russian transliteration in our bilingual news corpus spanning years 2001 through late 2005.
The Russian data set, originally introduced in (Klementiev and Roth, 2006b), is comprised of temporally aligned news articles. $$$$$ To this end, we would like to compare the performance of an NER system trained on a corpus tagged using this approach to one trained on a hand-tagged corpus.
The Russian data set, originally introduced in (Klementiev and Roth, 2006b), is comprised of temporally aligned news articles. $$$$$ We can exploit such weak synchronicity of NEs across languages to associate them.
The Russian data set, originally introduced in (Klementiev and Roth, 2006b), is comprised of temporally aligned news articles. $$$$$ We developed a linear discriminative transliteration model, and presented a method to automatically generate features.

 $$$$$ Figure 5 shows parts of transliteration lists for NE forsyth for two iterations of the algorithm.
 $$$$$ We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.
 $$$$$ The weak transliteration model selects the correct transliteration (italicized) as the 24th best transliteration in the first iteration.

For Russian, we compare to the model presented in (Klementiev and Roth, 2006b), a weakly supervised algorithm that uses both phonetic information and temporal information. $$$$$ The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005).
For Russian, we compare to the model presented in (Klementiev and Roth, 2006b), a weakly supervised algorithm that uses both phonetic information and temporal information. $$$$$ We build a feature vector from this example in the following manner: First, we split both words into all possible substrings of up to size two: We build a feature vector by coupling substrings from the two sets: We use the observation that transliteration tends to preserve phonetic sequence to limit the number of couplings.

We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal co-occurrence similarity when ranking the transliteration candidates. $$$$$ As we decrease the size from 80 to 20, the accuracy of the first iteration drops by over 20%, but a few iterations later the two have similar performance.
We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal co-occurrence similarity when ranking the transliteration candidates. $$$$$ We developed a linear discriminative transliteration model, and presented a method to automatically generate features.
We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal co-occurrence similarity when ranking the transliteration candidates. $$$$$ Seeded with a small number of transliteration pairs, our algorithm discovers multi-word NEs, and takes advantage of a dictionary (if one exists) to account for translated or partially translated NEs.
We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal co-occurrence similarity when ranking the transliteration candidates. $$$$$ The second observation is that NEs often contain or are entirely made up of words that are phonetically transliterated or have a common etymological origin across languages (e.g. parliament in English and , its Russian translation), and thus are phonetically similar.

This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language.
This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ The algorithm can be naturally extended to comparable corpora of more than two languages.
This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ New features were discovered throughout training; all but top 3000 features from positive and 3000 from negative examples were pruned based on the number of their occurrences so far.
This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.

The extraction proceeds either iteratively by starting from a few seed extraction rules (Collins and Singer, 1999), or by mining named entities from comparable news articles (Shinyama and Sekine, 2004) or from multilingual corpora (Klementiev and Roth, 2006). $$$$$ Negative examples are English non-NEs paired with random Russian words.
The extraction proceeds either iteratively by starting from a few seed extraction rules (Collins and Singer, 1999), or by mining named entities from comparable news articles (Shinyama and Sekine, 2004) or from multilingual corpora (Klementiev and Roth, 2006). $$$$$ If its similarity score surpassed a set threshold, it was added to the list of positive examples for the next round of training.
The extraction proceeds either iteratively by starting from a few seed extraction rules (Collins and Singer, 1999), or by mining named entities from comparable news articles (Shinyama and Sekine, 2004) or from multilingual corpora (Klementiev and Roth, 2006). $$$$$ In general, one would expect the size of the training set necessary for the algorithm to improve to depend on the level of temporal alignment of the two sides of the corpus.
The extraction proceeds either iteratively by starting from a few seed extraction rules (Collins and Singer, 1999), or by mining named entities from comparable news articles (Shinyama and Sekine, 2004) or from multilingual corpora (Klementiev and Roth, 2006). $$$$$ For a given NE, transliteration model selects a candidate list for each constituent word.

More recently, Klementiev and Roth (2006) also use F-index (Hetland, 2004), a score using DFT, to calculate the time distribution similarity. $$$$$ To this end, we would like to compare the performance of an NER system trained on a corpus tagged using this approach to one trained on a hand-tagged corpus.
More recently, Klementiev and Roth (2006) also use F-index (Hetland, 2004), a score using DFT, to calculate the time distribution similarity. $$$$$ NEs have similar time distributions across such corpora, and often some of the tokens in a multi-word NE are transliterated.
More recently, Klementiev and Roth (2006) also use F-index (Hetland, 2004), a score using DFT, to calculate the time distribution similarity. $$$$$ Pair-wise time sequence scoring and transliteration models should give better confidence in NE matches.
More recently, Klementiev and Roth (2006) also use F-index (Hetland, 2004), a score using DFT, to calculate the time distribution similarity. $$$$$ We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anonymous referees for their helpful comments.
