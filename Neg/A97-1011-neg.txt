To identify associative constructions, we first process our texts using Conexor's FDG parser (Tapanainen and Jarvinen, 1997). $$$$$ A simplified example is in Figure 1, where the link between I and see denotes that I is the modifier of see and its syntactic function is that of subject.
To identify associative constructions, we first process our texts using Conexor's FDG parser (Tapanainen and Jarvinen, 1997). $$$$$ Instead, we can apply the rules iteratively, and usually some of the rules apply when the ambiguity is reduced.
To identify associative constructions, we first process our texts using Conexor's FDG parser (Tapanainen and Jarvinen, 1997). $$$$$ As already noted, the dependency grammar has a big advantage over ENGCG in dealing with ambiguity.
To identify associative constructions, we first process our texts using Conexor's FDG parser (Tapanainen and Jarvinen, 1997). $$$$$ For example, the rule discards a verb (V) reading if the preceding word (-1) is unambiguously (C) a determiner (DET).

For English texts, these trees were first provided by the Connexor parser at UMIACS (Tapanainen and Jarvinen, 1997), and then corrected by one of the team PIs. $$$$$ We first describe the older Constraint Grammar parser where many of the ideas come from.
For English texts, these trees were first provided by the Connexor parser at UMIACS (Tapanainen and Jarvinen, 1997), and then corrected by one of the team PIs. $$$$$ We have the following hypotheses: (1) the dependency forest is quite sparse and a whole parse tree can not always be found; (2) pruning should favour large (sub)trees; (3) unlinked readings of a word can be removed when there is a linked reading present among the alternatives; (4) unambiguous subtrees are more likely to be correct than ambiguous ones; and (5) pruning need not force the words to be unambiguous.
For English texts, these trees were first provided by the Connexor parser at UMIACS (Tapanainen and Jarvinen, 1997), and then corrected by one of the team PIs. $$$$$ This setup makes it possible to operate on several layers of information, and use and combine structural information more efficiently than in the original Constraint Grammar framework, without any further disadvantage in dealing with ambiguity.
For English texts, these trees were first provided by the Connexor parser at UMIACS (Tapanainen and Jarvinen, 1997), and then corrected by one of the team PIs. $$$$$ Some early formalisations, c.f.

It is developped at the Xerox Research Centre Europe (XRCE) and shares the same computationnal paradigm as the PNLPL approach (Jensen, 1992) and the FDGP approach (Tapanainen and Jarvinen, 1997). $$$$$ Rules also have contextual tests that describe the condition according to which they may be applied.
It is developped at the Xerox Research Centre Europe (XRCE) and shares the same computationnal paradigm as the PNLPL approach (Jensen, 1992) and the FDGP approach (Tapanainen and Jarvinen, 1997). $$$$$ Then object or complement links are followed downwards (BOTTOM), to the last verbal reading (here decide).
It is developped at the Xerox Research Centre Europe (XRCE) and shares the same computationnal paradigm as the PNLPL approach (Jensen, 1992) and the FDGP approach (Tapanainen and Jarvinen, 1997). $$$$$ We describe a practical parser for unrestricted dependencies.
It is developped at the Xerox Research Centre Europe (XRCE) and shares the same computationnal paradigm as the PNLPL approach (Jensen, 1992) and the FDGP approach (Tapanainen and Jarvinen, 1997). $$$$$ The rule thus is of the form:
