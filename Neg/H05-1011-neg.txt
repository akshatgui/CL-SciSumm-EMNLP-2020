(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ This model is in some respects very similar to our LLR-based model, us ing Dice coefficient association scores where we use LLR scores, and absolute position differences where we use nonmonotonicity measures.
(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ Ifthe feature values are discrete, however, the mini mum difference may be too large compared to theunweighted association score.
(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.

LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ The possible alignment havingthe best overall score is selected as the word align ment for that sentence pair.
LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ We optimize the model weights using a modified version of averaged perceptron learning as describedby Collins (2002).
LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ These models have the theadvantages that they are easy to add fea tures to and they allow fast optimization of model parameters using small amounts of annotated data.
LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ They train Model 3 us ing Giza++, and then use the Model 3 score of apossible alignment as a feature value in a discriminatively trained log-linear model, along with fea 87 tures incorporating part-of-speech information, and whether the aligned words are given as translations in a bilingual dictionary.

A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ While the discriminative models presented above are very simple to describe, finding the optimal alignment according to these models is non-trivial.
A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ These models have the theadvantages that they are easy to add fea tures to and they allow fast optimization of model parameters using small amounts of annotated data.
A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ or ?possible?
A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ Nevertheless, the parameter opti mization was still quite fast, since it took only a few iterations over our 224 sentence pair developmentset.

In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ When Brown et al (1993) wanted to add a fertility component to create Models 3, 4, and 5, however, this generative 81story didn?t fit any longer, because it does not in clude how many target language words to align to each source language word as a separate decision.
In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ Auto matic sentence alignment of the training data wasprovided by Ulrich Germann, and the hand align ments of the words in the test data were created by Franz Och and Hermann Ney (Och and Ney, 2003).Since our discriminative training approach requires a small amount of annotated data for parame ter optimization, we split the test data set into two virtually equal subsets, by randomly ordering the test data pairs, and assigning alternate pairs from the random order to the two subsets.
In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ As described by Collins, the perceptron up date rule involves incrementing each weight by the difference in the feature values being compared.

Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ In this paper, we demonstrate a discriminative approachto training simple word alignment mod els that are comparable in accuracy tothe more complex generative models nor mally used.
Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ That meant that a learning rate small enough to let 85 us converge on the desired weight values might take a very large number of iterations through the data to reach those values.
Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ = argmaxa n ? i=1 ?ifi(a, e, f) where the fi are features and the ?i are weights.
Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ Fraser and Marcu(2005) modify Model 4 to be a log-linear combina tion of 11 submodels (5 based on standard Model 4 parameters, and 6 based on additional features) and discriminatively optimize the submodel weights on each iteration of a Viterbi approximation to EM.

We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ Current word align ment methods are predominantly based on generative models.
We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ Fraser and Marcu(2005) modify Model 4 to be a log-linear combina tion of 11 submodels (5 based on standard Model 4 parameters, and 6 based on additional features) and discriminatively optimize the submodel weights on each iteration of a Viterbi approximation to EM.
We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ links.

As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ We experimented with both the downhill sim plex method (Press et al, 2002, Section 10.4) and Powell?s method (Press et al, 2002, Section 10.5), but we obtained slightly better results with a more heuristic method designed to look past minor local minima.
As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ In this paper, we demonstrate a discriminative approachto training simple word alignment mod els that are comparable in accuracy tothe more complex generative models nor mally used.
As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ Callison-Burch et al (2004) had investigated the use of small amounts of annotated data to help train the IBM and HMMmodels, but the models were still generative and were trained using maximum-likelihood methods.Recently, however, three efforts nearly simultaneous with ours have made use of discriminative meth ods to train alignment models.
As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ Callison-Burch et al (2004) had investigated the use of small amounts of annotated data to help train the IBM and HMMmodels, but the models were still generative and were trained using maximum-likelihood methods.Recently, however, three efforts nearly simultaneous with ours have made use of discriminative meth ods to train alignment models.

Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.
Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ log p(f?|e?)p(f?) In this formula f and e mean that the words whose degree of association is being measured occur in the respective target and source sentences of an alignedsentence pair, ?f and ?e mean that the correspond ing words do not occur in the respective sentences, f?
Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ First, we average the weight values over each pass through the data, rather thanover all passes, as we found this led to faster con vergence.
Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ links.

 $$$$$ We experimented with both the downhill sim plex method (Press et al, 2002, Section 10.4) and Powell?s method (Press et al, 2002, Section 10.5), but we obtained slightly better results with a more heuristic method designed to look past minor local minima.
 $$$$$ The points of nonmonotonicity in the alignment will be the places where there are backward jumps in this sequence of target word positions.
 $$$$$ This necessitates, however, employing a version ofperceptron learning that uses a learning rate parameter.
 $$$$$ Since we expect translation pairs to be positively associated, we discard any negatively associated word pairs by requiring thatp(f, e) > p(f) ? p(e).

d is an absolute discount parameter as in (Moore, 2005). $$$$$ We make a few modifications to the procedure as described by Collins.
d is an absolute discount parameter as in (Moore, 2005). $$$$$ In generating the list of associ ation types to be used in aligning a given sentence pair, we use only association types which have the best association score for this sentence pair for one of the word types involved in the association.
d is an absolute discount parameter as in (Moore, 2005). $$$$$ We trained CLP-based models from these counts for a range of values for the discount used in the conditional link probability estimation, finding a value of 0.4 to be a roughly optimal value of the discount parameter for the development set.
d is an absolute discount parameter as in (Moore, 2005). $$$$$ When we do this merge, the resulting set of alignments is sorted by overall score, and only the N best alignments are kept, for a fixed N . Some details of the search differ between the LLR-based model and the CLP-based model.

(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ For the CLP-based model, each association score is for a cluster of words that must be disjoint from any other association cluster, so when we add links for a new cluster, we mustremove any other links involving the same word instances.
(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ Perceptron learning does not directly optimize error rate, but we have onlya small number of parameters that we need to op timize.
(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ One estimate of theconditional link probabilities comes from the LLRbased model described above, optimized on an an notated development set.
(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ We experimented with both the downhill sim plex method (Press et al, 2002, Section 10.4) and Powell?s method (Press et al, 2002, Section 10.5), but we obtained slightly better results with a more heuristic method designed to look past minor local minima.

2) Conditional link probability (Moore, 2005). $$$$$ They train Model 3 us ing Giza++, and then use the Model 3 score of apossible alignment as a feature value in a discriminatively trained log-linear model, along with fea 87 tures incorporating part-of-speech information, and whether the aligned words are given as translations in a bilingual dictionary.
2) Conditional link probability (Moore, 2005). $$$$$ The results of our work and other recent efforts on discriminatively trained alignment models showthat results comparable to or better than those ob tained with the IBM models are possible within aframework that makes it easy to add arbitrary ad ditional features.
2) Conditional link probability (Moore, 2005). $$$$$ Perceptron learning does not directly optimize error rate, but we have onlya small number of parameters that we need to op timize.
2) Conditional link probability (Moore, 2005). $$$$$ We useda subset of the Canadian Hansards bilingual cor pus supplied for the workshop, comprising 500,000English-French sentences pairs, including 447 man ually word-aligned sentence pairs designated as test data.

For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ The situation with the LLR-based model was more complicated.
For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ links.
For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ |A ? P |+ |A ? S| |A|+ |S| In these definitions, S denotes the set of alignments annotated as sure, P denotes the set of alignments annotated possible or sure, and A denotes the set ofalignments produced by the method under test.

d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ The results of our work and other recent efforts on discriminatively trained alignment models showthat results comparable to or better than those ob tained with the IBM models are possible within aframework that makes it easy to add arbitrary ad ditional features.
d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ Each of our feature scores have analogs in theIBM and HMM models.
d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ as to how the observed data is generated by an interrelatedset of stochastic processes.

Moore (2005) proposes a similar framework, but with more features and a different search method. $$$$$ This is fast to train, because selecting the feature weights is the last step in build ing the model and the ?online?
Moore (2005) proposes a similar framework, but with more features and a different search method. $$$$$ or ?possible?
Moore (2005) proposes a similar framework, but with more features and a different search method. $$$$$ To tal training time was greater since we used multiple runs of perceptron learning with different learningrates for the LLR-based model and different condi tional link probability discounts for CLP 1 , but total training time for each model was around an hour.

In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ = argmaxa n ? i=1 ?ifi(a, e, f) where the fi are features and the ?i are weights.
In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ The second problem we address is the difficulty of adding features to the standard generative models.
In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ These models have the theadvantages that they are easy to add fea tures to and they allow fast optimization of model parameters using small amounts of annotated data.
In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ The best combinations of these models can produce high accuracy alignments,at least when trained on a large corpus of fairly di rect translations in related languages.These standard models are less than ideal, how ever, in a number of ways, two of which we address in this paper.

These models are roughly clustered into two groups: generative models, such as those pro posed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative models, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006). $$$$$ Fol lowing standard practice in the field, we take AER, which is derived from F-measure, as the primary evaluation metric that we are attempting to optimize.
These models are roughly clustered into two groups: generative models, such as those pro posed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative models, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006). $$$$$ Callison-Burch et al (2004) had investigated the use of small amounts of annotated data to help train the IBM and HMMmodels, but the models were still generative and were trained using maximum-likelihood methods.Recently, however, three efforts nearly simultaneous with ours have made use of discriminative meth ods to train alignment models.
These models are roughly clustered into two groups: generative models, such as those pro posed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative models, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006). $$$$$ Current word align ment methods are predominantly based on generative models.

Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ or ?possible?
Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ To model this explicitly, they had to come up with a different generative story.
Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ Fol lowing standard practice in the field, we take AER, which is derived from F-measure, as the primary evaluation metric that we are attempting to optimize.
Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ Current word align ment methods are predominantly based on generative models.

Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ Allowing all weights tovary allows many equivalent sets of weights that dif fer only by a constant scale factor.
Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ Since the values of these parameters affect the values of the translation, align ment, and fertility probabilities trained by EM, there is no effective way to optimize them other than torun the training procedure with a particular combination of values and evaluate the accuracy of the resulting alignments.
Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ The results of our work and other recent efforts on discriminatively trained alignment models showthat results comparable to or better than those ob tained with the IBM models are possible within aframework that makes it easy to add arbitrary ad ditional features.

 $$$$$ nature of perceptronlearning allows the parameter optimization to con verge quickly.
 $$$$$ The possible alignment havingthe best overall score is selected as the word align ment for that sentence pair.
 $$$$$ Never theless, we have found a beam-search procedure that seems highly effective in finding good alignments when used with these models.For each sentence pair, we create a list of associa tion types and their corresponding scores, consisting of the associations for which we have determined ascore and for which the words involved in the asso ciation type occur in the sentence pair.3 We sort the resulting list of association types from best to worst according to their scores.
 $$$$$ In generating the list of associ ation types to be used in aligning a given sentence pair, we use only association types which have the best association score for this sentence pair for one of the word types involved in the association.
