(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ as to how the observed data is generated by an interrelatedset of stochastic processes.
(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ Bilingual word alignment forms the foun dation of most approaches to statisticalmachine translation.
(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features. $$$$$ Iterating through the data continues until the weights stop changing, because aref = ahyp foreach sentence pair, or until some other stopping con dition is met.

LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ The possible alignment havingthe best overall score is selected as the word align ment for that sentence pair.
LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ We used one ofthese subsets as a development set for parameter op timization, and held out the other for a final test set.We report the performance of our alignment mod els in terms of precision, recall, and alignment error rate (AER) as defined by Och and Ney (2003): recall = |A ? S| |S| precision = |A ? P | |A| AER = 1?
LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ That seemed to produce good results, so we did not attempt to further optimize the learning rate parameter for this model.
LLR and CLP are the word association statistics used in Moore's work (Moore, 2005). $$$$$ Current word align ment methods are predominantly based on generative models.

A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ These models have the theadvantages that they are easy to add fea tures to and they allow fast optimization of model parameters using small amounts of annotated data.
A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ The results of our work and other recent efforts on discriminatively trained alignment models showthat results comparable to or better than those ob tained with the IBM models are possible within aframework that makes it easy to add arbitrary ad ditional features.
A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ We believe the most likely explanation is the fact that 4Thanks to Chris Quirk for carrying out this alignment.
A variation of this feature was used by (Moore, 2005) in his paper. $$$$$ Bilingual word alignment forms the foun dation of most approaches to statisticalmachine translation.

In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ Liu et al (2005) also develop a log-linear model,based on IBM Model 3.
In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ We therefore thought it might be helpful to apply a general optimization procedure directlyto the error rate, starting from the best parame ter values found by perceptron learning, using theN -best alignments found with these parameter values.
In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.
In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005). $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.

Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ Bilingual word alignment forms the foun dation of most approaches to statisticalmachine translation.
Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ Liu et al (2005) also develop a log-linear model,based on IBM Model 3.
Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ We then iterate through our sorted list of association types from best to worst, creating new alignments that add links for all instances of the association type currently beingconsidered to existing alignments, potentially keep ing both the old and new alignments in our set of possible alignments.
Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005). $$$$$ We used one ofthese subsets as a development set for parameter op timization, and held out the other for a final test set.We report the performance of our alignment mod els in terms of precision, recall, and alignment error rate (AER) as defined by Och and Ney (2003): recall = |A ? S| |S| precision = |A ? P | |A| AER = 1?

We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ This model is in some respects very similar to our LLR-based model, us ing Dice coefficient association scores where we use LLR scores, and absolute position differences where we use nonmonotonicity measures.
We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ While the discriminative models presented above are very simple to describe, finding the optimal alignment according to these models is non-trivial.
We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ Ifthe feature values are discrete, however, the mini mum difference may be too large compared to theunweighted association score.
We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data. $$$$$ Generative models require a generative ?story?

As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ model, so one might have expected it to perform better.
As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ Fraser and Marcu(2005) modify Model 4 to be a log-linear combina tion of 11 submodels (5 based on standard Model 4 parameters, and 6 based on additional features) and discriminatively optimize the submodel weights on each iteration of a Viterbi approximation to EM.
As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ Furthermore, no generative story has to be invented to explain how the features generate the data, so new features can be easily added without having to change the overall structure of the model.In theory, a disadvantage of a discrimintative ap proach compared to a generative approach is that it requires annotated data for training.
As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them. $$$$$ In both cases, if there are no existing links involving any of the words involved in the new link, we simply add it (keeping a copy of the original alignment, subject to pruning).If there are existing links involving word instances also involved in the new link, the two mod 3By association type we mean a possible link between a pair of words, or, in the case of the CLP-based models, a possible one-to-many or many-to-one linkage of words.

Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ The log-linear model is trained by standard maximum-entropy methods.Klein and Taskar (2005), in a tutorial on maximum margin methods for natural-language processing, described a weighted linear model incorporat ing association, position, and orthography features,with its parameters trained by a structured-supportvector-machine method.
Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ These models have the theadvantages that they are easy to add fea tures to and they allow fast optimization of model parameters using small amounts of annotated data.
Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ Fol lowing standard practice in the field, we take AER, which is derived from F-measure, as the primary evaluation metric that we are attempting to optimize.
Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. $$$$$ Bilingual word alignment is the first step of most current approaches to statistical machine translation.Although the best performing systems are ?phrase based?

 $$$$$ All the probabilities in the for mula refer to maximum likelihood estimates.
 $$$$$ Bilingual word alignment forms the foun dation of most approaches to statisticalmachine translation.
 $$$$$ |A ? P |+ |A ? S| |A|+ |S| In these definitions, S denotes the set of alignments annotated as sure, P denotes the set of alignments annotated possible or sure, and A denotes the set ofalignments produced by the method under test.
 $$$$$ Ifthe feature values are discrete, however, the mini mum difference may be too large compared to theunweighted association score.

d is an absolute discount parameter as in (Moore, 2005). $$$$$ or ?possible?
d is an absolute discount parameter as in (Moore, 2005). $$$$$ They train Model 3 us ing Giza++, and then use the Model 3 score of apossible alignment as a feature value in a discriminatively trained log-linear model, along with fea 87 tures incorporating part-of-speech information, and whether the aligned words are given as translations in a bilingual dictionary.
d is an absolute discount parameter as in (Moore, 2005). $$$$$ When Brown et al (1993) wanted to add a fertility component to create Models 3, 4, and 5, however, this generative 81story didn?t fit any longer, because it does not in clude how many target language words to align to each source language word as a separate decision.

(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ Rather than choose between them, we use both features.the one-to-many feature It has often been observed that word alignment links tend to be one-to one.
(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ Since evaluating each combina tion of parameter values in this way can take hours to days on a large training corpus, it seems safe to say that these parameters are rarely if ever truly jointly optimized for a particular alignment task.
(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ They train Model 3 us ing Giza++, and then use the Model 3 score of apossible alignment as a feature value in a discriminatively trained log-linear model, along with fea 87 tures incorporating part-of-speech information, and whether the aligned words are given as translations in a bilingual dictionary.
(Moore, 2005) uses an averaged perceptron for training with a customized beam search. $$$$$ We optimize the feature weights using a modified version of averaged perceptron learning as described by Collins (2002).

2) Conditional link probability (Moore, 2005). $$$$$ When the first version of this paper was submitted for review, we could honestly state, ?We are not aware of any previous work on discriminative word alignment models.?
2) Conditional link probability (Moore, 2005). $$$$$ model, so one might have expected it to perform better.
2) Conditional link probability (Moore, 2005). $$$$$ Callison-Burch et al (2004) had investigated the use of small amounts of annotated data to help train the IBM and HMMmodels, but the models were still generative and were trained using maximum-likelihood methods.Recently, however, three efforts nearly simultaneous with ours have made use of discriminative meth ods to train alignment models.
2) Conditional link probability (Moore, 2005). $$$$$ Thus, for a sentence pair (e, f) we seek the alignment a?

For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ Hence CLP 2 was able to consider more possible links.In light of our claims about the ease of optimiz ing the models, we should make some commentson the time need to train the parameters.
For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.
For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively. $$$$$ The association scores corresponds to word translation probabilities; the reordering scores correspond to distortion probabili ties; the scores for words left unlinked corresponds to probabilities of words being linked to the nullword; and the scores for one-to-many links corre spond to fertility probabilities.

d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.
d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ We evaluated our models using data from the bilin gual word alignment workshop held at HLT-NAACL 2003 (Mihalcea and Pedersen, 2003).
d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ We optimize the feature weights using a modified version of averaged perceptron learning as described by Collins (2002).
d is a discounting constant which is set to 0.4 following Moore (2005). $$$$$ We then iterate through our sorted list of association types from best to worst, creating new alignments that add links for all instances of the association type currently beingconsidered to existing alignments, potentially keep ing both the old and new alignments in our set of possible alignments.

Moore (2005) proposes a similar framework, but with more features and a different search method. $$$$$ The results of our work and other recent efforts on discriminatively trained alignment models showthat results comparable to or better than those ob tained with the IBM models are possible within aframework that makes it easy to add arbitrary ad ditional features.
Moore (2005) proposes a similar framework, but with more features and a different search method. $$$$$ When Brown et al (1993) wanted to add a fertility component to create Models 3, 4, and 5, however, this generative 81story didn?t fit any longer, because it does not in clude how many target language words to align to each source language word as a separate decision.

In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ Liu et al (2005) also develop a log-linear model,based on IBM Model 3.
In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ We therefore add both an alignment that keeps all previous links, and an additional set of alignments, each of which omits one of the previous links involving one of the word instances involved in the new link.
In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005). $$$$$ In generating the list of associ ation types to be used in aligning a given sentence pair, we use only association types which have the best association score for this sentence pair for one of the word types involved in the association.

These models are roughly clustered into two groups $$$$$ That meant that a learning rate small enough to let 85 us converge on the desired weight values might take a very large number of iterations through the data to reach those values.
These models are roughly clustered into two groups $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.
These models are roughly clustered into two groups $$$$$ In generating the list of associ ation types to be used in aligning a given sentence pair, we use only association types which have the best association score for this sentence pair for one of the word types involved in the association.
These models are roughly clustered into two groups $$$$$ Liu et al (2005) also develop a log-linear model,based on IBM Model 3.

Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ Weinitially explored limiting the number of associations considered for each word type simply as an ef ficiency heuristic, but we were surprised to discover that the most extreme form of such pruning actually reduced alignment error rate over any less restrictive form or not pruning on this basis at all.
Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ The log-linear model is trained by standard maximum-entropy methods.Klein and Taskar (2005), in a tutorial on maximum margin methods for natural-language processing, described a weighted linear model incorporat ing association, position, and orthography features,with its parameters trained by a structured-supportvector-machine method.
Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ They train Model 3 us ing Giza++, and then use the Model 3 score of apossible alignment as a feature value in a discriminatively trained log-linear model, along with fea 87 tures incorporating part-of-speech information, and whether the aligned words are given as translations in a bilingual dictionary.
Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story. $$$$$ We used one ofthese subsets as a development set for parameter op timization, and held out the other for a final test set.We report the performance of our alignment mod els in terms of precision, recall, and alignment error rate (AER) as defined by Och and Ney (2003): recall = |A ? S| |S| precision = |A ? P | |A| AER = 1?

Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ In this paper, we demonstrate a discriminative approachto training simple word alignment mod els that are comparable in accuracy tothe more complex generative models nor mally used.
Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ Fraser and Marcu(2005) modify Model 4 to be a log-linear combina tion of 11 submodels (5 based on standard Model 4 parameters, and 6 based on additional features) and discriminatively optimize the submodel weights on each iteration of a Viterbi approximation to EM.
Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ To find the points of nonmonotonicity of a wordalignment, we arbitrarily designate one of the lan guages as the source and the other as the target.
Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features. $$$$$ Full details are provided in the reference.what other links are present in the alignment.

 $$$$$ The other difference in how the two models are treated is an extra pruning heuristic we use in theLLR-based model.
 $$$$$ After many years using the same small set of alignment models, we now have an easy way to experiment with a wide variety of knowledge sources to improve word-alignment accuracy.
 $$$$$ 84 els are treated differently.
 $$$$$ We therefore thought it might be helpful to apply a general optimization procedure directlyto the error rate, starting from the best parame ter values found by perceptron learning, using theN -best alignments found with these parameter values.
