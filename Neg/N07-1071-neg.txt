Though, at least, roles of participants in the event have to be preserved by some means, such as the way presented in (Pantel et al, 2007). $$$$$ The strictest filters, ISP.JIM and ISP.IIM.n, have the poorest overall performance but, as expected, have a generally very low rate of false positives.
Though, at least, roles of participants in the event have to be preserved by some means, such as the way presented in (Pantel et al, 2007). $$$$$ In practical NLP applications, however, plausible inference rules such as “X married Y” ⇒ “X dated Y” are very useful.
Though, at least, roles of participants in the event have to be preserved by some means, such as the way presented in (Pantel et al, 2007). $$$$$ Semantic inference is a key component for advanced natural language understanding.

This work was refined by Pantel et al (2007) by assigning the x and y terms semantic types (inferential selectional preferences - ISP) based on lexical abstraction from empirically observed argument types. $$$$$ While these systems differ in their approaches, neither provides for the extracted inference rules to hold or fail based on SPs.
This work was refined by Pantel et al (2007) by assigning the x and y terms semantic types (inferential selectional preferences - ISP) based on lexical abstraction from empirically observed argument types. $$$$$ For each ISP algorithm and parameter combination, we constructed a confusion matrix on the development set and computed the system sensitivity, specificity and accuracy as described in Section 4.3.
This work was refined by Pantel et al (2007) by assigning the x and y terms semantic types (inferential selectional preferences - ISP) based on lexical abstraction from empirically observed argument types. $$$$$ We presented algorithms for learning what we call inferential selectional preferences, and presented evidence that learning selectional preferences can be useful in filtering out incorrect inferences.
This work was refined by Pantel et al (2007) by assigning the x and y terms semantic types (inferential selectional preferences - ISP) based on lexical abstraction from empirically observed argument types. $$$$$ Figure 2 illustrates the ROC curve for all our systems and parameter combinations on the TEST set.

Most distributional methods so far extract representations from large texts, and only as a follow-on step they either 1) alter these in order to reflect a disambiguated word (such as (Erk and Pado, 2008)) or 2) directly asses the appropriateness of a similarity judgment, given a specific context (such as (Pantel et al, 2007)). $$$$$ However, given the sentence: Fraud was suspected when accounts were charged by CCM telemarketers without obtaining consumer authorization. the plausible inference rule (1) would incorrectly infer that “CCM telemarketers announced the arrest of accounts”.
Most distributional methods so far extract representations from large texts, and only as a follow-on step they either 1) alter these in order to reflect a disambiguated word (such as (Erk and Pado, 2008)) or 2) directly asses the appropriateness of a similarity judgment, given a specific context (such as (Pantel et al, 2007)). $$$$$ In our experiments, reported in Section 5, we tested each model using various values of i.
Most distributional methods so far extract representations from large texts, and only as a follow-on step they either 1) alter these in order to reflect a disambiguated word (such as (Erk and Pado, 2008)) or 2) directly asses the appropriateness of a similarity judgment, given a specific context (such as (Pantel et al, 2007)). $$$$$ This section describes the methodology for testing our claim that inferential selectional preferences can be learned to filter incorrect inferences.
Most distributional methods so far extract representations from large texts, and only as a follow-on step they either 1) alter these in order to reflect a disambiguated word (such as (Erk and Pado, 2008)) or 2) directly asses the appropriateness of a similarity judgment, given a specific context (such as (Pantel et al, 2007)). $$$$$ We presented algorithms for learning what we call inferential selectional preferences, and presented evidence that learning selectional preferences can be useful in filtering out incorrect inferences.

Context-sensitive extensions of DIRT (Pantelet al, 2007) and (Basili et al, 2007) focus on making DIRT rules context-sensitive by attaching appropriate semantic classes to the X and Y slots of an inference rule. $$$$$ For instance the preference of win for the subject player, a nominalization of play, is used to derive that “win => play”.
Context-sensitive extensions of DIRT (Pantelet al, 2007) and (Basili et al, 2007) focus on making DIRT rules context-sensitive by attaching appropriate semantic classes to the X and Y slots of an inference rule. $$$$$ Finally, we propose inference filtering algorithms in Section 3.3. cx Resnik (1996) defined the selectional preferences of a predicate as the semantic classes of the words that appear as its arguments.
Context-sensitive extensions of DIRT (Pantelet al, 2007) and (Basili et al, 2007) focus on making DIRT rules context-sensitive by attaching appropriate semantic classes to the X and Y slots of an inference rule. $$$$$ To properly test WordNet as a source of semantic classes for our selectional preferences, we would need to experiment with different extraction algorithms.

For this (Pantel et al, 2007) build a set of semantic classes using WordNet in one case and CBC clustering algorithm in the other; for each rule, they use the overlap of the fillers found in the input corpus as an indicator of the correct semantic classes. $$$$$ Automatic derivation of semantic classes can take a variety of approaches, but often uses corpus methods and the Distributional Hypothesis (Harris 1964) to automatically cluster similar entities into classes, e.g.
For this (Pantel et al, 2007) build a set of semantic classes using WordNet in one case and CBC clustering algorithm in the other; for each rule, they use the overlap of the fillers found in the input corpus as an indicator of the correct semantic classes. $$$$$ We randomly selected 100 inference rules of the form pi => pj from DIRT.
For this (Pantel et al, 2007) build a set of semantic classes using WordNet in one case and CBC clustering algorithm in the other; for each rule, they use the overlap of the fillers found in the input corpus as an indicator of the correct semantic classes. $$$$$ In response, several researchers have created resources for enabling semantic inference.
For this (Pantel et al, 2007) build a set of semantic classes using WordNet in one case and CBC clustering algorithm in the other; for each rule, they use the overlap of the fillers found in the input corpus as an indicator of the correct semantic classes. $$$$$ Model 2: Independent Inferential Model (IIM) Our independent model is the same as the joint model above except that it computes candidate inferential SPs using the Independent Relational Model (IRM) instead of the JRM.

On a common data set (Pantel et al, 2007) and (Basili et al, 2007) achieve significant improvements over DIRT at 95% confidence level when employing the clustering methods. $$$$$ Future work in this direction includes further exploration of the appropriate inventory of semantic classes used as SP’s.
On a common data set (Pantel et al, 2007) and (Basili et al, 2007) achieve significant improvements over DIRT at 95% confidence level when employing the clustering methods. $$$$$ What is missing is knowledge about the admissible argument values for which an inference rule holds, which we call Inferential Selectional Preferences.
On a common data set (Pantel et al, 2007) and (Basili et al, 2007) achieve significant improvements over DIRT at 95% confidence level when employing the clustering methods. $$$$$ Selectional preference (SP) as a foundation for computational semantics is one of the earliest topics in AI and NLP, and has its roots in (Katz and Fodor 1963).
On a common data set (Pantel et al, 2007) and (Basili et al, 2007) achieve significant improvements over DIRT at 95% confidence level when employing the clustering methods. $$$$$ Intuitively, we have more confidence in a particular candidate if its semantic classes are closely associated given the relation p. Pointwise mutual information (Cover and Thomas 1991) is a commonly used metric for measuring this association strength between two events e1 and e2: 2 In this paper, the semantic classes C(x) and C(y) are extracted from WordNet and CBC (described in Section 4.2).

A couple of earlier works utilized a cluster-based model (Pantel et al, 2007) and an LSA-based model (Szpektor et al, 2008), in a selectional-preferences style approach. $$$$$ 2006), and textual entailment (Szpektor et al. 2004).
A couple of earlier works utilized a cluster-based model (Pantel et al, 2007) and an LSA-based model (Szpektor et al, 2008), in a selectional-preferences style approach. $$$$$ CBC (Pantel and Lin 2002).
A couple of earlier works utilized a cluster-based model (Pantel et al, 2007) and an LSA-based model (Szpektor et al, 2008), in a selectional-preferences style approach. $$$$$ Learning SPs often relies on an underlying set of semantic classes, as in both Resnik’s and our approach.

While most works on context-insensitive predicate inference rules, such as DIRT (Lin and Pantel, 2001), are based on word-level similarity measures, almost all prior models addressing context sensitive predicate inference rules are based on topic models (except for (Pantel et al, 2007), which was outperformed by later models). $$$$$ Resnik (1996), the seminal paper on this topic, introduced a statistical model for learning SPs for predicates using an unsupervised method.
While most works on context-insensitive predicate inference rules, such as DIRT (Lin and Pantel, 2001), are based on word-level similarity measures, almost all prior models addressing context sensitive predicate inference rules are based on topic models (except for (Pantel et al, 2007), which was outperformed by later models). $$$$$ This work constitutes a step towards better understanding of the interaction of selectional preferences and inferences, bridging these two aspects of semantics.
While most works on context-insensitive predicate inference rules, such as DIRT (Lin and Pantel, 2001), are based on word-level similarity measures, almost all prior models addressing context sensitive predicate inference rules are based on topic models (except for (Pantel et al, 2007), which was outperformed by later models). $$$$$ We presented algorithms for learning what we call inferential selectional preferences, and presented evidence that learning selectional preferences can be useful in filtering out incorrect inferences.

In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ Our work can be viewed as complementary to the work on extracting semantic inferences and paraphrases, since we seek to refine when a given inference applies, filtering out incorrect inferences.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ The goal of the filtering task is to minimize false positives (incorrectly accepted inferences) and false negatives (incorrectly rejected inferences).

Terminal nodes of the resultant structure were used as the basis for inferring semantic type restrictions, reminiscent of the use of CBC clusters (Pantel and Lin, 2002) by Pantel et al (2007), for typing the arguments of paraphrase rules. $$$$$ Overviews of NLP research on this theme are (Wilks and Fass 1992), which includes the influential theory of Preference Semantics by Wilks, and more recently (Light and Greiff 2002).
Terminal nodes of the resultant structure were used as the basis for inferring semantic type restrictions, reminiscent of the use of CBC clusters (Pantel and Lin, 2002) by Pantel et al (2007), for typing the arguments of paraphrase rules. $$$$$ Our models for learning inferential selectional preferences can be applied to any collection of inference rules between binary semantic relations.
Terminal nodes of the resultant structure were used as the basis for inferring semantic type restrictions, reminiscent of the use of CBC clusters (Pantel and Lin, 2002) by Pantel et al (2007), for typing the arguments of paraphrase rules. $$$$$ Future work in this direction includes further exploration of the appropriate inventory of semantic classes used as SP’s.
Terminal nodes of the resultant structure were used as the basis for inferring semantic type restrictions, reminiscent of the use of CBC clusters (Pantel and Lin, 2002) by Pantel et al (2007), for typing the arguments of paraphrase rules. $$$$$ In this paper, we focus on the inference rules contained in the DIRT resource (Lin and Pantel 2001).

Pantel et al (2007) and Szpektor et al (2008) represented the context of such rules as the intersection of preferences of the rule's LHS and RHS, namely the observed argument instantiations or their semantic classes. $$$$$ Overviews of NLP research on this theme are (Wilks and Fass 1992), which includes the influential theory of Preference Semantics by Wilks, and more recently (Light and Greiff 2002).
Pantel et al (2007) and Szpektor et al (2008) represented the context of such rules as the intersection of preferences of the rule's LHS and RHS, namely the observed argument instantiations or their semantic classes. $$$$$ Among manual resources used for this task are WordNet (Fellbaum 1998) and Cyc (Lenat 1995).
Pantel et al (2007) and Szpektor et al (2008) represented the context of such rules as the intersection of preferences of the rule's LHS and RHS, namely the observed argument instantiations or their semantic classes. $$$$$ Whereas in Section 3.1 we learned selectional preferences for the arguments of a relation p, in this section we learn selectional preferences for the arguments of an inference rule pi => pj.
Pantel et al (2007) and Szpektor et al (2008) represented the context of such rules as the intersection of preferences of the rule's LHS and RHS, namely the observed argument instantiations or their semantic classes. $$$$$ Future work in this direction includes further exploration of the appropriate inventory of semantic classes used as SP’s.

To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules. $$$$$ Whereas in Section 3.1 we learned selectional preferences for the arguments of a relation p, in this section we learn selectional preferences for the arguments of an inference rule pi => pj.
To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules. $$$$$ Semantic inference is a key component for advanced natural language understanding.
To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules. $$$$$ Learning SPs often relies on an underlying set of semantic classes, as in both Resnik’s and our approach.

We follow Pantel et al (2007) in using automatically-extracted semantic classes to help characterize plausible arguments. $$$$$ Overviews of NLP research on this theme are (Wilks and Fass 1992), which includes the influential theory of Preference Semantics by Wilks, and more recently (Light and Greiff 2002).
We follow Pantel et al (2007) in using automatically-extracted semantic classes to help characterize plausible arguments. $$$$$ In this paper, we experiment with two sets of semantic classes, one from WordNet and one from CBC.
We follow Pantel et al (2007) in using automatically-extracted semantic classes to help characterize plausible arguments. $$$$$ The cut produced 1287 semantic classes, a number similar to the classes in CBC.
We follow Pantel et al (2007) in using automatically-extracted semantic classes to help characterize plausible arguments. $$$$$ Let C(w) be the set of semantic classes c(w) to which word w belongs.

MI was also recently used for inference-rule SPs by Pantel et al (2007). $$$$$ Another thread related to our work includes extracting from text corpora paraphrases (Barzilay and McKeown 2001) and inference rules, e.g.
MI was also recently used for inference-rule SPs by Pantel et al (2007). $$$$$ Another thread related to our work includes extracting from text corpora paraphrases (Barzilay and McKeown 2001) and inference rules, e.g.
MI was also recently used for inference-rule SPs by Pantel et al (2007). $$$$$ Similarly, we define the relational selectional preferences of a binary semantic relation pi as the semantic classes C(x) of the words that can be instantiated for x and as the semantic classes C(y) of the words that can be instantiated for y.

As a way of enriching such a template-like knowledge, Pantel et al (2007) proposed the notion of inferential selectional preference and collected expressions that would fill those slots. $$$$$ Manual collections of semantic classes include the hierarchies of WordNet (Fellbaum 1998), Levin verb classes (Levin 1993), and FrameNet (Baker et al. 1998).
As a way of enriching such a template-like knowledge, Pantel et al (2007) proposed the notion of inferential selectional preference and collected expressions that would fill those slots. $$$$$ Each triple 〈c(x), p, c(y)〉 is a candidate selectional preference for p. Candidates can be incorrect when: a) they were generated from the incorrect sense of a polysemous word; or b) p does not hold for the other words in the semantic class.
As a way of enriching such a template-like knowledge, Pantel et al (2007) proposed the notion of inferential selectional preference and collected expressions that would fill those slots. $$$$$ DIRT consists of over 12 million rules which were extracted from a 1GB newspaper corpus (San Jose Mercury, Wall Street Journal and AP Newswire from the TREC-9 collection).

 $$$$$ This work constitutes a step towards better understanding of the interaction of selectional preferences and inferences, bridging these two aspects of semantics.
 $$$$$ Given a collection of DIRT inference rules of the form pi => pj, our experiments, using the methodology of Section 4, evaluate the capability of our ISP models for determining if (x, pj, y) holds given that (x, pi, y) holds.
 $$$$$ We present empirical evidence of its effectiveness.

Pantel et al (2007) apply a collection of rules to filter out incorrect inferences for SP. $$$$$ Each triple 〈c(x), p, c(y)〉 is a candidate selectional preference for p. Candidates can be incorrect when: a) they were generated from the incorrect sense of a polysemous word; or b) p does not hold for the other words in the semantic class.
Pantel et al (2007) apply a collection of rules to filter out incorrect inferences for SP. $$$$$ ISP.IIM.v, which is a much more permissive filter because it does not require both arguments of a relation to match, has generally many more false positives but has an overall better performance.
Pantel et al (2007) apply a collection of rules to filter out incorrect inferences for SP. $$$$$ CBC generated 1628 noun concepts and these were used as our semantic classes for SPs.
Pantel et al (2007) apply a collection of rules to filter out incorrect inferences for SP. $$$$$ In practical NLP applications, however, plausible inference rules such as “X married Y” ⇒ “X dated Y” are very useful.

The notion of Inferential Selectional Preference (ISP) has been introduced by Pantel et al (2007). $$$$$ However, given the sentence: Fraud was suspected when accounts were charged by CCM telemarketers without obtaining consumer authorization. the plausible inference rule (1) would incorrectly infer that “CCM telemarketers announced the arrest of accounts”.
The notion of Inferential Selectional Preference (ISP) has been introduced by Pantel et al (2007). $$$$$ Figure 2 illustrates the ROC curve for all our systems and parameter combinations on the TEST set.
The notion of Inferential Selectional Preference (ISP) has been introduced by Pantel et al (2007). $$$$$ TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).

In (Pantel et al, 2007), they augment each relation with its selectional preferences, i.e. fine-grained entity types of two arguments, to handle polysemy. $$$$$ We used the Minipar parser (Lin 1993) to match DIRT patterns in the text.
In (Pantel et al, 2007), they augment each relation with its selectional preferences, i.e. fine-grained entity types of two arguments, to handle polysemy. $$$$$ We present empirical evidence to support the following main contribution: Claim: Inferential selectional preferences can be automatically learned and used for effectively filtering out incorrect inferences.
In (Pantel et al, 2007), they augment each relation with its selectional preferences, i.e. fine-grained entity types of two arguments, to handle polysemy. $$$$$ The aim of this paper is to learn inferential selectional preferences for filtering inference rules.

This approach can be seen as a proxy to ISP (Pantel et al, 2007), since selectional preferences are one way of distinguishing multiple senses of a path. $$$$$ Finally, we propose inference filtering algorithms in Section 3.3. cx Resnik (1996) defined the selectional preferences of a predicate as the semantic classes of the words that appear as its arguments.
This approach can be seen as a proxy to ISP (Pantel et al, 2007), since selectional preferences are one way of distinguishing multiple senses of a path. $$$$$ Manual collections of semantic classes include the hierarchies of WordNet (Fellbaum 1998), Levin verb classes (Levin 1993), and FrameNet (Baker et al. 1998).
This approach can be seen as a proxy to ISP (Pantel et al, 2007), since selectional preferences are one way of distinguishing multiple senses of a path. $$$$$ We present empirical evidence to support the following main contribution: Claim: Inferential selectional preferences can be automatically learned and used for effectively filtering out incorrect inferences.
