We use unsupervised methods to build a pipeline that identifies ill-formed English SMS word tokens and builds a dictionary of their most likely normalized forms. $$$$$ While the noisy channel model is appropriate for text normalisation, P(T|S), which encodes the underlying error production process, is hard to approximate accurately.
We use unsupervised methods to build a pipeline that identifies ill-formed English SMS word tokens and builds a dictionary of their most likely normalized forms. $$$$$ Suppose the ill-formed text is T and its corresponding standard form is S, the approach aims to find arg max P(S|T) by computing arg maxP(T|S)P(S), in which P(S) is usually a language model and P (T |S) is an error model.
We use unsupervised methods to build a pipeline that identifies ill-formed English SMS word tokens and builds a dictionary of their most likely normalized forms. $$$$$ hanb@student.unimelb.edu.au tb@ldwin.net Abstract Twitter provides access to large volumes of data in real time, but is notoriously noisy, hampering its utility for NLP.
We use unsupervised methods to build a pipeline that identifies ill-formed English SMS word tokens and builds a dictionary of their most likely normalized forms. $$$$$ Furthermore, we intend to alleviate noisy contexts with a bootstrapping approach, in which ill-formed words with high confidence and no ambiguity will be replaced by their standard forms, and fed into the normalisation model as new training data.

Hanand Baldwin (2011) use a classifier to detect ill formed words, and then generate correction candidates based on morphophonemic similarity. $$$$$ Our ill-formed word detector requires no explicit annotations, and the dependency-based features were shown to be somewhat effective, however, there was still a lot of room for improvement at ill-formed word detection.
Hanand Baldwin (2011) use a classifier to detect ill formed words, and then generate correction candidates based on morphophonemic similarity. $$$$$ For example, Gooood may refer to Good or God depending on context.
Hanand Baldwin (2011) use a classifier to detect ill formed words, and then generate correction candidates based on morphophonemic similarity. $$$$$ These form the positive training exemplars.

w2wN: The output of the word-to-word normalization of Han and Baldwin (2011). $$$$$ We found that only 32.6% ill-formed words have all IV words in their context windows.
w2wN: The output of the word-to-word normalization of Han and Baldwin (2011). $$$$$ Thus, we use a smaller threshold, i.e. td = 1.

5.2.1 Twitter To evaluate the performance on Twitter data, we use the dataset of randomly sampled tweets produced by (Han and Baldwin, 2011). $$$$$ This empirical finding assists in shaping our strategy for lexical normalisation.
5.2.1 Twitter To evaluate the performance on Twitter data, we use the dataset of randomly sampled tweets produced by (Han and Baldwin, 2011). $$$$$ This is arguably the right approach to normalisation, in choosing to under- rather than over-normalise in cases of uncertainty.

We expect that our language model could improve other Social Media tasks, for example lexical normalisation (Han and Baldwin, 2011) or even event detection (Lin et al., 2011). $$$$$ We choose dependencies to represent context because they are an effective way of capturing key relationships between words, and similar features can easily be extracted from tweets.
We expect that our language model could improve other Social Media tasks, for example lexical normalisation (Han and Baldwin, 2011) or even event detection (Lin et al., 2011). $$$$$ This provides the motivation to develop a method which does not require annotated training data, but is able to leverage context for lexical normalisation.
We expect that our language model could improve other Social Media tasks, for example lexical normalisation (Han and Baldwin, 2011) or even event detection (Lin et al., 2011). $$$$$ If all its candidates are predicted to be negative by the model, we mark it as correct; otherwise, we treat it as ill-formed, and pass all candidates (not just positively-classified candidates) on to the candidate selection step.
We expect that our language model could improve other Social Media tasks, for example lexical normalisation (Han and Baldwin, 2011) or even event detection (Lin et al., 2011). $$$$$ Through a pilot study, we compared OOV words in Twitter and SMS data with other domain corpora, revealing their characteristics in OOV word distribution.

Han and Baldwin (2011) use a classifier to detect ill-formed words, and generate correction candidates based on morphophonemic similarity. $$$$$ Our aim in this paper is this task of lexical normalisation of noisy English text, with a particular focus on Twitter and SMS messages.
Han and Baldwin (2011) use a classifier to detect ill-formed words, and generate correction candidates based on morphophonemic similarity. $$$$$ This is arguably the right approach to normalisation, in choosing to under- rather than over-normalise in cases of uncertainty.
Han and Baldwin (2011) use a classifier to detect ill-formed words, and generate correction candidates based on morphophonemic similarity. $$$$$ The final selection is based on the following features, in line with previous work (Wong et al., 2006; Cook and Stevenson, 2009).

Recently, Han and Baldwin (2011) and Gouwsetal2011) propose two-step unsupervised approaches to normalisation, in which lexical variants are first identified, and then normalised. $$$$$ The SMT approach is relatively stable on the two datasets, but well below the performance of our method.
Recently, Han and Baldwin (2011) and Gouwsetal2011) propose two-step unsupervised approaches to normalisation, in which lexical variants are first identified, and then normalised. $$$$$ For example, uz “use” in i did #tt uz me and yu, dependencies can capture relationships like aux(use-4, do-2), which is beyond the capabilities of the language model due to the hashtag being treated as a correct OOV word.
Recently, Han and Baldwin (2011) and Gouwsetal2011) propose two-step unsupervised approaches to normalisation, in which lexical variants are first identified, and then normalised. $$$$$ Manning, 2003; de Marneffe et al., 2006) analyses bout the paper and thinkin movies as a clause and noun phrase, respectively, rather than a prepositional phrase and verb phrase.
Recently, Han and Baldwin (2011) and Gouwsetal2011) propose two-step unsupervised approaches to normalisation, in which lexical variants are first identified, and then normalised. $$$$$ Both word similarity and context are then exploited to select the most probable correction candidate for the word.

They approach lexical variant detection by using a context fitness classifier (Han and Baldwin, 2011) or through dictionary lookup (Gouws et al 2011). $$$$$ Our method uses a classifier to detect ill-formed words, and generates correction candidates based on morphophonemic similarity.
They approach lexical variant detection by using a context fitness classifier (Han and Baldwin, 2011) or through dictionary lookup (Gouws et al 2011). $$$$$ The noisy channel method of Cook and Stevenson (2009) shares similar features with word similarity (“WS”), However, when word similarity and context support are combined (“WS+CS”), our method outperforms the noisy channel method by about 7% and 12% in F-score over SMS and Twitter corpora, respectively.
They approach lexical variant detection by using a context fitness classifier (Han and Baldwin, 2011) or through dictionary lookup (Gouws et al 2011). $$$$$ The prefix and suffix features are intended to capture the fact that leading and trailing characters are frequently dropped from words, e.g. in cases such as ish and talkin.
They approach lexical variant detection by using a context fitness classifier (Han and Baldwin, 2011) or through dictionary lookup (Gouws et al 2011). $$$$$ Thus, we use a smaller threshold, i.e. td = 1.

In contrast to the normalisation dictionaries of Han and Baldwin (2011) and Gouws et al 2011) which focus on very frequent lexical variants, we focus on moderate frequency lexical variants of a minimum character length, which tend to have unambiguous standard forms; our intention is to produce normalisation lexicons that are complementary to those currently available. $$$$$ We also consider that deabbreviation largely falls outside the scope of text normalisation, as abbreviations can be formed freely in standard English.
In contrast to the normalisation dictionaries of Han and Baldwin (2011) and Gouws et al 2011) which focus on very frequent lexical variants, we focus on moderate frequency lexical variants of a minimum character length, which tend to have unambiguous standard forms; our intention is to produce normalisation lexicons that are complementary to those currently available. $$$$$ First, we plan to improve our ill-formed word detection classifier by introducing an OOV word whitelist.
In contrast to the normalisation dictionaries of Han and Baldwin (2011) and Gouws et al 2011) which focus on very frequent lexical variants, we focus on moderate frequency lexical variants of a minimum character length, which tend to have unambiguous standard forms; our intention is to produce normalisation lexicons that are complementary to those currently available. $$$$$ Furthermore, we intend to alleviate noisy contexts with a bootstrapping approach, in which ill-formed words with high confidence and no ambiguity will be replaced by their standard forms, and fed into the normalisation model as new training data.

To further narrow the search space, we only consider IV words which are morphophonemic ally similar to the OOV type, following settings in Han and Baldwin (2011). $$$$$ Our method uses a classifier to detect ill-formed words, and generates correction candidates based on morphophonemic similarity.
To further narrow the search space, we only consider IV words which are morphophonemic ally similar to the OOV type, following settings in Han and Baldwin (2011). $$$$$ We found that most illformed words are based on morphophonemic variation and proposed a cascaded method to detect and normalise ill-formed words.
To further narrow the search space, we only consider IV words which are morphophonemic ally similar to the OOV type, following settings in Han and Baldwin (2011). $$$$$ We found Twitter data to have an unsurprisingly long tail of OOV words, suggesting that conventional supervised learning will not perform well due to data sparsity.
To further narrow the search space, we only consider IV words which are morphophonemic ally similar to the OOV type, following settings in Han and Baldwin (2011). $$$$$ This provides the motivation to develop a method which does not require annotated training data, but is able to leverage context for lexical normalisation.

Given the re-ranked pairs from Section 5, here we apply them to a token-level normalisation task using the normalisation dataset of Han and Baldwin (2011). $$$$$ Manual analysis of the two sets revealed that most OOV words found only in SMS were personal names.
Given the re-ranked pairs from Section 5, here we apply them to a token-level normalisation task using the normalisation dataset of Han and Baldwin (2011). $$$$$ In future work, we propose to pursue a number of directions.
Given the re-ranked pairs from Section 5, here we apply them to a token-level normalisation task using the normalisation dataset of Han and Baldwin (2011). $$$$$ First, we plan to improve our ill-formed word detection classifier by introducing an OOV word whitelist.
Given the re-ranked pairs from Section 5, here we apply them to a token-level normalisation task using the normalisation dataset of Han and Baldwin (2011). $$$$$ Typos, ad hoc abbreviations, phonetic substitutions, ungrammatical structures and emoticons abound in short text messages, causing grief for text processing tools (Sproat et al., 2001; Ritter et al., 2010).

In addition, the contribution of these dictionaries in hybrid normalisation approaches is also presented, in which we first normalise OOVs using a given dictionary (combined or otherwise), and then apply the normalisation method of Gouws et al2011) based on consonant edit distance (GHM-norm), or the approach of Han and Baldwin (2011) based on the summation of many unsupervised approaches (HB-norm), to the remaining OOVs. $$$$$ We found that most illformed words are based on morphophonemic variation and proposed a cascaded method to detect and normalise ill-formed words.
In addition, the contribution of these dictionaries in hybrid normalisation approaches is also presented, in which we first normalise OOVs using a given dictionary (combined or otherwise), and then apply the normalisation method of Gouws et al2011) based on consonant edit distance (GHM-norm), or the approach of Han and Baldwin (2011) based on the summation of many unsupervised approaches (HB-norm), to the remaining OOVs. $$$$$ Predominantly, however, these methods require large-scale annotated training data, limiting their adaptability to new domains or languages.
In addition, the contribution of these dictionaries in hybrid normalisation approaches is also presented, in which we first normalise OOVs using a given dictionary (combined or otherwise), and then apply the normalisation method of Gouws et al2011) based on consonant edit distance (GHM-norm), or the approach of Han and Baldwin (2011) based on the summation of many unsupervised approaches (HB-norm), to the remaining OOVs. $$$$$ In future work, we propose to pursue a number of directions.
In addition, the contribution of these dictionaries in hybrid normalisation approaches is also presented, in which we first normalise OOVs using a given dictionary (combined or otherwise), and then apply the normalisation method of Gouws et al2011) based on consonant edit distance (GHM-norm), or the approach of Han and Baldwin (2011) based on the summation of many unsupervised approaches (HB-norm), to the remaining OOVs. $$$$$ This has implications for any context modelling, as we cannot rely on having only isolated occurrences of OOV words.

the Internet slang dictionary (HB-dict) from Han and Baldwin (2011), and combinations of these dictionaries. $$$$$ Our method uses a classifier to detect ill-formed words, and generates correction candidates based on morphophonemic similarity.
the Internet slang dictionary (HB-dict) from Han and Baldwin (2011), and combinations of these dictionaries. $$$$$ Additionally, these methods make the strong assumption that a token tz E T only depends on sz E S, ignoring the context around the token, which could be utilised to help in resolving ambiguity.
the Internet slang dictionary (HB-dict) from Han and Baldwin (2011), and combinations of these dictionaries. $$$$$ For instance, presented with the input u must be talkin bout the paper but I was thinkin movies (“You must be talking about the paper but I was thinking movies”),' the Stanford parser (Klein and 'Throughout the paper, we will provide a normalised version of examples as a gloss in double quotes.

In addition, we combine the dictionaries with the normalisation method of Gouws et al2011) (GHM-norm) and the combined unsupervised approach of Han and Baldwin (2011) (HB-norm). $$$$$ hanb@student.unimelb.edu.au tb@ldwin.net Abstract Twitter provides access to large volumes of data in real time, but is notoriously noisy, hampering its utility for NLP.

6.2.3 Hybrid Approaches The methods of Gouws et al2011) (i.e. GHM-dict+GHM-norm) and Han and Baldwin (2011) (i.e. HB-dict+HB-norm) have lower precision and higher false alarm rates than the dictionary based approaches; this is largely caused by lexical variant detection errors. $$$$$ The next step is to detect whether a given OOV word in context is actually an ill-formed word or not, relative to its confusion set.
6.2.3 Hybrid Approaches The methods of Gouws et al2011) (i.e. GHM-dict+GHM-norm) and Han and Baldwin (2011) (i.e. HB-dict+HB-norm) have lower precision and higher false alarm rates than the dictionary based approaches; this is largely caused by lexical variant detection errors. $$$$$ In confusion set generation, we generate a set of IV normalisation candidates for each OOV word type based on morphophonemic variation.

The present lexical normalisation used by our system is the dictionary lookup method of Hanand Baldwin (2011) which normalises noisy tokens only when the normalised form is known with high confidence (e.g. you for u). $$$$$ We found that most illformed words are based on morphophonemic variation and proposed a cascaded method to detect and normalise ill-formed words.
The present lexical normalisation used by our system is the dictionary lookup method of Hanand Baldwin (2011) which normalises noisy tokens only when the normalised form is known with high confidence (e.g. you for u). $$$$$ It builds on the work on SMS text normalisation, and adapts it to Twitter data, exploiting multiple data sources for normalisation.
The present lexical normalisation used by our system is the dictionary lookup method of Hanand Baldwin (2011) which normalises noisy tokens only when the normalised form is known with high confidence (e.g. you for u). $$$$$ Toutanova and Moore (2002) improve the model by incorporating pronunciation information.

Ultimately, however, we are interested in performing context sensitive lexical normalisation, based on a reimplementation of the method of Han and Baldwin (2011). $$$$$ We found that most illformed words are based on morphophonemic variation and proposed a cascaded method to detect and normalise ill-formed words.
Ultimately, however, we are interested in performing context sensitive lexical normalisation, based on a reimplementation of the method of Han and Baldwin (2011). $$$$$ Note that increasing the edit distance further in both cases leads to an explosion in the average number of candidates, with serious computational implications for downstream processing.
Ultimately, however, we are interested in performing context sensitive lexical normalisation, based on a reimplementation of the method of Han and Baldwin (2011). $$$$$ SMT approaches tend to suffer from a critical lack of training data, however.

(Hanand Baldwin, 2011) reported an average of 127 candidates per nonstandard token with the correct-word coverage of 84%. $$$$$ We found that most illformed words are based on morphophonemic variation and proposed a cascaded method to detect and normalise ill-formed words.
(Hanand Baldwin, 2011) reported an average of 127 candidates per nonstandard token with the correct-word coverage of 84%. $$$$$ Cook and Stevenson (2009) expand the error model by introducing inference from different erroneous formation processes, according to the sampled error distribution.
(Hanand Baldwin, 2011) reported an average of 127 candidates per nonstandard token with the correct-word coverage of 84%. $$$$$ Furthermore, we intend to alleviate noisy contexts with a bootstrapping approach, in which ill-formed words with high confidence and no ambiguity will be replaced by their standard forms, and fed into the normalisation model as new training data.
(Hanand Baldwin, 2011) reported an average of 127 candidates per nonstandard token with the correct-word coverage of 84%. $$$$$ If we truncate the ranking to the top 10% of candidates, the recall drops back to 84% with a 90% reduction in candidates.

(Han and Baldwin, 2011) developed classifiers for detecting the ill-formed word sand generated corrections based on the morphophonemic similarity. $$$$$ The OOV word definition is somewhat rough, because it includes neologisms and proper nouns like hopeable or WikiLeaks which have not made their way into the dictionary.
(Han and Baldwin, 2011) developed classifiers for detecting the ill-formed word sand generated corrections based on the morphophonemic similarity. $$$$$ From Table 1, it is clear that “Letter” accounts for the majority of ill-formed words in Twitter, and that most ill-formed words are based on morphophonemic variations.
(Han and Baldwin, 2011) developed classifiers for detecting the ill-formed word sand generated corrections based on the morphophonemic similarity. $$$$$ Furthermore, we intend to alleviate noisy contexts with a bootstrapping approach, in which ill-formed words with high confidence and no ambiguity will be replaced by their standard forms, and fed into the normalisation model as new training data.
(Han and Baldwin, 2011) developed classifiers for detecting the ill-formed word sand generated corrections based on the morphophonemic similarity. $$$$$ The dictionary lookup method (“DL”) unsurprisingly achieves the best precision, but the recall on Twitter is not competitive.

 $$$$$ Thankfully, T, < 2 V Tp < 1 leads to an extra increment in recall to 88.8%, with only a slight increase in the average number of candidates.
 $$$$$ Note that single-word abbreviations such as govt “government” are very much within the scope of lexical normalisation, as they are OOV and match to a single token in their standard lexical form.
 $$$$$ Both word similarity and context are then exploited to select the most probable correction candidate for the word.
 $$$$$ The proposed method doesn’t require any annotations, and achieves state-of-the-art performance over an SMS corpus and a novel dataset based on Twitter.
