It is possible to obtain a polynomial parser provided that we limit the number of nodes simultaneously involved in non-projective configurations (see Kahane et al 1998 for similar techniques). $$$$$ We initialize the parse matrix as follows.
It is possible to obtain a polynomial parser provided that we limit the number of nodes simultaneously involved in non-projective configurations (see Kahane et al 1998 for similar techniques). $$$$$ This procedure determines a new multiset LM so we can add entry (in, q, LM) in the parse matrix.
It is possible to obtain a polynomial parser provided that we limit the number of nodes simultaneously involved in non-projective configurations (see Kahane et al 1998 for similar techniques). $$$$$ A tree T is projective if and only if every arc of T is projective A projective tree has been represented in Figure 1.

This formalism is based on previous work presented in (Kahane et al, 1998), which has been substantially reformulated in order to simplify it. $$$$$ The lifting conditions contained in the lift multiset of all the newly introduced dependents D should be compatible with D, with the dot advanced appropriately.
This formalism is based on previous work presented in (Kahane et al, 1998), which has been substantially reformulated in order to simplify it. $$$$$ 'We can use pre-computed top-down prediction to limit the number of pairs added. governor, which must be an ancestor of the governor.
This formalism is based on previous work presented in (Kahane et al, 1998), which has been substantially reformulated in order to simplify it. $$$$$ The left-hand side nonterminal is the same as that we want to rewrite.

We will extend our basic approach in the spirit of (Kahane et al, 1998) in future work. $$$$$ In this paper, we present a form of projectivity which we call pseudoprojectivity, and we present a generative stringrewriting formalism that can generate pseudoprojective analyses and which is polynomially parsable.
We will extend our basic approach in the spirit of (Kahane et al, 1998) in future work. $$$$$ One problem that has posed an impediment to more wide-spread acceptance of dependency grammars is the fact that there is no computationally tractable version of dependency grammar which is not restricted to projective analyses.
We will extend our basic approach in the spirit of (Kahane et al, 1998) in future work. $$$$$ The rewriting operation then must meet the following three conditions: As an example, consider a grammar containing the three dependency rules di (rule 2), d2 (rule 3), and d3 (rule 4), as well as the LP rule pi (rule 5).

Kahane et al (1998) present three different types of rules, for sub categorization, modification, and linear precedence. $$$$$ We can extend the bottom-up parser for GDG to a parser for PP-GDG in the following manner.
Kahane et al (1998) present three different types of rules, for sub categorization, modification, and linear precedence. $$$$$ We informally present a parser in Section 5.
Kahane et al (1998) present three different types of rules, for sub categorization, modification, and linear precedence. $$$$$ Let us consider an example.

It is also related to the lifting rules of (Kahane et al, 1998), but where they choose to stipulate rules that license liftings, we opt instead for placing constraints on otherwise unrestricted climbing. $$$$$ When we have reached a final state q of the rule-FSM m, we have recognized a complete subtree rooted in the new governor, 7/.
It is also related to the lifting rules of (Kahane et al, 1998), but where they choose to stipulate rules that license liftings, we opt instead for placing constraints on otherwise unrestricted climbing. $$$$$ This transition is called the &quot;head transition&quot;.

The pseudo-projective grammar proposed by Kahane et al (1998) can be parsed in polynomial time and captures non-local dependencies through a form of gap-threading, but the structures generated by the grammar are strictly projective. $$$$$ The entries in the parse matrix M are of the form (in, q), where in is a rule-FSM and q a state of it, except for the entries in squares M(i, i), 1 < j< n, which also contain category labels.
The pseudo-projective grammar proposed by Kahane et al (1998) can be parsed in polynomial time and captures non-local dependencies through a form of gap-threading, but the structures generated by the grammar are strictly projective. $$$$$ The domain of locality of the linear order rules is therefore limited to a subtree of depth equal to one.
The pseudo-projective grammar proposed by Kahane et al (1998) can be parsed in polynomial time and captures non-local dependencies through a form of gap-threading, but the structures generated by the grammar are strictly projective. $$$$$ There is a special case for the head transitions in mi: if k = i â€” 1, C is in M(i, i), mi is a Crule-FSM, and there is a head transition from qi to q in ml, then we add (mi, q) to M(i, j).

With this conversion technique, output dependency trees are necessarily projective, and extracted dependencies are necessarily local to a phrase, which means that the automatically converted trees can be regarded as pseudo-projective approximations to the correct dependency trees (Kahane et al, 1998). $$$$$ Note that the exponent is a grammar constant, but this number can be rather small since the lifting rules are not lexicalized - they are construction-specific, not lexemespecific.
With this conversion technique, output dependency trees are necessarily projective, and extracted dependencies are necessarily local to a phrase, which means that the automatically converted trees can be regarded as pseudo-projective approximations to the correct dependency trees (Kahane et al, 1998). $$$$$ Finally, if 1 is an arc of an ordered tree T, then Supp(1) represents the support of 1, i.e. the set of the nodes of T situated between the extremities of 1, extremities included.
With this conversion technique, output dependency trees are necessarily projective, and extracted dependencies are necessarily local to a phrase, which means that the automatically converted trees can be regarded as pseudo-projective approximations to the correct dependency trees (Kahane et al, 1998). $$$$$ In a rewrite step, we choose a multiset of dependency rules (i.e., a set of instances of dependency rules) which contains exactly one srule and zero or more m-rules.

This concept was introduced as lifting in (Kahane et al, 1998). $$$$$ Dependency grammar has a long tradition in syntactic theory, dating back to at least Tesniere's work from the thirties.'

based: for example, those described by Lombardoand Lesmo (1996), Barbero et al (1998) and Kahane et al (1998) are tied to the formalizations of dependency grammar using context-free like rules described by Hays (1964) and Gaifman (1965). $$$$$ (In fact, it may determine several possible new multisets, resulting in multiple new entries.)
based: for example, those described by Lombardoand Lesmo (1996), Barbero et al (1998) and Kahane et al (1998) are tied to the formalizations of dependency grammar using context-free like rules described by Hays (1964) and Gaifman (1965). $$$$$ We use the hash sign (#) to denote the position of the governor (head).

However, predictive grammar-based algorithms such as those of Lombardo and Lesmo (1996) and Kahane et al (1998) have operations which postulate rules and can not be defined in terms of dependency graphs, since they do not do any modifications to the graph. $$$$$ Dependency grammar has a long tradition in syntactic theory, dating back to at least Tesniere's work from the thirties.'
However, predictive grammar-based algorithms such as those of Lombardo and Lesmo (1996) and Kahane et al (1998) have operations which postulate rules and can not be defined in terms of dependency graphs, since they do not do any modifications to the graph. $$$$$ The new entry will be (m, q', LMULM ) (where q is the state that m transitions to when n' is recognized as the next linear dependent.
However, predictive grammar-based algorithms such as those of Lombardo and Lesmo (1996) and Kahane et al (1998) have operations which postulate rules and can not be defined in terms of dependency graphs, since they do not do any modifications to the graph. $$$$$ Recently, it has gained renewed attention as empirical methods in parsing are discovering the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly do, but context-free phrasestructure grammars do not.
However, predictive grammar-based algorithms such as those of Lombardo and Lesmo (1996) and Kahane et al (1998) have operations which postulate rules and can not be defined in terms of dependency graphs, since they do not do any modifications to the graph. $$$$$ The following definitions make sense only for trees whose nodes are labeled with categories.'

In addition, the work of Kahane et al (1998) provides a polynomial parsing algorithm for a constrained class of non projective structures. $$$$$ The regular expression representing the lifting condition is enriched with a dot separating, on its left, the part of the lifting path which has already been introduced during the rewriting and on its right the part which is still to be introduced for the rewriting to be valid.
In addition, the work of Kahane et al (1998) provides a polynomial parsing algorithm for a constrained class of non projective structures. $$$$$ In this paper, we present a form of projectivity which we call pseudoprojectivity, and we present a generative stringrewriting formalism that can generate pseudoprojective analyses and which is polynomially parsable.
In addition, the work of Kahane et al (1998) provides a polynomial parsing algorithm for a constrained class of non projective structures. $$$$$ When applied to a tree, this operation leads to the creation of a second tree, a lift of the first one.
In addition, the work of Kahane et al (1998) provides a polynomial parsing algorithm for a constrained class of non projective structures. $$$$$ However, it is well known that there are some syntactic phenomena (such as wh-movement in English or clitic climbing in Romance) that require nonprojective analyses.

The definition of non-projectivity can be found in Kahane et al (1998). $$$$$ The projection of a node x, belonging to a tree T, is the set of the nodes y of T such that y x.

 $$$$$ In a rewrite step, we choose a multiset of dependency rules (i.e., a set of instances of dependency rules) which contains exactly one srule and zero or more m-rules.
 $$$$$ An arc between two nodes y and x of a tree T, directed from y to x will be noted either (y, x) or The node x will be referred to as the dependent and y as the governor.

First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al, 1998) and encoding information about these lifts in arc labels. $$$$$ However, it is well known that there are some syntactic phenomena (such as wh-movement in English or clitic climbing in Romance) that require nonprojective analyses.
First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al, 1998) and encoding information about these lifts in arc labels. $$$$$ The time complexity of the algorithm is 0(n3IGIQmax), where G is the number of ruleFSMs derived from the dependency and LP rules in the grammar and Qmax is the maximum number of states in any of the rule-FSMs.
First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al, 1998) and encoding information about these lifts in arc labels. $$$$$ We start our derivation with the start symbol Klause and rewrite it using dependency rules d2 and d3, and the lifting rule /1 which introduces an objective NP argument.
First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al, 1998) and encoding information about these lifts in arc labels. $$$$$ We can extend the bottom-up parser for GDG to a parser for PP-GDG in the following manner.

We call this pseudo projective dependency parsing, since it is based on a notion of pseudo-projectivity (Kahane et al, 1998). $$$$$ Dependency grammar has a long tradition in syntactic theory, dating back to at least Tesniere's work from the thirties.'
We call this pseudo projective dependency parsing, since it is based on a notion of pseudo-projectivity (Kahane et al, 1998). $$$$$ As we traverse the Crule-FSM m, we recognize one by one the linear dependents of a node of category C. Call this governor n. The action of adding a new entry to the parse matrix corresponds to adding a single new linear dependent to n. (While we are working on the C-rule-FSM 771 and are not yet in a final state, we have not yet recognized n itself.)
We call this pseudo projective dependency parsing, since it is based on a notion of pseudo-projectivity (Kahane et al, 1998). $$$$$ Then, we add to M(i, i) every pair (7n, q) such that m is a rule-FSM with a transition labeled C from a start state and q the state reached after that transition.6 Embedded in the usual three loops on i, j, k, we add an entry (mi, q) to M(i, j) if (m1, qi) is in M (k, j), (m2, q2) is in M (i, k+1), q2 is a final state of m2, m2 is a C-rule-FSM, and mi transitions from qi to q on C (a non-head transition).
We call this pseudo projective dependency parsing, since it is based on a notion of pseudo-projectivity (Kahane et al, 1998). $$$$$ In the rewriting operation, we introduce a multiset of new nonterminals and exactly one terminal symbol (the head).

The dependency graph in Figure 1 satisfies all the defining conditions above, but it fails to satisfy the condition of projectivity (Kahane et al, 1998). $$$$$ For every syntactic dependent of rh we determine if it is a linear dependent of n which has not yet been identified as lifted.
The dependency graph in Figure 1 satisfies all the defining conditions above, but it fails to satisfy the condition of projectivity (Kahane et al, 1998). $$$$$ See for example (Lombardi, 1996; Eisner, 1996), who also discuss Early-style parsers for projective dependency grammars.

Using the terminology of Kahane et al (1998), we say that jedna is the syntactic head of Z, while je is its linear head in the projectivized representation. $$$$$ We briefly review a previously proposed formalization of projective dependency grammars in Section 3.
Using the terminology of Kahane et al (1998), we say that jedna is the syntactic head of Z, while je is its linear head in the projectivized representation. $$$$$ The dependency rules are further subdivided into subcategorization rules (or s-rules) and modification rules (or m-rules).
Using the terminology of Kahane et al (1998), we say that jedna is the syntactic head of Z, while je is its linear head in the projectivized representation. $$$$$ This condition is represented in the rule by means of a constraint on the categories found along the lifting path.

Unlike Kahane et al (1998), we do not regard a projectivized representation as the final target of the parsing process. $$$$$ An arc between two nodes y and x of a tree T, directed from y to x will be noted either (y, x) or The node x will be referred to as the dependent and y as the governor.
Unlike Kahane et al (1998), we do not regard a projectivized representation as the final target of the parsing process. $$$$$ The hierarchical order (dominance) between the nodes of a tree T will be represented with the symbol -<T and Whenever they are unambiguous, the notations -< and -â€¹ will be used.
