Wilson et al (2005) proposed supervised learning, dividing the resources into prior polarity and context polarity, which are similar to polar atoms and syntactic patterns in this paper, respectively. $$$$$ This paper presents a new approach to phrase-level sentiment analysis that firstdetermines whether an expression is neu tral or polar and then disambiguates the polarity of the polar expressions.
Wilson et al (2005) proposed supervised learning, dividing the resources into prior polarity and context polarity, which are similar to polar atoms and syntactic patterns in this paper, respectively. $$$$$ These patterns are high-quality, yielding quite highprecision, but very low recall.

For example, AbuJbara et al (2013) and Jochim and Schutze (2012) find the list of polar words from Wilson et al (2005) to be useful, and neither study lists dependency relations as significant features. $$$$$ With this approach, we are able to automatically identify the contextual polarity for a large subset ofsentiment expressions, achieving results that are sig nificantly better than baseline.
For example, AbuJbara et al (2013) and Jochim and Schutze (2012) find the list of polar words from Wilson et al (2005) to be useful, and neither study lists dependency relations as significant features. $$$$$ Ofthe 4,247 sentences containing two or more subjec tive expressions, 17% contain mixtures of positive and negative expressions, and 62% contain mixturesof polar (positive/negative/both) and neutral subjec tive expressions.

In addition, we used subjectivity clues extracted from the lexicon by Wilson et al (2005). $$$$$ In the MPQA Cor pus, subjective expressions of varying lengths are marked, from single words to long phrases.For this work, our focus is on sentiment expressions ? positive and negative expressions of emo tions, evaluations, and stances.
In addition, we used subjectivity clues extracted from the lexicon by Wilson et al (2005). $$$$$ This paper presents a new approach to phrase-level sentiment analysis that firstdetermines whether an expression is neu tral or polar and then disambiguates the polarity of the polar expressions.
In addition, we used subjectivity clues extracted from the lexicon by Wilson et al (2005). $$$$$ Most work on sentiment analysis has been done atthe document level, for example distinguishing pos itive from negative reviews.
In addition, we used subjectivity clues extracted from the lexicon by Wilson et al (2005). $$$$$ and conj polarity is negative for the word ?good.?

Wilson et al (2005) present a two-step process to recognize contextual polarity that employs machine learning and a variety of features. $$$$$ Words that are subjective in most contexts were marked strongly subjective (strongsubj), and those that may only have certain subjective usages were marked weakly subjective (weaksubj).
Wilson et al (2005) present a two-step process to recognize contextual polarity that employs machine learning and a variety of features. $$$$$ falls within thisproposition, its contextual polarity becomes nega tive.
Wilson et al (2005) present a two-step process to recognize contextual polarity that employs machine learning and a variety of features. $$$$$ They clas sify expressions that are about specific items, and use manually developed patterns to classify polarity.

Some lexicons assign real number scores to indicate sentiment orientations and strengths (i.e. probabilities of having positive and negative sentiments) (Esuli and Sebastiani, 2006) while other lexicons assign discrete classes (weak/strong, positive/negative) (Wilson et al, 2005). $$$$$ To compile the lexicon, we began with a list of subjectivity clues from (Riloff and Wiebe, 2003).
Some lexicons assign real number scores to indicate sentiment orientations and strengths (i.e. probabilities of having positive and negative sentiments) (Esuli and Sebastiani, 2006) while other lexicons assign discrete classes (weak/strong, positive/negative) (Wilson et al, 2005). $$$$$ We define the gold standard used to train and test the system in terms of the manual annotations described in Section 2.
Some lexicons assign real number scores to indicate sentiment orientations and strengths (i.e. probabilities of having positive and negative sentiments) (Esuli and Sebastiani, 2006) while other lexicons assign discrete classes (weak/strong, positive/negative) (Wilson et al, 2005). $$$$$ Simi larly for ?polluters?: in the context of the article, it simply refers to companies that pollute.

 $$$$$ The in subject feature is true if we find a subj relationship.
 $$$$$ A subjective expression is any word or phrase used to express an opinion, emotion, evaluation, stance, speculation, 1The MPQA Corpus is described in (Wiebe et al, 2005) and available at nrrc.mitre.org/NRRC/publications.htm.
 $$$$$ The first line in Table 5 lists the results forthe classifier that uses just one feature, the word token.
 $$$$$ In contrast, our ex periments classify individual words and phrases.

Further, there are analyses (Wiebe et al, 2005) and experiments (Wilson et al, 2005) that indicate that lexicon-lookup approaches to subjectivity analysis will have limited success on general texts. $$$$$ With thisapproach, the system is able to automat ically identify the contextual polarity for a large subset of sentiment expressions,achieving results that are significantly bet ter than baseline.
Further, there are analyses (Wiebe et al, 2005) and experiments (Wilson et al, 2005) that indicate that lexicon-lookup approaches to subjectivity analysis will have limited success on general texts. $$$$$ judgments.
Further, there are analyses (Wiebe et al, 2005) and experiments (Wilson et al, 2005) that indicate that lexicon-lookup approaches to subjectivity analysis will have limited success on general texts. $$$$$ The first (66 documents/1,373 sentences/2,808 subjective expressions) is a development set, used for data exploration and feature development.
Further, there are analyses (Wiebe et al, 2005) and experiments (Wilson et al, 2005) that indicate that lexicon-lookup approaches to subjectivity analysis will have limited success on general texts. $$$$$ In this paper, we present a new approach to phrase-level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions.

The former were based on the General Inquirer lexicon (Wilson et al, 2005), the MontyLingua part-of-speech tagger (Liu, 2004) and co-occurrence statistics of words with a set of predefined reference words. $$$$$ This paper presents a new approach to phrase-level sentiment analysis that firstdetermines whether an expression is neu tral or polar and then disambiguates the polarity of the polar expressions.
The former were based on the General Inquirer lexicon (Wilson et al, 2005), the MontyLingua part-of-speech tagger (Liu, 2004) and co-occurrence statistics of words with a set of predefined reference words. $$$$$ Words that are subjective in most contexts were marked strongly subjective (strongsubj), and those that may only have certain subjective usages were marked weakly subjective (weaksubj).
The former were based on the General Inquirer lexicon (Wilson et al, 2005), the MontyLingua part-of-speech tagger (Liu, 2004) and co-occurrence statistics of words with a set of predefined reference words. $$$$$ Ofthe 4,247 sentences containing two or more subjec tive expressions, 17% contain mixtures of positive and negative expressions, and 62% contain mixturesof polar (positive/negative/both) and neutral subjec tive expressions.

More specifically, we use the terms in the lexicon constructed from (Wilson et al, 2005) as the indicators to identify the substructures for the convolution kernels, and extract different sub-structures according to these indicators for various types of parse trees (Section 3). $$$$$ Only a small number of clues (0.3%) are marked as having both positive and negative polarity.
More specifically, we use the terms in the lexicon constructed from (Wilson et al, 2005) as the indicators to identify the substructures for the convolution kernels, and extract different sub-structures according to these indicators for various types of parse trees (Section 3). $$$$$ Weuse the second set (359 documents/7,611 sen tences/13,183 subjective expressions) in 10-fold cross-validation experiments, described below.
More specifically, we use the terms in the lexicon constructed from (Wilson et al, 2005) as the indicators to identify the substructures for the convolution kernels, and extract different sub-structures according to these indicators for various types of parse trees (Section 3). $$$$$ In particular, we developed an annotationscheme3 for marking the contextual polarity of sub jective expressions.
More specifically, we use the terms in the lexicon constructed from (Wilson et al, 2005) as the indicators to identify the substructures for the convolution kernels, and extract different sub-structures according to these indicators for various types of parse trees (Section 3). $$$$$ Examples of these are verbs such as feel, look, and think, and intensifiers such asdeeply, entirely, and practically.

To solve this problem, we define the indicators in this task as subjective words in a polarity lexicon (Wilson et al, 2005). $$$$$ A subjective expression is any word or phrase used to express an opinion, emotion, evaluation, stance, speculation, 1The MPQA Corpus is described in (Wiebe et al, 2005) and available at nrrc.mitre.org/NRRC/publications.htm.
To solve this problem, we define the indicators in this task as subjective words in a polarity lexicon (Wilson et al, 2005). $$$$$ 6.3 Contextual Polarity Disambiguation.
To solve this problem, we define the indicators in this task as subjective words in a polarity lexicon (Wilson et al, 2005). $$$$$ In total, 15,991 subjective expressions from 425 documents (8,984 sentences) were annotated withcontextual polarity as described above.
To solve this problem, we define the indicators in this task as subjective words in a polarity lexicon (Wilson et al, 2005). $$$$$ Words that are subjective in most contexts were marked strongly subjective (strongsubj), and those that may only have certain subjective usages were marked weakly subjective (weaksubj).

We use a manually constructed polarity lexicon (Wilson et al, 2005), in which each entry is annotated with its degree of subjectivity (strong, weak), as well as its sentiment polarity (positive, negative and neutral). $$$$$ In total, 15,991 subjective expressions from 425 documents (8,984 sentences) were annotated withcontextual polarity as described above.
We use a manually constructed polarity lexicon (Wilson et al, 2005), in which each entry is annotated with its degree of subjectivity (strong, weak), as well as its sentiment polarity (positive, negative and neutral). $$$$$ As these are types of subjective expressions, to create the corpus, we just needed to manually annotate the existing subjective expressions with their contextual polarity.
We use a manually constructed polarity lexicon (Wilson et al, 2005), in which each entry is annotated with its degree of subjectivity (strong, weak), as well as its sentiment polarity (positive, negative and neutral). $$$$$ (6) The criteria set by Rice are the following: thethree countries in question are repressive (nega tive) and grave human rights violators (negative) . . .

 $$$$$ Overall agreement is 82%, with a Kappa (?)
 $$$$$ Thus, the subjective expression, they have not succeeded, and 3The annotation instructions are available at http://www.cs.pitt.edu/?twilson.
 $$$$$ The first step classifies each phrase containing a clue as neutral or polar.

PRIOR-POLARITY & PRIOR-INTENSITY $$$$$ (7) Besides, politicians refer to good and evil (both) only for purposes of intimidation and exaggeration.(8) Jerome says the hospital feels (neutral) no dif ferent than a hospital in the states.The annotators were asked to judge the contextual polarity of the sentiment that is ultimately be ing conveyed by the subjective expression, i.e., once the sentence has been fully interpreted.
PRIOR-POLARITY & PRIOR-INTENSITY $$$$$ The word ?Trust?

 $$$$$ To compile the lexicon, we began with a list of subjectivity clues from (Riloff and Wiebe, 2003).
 $$$$$ By far, the majority of clues, 92.8%, aremarked as having either positive (33.1%) or nega tive (59.7%) prior polarity.
 $$$$$ Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al.

Polar word Count (PC) Number of words that are polar (strong subjective words from the lexicon (Wilson et al, 2005)). $$$$$ With thisapproach, the system is able to automat ically identify the contextual polarity for a large subset of sentiment expressions,achieving results that are significantly bet ter than baseline.
Polar word Count (PC) Number of words that are polar (strong subjective words from the lexicon (Wilson et al, 2005)). $$$$$ With this approach, we are able to automatically identify the contextual polarity for a large subset ofsentiment expressions, achieving results that are sig nificantly better than baseline.
Polar word Count (PC) Number of words that are polar (strong subjective words from the lexicon (Wilson et al, 2005)). $$$$$ In contrast, our ex periments classify individual words and phrases.

We also used two datasets for the evaluation purpose $$$$$ The 10 documents contain 447 subjective expressions.
We also used two datasets for the evaluation purpose $$$$$ This paper presents a new approach to phrase-level sentiment analysis that firstdetermines whether an expression is neu tral or polar and then disambiguates the polarity of the polar expressions.
We also used two datasets for the evaluation purpose $$$$$ The first (66 documents/1,373 sentences/2,808 subjective expressions) is a development set, used for data exploration and feature development.

In this work we use MPQA (Wilson et al, 2005). $$$$$ This paper presents a new approach to phrase-level sentiment analysis that firstdetermines whether an expression is neu tral or polar and then disambiguates the polarity of the polar expressions.
In this work we use MPQA (Wilson et al, 2005). $$$$$ With thisapproach, the system is able to automat ically identify the contextual polarity for a large subset of sentiment expressions,achieving results that are significantly bet ter than baseline.
In this work we use MPQA (Wilson et al, 2005). $$$$$ judgments.

The MPQA lexicon contains separate lexicons for subjectivity clues, intensifiers and valence shifters (Wilson et al, 2005), which are used for identifying opinion roots, modifiers and negation words. $$$$$ In total, 15,991 subjective expressions from 425 documents (8,984 sentences) were annotated withcontextual polarity as described above.
The MPQA lexicon contains separate lexicons for subjectivity clues, intensifiers and valence shifters (Wilson et al, 2005), which are used for identifying opinion roots, modifiers and negation words. $$$$$ The first four involve relationships with the word immediately before or after: if theword is a noun preceded by an adjective, if the preceding word is an adverb other than not, if the pre ceding word is an intensifier, and if the word itself is an intensifier.
The MPQA lexicon contains separate lexicons for subjectivity clues, intensifiers and valence shifters (Wilson et al, 2005), which are used for identifying opinion roots, modifiers and negation words. $$$$$ In total, 15,991 subjective expressions from 425 documents (8,984 sentences) were annotated withcontextual polarity as described above.
The MPQA lexicon contains separate lexicons for subjectivity clues, intensifiers and valence shifters (Wilson et al, 2005), which are used for identifying opinion roots, modifiers and negation words. $$$$$ This paper presents a new approach to phrase-level sentiment analysis that firstdetermines whether an expression is neu tral or polar and then disambiguates the polarity of the polar expressions.

They use the Opinion Finder lexicon (Wilson et al, 2005) and two bilingual English-Romanian dictionaries to translate the words in the lexicon. $$$$$ To make the relationship between that task and ours clearer, note that some word lists used to evaluate methods for recognizing prior polarity areincluded in our prior-polarity lexicon (General Inquirer lists (General-Inquirer, 2000) used for evaluation by Turney, and lists of manually identified pos itive and negative adjectives, used for evaluation by Hatzivassiloglou and McKeown).Some research classifies the sentiments of sen tences.
They use the Opinion Finder lexicon (Wilson et al, 2005) and two bilingual English-Romanian dictionaries to translate the words in the lexicon. $$$$$ Focusing on the metrics for positive and negative expressions, we again see that the simpler classifiers 352 Acc Polar Rec Polar Prec Polar F Neut Rec Neut Prec Neut F word token 73.6 45.3 72.2 55.7 89.9 74.0 81.2 word+priorpol 74.2 54.3 68.6 60.6 85.7 76.4 80.7 28 features 75.9 56.8 71.6 63.4 87.0 77.7 82.1 Table 4: Results for Step 1 Neutral-Polar Classification Positive Negative Both Neutral Acc Rec Prec F Rec Prec F Rec Prec F Rec Prec F word token 61.7 59.3 63.4 61.2 83.9 64.7 73.1 9.2 35.2 14.6 30.2 50.1 37.7 word+priorpol 63.0 69.4 55.3 61.6 80.4 71.2 75.5 9.2 35.2 14.6 33.5 51.8 40.7 10 features 65.7 67.1 63.3 65.1 82.1 72.9 77.2 11.2 28.4 16.1 41.4 52.4 46.2 Table 5: Results for Step 2 Polarity Classification.
They use the Opinion Finder lexicon (Wilson et al, 2005) and two bilingual English-Romanian dictionaries to translate the words in the lexicon. $$$$$ In this paper, we present a new approach to phrase-level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions.

To generate the initial explanations, one can use an off-the shelf sentiment classifier such as OpinionFinder2 (Wilson et al, 2005). $$$$$ With thisapproach, the system is able to automat ically identify the contextual polarity for a large subset of sentiment expressions,achieving results that are significantly bet ter than baseline.
To generate the initial explanations, one can use an off-the shelf sentiment classifier such as OpinionFinder2 (Wilson et al, 2005). $$$$$ Ofthe 4,247 sentences containing two or more subjec tive expressions, 17% contain mixtures of positive and negative expressions, and 62% contain mixturesof polar (positive/negative/both) and neutral subjec tive expressions.
