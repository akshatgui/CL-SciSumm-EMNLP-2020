Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0). $$$$$ For MUC-7, there is no drop in F-measure; for MUC-6, the F-measure dropped slightly.
Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0). $$$$$ Our current learning-based, HMM named entity recognition module is trained on 318 documents (a disjoint set from both the MUC-6 and MUC-7 test documents) tagged with named entities, and its score on the MUC-6 named entity task for the 30 formal test documents is only 88.9%, which is not considered very high by MUC-6 standards.
Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0). $$$$$ The 8 domain-specific features were completely changed for the MUC-6 task.
Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0). $$$$$ We obtained encouraging results, indicating that on the general noun phrase coreference task, the learning approach achieves accuracy comparable to that of nonlearning approaches.

It was criticized (Soon et al, 2001) that the features used by McCarthy and Lehnert (1995) are highly idiosyncratic and applicable only to one particular domain. $$$$$ In order to determine the major classes of errors made by our system, we randomly chose five test documents from MUC-6 and determined the coreference links that were either missing (false negatives) or spurious (false positives) in these sample documents.
It was criticized (Soon et al, 2001) that the features used by McCarthy and Lehnert (1995) are highly idiosyncratic and applicable only to one particular domain. $$$$$ In particular, information extraction (IE) systems like those built in the DARPA Message Understanding Conferences (Chinchor 1998; Sundheim 1995) have revealed that coreference resolution is such a critical component of IE systems that a separate coreference subtask has been defined and evaluated since MUC-6 (MUC-6 1995).
It was criticized (Soon et al, 2001) that the features used by McCarthy and Lehnert (1995) are highly idiosyncratic and applicable only to one particular domain. $$$$$ We evaluate our approach on common data sets (namely, the MUC-6 and MUC-7 coreference corpora) and obtain encouraging results, indicating that on the general noun phrase coreference task, the learning approach holds promise and achieves accuracy comparable to that of nonlearning approaches.
It was criticized (Soon et al, 2001) that the features used by McCarthy and Lehnert (1995) are highly idiosyncratic and applicable only to one particular domain. $$$$$ All the unary features score an F-measure of 0.

Soon et al (2001) use twelve features (see Table 1). $$$$$ It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of &quot;organization,&quot; &quot;person,&quot; or other types.
Soon et al (2001) use twelve features (see Table 1). $$$$$ We also thank Beth Sundheim for helpful comments on an earlier version of this paper, and Hai Leong Chieu for his implementation of the HMM-based named entity recognition module.
Soon et al (2001) use twelve features (see Table 1). $$$$$ We evaluated our approach on common data sets, namely, the MUC-6 and MUC-7 coreference corpora.
Soon et al (2001) use twelve features (see Table 1). $$$$$ To our knowledge, the research efforts of Aone and Bennett (1995), Ge, Hale, and Charniak (1998), Kehler (1997), McCarthy and Lehnert (1995), Fisher et al. (1995), and McCarthy (1996) are the only ones that are based on learning from an annotated corpus.

Soon et al (2001) include all noun phrases returned by their NP identifier and report an F-measure of 62.6% for MUC-6 data and 60.4% for MUC-7 data. $$$$$ It is also interesting to note that only 8 out of the 12 available features in the training examples are actually used in the final decision tree built.
Soon et al (2001) include all noun phrases returned by their NP identifier and report an F-measure of 62.6% for MUC-6 data and 60.4% for MUC-7 data. $$$$$ The purpose of ONE-CHAIN is to determine the maximum recall our system is capable of.

Features like the string ident and substring match features were used by other researchers (Soon et al, 2001), while the features ante med and ana med were used by Strube et al (2002) in order to improve the performance for definite NPs. $$$$$ It is also interesting to note that only 8 out of the 12 available features in the training examples are actually used in the final decision tree built.
Features like the string ident and substring match features were used by other researchers (Soon et al, 2001), while the features ante med and ana med were used by Strube et al (2002) in order to improve the performance for definite NPs. $$$$$ Thus, our coreference task resolves general noun phrases and is not restricted to a certain type of noun phrase such as pronouns.
Features like the string ident and substring match features were used by other researchers (Soon et al, 2001), while the features ante med and ana med were used by Strube et al (2002) in order to improve the performance for definite NPs. $$$$$ It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of &quot;organization,&quot; &quot;person,&quot; or other types.
Features like the string ident and substring match features were used by other researchers (Soon et al, 2001), while the features ante med and ana med were used by Strube et al (2002) in order to improve the performance for definite NPs. $$$$$ Although Aone and Bennett's (1995) system also made use of decision tree learning for coreference resolution, they dealt with Japanese texts, and their evaluation focused only on noun phrases denoting organizations, whereas our evaluation, which dealt with English texts, encompassed noun phrases of all types, not just those denoting organizations.

However, reference resolution algorithms based on these classifiers achieve reasonable performance of about 60 to 63% F-measure (Soon et al, 2001). $$$$$ It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of &quot;organization,&quot; &quot;person,&quot; or other types.
However, reference resolution algorithms based on these classifiers achieve reasonable performance of about 60 to 63% F-measure (Soon et al, 2001). $$$$$ .
However, reference resolution algorithms based on these classifiers achieve reasonable performance of about 60 to 63% F-measure (Soon et al, 2001). $$$$$ In this paper, we present a learning approach to coreference resolution of noun phrases in unrestricted text.
However, reference resolution algorithms based on these classifiers achieve reasonable performance of about 60 to 63% F-measure (Soon et al, 2001). $$$$$ The 12 features can be divided into unary and binary features.

While the second best system (Bjorkelund and Farkas, 2012) followed the widely used baseline of Soon et al (2001), the winning system (Fernandes et al, 2012) proposed the use of a tree representation. $$$$$ Specifically, a coreference relation denotes an identity of reference and holds between two textual elements known as markables, which can be definite noun phrases, demonstrative noun phrases, proper names, appositives, subâ€”noun phrases that act as modifiers, pronouns, and so on.
While the second best system (Bjorkelund and Farkas, 2012) followed the widely used baseline of Soon et al (2001), the winning system (Fernandes et al, 2012) proposed the use of a tree representation. $$$$$ For example, the feature JV-CHILD-i determined whether i referred to a joint venture formed as the result of a tie-up.
While the second best system (Bjorkelund and Farkas, 2012) followed the widely used baseline of Soon et al (2001), the winning system (Fernandes et al, 2012) proposed the use of a tree representation. $$$$$ The decision tree generated for MUC-6, shown in Figure 2, seems to encapsulate a reasonable rule of thumb that matches our intuitive linguistic notion of when two noun phrases can corefer.
While the second best system (Bjorkelund and Farkas, 2012) followed the widely used baseline of Soon et al (2001), the winning system (Fernandes et al, 2012) proposed the use of a tree representation. $$$$$ RESOLVE's feature set includes the two highly informative features, ALIAS and STR_MATCH.

For instance, the popular pairwise instance creation method suggested by Soon et al (2001) assumes non-branching trees, where the antecedent of every mention is its linear predecessor (i.e., he b 2 is the antecedent of Gary Wilber b 3). $$$$$ In particular, information extraction (IE) systems like those built in the DARPA Message Understanding Conferences (Chinchor 1998; Sundheim 1995) have revealed that coreference resolution is such a critical component of IE systems that a separate coreference subtask has been defined and evaluated since MUC-6 (MUC-6 1995).
For instance, the popular pairwise instance creation method suggested by Soon et al (2001) assumes non-branching trees, where the antecedent of every mention is its linear predecessor (i.e., he b 2 is the antecedent of Gary Wilber b 3). $$$$$ At higher numbers of training documents, our system seems to start overfitting the training data.
For instance, the popular pairwise instance creation method suggested by Soon et al (2001) assumes non-branching trees, where the antecedent of every mention is its linear predecessor (i.e., he b 2 is the antecedent of Gary Wilber b 3). $$$$$ One important factor is the distance between the two markables.
For instance, the popular pairwise instance creation method suggested by Soon et al (2001) assumes non-branching trees, where the antecedent of every mention is its linear predecessor (i.e., he b 2 is the antecedent of Gary Wilber b 3). $$$$$ It is also the first machine learning-based system to offer performance comparable to that of nonlearning approaches.

By using a simple co-reference resolution tool adapted from (Soon et al, 2001), we add all the mentions referring to the target into the extended target set. $$$$$ In (3), the noun phrase extraction module mistakenly extracted (vice)1 and (vice)2, which are not prenominal modifiers.
By using a simple co-reference resolution tool adapted from (Soon et al, 2001), we add all the mentions referring to the target into the extended target set. $$$$$ These errors are caused by the wrong assignment of semantic classes to words.
By using a simple co-reference resolution tool adapted from (Soon et al, 2001), we add all the mentions referring to the target into the extended target set. $$$$$ We also thank Beth Sundheim for helpful comments on an earlier version of this paper, and Hai Leong Chieu for his implementation of the HMM-based named entity recognition module.
By using a simple co-reference resolution tool adapted from (Soon et al, 2001), we add all the mentions referring to the target into the extended target set. $$$$$ The approach learns from a small, annotated corpus and the task includes resolving not just a certain type of noun phrase (e.g., pronouns) but rather general noun phrases.

Instances are created following Soon et al (2001). $$$$$ As explained in McCarthy (1996), the reason for this low recall is that RESOLVE takes only the &quot;relevant entities&quot; and &quot;relevant references&quot; as input, where the relevant entities and relevant references are restricted to &quot;person&quot; and &quot;organization.&quot; In addition, because of limitations of the noun phrase detection module, nested phrases are not extracted and therefore do not take part in coreference.
Instances are created following Soon et al (2001). $$$$$ For example, JV-CHILD-i was changed to CHILD-i to decide whether i is a &quot;unit&quot; or a &quot;subsidiary&quot; of a certain parent company.
Instances are created following Soon et al (2001). $$$$$ As with RESOLVE, &quot;feature ambiguity&quot; is the main source of precision errors.
Instances are created following Soon et al (2001). $$$$$ Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets.

Following Ng & Cardie (2002), our baseline system reimplements the Soon et al (2001) system. $$$$$ Our system's scores are in the upper region of the MUC-6 and MUC-7 systems.
Following Ng & Cardie (2002), our baseline system reimplements the Soon et al (2001) system. $$$$$ In this paper, we presented a learning approach to coreference resolution of noun phrases in unrestricted text.
Following Ng & Cardie (2002), our baseline system reimplements the Soon et al (2001) system. $$$$$ This approach requires a relatively small corpus of training documents that have been annotated with coreference chains of noun phrases.

We start with a baseline system using all the features from Soon et al (2001) that were not removed in the feature selection process (i.e. DISTANCE). $$$$$ 5.
We start with a baseline system using all the features from Soon et al (2001) that were not removed in the feature selection process (i.e. DISTANCE). $$$$$ Similarly, the inadequacy of our system's surface features means that the current feature set may not be enough and more information sources should be added.
We start with a baseline system using all the features from Soon et al (2001) that were not removed in the feature selection process (i.e. DISTANCE). $$$$$ Figure 7 shows the distribution of the test cases over the five positive leaf nodes of the MUC-6 tree.

It supports both local (Soon et al (2001)-style) and global (ILP, Denis and Baldridge (2007)-style) models of coreference. $$$$$ Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets.
It supports both local (Soon et al (2001)-style) and global (ILP, Denis and Baldridge (2007)-style) models of coreference. $$$$$ Thus, our coreference task resolves general noun phrases and is not restricted to a certain type of noun phrase such as pronouns.
It supports both local (Soon et al (2001)-style) and global (ILP, Denis and Baldridge (2007)-style) models of coreference. $$$$$ The decision tree generated for MUC-6, shown in Figure 2, seems to encapsulate a reasonable rule of thumb that matches our intuitive linguistic notion of when two noun phrases can corefer.

Our local model of coreference is a reimplementation of the algorithm, proposed by Soon et al (2001) with an extended feature set. $$$$$ We evaluated our approach on common data sets, namely, the MUC-6 and MUC-7 coreference corpora.
Our local model of coreference is a reimplementation of the algorithm, proposed by Soon et al (2001) with an extended feature set. $$$$$ In this paper, we present a learning approach to coreference resolution of noun phrases in unrestricted text.
Our local model of coreference is a reimplementation of the algorithm, proposed by Soon et al (2001) with an extended feature set. $$$$$ Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets.

PAIRWISE $$$$$ In addition, these features must be generic enough to be used across different domains.
PAIRWISE $$$$$ Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets.
PAIRWISE $$$$$ The approach learns from a small, annotated corpus and the task includes resolving not just a certain type of noun phrase (e.g., pronouns) but rather general noun phrases.
PAIRWISE $$$$$ There are other features that are related to the gender, number, and semantic class of the two markables.

Our event-anaphora resolution system adopts the common learning-based model for object anaphora resolution, as employed by (Soon et al, 2001) and (Ng and Cardie, 2002a). $$$$$ It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of &quot;organization,&quot; &quot;person,&quot; or other types.
Our event-anaphora resolution system adopts the common learning-based model for object anaphora resolution, as employed by (Soon et al, 2001) and (Ng and Cardie, 2002a). $$$$$ In many of the negative training examples, although the noun phrases are assigned the same semantic classes, these assignments do not seem to be correct.
Our event-anaphora resolution system adopts the common learning-based model for object anaphora resolution, as employed by (Soon et al, 2001) and (Ng and Cardie, 2002a). $$$$$ Next, both the noun phrases determined by the noun phrase identification module and the named entities are merged in such a way that if the noun phrase overlaps with a named entity, the noun phrase boundaries will be adjusted to subsume the named entity.
Our event-anaphora resolution system adopts the common learning-based model for object anaphora resolution, as employed by (Soon et al, 2001) and (Ng and Cardie, 2002a). $$$$$ We evaluate our approach on common data sets (namely, the MUC-6 and MUC-7 coreference corpora) and obtain encouraging results, indicating that on the general noun phrase coreference task, the learning approach holds promise and achieves accuracy comparable to that of nonlearning approaches.

We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al, 2001). $$$$$ When the system considers the anaphor, (her)76, all preceding phrases, except (her boss)75, are tested to see whether they corefer with it.
We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al, 2001). $$$$$ McCarthy and Lehnert (1995) describe how RESOLVE was tested on the MUC5 English Joint Ventures (EJV) corpus.
We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al, 2001). $$$$$ Specifically, a coreference relation denotes an identity of reference and holds between two textual elements known as markables, which can be definite noun phrases, demonstrative noun phrases, proper names, appositives, subâ€”noun phrases that act as modifiers, pronouns, and so on.
We construct this entity-mention graph by learning to decide for each mention which preceding mention, if any, belongs in the same equivalence class; this approach is commonly called the pairwise coreference model (Soon et al, 2001). $$$$$ For MUC-6, 30 dry-run documents annotated with coreference information were used as the training documents for our coreference engine.

Soon et al (2001) use the Closest-Link method $$$$$ The approach learns from a small, annotated corpus and the task includes resolving not just a certain type of noun phrase (e.g., pronouns) but rather general noun phrases.
Soon et al (2001) use the Closest-Link method $$$$$ In this case, the longer string is chosen to be the one that is converted into the acronym form.
Soon et al (2001) use the Closest-Link method $$$$$ For organization names, the alias function also checks for acronym match such as IBM and International Business Machines Corp.
Soon et al (2001) use the Closest-Link method $$$$$ This paper is an expanded version of a preliminary paper that appeared in the Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.

Distance features are important for a system that makes links based on the best pairwise coreference value rather than implicitly incorporating distance by linking only the closest pair whose score is above a threshold, as done by e.g. Soon et al (2001). $$$$$ The ability to link coreferring noun phrases both within and across sentences is critical to discourse analysis and language understanding in general.
Distance features are important for a system that makes links based on the best pairwise coreference value rather than implicitly incorporating distance by linking only the closest pair whose score is above a threshold, as done by e.g. Soon et al (2001). $$$$$ In ONE_WRD, markables corefer if there is at least one common word.
Distance features are important for a system that makes links based on the best pairwise coreference value rather than implicitly incorporating distance by linking only the closest pair whose score is above a threshold, as done by e.g. Soon et al (2001). $$$$$ The first step is to remove all postmodifiers such as Corp. and Ltd. Then, the acronym function considers each word in turn, and if the first letter is capitalized, it is used to form the acronym.

The remaining predicates in Table 1 are a subset of features used by other coreference resolution systems (cf. Soon et al., 2001). $$$$$ It is an important subtask in natural language processing systems.
The remaining predicates in Table 1 are a subset of features used by other coreference resolution systems (cf. Soon et al., 2001). $$$$$ Missing links result in recall errors; spurious links result in precision errors.
The remaining predicates in Table 1 are a subset of features used by other coreference resolution systems (cf. Soon et al., 2001). $$$$$ The contribution of our work lies in showing that a learning approach, when evaluated on common coreference data sets, is able to achieve accuracy competitive with that of state-of-the-art systems using nonlearning approaches.
The remaining predicates in Table 1 are a subset of features used by other coreference resolution systems (cf. Soon et al., 2001). $$$$$ We would like to thank the MUC organizers who made available to us the MUC-6 and MUC-7 data sets, without which this work would have been impossible.
