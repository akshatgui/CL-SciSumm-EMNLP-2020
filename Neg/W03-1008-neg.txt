The Gildea and Hockenmaier (2003) system uses features extracted from Combinatory Categorial Grammar (CCG) corresponding to the features that were used by G&J and G&P systems. $$$$$ As the CCG parser is trained and tested on a corpus of CCG derivations that have been obtained by automatic conversion from the Penn Treebank, we are able to compare performance using both goldstandard and automatic parses for both CCG and the traditional Treebank representation.
The Gildea and Hockenmaier (2003) system uses features extracted from Combinatory Categorial Grammar (CCG) corresponding to the features that were used by G&J and G&P systems. $$$$$ This system performs at least as well as a system based on a traditional Treebank parser, and outperforms it on core argument roles.
The Gildea and Hockenmaier (2003) system uses features extracted from Combinatory Categorial Grammar (CCG) corresponding to the features that were used by G&J and G&P systems. $$$$$ An interesting experiment would be the application of our role-labeling system to the output of the trace recovery system of Johnson (2002).
The Gildea and Hockenmaier (2003) system uses features extracted from Combinatory Categorial Grammar (CCG) corresponding to the features that were used by G&J and G&P systems. $$$$$ We refer to PropBank’s numbered arguments as “core” arguments.

This analysis allows recovery of verbal arguments of nominalised raising and control verbs, a construction which both Gildea and Hockenmaier (2003) and Boxwell and White (2008) identify as a problem case when aligning Propbank and CCGbank. $$$$$ Although the path is composed as a string of symbols, our systems will treat the string as an atomic value.
This analysis allows recovery of verbal arguments of nominalised raising and control verbs, a construction which both Gildea and Hockenmaier (2003) and Boxwell and White (2008) identify as a problem case when aligning Propbank and CCGbank. $$$$$ The PropBank (Kingsbury and Palmer, 2002) and the FrameNet (Baker et al., 1998) projects both document the variation in syntactic realization of the arguments of predicates in general English text.
This analysis allows recovery of verbal arguments of nominalised raising and control verbs, a construction which both Gildea and Hockenmaier (2003) and Boxwell and White (2008) identify as a problem case when aligning Propbank and CCGbank. $$$$$ Adjuncts are represented as functor categories such as S/S which expect and return the same type.
This analysis allows recovery of verbal arguments of nominalised raising and control verbs, a construction which both Gildea and Hockenmaier (2003) and Boxwell and White (2008) identify as a problem case when aligning Propbank and CCGbank. $$$$$ The Treebankparser returns skeletal phrase-structure trees without the traces or functional tags in the original Penn Treebank, whereas the CCG parser returns wordword dependencies that correspond to the underlying predicate-argument structure, including longrange dependencies arising through control, raising, extraction and coordination.

Conventionally there are two kinds of methods for role assignments, one is using only statistical information (Gildea and Jurafsky, 2002) and the other is combining with grammar rules (Gildea and Hockenmaier, 2003). $$$$$ Most of the numbered arguments (in particular ARG0 and ARG1) correspond to arguments that the CCG category of the verb directly subcategorizes for.
Conventionally there are two kinds of methods for role assignments, one is using only statistical information (Gildea and Jurafsky, 2002) and the other is combining with grammar rules (Gildea and Hockenmaier, 2003). $$$$$ If the CCG derivation does not define a predicateargument relation between the two words, we use the parse tree path feature described above, defined over the CCG derivation tree.
Conventionally there are two kinds of methods for role assignments, one is using only statistical information (Gildea and Jurafsky, 2002) and the other is combining with grammar rules (Gildea and Hockenmaier, 2003). $$$$$ The phrase type feature is replaced with the lexical category of the maximal projection of the PropBank argument’s head word in the CCG derivation tree.

 $$$$$ PropBank argument labels are assigned to nodes in the syntactic trees from the Penn Treebank.
 $$$$$ These relations are recovered with an accuracy of around 83% (labeled recovery) or 91% (unlabeled recovery) (Hockenmaier, 2003).
 $$$$$ That is, there may be no constituent in the CCG derivation corresponding to the same sequence of words as a particular constituent in the Treebank tree.
 $$$$$ In this paper, we examine how the syntactic representations used by different statistical parsers affect the performance of such a system.

Gildea and Hockenmaier (2003) report that using features extracted from a Combinatory Categorial Grammar (CCG) representation improves semantic labeling performance on core arguments. $$$$$ We present a system for automatically identifying PropBank-style semantic roles based on the output of a statistical parser for Combinatory Categorial Grammar.
Gildea and Hockenmaier (2003) report that using features extracted from a Combinatory Categorial Grammar (CCG) representation improves semantic labeling performance on core arguments. $$$$$ We present a system for automatically identifying PropBank-style semantic roles based on the output of a statistical parser for Combinatory Categorial Grammar.

However, this mismatch is significantly less than the 23% mismatch reported in (Gildea and Hockenmaier, 2003) between the CCGBank and an earlier version of the PropBank. $$$$$ In order to do this, we wish to correlate the CCG relations above with PropBank arguments.
However, this mismatch is significantly less than the 23% mismatch reported in (Gildea and Hockenmaier, 2003) between the CCGBank and an earlier version of the PropBank. $$$$$ Long-range dependencies are especially important for core arguments, shown by the fact that removing trace information from the Treebank parses results in a bigger drop for core arguments (83.5 to 76.3 F-score) than for all roles (74.1 to 70.2).
However, this mismatch is significantly less than the 23% mismatch reported in (Gildea and Hockenmaier, 2003) between the CCGBank and an earlier version of the PropBank. $$$$$ In order to do this, we wish to correlate the CCG relations above with PropBank arguments.
However, this mismatch is significantly less than the 23% mismatch reported in (Gildea and Hockenmaier, 2003) between the CCGBank and an earlier version of the PropBank. $$$$$ Instead, probabilities are estimated from various subsets of the features, and interpolated as a linear combination of the resulting distributions.

In order to generalize the path feature (see Table 1 in Section 3) which is probably the most salient (while being the most data sparse) feature for SRL, previous work has extracted features from other syntactic representations, such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004) or integrated features from different parsers (Pradhan et al, 2005b). $$$$$ We believe this performance gap to be caused by the mismatches between the CCG analyses and the PropBank annotations described in Section 5.2.
In order to generalize the path feature (see Table 1 in Section 3) which is probably the most salient (while being the most data sparse) feature for SRL, previous work has extracted features from other syntactic representations, such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004) or integrated features from different parsers (Pradhan et al, 2005b). $$$$$ This system performs at least as well as a system based on a traditional Treebank parser, and outperforms it on core argument roles.
In order to generalize the path feature (see Table 1 in Section 3) which is probably the most salient (while being the most data sparse) feature for SRL, previous work has extracted features from other syntactic representations, such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004) or integrated features from different parsers (Pradhan et al, 2005b). $$$$$ The impact of our head-word based scoring is analyzed in Table 3, which compares results when only the head word must be correctly identified (as in Table 2) and to results when both the beginning and end of the argument must be correctly identified in the sentence (as in Gildea and Palmer (2002)).
In order to generalize the path feature (see Table 1 in Section 3) which is probably the most salient (while being the most data sparse) feature for SRL, previous work has extracted features from other syntactic representations, such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004) or integrated features from different parsers (Pradhan et al, 2005b). $$$$$ Gildea and Palmer (2002) developed a system to predict semantic roles (as defined in PropBank) from sentences and their parse trees as determined by the statistical parser of Collins (1999).

For instance, Gildea and Hockenmaier (2003) reported that a CCG-based parser gives improved results over the Collins parser. $$$$$ We speculate that much of the performance improvement we show could be obtained with traditional (ie. non-CCG-based) parsers if they were designed to recover more of the information present in the Penn Treebank, in particular the trace co-indexation.
For instance, Gildea and Hockenmaier (2003) reported that a CCG-based parser gives improved results over the Collins parser. $$$$$ Gildea and Palmer (2002) developed a system to predict semantic roles (as defined in PropBank) from sentences and their parse trees as determined by the statistical parser of Collins (1999).
For instance, Gildea and Hockenmaier (2003) reported that a CCG-based parser gives improved results over the Collins parser. $$$$$ Because of the mismatch between the constituent structures of CCG and the Treebank, we score both systems according to how well they identify the head words of PropBank’s arguments.
For instance, Gildea and Hockenmaier (2003) reported that a CCG-based parser gives improved results over the Collins parser. $$$$$ Our aim is to use CCG derivations as input to a system for automatically producing the argument labels of PropBank.

As with a previous approach in CCG semantic role labeling (Gildea and Hockenmaier, 2003), this feature shows the exact nature of the syntactic dependency between the predicate and the word we are considering, if any such dependency exists. $$$$$ This system performs at least as well as a system based on a traditional Treebank parser, and outperforms it on core argument roles.
As with a previous approach in CCG semantic role labeling (Gildea and Hockenmaier, 2003), this feature shows the exact nature of the syntactic dependency between the predicate and the word we are considering, if any such dependency exists. $$$$$ The voice feature distinguishes between active and passive verbs, and is important in predicting semantic roles because direct objects of active verbs correspond to subjects of passive verbs.
As with a previous approach in CCG semantic role labeling (Gildea and Hockenmaier, 2003), this feature shows the exact nature of the syntactic dependency between the predicate and the word we are considering, if any such dependency exists. $$$$$ Adjuncts are represented as functor categories such as S/S which expect and return the same type.

We also compare with the CCG-based SRL presented in (Gildea and Hockenmaier, 2003) , which has a similar motivation as this paper, except they use the Combinatory Categorial Grammar formalism and the CCGBank syntactic Treebank which was converted from the Penn Tree bank. $$$$$ An instance of a verb was considered passive if it is tagged as a past participle (e.g. taken), unless it occurs as a descendent verb phrase headed by any form of have (e.g. has taken) without an intervening verb phrase headed by any form of be (e.g. has been taken).
We also compare with the CCG-based SRL presented in (Gildea and Hockenmaier, 2003) , which has a similar motivation as this paper, except they use the Combinatory Categorial Grammar formalism and the CCGBank syntactic Treebank which was converted from the Penn Tree bank. $$$$$ An interesting experiment would be the application of our role-labeling system to the output of the trace recovery system of Johnson (2002).
We also compare with the CCG-based SRL presented in (Gildea and Hockenmaier, 2003) , which has a similar motivation as this paper, except they use the Combinatory Categorial Grammar formalism and the CCGBank syntactic Treebank which was converted from the Penn Tree bank. $$$$$ In generating the CCGbank, various heuristics were used to make this distinction.
We also compare with the CCG-based SRL presented in (Gildea and Hockenmaier, 2003) , which has a similar motivation as this paper, except they use the Combinatory Categorial Grammar formalism and the CCGBank syntactic Treebank which was converted from the Penn Tree bank. $$$$$ PropBank argument labels are assigned to nodes in the syntactic trees from the Penn Treebank.

As a result they show that the oracle f-score improves by over 2 points over the (Gildea and Hockenmaier, 2003) oracle results for the numbered arguments only (A0,..., A5). $$$$$ Adjuncts are represented as functor categories such as S/S which expect and return the same type.
As a result they show that the oracle f-score improves by over 2 points over the (Gildea and Hockenmaier, 2003) oracle results for the numbered arguments only (A0,..., A5). $$$$$ The relations extracted from the CCG derivation for the sentence “London denied plans on Monday” are shown in Table 1.
As a result they show that the oracle f-score improves by over 2 points over the (Gildea and Hockenmaier, 2003) oracle results for the numbered arguments only (A0,..., A5). $$$$$ Although the path is composed as a string of symbols, our systems will treat the string as an atomic value.
As a result they show that the oracle f-score improves by over 2 points over the (Gildea and Hockenmaier, 2003) oracle results for the numbered arguments only (A0,..., A5). $$$$$ These secondary roles can be thought of as being adjuncts, rather than arguments, although no claims are made as to optionality or other traditional argument/adjunct tests.

In contrast to the approach in (Punyakanok et al, 2008), which tags constituents directly, we tag headwords and then associate them with a constituent, as in a previous CCG-based approach (Gildea and Hockenmaier, 2003). $$$$$ For each verb appearing in the corpus, a set of semantic roles is defined.
In contrast to the approach in (Punyakanok et al, 2008), which tags constituents directly, we tag headwords and then associate them with a constituent, as in a previous CCG-based approach (Gildea and Hockenmaier, 2003). $$$$$ Core arguments represent 75% of the total labeled roles in the PropBank data.
In contrast to the approach in (Punyakanok et al, 2008), which tags constituents directly, we tag headwords and then associate them with a constituent, as in a previous CCG-based approach (Gildea and Hockenmaier, 2003). $$$$$ We present a system for automatically identifying PropBank-style semantic roles based on the output of a statistical parser for Combinatory Categorial Grammar.
In contrast to the approach in (Punyakanok et al, 2008), which tags constituents directly, we tag headwords and then associate them with a constituent, as in a previous CCG-based approach (Gildea and Hockenmaier, 2003). $$$$$ For each role label for a verb’s argument in PropBank, we first find the head word for its constituent according to the the head rules of (Collins, 1999).

This feature has been shown (Gildea and Hockenmaier, 2003) to be an effective substitute for tree path-based features. $$$$$ The Treebankparser returns skeletal phrase-structure trees without the traces or functional tags in the original Penn Treebank, whereas the CCG parser returns wordword dependencies that correspond to the underlying predicate-argument structure, including longrange dependencies arising through control, raising, extraction and coordination.
This feature has been shown (Gildea and Hockenmaier, 2003) to be an effective substitute for tree path-based features. $$$$$ This system performs at least as well as a system based on a traditional Treebank parser, and outperforms it on core argument roles.
This feature has been shown (Gildea and Hockenmaier, 2003) to be an effective substitute for tree path-based features. $$$$$ Our CCG-based system for automatically labeling verb arguments with PropBank-style semantic roles outperforms a system using a traditional Treebankbased parser for core arguments, which comprise 75% of the role labels, but scores lower on adjunctlike roles such as temporals and locatives.

 $$$$$ That is, there may be no constituent in the CCG derivation corresponding to the same sequence of words as a particular constituent in the Treebank tree.
 $$$$$ For each role label for a verb’s argument in PropBank, we first find the head word for its constituent according to the the head rules of (Collins, 1999).
 $$$$$ This feature is much sparser in CCG: since CCG categories encode subcategorization information, the number of categories in CCGbank is much larger than that of Penn Treebank labels.
 $$$$$ The relations extracted from the CCG derivation for the sentence “London denied plans on Monday” are shown in Table 1.

We follow a previous CCG based approach (Gildea and Hockenmaier, 2003) in using a feature to describe the PARG relationship between the two words, if one exists. $$$$$ We believe that the superior performance of the CCG system on this core arguments is due to its ability to recover long-distance dependencies, whereas we attribute its lower performance on non-core arguments mainly to the mismatches between PropBank and CCGbank.
We follow a previous CCG based approach (Gildea and Hockenmaier, 2003) in using a feature to describe the PARG relationship between the two words, if one exists. $$$$$ We compare a parser based on Combinatory Categorial Grammar (CCG) (Hockenmaier and Steedman, 2002b) with the Collins parser.
We follow a previous CCG based approach (Gildea and Hockenmaier, 2003) in using a feature to describe the PARG relationship between the two words, if one exists. $$$$$ As an example, the entryspecific roles for the verb offer are given below: These roles are then annotated for every instance of the verb appearing in the corpus, including the following examples: A variety of additional roles are assumed to apply across all verbs.
We follow a previous CCG based approach (Gildea and Hockenmaier, 2003) in using a feature to describe the PARG relationship between the two words, if one exists. $$$$$ We refer to PropBank’s numbered arguments as “core” arguments.

Using a version of Brutus incorporating only the CCG-based features described above, we achieve better results than a previous CCG based system (Gildea and Hockenmaier, 2003, henceforth G&H). $$$$$ The phrase type feature is replaced with the lexical category of the maximal projection of the PropBank argument’s head word in the CCG derivation tree.
Using a version of Brutus incorporating only the CCG-based features described above, we achieve better results than a previous CCG based system (Gildea and Hockenmaier, 2003, henceforth G&H). $$$$$ The CCG parser returns predicate-argument structures that include long-range dependencies; therefore, it seems inherently better suited for this task.
Using a version of Brutus incorporating only the CCG-based features described above, we achieve better results than a previous CCG based system (Gildea and Hockenmaier, 2003, henceforth G&H). $$$$$ Our results also have implications for parser evaluation, as the most frequently used constituent-based precision and recall measures do not evaluate how well long-range dependencies can be recovered from the output of a parser.
