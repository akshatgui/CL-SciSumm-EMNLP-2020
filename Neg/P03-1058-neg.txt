To tackle this problem, in one of our recent work (Ng et al, 2003), we had gathered training data from parallel texts and obtained encouraging results in our evaluation on the nouns of SENSEVAL-2 English lexical sample task (Kilgarriff, 2001). $$$$$ The list of 29 nouns is given in Table 3.
To tackle this problem, in one of our recent work (Ng et al, 2003), we had gathered training data from parallel texts and obtained encouraging results in our evaluation on the nouns of SENSEVAL-2 English lexical sample task (Kilgarriff, 2001). $$$$$ To illustrate, we consider the noun channel where the difference between M3 and P2 is the largest.
To tackle this problem, in one of our recent work (Ng et al, 2003), we had gathered training data from parallel texts and obtained encouraging results in our evaluation on the nouns of SENSEVAL-2 English lexical sample task (Kilgarriff, 2001). $$$$$ Resnik and Yarowsky (2000) considered word sense disambiguation using multiple languages.
To tackle this problem, in one of our recent work (Ng et al, 2003), we had gathered training data from parallel texts and obtained encouraging results in our evaluation on the nouns of SENSEVAL-2 English lexical sample task (Kilgarriff, 2001). $$$$$ On average, about statistical methods in word sense disambiguation in the context of machine translation.

To gather training examples from these parallel texts, we used the approach we described in (Ng et al, 2003) and (Chan and Ng, 2005b). $$$$$ Henceforth, we shall refer to this set of 8 nouns as “difficult” nouns.
To gather training examples from these parallel texts, we used the approach we described in (Ng et al, 2003) and (Chan and Ng, 2005b). $$$$$ On a subset of the most difficult SENSEVAL-2 nouns, the accuracy difference between the two approaches is only 14.0%, and the difference could narrow further to 6.5% if we disregard the advantage that manually sense-tagged data have in their sense coverage.
To gather training examples from these parallel texts, we used the approach we described in (Ng et al, 2003) and (Chan and Ng, 2005b). $$$$$ In this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from English-Chinese parallel corpora, which were then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.

Other similar work includes that in (Ng et al, 2003), where a sense-annotated corpus was automatically generated from a parallel corpus. $$$$$ Firstly, what constitutes a valid sense distinction carries much subjectivity.
Other similar work includes that in (Ng et al, 2003), where a sense-annotated corpus was automatically generated from a parallel corpus. $$$$$ In this paper, we evaluate an approach to automatically acquire sensetagged training data from English-Chinese parallel corpora, which are then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.
Other similar work includes that in (Ng et al, 2003), where a sense-annotated corpus was automatically generated from a parallel corpus. $$$$$ On a subset of the most difficult SENSEVAL-2 nouns, the accuracy difference between the two approaches is only 14.0%, and the difference could narrow further to 6.5% if we disregard the advantage that manually sense-tagged data have in their sense coverage.
Other similar work includes that in (Ng et al, 2003), where a sense-annotated corpus was automatically generated from a parallel corpus. $$$$$ For the remaining nouns (art, authority, channel, church, circuit, facility, grip, spade), the accuracy difference between M1 and P1 is at least 0.10.

For example, Ng et al (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software. $$$$$ In this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from English-Chinese parallel corpora, which were then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.
For example, Ng et al (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software. $$$$$ The alignment result contains much noise, especially for words with low frequency counts.
For example, Ng et al (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software. $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising and provides an alternative to manual sense tagging.

There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (Ng et al, 2003), syntactic parsing (Hwa et al, 2005), information retrieval (Monz and Dorr, 2005), subjectivity analysis (Mihalcea et al, 2007), and others. $$$$$ (iii) Truly ambiguous word: Sometimes, a word is truly ambiguous in a particular context, and different translators may translate it differently.
There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (Ng et al, 2003), syntactic parsing (Hwa et al, 2005), information retrieval (Monz and Dorr, 2005), subjectivity analysis (Mihalcea et al, 2007), and others. $$$$$ This confirms our hypothesis that eliminating the possibility that training and test examples come from the same document would result in a fairer comparison.
There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (Ng et al, 2003), syntactic parsing (Hwa et al, 2005), information retrieval (Monz and Dorr, 2005), subjectivity analysis (Mihalcea et al, 2007), and others. $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising.

For the translation of ambiguous English words Ng et al (2003) made use of the fact that the various senses are often translated differently. $$$$$ We evaluated our approach on all the nouns in the English lexical sample task of SENSEVAL-2 (Edmonds and Cotton, 2001; Kilgarriff 2001), which used the WordNet 1.7 sense inventory (Miller, 1990).
For the translation of ambiguous English words Ng et al (2003) made use of the fact that the various senses are often translated differently. $$$$$ In this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from English-Chinese parallel corpora, which were then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.
For the translation of ambiguous English words Ng et al (2003) made use of the fact that the various senses are often translated differently. $$$$$ In addition, the difference between the accuracy figures of M3 and P2 averaged over the set of all difficult nouns is 0.065.
For the translation of ambiguous English words Ng et al (2003) made use of the fact that the various senses are often translated differently. $$$$$ Given a word-aligned parallel corpus, the different translations in a target language serve as the “sense-tags” of an ambiguous word in the source language.

Ng et al (2003) show that it is possible to use automatically word aligned parallel corpora to train accurate supervised WSD models. $$$$$ The number of senses of each noun after sense lumping is given in column 3 of Table 3.
Ng et al (2003) show that it is possible to use automatically word aligned parallel corpora to train accurate supervised WSD models. $$$$$ While it is encouraging to find out that the parallel text sense tags are of high quality, we are still left with the task of explaining the difference between M1 and P1 for the set of difficult nouns.
Ng et al (2003) show that it is possible to use automatically word aligned parallel corpora to train accurate supervised WSD models. $$$$$ Comparing the M1 and P1 figures, we observed that there is a set of nouns for which they are relatively close.
Ng et al (2003) show that it is possible to use automatically word aligned parallel corpora to train accurate supervised WSD models. $$$$$ Li and Li (2002) investigated a bilingual bootstrapping technique, which differs from the method we implemented here.

Similarly, (Ng et al, 2003) report a research study which uses an English-Chinese parallel corpus in order to extract sense-tagged training data. $$$$$ This is smaller than the difference of 0.189 between the accuracy figures of M1 and P1 averaged over the set of all difficult nouns.
Similarly, (Ng et al, 2003) report a research study which uses an English-Chinese parallel corpus in order to extract sense-tagged training data. $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising and provides an alternative to manual sense tagging.

 $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising and provides an alternative to manual sense tagging.
 $$$$$ In contrast, the P1 score of each noun is obtained by training the WSD classifier on a mixture of six parallel corpora, and tested on the official SENSEVAL-2 test set, and hence the training and test data come from dissimilar domains in this case.

Similarly, Ng et al (2003) employ English Chinese parallel word aligned corpora to identify a repository of senses for English. $$$$$ Much research has been done on the best supervised learning approach for WSD (Florian and Yarowsky, 2002; Lee and Ng, 2002; Mihalcea and Moldovan, 2001; Yarowsky et al., 2001).
Similarly, Ng et al (2003) employ English Chinese parallel word aligned corpora to identify a repository of senses for English. $$$$$ However, they only looked at assigning at most two senses to a word, and their method only asked a single question about a single word of context.
Similarly, Ng et al (2003) employ English Chinese parallel word aligned corpora to identify a repository of senses for English. $$$$$ We evaluated our approach to word sense disambiguation on all the 29 nouns in the English lexical sample task of SENSEVAL-2 (Edmonds and Cotton, 2001; Kilgarriff 2001).

For example, Ng et al (2003) proposed to train a classifier on sense examples acquired from word-aligned English-Chinese parallel corpora. $$$$$ In this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from English-Chinese parallel corpora, which were then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.
For example, Ng et al (2003) proposed to train a classifier on sense examples acquired from word-aligned English-Chinese parallel corpora. $$$$$ On a subset of the most difficult SENSEVAL-2 nouns, the accuracy difference between the two approaches is only 14.0%, and the difference could narrow further to 6.5% if we disregard the advantage that manually sense-tagged data have in their sense coverage.
For example, Ng et al (2003) proposed to train a classifier on sense examples acquired from word-aligned English-Chinese parallel corpora. $$$$$ The parallel text alignment approach works well for nature and sense, among these nouns.

Ng et al (2003) address word sense disambiguation by manually annotating WordNet senses with their translation in the target language (Chinese), and then automatically extracting labeled examples for word sense disambiguation by applying the IBM Models to a bilingual corpus. $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising.
Ng et al (2003) address word sense disambiguation by manually annotating WordNet senses with their translation in the target language (Chinese), and then automatically extracting labeled examples for word sense disambiguation by applying the IBM Models to a bilingual corpus. $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising.
Ng et al (2003) address word sense disambiguation by manually annotating WordNet senses with their translation in the target language (Chinese), and then automatically extracting labeled examples for word sense disambiguation by applying the IBM Models to a bilingual corpus. $$$$$ In this paper, we evaluate an approach to automatically acquire sensetagged training data from English-Chinese parallel corpora, which are then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.
Ng et al (2003) address word sense disambiguation by manually annotating WordNet senses with their translation in the target language (Chinese), and then automatically extracting labeled examples for word sense disambiguation by applying the IBM Models to a bilingual corpus. $$$$$ In this step, we will decide on the sense classes of an English word w that are relevant to translating w into Chinese.

Moreover, some studies present multilingual WSD systems that attain state-of-the-art performance in all-words disambiguation (Ng et al, 2003). $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising.
Moreover, some studies present multilingual WSD systems that attain state-of-the-art performance in all-words disambiguation (Ng et al, 2003). $$$$$ In this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from English-Chinese parallel corpora, which were then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.
Moreover, some studies present multilingual WSD systems that attain state-of-the-art performance in all-words disambiguation (Ng et al, 2003). $$$$$ Li and Li (2002) investigated a bilingual bootstrapping technique, which differs from the method we implemented here.

For instance, Ng et al (2003) showed that it is possible to use word aligned parallel corpora to train accurate supervised WSD models. $$$$$ Li and Li (2002) investigated a bilingual bootstrapping technique, which differs from the method we implemented here.
For instance, Ng et al (2003) showed that it is possible to use word aligned parallel corpora to train accurate supervised WSD models. $$$$$ We then used our approach of parallel text alignment described in the last section to obtain the training examples from the English side of the parallel texts.
For instance, Ng et al (2003) showed that it is possible to use word aligned parallel corpora to train accurate supervised WSD models. $$$$$ Various alignment algorithms (Melamed 2001; Och and Ney 2000) have been developed in the past.

Ng et al (2003) extend this approach further and demonstrate that it is feasible for large scale WSD. $$$$$ Corpus-based, supervised machine learning methods have been used to tackle the WSD task, just like the other NLP tasks.
Ng et al (2003) extend this approach further and demonstrate that it is feasible for large scale WSD. $$$$$ Ide et al. (2002) investigated word sense distinctions using parallel corpora.

Unlike Ng et al (2003) our algorithm works on monolingual corpora, which are much more abundant than parallel ones, and is fully automatic. $$$$$ On a subset of the most difficult SENSEVAL-2 nouns, the accuracy difference between the two approaches is only 14.0%, and the difference could narrow further to 6.5% if we disregard the advantage that manually sense-tagged data have in their sense coverage.
Unlike Ng et al (2003) our algorithm works on monolingual corpora, which are much more abundant than parallel ones, and is fully automatic. $$$$$ For the remaining nouns (art, authority, channel, church, circuit, facility, grip, spade), the accuracy difference between M1 and P1 is at least 0.10.
Unlike Ng et al (2003) our algorithm works on monolingual corpora, which are much more abundant than parallel ones, and is fully automatic. $$$$$ Our work confirms the importance of domain dependence in WSD.
Unlike Ng et al (2003) our algorithm works on monolingual corpora, which are much more abundant than parallel ones, and is fully automatic. $$$$$ The accuracy figures thus obtained for all the difficult nouns are listed in the column labeled P2 in Table 3.

To gather examples from these parallel corpora, we followed the approach in (Ng et al, 2003). $$$$$ Our investigation reveals that this method of acquiring sense-tagged data is promising.
To gather examples from these parallel corpora, we followed the approach in (Ng et al, 2003). $$$$$ In this paper, we used the WSD program reported in (Lee and Ng, 2002).
To gather examples from these parallel corpora, we followed the approach in (Ng et al, 2003). $$$$$ However, note that in our approach, we only select the English word occurrences that align to our manually selected Chinese translations.

For instance, Ng et al (2003) showed that it is possible to use word aligned parallel corpora to train accurate supervised WSD models. $$$$$ These parallel corpora are listed in Table 2, with a combined size of 280 MB.
For instance, Ng et al (2003) showed that it is possible to use word aligned parallel corpora to train accurate supervised WSD models. $$$$$ We then tested the WSD classifier on the official SENSEVAL-2 test data (but with lumped senses) for w. The test accuracy (based on fine-grained scoring of SENSEVAL-2) of each noun obtained is listed in the column labeled M1 in Table 3.
For instance, Ng et al (2003) showed that it is possible to use word aligned parallel corpora to train accurate supervised WSD models. $$$$$ Henceforth, we shall refer to this set of 8 nouns as “difficult” nouns.

To gather examples from parallel corpora, we followed the approach in (Ng et al, 2003). $$$$$ Firstly, what constitutes a valid sense distinction carries much subjectivity.
To gather examples from parallel corpora, we followed the approach in (Ng et al, 2003). $$$$$ A central problem of word sense disambiguation (WSD) is the lack of manually sense-tagged data required for supervised learning.
To gather examples from parallel corpora, we followed the approach in (Ng et al, 2003). $$$$$ In this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from English-Chinese parallel corpora, which were then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.

As described in (Ng et al, 2003), when several senses of an English word are translated by the same Chinese word, we can collapse these senses to obtain a coarser-grained, lumped sense inventory. $$$$$ Ide et al. (2002) investigated word sense distinctions using parallel corpora.
As described in (Ng et al, 2003), when several senses of an English word are translated by the same Chinese word, we can collapse these senses to obtain a coarser-grained, lumped sense inventory. $$$$$ While this use of parallel corpus for word sense disambiguation seems appealing, several practical issues arise in its implementation: (i) What is the size of the parallel corpus needed in order for this approach to be able to disambiguate a source language word accurately?
As described in (Ng et al, 2003), when several senses of an English word are translated by the same Chinese word, we can collapse these senses to obtain a coarser-grained, lumped sense inventory. $$$$$ Resnik and Yarowsky (2000) considered word sense disambiguation using multiple languages.
As described in (Ng et al, 2003), when several senses of an English word are translated by the same Chinese word, we can collapse these senses to obtain a coarser-grained, lumped sense inventory. $$$$$ In this paper, we reported an empirical study to evaluate an approach of automatically acquiring sense-tagged training data from English-Chinese parallel corpora, which were then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task.
