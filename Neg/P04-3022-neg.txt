They use two kinds of features: syntactic ones and word based ones, for example, the path of the given pair of NEs in the parse tree and the word n-gram between NEs (Kambhatla, 2004). $$$$$ Dependency The words and part-of-speech and chunk labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic parse tree.
They use two kinds of features: syntactic ones and word based ones, for example, the path of the given pair of NEs in the parse tree and the word n-gram between NEs (Kambhatla, 2004). $$$$$ Here we present our general approach and describe our ACE results.

Supervised learning method using syntactic and word-based features, the path of the pairs of NEs in the parse tree and the word n gram between pairs of NEs (Kambhatla, 2004). $$$$$ Our system obtained competitive results in the Automatic Content Extraction (ACE) evaluation.
Supervised learning method using syntactic and word-based features, the path of the pairs of NEs in the parse tree and the word n gram between pairs of NEs (Kambhatla, 2004). $$$$$ The training set contained around 300K words, and 9752 instances of relations and the development set contained around 46K words, and 1679 instances of relations.
Supervised learning method using syntactic and word-based features, the path of the pairs of NEs in the parse tree and the word n gram between pairs of NEs (Kambhatla, 2004). $$$$$ We report both the F-measure' and the ACE value of relation extraction.

The approaches proposed to the ACE RDC task such as kernel methods (Zelenko et al, 2002) and Maximum Entropy methods (Kambhatla, 2004) required the availability of large set of human annotated corpora which are tagged with relation instances. $$$$$ To isolate the perfomance of relation extraction, we measure the performance of relation extraction models on “true” mentions with “true” chaining (i.e. as annotated by LDC annotators).
The approaches proposed to the ACE RDC task such as kernel methods (Zelenko et al, 2002) and Maximum Entropy methods (Kambhatla, 2004) required the availability of large set of human annotated corpora which are tagged with relation instances. $$$$$ Even using very simple lexical features, we obtained high precision extractors that can potentially be used to annotate large amounts of unlabeled data for semi-supervised or unsupervised learning, without having to parse the entire data.
The approaches proposed to the ACE RDC task such as kernel methods (Zelenko et al, 2002) and Maximum Entropy methods (Kambhatla, 2004) required the availability of large set of human annotated corpora which are tagged with relation instances. $$$$$ The addition of entity types, mention levels and especially, the word proximity features (“overlap”) boosts the recall at the expense of the very sets with true (T) and system output (S) mentions and entities. high precision.

We compare our results to a state-of-the-art supervised system similar to the system described in (Kambhatla, 2004). $$$$$ This paper focuses on the relation extraction component of our ACE system.
We compare our results to a state-of-the-art supervised system similar to the system described in (Kambhatla, 2004). $$$$$ Even using very simple lexical features, we obtained high precision extractors that can potentially be used to annotate large amounts of unlabeled data for semi-supervised or unsupervised learning, without having to parse the entire data.
We compare our results to a state-of-the-art supervised system similar to the system described in (Kambhatla, 2004). $$$$$ Our system obtained competitive results in the Automatic Content Extraction (ACE) evaluation.

Kambhatla (2004) took a similar approach but used multivariate logistic regression (Kambhatla, 2004). $$$$$ For each pair of mentions, we compute several feature streams shown below.

 $$$$$ Words , , , .
 $$$$$ Extracting semantic relationships between entities is challenging because of a paucity of annotated data and the errors induced by entity detection modules.
 $$$$$ Even using very simple lexical features, we obtained high precision extractors that can potentially be used to annotate large amounts of unlabeled data for semi-supervised or unsupervised learning, without having to parse the entire data.
 $$$$$ The EDT task entails the detection of mentions of entities and chaining them together by identifying their coreference.

Kambhatla (2004) developed a method for extracting relations by applying Maximum Entropy models to combine lexical, syntactic and semantic features and report that they obtain improvement in results when they combine variety of features. $$$$$ Thus, when comparing mentions and , we distinguish between the case where -citizen-Of- and -citizen-Of- .
Kambhatla (2004) developed a method for extracting relations by applying Maximum Entropy models to combine lexical, syntactic and semantic features and report that they obtain improvement in results when they combine variety of features. $$$$$ Table 1 lists the types and subtypes of relations for the ACE RDC task, along with their frequency of occurence in the ACE training data2.
Kambhatla (2004) developed a method for extracting relations by applying Maximum Entropy models to combine lexical, syntactic and semantic features and report that they obtain improvement in results when they combine variety of features. $$$$$ In electing Thomas R. Reardon, an Oregon general practitioner who had been the chairman of its board, ...

 $$$$$ We employ Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text.
 $$$$$ Several previous relation extraction systems have focused almost exclusively on syntactic parse trees.
 $$$$$ Moreover, there is an explicit management relation between chairman and board, which are references to Thomas R. Reardon and the board of the American Medical Association respectively.
 $$$$$ Here we present our general approach and describe our ACE results.

Similar to our earlier work (Kambhatla, 2004), we used a combination of lexical, syntactic, and semantic features including all the words in between the two mentions, the entity types and subtypes of the two mentions, the number of words in between the two mentions, features derived from the smallest parse fragment connecting the two mentions, etc. $$$$$ The ACE value counts each relation only once, even if it was expressed many times in a document in different ways.
Similar to our earlier work (Kambhatla, 2004), we used a combination of lexical, syntactic, and semantic features including all the words in between the two mentions, the entity types and subtypes of the two mentions, the number of words in between the two mentions, features derived from the smallest parse fragment connecting the two mentions, etc. $$$$$ For example, for the mention pair his and wife with no words in between, the lexical features together with the fact that there are no words in between is sufficient (though not necessary) to extract the relationship between the two entities.
Similar to our earlier work (Kambhatla, 2004), we used a combination of lexical, syntactic, and semantic features including all the words in between the two mentions, the entity types and subtypes of the two mentions, the number of words in between the two mentions, features derived from the smallest parse fragment connecting the two mentions, etc. $$$$$ We employ Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text.

For the feature-based methods, Kambhatla (2004) employed Maximum Entropy models to combine diverse lexical, syntactic and semantic features in relation extraction, and achieved the F-measure of 52.8 on the 24 relation subtypes in the ACE RDC 2003 corpus. $$$$$ Overlap The number of words (if any) separating the two mentions, the number of other mentions in between, flags indicating whether the two mentions are in the same noun phrase, verb phrase or prepositional phrase.
For the feature-based methods, Kambhatla (2004) employed Maximum Entropy models to combine diverse lexical, syntactic and semantic features in relation extraction, and achieved the F-measure of 52.8 on the 24 relation subtypes in the ACE RDC 2003 corpus. $$$$$ In this paper, we present our general approach, describe the features we currently use and show the results of our participation in the ACE evaluation.
For the feature-based methods, Kambhatla (2004) employed Maximum Entropy models to combine diverse lexical, syntactic and semantic features in relation extraction, and achieved the F-measure of 52.8 on the 24 relation subtypes in the ACE RDC 2003 corpus. $$$$$ Entities can be of five types: persons, organizations, locations, facilities, and geo-political entities (geographically defined regions that define a political boundary, e.g. countries, cities, etc.).

Another problem is that, although they can explore some structured information in the parse tree (e.g. Kambhatla (2004) used the non-terminal path connecting the given two entities in a parse tree while Zhou et al (2005) introduced additional chunking features to enhance the performance), it is found difficult to well preserve structured information in the parse trees using the feature-based methods. $$$$$ In the next section, we describe our extraction system.
Another problem is that, although they can explore some structured information in the parse tree (e.g. Kambhatla (2004) used the non-terminal path connecting the given two entities in a parse tree while Zhou et al (2005) introduced additional chunking features to enhance the performance), it is found difficult to well preserve structured information in the parse trees using the feature-based methods. $$$$$ The addition of entity types, mention levels and especially, the word proximity features (“overlap”) boosts the recall at the expense of the very sets with true (T) and system output (S) mentions and entities. high precision.
Another problem is that, although they can explore some structured information in the parse tree (e.g. Kambhatla (2004) used the non-terminal path connecting the given two entities in a parse tree while Zhou et al (2005) introduced additional chunking features to enhance the performance), it is found difficult to well preserve structured information in the parse trees using the feature-based methods. $$$$$ As expected, the numbers are significantly lower for the system output runs due to errors made by the mention detection and mention chaining modules.

 $$$$$ Relation extraction is hard, since successful extraction implies correctly detecting both the argument mentions, correctly chaining these mentions to their rein the ACE 2003 evaluation. spective entities, and correctly determining the type of relation that holds between them.
 $$$$$ Here we present our general approach and describe our ACE results.
 $$$$$ Moreover, there is an explicit management relation between chairman and board, which are references to Thomas R. Reardon and the board of the American Medical Association respectively.

Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree. $$$$$ Overlap one-mention-in-between (the word “its”), two-words-apart, in-same-noun-phrase.
Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree. $$$$$ We obtained our best results when we combined a variety of features.
Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree. $$$$$ We obtained competitive results shown in Table 4.

Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect. $$$$$ We believe our approach of combining many kinds of evidence can potentially scale better to problems (like ACE), where we have a lot of relation types with relatively small amounts of annotated data.
Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect. $$$$$ In this paper, we present our general approach, describe the features we currently use and show the results of our participation in the ACE evaluation.
Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect. $$$$$ The ACE value is a NIST metric that assigns 0% value for a system which produces no output and 100% value for a system that extracts all the relations and produces no false alarms.
Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect. $$$$$ In this fragment, all the underlined phrases are mentions referring to the American Medical Association, or to Thomas R. Reardon or the board (an organization) of the American Medical Association.

Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes. $$$$$ More recently, (Zelenko et al., 2003) have proposed extracting relations by computing kernel functions between parse trees and (Culotta and Sorensen, 2004) have extended this work to estimate kernel functions between augmented dependency trees.
Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes. $$$$$ Extracting semantic relationships between entities is challenging because of a paucity of annotated data and the errors induced by entity detection modules.
Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes. $$$$$ We thus model the extraction as a classification problem with 49 classes, two for each relation subtype and a “NONE” class for the case where the two mentions are not related.
Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes. $$$$$ We present results in section 3, and we conclude after making some general observations in section 4.

(Culotta and Sorensen, 2004) extended this work to estimate kernel functions between augmented dependency trees, while (Kambhatla, 2004) combined lexical features, syntactic features, and semantic features in a maximum entropy model. $$$$$ The reader is referred to (Florian et al., 2004; Ittycheriah et al., 2003; Luo et al., 2004) for more details of our mention detection and mention chaining modules.
(Culotta and Sorensen, 2004) extended this work to estimate kernel functions between augmented dependency trees, while (Kambhatla, 2004) combined lexical features, syntactic features, and semantic features in a maximum entropy model. $$$$$ We employ Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text.
(Culotta and Sorensen, 2004) extended this work to estimate kernel functions between augmented dependency trees, while (Kambhatla, 2004) combined lexical features, syntactic features, and semantic features in a maximum entropy model. $$$$$ Extracting semantic relationships between entities is challenging because of a paucity of annotated data and the errors induced by entity detection modules.

However, the semantic features discussed in (Kambhatla, 2004) still focus on the word level instead of the conceptual level. $$$$$ Dependency The words and part-of-speech and chunk labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic parse tree.
However, the semantic features discussed in (Kambhatla, 2004) still focus on the word level instead of the conceptual level. $$$$$ We obtained competitive results on the ACE RDC task.
However, the semantic features discussed in (Kambhatla, 2004) still focus on the word level instead of the conceptual level. $$$$$ In electing Thomas R. Reardon, an Oregon general practitioner who had been the chairman of its board, ...

Kambhatla (2004) employs Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text for relation extraction. $$$$$ The addition of entity types, mention levels and especially, the word proximity features (“overlap”) boosts the recall at the expense of the very sets with true (T) and system output (S) mentions and entities. high precision.
Kambhatla (2004) employs Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text for relation extraction. $$$$$ We employ Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text.

 $$$$$ As expected, the numbers are significantly lower for the system output runs due to errors made by the mention detection and mention chaining modules.
 $$$$$ Our system obtained competitive results in the Automatic Content Extraction (ACE) evaluation.
 $$$$$ Here we present our general approach and describe our ACE results.
 $$$$$ Several previous relation extraction systems have focused almost exclusively on syntactic parse trees.

Kambhatla (2004) use the path of non-terminals connecting two mentions in a parse tree as the parse tree features. $$$$$ We explicitly model the argument order of mentions.
