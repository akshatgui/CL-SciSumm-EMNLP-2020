We use an automatic topic segmentation tool, LCSeg (Galley et al, 2003) setting parameters so that the derived segments are of the approximate desired length. $$$$$ Content based features are computed by a segmentation algorithm that utilizes a metric of lexical cohesion and that performs as well as state-ofthe-art text-based segmentation techniques.
We use an automatic topic segmentation tool, LCSeg (Galley et al, 2003) setting parameters so that the derived segments are of the approximate desired length. $$$$$ The learned combination of features results in a significant increase in accuracy over previous approaches to segmentation when applied to meetings.

 $$$$$ We present a domain-independent topic segmentation algorithm for multi-party speech.
 $$$$$ Subjects were asked to mark each speaker change (potential boundary) as either boundary or non-boundary.

The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ We performed 25-fold cross-validation for evaluating the induced probabilistic classifier, computing the average of Pk and WD on the held-out meetings.
The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ On the one hand, many algorithms exploit the fact that topic segments tend to be lexically cohesive.
The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ Previous work on discourse segmentation of written texts indicates that lexical cohesion is a strong indicator of discourse structure.
The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ Table 5 gives some examples of the type of rules that are learned.

We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).
We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ In work on segmentation of spoken documents, intonational, prosodic, and acoustic indicators are used to detect topic boundaries (Grosz and Hirschberg, 1992; Nakatani et al., 1995; Hirschberg and Nakatani, 1996; Passonneau and Litman, 1997; Hirschberg and Nakatani, 1998; Beeferman et al., 1999; T¨ur et al., 2001).
We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ A pause is a silence that is attributable to a given party, for example in the middle of an adjacency pair, or when a speaker pauses in the middle of her speech.
We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ Content based features are computed by a segmentation algorithm that utilizes a metric of lexical cohesion and that performs as well as state-ofthe-art text-based segmentation techniques.

For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).
For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ These approaches use different learning mechanisms to combine features, including decision trees (Grosz and Hirschberg, 1992; Passonneau and Litman, 1997; T¨ur et al., 2001) exponential models (Beeferman et al., 1999) or other probabilistic models (Hajime et al., 1998; Reynar, 1999).
For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ Experimental results show a marked improvement in meeting segmentation with the incorporation of both sets of features.
For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ We are grateful to Julia Hirschberg, Dan Ellis, Elizabeth Shriberg, and Mari Ostendorf for their helpful advice.

Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ In this section, we describe our work on LCseg, a topic segmenter based on lexical cohesion that can handle both speech and text, but that is especially designed to generate the lexical cohesion feature used in the feature-based segmentation described in Section 5.
Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ In Section 2, we review previous approaches to the segmentation problem applied to spoken and written documents.
Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ This segmentation algorithm uses automatically induced decision rules to combine the different features.
Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ This corpus is one of a growing number of corpora with human-to-human multi-party conversations.

Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).
Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ While extensive research has targeted the problem of topic segmentation of written texts and spoken monologues, few have studied the problem of segmenting conversations with many participants (e.g., meetings).
Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ This segmentation algorithm uses automatically induced decision rules to combine the different features.
Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ In the subsequent section, we describe conversational features, such as silences, speaker change, and other features like cue phrases.

 $$$$$ In this paper, we present an algorithm for segmenting meeting transcripts.
 $$$$$ In this section, we explore formal devices that are indicative of topic shifts, and explain how we use these cues to build a segmenter targeting conversational speech.
 $$$$$ Cochran’s test evaluates the null hypothesis that the number of subjects assigning a boundary at any position is randomly distributed.
 $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.

Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ LCseg computes lexical chains, which are thought to mirror the discourse structure of the underlying text (Morris and Hirst, 1991).
Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ In this paper, we present an algorithm for segmenting meeting transcripts.
Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ A significant error reduction is obtained by combining the two knowledge sources.

For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ For every potential boundary BZ, the classifier analyzes features in a window surrounding BZ to decide whether it is a topic boundary or not.
For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ The text-based segmentation approach alone, when applied to meetings, outperforms all other segmenters, although the difference is not statistically significant.
For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ The text-based segmentation approach alone, when applied to meetings, outperforms all other segmenters, although the difference is not statistically significant.
For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ Existing approaches to textual segmentation can be broadly divided into two categories.

 $$$$$ In this section, we explore formal devices that are indicative of topic shifts, and explain how we use these cues to build a segmenter targeting conversational speech.
 $$$$$ A significant error reduction is obtained by combining the two knowledge sources.
 $$$$$ Compactness: shorter chains receive a higher weight than longer ones.

Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ Existing approaches to textual segmentation can be broadly divided into two categories.
Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ Existing approaches to textual segmentation can be broadly divided into two categories.
Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.

However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ We used Cochran’s Q (1950) to evaluate the agreement among annotators.
However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ We present a domain-independent topic segmentation algorithm for multi-party speech.
However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ Subjects were asked to mark each speaker change (potential boundary) as either boundary or non-boundary.

The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ Embodiments of this idea include semantic similarity (Morris and Hirst, 1991; Kozima, 1993), cosine similarity in word vector space (Hearst, 1994), inter-sentence similarity matrix (Reynar, 1994; Choi, 2000), entity repetition (Kan et al., 1998), word frequency models (Reynar, 1999), or adaptive language models (Beeferman et al., 1999).
The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ A significant error reduction is obtained by combining the two knowledge sources.
The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ We are grateful to Julia Hirschberg, Dan Ellis, Elizabeth Shriberg, and Mari Ostendorf for their helpful advice.
The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ Embodiments of this idea include semantic similarity (Morris and Hirst, 1991; Kozima, 1993), cosine similarity in word vector space (Hearst, 1994), inter-sentence similarity matrix (Reynar, 1994; Choi, 2000), entity repetition (Kan et al., 1998), word frequency models (Reynar, 1999), or adaptive language models (Beeferman et al., 1999).

The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ This segmentation algorithm uses automatically induced decision rules to combine the different features.
The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ We are grateful to Julia Hirschberg, Dan Ellis, Elizabeth Shriberg, and Mari Ostendorf for their helpful advice.
The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ The greedy nature of decision rule learning algorithms implies that a large set of features can lead to bad performance and generalization capability.
The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ In this corpus, recordings of meetings ranged primarily over three different recurring meeting types, all of which concerned speech or language research.1 The average duration is 60 minutes, with an average of 6.5 participants.

Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ In this section, we explore formal devices that are indicative of topic shifts, and explain how we use these cues to build a segmenter targeting conversational speech.
Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ In this paper, we present an algorithm for segmenting meeting transcripts.
Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ In this paper, we present an algorithm for segmenting meeting transcripts.
Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ The two distributions are normalized to form two probability distributions l and r, and significant changes of speakership are detected by computing their Jensen-Shannon divergence: where D(l||r) is the KL-divergence between the two distributions.

The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ Topic segmentation aims to automatically divide text documents, audio recordings, or video segments, into topically related units.
The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ Since it has been argued in (Pevzner and Hearst, 2002) that Pk has some weaknesses, we also include results according to the WindowDiff (WD) metric (which is described in the same work).
The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ The text-based segmentation approach alone, when applied to meetings, outperforms all other segmenters, although the difference is not statistically significant.
The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ It computes the 5Normalizing anything in these windows has little effect, since the cosine similarity is scale invariant, that is cosine(αxa, xb) = cosine(xa, xb) for α > 0. x-axis represent sentence indices, and y-axis represents the lexical cohesion function.

The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ Existing approaches to textual segmentation can be broadly divided into two categories.
The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ In this corpus, recordings of meetings ranged primarily over three different recurring meeting types, all of which concerned speech or language research.1 The average duration is 60 minutes, with an average of 6.5 participants.
The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ In general, we found that the derived rules show that lexical cohesion plays a stronger role than most other features in determining topic breaks.
The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ The test shows that the interjudge reliability is significant to the 0.05 level for 19 of the meetings, which seems to indicate that segment identification is a feasible task.2

Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ Subjects were asked to mark each speaker change (potential boundary) as either boundary or non-boundary.
Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ A term is any stemmed content word within the text.
Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ We present a domain-independent topic segmentation algorithm for multi-party speech.

 $$$$$ The input document is first tokenized, non-content words are removed, and remaining words are stemmed using an extension of Porter’s stemming algorithm (Xu and Croft, 1998) that conflates stems using corpus statistics.
 $$$$$ It works both with written and spoken texts.
 $$$$$ A significant error reduction is obtained by combining the two knowledge sources.
 $$$$$ We are grateful to Julia Hirschberg, Dan Ellis, Elizabeth Shriberg, and Mari Ostendorf for their helpful advice.
