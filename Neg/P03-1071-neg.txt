We use an automatic topic segmentation tool, LCSeg (Galley et al, 2003) setting parameters so that the derived segments are of the approximate desired length. $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.
We use an automatic topic segmentation tool, LCSeg (Galley et al, 2003) setting parameters so that the derived segments are of the approximate desired length. $$$$$ We thank our ICSI project partners for granting us access to the meeting corpus and for useful discussions.
We use an automatic topic segmentation tool, LCSeg (Galley et al, 2003) setting parameters so that the derived segments are of the approximate desired length. $$$$$ We thank our ICSI project partners for granting us access to the meeting corpus and for useful discussions.

 $$$$$ Our feature-based algorithm comknowledge about a text-based algorithm as a feature and linguistic and acoustic cues about topic shifts extracted from speech.
 $$$$$ We thank our ICSI project partners for granting us access to the meeting corpus and for useful discussions.
 $$$$$ LCseg depends on several parameters.
 $$$$$ Existing approaches to textual segmentation can be broadly divided into two categories.

The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ Our feature-based algorithm comknowledge about a text-based algorithm as a feature and linguistic and acoustic cues about topic shifts extracted from speech.
The gold standard for thematic segmentations has been kindly provided by (Galley et al., 2003) and has been chosen by considering the agreement between at least three human annotations. $$$$$ (Grosz and Sidner, 1986)) are generally considered to be difficult to mark reliably.

We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.
We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ We opted for a linear representation of discourse, since finer-grained discourse structures (e.g.
We evaluated WLM's performance on the ICSI meeting corpus (Janin et al 2003) by comparing our segmentation results to the results obtained by implementing LCSeg (Galley et al, 2003). $$$$$ A significant error reduction is obtained by combining the two knowledge sources.

For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ This study uses recorded meetings of typically six to eight participants, in which the informal style includes ungrammatical sentences and overlapping speakers.
For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ The preprocessing steps of LCseg are common to many segmentation algorithms.
For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ An implementation of our lexical cohesion segmenter is freely available for educational or research purposes.11
For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. $$$$$ Our feature-based algorithm comknowledge about a text-based algorithm as a feature and linguistic and acoustic cues about topic shifts extracted from speech.

Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ These meetings generally do not have pre-set agendas, and the topics discussed in the same meeting may or may not related.
Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ Our feature-based algorithm comknowledge about a text-based algorithm as a feature and linguistic and acoustic cues about topic shifts extracted from speech.
Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ For example, in Figure 2, it is clear that the contribution of individual speakers to the discussion can greatly change from one discourse unit to the next.
Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al, 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. $$$$$ In work on segmentation of spoken documents, intonational, prosodic, and acoustic indicators are used to detect topic boundaries (Grosz and Hirschberg, 1992; Nakatani et al., 1995; Hirschberg and Nakatani, 1996; Passonneau and Litman, 1997; Hirschberg and Nakatani, 1998; Beeferman et al., 1999; T¨ur et al., 2001).

Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ We presented a domain-independent segmentation algorithm for multi-party conversation that integrates features based on content with features based on form.
Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).
Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.
Adapting the standard definition of topic (Galley et al, 2003) to conversations/emails, we consider a topic is something about which the participant(s) discuss or argue or express their opinions. $$$$$ The representative example presented here is segmented by LCseg with an error of Pk = 15.79, while the average performance of the algorithm is Pk = 15.31 on the WSJ test corpus (unknown number of segments). mean and the variance of the hypothesized probabilities of all potential boundaries (local minima).

 $$$$$ In this corpus, recordings of meetings ranged primarily over three different recurring meeting types, all of which concerned speech or language research.1 The average duration is 60 minutes, with an average of 6.5 participants.
 $$$$$ This study uses recorded meetings of typically six to eight participants, in which the informal style includes ungrammatical sentences and overlapping speakers.
 $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).
 $$$$$ The text-based segmentation approach alone, when applied to meetings, outperforms all other segmenters, although the difference is not statistically significant.

Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ These approaches use different learning mechanisms to combine features, including decision trees (Grosz and Hirschberg, 1992; Passonneau and Litman, 1997; T¨ur et al., 2001) exponential models (Beeferman et al., 1999) or other probabilistic models (Hajime et al., 1998; Reynar, 1999).
Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ In work on segmentation of spoken documents, intonational, prosodic, and acoustic indicators are used to detect topic boundaries (Grosz and Hirschberg, 1992; Nakatani et al., 1995; Hirschberg and Nakatani, 1996; Passonneau and Litman, 1997; Hirschberg and Nakatani, 1998; Beeferman et al., 1999; T¨ur et al., 2001).
Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ We use statistical modeling techniques to build a classifier that uses local features (e.g. cue phrases, pauses) to determine if an utterance break corresponds to a topic boundary.
Moving to the task of segmenting dialogs, (Galley et al, 2003) first proposed the lexical chain based unsupervised segmenter (LCSeg) and a supervised segmenter for segmenting meeting transcripts. $$$$$ In this corpus, recordings of meetings ranged primarily over three different recurring meeting types, all of which concerned speech or language research.1 The average duration is 60 minutes, with an average of 6.5 participants.

For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ Subjects were asked to mark each speaker change (potential boundary) as either boundary or non-boundary.
For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ LCseg computes lexical chains, which are thought to mirror the discourse structure of the underlying text (Morris and Hirst, 1991).
For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ Such indicators include long pauses, shifts in speaking rate, great range in F0 and intensity, and higher maximum accent peak.
For the topic level, they achieve similar results as (Galley et al, 2003), with the supervised approach outperforming LCSeg. $$$$$ It is desirable to remove redundant and irrelevant features, especially in our case since we have little data labeled with topic shifts; with a large set of features, we would risk overfitting the data.

 $$$$$ The learned combination of features results in a significant increase in accuracy over previous approaches to segmentation when applied to meetings.
 $$$$$ Other algorithms exploit a variety of linguistic features that may mark topic boundaries, such as referential noun phrases (Passonneau and Litman, 1997).
 $$$$$ This score is supposed to capture the sharpness of the change in lexical cohesion, and give probabilities close to 1 for breaks like sentence 179 in Figure 1.
 $$$$$ Such indicators include long pauses, shifts in speaking rate, great range in F0 and intensity, and higher maximum accent peak.

Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ Topic segmentation is reduced here to a classification problem, where each utterance break Bi is either considered a topic boundary or not.
Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ While extensive research has targeted the problem of topic segmentation of written texts and spoken monologues, few have studied the problem of segmenting conversations with many participants (e.g., meetings).
Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ Cue phrases: previous work on segmentation has found that discourse particles like now, well provide valuable information about the structure of texts (Grosz and Sidner, 1986; Hirschberg and Litman, 1994; Passonneau and Litman, 1997).
Our second model is the lexical chain based segmenter LCSeg, (Galley et al, 2003). $$$$$ The chain is divided into subchains when there is a long hiatus of h consecutive sentences with no occurrence of the term, where h is determined experimentally.

However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ This component mainly relies on lexical cohesion, particularly term repetition, to detect topic boundaries.
However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ Existing approaches to textual segmentation can be broadly divided into two categories.
However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ Other algorithms exploit a variety of linguistic features that may mark topic boundaries, such as referential noun phrases (Passonneau and Litman, 1997).
However, Galley et al, (Galley et al, 2003) uses only repetition relation as previous research results (e.g., (Choi, 2000)) account only for repetition. $$$$$ This segmentation algorithm uses automatically induced decision rules to combine the different features.

The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ While other relations between lexical items also work as cohesive factors (e.g. between a term and its super-ordinate), the work on linear topic segmentation reporting the most promising results account for term repetitions alone (Choi, 2000; Utiyama and Isahara, 2001).
The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ These approaches use different learning mechanisms to combine features, including decision trees (Grosz and Hirschberg, 1992; Passonneau and Litman, 1997; T¨ur et al., 2001) exponential models (Beeferman et al., 1999) or other probabilistic models (Hajime et al., 1998; Reynar, 1999).
The first dataset is a subset of the ICSI-MR corpus (Janin et al, 2004), where the gold standard for thematic segmentations has been provided by taking into account the agreement of at least three human annotators (Galley et al, 2003). $$$$$ For example, in Figure 2, it is clear that the contribution of individual speakers to the discussion can greatly change from one discourse unit to the next.

The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ Our feature-based algorithm comknowledge about a text-based algorithm as a feature and linguistic and acoustic cues about topic shifts extracted from speech.
The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ Other algorithms exploit a variety of linguistic features that may mark topic boundaries, such as referential noun phrases (Passonneau and Litman, 1997).
The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ This segmentation algorithm uses automatically induced decision rules to combine the different features.
The LCseg system (Galley et al, 2003), labeled here as G03, is to our knowledge the only word distribution based system evaluated on ICSI meeting data. $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.

Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ In work on segmentation of spoken documents, intonational, prosodic, and acoustic indicators are used to detect topic boundaries (Grosz and Hirschberg, 1992; Nakatani et al., 1995; Hirschberg and Nakatani, 1996; Passonneau and Litman, 1997; Hirschberg and Nakatani, 1998; Beeferman et al., 1999; T¨ur et al., 2001).
Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ We are grateful to Julia Hirschberg, Dan Ellis, Elizabeth Shriberg, and Mari Ostendorf for their helpful advice.
Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.
Therefore, we replicate the results reported by (Galley et al, 2003) when evaluation of LCseg was done on ICSI data. $$$$$ While the correlation between long silences and discourse boundaries seem to be less pervasive in meetings than in other speech corpora, we have noticed that some topic boundaries are preceded (within some window) by numerous gaps.

The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ Subjects were asked to mark each speaker change (potential boundary) as either boundary or non-boundary.
The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ A significant error reduction is obtained by combining the two knowledge sources.
The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ This study uses recorded meetings of typically six to eight participants, in which the informal style includes ungrammatical sentences and overlapping speakers.
The so-labeled G03* algorithm indicates the error rates obtained by (Galley et al, 2003) when extra (meeting specific) features have been adopted in a decision tree classifier. $$$$$ It works both with written and spoken texts.

The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ In future work, we would like to investigate the effects of adding prosodic features, such as pitch ranges, to our segmenter, as well as the effect of using errorful speech recognition transcripts as opposed to manually transcribed utterances.
The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information.
The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ This work was funded under the NSF project Mapping Meetings (IIS-012196).
The work of (Galley et al, 2003) shows that the G03* algorithm is better than G03 by approximately 10%, which indicates that on meeting data the performance of our word-distribution based approach could possibly be increased by using other meeting-specific features. $$$$$ We thank our ICSI project partners for granting us access to the meeting corpus and for useful discussions.

Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ An implementation of our lexical cohesion segmenter is freely available for educational or research purposes.11
Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ In this paper, we present an algorithm for segmenting meeting transcripts.
Our feature set incorporates information which has proven useful in meeting segmentation (Galley et al, 2003) and the task of detecting addressees of a specific utterance in a meeting (Jovanovic et al, 2006). $$$$$ We presented a domain-independent segmentation algorithm for multi-party conversation that integrates features based on content with features based on form.

 $$$$$ We thank our ICSI project partners for granting us access to the meeting corpus and for useful discussions.
 $$$$$ From the corpus, we selected 25 meetings to be segmented, each by at least three subjects.
 $$$$$ This segmentation algorithm uses automatically induced decision rules to combine the different features.
