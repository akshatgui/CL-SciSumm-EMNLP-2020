In comparison, (Yarowsky, 1995) achieved 91.4% correct performance, using 1380 contexts and the dictionary definitions in training. $$$$$ Tested accuracy exceeds 96%.
In comparison, (Yarowsky, 1995) achieved 91.4% correct performance, using 1380 contexts and the dictionary definitions in training. $$$$$ It is very much stronger for collocations with content words than those with function words.'
In comparison, (Yarowsky, 1995) achieved 91.4% correct performance, using 1380 contexts and the dictionary definitions in training. $$$$$ Using the salient words of a dictionary definition as seeds increases the coverage of the concept space, improving accuracy (94.8%).
In comparison, (Yarowsky, 1995) achieved 91.4% correct performance, using 1380 contexts and the dictionary definitions in training. $$$$$ SENSE-A seeds plus newly added examples) will tend to grow, while the residual will tend to shrink.

Recently, Yarowsky (1995) combined a MIlD and a corpus in a bootstrapping process. $$$$$ This augmentation of the training data can often form a bridge to new collocations that may not otherwise co-occur in the same nearby context with previously identified collocations.
Recently, Yarowsky (1995) combined a MIlD and a corpus in a bootstrapping process. $$$$$ The decision list algorithm resolves any conflicts by using only the single most reliable piece of evidence, not a combination of all matching collocations.
Recently, Yarowsky (1995) combined a MIlD and a corpus in a bootstrapping process. $$$$$ It thus uses more discriminating information than available to algorithms treating documents as bags of words, ignoring relative position and sequence.

Another line of research is to pick up some high-quality auto-parsed training instances from unlabeled data using bootstrapping methods, such as self-training (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and tri-training (Zhou and Li, 2005). $$$$$ The work reported here is the first to take advantage of this regularity in conjunction with separate models of local context for each word.
Another line of research is to pick up some high-quality auto-parsed training instances from unlabeled data using bootstrapping methods, such as self-training (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and tri-training (Zhou and Li, 2005). $$$$$ Tested accuracy exceeds 96%.
Another line of research is to pick up some high-quality auto-parsed training instances from unlabeled data using bootstrapping methods, such as self-training (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and tri-training (Zhou and Li, 2005). $$$$$ If cumulative evidence for the majority sense exceeds that of the minority by a threshold (conditional on n), the minority cases are relabeled.
Another line of research is to pick up some high-quality auto-parsed training instances from unlabeled data using bootstrapping methods, such as self-training (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and tri-training (Zhou and Li, 2005). $$$$$ 'Here I use the traditional dictionary definition of collocation — &quot;appearing in the same location; a juxtaposition of words&quot;.

Yarowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD model. $$$$$ The algorithm should begin with seed words that accurately and productively distinguish the possible senses.
Yarowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD model. $$$$$ Words in the entry appearing in the most reliable collocational relationships with the target word are given the most weight, based on the criteria given in Yarowsky (1993).

This heuristic naturally reflects the broadly known assumption about lexical ambiguity presented in (Yarowsky, 1995), namely the one-sense-per-discourse heuristic. $$$$$ In contrast, our algorithm models these properties carefully, adding considerable discriminating power lost in other relatively impoverished models of language.
This heuristic naturally reflects the broadly known assumption about lexical ambiguity presented in (Yarowsky, 1995), namely the one-sense-per-discourse heuristic. $$$$$ Words that co-occur with the target word in unusually great frequency, especially in certain collocational relationships, will tend to be reliable indicators of one of the target word's senses (e.g. flock and bulldozer for &quot;crane&quot;).
This heuristic naturally reflects the broadly known assumption about lexical ambiguity presented in (Yarowsky, 1995), namely the one-sense-per-discourse heuristic. $$$$$ IIf their classification begins to waver because new examples have discredited the crucial collocate, they are returned to the residual and may later be classified differently.

This heuristic mimes the one-sense-per collocation heuristic presented in (Yarowsky, 1995). $$$$$ In the example below, the words life and manufacturing are used as seed collocations for the two major senses of plant (labeled A and B respectively).
This heuristic mimes the one-sense-per collocation heuristic presented in (Yarowsky, 1995). $$$$$ The training sets (e.g.
This heuristic mimes the one-sense-per collocation heuristic presented in (Yarowsky, 1995). $$$$$ Tested accuracy exceeds 96%.
This heuristic mimes the one-sense-per collocation heuristic presented in (Yarowsky, 1995). $$$$$ Comparative performance: Column 5 shows the relative performance of supervised training using the decision list algorithm, applied to the same data and not using any discourse information.

These include the bootstrapping approach [Yarowsky 1995] and the context clustering approach [Schutze 1998]. $$$$$ The algorithm is based on two powerful constraints — that words tend to have one sense per discourse and one sense per collocation — exploited in an iterative bootstrapping procedure.
These include the bootstrapping approach [Yarowsky 1995] and the context clustering approach [Schutze 1998]. $$$$$ Examples added to the the growing seed sets remain there only as long as the probability of the classification stays above the threshold.
These include the bootstrapping approach [Yarowsky 1995] and the context clustering approach [Schutze 1998]. $$$$$ The acquisition of additional partitioning collocations from cooccurrence with previously-identified ones is illustrated in the lower portion of Figure 2.
These include the bootstrapping approach [Yarowsky 1995] and the context clustering approach [Schutze 1998]. $$$$$ Also, for an unsupervised algorithm it works surprisingly well, directly outperforming Schiitze's unsupervised algorithm 96.7 % to 92.2 %, on a test of the same 4 words.

Yarowsky (1995) presented an approach that significantly reduces the amount of labeled data needed forword sense disambiguation. $$$$$ This would indicate that the cost of a large sense-tagged training corpus may not be necessary to achieve accurate word-sense disambiguation.
Yarowsky (1995) presented an approach that significantly reduces the amount of labeled data needed forword sense disambiguation. $$$$$ We have yet to use this additional information.
Yarowsky (1995) presented an approach that significantly reduces the amount of labeled data needed forword sense disambiguation. $$$$$ Co-occurrence analysis selects collocates that span the space with minimal overlap, optimizing the efforts of the human assistant.

Many of these tasks have been addressed in other fields, for example, hypothesis verification in the field of machine translation (Tran et al, 1996), sense disambiguation in speech synthesis (Yarowsky, 1995), and relation tagging in information retrieval (Marsh and Perzanowski, 1999). $$$$$ However, accuracy can be improved by also exploiting the fact that all occurrences of a word in the discourse are likely to exhibit the same sense.
Many of these tasks have been addressed in other fields, for example, hypothesis verification in the field of machine translation (Tran et al, 1996), sense disambiguation in speech synthesis (Yarowsky, 1995), and relation tagging in information retrieval (Marsh and Perzanowski, 1999). $$$$$ Dagan and Itai (1994) have proposed a method using co-occurrence statistics in independent monolingual corpora of two languages to guide lexical choice in machine translation.
Many of these tasks have been addressed in other fields, for example, hypothesis verification in the field of machine translation (Tran et al, 1996), sense disambiguation in speech synthesis (Yarowsky, 1995), and relation tagging in information retrieval (Marsh and Perzanowski, 1999). $$$$$ No idiomatic or non-compositional interpretation is implied. for each sense, This procedure is robust and selfcorrecting, and exhibits many strengths of supervised approaches, including sensitivity to word-order information lost in earlier unsupervised algorithms.
Many of these tasks have been addressed in other fields, for example, hypothesis verification in the field of machine translation (Tran et al, 1996), sense disambiguation in speech synthesis (Yarowsky, 1995), and relation tagging in information retrieval (Marsh and Perzanowski, 1999). $$$$$ This paper presents an unsupervised algorithm that can accurately disambiguate word senses in a large, completely untagged corpus.1 The algorithm avoids the need for costly hand-tagged training data by exploiting two powerful properties of human language: Moreover, language is highly redundant, so that the sense of a word is effectively overdetermined by (1) and (2) above.

Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis. $$$$$ ... vinyl chloride monomer plant, which is ... ?
Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis. $$$$$ In contrast, our algorithm uses automatically acquired seeds to tie the sense partitions to the desired standard at the beginning, where it can be most useful as an anchor and guide.
Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis. $$$$$ The bulk of the sample points &quot;?&quot; constitute the untagged residual.

The idea of sense consistency was first introduced and extended to operate across related documents by (Yarowsky, 1995). $$$$$ A human judge must decide which one, but this can be done very quickly (typically under 2 minutes for a full list of 30-60 such words).
The idea of sense consistency was first introduced and extended to operate across related documents by (Yarowsky, 1995). $$$$$ Repeat Step 3 iteratively.
The idea of sense consistency was first introduced and extended to operate across related documents by (Yarowsky, 1995). $$$$$ This effect varies depending on the type of collocation.
The idea of sense consistency was first introduced and extended to operate across related documents by (Yarowsky, 1995). $$$$$ Repeat Step 3 iteratively.

This method, initially proposed by (Yarowsky, 1995), was successfully evaluated in the context of the SENSEVAL framework (Mihalcea, 2002). $$$$$ Other unsupervised methods have shown great promise.
This method, initially proposed by (Yarowsky, 1995), was successfully evaluated in the context of the SENSEVAL framework (Mihalcea, 2002). $$$$$ Although there is some hope from using aligned bilingual corpora as training data for supervised algorithms (Brown et al., 1991), this approach suffers from both the limited availability of such corpora, and the frequent failure of bilingual translation differences to model monolingual sense differences.
This method, initially proposed by (Yarowsky, 1995), was successfully evaluated in the context of the SENSEVAL framework (Mihalcea, 2002). $$$$$ Columns 9 and 10 illustrate the effect of adding the probabilistic one-sense-per-discourse constraint to collocation-based models using dictionary entries as training seeds.

See Yarowsky (1995) for details. $$$$$ No idiomatic or non-compositional interpretation is implied. for each sense, This procedure is robust and selfcorrecting, and exhibits many strengths of supervised approaches, including sensitivity to word-order information lost in earlier unsupervised algorithms.
See Yarowsky (1995) for details. $$$$$ In essence, our algorithm works by harnessing several powerful, empirically-observed properties of language, namely the strong tendency for words to exhibit only one sense per collocation and per discourse.
See Yarowsky (1995) for details. $$$$$ Words in the entry appearing in the most reliable collocational relationships with the target word are given the most weight, based on the criteria given in Yarowsky (1993).

The well-known observation that words rarely exhibit more than one sense per discourse (Yarowsky, 1995) implies that features closely associated with a particular sense have a low probability of appearing in the same document as features associated with another sense. $$$$$ The observation that words strongly tend to exhibit only one sense in a given discourse or document was stated and quantified in Gale, Church and Yarowsky (1992).
The well-known observation that words rarely exhibit more than one sense per discourse (Yarowsky, 1995) implies that features closely associated with a particular sense have a low probability of appearing in the same document as features associated with another sense. $$$$$ The strong tendency for words to exhibit only one sense in a given collocation was observed and quantified in (Yarowsky, 1993).
The well-known observation that words rarely exhibit more than one sense per discourse (Yarowsky, 1995) implies that features closely associated with a particular sense have a low probability of appearing in the same document as features associated with another sense. $$$$$ This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations.

Yarowsky (1995) first recognized that it is possible to use a small number of features for different senses to bootstrap an unsupervised word sense disambiguation system. $$$$$ No idiomatic or non-compositional interpretation is implied. for each sense, This procedure is robust and selfcorrecting, and exhibits many strengths of supervised approaches, including sensitivity to word-order information lost in earlier unsupervised algorithms.
Yarowsky (1995) first recognized that it is possible to use a small number of features for different senses to bootstrap an unsupervised word sense disambiguation system. $$$$$ More impressively, it achieves nearly the same performance as the supervised algorithm given identical training contexts (95.5 % vs. 96.1 %) , and in some cases actually achieves superior performance when using the one-sense-perdiscourse constraint (96.5 % vs. 96.1%).
Yarowsky (1995) first recognized that it is possible to use a small number of features for different senses to bootstrap an unsupervised word sense disambiguation system. $$$$$ The major difference is that in discourses where there is substantial disagreement concerning which is the dominant sense, all instances in the discourse are returned to the residual rather than merely leaving their current tags unchanged.
Yarowsky (1995) first recognized that it is possible to use a small number of features for different senses to bootstrap an unsupervised word sense disambiguation system. $$$$$ Using the salient words of a dictionary definition as seeds increases the coverage of the concept space, improving accuracy (94.8%).

Self-training (Yarowsky, 1995) is a semi supervised algorithm which has been well studied in the NLP area and gained promising result. $$$$$ The major difference is that in discourses where there is substantial disagreement concerning which is the dominant sense, all instances in the discourse are returned to the residual rather than merely leaving their current tags unchanged.
Self-training (Yarowsky, 1995) is a semi supervised algorithm which has been well studied in the NLP area and gained promising result. $$$$$ This differs from sense induction: using distributional similarity to partition word instances into clusters that may have no relation to standard sense partitions.
Self-training (Yarowsky, 1995) is a semi supervised algorithm which has been well studied in the NLP area and gained promising result. $$$$$ The fundamental limitation of this property is coverage.
Self-training (Yarowsky, 1995) is a semi supervised algorithm which has been well studied in the NLP area and gained promising result. $$$$$ Similarly, the one-sense-per-discourse constraint may also be used to correct erroneously labeled examples.

The algorithm proposed by Yarowsky (1995) for the problem of word sense disambiguation has been cited as the origination of self-training. $$$$$ They include words where sense differences are realized as differences in French translation (drug drogue/medicament, and duty .&quot;-P devoir/droit), a verb (poach) and words used in Schiitze's 1992 disambiguation experiments (tank, space, motion, plant).1° The data were extracted from a 460 million word corpus containing news articles, scientific abstracts, spoken transcripts, and novels, and almost certainly constitute the largest training/testing sets used in the sense-disambiguation literature.
The algorithm proposed by Yarowsky (1995) for the problem of word sense disambiguation has been cited as the origination of self-training. $$$$$ The redundancy of language with respect to collocation makes the process primarily self-correcting.
The algorithm proposed by Yarowsky (1995) for the problem of word sense disambiguation has been cited as the origination of self-training. $$$$$ However, spurious words in example sentences can be a source of noise.
The algorithm proposed by Yarowsky (1995) for the problem of word sense disambiguation has been cited as the origination of self-training. $$$$$ For example: TIndeed, any supervised classification algorithm that returns probabilities with its classifications may potentially be used here.

For the fine-grained track, it achieves 2nd place after that of Tugwell and Kilgarriff (2001), which used a decision list (Yarowsky, 1995) on manually selected corpora evidence for each inventory sense, and thus is not subject to loss of distinguishability in the glosses as Lesk variants are. $$$$$ Clearly, the claim holds with very high reliability for these words, and may be confidently exploited as another source of evidence in sense tagging.'
For the fine-grained track, it achieves 2nd place after that of Tugwell and Kilgarriff (2001), which used a decision list (Yarowsky, 1995) on manually selected corpora evidence for each inventory sense, and thus is not subject to loss of distinguishability in the glosses as Lesk variants are. $$$$$ The variables in this decision are the total number of occurrences of plant in the discourse (n), the number of occurrences assigned to the majority and minor senses for the discourse, and the cumulative scores for both (a sum of log-likelihood ratios).
For the fine-grained track, it achieves 2nd place after that of Tugwell and Kilgarriff (2001), which used a decision list (Yarowsky, 1995) on manually selected corpora evidence for each inventory sense, and thus is not subject to loss of distinguishability in the glosses as Lesk variants are. $$$$$ Regardless of origin, this phenomenon is strong enough to be of significant practical use as an additional probabilistic disambiguation constraint.
For the fine-grained track, it achieves 2nd place after that of Tugwell and Kilgarriff (2001), which used a decision list (Yarowsky, 1995) on manually selected corpora evidence for each inventory sense, and thus is not subject to loss of distinguishability in the glosses as Lesk variants are. $$$$$ The decision list algorithm resolves any conflicts by using only the single most reliable piece of evidence, not a combination of all matching collocations.

Two more recent investigations are by Yarowsky, (Yarowsky, 1995), and later, Mihalcea, (Mihalcea,2002). $$$$$ Yet to date, the full power of this property has not been exploited for sense disambiguation.
Two more recent investigations are by Yarowsky, (Yarowsky, 1995), and later, Mihalcea, (Mihalcea,2002). $$$$$ When a polysemous word such as plant occurs multiple times in a discourse, tokens that were tagged by the algorithm with low confidence using local collocation information may be overridden by the dominant tag for the discourse.
Two more recent investigations are by Yarowsky, (Yarowsky, 1995), and later, Mihalcea, (Mihalcea,2002). $$$$$ Note that most training examples will exhibit multiple collocations indicative of the same sense (as illustrated in Figure 3).
Two more recent investigations are by Yarowsky, (Yarowsky, 1995), and later, Mihalcea, (Mihalcea,2002). $$$$$ For these words, the table below measures the claim's accuracy (when the word occurs more than once in a discourse, how often it takes on the majority sense for the discourse) and applicability (how often the word does occur more than once in a discourse).

Self-training (Yarowsky, 1995) is a form of semi-supervised learning. $$$$$ Additional details aimed at correcting and avoiding misclassifications will be discussed in Section 6.
Self-training (Yarowsky, 1995) is a form of semi-supervised learning. $$$$$ However, certain strong collocates may become entrenched as indicators for the wrong class.
Self-training (Yarowsky, 1995) is a form of semi-supervised learning. $$$$$ The decision list algorithm resolves any conflicts by using only the single most reliable piece of evidence, not a combination of all matching collocations.
Self-training (Yarowsky, 1995) is a form of semi-supervised learning. $$$$$ Also, for an unsupervised algorithm it works surprisingly well, directly outperforming Schiitze's unsupervised algorithm 96.7 % to 92.2 %, on a test of the same 4 words.
