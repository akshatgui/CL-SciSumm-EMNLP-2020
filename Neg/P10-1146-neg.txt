Chiang (2010) also obtained significant improvement over his hierarchical baseline by using syntactic parse trees on both source and target sides to induce fuzzy (not exact) tree-to-tree rules and by also allowing syntactically mismatched substitutions. $$$$$ First, Table 4 shows that the system using the tree-to-tree grammar used the glue rule much less and performed more matching substitutions.
Chiang (2010) also obtained significant improvement over his hierarchical baseline by using syntactic parse trees on both source and target sides to induce fuzzy (not exact) tree-to-tree rules and by also allowing syntactically mismatched substitutions. $$$$$ Indeed, we have found that the model learns on its own to choose syntactically richer and more wellformed structures, demonstrating that source- and target-side syntax can be used together profitably as long as they are not allowed to overconstrain the translation model.
Chiang (2010) also obtained significant improvement over his hierarchical baseline by using syntactic parse trees on both source and target sides to induce fuzzy (not exact) tree-to-tree rules and by also allowing syntactically mismatched substitutions. $$$$$ This limit controls how deeply nested the tree structures built by the decoder are, and we want to see whether adding syntactic information leads to more complex structures.

Chiang (2010) also avoided hard constraints and took a soft alternative that directly models the cost of mismatched rule substitutions. $$$$$ Tables 5 and 6 show how the new syntax features affected particular substitutions.
Chiang (2010) also avoided hard constraints and took a soft alternative that directly models the cost of mismatched rule substitutions. $$$$$ First, Table 4 shows that the system using the tree-to-tree grammar used the glue rule much less and performed more matching substitutions.
Chiang (2010) also avoided hard constraints and took a soft alternative that directly models the cost of mismatched rule substitutions. $$$$$ But progress has been slower on translation models that are able to learn the relationship between the grammars of both the source and target language.
Chiang (2010) also avoided hard constraints and took a soft alternative that directly models the cost of mismatched rule substitutions. $$$$$ We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a simple approach that uses both source and target syntax for significant improvements in translation accuracy.

 $$$$$ The simplest of these (Chiang, 2005) make no use of information from syntactic theories or syntactic annotations, whereas others have successfully incorporated syntactic information on the target side (Galley et al., 2004; Galley et al., 2006) or the source side (Liu et al., 2006; Huang et al., 2006).
 $$$$$ Furthermore, neither “surplus...shores” nor its Chinese counterpart are constituents.

SAMT extension with source and target-side syntax described by Chiang (2010). $$$$$ But both rules are arguably useful for translation.
SAMT extension with source and target-side syntax described by Chiang (2010). $$$$$ Though exact tree-to-tree translation tends to hamper translation quality by imposing too many constraints during both grammar extraction and decoding, we have shown that using both source and target syntax improves translation accuracy when the model is given the opportunity to learn from data how strongly to apply syntactic constraints.
SAMT extension with source and target-side syntax described by Chiang (2010). $$$$$ S. D. G. rewrites in Chinese-English translation between string-to-string (s-to-s) and fuzzy tree-to-tree (t-tot) grammars.

In future work, the problem could be addressed by reconsidering our naming scheme for virtual nodes, by allowing fuzzy matching of labels at translation time (Chiang, 2010), or by other techniques aimed at reducing the size of the overall nonterminal set. $$$$$ In experiments on Chinese-English and ArabicEnglish translation, we find that when both source and target syntax are made available to the model in an unobtrusive way, the model chooses to build structures that are more syntactically well-formed and yield significantly better translations than a nonsyntactic hierarchical phrase-based model.
In future work, the problem could be addressed by reconsidering our naming scheme for virtual nodes, by allowing fuzzy matching of labels at translation time (Chiang, 2010), or by other techniques aimed at reducing the size of the overall nonterminal set. $$$$$ Though exact tree-to-tree translation tends to hamper translation quality by imposing too many constraints during both grammar extraction and decoding, we have shown that using both source and target syntax improves translation accuracy when the model is given the opportunity to learn from data how strongly to apply syntactic constraints.
In future work, the problem could be addressed by reconsidering our naming scheme for virtual nodes, by allowing fuzzy matching of labels at translation time (Chiang, 2010), or by other techniques aimed at reducing the size of the overall nonterminal set. $$$$$ Tables 5 and 6 show how the new syntax features affected particular substitutions.

Although MT systems that employ syntactic or hierarchical information have recently shown improvements over phrase-based approaches (Chiang, 2010), our initial investigation with syntactically driven approaches showed poorer performance on the text simplification task and were less robust to noise in the training data. $$$$$ Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years.
Although MT systems that employ syntactic or hierarchical information have recently shown improvements over phrase-based approaches (Chiang, 2010), our initial investigation with syntactically driven approaches showed poorer performance on the text simplification task and were less robust to noise in the training data. $$$$$ Indeed, we have found that the model learns on its own to choose syntactically richer and more wellformed structures, demonstrating that source- and target-side syntax can be used together profitably as long as they are not allowed to overconstrain the translation model.
Although MT systems that employ syntactic or hierarchical information have recently shown improvements over phrase-based approaches (Chiang, 2010), our initial investigation with syntactically driven approaches showed poorer performance on the text simplification task and were less robust to noise in the training data. $$$$$ Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years.
Although MT systems that employ syntactic or hierarchical information have recently shown improvements over phrase-based approaches (Chiang, 2010), our initial investigation with syntactically driven approaches showed poorer performance on the text simplification task and were less robust to noise in the training data. $$$$$ Indeed, we have found that the model learns on its own to choose syntactically richer and more wellformed structures, demonstrating that source- and target-side syntax can be used together profitably as long as they are not allowed to overconstrain the translation model.

The string-to-tree (Galleyet al 2006) and tree-to-tree (Chiang, 2010) methods have also been the subject of experimentation, as well as other formalisms such as Dependency Trees (Shen et al, 2008). $$$$$ To do this, we add the following features to the model: iments.
The string-to-tree (Galleyet al 2006) and tree-to-tree (Chiang, 2010) methods have also been the subject of experimentation, as well as other formalisms such as Dependency Trees (Shen et al, 2008). $$$$$ All rewrites occurring more than 1% of the time in either system are shown, plus a few more of interest.
The string-to-tree (Galleyet al 2006) and tree-to-tree (Chiang, 2010) methods have also been the subject of experimentation, as well as other formalisms such as Dependency Trees (Shen et al, 2008). $$$$$ In experiments on Chinese-English and ArabicEnglish translation, we find that when both source and target syntax are made available to the model in an unobtrusive way, the model chooses to build structures that are more syntactically well-formed and yield significantly better translations than a nonsyntactic hierarchical phrase-based model.
The string-to-tree (Galleyet al 2006) and tree-to-tree (Chiang, 2010) methods have also been the subject of experimentation, as well as other formalisms such as Dependency Trees (Shen et al, 2008). $$$$$ Any STSSG can be converted into an equivalent STSG via the creation of virtual nodes (see Figure 3b): for every elementary tree sequence with roots X1, ... , Xn, create a new root node with a that differ only in their nonterminal labels, only the most-frequent rule is kept, and its count is the total count of all the rules.

The reported results show that while utilizing linguistic information helps, the coverage is more important (Chiang, 2010). $$$$$ These models make use of varying amounts of information from linguistic theory: some use none at all, some use information about the grammar of the target language, some use information about the grammar of the source language.
The reported results show that while utilizing linguistic information helps, the coverage is more important (Chiang, 2010). $$$$$ On the English side, the high attachment of the PP disagrees with the corresponding Chinese structure, but low attachment also seems reasonable: Thus even in the gold-standard parse trees, phrase structure can be underspecified (like the flat IP above) or uncertain (like the PP attachment above).
The reported results show that while utilizing linguistic information helps, the coverage is more important (Chiang, 2010). $$$$$ The label “entity” stands for handwritten rules for named entities and numbers.
The reported results show that while utilizing linguistic information helps, the coverage is more important (Chiang, 2010). $$$$$ Statistical translation models that use synchronous context-free grammars (SCFGs) or related formalisms to try to capture the recursive structure of language have been widely adopted over the last few years.

Chiang (2010) extended SAMT-style labels to both source and target-side parses, also introducing a mechanism by which SCFG rules may apply at runtime even if their labels do not match. $$$$$ These models make use of varying amounts of information from linguistic theory: some use none at all, some use information about the grammar of the target language, some use information about the grammar of the source language.
Chiang (2010) extended SAMT-style labels to both source and target-side parses, also introducing a mechanism by which SCFG rules may apply at runtime even if their labels do not match. $$$$$ Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years.
Chiang (2010) extended SAMT-style labels to both source and target-side parses, also introducing a mechanism by which SCFG rules may apply at runtime even if their labels do not match. $$$$$ First, Table 4 shows that the system using the tree-to-tree grammar used the glue rule much less and performed more matching substitutions.
Chiang (2010) extended SAMT-style labels to both source and target-side parses, also introducing a mechanism by which SCFG rules may apply at runtime even if their labels do not match. $$$$$ Though exact tree-to-tree translation tends to hamper translation quality by imposing too many constraints during both grammar extraction and decoding, we have shown that using both source and target syntax improves translation accuracy when the model is given the opportunity to learn from data how strongly to apply syntactic constraints.

However, as discussed by Chiang (2010), while tree-to-tree translation is indeed promising in theory, in practice it usually ends up over-constrained. $$$$$ This research was supported in part by DARPA contract HR0011-06-C-0022 under subcontract to BBN Technologies and DARPA contract HR0011-09-1-0028.
However, as discussed by Chiang (2010), while tree-to-tree translation is indeed promising in theory, in practice it usually ends up over-constrained. $$$$$ Though exact tree-to-tree translation tends to hamper translation quality by imposing too many constraints during both grammar extraction and decoding, we have shown that using both source and target syntax improves translation accuracy when the model is given the opportunity to learn from data how strongly to apply syntactic constraints.
However, as discussed by Chiang (2010), while tree-to-tree translation is indeed promising in theory, in practice it usually ends up over-constrained. $$$$$ We then compared against two systems using tree-to-tree grammars.
However, as discussed by Chiang (2010), while tree-to-tree translation is indeed promising in theory, in practice it usually ends up over-constrained. $$$$$ S. D. G. rewrites in Chinese-English translation between string-to-string (s-to-s) and fuzzy tree-to-tree (t-tot) grammars.

Inspired by Chiang (2010), we adopt a fuzzy way to label every source string with the complex syntactic categories of SAMT (Zollmann and Venugopal, 2006). $$$$$ We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a simple approach that uses both source and target syntax for significant improvements in translation accuracy.
Inspired by Chiang (2010), we adopt a fuzzy way to label every source string with the complex syntactic categories of SAMT (Zollmann and Venugopal, 2006). $$$$$ On the English side, the high attachment of the PP disagrees with the corresponding Chinese structure, but low attachment also seems reasonable: Thus even in the gold-standard parse trees, phrase structure can be underspecified (like the flat IP above) or uncertain (like the PP attachment above).
Inspired by Chiang (2010), we adopt a fuzzy way to label every source string with the complex syntactic categories of SAMT (Zollmann and Venugopal, 2006). $$$$$ Tables 5 and 6 show how the new syntax features affected particular substitutions.
Inspired by Chiang (2010), we adopt a fuzzy way to label every source string with the complex syntactic categories of SAMT (Zollmann and Venugopal, 2006). $$$$$ All rewrites occurring more than 1% of the time in either system are shown.

However, as noted by Lavie et al. (2008), Liu et al. (2009), and Chiang (2010), the integration of syntactic information on both sides tends to decrease translation quality because the systems be come too restrictive. $$$$$ The label “entity” stands for handwritten rules for named entities and numbers. rewrites in Chinese-English translation between string-to-string (s-to-s) and fuzzy tree-to-tree (tto-t) grammars.
However, as noted by Lavie et al. (2008), Liu et al. (2009), and Chiang (2010), the integration of syntactic information on both sides tends to decrease translation quality because the systems be come too restrictive. $$$$$ We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a simple approach that uses both source and target syntax for significant improvements in translation accuracy.
However, as noted by Lavie et al. (2008), Liu et al. (2009), and Chiang (2010), the integration of syntactic information on both sides tends to decrease translation quality because the systems be come too restrictive. $$$$$ Drawing on previous successful attempts to relax syntactic constraints during grammar extraction in various ways (Zhang et al., 2008; Liu et al., 2009; Zollmann and Venugopal, 2006), we compare several methods for extracting a synchronous grammar from tree-to-tree data.
However, as noted by Lavie et al. (2008), Liu et al. (2009), and Chiang (2010), the integration of syntactic information on both sides tends to decrease translation quality because the systems be come too restrictive. $$$$$ But in some cases we may want to soften the matching constraint itself.

Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). $$$$$ We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a simple approach that uses both source and target syntax for significant improvements in translation accuracy.
Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). $$$$$ For all systems but the baselines, the features described in Section 3 were added.
Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). $$$$$ Though exact tree-to-tree translation tends to hamper translation quality by imposing too many constraints during both grammar extraction and decoding, we have shown that using both source and target syntax improves translation accuracy when the model is given the opportunity to learn from data how strongly to apply syntactic constraints.
Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). $$$$$ The two Chinese phrases (4) and (5) cross, and therefore cannot both be constituents in the same tree.

Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). $$$$$ For all systems but the baselines, the features described in Section 3 were added.
Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). $$$$$ The simplest of these (Chiang, 2005) make no use of information from syntactic theories or syntactic annotations, whereas others have successfully incorporated syntactic information on the target side (Galley et al., 2004; Galley et al., 2006) or the source side (Liu et al., 2006; Huang et al., 2006).

Chiang (2010) proposes a method for learning to translate with both source and target syntax in the framework of a hierarchical. $$$$$ Though exact tree-to-tree translation tends to hamper translation quality by imposing too many constraints during both grammar extraction and decoding, we have shown that using both source and target syntax improves translation accuracy when the model is given the opportunity to learn from data how strongly to apply syntactic constraints.

Tellingly, in the entire proceedings of ACL 2010 (Hajic et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT. $$$$$ Indeed, we have found that the model learns on its own to choose syntactically richer and more wellformed structures, demonstrating that source- and target-side syntax can be used together profitably as long as they are not allowed to overconstrain the translation model.
Tellingly, in the entire proceedings of ACL 2010 (Hajic et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT. $$$$$ This suggests that the strength of fuzzy tree-to-tree extraction lies in its ability to break up flat structures and to reconcile the source and target trees with each other, rather than multiple restructurings of the training trees.
Tellingly, in the entire proceedings of ACL 2010 (Hajic et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT. $$$$$ For example, a translation with the rewriting NP-C —* DT \ NP-C begins with “24th meeting of the Standing Committee...,” but the system using the fuzzy tree-to-tree grammar changes this to “The 24th meeting of the Standing Committee....” The root features had a less noticeable effect on rule choice; one interesting change was that the frequency of rules with Chinese root VP / IP and English root VP / S-C increased from 0.2% to 0.7%: apparently the model learned that it is good to use rules that pair Chinese and English verbs that subcategorize for sentential complements.
Tellingly, in the entire proceedings of ACL 2010 (Hajic et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT. $$$$$ “Loose source/target” is the maximum number of unaligned source/target words at the endpoints of a phrase. limit, above which the glue rule must be used.
