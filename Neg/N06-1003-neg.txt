Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ This is problematic for so called “low density” language pairs which do not have very large parallel corpora.
Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ Although Bleu is currently the standard metric for MT evaluation, we believe that it may not meaningfully measure translation improvements in our setup.
Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ Because we focus on words that the system was previously unable to translate, the increase in coverage and the translation quality of the newly covered phrases are the two most relevant indicators as to the efficacy of the method.
Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ Our results show that augmenting a stateof-the-art SMT system with paraphrases leads to significantly improved coverage and translation quality.

Callison-Burch et al (2006) point out three prominent factors. $$$$$ When the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output.
Callison-Burch et al (2006) point out three prominent factors. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Callison-Burch et al (2006) point out three prominent factors. $$$$$ Limited amounts of training data can further lead to a problem of low coverage in that many phrases encountered at run-time are not observed in the training data and therefore their translations will not be learned.

This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ For a training corpus with 10,000 sentence pairs we increase the coverage of unique test set unigrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.
This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ Bleu relies on exact matches of n-grams in a reference translation.
This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ We asked a monolingual judge whether the phrases in the machine translated output had the same meaning as of the reference phrase.
This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ For instance, with multiword units less re-ordering needs to occur since local dependencies are frequently captured.

Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ In addition to judging the accuracy of 100 phrases for each of the translated sets, we measured how much our paraphrase method increased the coverage of the translation system.
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ Figure 2 illustrates how a German phrase can be used as a point of identification for English paraphrases in this way.

Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ Although Bleu is currently the standard metric for MT evaluation, we believe that it may not meaningfully measure translation improvements in our setup.
Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ The phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training on each of the three training corpora.
Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ For these language pairs a huge portion of phrases encountered at run-time will be unknown.

Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).
Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ We can exploit knowledge that is external to the translation model about what words have similar meanings and use that in the process of translation.
Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ This is the default behavior for many systems, as noted in Section 2.1.
Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ We were able to use these alignments to extract the translations of the Spanish and French words that we were applying our paraphrase method to.

Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ For a training corpus containing 10,000 words translations will have been learned for only 10% of the unigrams (types, not tokens).
Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ Figure 1 shows the extent of this problem.
Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ Finally, we plan to formalize our targeted manual evaluation method, in the hopes of creating a evaluation methodology for machine translation that is more thorough and elucidating than Bleu.

We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ By counting how often a correct phrase would have contributed to an increased Bleu score, and how often it would fail to increase the Bleu score we were able to determine with what frequency Bleu was sensitive to our improvements.
We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ Koehn and Knight (2003) show how monolingual texts and parallel corpora can be used to figure out appropriate places to split German compounds.
We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ Bannard and Callison-Burch (2005) use bilingual parallel corpora to generate paraphrases.
We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ For each of these phrases we generated a list of paraphrases using all of the parallel corpora from Europarl aside from the Spanish-English and French-English corpora.

Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ Limited amounts of training data can further lead to a problem of low coverage in that many phrases encountered at run-time are not observed in the training data and therefore their translations will not be learned.
Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ The method defined in Bannard and CallisonBurch (2005) has several features that make it an ideal candidate for incorporation into statistical machine translation system.
Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ In future work, we plan to determine how much data is required to learn useful paraphrases.

Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ The foreign language translations of an English phrase are identified, all occurrences of those foreign phrases are found, and all English phrases that they translate back to are treated as potential paraphrases of the original English phrase.
Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ Neither of these strategies is satisfying.
Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ We extracted all source language (Spanish and French) phrases up to length 10 from the test and development sets which did not have translations in phrase tables that were generated for the three training corpora.

Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).
Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ For a baseline system we produced a phrase-based statistical machine translation system based on the log-linear formulation described in (Och and Ney, 2002) The baseline model had a total of eight feature functions, hm(e, f): a language model probability, a phrase translation probability, a reverse phrase translation probability, lexical translation probability, a reverse lexical translation probability, a word penalty, a phrase penalty, and a distortion cost.
Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ If we exclude 451 words worth of names, numbers, and foreign language text in 2,000 sentences that comprise the Spanish portion of the Europarl test set, then the number of unique n-grams in text are: 7,331 unigrams, 28,890 bigrams, 44,194 trigrams, and 48,259 4-grams.

Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ Previous research on trying to overcome data sparsity issues in statistical machine translation has largely focused on introducing morphological analysis as a way of reducing the number of types observed in a training text.
Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ Specifically we show that upon encountering an unknown source phrase, we can substitute a paraphrase for it and then proceed using the translation of that paraphrase.
Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ For example, when words occur infrequently in a parallel corpus parameter estimates for word-level alignments can be inaccurate, which can in turn lead to inaccurate phrase translations.
Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ As illustrated in Figure 1, translation models suffer from sparse data.

to explain how difficult it is to translate the source-side sentence in three respects $$$$$ The coverage of unique 4-grams jumps from 3% to 16% – a level reached only after observing more than 100,000 sentence pairs, or roughly three million words of text, without using paraphrases.
to explain how difficult it is to translate the source-side sentence in three respects $$$$$ The foreign language translations of an English phrase are identified, all occurrences of those foreign phrases are found, and all English phrases that they translate back to are treated as potential paraphrases of the original English phrase.

system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ For these language pairs a huge portion of phrases encountered at run-time will be unknown.
system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ In this case translating a paraphrase would not be guaranteed to received an improved or identical Bleu score, as in the single word case.
system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ There are two strategies that are generally employed when an unknown source word is encountered.

Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ Limited amounts of training data can further lead to a problem of low coverage in that many phrases encountered at run-time are not observed in the training data and therefore their translations will not be learned.
Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ For each of these phrases we generated a list of paraphrases using all of the parallel corpora from Europarl aside from the Spanish-English and French-English corpora.
Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ To set the weights, am, we performed minimum error rate training (Och, 2003) on the development set using Bleu (Papineni et al., 2002) as the objective function.

Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ Goldwater and McClosky (2005) find that stemming Czech and using lemmas improves the word-to-word correspondences when training Czech-English alignment models.
Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ For each paraphrase that had translations in the phrase table, we added additional entries in the phrase table containing the original phrase and the paraphrase’s translations.
Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ For these language pairs a huge portion of phrases encountered at run-time will be unknown.

 $$$$$ This method is particularly pertinent to small data conditions, which are plagued by sparse data problems.
 $$$$$ This problem is obviously compounded for higher-order n-grams (longer phrases), and for morphologically richer languages. phrases for the Spanish words encargarnos and usado along with their English translations which were automatically learned from the Europarl corpus Currently most statistical machine translation systems are simply unable to handle unknown words.
 $$$$$ Our results show that augmenting a stateof-the-art SMT system with paraphrases leads to significantly improved coverage and translation quality.

For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ We show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases.
For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ We examined the application of paraphrases to deal with unknown phrases when translating from Spanish and French into English.

The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ This is illustrated in Figure 4.
The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ Without it, the multi-word paraphrases harm translation performance when compared to the baseline.
The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ The scenario described in this paper was very favorable to creating high quality paraphrases.
The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ For a baseline system we produced a phrase-based statistical machine translation system based on the log-linear formulation described in (Och and Ney, 2002) The baseline model had a total of eight feature functions, hm(e, f): a language model probability, a phrase translation probability, a reverse phrase translation probability, lexical translation probability, a reverse lexical translation probability, a word penalty, a phrase penalty, and a distortion cost.

This work is most closely related to that of Callison-Burch et al (2006), who also translate source-side paraphrases of the OOV phrases. $$$$$ Oard et al. (2003) describe various methods employed for quickly gathering resources to create a machine translation system for a language with no initial resources.
This work is most closely related to that of Callison-Burch et al (2006), who also translate source-side paraphrases of the OOV phrases. $$$$$ Goldwater and McClosky (2005) find that stemming Czech and using lemmas improves the word-to-word correspondences when training Czech-English alignment models.
This work is most closely related to that of Callison-Burch et al (2006), who also translate source-side paraphrases of the OOV phrases. $$$$$ These multi-word units may not have been observed in the training data as a unit, but each of the component words may have been.
