Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ In this paper we have shown that significant gains in coverage and translation quality can be had by integrating paraphrases into statistical machine translation.
Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ When a system is trained using 10,000 sentence pairs (roughly 200,000 words) there will be a number of words and phrases in a test sentence which it has not learned the translation of.
Although both methods have gained mainstream acceptance and have shown good correlations with human judgments, their deficiencies have become more evident and serious as research in MT and summarization progresses (Callison-Burch et al, 2006). $$$$$ Previous research on trying to overcome data sparsity issues in statistical machine translation has largely focused on introducing morphological analysis as a way of reducing the number of types observed in a training text.

Callison-Burch et al (2006) point out three prominent factors. $$$$$ The automatic generation of paraphrases has been the focus of a significant amount of research lately.
Callison-Burch et al (2006) point out three prominent factors. $$$$$ While this is a realistic scenario, in that many new official languages have been added to the European Union, some of which do not yet have extensive parallel corpora, we realize that this may be a slightly idealized scenario.
Callison-Burch et al (2006) point out three prominent factors. $$$$$ For each of these phrases we generated a list of paraphrases using all of the parallel corpora from Europarl aside from the Spanish-English and French-English corpora.
Callison-Burch et al (2006) point out three prominent factors. $$$$$ We can extend the definition of the paraphrase probability to include multiple corpora, as follows: where c is a parallel corpus from a set of parallel corpora C. Thus multiple corpora may be used by summing over all paraphrase probabilities calculated from a single corpus (as in Equation 1) and normalized by the number of parallel corpora.

This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ When only a very small parallel corpus is available for training, translations are learned for very few of the unique phrases in a test set.
This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ This allowed us to identify which elements in the machine translated output corresponded to the paraphrased foreign phrase.
This substitution technique has shown some improvement in translation quality (Callison-Burch et al, 2006). $$$$$ The scenario described in this paper was very favorable to creating high quality paraphrases.

Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ We were able to use these alignments to extract the translations of the Spanish and French words that we were applying our paraphrase method to.
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ We derive these paraphrases from resources that are external to the parallel corpus that the translation model is trained from, and we are able to exploit (potentially more abundant) parallel corpora from other language pairs to do so.
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ These multi-word units may not have been observed in the training data as a unit, but each of the component words may have been.
Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data. $$$$$ In future work, we plan to determine how much data is required to learn useful paraphrases.

Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ The article is countering discrimination and the unequal treatment of citizens for the reasons that in the same.
Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ Oard et al. (2003) describe various methods employed for quickly gathering resources to create a machine translation system for a language with no initial resources.
Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ We examined the application of paraphrases to deal with unknown phrases when translating from Spanish and French into English.
Other proposed methods include paraphrasing (Callison-Burch et al, 2006) and transliteration (Knight and Graehl, 1997) that uses the feature of phonetic similarity. $$$$$ Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation (Callison-Burch et al., 2006).

Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ Because we focus on words that the system was previously unable to translate, the increase in coverage and the translation quality of the newly covered phrases are the two most relevant indicators as to the efficacy of the method.
Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ The automatic generation of paraphrases has been the focus of a significant amount of research lately.
Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ The method defined in Bannard and CallisonBurch (2005) has several features that make it an ideal candidate for incorporation into statistical machine translation system.
Callison-Burch et al (2006) propose the use of paraphrases as a means of dealing with unseen source phrases. $$$$$ However, for many language pairs they are available only in very limited quantities.

Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ We used the publicly available Europarl multilingual parallel corpus (Koehn, 2005) to create six training corpora for the two language pairs, and used the standard Europarl development and test sets.
Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ However, for many language pairs they are available only in very limited quantities.
Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general. $$$$$ Many methods for extracting paraphrases (Barzilay and McKeown, 2001; Pang et al., 2003) make use of monolingual parallel corpora, such as multiple translations of classic French novels into English, or the multiple reference translations used by many automatic evaluation metrics for machine translation.

We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ While this is a realistic scenario, in that many new official languages have been added to the European Union, some of which do not yet have extensive parallel corpora, we realize that this may be a slightly idealized scenario.
We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ For example, when words occur infrequently in a parallel corpus parameter estimates for word-level alignments can be inaccurate, which can in turn lead to inaccurate phrase translations.
We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ In effect, paraphrases introduce some amount ofgeneralization into statistical machine translation.
We carried out experiments on small, medium and large scale English-Chinese translation tasks to compare against a baseline PBSMT system, the translation model augmentation of (Callison-Burch et al, 2006) method and the word-lattice-based method of (Du et al., 2010) to show the effectiveness of our novel approach. $$$$$ For those items judged to have the same meaning as the gold standard phrases we could track how many would have contributed to a higher Bleu score (that is, which of them were exactly the same as the reference translation phrase, or had some words in common with the reference translation phrase).

Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ To do this, had bilingual speakers create word-level alignments for the first 150 and 250 sentence in the Spanish-English and French-English test corpora, as shown in Figure 3.
Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ The phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training on each of the three training corpora.
Compared with translation model augmentation with paraphrases (Callison-Burch et al, 2006), word-lattice-based paraphrasing for PBSMT is introduced in (Du et al, 2010). $$$$$ We augmented the baseline model by incorporating the paraphrase probability into an additional feature function which assigns values as follows: p(f2|f1) If phrase table entry (e, f1) is generated from (e, f2)

Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ Table 1 gives examples of paraphrases and their translations.
Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ The method defined in Bannard and CallisonBurch (2005) has several features that make it an ideal candidate for incorporation into statistical machine translation system.
Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ To set the weights, am, we performed minimum error rate training (Och, 2003) on the development set using Bleu (Papineni et al., 2002) as the objective function.
Callison-Burch et al (2006) used paraphrases of the trainig corpus for translating unseen phrases. $$$$$ Here we address the problem of unknown phrases.

Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ We performed a manual evaluation by judging the accuracy of phrases for 100 paraphrased translations from each of the sets using the manual word alignments.1 Table 4 gives the percentage of time that each of the translations of paraphrases were judged to have the same meaning as the equivalent target phrase.
Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ As with the Bleu scores, the translations of multi-word paraphrases were judged to be more accurate than the translations of single word paraphrases.
Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ Parallel corpora are crucial for training SMT systems.
Callison-Burch et al (2006) argue that limited amounts of parallel training data can lead to the problem of low coverage in that many phrases encountered at run-time are not observed in the training data and so their translations will not be learned. $$$$$ We extracted all source language (Spanish and French) phrases up to length 10 from the test and development sets which did not have translations in phrase tables that were generated for the three training corpora.

Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ In effect, paraphrases introduce some amount ofgeneralization into statistical machine translation.
Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ Specifically we show that upon encountering an unknown source phrase, we can substitute a paraphrase for it and then proceed using the translation of that paraphrase.
Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ Goldwater and McClosky (2005) find that stemming Czech and using lemmas improves the word-to-word correspondences when training Czech-English alignment models.
Callison-Burch et al (2006) proposed a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence, and then proceeds to use the translation of that paraphrase in the production of the target-language result. $$$$$ The automatic generation of paraphrases has been the focus of a significant amount of research lately.

to explain how difficult it is to translate the source-side sentence in three respects: The OOV rates of the source sentences in the test set (Callison-Burch et al, 2006). $$$$$ As with many other statistical natural language processing tasks, statistical machine translation (Brown et al., 1993) produces high quality results when ample training data is available.
to explain how difficult it is to translate the source-side sentence in three respects: The OOV rates of the source sentences in the test set (Callison-Burch et al, 2006). $$$$$ For a training corpus with 10,000 sentence pairs we increase the coverage of unique test set unigrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.
to explain how difficult it is to translate the source-side sentence in three respects: The OOV rates of the source sentences in the test set (Callison-Burch et al, 2006). $$$$$ We augmented the baseline model by incorporating the paraphrase probability into an additional feature function which assigns values as follows: p(f2|f1) If phrase table entry (e, f1) is generated from (e, f2)
to explain how difficult it is to translate the source-side sentence in three respects: The OOV rates of the source sentences in the test set (Callison-Burch et al, 2006). $$$$$ Since e1 can translate as multiple foreign language phrases, we marginalize f out: The translation model probabilities can be computed using any standard formulation from phrasebased machine translation.

system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ Resnik and Smith (2003) develop a method for gathering parallel corpora from the web.
system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ We show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases.
system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ For each paraphrase that had translations in the phrase table, we added additional entries in the phrase table containing the original phrase and the paraphrase’s translations.
system performs slightly better (0.36 absolute BLEU points) than the baseline system on the 20K data set, but slightly worse (0.19 absolute BLEU points) than the baseline on the 200K data set, which indicates that the paraphrase substitution method used in (Callison-Burch et al, 2006) does not work on resource-sufficient data sets. $$$$$ Parallel corpora are crucial for training SMT systems.

Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ If we had learned a translation of garantizar we could translate it instead of encargarnos, and similarly for utilizado instead of usado.
Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ For example, common adjective-noun alternations are memorized.
Callison-Burch et al (2006) aim to improve MT quality by adding paraphrases in the translation table, while Madnani et al (2007) aim to improve the minimum error rate training by adding the automatically generated paraphrases into the English reference sets. $$$$$ Table 5 gives the percentage of these which have translations in each of the three training corpora, if we do not use paraphrasing.

Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ For these language pairs a huge portion of phrases encountered at run-time will be unknown.
Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ The article is countering discrimination and the unequal treatment of citizens for the reasons that in the same.
Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. $$$$$ Previous research on trying to overcome data sparsity issues in statistical machine translation has largely focused on introducing morphological analysis as a way of reducing the number of types observed in a training text.

 $$$$$ We calculated paraphrase probabilities using the Bannard and CallisonBurch (2005) method, summarized in Equation 3.
 $$$$$ The article is countering discrimination and the unequal treatment of citizens for the reasons that in the same.
 $$$$$ For each paraphrase that had translations in the phrase table, we added additional entries in the phrase table containing the original phrase and the paraphrase’s translations.
 $$$$$ We tested the usefulness of the paraphrase feature function by performing an additional experiment where the phrase table was expanded but the paraphrase probability was omitted.

For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ Whereas before we relied on having observed a particular word or phrase in the training set in order to produce a translation of it, we are no longer tied to having seen every word in advance.
For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ Paraphrases are identified by pivoting through phrases in another language.
For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ The scenario described in this paper was very favorable to creating high quality paraphrases.
For example, according to Callison-Burch et al (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. $$$$$ The paraphrase probability p(e2|e1) is defined in terms of two translation model probabilities: p(f|e1), the probability that the original English phrase e1 translates as a particular phrase f in the other language, and p(e2|f), the probability that the candidate paraphrase e2 translates as the foreign language phrase.

The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ In effect, paraphrases introduce some amount ofgeneralization into statistical machine translation.
The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ Statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004).
The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ Many methods for extracting paraphrases (Barzilay and McKeown, 2001; Pang et al., 2003) make use of monolingual parallel corpora, such as multiple translations of classic French novels into English, or the multiple reference translations used by many automatic evaluation metrics for machine translation.
The table augmentation idea is similar to Callison Burch et al (Callison-Burch et al, 2006), but our proposed paradigm does not require using a limited resource such as parallel texts in order to generate paraphrases. $$$$$ We manage the parallel corpora with a suffix array -based data structure (Callison-Burch et al., 2005).

This work is most closely related to that of Callison-Burch et al (2006), who also translate source-side paraphrases of the OOV phrases. $$$$$ For a training corpus containing 100,000 words this increases to 30%.
This work is most closely related to that of Callison-Burch et al (2006), who also translate source-side paraphrases of the OOV phrases. $$$$$ To set the weights, am, we performed minimum error rate training (Och, 2003) on the development set using Bleu (Papineni et al., 2002) as the objective function.
