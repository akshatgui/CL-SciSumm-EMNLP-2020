Pustejovsky confronted with the problem of automatic acquisition more extensively in [Pustejovsky et al 1993]. $$$$$ We would like to thank Scott Waterman for his assistance in preparing the statistics.
Pustejovsky confronted with the problem of automatic acquisition more extensively in [Pustejovsky et al 1993]. $$$$$ Unlike previous attempts at corpus research, the current focus is supported and guided by theoretical tools, and not merely statistical techniques.
Pustejovsky confronted with the problem of automatic acquisition more extensively in [Pustejovsky et al 1993]. $$$$$ Corpus studies confirm similar results for &quot;weakly intensional contexts&quot; such as the complement of coercive verbs such as veto.
Pustejovsky confronted with the problem of automatic acquisition more extensively in [Pustejovsky et al 1993]. $$$$$ Thus, such presupposition and preference statistics are vital to efficient processing of real text.

We inferred the bracketing by modifying an algorithm initially proposed by Pustejovsky et al (1993). $$$$$ Unlike with purely statistical collocational analyses, the framework of a semantic theory allows the automatic construction of predictions about deeper semantic relationships among words appearing in collocational systems.
We inferred the bracketing by modifying an algorithm initially proposed by Pustejovsky et al (1993). $$$$$ Our analysis proceeds in two phases.
We inferred the bracketing by modifying an algorithm initially proposed by Pustejovsky et al (1993). $$$$$ We illustrate the approach for the acquisition of lexical information for several classes of nominals, and how such techniques can fine-tune the lexical structures acquired from an initial seeding of a machine-readable dictionary.
We inferred the bracketing by modifying an algorithm initially proposed by Pustejovsky et al (1993). $$$$$ Probably the main distinguishing feature of our approach is its reliance on a fairly well studied semantic framework to aid and guide the semantic induction process itself, whether it involves selectional restrictions or semantic types.

The bracketing problem for noun-noun-noun compounds has been investigated by Liberrnan (1992), Pustejovsky et al (1993). $$$$$ LDOCE suggests write in rather than write as the value for the telic role, while the OALD suggests nothing for this role.
The bracketing problem for noun-noun-noun compounds has been investigated by Liberrnan (1992), Pustejovsky et al (1993). $$$$$ Finally, we discuss the potential that corpus studies have for enriching the data set for theoretical linguistic research, as well as helping to confirm or disconfirm linguistic hypotheses.
The bracketing problem for noun-noun-noun compounds has been investigated by Liberrnan (1992), Pustejovsky et al (1993). $$$$$ Such information can be represented by means of a representational schema called qualia structure, which, among other things, specifies the relations associated with objects.

(Pustejovsky et al., 1993) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps $$$$$ By applying the mutual information metric (MI) to the verb—object pairs, we can sort the verbs accordingly, giving us the table of verbs most highly associated with tape, shown in Figure 2.
(Pustejovsky et al., 1993) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps $$$$$ We first presented a representation language for lexical knowledge, the generative lexicon, and demonstrated how it facilitates the structuring of lexical relations among words, looking in particular at the problems of metonymy and polysemy.
(Pustejovsky et al., 1993) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps $$$$$ Let us assume, on the basis of this preliminary date presented in Bergler (1992) that these verbs in fact do behave as discourse polarity items.
(Pustejovsky et al., 1993) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps $$$$$ Other verbs, for which mouse appears as a direct object are currently defaulted into the formal role, resulting in an entry for mouse as follows: The above experiments have met with limited success, enough to warrant continuing our application of lexical semantic theory to knowledge acquisition from corpora, but not enough to remove the human from the loop.

 $$$$$ We would also like to thank Mats Rooth, Scott Waterman, and four anonymous reviewers for useful comments and discussion.
 $$$$$ We then generate the set of verbs that take T as direct object and calculate the mutual information value for each verb/T collocation (cf.
 $$$$$ The few examples of lexical preference mentioned in this section might not tell us anything conclusive for the definitive usage of a word such as said, if there even exists such a notion.

 $$$$$ ... smash the vase with the hammer The hammer smashed the vase.
 $$$$$ We would like to thank Scott Waterman for his assistance in preparing the statistics.
 $$$$$ The purpose of the research described in this section is to experiment with the automatic acquisition of semantic tags for words in a sublanguage, tags well beyond that available from the seeding of MRDs.

Finally, (Pustejovsky et al, 1993) present an interesting framework for the acquisition of semantic relations from corpora not only relying on statistics, but guided by theoretical lexicon principles. $$$$$ We do the same for each noun N. Under the assumption that instance and class nouns are likely to co-occur with the same verbs, we compute a similarity score between T and each noun N„ by summing the product of the mutual information values for those verbs occurring with both nouns.
Finally, (Pustejovsky et al, 1993) present an interesting framework for the acquisition of semantic relations from corpora not only relying on statistics, but guided by theoretical lexicon principles. $$$$$ The work suggests how linguistic phenomena such as metonymy and polysemy might be exploitable for semantic tagging of lexical items.
Finally, (Pustejovsky et al, 1993) present an interesting framework for the acquisition of semantic relations from corpora not only relying on statistics, but guided by theoretical lexicon principles. $$$$$ The work suggests how linguistic phenomena such as metonymy and polysemy might be exploited for knowledge acquisition for lexical items.

The best known early work on automated unsupervised NC bracketing is that of Lauer (1995) who introduces the probabilistic dependency model for the syntactic disambiguation of NCs and argues against the adjacency model, proposed by Marcus (1980), Pustejovsky et al (1993) and Resnik (1993). $$$$$ The percentage shown indicates the ratio of the particular collocation to the key word.
The best known early work on automated unsupervised NC bracketing is that of Lauer (1995) who introduces the probabilistic dependency model for the syntactic disambiguation of NCs and argues against the adjacency model, proposed by Marcus (1980), Pustejovsky et al (1993) and Resnik (1993). $$$$$ What these expressions in effect indicate is the range of semantic environments they will appear in.
The best known early work on automated unsupervised NC bracketing is that of Lauer (1995) who introduces the probabilistic dependency model for the syntactic disambiguation of NCs and argues against the adjacency model, proposed by Marcus (1980), Pustejovsky et al (1993) and Resnik (1993). $$$$$ The database of partially parsed sentences provides the raw material for a number of sublanguage analyses.
The best known early work on automated unsupervised NC bracketing is that of Lauer (1995) who introduces the probabilistic dependency model for the syntactic disambiguation of NCs and argues against the adjacency model, proposed by Marcus (1980), Pustejovsky et al (1993) and Resnik (1993). $$$$$ Although the results here are preliminary, it is important to mention the process of converting an MRD into a lexical knowledge base, so that the process of corpus-tuning is put into the proper perspective.

Pustejovsky et al (1993) show how statistical techniques, such as mutual information measures can contribute to automatically acquire lexical information regarding the link between a noun and a predicate. $$$$$ We would also like to thank Mats Rooth, Scott Waterman, and four anonymous reviewers for useful comments and discussion.
Pustejovsky et al (1993) show how statistical techniques, such as mutual information measures can contribute to automatically acquire lexical information regarding the link between a noun and a predicate. $$$$$ This research was supported by DARPA contract MDA904-91-C-9328.
Pustejovsky et al (1993) show how statistical techniques, such as mutual information measures can contribute to automatically acquire lexical information regarding the link between a noun and a predicate. $$$$$ For example, while the verb announce selects for a human subject, sentences like The Dow Corporation announced third quarter losses are not only an acceptable paraphrase of the selectionally correct form Mr. Dow Jr. announced third quarter losses for Dow Corp, but they are the preferred form in the corpora being examined.
Pustejovsky et al (1993) show how statistical techniques, such as mutual information measures can contribute to automatically acquire lexical information regarding the link between a noun and a predicate. $$$$$ In this paper we outline a research program for computational linguistics, making extensive use of text corpora.

 $$$$$ We illustrated the approach for the acquisition of lexical information for several classes of nominals, and how such techniques can fine-tune the lexical structures acquired from an initial seeding of a machine-readable dictionary.
 $$$$$ Based on the distributional hypothesis that the degree of shared contexts is a similarity measure for words, he develops a similarity metric for nouns based on their substitutability in certain verb contexts.
 $$$$$ We illustrate the approach for the acquisition of lexical information for several classes of nominals, and how such techniques can fine-tune the lexical structures acquired from an initial seeding of a machine-readable dictionary.
 $$$$$ Extraction of information relating to noun's qualia.

For example, Pustejovsky et al (1993) use generalized syntactic patterns for extracting qualia structures from a partially parsed corpus. $$$$$ The purpose of the research described in this section is to experiment with the automatic acquisition of semantic tags for words in a sublanguage, tags well beyond that available from the seeding of MRDs.
For example, Pustejovsky et al (1993) use generalized syntactic patterns for extracting qualia structures from a partially parsed corpus. $$$$$ 13 Because the technique was sensitive to grammatical position of the object NP, the argument can be bound to the appropriate variable in the relation expressed in the qualia.
For example, Pustejovsky et al (1993) use generalized syntactic patterns for extracting qualia structures from a partially parsed corpus. $$$$$ We would like to thank Scott Waterman for his assistance in preparing the statistics.
For example, Pustejovsky et al (1993) use generalized syntactic patterns for extracting qualia structures from a partially parsed corpus. $$$$$ To test whether the intuitions supported by the above data could be confirmed in corpora, Bergler (1991) derived the statistical co-occurrence of insist with discourse polarity markers in the 7 million-word corpus of Wall Street Journal articles.

Concerning relatedness measure, additional corpus-based measures such as Web-basedmeasures (Cimiano and Wenderoth, 2007) or measures based on syntactic relations (Pustejovsky et al, 1993) could appear to be useful for improving the ranking of the extracted relations. $$$$$ We would also like to thank Mats Rooth, Scott Waterman, and four anonymous reviewers for useful comments and discussion.
Concerning relatedness measure, additional corpus-based measures such as Web-basedmeasures (Cimiano and Wenderoth, 2007) or measures based on syntactic relations (Pustejovsky et al, 1993) could appear to be useful for improving the ranking of the extracted relations. $$$$$ In the previous section we presented algorithms for extracting collocational information from corpora, in order to supplement and fine-tune the lexical structures seeded by a machine-readable dictionary.
Concerning relatedness measure, additional corpus-based measures such as Web-basedmeasures (Cimiano and Wenderoth, 2007) or measures based on syntactic relations (Pustejovsky et al, 1993) could appear to be useful for improving the ranking of the extracted relations. $$$$$ An important question related to the extraction of preference information is what the corpus should be.
