 $$$$$ Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity.
 $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.
 $$$$$ One of the disadvantages of our method is that its performance depends on the structure of the particular thesaurus used.

 $$$$$ We are grateful to K. Nakamura and T. Fujita of NEC C&C Res.
 $$$$$ If we use MLE for the parameter estimation, we can obtain five tree cut models from the co-occurrence data in Figure 1; Figures 4-6 show three of these.
 $$$$$ Experimental results indicate that the proposed method improves upon or is at least comparable with existing methods.
 $$$$$ These curves were obtained by averaging over the 10 data sets.

After extracting the argument heads of the target slots of each verb (e.g., the intransitive subject and the transitive object for the causative alternation), she then determined their selectional profiles using a minimum description length tree cut model (Li and Abe, 1998). $$$$$ For an arbitrary subtree T' of a thesaurus tree T and an arbitrary tree cut model M = 0) of T, let MT, = (UT', ) denote the submodel of M that is contained in T'.
After extracting the argument heads of the target slots of each verb (e.g., the intransitive subject and the transitive object for the causative alternation), she then determined their selectional profiles using a minimum description length tree cut model (Li and Abe, 1998). $$$$$ Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity.

The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ A new method for automatically acquiring case frame patterns from large corpora is proposed.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ We thank K. Yaminishi and J. Takeuchi of C&C Res.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.

Li and Abe (1998) use a minimum description length-based algorithm to find an optimal tree cut over WordNet for each classification problem, finding improvements over both lexical association (Hindle and Rooth, 1993) and conceptual association, and equaling the transformation-based results. $$$$$ ,k, we have: provided that FT is not a single node (root node of T).
Li and Abe (1998) use a minimum description length-based algorithm to find an optimal tree cut over WordNet for each classification problem, finding improvements over both lexical association (Hindle and Rooth, 1993) and conceptual association, and equaling the transformation-based results. $$$$$ A new method for automatically acquiring case frame patterns from large corpora is proposed.
Li and Abe (1998) use a minimum description length-based algorithm to find an optimal tree cut over WordNet for each classification problem, finding improvements over both lexical association (Hindle and Rooth, 1993) and conceptual association, and equaling the transformation-based results. $$$$$ One of the disadvantages of our method is that its performance depends on the structure of the particular thesaurus used.
Li and Abe (1998) use a minimum description length-based algorithm to find an optimal tree cut over WordNet for each classification problem, finding improvements over both lexical association (Hindle and Rooth, 1993) and conceptual association, and equaling the transformation-based results. $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.

W ealso plan to compare the results to the tree cut algorithm reported in (Li and Abe, 1998), which allows different levels to be identified for different subtrees. $$$$$ We then give some concluding remarks in Section 5.
W ealso plan to compare the results to the tree cut algorithm reported in (Li and Abe, 1998), which allows different levels to be identified for different subtrees. $$$$$ In this case, our method would select the model that stops generalizing at bird, swallow, eagle, etc., because the description length for the same subtree now is 86.22 + 3.32 = 89.54 if generalized, and 55.04 + 33.22 = 88.26 if not generalized.
W ealso plan to compare the results to the tree cut algorithm reported in (Li and Abe, 1998), which allows different levels to be identified for different subtrees. $$$$$ Our approach of applying MDL to estimate a tree cut model in an existing thesaurus is not limited to just the problem of generalizing values of a case frame slot.
W ealso plan to compare the results to the tree cut algorithm reported in (Li and Abe, 1998), which allows different levels to be identified for different subtrees. $$$$$ Our algorithm, which we call Find-MDL, recursively finds the optimal MDL model for each child subtree of a given tree and appends all the optimal models of these subtrees and returns the appended models, unless collapsing all the lower-level optimal models into a model consisting of a single node (the root node of the given tree) reduces the total description length, in which case it does so.

Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ This method is based on an interesting intuition, but its interpretation as a method of estimation is not clear.
Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ We also express our special appreciation to the two anonymous reviewers who have provided many valuable comments.
Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ An efficient algorithm is given, which provably obtains the optimal tree cut model for the given frequency data of a case slot, in the sense of MDL.
Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ In order to assist with efficiency, our method makes use of an existing thesaurus and restricts its attention on those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.

Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them. $$$$$ The case frame (case slot) pattern acquisition process consists of two phases: extraction of case frame instances from corpus data, and generalization of those instances to case frame patterns.
Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them. $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them. $$$$$ ,k, we have: provided that FT is not a single node (root node of T).
Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them. $$$$$ In Section 3, we describe our MDL-based generalization method.

 $$$$$ Since the number of partitions for a given set of nouns is extremely large, the problem of selecting the best model from among all possible class-based models is most likely intractable.
 $$$$$ For instance, a high estimated value for (drop, bead, pearl) at protect against shown in Table 14 is rather odd, and is because the estimate of P(C) is unreliable (too small).
 $$$$$ Specifically, we formalize the problem of generalizing values of a case frame slot for a given verb as that of estimating a conditional probability distribution over a partition of words, and propose a new generalization method based on the Minimum Description Length principle (MDL): a principle of data compression and statistical estimation from information theory.'

 $$$$$ A new method for automatically acquiring case frame patterns from large corpora is proposed.
 $$$$$ Since our learning method based on MDL is robust against noise, this should not significantly degrade performance.
 $$$$$ It is easy to see that the running time of the algorithm is linear in both the number of leaf nodes of the input thesaurus tree and the input sample size.
 $$$$$ An efficient algorithm is given, which provably obtains the optimal tree cut model for the given frequency data of a case slot, in the sense of MDL.

In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ We also express our special appreciation to the two anonymous reviewers who have provided many valuable comments.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ We also have, when T is a proper subtree of the thesaurus tree: Since the number of free parameters of a model in the entire thesaurus tree equals the number of nodes in the model minus one due to the stochastic condition (that the probability parameters must sum to one), when T equals the entire thesaurus tree, theoretically the parameter description length for a tree cut model of T should be: where IS I is the size of the entire sample.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity.

Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ First, when T is of a single leaf node, the submodel consisting solely of the node and the MLE of the generation probability for the class represented by T is returned, which is clearly a submodel with minimum description length in the subtree T. Next, inductively assume that Find-MDL(T') correctly outputs a (sub)model with the minimum description length for any tree T' of size less than n. Then, given a tree T of size n whose root node has at least two children, say T : i = 1,. .
Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ The remainder of this paper is organized as follows: In Section 2, we formalize the problem of generalizing values of a case frame slot as that of estimating a conditional distribution.
Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ In our current problem, this corresponds to the generalization of individual nouns present in case frame instances in the data as classes of nouns present in a given thesaurus.
Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ In order to assist with efficiency, our method makes use of an existing thesaurus and restricts its attention on those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.

Li and Abe (1998) used a tree cut model over WordNet, based on the principle of MinimumDescription Length (MDL). $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
Li and Abe (1998) used a tree cut model over WordNet, based on the principle of MinimumDescription Length (MDL). $$$$$ We therefore leave this issue as a future topic, and employ a simple heuristic of equally distributing each word occurrence in the data to all of its potential word senses in our experiments.
Li and Abe (1998) used a tree cut model over WordNet, based on the principle of MinimumDescription Length (MDL). $$$$$ An efficient algorithm is given, which provably obtains the optimal tree cut model for the given frequency data of a case slot, in the sense of MDL.

 $$$$$ This, however, is a problem commonly shared by any generalization method that uses a thesaurus as prior knowledge.
 $$$$$ For an arbitrary subtree T' of a thesaurus tree T and an arbitrary tree cut model M = 0) of T, let MT, = (UT', ) denote the submodel of M that is contained in T'.
 $$$$$ Our experimental results indicate that the performance of our method is better than, or at least comparable to, existing methods.
 $$$$$ We believe that our method has the following merits: (1) it is theoretically sound; (2) it is computationally efficient; (3) it is robust against noise.

McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy (Li and Abe, 1998). $$$$$ We thank T. Futagami of NIS for his programming efforts.
McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy (Li and Abe, 1998). $$$$$ Here, a partition F of .AT is any collection of mutually disjoint subsets of .N that exhaustively cover N'.
McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy (Li and Abe, 1998). $$$$$ We thank K. Yaminishi and J. Takeuchi of C&C Res.

We suspect the problem is two-fold, arising from the dependence of her method on tree cut models (Li and Abe, 1998). $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.
We suspect the problem is two-fold, arising from the dependence of her method on tree cut models (Li and Abe, 1998). $$$$$ Our experimental results indicate that the performance of our method is better than, or at least comparable to, existing methods.
We suspect the problem is two-fold, arising from the dependence of her method on tree cut models (Li and Abe, 1998). $$$$$ Finally, the data description length L(S I F, e) is calculated by: Calculating the description length for the model of Figure 5.

The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ Experimental results indicate that the proposed method improves upon or is at least comparable with existing methods.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ But since the number of cuts in a thesaurus tree is exponential in the size of the tree (for example, it is easy to verify that for a complete b-ary tree of depth d it is of the order O(2bd 1)), it is impractical to do so.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ Labs. for their constant encouragement.

The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ The generalization step is needed in order to represent the input case frame instances more compactly as well as to judge the (degree of) acceptability of unseen case frame instances.
The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.
The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity.

This leads to the notion of "cutting" the hierarchy at one or more positions (Li and Abe, 1998). $$$$$ First note that for any (sub)tree T, (sub)model MT = (FT, UT) contained in T, and (sub)sample ST contained in T, and T's child subtrees T, : i = 1, .
This leads to the notion of "cutting" the hierarchy at one or more positions (Li and Abe, 1998). $$$$$ When the estimation problem involves model selection, i.e., the choice of a tree cut in the present context, MDL's behavior significantly deviates from that of MLE.
This leads to the notion of "cutting" the hierarchy at one or more positions (Li and Abe, 1998). $$$$$ ,k, we have: provided that FT is not a single node (root node of T).
This leads to the notion of "cutting" the hierarchy at one or more positions (Li and Abe, 1998). $$$$$ A new method for automatically acquiring case frame patterns from large corpora is proposed.

Li and Abe (1998) propose a model in which the appropriate cut c is selected according to the Minimum Description Length principle; this principle explicitly accounts for the trade-off between generalisation and accuracy by minimising a sum of model description length and data description length. $$$$$ An efficient algorithm is given, which provably obtains the optimal tree cut model for the given frequency data of a case slot, in the sense of MDL.
Li and Abe (1998) propose a model in which the appropriate cut c is selected according to the Minimum Description Length principle; this principle explicitly accounts for the trade-off between generalisation and accuracy by minimising a sum of model description length and data description length. $$$$$ More specifically, conditional probabilities of words are smoothed by taking the weighted average of those of similar words using the similarity measure as the weights.
