 $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
 $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.
 $$$$$ Since the second term log21s1 in (19) is constant once the input sample S is fixed, for the purpose of finding a model with the minimum description length, it is irrelevant.

 $$$$$ We proposed a new method of generalizing case frames.
 $$$$$ A new method for automatically acquiring case frame patterns from large corpora is proposed.
 $$$$$ In this paper, we confine ourselves to the former issue, and refer the interested reader to Li and Abe (1996), which deals with the latter issue.
 $$$$$ This, however, is a problem commonly shared by any generalization method that uses a thesaurus as prior knowledge.

After extracting the argument heads of the target slots of each verb (e.g., the intransitive subject and the transitive object for the causative alternation), she then determined their selectional profiles using a minimum description length tree cut model (Li and Abe, 1998). $$$$$ We repeated this process 10 times and obtained 10 sets of data consisting of different training data and test data.
After extracting the argument heads of the target slots of each verb (e.g., the intransitive subject and the transitive object for the causative alternation), she then determined their selectional profiles using a minimum description length tree cut model (Li and Abe, 1998). $$$$$ We also express our special appreciation to the two anonymous reviewers who have provided many valuable comments.
After extracting the argument heads of the target slots of each verb (e.g., the intransitive subject and the transitive object for the causative alternation), she then determined their selectional profiles using a minimum description length tree cut model (Li and Abe, 1998). $$$$$ We are grateful to K. Nakamura and T. Fujita of NEC C&C Res.
After extracting the argument heads of the target slots of each verb (e.g., the intransitive subject and the transitive object for the causative alternation), she then determined their selectional profiles using a minimum description length tree cut model (Li and Abe, 1998). $$$$$ In our current problem, this corresponds to the generalization of individual nouns present in case frame instances in the data as classes of nouns present in a given thesaurus.

The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ Labs. for their constant encouragement.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ (Note that MT = M, ST = S.) Then define, in general for any submodel MT' and subsample ST', UST' I , Or) to be the data description length of subsample ST, using submodel L(Or UT') to be the parameter description length for the submodel Mr, and L'(MT, ) to be L(ST, I UT', GT') + L(OT, I Up).
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ For example, Rissanen (1995) has devised an algorithm for learning decision trees.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ BIRD bug bee insect f(C) 8 0 2 0 Cl 4 1 1 1 P(C) 0.8 0.0 0.2 0.0 P(n) 0.2 0.0 0.2 0.0 where for simplicity we write P(n) for Pm(n I v, r).

Li and Abe (1998) use a minimum description length-based algorithm to find an optimal tree cut over WordNet for each classification problem, finding improvements over both lexical association (Hindle and Rooth, 1993) and conceptual association, and equaling the transformation-based results. $$$$$ We acknowledge the ACL for providing the ACL/DCI CD-ROM, LDC of the University of Pennsylvania for providing the Penn Treebank corpus data, and Princeton University for providing WordNet, and E. Brill and P. Resnik for providing their PP-attachment disambiguation program.
Li and Abe (1998) use a minimum description length-based algorithm to find an optimal tree cut over WordNet for each classification problem, finding improvements over both lexical association (Hindle and Rooth, 1993) and conceptual association, and equaling the transformation-based results. $$$$$ The noun taxonomy of WordNet has a structure of directed acyclic graph (DAG), and its nodes stand for a word sense (a concept) and often contain several words having the same word sense.
Li and Abe (1998) use a minimum description length-based algorithm to find an optimal tree cut over WordNet for each classification problem, finding improvements over both lexical association (Hindle and Rooth, 1993) and conceptual association, and equaling the transformation-based results. $$$$$ ,k, we have: provided that FT is not a single node (root node of T).

W ealso plan to compare the results to the tree cut algorithm reported in (Li and Abe, 1998), which allows different levels to be identified for different subtrees. $$$$$ Our approach of applying MDL to estimate a tree cut model in an existing thesaurus is not limited to just the problem of generalizing values of a case frame slot.
W ealso plan to compare the results to the tree cut algorithm reported in (Li and Abe, 1998), which allows different levels to be identified for different subtrees. $$$$$ The acquired knowledge would also be helpful for building a lexicon, as it would provide lexicographers with word usage descriptions.
W ealso plan to compare the results to the tree cut algorithm reported in (Li and Abe, 1998), which allows different levels to be identified for different subtrees. $$$$$ As for the parameter description length for a subtree, it depends only on the number of classes in the tree cut within that subtree, and hence can be computed independently as well.

Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ Our approach of applying MDL to estimate a tree cut model in an existing thesaurus is not limited to just the problem of generalizing values of a case frame slot.
Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity.
Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ Thus it would seem to be easier to obtain more data in the future for MDL and other methods based on unsupervised learning.
Our selectional preference model relies on Li and Abe (1998), applying the MDL principle to determine selectional preferences of verbs and their arguments, by means of a concept hierarchy ordered by hypernym/hyponym relations. $$$$$ For example, since there are four nouns that fall under the class BIRD, and swallow is one of them, the probability of swallow is thus given by PA:4(swallow I fly, arg1) = 0.8/4 -= 0.2.

Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them. $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them. $$$$$ We propose a class-based generalization method whose performance as a method of estimation is guaranteed to be near optimal.
Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them. $$$$$ Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity.

 $$$$$ We believe that our method has the following merits: (1) it is theoretically sound; (2) it is computationally efficient; (3) it is robust against noise.
 $$$$$ According to our experimental results, the accuracy and coverage of MDL appear to be somewhat better than those of SA.
 $$$$$ First, we modified our algorithm Find-MDL so that it can be applied to a DAG; now, Find-MDL effectively copies each subgraph having multiple parents (and its associated data) so that the DAG is transformed to a tree structure.
 $$$$$ In this case, MLE amounts to estimating the parameters by simply normalizing the frequencies so that they sum to one, giving, for example, the estimated probabilities of 0, 0.2, and 0.4 for swallow, eagle, and bird, respectively (see Figure 2).

 $$$$$ Consider co-occurrence data having 8 occurrences of bird, 2 occurrences of swallow, 1 occurrence of crow, 1 occurrence of eagle, and 0 occurrence of all other words, as part of, say, 100 data obtained for the subject slot of verb fly.
 $$$$$ An efficient algorithm is given, which provably obtains the optimal tree cut model for the given frequency data of a case slot, in the sense of MDL.
 $$$$$ Suppose that the data available to us are of the type shown in Table 1, which are slot values for a given verb (verb,slot_name,slot_value triples) automatically extracted from a corpus using existing techniques.

In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ A satisfactory solution to this problem would have a great impact on various tasks in natural language processing, including the structural disambiguation problem in parsing.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ Labs. for their constant encouragement.

Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ Interpreting — log P(M) as the model description length translates, in the Bayesian estimation, to assigning larger prior probabilities on simpler models, since it is equivalent to assuming that P(M) = ( )1(M), where l(M) is the description length of M. (Note that if we assign uniform prior probability P(M) to all models M, then (15) becomes equivalent to (13), giving the maximum-likelihood estimate.)
Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ This, however, is a problem commonly shared by any generalization method that uses a thesaurus as prior knowledge.
Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ Another problem that must be dealt with concerning SA is how to remove noise (resulting, for example, from erroneous extraction) from the generalization results.
Initially our project began as an application of the closely related MDL approach of Li and Abe (1998), but was hindered by sparse data. $$$$$ We thank K. Yaminishi and J. Takeuchi of C&C Res.

Li and Abe (1998) used a tree cut model over WordNet, based on the principle of MinimumDescription Length (MDL). $$$$$ Another important property of the definition of description length is that it affects not only the effective prior probabilities on the models, but also the procedure for computing the model minimizing the measure.
Li and Abe (1998) used a tree cut model over WordNet, based on the principle of MinimumDescription Length (MDL). $$$$$ We therefore leave this issue as a future topic, and employ a simple heuristic of equally distributing each word occurrence in the data to all of its potential word senses in our experiments.
Li and Abe (1998) used a tree cut model over WordNet, based on the principle of MinimumDescription Length (MDL). $$$$$ The class of tree cut models of a fixed thesaurus tree is then obtained by restricting the partition F in the definition of a class-based model to be those partitions that are present as a cut in that thesaurus tree.
Li and Abe (1998) used a tree cut model over WordNet, based on the principle of MinimumDescription Length (MDL). $$$$$ It is potentially useful in other natural language processing tasks, such as the problem of estimating n-gram models (Brown et al. 1992) or the problem of semantic tagging (Cucchiarelli and Velardi 1997).

 $$$$$ Figure 8 illustrates how the algorithm works (on the co-occurrence data shown at the bottom): In the recursive application of Find-MDL on the subtree rooted at AIRPLANE, the if-clause on line 9 evaluates to true since L' ([AIRPLANE]) = 32.27, L'( [jet, helicopter, airplane]) = 32.72, and hence [AIRPLANE] is returned.
 $$$$$ Namely, if we let L',,,„(A4T, ST) denote the minimum description length (as defined by [17] and [181) achievable for (sub)model MT on (sub)sample ST contained in (sub)tree T, Ps(n) the MLE estimate for node n using the entire sample S. and root(T) the root node of tree T, then we have: (MT, ST) min { E ST,), L' ( ( [root( T)l, [Ps (Toot( TM ), ST) } (20) The rest of the proof proceeds by induction.
 $$$$$ Our experimental results indicate that the performance of our method is better than, or at least comparable to, existing methods.
 $$$$$ In particular, we restrict our attention to those partitions that exist within the thesaurus in the form of a cut.

McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy (Li and Abe, 1998). $$$$$ Since in general the number of parameters exceeds the size of data that is typically available, MLE will result in estimating most of the probability parameters to be zero.
McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy (Li and Abe, 1998). $$$$$ A number of methods for generalizing values of a case frame slot for a verb have been proposed.
McCarthy determines the sense profile of a verb/slot pair using a minimum description length tree cut model over the frequency-populated hierarchy (Li and Abe, 1998). $$$$$ Namely, if we let L',,,„(A4T, ST) denote the minimum description length (as defined by [17] and [181) achievable for (sub)model MT on (sub)sample ST contained in (sub)tree T, Ps(n) the MLE estimate for node n using the entire sample S. and root(T) the root node of tree T, then we have: (MT, ST) min { E ST,), L' ( ( [root( T)l, [Ps (Toot( TM ), ST) } (20) The rest of the proof proceeds by induction.

We suspect the problem is two-fold, arising from the dependence of her method on tree cut models (Li and Abe, 1998). $$$$$ In our experiments, we extracted verbs and their case frame slots (verb, slot _name , slot _value triples) from the tagged texts of the Wall Street Journal corpus (ACL/DCI CD-ROM1) consisting of 126,084 sentences, using existing techniques (specifically, those in Smadja [19931), then Example input data (for the direct object slot of eat). eat arg2 food 3 eat arg2 lobster 1 eat arg2 seed 1 eat arg2 heart 2 eat arg2 liver 1 eat arg2 plant 1 eat arg2 sandwich 2 eat arg2 crab 1 eat arg2 elephant 1 eat arg2 meal 2 eat arg2 rope 1 eat arg2 seafood 1 eat arg2 amount 2 eat arg2 horse 1 eat arg2 mushroom 1 eat arg2 night 2 eat arg2 bug 1 eat arg2 ketchup 1 eat arg2 lunch 2 eat arg2 bowl 1 eat arg2 sawdust 1 eat arg2 snack 2 eat arg2 month 1 eat arg2 egg 1 eat arg2 jam 2 eat arg2 effect 1 eat arg2 sprout 1 eat arg2 diet 1 eat arg2 debt 1 eat arg2 nail 1 eat arg2 pizza 1 eat arg2 oyster 1 applied our method to generalize the slot_values.
We suspect the problem is two-fold, arising from the dependence of her method on tree cut models (Li and Abe, 1998). $$$$$ Since the number of partitions for a given set of nouns is extremely large, the problem of selecting the best model from among all possible class-based models is most likely intractable.
We suspect the problem is two-fold, arising from the dependence of her method on tree cut models (Li and Abe, 1998). $$$$$ It is potentially useful in other natural language processing tasks, such as the problem of estimating n-gram models (Brown et al. 1992) or the problem of semantic tagging (Cucchiarelli and Velardi 1997).

The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ We then give an efficient algorithm that provably obtains the optimal tree cut model for the given frequency data of a case slot, in the sense of MDL.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ (Classes with probabilities less than 0.05 are discarded due to space limitations.)
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ The case frame (case slot) pattern acquisition process consists of two phases: extraction of case frame instances from corpus data, and generalization of those instances to case frame patterns.
The method addresses conceptual problems of an earlier measure proposed by McCarthy (2000), which was limited to tree cut models (Li and Abe, 1998) and failed to distinguish detailed semantic differences between them. $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.

The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as &quot;cuts&quot; in the thesaurus tree, thus reducing the generalization problem to that of estimating a &quot;tree cut model&quot; of the thesaurus tree.
The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ We applied our generalization method to large corpora and inspected the obtained tree cut models to see if they agreed with human intuition.
The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ ,k, we have: provided that FT is not a single node (root node of T).
The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998). $$$$$ We proposed a new method of generalizing case frames.

This leads to the notion of "cutting" the hierarchy at one or more positions (Li and Abe, 1998). $$$$$ We have thus formalized the problem of generalizing values of a case frame slot as that of estimating a model from the class of tree cut models for some fixed thesaurus tree; namely, selecting a model that best explains the data from among the class of tree cut models.
This leads to the notion of "cutting" the hierarchy at one or more positions (Li and Abe, 1998). $$$$$ We are grateful to K. Nakamura and T. Fujita of NEC C&C Res.
This leads to the notion of "cutting" the hierarchy at one or more positions (Li and Abe, 1998). $$$$$ In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed.

Li and Abe (1998) propose a model in which the appropriate cut c is selected according to the Minimum Description Length principle; this principle explicitly accounts for the trade-off between generalisation and accuracy by minimising a sum of model description length and data description length. $$$$$ As Resnik (1993b) pointed out, the use of selectional association log P(pc(1c7) seems to be appropriate for cognitive modeling.
Li and Abe (1998) propose a model in which the appropriate cut c is selected according to the Minimum Description Length principle; this principle explicitly accounts for the trade-off between generalisation and accuracy by minimising a sum of model description length and data description length. $$$$$ We proposed a new method of generalizing case frames.
Li and Abe (1998) propose a model in which the appropriate cut c is selected according to the Minimum Description Length principle; this principle explicitly accounts for the trade-off between generalisation and accuracy by minimising a sum of model description length and data description length. $$$$$ Concerning the above algorithm, we show that the following proposition holds: The algorithm Find-MDL terminates in time 0(N x Si),I where N denotes the number of leaf nodes in the input thesaurus tree T and IS I denotes the input sample size, and outputs a tree cut model of T with the minimum description length (with respect to the encoding scheme described in Section 3.1).
Li and Abe (1998) propose a model in which the appropriate cut c is selected according to the Minimum Description Length principle; this principle explicitly accounts for the trade-off between generalisation and accuracy by minimising a sum of model description length and data description length. $$$$$ Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity.
