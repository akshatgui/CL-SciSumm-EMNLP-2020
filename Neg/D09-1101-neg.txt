 $$$$$ For both types of mentions, the improvements over the corresponding results for the entity-mention baseline are significant, and suggest that mention ranking is a precision-enhancing device.
 $$$$$ We then apply the resulting classifier to each test text to filter discourse-new mentions prior to coreference resolution.
 $$$$$ General discourse-new detectors that are applicable to different types of NPs have been built using heuristics (e.g., Byron and Gegg-Harrison (2004)) and modeled generatively (e.g., Elsner and Charniak (2007)) and discriminatively (e.g., Uryupina (2003)).
 $$$$$ Following Florian et al. (2004), we recast mention extraction as a sequence labeling task, where we assign to each token in a test text a label that indicates whether it begins a mention, is inside a mention, or is outside a mention.

 $$$$$ As mentioned before, Denis and Baldridge (2008) train a mention-ranking model.
 $$$$$ Heuristic-based cluster ranking.
 $$$$$ Experimental results on the ACE data sets demonstrate its superior performance to competing approaches.
 $$$$$ We then apply the resulting classifier to each test text to filter discourse-new mentions prior to coreference resolution.

For comparison purposes, the B3None variant used on A05RA is calculated slightly differently than other B3None results; see Rahman and Ng (2009). $$$$$ (2004), as described below.
For comparison purposes, the B3None variant used on A05RA is calculated slightly differently than other B3None results; see Rahman and Ng (2009). $$$$$ This suggests that the use of an appropriate learning framework can bring us a long way towards highperformance coreference resolution.
For comparison purposes, the B3None variant used on A05RA is calculated slightly differently than other B3None results; see Rahman and Ng (2009). $$$$$ As a result, only a subset of mention pairs will be generated for training.
For comparison purposes, the B3None variant used on A05RA is calculated slightly differently than other B3None results; see Rahman and Ng (2009). $$$$$ We thank the three anonymous reviewers for their invaluable comments on the paper.

The Stoyanov et al (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahmanand Ng (2009) numbers represent their highest performing cluster ranking model. $$$$$ Crucially, our approach combines the strengths of entity-mention models and mention-ranking models.
The Stoyanov et al (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahmanand Ng (2009) numbers represent their highest performing cluster ranking model. $$$$$ (1998), and Mitkov (2002)).
The Stoyanov et al (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahmanand Ng (2009) numbers represent their highest performing cluster ranking model. $$$$$ All these test instances are then presented to the ranker.
The Stoyanov et al (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahmanand Ng (2009) numbers represent their highest performing cluster ranking model. $$$$$ Experimental results on the ACE 2005 corpus show that (1) jointly learning coreference resolution and discourse-new detection allows the cluster ranker to achieve better performance than adopting a pipeline coreference architecture; and (2) our cluster ranker significantly outperforms the mention ranker, the best of the three baseline coreference models, under both the pipeline architecture and the joint architecture.

The set of features that we use, listed in Table 5, is an extension of the set by Rahman and Ng (2009). $$$$$ Crucially, our approach combines the strengths of entity-mention models and mention-ranking models.
The set of features that we use, listed in Table 5, is an extension of the set by Rahman and Ng (2009). $$$$$ Following Florian et al. (2004), we recast mention extraction as a sequence labeling task, where we assign to each token in a test text a label that indicates whether it begins a mention, is inside a mention, or is outside a mention.
The set of features that we use, listed in Table 5, is an extension of the set by Rahman and Ng (2009). $$$$$ This suggests that the use of an appropriate learning framework can bring us a long way towards highperformance coreference resolution.
The set of features that we use, listed in Table 5, is an extension of the set by Rahman and Ng (2009). $$$$$ Experimental results on the ACE data sets demonstrate its superior performance to competing approaches.

Our system is based on a cluster-ranking model proposed by Rahman and Ng (2009), with novel semantic features based on recent re search on narrative event schema (Chambers and Jurafsky, 2009). $$$$$ This work was supported in part by NSF Grant IIS-0812261.
Our system is based on a cluster-ranking model proposed by Rahman and Ng (2009), with novel semantic features based on recent re search on narrative event schema (Chambers and Jurafsky, 2009). $$$$$ Like the mention-pair model, each training instance i(mj, mk) represents mk and a preceding mention mj.

We created a baseline system based on the cluster-ranking model proposed by Rahman and Ng (2009). $$$$$ Our work bridges this gap by realizing in a new machine learning framework ideas rooted in Lappin and Leass’s (1994) heuristic-based pronoun resolver, which in turn was motivated by classic salience-based approaches to anaphora resolution.
We created a baseline system based on the cluster-ranking model proposed by Rahman and Ng (2009). $$$$$ The notion of ranking candidate antecedents can be traced back to centering algorithms, many of which use grammatical roles to rank forward-looking centers (see Grosz et al. (1995), Walker et al.
We created a baseline system based on the cluster-ranking model proposed by Rahman and Ng (2009). $$$$$ Each training instance, i(cj, mk), represents cj and mk.
We created a baseline system based on the cluster-ranking model proposed by Rahman and Ng (2009). $$$$$ We propose a cluster-ranking approach to coreference resolution that combines the strengths of mention rankers and entitymention models.

Rahman and Ng (2009) in particular propose the cluster-ranking model which we used in our baseline. $$$$$ Crucially, our approach combines the strengths of entity-mention models and mention-ranking models.
Rahman and Ng (2009) in particular propose the cluster-ranking model which we used in our baseline. $$$$$ This work was supported in part by NSF Grant IIS-0812261.
Rahman and Ng (2009) in particular propose the cluster-ranking model which we used in our baseline. $$$$$ This work was supported in part by NSF Grant IIS-0812261.
Rahman and Ng (2009) in particular propose the cluster-ranking model which we used in our baseline. $$$$$ Second, their algorithm is heuristic-based; in particular, the score assigned to a preceding cluster is computed by summing over the weights associated with the factors applicable to the cluster, where the weights are determined heuristically, rather than learned, unlike ours.

In each query we include a null-cluster instance, to allow joint learning of discourse-new detection, following (Rahman and Ng, 2009). $$$$$ We additionally show how our cluster-ranking framework naturally allows discourse-new entity detection to be learned jointly with coreference resolution.
In each query we include a null-cluster instance, to allow joint learning of discourse-new detection, following (Rahman and Ng, 2009). $$$$$ Overall, we believe that our cluster-ranking approach advances the state-of-the-art in coreference resolution both theoretically and empirically.
In each query we include a null-cluster instance, to allow joint learning of discourse-new detection, following (Rahman and Ng, 2009). $$$$$ As we can see, the ranker achieves F-scores of 57.8–71.2 and 54.1–65.4 for true mentions and system mentions, respectively, yielding a significant improvement over the entity-mention baseline in all but one case (MUC/true mentions).

We follow Rahman and Ng (2009) in jointly learning to detect anaphoric mentions along with resolving coreference relations. $$$$$ We have presented a cluster-ranking approach that recasts the mention resolution process as the problem of finding the best preceding cluster to link an active mention to.
We follow Rahman and Ng (2009) in jointly learning to detect anaphoric mentions along with resolving coreference relations. $$$$$ We thank the three anonymous reviewers for their invaluable comments on the paper.
We follow Rahman and Ng (2009) in jointly learning to detect anaphoric mentions along with resolving coreference relations. $$$$$ The main advantage of jointly learning the two tasks is that it allows the ranking model to evaluate all possible options for an active mention (i.e., whether to resolve it, and if so, which preceding cluster is the best) simultaneously.

We follow the procedure described in (Rahman and Ng, 2009). $$$$$ Specifically, we recast coreference as the problem of determining which of a set of preceding coreference clusters is the best to link to an active mention using a learned cluster ranker.
We follow the procedure described in (Rahman and Ng, 2009). $$$$$ We propose a cluster-ranking approach to coreference resolution that combines the strengths of mention rankers and entitymention models.
We follow the procedure described in (Rahman and Ng, 2009). $$$$$ Luo et al. (2004) represent one of the earliest attempts to investigate learning-based entity-mention models.
We follow the procedure described in (Rahman and Ng, 2009). $$$$$ Experimental results on the ACE 2005 corpus show that (1) jointly learning coreference resolution and discourse-new detection allows the cluster ranker to achieve better performance than adopting a pipeline coreference architecture; and (2) our cluster ranker significantly outperforms the mention ranker, the best of the three baseline coreference models, under both the pipeline architecture and the joint architecture.

In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ They use the ANY predicate to generate clusterlevel features as follows: given a binary-valued feature X defined over a pair of mentions, they introduce an ANY-X cluster-level feature, which has the value TRUE if X is true between the active mention and any mention in the preceding cluster under consideration.
In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ Specifically, when training the ranker, we provide each active mention with the option to start a new cluster by creating an additional instance that (1) contains features that solely describe the active mention (i.e., the features shown in the second block of Table 1), and (2) has the highest rank value among competing clusters (i.e., 2) if it is discourse-new and the lowest rank value (i.e., 1) otherwise.
In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ The test instances are then presented to the ranker, and mk is linked to the cluster that is assigned the highest value by the ranker.
In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ We additionally show how our cluster-ranking framework naturally allows discourse-new entity detection to be learned jointly with coreference resolution.

 $$$$$ This work was supported in part by NSF Grant IIS-0812261.
 $$$$$ We thank the three anonymous reviewers for their invaluable comments on the paper.
 $$$$$ We have presented a cluster-ranking approach that recasts the mention resolution process as the problem of finding the best preceding cluster to link an active mention to.
 $$$$$ Ranking is arguably a more natural reformulation of coreference resolution than classification, as a ranker allows all candidate antecedents to be considered simultaneously and therefore directly captures the competition among them.

Also, the B3 variant used by Rahman and Ng (2009) is slightly different from other systems (they remove all and only the singleton twinless system mentions, so it is neither B3All nor B3None). $$$$$ Overall, we believe that our cluster-ranking approach advances the state-of-the-art in coreference resolution both theoretically and empirically.
Also, the B3 variant used by Rahman and Ng (2009) is slightly different from other systems (they remove all and only the singleton twinless system mentions, so it is neither B3All nor B3None). $$$$$ We additionally show how our cluster-ranking framework naturally allows discourse-new entity detection to be learned jointly with coreference resolution.
Also, the B3 variant used by Rahman and Ng (2009) is slightly different from other systems (they remove all and only the singleton twinless system mentions, so it is neither B3All nor B3None). $$$$$ As in the mention-pair model, three training instances will be generated for He: i(Monday, He), i(secretary of state, He), i(his, He).
Also, the B3 variant used by Rahman and Ng (2009) is slightly different from other systems (they remove all and only the singleton twinless system mentions, so it is neither B3All nor B3None). $$$$$ Another desirable consequence is that there exists a natural resolution strategy for a ranking approach: a mention is resolved to the candidate antecedent that has the highest rank.

The other systems we compare to and outperform are the perceptron-based Reconcile system of Stoyanov et al (2009), the strong deterministic system of Haghighi and Klein (2009), and the cluster-ranking model of Rahman and Ng (2009). $$$$$ To extract system mentions from a test text, we trained a mention extractor on the training texts.
The other systems we compare to and outperform are the perceptron-based Reconcile system of Stoyanov et al (2009), the strong deterministic system of Haghighi and Klein (2009), and the cluster-ranking model of Rahman and Ng (2009). $$$$$ Traditional learning-based coreference reoperate by training a mentionfor determining whether two mentions are coreferent or not.
The other systems we compare to and outperform are the perceptron-based Reconcile system of Stoyanov et al (2009), the strong deterministic system of Haghighi and Klein (2009), and the cluster-ranking model of Rahman and Ng (2009). $$$$$ The only difference lies in the assignment of class values to training instances.

To extract NPs from the ACE-annotated documents, we train a mention extractor on the training texts (see Section 5.1 of Rahman and Ng (2009) for details), which recalls 83.6% of the NPs in the test set. $$$$$ We additionally show how our cluster-ranking framework naturally allows discourse-new entity detection to be learned jointly with coreference resolution.
To extract NPs from the ACE-annotated documents, we train a mention extractor on the training texts (see Section 5.1 of Rahman and Ng (2009) for details), which recalls 83.6% of the NPs in the test set. $$$$$ Overall, we believe that our cluster-ranking approach advances the state-of-the-art in coreference resolution both theoretically and empirically.
To extract NPs from the ACE-annotated documents, we train a mention extractor on the training texts (see Section 5.1 of Rahman and Ng (2009) for details), which recalls 83.6% of the NPs in the test set. $$$$$ The first two blocks consist of features that describe the properties of mj and mk, respectively, and the last two blocks of features describe the relationship between mj and mk.
To extract NPs from the ACE-annotated documents, we train a mention extractor on the training texts (see Section 5.1 of Rahman and Ng (2009) for details), which recalls 83.6% of the NPs in the test set. $$$$$ Discourse-new detection.

Since space limitations preclude a description of these features, we refer the reader to Rahman and Ng (2009) for details. $$$$$ We have presented a cluster-ranking approach that recasts the mention resolution process as the problem of finding the best preceding cluster to link an active mention to.
Since space limitations preclude a description of these features, we refer the reader to Rahman and Ng (2009) for details. $$$$$ In other words, the model still relies heavily on features used in a mention-pair model.

Details of the CR model can be found in Rahman and Ng (2009). $$$$$ In this section, we describe our cluster-ranking approach to NP coreference.
Details of the CR model can be found in Rahman and Ng (2009). $$$$$ Two independent lines of recent research have attempted to improve these mention-pair one by learning a mentionto rank preceding mentions for a given anaphor, and the other training an to determine whether a preceding cluster is coreferent with a given mention.
Details of the CR model can be found in Rahman and Ng (2009). $$$$$ Overall, we believe that our cluster-ranking approach advances the state-of-the-art in coreference resolution both theoretically and empirically.
Details of the CR model can be found in Rahman and Ng (2009). $$$$$ Our work advances the state-of-the-art in coreference resolution by bringing learningbased coreference systems to the next level of performance.

Also, the results show that the CR model is stronger than the MP model, corroborating previous empirical findings (Rahman and Ng, 2009). $$$$$ Each instance represents wi, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al. (1999) and Florian et al.
Also, the results show that the CR model is stronger than the MP model, corroborating previous empirical findings (Rahman and Ng, 2009). $$$$$ This work was supported in part by NSF Grant IIS-0812261.
Also, the results show that the CR model is stronger than the MP model, corroborating previous empirical findings (Rahman and Ng, 2009). $$$$$ Finally, mk will be linked to the closest preceding cluster that is classified as coreferent with mk.

The cluster ranking model of Rahman and Ng (2009) proceeds in a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster. $$$$$ The rest of the paper is structured as follows.
The cluster ranking model of Rahman and Ng (2009) proceeds in a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster. $$$$$ Semantic (1): The named entity (NE) tag of wi obtained using the Stanford CRF-based NE recognizer (Finkel et al., 2005).
The cluster ranking model of Rahman and Ng (2009) proceeds in a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster. $$$$$ Following Yang et al. (2008), we create (1) a positive instance for each discourse-old mention mk and the preceding cluster cj to which it belongs; and (2) a negative instance for mk paired with each partial cluster whose last mention appears between mk and its closest antecedent (i.e., the last mention of cj).
The cluster ranking model of Rahman and Ng (2009) proceeds in a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster. $$$$$ Traditional learning-based coreference reoperate by training a mentionfor determining whether two mentions are coreferent or not.
