Shallow semantic representations, bearing a more compact information, can prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ We define (a) new tree structures based on shallow semantics encoded in Predicate Argument Structures (PASs) and (b) new kernel functions to exploit the representational power of such structures with Support Vector Machines.
Shallow semantic representations, bearing a more compact information, can prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ We thank the anonymous reviewers for their helpful suggestions.
Shallow semantic representations, bearing a more compact information, can prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ We prove by induction the above claim.
Shallow semantic representations, bearing a more compact information, can prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ We have defined tree structures (PAS and PASN) to represent predicateargument relations, which we automatically extract using our SRL system.

There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). $$$$$ We study the impact of syntactic and shallow semantic information in automatic classification of questions and answers and answer re-ranking.
There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). $$$$$ Alessandro Moschitti would like to thank the AMI2 lab at the University of Trento and the EU project LUNA “spoken Language UNderstanding in multilinguAl communication systems” contract no 33549 for supporting part of his research.
There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). $$$$$ (b) PB predicative structures are not effective for question classification but show promising results for answer classification on a corpus of answers to TREC-QA 2001 description questions.

Shallow semantic representations, bearing a more compact information, could prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ We have defined tree structures (PAS and PASN) to represent predicateargument relations, which we automatically extract using our SRL system.
Shallow semantic representations, bearing a more compact information, could prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ Here, too, the syntactic structure of a sentence appears to provide more useful information than a bag of words (Chen et al., 2006), although the correct way to exploit it is still an open problem.
Shallow semantic representations, bearing a more compact information, could prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ Such annotation can be used to design a shallow semantic representation that can be matched against other semantically similar sentences, e.g.
Shallow semantic representations, bearing a more compact information, could prevent the sparseness of deep structural approaches and the weakness of BOW models (Moschitti et al, 2007). $$$$$ Alessandro Moschitti would like to thank the AMI2 lab at the University of Trento and the EU project LUNA “spoken Language UNderstanding in multilinguAl communication systems” contract no 33549 for supporting part of his research.

(Moschitti et al, 2007) solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a ST. $$$$$ Alessandro Moschitti would like to thank the AMI2 lab at the University of Trento and the EU project LUNA “spoken Language UNderstanding in multilinguAl communication systems” contract no 33549 for supporting part of his research.
(Moschitti et al, 2007) solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a ST. $$$$$ As an example, for question “What is foreclosure?”, the sentence “Foreclosure means that the lender takes possession of your home and sells it in order to get its money back.” was correctly classified by the best model, while BOW failed.
(Moschitti et al, 2007) solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a ST. $$$$$ Alessandro Moschitti would like to thank the AMI2 lab at the University of Trento and the EU project LUNA “spoken Language UNderstanding in multilinguAl communication systems” contract no 33549 for supporting part of his research.
(Moschitti et al, 2007) solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a ST. $$$$$ When PT is used for the answer the simple BOW model is outperformed by 2 to 3 points.

 $$$$$ In particular, we focus on question classification and answer re-ranking for Web-based QA systems.
 $$$$$ Second, as the original tree kernel would generate many matches with slots filled with the null label, we have set a new step 0: (0) if n1 (or n2) is a pre-terminal node and its child label is null, Δ(n1, n2) = 0; and subtract one unit to Δ(n1, n2), in step 3: The above changes generate a new Δ which, when substituted (in place of the original Δ) in Eq.
 $$$$$ This suggests that the dependencies between the nested PASs are in some way captured by the PT information.

Counting the number of matched dependencies is essentially a simplified tree kernel for QA (e.g., see (Moschitti et al, 2007)) matching only trees of depth 2. $$$$$ Our experiments suggest that syntactic information helps tasks such as question/answer classification and that shallow semantics gives remarkable contribution when a reliable set of PASs can be extracted, e.g. from answers.
Counting the number of matched dependencies is essentially a simplified tree kernel for QA (e.g., see (Moschitti et al, 2007)) matching only trees of depth 2. $$$$$ Initiatives such as PropBank (PB) (Kingsbury and Palmer, 2002) have made possible the design of accurate automatic Semantic Role Labeling (SRL) systems (Carreras and M`arquez, 2005).
Counting the number of matched dependencies is essentially a simplified tree kernel for QA (e.g., see (Moschitti et al, 2007)) matching only trees of depth 2. $$$$$ Our experiments using SVMs and the above kernels and data (Section 4) shows the following: (a) our approach reaches state-of-the-art accuracy on question classification.
Counting the number of matched dependencies is essentially a simplified tree kernel for QA (e.g., see (Moschitti et al, 2007)) matching only trees of depth 2. $$$$$ We study the impact of syntactic and shallow semantic information in automatic classification of questions and answers and answer re-ranking.

In particular, in (Moschitti et al, 2007) kernels for the processing of PASs (in PropBank1 format (Kingsbury and Palmer, 2002)) extracted from question/answer pairs were proposed. $$$$$ Section 3 introduces a viable approach based on tree kernels.
In particular, in (Moschitti et al, 2007) kernels for the processing of PASs (in PropBank1 format (Kingsbury and Palmer, 2002)) extracted from question/answer pairs were proposed. $$$$$ In the question classification task, we extend previous studies, e.g.
In particular, in (Moschitti et al, 2007) kernels for the processing of PASs (in PropBank1 format (Kingsbury and Palmer, 2002)) extracted from question/answer pairs were proposed. $$$$$ BOW and POS are processed by means of a linear kernel, PT is processed with TK, PAS and PASN are processed by SSTK.
In particular, in (Moschitti et al, 2007) kernels for the processing of PASs (in PropBank1 format (Kingsbury and Palmer, 2002)) extracted from question/answer pairs were proposed. $$$$$ Q(BOW) + A(PT,BOW).

Then, we design a novel shallow semantic kernel which is far more efficient and also more accurate than the one proposed in (Moschitti et al, 2007). $$$$$ Our experiments with SVMs and the above models suggest that syntactic information helps tasks such as question classification whereas semantic information contained in PAS and PASN gives promising results in answer classification.
Then, we design a novel shallow semantic kernel which is far more efficient and also more accurate than the one proposed in (Moschitti et al, 2007). $$$$$ Hence, we infer that both the answer’s PT and BOW features are very useful in the classification task.
Then, we design a novel shallow semantic kernel which is far more efficient and also more accurate than the one proposed in (Moschitti et al, 2007). $$$$$ Forms of generalization for predicates and arguments within PASNs like LSA clusters, WordNet synsets and FrameNet (roles and frames) information also appear as a promising research area.
Then, we design a novel shallow semantic kernel which is far more efficient and also more accurate than the one proposed in (Moschitti et al, 2007). $$$$$ Alessandro Moschitti would like to thank the AMI2 lab at the University of Trento and the EU project LUNA “spoken Language UNderstanding in multilinguAl communication systems” contract no 33549 for supporting part of his research.

To overcome this problem, a Shallow Semantic Tree Kernel (SSTK) was designed in (Moschitti et al, 2007). $$$$$ Taken as standalone, such PASs do not express the whole meaning of the sentence; it is more accurate to define a single structure encoding the dependency between the two predicates as in It is worth to note that semantically equivalent sentences syntactically expressed in different ways share the same PB arguments and the same PASs, whereas semantically different sentences result in different PASs.
To overcome this problem, a Shallow Semantic Tree Kernel (SSTK) was designed in (Moschitti et al, 2007). $$$$$ Question answering (QA) is as a form of information retrieval where one or more answers are returned to a question in natural language in the form of sentences or phrases.
To overcome this problem, a Shallow Semantic Tree Kernel (SSTK) was designed in (Moschitti et al, 2007). $$$$$ We thank the anonymous reviewers for their helpful suggestions.
To overcome this problem, a Shallow Semantic Tree Kernel (SSTK) was designed in (Moschitti et al, 2007). $$$$$ We define: While during the experiments (Sect.

Thus, ? can recursively be an SRK (and evaluate Nested PASs (Moschitti et al, 2007)) or any other potential kernel (over the arguments). $$$$$ We thank the anonymous reviewers for their helpful suggestions.
Thus, ? can recursively be an SRK (and evaluate Nested PASs (Moschitti et al, 2007)) or any other potential kernel (over the arguments). $$$$$ (c) The answer classifier increases the ranking accuracy of our QA system by about 25%.
Thus, ? can recursively be an SRK (and evaluate Nested PASs (Moschitti et al, 2007)) or any other potential kernel (over the arguments). $$$$$ Alessandro Moschitti would like to thank the AMI2 lab at the University of Trento and the EU project LUNA “spoken Language UNderstanding in multilinguAl communication systems” contract no 33549 for supporting part of his research.

The result is 89.05? 1.25 and 83.73? 1.61 for 6 and 50 classes, which outperforms the best result of 86.1? 1.1 for 6 classes as reported in (Moschitti et al, 2007). $$$$$ We thank the anonymous reviewers for their helpful suggestions.
The result is 89.05? 1.25 and 83.73? 1.61 for 6 and 50 classes, which outperforms the best result of 86.1? 1.1 for 6 classes as reported in (Moschitti et al, 2007). $$$$$ The experiments were organized as follows: First, we examined the contributions of BOW and PT representations as they proved very important for question classification.
The result is 89.05? 1.25 and 83.73? 1.61 for 6 and 50 classes, which outperforms the best result of 86.1? 1.1 for 6 classes as reported in (Moschitti et al, 2007). $$$$$ Forms of generalization for predicates and arguments within PASNs like LSA clusters, WordNet synsets and FrameNet (roles and frames) information also appear as a promising research area.
The result is 89.05? 1.25 and 83.73? 1.61 for 6 and 50 classes, which outperforms the best result of 86.1? 1.1 for 6 classes as reported in (Moschitti et al, 2007). $$$$$ The retrieval and answer extraction phases consist in retrieving relevant documents (Collins-Thompson et al., 2004) and selecting candidate answer passages from them.

In (Moschitti et al, 2007) it was shown that the use of TK improves QC of 1.2 percent points, i.e. from 90.6 to 91.8 $$$$$ We thank the anonymous reviewers for their helpful suggestions.
In (Moschitti et al, 2007) it was shown that the use of TK improves QC of 1.2 percent points, i.e. from 90.6 to 91.8 $$$$$ Such PAS node is actually the root of the subordinate clause in Figure 2.(b).
In (Moschitti et al, 2007) it was shown that the use of TK improves QC of 1.2 percent points, i.e. from 90.6 to 91.8 $$$$$ 2.(b).
In (Moschitti et al, 2007) it was shown that the use of TK improves QC of 1.2 percent points, i.e. from 90.6 to 91.8 $$$$$ Q(PT) + A(PT,BOW) combinations).

In (Moschitti et al, 2007), we proposed the Shallow Semantic Tree Kernel (SSTK) designed to encode PASs1 in SVMs. $$$$$ In this paper, we extensively study new structural representations, encoding parse trees, bag-of-words, POS tags and predicate argument structures (PASs) for question classification and answer re-ranking.

Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ Traditionally, information retrieval techniques are based on the bag-of-words (BOW) approach augmented by language modeling (Allan et al., 2002).
Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ We have also introduced two functions, SSTK and Kall, to exploit their representative power.
Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ Figure 4 reports the plot of the F1-measure of answer classifiers trained with all combinations of the above models according to different values of the cost-factor parameter, adjusting the rate between Precision and Recall.

Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ Proof We observe that a kernel applied to a tree and itself computes all its substructures, thus if we evaluate SSTK between a PAS and itself we must obtain the number of generated k-ary relations.
Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ When the task requires the use of more complex semantics, the above approaches are often inadequate to perform fine-level textual analysis.
Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ Forms of generalization for predicates and arguments within PASNs like LSA clusters, WordNet synsets and FrameNet (roles and frames) information also appear as a promising research area.
Instead, the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into account, thus it fails to capture the linguistic rationale expressed above. $$$$$ Here, too, the syntactic structure of a sentence appears to provide more useful information than a bag of words (Chen et al., 2006), although the correct way to exploit it is still an open problem.

In future work, we intend to expand our analysis of both the gold-standard answer and the student answers beyond the bag-of-words paradigm by considering basic logical features in the text (i.e., AND, OR, NOT) as well as the existence of shallow grammatical features such as predicate argument structure (Moschitti et al, 2007) as well as semantic classes for words. $$$$$ Our results show that PAS and syntactic parsing are promising methods to address tasks affected by data sparseness like question/answer categorization.
In future work, we intend to expand our analysis of both the gold-standard answer and the student answers beyond the bag-of-words paradigm by considering basic logical features in the text (i.e., AND, OR, NOT) as well as the existence of shallow grammatical features such as predicate argument structure (Moschitti et al, 2007) as well as semantic classes for words. $$$$$ We created such dataset by using YourQA (Quarteroni and Manandhar, 2006), our basic Webbased QA system1.
In future work, we intend to expand our analysis of both the gold-standard answer and the student answers beyond the bag-of-words paradigm by considering basic logical features in the text (i.e., AND, OR, NOT) as well as the existence of shallow grammatical features such as predicate argument structure (Moschitti et al, 2007) as well as semantic classes for words. $$$$$ SNoW (Li and Roth, 2005), where questions are encoded using various lexical, syntactic and semantic features.
