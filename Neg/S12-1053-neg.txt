Recently, a new dataset including "Unknown" pairs has been used in the "Cross-Lingual Textual Entailment for Content Synchronization" task at SemEval-2012 (Negri et al, 2012). $$$$$ Participants were presented with datasets for different language pairs, where multi-directional entailment relations (“forward”, “backward”, “bidirectional”, “no entailment”) had to be identified.
Recently, a new dataset including "Unknown" pairs has been used in the "Cross-Lingual Textual Entailment for Content Synchronization" task at SemEval-2012 (Negri et al, 2012). $$$$$ These scores aim at giving participants the possibility to gain clearer insights into their system’s behavior on the entailment phenomena relevant to the task.
Recently, a new dataset including "Unknown" pairs has been used in the "Cross-Lingual Textual Entailment for Content Synchronization" task at SemEval-2012 (Negri et al, 2012). $$$$$ Alternatively, the task can be seen as a machine translation evaluation problem, where judgments about semantic equivalence and novelty depend on the possibility to fully or partially translate a text fragment into the other.

 $$$$$ Our ambition, for the future editions of the CLTE task, is to further consolidate the bridge between the semantics and MT communities.
 $$$$$ Wiki pages), the task consists of automatically detecting and resolving differences in the information they provide, in order to produce aligned, mutually enriched versions of the two documents.
 $$$$$ Baseline results are reported in Table 2.
 $$$$$ The datasets are released in the XML format shown in Figure 1.

For a comprehensive description of the task see (Negri et al, 2012). $$$$$ In line with a number of systems that model the RTE task as a similarity problem (i.e. handling similarity scores between T and H as useful evidence to draw entailment decisions), the standard sentence and word alignment programs used in SMT offer a strong baseline for CLTE.
For a comprehensive description of the task see (Negri et al, 2012). $$$$$ Content synchronization represents a challenging application scenario to test the capabilities of advanced NLP systems.
For a comprehensive description of the task see (Negri et al, 2012). $$$$$ The CLTE task aims at prompting research to fill this gap.

Readers can refer to M. Negri et al 2012.s., for more detailed introduction. $$$$$ The best performing system relies on a “hybrid” approach (combining monolingual and cross-lingual alignments) and a compositional strategy.
Readers can refer to M. Negri et al 2012.s., for more detailed introduction. $$$$$ The datasets are released in the XML format shown in Figure 1.
Readers can refer to M. Negri et al 2012.s., for more detailed introduction. $$$$$ The authors would also like to acknowledge Giovanni Moretti from CELCT for evaluation scripts and technical assistance, and the volunteer translators that contributed to the creation of the dataset:
Readers can refer to M. Negri et al 2012.s., for more detailed introduction. $$$$$ Participants were presented with datasets for different language pairs, where multi-directional entailment relations (“forward”, “backward”, “bidirectional”, “no entailment”) had to be identified.

Spanish data sets provided in the task 8 of SemEval 2012 (Negri et al, 2012). $$$$$ Towards this objective, a crucial requirement is to identify the information in one page that is either equivalent or novel (more informative) with respect to the content of the other.
Spanish data sets provided in the task 8 of SemEval 2012 (Negri et al, 2012). $$$$$ To better understand the behaviour of each system (also in relation to the different language combinations), Table 4 provides separate precision, recall, and F1 scores for each entailment judgment, calculated over the best runs of each participating team.
Spanish data sets provided in the task 8 of SemEval 2012 (Negri et al, 2012). $$$$$ In one run (Run 1), they are used to train a classifier that assigns separate entailment judgments for each direction.
Spanish data sets provided in the task 8 of SemEval 2012 (Negri et al, 2012). $$$$$ The authors would also like to acknowledge Giovanni Moretti from CELCT for evaluation scripts and technical assistance, and the volunteer translators that contributed to the creation of the dataset:

The SemEval-2012 CLTE task (Negri et al, 2012) asks participants to judge entailment pairs in four language combinations, defining four target entailment relations, for ward, backward, bidirectional and no entailment. $$$$$ HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction.
The SemEval-2012 CLTE task (Negri et al, 2012) asks participants to judge entailment pairs in four language combinations, defining four target entailment relations, for ward, backward, bidirectional and no entailment. $$$$$ These scores aim at giving participants the possibility to gain clearer insights into their system’s behavior on the entailment phenomena relevant to the task.
The SemEval-2012 CLTE task (Negri et al, 2012) asks participants to judge entailment pairs in four language combinations, defining four target entailment relations, for ward, backward, bidirectional and no entailment. $$$$$ Although contradiction is relevant from an application-oriented perspective, contradictory pairs are not present in the dataset created for the first round of the task.
The SemEval-2012 CLTE task (Negri et al, 2012) asks participants to judge entailment pairs in four language combinations, defining four target entailment relations, for ward, backward, bidirectional and no entailment. $$$$$ The task can be naturally cast as an entailment recognition problem, where bidirectional and unidirectional entailment judgments for two text fragments are respectively mapped into judgments about semantic equivalence and novelty.

Cross-Lingual Text Entailment (CLTE), besides introducing the extra dimension of cross-linguality, also requires to determine the exact direction of the entailment relation, to provide content synchronization (Negri et al, 2012). $$$$$ Given a pair of topically related text fragments (T1 and T2) in different languages, the CLTE task consists of automatically annotating it with one of the following entailment judgments (see Figure 1 for Spanish/English examples of each judgment): In this task, both T1 and T2 are assumed to be true statements.
Cross-Lingual Text Entailment (CLTE), besides introducing the extra dimension of cross-linguality, also requires to determine the exact direction of the entailment relation, to provide content synchronization (Negri et al, 2012). $$$$$ The CLTE task aims at prompting research to fill this gap.
Cross-Lingual Text Entailment (CLTE), besides introducing the extra dimension of cross-linguality, also requires to determine the exact direction of the entailment relation, to provide content synchronization (Negri et al, 2012). $$$$$ The authors would also like to acknowledge Giovanni Moretti from CELCT for evaluation scripts and technical assistance, and the volunteer translators that contributed to the creation of the dataset:
Cross-Lingual Text Entailment (CLTE), besides introducing the extra dimension of cross-linguality, also requires to determine the exact direction of the entailment relation, to provide content synchronization (Negri et al, 2012). $$$$$ This paper presents the first round of the on Textual Entailment for organized within SemEval-2012.

In this paper we have presented the DirRelCond3 systems that participated at the CLTE task (Negri et al., 2012) from SemEval-2012. $$$$$ The authors would also like to acknowledge Giovanni Moretti from CELCT for evaluation scripts and technical assistance, and the volunteer translators that contributed to the creation of the dataset:
In this paper we have presented the DirRelCond3 systems that participated at the CLTE task (Negri et al., 2012) from SemEval-2012. $$$$$ The proposed approaches reflect this situation, with teams traditionally working on MT now dealing with entailment, and teams traditionally participating in the RTE challenges now dealing with cross-lingual alignment techniques.
In this paper we have presented the DirRelCond3 systems that participated at the CLTE task (Negri et al., 2012) from SemEval-2012. $$$$$ In fact, as shown in Table 1, the majority of the pairs is always included in the same length diff range (approximately [-5,+5]) and, within this range, the distribution of the four classes is substantially uniform.
In this paper we have presented the DirRelCond3 systems that participated at the CLTE task (Negri et al., 2012) from SemEval-2012. $$$$$ Participants were allowed to submit up to five runs for each language combination.
