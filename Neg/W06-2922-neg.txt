Bick (2006) used the lowercased FORM if the LEMMA is not available, Corston-Oliver and Aue (2006) a prefix and Attardi (2006) a stem derived by a rule-based system for Danish, German and Swedish. $$$$$ Prepositions are problematic, but their error rate is higher than expected since they are, in terms of surface order, rather regular and close to the noun.
Bick (2006) used the lowercased FORM if the LEMMA is not available, Corston-Oliver and Aue (2006) a prefix and Attardi (2006) a stem derived by a rule-based system for Danish, German and Swedish. $$$$$ Prepositions are problematic, but their error rate is higher than expected since they are, in terms of surface order, rather regular and close to the noun.
Bick (2006) used the lowercased FORM if the LEMMA is not available, Corston-Oliver and Aue (2006) a prefix and Attardi (2006) a stem derived by a rule-based system for Danish, German and Swedish. $$$$$ Here is an example of non-projectivity that can be handled with Right2 (nejen --+ ale) and Left3 (fax --+ Vetšinu): Vetšinu techto prístroju lze take používat nejen jako fax, ale soucasne ... V6tšinu t6chto pfístroju lze take používat nejen jako fax , ale The remaining cases are handled with the last two actions: Extract is used to postpone the creation of a link, by saving the token in a temporary stack; Insert restores the token from the temporary stack and resumes normal processing. zou gemaakt moeten worden in This fragment in Dutch is dealt by performing an Extract in configuration (moeten|gemaakt|zou, worden|in, A) followed immediately by an Insert, leading to the following configuration, which can be handled by normal Shift/Reduce actions: zou moeten worden gemaakt in Another linguistic phenomenon is the anticipation of pronouns, like in this Portuguese fragment: Tudo a possive7 encontrar em o IX Sa7�o de Antiguidades, desde objectos de ouro e prata, moedas, ...
Bick (2006) used the lowercased FORM if the LEMMA is not available, Corston-Oliver and Aue (2006) a prefix and Attardi (2006) a stem derived by a rule-based system for Danish, German and Swedish. $$$$$ Dependency parsers are promising for these applications since a dependency tree provides predicate-argument relations which are convenient for use in the later stages.

Use only some components, e.g. Bick (2006) uses only case, mood and pronoun subclass and Attardi (2006) uses only gender, number, person and case. $$$$$ No pre-processing or post-processing is used, except stemming for Danish, German and Swedish.
Use only some components, e.g. Bick (2006) uses only case, mood and pronoun subclass and Attardi (2006) uses only gender, number, person and case. $$$$$ A post-processing step is then required to restore the arcs to the proper heads.
Use only some components, e.g. Bick (2006) uses only case, mood and pronoun subclass and Attardi (2006) uses only gender, number, person and case. $$$$$ Right1 in a configuration (s1|S, n|I, T, A), adds an arc from s1 to n and pops s1 from the stack, producing the configuration (S, n|I, T, A∪{(s1, r, n)}).
Use only some components, e.g. Bick (2006) uses only case, mood and pronoun subclass and Attardi (2006) uses only gender, number, person and case. $$$$$ Parsing natural language is an essential step in several applications that involve document analysis, e.g. knowledge extraction, question answering, summarization, filtering.

The most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others. $$$$$ No pre-processing or post-processing is used, except stemming for Danish, German and Swedish.
The most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others. $$$$$ The labels ending with _Co, _Ap or _Pa are nodes who are members of the Coordination, Apposition or the Parenthetical relation, so it may be worth while omitting these suffixes in learning and restore them by post-processing.
The most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others. $$$$$ Here is an example of non-projectivity that can be handled with Right2 (nejen --+ ale) and Left3 (fax --+ Vetšinu): Vetšinu techto prístroju lze take používat nejen jako fax, ale soucasne ... V6tšinu t6chto pfístroju lze take používat nejen jako fax , ale The remaining cases are handled with the last two actions: Extract is used to postpone the creation of a link, by saving the token in a temporary stack; Insert restores the token from the temporary stack and resumes normal processing. zou gemaakt moeten worden in This fragment in Dutch is dealt by performing an Extract in configuration (moeten|gemaakt|zou, worden|in, A) followed immediately by an Insert, leading to the following configuration, which can be handled by normal Shift/Reduce actions: zou moeten worden gemaakt in Another linguistic phenomenon is the anticipation of pronouns, like in this Portuguese fragment: Tudo a possive7 encontrar em o IX Sa7�o de Antiguidades, desde objectos de ouro e prata, moedas, ...

Speech tagger described in Dell Orletta (2009) and dependency parsed by the DeSR parser (Attardi,2006) using Support Vector Machine as learning algorithm. $$$$$ I experimented adding various features controlled by the parameters above: none appeared to be effective, except the addition of the previous action.
Speech tagger described in Dell Orletta (2009) and dependency parsed by the DeSR parser (Attardi,2006) using Support Vector Machine as learning algorithm. $$$$$ Often this is due to the fact that commas introduce relative phrases or parenthetical phrases (e.g.
Speech tagger described in Dell Orletta (2009) and dependency parsed by the DeSR parser (Attardi,2006) using Support Vector Machine as learning algorithm. $$$$$ Tests on the PDT (Böhmovà et al., 2003) show that the added actions are sufficient to handle all cases of non-projectivity.
Speech tagger described in Dell Orletta (2009) and dependency parsed by the DeSR parser (Attardi,2006) using Support Vector Machine as learning algorithm. $$$$$ I tried to add some global context features, to be able to distinguish these cases, in particular, a count of the number of punctuation marks seen so far, whether punctuation is present between the focus words.

This model is a version of DeSR (Attardi, 2006), a deterministic classifier-based Shift/Reduce parser. $$$$$ The parser by Yamada and Matsumoto (2003) used the following actions: Shift in a configuration (S, n|I, T, A), pushes n to the stack, producing the configuration (n|S, I, T, A).
This model is a version of DeSR (Attardi, 2006), a deterministic classifier-based Shift/Reduce parser. $$$$$ Insert in a configuration (S, I, s1|T, A), pops s1 from T and pushes it to the stack, producing the configuration (s1|S, I, T, A).

Transition based parsers typically have a linear or quadratic complexity (Attardi, 2006) .Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ The best performing systems at the TREC Question Answering track employ parsing for analyzing sentences in order to identify the query focus, to extract relations and to disambiguate meanings of words.
Transition based parsers typically have a linear or quadratic complexity (Attardi, 2006) .Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ An experiment cycle in our setting requires less than 15 minutes for a treebank of moderate size like the Portuguese treebank (Afonso et al., 2002) and this allows evaluating the effectiveness of adding/removing features that hopefully might apply also when using other learning techniques.
Transition based parsers typically have a linear or quadratic complexity (Attardi, 2006) .Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ The settings used in the submitted runs are listed below and configure the parser for not using any word forms.

 $$$$$ No additional resources are used.
 $$$$$ Most current parsers for Czech do not perform well on Apos (apposition), Coord (coordination) and ExD (ellipses), but they are not very frequent.
 $$$$$ Parsing is also very fast, with an average throughput of 200 sentences per second: Table 1 reports parse time for parsing each whole test set.

However, other non-projective parsers such as (Attardi, 2006) follow a constructive approach and can be analysed deductively. $$$$$ On the other hand MBL achieves an improvement up to 5% in accuracy, as shown in detail in Table 1.
However, other non-projective parsers such as (Attardi, 2006) follow a constructive approach and can be analysed deductively. $$$$$ I used my own C++ implementation of Maximum Entropy, which is very fast both in learning and classification.
However, other non-projective parsers such as (Attardi, 2006) follow a constructive approach and can be analysed deductively. $$$$$ Shift/Reduce, one to decide which Reduce action and a third one to choose the dependency in case of Left/Right action For details on the CoNLL-X shared task and the measurements see (Buchholz, et al. 2006).

However, the goal of that transition is different from ours (selecting between projective and non projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition can not be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ Only CPOSTAG were used.
However, the goal of that transition is different from ours (selecting between projective and non projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition can not be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ LEMMA was used in features whenever available, otherwise the FORM was used.
However, the goal of that transition is different from ours (selecting between projective and non projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition can not be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ Labeling is integrated within a single processing step.
However, the goal of that transition is different from ours (selecting between projective and non projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition can not be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ For Danish, German and Swedish the Snowball stemmer (Porter 2001) was used to generate a value for LEMMA.

Non-projective transitions that create dependency arcs between non-contiguous nodes have been used in the transition-based parser by Attardi (2006). $$$$$ Using a notation similar to (Nivre and Scholz, 2003), the state of the parser is represented by a quadruple (S, I, T, A), where S is the stack, I is the list of (remaining) input tokens, T is a stack of temporary tokens and A is the arc relation for the dependency graph.
Non-projective transitions that create dependency arcs between non-contiguous nodes have been used in the transition-based parser by Attardi (2006). $$$$$ For example, the parameter PosFeatures determines for which tokens the POS tag will be included in the context, PosLeftChi7dren determines how many left outermost children of a token to consider, PastActions tells how many previous actions to include as features.
Non-projective transitions that create dependency arcs between non-contiguous nodes have been used in the transition-based parser by Attardi (2006). $$$$$ The high error rate of J (adjective) is expected, mainly due to coordination problems.

DeSR (Attardi, 2006) is an incremental deterministic classifier-based parser. $$$$$ I experimented adding various features controlled by the parameters above: none appeared to be effective, except the addition of the previous action.
DeSR (Attardi, 2006) is an incremental deterministic classifier-based parser. $$$$$ I used my own C++ implementation of Maximum Entropy, which is very fast both in learning and classification.
DeSR (Attardi, 2006) is an incremental deterministic classifier-based parser. $$$$$ The parser does not attempt to assign a dependency relation to the root.
DeSR (Attardi, 2006) is an incremental deterministic classifier-based parser. $$$$$ The best performing systems at the TREC Question Answering track employ parsing for analyzing sentences in order to identify the query focus, to extract relations and to disambiguate meanings of words.

This idea is demonstrated by Attardi (2006), who proposes a transition system whose individual transitions can deal with non-projective dependencies only to a limited extent, depending on the distance in the stack of the nodes involved in the newly constructed dependency. $$$$$ Given an input string W, the parser is initialized to ((), W, (), ()), and terminates when it reaches a configuration (S, (), (), A).
This idea is demonstrated by Attardi (2006), who proposes a transition system whose individual transitions can deal with non-projective dependencies only to a limited extent, depending on the distance in the stack of the nodes involved in the newly constructed dependency. $$$$$ Parsing is deterministic and proceeds bottom-up.
This idea is demonstrated by Attardi (2006), who proposes a transition system whose individual transitions can deal with non-projective dependencies only to a limited extent, depending on the distance in the stack of the nodes involved in the newly constructed dependency. $$$$$ On a 2.8 MHz Pentium Xeon PC, the learning time is about 15 minutes for Portuguese and 4 hours for Czech.
This idea is demonstrated by Attardi (2006), who proposes a transition system whose individual transitions can deal with non-projective dependencies only to a limited extent, depending on the distance in the stack of the nodes involved in the newly constructed dependency. $$$$$ In fact the pair Extract/Insert behaves like a generalized Rightn/Leftn, when n is not known.

The reported coverage in Attardi (2006) is already very high when the system is restricted to transitions of degree two or three. $$$$$ Parsing is deterministic and proceeds bottom-up.
The reported coverage in Attardi (2006) is already very high when the system is restricted to transitions of degree two or three. $$$$$ Insert in a configuration (S, I, s1|T, A), pops s1 from T and pushes it to the stack, producing the configuration (s1|S, I, T, A).
The reported coverage in Attardi (2006) is already very high when the system is restricted to transitions of degree two or three. $$$$$ The largest number of errors occur on Obj (166), Adv (155), Sb (113), Atr (98).
The reported coverage in Attardi (2006) is already very high when the system is restricted to transitions of degree two or three. $$$$$ For example, the parameter PosFeatures determines for which tokens the POS tag will be included in the context, PosLeftChi7dren determines how many left outermost children of a token to consider, PastActions tells how many previous actions to include as features.

Table 1 gives additional statistics for treebanks from the CoNLL-X shared task (Buchholz and Marsi, 2006). We now turn to describe our variant of the transition system of Attardi (2006), which is equivalent to the original system restricted to transitions of degree two. $$$$$ The use of SVM turned out quite impractical since the technique does not scale to the size of training data involved: training an SVM with such a large number of features was impossible for any of the larger corpora.
Table 1 gives additional statistics for treebanks from the CoNLL-X shared task (Buchholz and Marsi, 2006). We now turn to describe our variant of the transition system of Attardi (2006), which is equivalent to the original system restricted to transitions of degree two. $$$$$ Only a small improvement in labeled attachment score was noticed using the full, nonspecialized classifier to decide the action but discarding its suggestion for label and using a specialized classifier for labeling.

Table 1 $$$$$ Kiril Ribarov provided insightful comments on the results for Czech.

We turn next to describe the equivalence between our system and the system in Attardi (2006). $$$$$ The actions Right2 and Left2 are sufficient to handle almost all cases of non-projectivity: for instance the training data for Czech contain 28081 non-projective relations, of which 26346 can be handled by Left2/Right2, 1683 by Left3/Right3 and just 52 require Extract/Insert.
We turn next to describe the equivalence between our system and the system in Attardi (2006). $$$$$ The parser by Yamada and Matsumoto (2003) used the following actions: Shift in a configuration (S, n|I, T, A), pushes n to the stack, producing the configuration (n|S, I, T, A).
We turn next to describe the equivalence between our system and the system in Attardi (2006). $$$$$ I adopted a novel approach, which consists in adding six new parsing actions: Right2 in a configuration (s1|s2|S, n|I, T, A), adds an arc from s2 to n and removes s2 from the stack, producing the configuration (s1|S, n|I, T, Au{(s2, r, n)}).
We turn next to describe the equivalence between our system and the system in Attardi (2006). $$$$$ The parser constructs dependency trees employing a deterministic bottom-up algorithm which performs Shift/Reduce actions while analyzing input sentences in left-to-right order.

While in the previous sections we have described a tabular method for the transition system of Attardi (2006) restricted to transitions of degree up to two, it is possible to generalize the model to include higher degree transitions. $$$$$ Finally, I extended the repertoire of actions used by the parser, in order to handle non-projective relations.
While in the previous sections we have described a tabular method for the transition system of Attardi (2006) restricted to transitions of degree up to two, it is possible to generalize the model to include higher degree transitions. $$$$$ Using a notation similar to (Nivre and Scholz, 2003), the state of the parser is represented by a quadruple (S, I, T, A), where S is the stack, I is the list of (remaining) input tokens, T is a stack of temporary tokens and A is the arc relation for the dependency graph.
While in the previous sections we have described a tabular method for the transition system of Attardi (2006) restricted to transitions of degree up to two, it is possible to generalize the model to include higher degree transitions. $$$$$ On the other hand MBL achieves an improvement up to 5% in accuracy, as shown in detail in Table 1.
While in the previous sections we have described a tabular method for the transition system of Attardi (2006) restricted to transitions of degree up to two, it is possible to generalize the model to include higher degree transitions. $$$$$ The largest number of errors occur on Obj (166), Adv (155), Sb (113), Atr (98).

We build upon DeSR, the shift-reduce parser described in (Attardi, 2006). $$$$$ I used my own C++ implementation of Maximum Entropy, which is very fast both in learning and classification.
We build upon DeSR, the shift-reduce parser described in (Attardi, 2006). $$$$$ Given an input string W, the parser is initialized to ((), W, (), ()), and terminates when it reaches a configuration (S, (), (), A).
We build upon DeSR, the shift-reduce parser described in (Attardi, 2006). $$$$$ Extract in a configuration (s1|s2|S, n|I, T, A), move s2 from the stack to the temporary stack, then Shift, producing the configuration (n|s1|S, I, s2|T, A).

(Attardi, 2006)) have been introduced for handling non-projective dependency trees $$$$$ An experiment cycle in our setting requires less than 15 minutes for a treebank of moderate size like the Portuguese treebank (Afonso et al., 2002) and this allows evaluating the effectiveness of adding/removing features that hopefully might apply also when using other learning techniques.
(Attardi, 2006)) have been introduced for handling non-projective dependency trees $$$$$ This use of stemming slightly improved both accuracy and performance.
(Attardi, 2006)) have been introduced for handling non-projective dependency trees $$$$$ Given an input string W, the parser is initialized to ((), W, (), ()), and terminates when it reaches a configuration (S, (), (), A).

ULISSE was tested against the output of two really different data-driven parsers $$$$$ Parsing is deterministic and proceeds bottom-up.
ULISSE was tested against the output of two really different data-driven parsers $$$$$ These are often demanding applications, which need to handle large collections and to provide results in a fraction of a second.
ULISSE was tested against the output of two really different data-driven parsers $$$$$ At each step the parser uses classifiers trained on treebank data in order to predict which action to perform and which dependency label to assign given the current configuration.
ULISSE was tested against the output of two really different data-driven parsers $$$$$ Shift/Reduce, one to decide which Reduce action and a third one to choose the dependency in case of Left/Right action For details on the CoNLL-X shared task and the measurements see (Buchholz, et al. 2006).
