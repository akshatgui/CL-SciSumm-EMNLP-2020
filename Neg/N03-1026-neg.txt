Furthermore, we consider an F-score measure that is adapted from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al,2003). $$$$$ These rules delete the adjunct of the first conjunct (for testing), the adjunct of the second conjunct (by the end of the year), the rest of the second conjunct (Leary hopes to set requirements for a full system), and the conjunction itself (and).
Furthermore, we consider an F-score measure that is adapted from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al,2003). $$$$$ An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings.
Furthermore, we consider an F-score measure that is adapted from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al,2003). $$$$$ This shows that it is more important to learn what a good transferred f-structure looks like than to have a perfect f-structure to transfer from.

The intrinsic evaluation measures used in our experiments are the well-known BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) metrics, and an F-score measure that adapts evaluation techniques from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al, 2003) to machine translation. $$$$$ Such alternations can easily be expressed in our transfer-based approach, whereas they impose severe problems to approaches that operate only on phrase structure trees.
The intrinsic evaluation measures used in our experiments are the well-known BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) metrics, and an F-score measure that adapts evaluation techniques from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al, 2003) to machine translation. $$$$$ An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings.
The intrinsic evaluation measures used in our experiments are the well-known BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) metrics, and an F-score measure that adapts evaluation techniques from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al, 2003) to machine translation. $$$$$ A prototype is ready and Leary hopes to set requirements for a full system by the end of the year.

We stand in a marked contrast to previous 'grafting' approaches which more or less rely on an ad-hoc collection of transformation rules to generate candidates (Riezler et al, 2003). $$$$$ For example, humans tend to make use of structural modifications such as nominalization and verb alternations such as active/passive or transitive/intransitive alternations in condensation.
We stand in a marked contrast to previous 'grafting' approaches which more or less rely on an ad-hoc collection of transformation rules to generate candidates (Riezler et al, 2003). $$$$$ Our system incorporates a linguistic parser/generator for LFG, a transfer component for parse reduction operating on packed parse forests, and a maximum-entropy model for stochastic output selection.
We stand in a marked contrast to previous 'grafting' approaches which more or less rely on an ad-hoc collection of transformation rules to generate candidates (Riezler et al, 2003). $$$$$ Note that in our current implementation, in some cases the transfer component was unable to operate on the packed representation.
We stand in a marked contrast to previous 'grafting' approaches which more or less rely on an ad-hoc collection of transformation rules to generate candidates (Riezler et al, 2003). $$$$$ Instead of deploying costly and non-reusable human evaluation, or using automatic evaluation methods based on word error rate or n-gram match, summarization quality can be evaluated directly and automatically by matching the reduced f-structures that were produced by the system against manually selected f-structures that were produced by parsing a set of manually created condensations.

 $$$$$ For example, humans tend to make use of structural modifications such as nominalization and verb alternations such as active/passive or transitive/intransitive alternations in condensation.
 $$$$$ In contrast to the approaches mentioned above, our system guarantees the grammaticality of generated strings through the use of a constraint-based generator for LFG which uses a slightly tighter version of the grammar than is used by the parser.
 $$$$$ Another desideratum for future work is to carry condensation all the way through without unpacking at any stage.
 $$$$$ A stochastic disambiguator using a maximum entropy model is trained on parsed and manually disambiguated f-structures for pairs of sentences and their condensations.

Our results show that grammatical relations based F-score (Riezler et al 2003) correlates reliably with human judgements and could thus be used to measure compression performance automatically. $$$$$ Stochastic selection of generation-filtered reduced structures uses a powerful Maximum-Entropy model.
Our results show that grammatical relations based F-score (Riezler et al 2003) correlates reliably with human judgements and could thus be used to measure compression performance automatically. $$$$$ Stochastic selection of generation-filtered reduced structures uses a powerful Maximum-Entropy model.
Our results show that grammatical relations based F-score (Riezler et al 2003) correlates reliably with human judgements and could thus be used to measure compression performance automatically. $$$$$ A prototype is ready and Leary hopes to set requirements for a full system by the end of the year.

Riezler et al (2003) present a discriminative sentence compressor over the output of an LFG parser that is a packed representation of possible compressions. $$$$$ We presented an approach to sentence condensation that employs linguistically rich LFG grammars in a parsing/generation-based stochastic sentence condensation system.
Riezler et al (2003) present a discriminative sentence compressor over the output of an LFG parser that is a packed representation of possible compressions. $$$$$ Robustness techniques for parsing and generation guarantee that the system produces non-empty output for unseen input.

It is an important and growing field of natural language processing with applications in areas such as transfer based machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al, 2003). $$$$$ Stochastic selection of generation-filtered reduced structures uses a powerful Maximum-Entropy model.
It is an important and growing field of natural language processing with applications in areas such as transfer based machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al, 2003). $$$$$ The filtering is done by running each transferred structure through the generator to see whether it produces an output string.
It is an important and growing field of natural language processing with applications in areas such as transfer based machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al, 2003). $$$$$ This will eventually lead to a system whose components work on packed representations of all or n-best solutions, but completely avoid costly unpacking of representations.
It is an important and growing field of natural language processing with applications in areas such as transfer based machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al, 2003). $$$$$ Our system incorporates a linguistic parser/generator for LFG, a transfer component for parse reduction operating on packed parse forests, and a maximum-entropy model for stochastic output selection.

Riezler et al (2003) applied linguistically rich LFG grammars to a sentence compression system. $$$$$ This might seem disappointing considering the more complex machinery employed in our approach.
Riezler et al (2003) applied linguistically rich LFG grammars to a sentence compression system. $$$$$ In the approach of Witbrock and Mittal (1999), selection and ordering of summary terms is based on bagof-words models and n-grams.
Riezler et al (2003) applied linguistically rich LFG grammars to a sentence compression system. $$$$$ This idea of computing matching scores to multiple reference examples was proposed by Alshawi et al. (1998), and later by Papineni et al.
Riezler et al (2003) applied linguistically rich LFG grammars to a sentence compression system. $$$$$ Such alternations can easily be expressed in our transfer-based approach, whereas they impose severe problems to approaches that operate only on phrase structure trees.

One of the most widely used automatic metrics is the F1 measure over grammatical relations of the gold standard compressions (Riezler et al, 2003). $$$$$ To overcome this problem, linguistic parsing and generation systems are used in the sentence condensation approaches of Knight and Marcu (2000) and Jing (2000).
One of the most widely used automatic metrics is the F1 measure over grammatical relations of the gold standard compressions (Riezler et al, 2003). $$$$$ In this section, each of the system components will be described in more detail.
One of the most widely used automatic metrics is the F1 measure over grammatical relations of the gold standard compressions (Riezler et al, 2003). $$$$$ As shown in an experimental evaluation, summarization quality of the system output is state-of-the-art, and grammaticality of condensed strings is guaranteed.
One of the most widely used automatic metrics is the F1 measure over grammatical relations of the gold standard compressions (Riezler et al, 2003). $$$$$ Evaluation of quality of sentence condensation systems, and of text summarization and simplification systems in general, has mostly been conducted as intrinsic evaluation by human experts.

As an automated metric of quality, we compute F-score based on grammatical relations (relational F1, or RelF1) (Riezler et al, 2003). $$$$$ 2.
As an automated metric of quality, we compute F-score based on grammatical relations (relational F1, or RelF1) (Riezler et al, 2003). $$$$$ Note that in our current implementation, in some cases the transfer component was unable to operate on the packed representation.
As an automated metric of quality, we compute F-score based on grammatical relations (relational F1, or RelF1) (Riezler et al, 2003). $$$$$ Similar to stochastic disambiguation for constraint-based parsing (Johnson et al., 1999; Riezler et al., 2002), an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from a set of training data.
As an automated metric of quality, we compute F-score based on grammatical relations (relational F1, or RelF1) (Riezler et al, 2003). $$$$$ However, we conducted a preliminary assessment of this possibility by unpacking and enumerating the transferred fstructures.

We also report results using F1 computed over grammatical relations (Riezler et al, 2003). $$$$$ 6 applies the same evaluation data and metrics to a sentence condensation experiment that performs transfer from packed fstructures, i.e. transfer is performed on all parses for an ambiguous sentence instead of on a single manually selected parse.
We also report results using F1 computed over grammatical relations (Riezler et al, 2003). $$$$$ The system presented in this paper is conceptualized as a tool that can be used as a standalone system for sentence condensation or simplification, or in combination with sentence extraction for text-summarization beyond the sentence-level.
We also report results using F1 computed over grammatical relations (Riezler et al, 2003). $$$$$ However, these approaches do not employ statistical learning techniques to disambiguate simplification decisions, but iteratively apply symbolic reduction rules, producing a single output for each sentence.
We also report results using F1 computed over grammatical relations (Riezler et al, 2003). $$$$$ Recent work in statistical text summarization has put forward systems that do not merely extract and concatenate sentences, but learn how to generate new sentences from (Summary, Text) tuples.

The first evaluation is dependency base devaluation same as Riezler et al (2003). $$$$$ F-score balances precision and recall as (2 × precision × recall)/(precision + recall).
The first evaluation is dependency base devaluation same as Riezler et al (2003). $$$$$ This history records the relation of transferred f-structures to the original f-structure and is available for stochastic disambiguation. slept.
The first evaluation is dependency base devaluation same as Riezler et al (2003). $$$$$ The second rows show summarization quality scores for generations from a random selection and the system selection, and for the human-written condensation.
The first evaluation is dependency base devaluation same as Riezler et al (2003). $$$$$ For example, humans tend to make use of structural modifications such as nominalization and verb alternations such as active/passive or transitive/intransitive alternations in condensation.
