A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ The following example illustrates how all these pieces are put together to generate answer proofs.
A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ Lexical chains improve the performance of question answering systems in two ways: (1) increase the document retrieval recall and (2) improve the answer extraction by providing the much needed world knowledge axioms that link question keywords with answers concepts.
A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ Additionally, similar to hyperresolution, paramodulation combines multiple substitution steps into one.
A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ All these are described below.

The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms - as in Moldovan et al (2003). $$$$$ The LF codification acknowledges syntax-based relationships such as: (1) syntactic subjects, (2) syntactic objects, (3) prepositional attachments, (4) complex nominals, and (5) adjectival/adverbial adjuncts.
The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms - as in Moldovan et al (2003). $$$$$ This work was supported in part by the ARDA AQUAINT program.
The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms - as in Moldovan et al (2003). $$$$$ Once the axioms are complete and loaded, justification of the answer begins.

Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ Questions answered by the complete system 415 Questions answered by COGEX 206 Questions answered only by COGEX 98 Questions answered without COGEX 317 The added value of automated reasoning to the QA system is 30.9% (98/317).
Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ COGEX will continue trying to find a proof until the Set of Support becomes empty, a refutation is found, or the proof score drops below a predefined threshold.
Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ The results show that the prover boosts the performance of the QA system on TREC questions by 30%.
Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ The complete system answered 415 questions out of 500 TREC 2002 questions.

Our system uses COGEX (Moldovan et al, 2003), a natural language prover originating from OT TER (McCune, 1994). $$$$$ Lexical chains improve the performance of question answering systems in two ways: (1) increase the document retrieval recall and (2) improve the answer extraction by providing the much needed world knowledge axioms that link question keywords with answers concepts.
Our system uses COGEX (Moldovan et al, 2003), a natural language prover originating from OT TER (McCune, 1994). $$$$$ A logic prover brings several advantages to question answering, but at a high cost.

This assumption, also made by other recent abductive approaches (Moldovanetal., 2003), does not hold for several classes of examples. $$$$$ A careful analysis indicates that the QA system without logic prover answered 317 questions and the prover can answer only 98 additional questions for which the system without prover failed.
This assumption, also made by other recent abductive approaches (Moldovanetal., 2003), does not hold for several classes of examples. $$$$$ Moreover, the trace of a proof constitutes a justification for that answer.
This assumption, also made by other recent abductive approaches (Moldovanetal., 2003), does not hold for several classes of examples. $$$$$ Moreover, the trace of a proof constitutes a justification for that answer.
This assumption, also made by other recent abductive approaches (Moldovanetal., 2003), does not hold for several classes of examples. $$$$$ Moreover, the trace of the proofs provide answer justifications.

Analysis of results on some RTE examples along without guesses and confidence probabilities inference of (Moldovan et al, 2003) and have proposed a way to capture common cases of this phenomenon. $$$$$ This paper introduces the idea of automated reasoning applied to question answering and shows the feasibility of integrating a logic prover into a Question Answering system.
Analysis of results on some RTE examples along without guesses and confidence probabilities inference of (Moldovan et al, 2003) and have proposed a way to capture common cases of this phenomenon. $$$$$ The numbers on the left hand side of the proof summary indicate the step number in the search, not the step number in the proof.
Analysis of results on some RTE examples along without guesses and confidence probabilities inference of (Moldovan et al, 2003) and have proposed a way to capture common cases of this phenomenon. $$$$$ The failures of the prover are due primarily to the lack of linguistic axioms.

In COGEX (Moldovan et al, 2003), a recent QA system, authors used automated reasoning for QA and showed that it is feasible, effective and scalable. $$$$$ The challenges one faces when using automated reasoning in the context of NLP include: logic representation of open text, need of world knowledge axioms, logic representation of semantically equivalent linguistic patterns, and others.
In COGEX (Moldovan et al, 2003), a recent QA system, authors used automated reasoning for QA and showed that it is feasible, effective and scalable. $$$$$ The auxiliary axioms are placed in the Usable list and are used to help the SOS infer new clauses.
In COGEX (Moldovan et al, 2003), a recent QA system, authors used automated reasoning for QA and showed that it is feasible, effective and scalable. $$$$$ The approach is to transform questions and answer passages into logic representations.
In COGEX (Moldovan et al, 2003), a recent QA system, authors used automated reasoning for QA and showed that it is feasible, effective and scalable. $$$$$ Some of these are: bridging the gap between question and answer words, pinpointing exact answers, taking into consideration syntactic and semantic roles of words, better answer ranking, answer justification, and others.

Moldovan et al (2003) describe a method similar to ours. $$$$$ A logic prover brings several advantages to question answering, but at a high cost.
Moldovan et al (2003) describe a method similar to ours. $$$$$ A logic prover brings several advantages to question answering, but at a high cost.
Moldovan et al (2003) describe a method similar to ours. $$$$$ As mentioned for the complex nominal and coordinated conjunction axioms, any proof that uses these axioms should be penalized and ranked lower than those that do not.

Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ Additionally, similar to hyperresolution, paramodulation combines multiple substitution steps into one.
Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ The QA system includes traditional modules such as question processing, document retrieval, answer extraction, built in ontologies, as well as many tools such as syntactic parser, name entity recognizer, word sense disambiguation (Moldovan and Noviscki 2002), logic representation of text (Moldovan and Rus 2001) and others.
Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ In this way, the Logic Prover is a powerful tool in boosting the accuracy of the QA system.
Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ The meaning of these paths is that the concepts along a path are topically related.

Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ The inference rule sets are based on hyperresolution and paramodulation.
Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ COGEX was implemented and integrated into a state-ofthe-art Question Answering system that participated in TREC 2002.
Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ An axiom is built to connect by to the possessive: Equivalence classes for prepositions Prepositions can be grouped into equivalence classes depending on the context of the question, which is determined by the expected answer type.
Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ However, the implementation of a QA logic prover is expensive as it requires logic representation of text, world knowledge axioms and a large number of linguistic axioms, that all take time to develop.

COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ General axioms that reflect equivalence classes of linguistic patterns need to be created and instantiated when invoked.
COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ WordNet supplies us with that chain such that develop make and make create Using WordNet glosses, this chain is transformed into two axioms: Furthermore, the question asks about the Internet browser Mosiac, while the candidate answer refers to Mosaic.
COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ Answer: The first internal - combustion engine was built in 1867.
COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ Based on the parse tree patterns in the question and answers, other NLP axioms are built to supplement the existing general NLP axioms.

a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ We have observed that the top ten most frequently used grammar rules cover 90% of the cases for WordNet glosses.
a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ The question may refer to the subject/object by this apposition.
a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ However, the implementation of a QA logic prover is expensive as it requires logic representation of text, world knowledge axioms and a large number of linguistic axioms, that all take time to develop.
a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ The term Question Logic Form (QLF) refers to the questions posed to the Question Answering system represented in logic form.

WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004). $$$$$ For example in the correct candidate answer for the question, “Which company created the Internet browser Mosaic?”, Internet browser Mosaic is referred to as Mosaic.
WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004). $$$$$ COGEX will continue trying to find a proof until the Set of Support becomes empty, a refutation is found, or the proof score drops below a predefined threshold.

Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ A text logic form (LF) is an intermediary step between syntactic parse and the deep semantic form.
Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ This work was supported in part by the ARDA AQUAINT program.
Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ The success of this proof boosts the candidate answer to the first position.
Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ The QA system includes traditional modules such as question processing, document retrieval, answer extraction, built in ontologies, as well as many tools such as syntactic parser, name entity recognizer, word sense disambiguation (Moldovan and Noviscki 2002), logic representation of text (Moldovan and Rus 2001) and others.

 $$$$$ Similar to the above issue, a question may refer to the subject/object in an abbreviated form, while the answer will refer to the subject/object in its full, proper form.
 $$$$$ The recent TREC results (Voorhees 2002) have demonstrated that many performing systems reached a plateau; the systems ranked from 4th to 14th answered correctly between 38.4% to 24.8% of the total number of questions.
 $$$$$ The results show that the prover boosts the performance of the QA system on TREC questions by 30%.
 $$$$$ Additionally, the prover needs rewriting procedures for semantically equivalent lexical patterns.
