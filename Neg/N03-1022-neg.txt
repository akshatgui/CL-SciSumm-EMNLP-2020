A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ These are considered weak axioms, and any proof that uses them will be penalized by being given a lower score than those that do not.
A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ Moreover, the trace of the proofs provide answer justifications.
A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ However, the implementation of a QA logic prover is expensive as it requires logic representation of text, world knowledge axioms and a large number of linguistic axioms, that all take time to develop.
A third approach, exemplified by Moldovan et al (2003) and Raina et al (2005), is to translate dependency parses into neo-Davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (Hobbs et al, 1988). $$$$$ With this deep and intelligent representation, COGEX effectively and efficiently re-ranks candidate answers by their correctness, extracts the exact answer, and ultimately eliminates incorrect answers.

The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms - as in Moldovan et al (2003). $$$$$ Using abduction, an axiom is built such that the head noun of the complex nominal in the question implies the remaining nouns in the complex nominal: all x1 (mosaic nn(x1) internet nn(x1) & browser nn(x1)) An additional axiom is built such that all the nouns in the complex nominal imply a complex nominal: all x1 (internet nn(x1) & browser nn(x1) & mosaic nn(x1) nn nnc(x1,x1,x1,x1)) So as not to restrict the ordering of the nouns in the noun phrase from which the complex nominal is built, the same argument is used for each of the noun predicates in the complex nominal.
The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms - as in Moldovan et al (2003). $$$$$ The question may refer to the subject/object by this apposition.
The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms - as in Moldovan et al (2003). $$$$$ The search strategy used is the Set of Support Strategy, which partitions the axioms used during the course of a proof into those that have support and those that are considered auxiliary (Wos 1988).
The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms - as in Moldovan et al (2003). $$$$$ COGEX was implemented and integrated into a state-ofthe-art Question Answering system that participated in TREC 2002.

Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ We wish to thank Mihai Surdeanu and Marius Pasca from LCC for their contribution to this work.
Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ Similar to the above issue, a question may refer to the subject/object in an abbreviated form, while the answer will refer to the subject/object in its full, proper form.
Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ This is what distinguishes an NLP prover from a traditional mathematical prover.
Most of existing systems on the web produce a set of answers to a question in the form of hyper links or page extracts, ranked according to a relevance score (for example, COGEX [Moldovan et al, 2003]). $$$$$ Lexical chains improve the performance of question answering systems in two ways: (1) increase the document retrieval recall and (2) improve the answer extraction by providing the much needed world knowledge axioms that link question keywords with answers concepts.

Our system uses COGEX (Moldovan et al, 2003), a natural language prover originating from OT TER (McCune, 1994). $$$$$ A careful analysis indicates that the QA system without logic prover answered 317 questions and the prover can answer only 98 additional questions for which the system without prover failed.
Our system uses COGEX (Moldovan et al, 2003), a natural language prover originating from OT TER (McCune, 1994). $$$$$ In order to prove that this answer is in fact correct, we need to detect and use a lexical chain between develop and create.
Our system uses COGEX (Moldovan et al, 2003), a natural language prover originating from OT TER (McCune, 1994). $$$$$ Some advantages are: the capability of pinpointing exact answers that otherwise will be missed, answer justification, and a quantifiable measure of how close a system is to providing an answer.

This assumption, also made by other recent abductive approaches (Moldovanetal., 2003), does not hold for several classes of examples. $$$$$ COGEX captures the syntax-based relationships such as the syntactic objects, syntactic subjects, prepositional attachments, complex nominals, and adverbial/adjectival adjuncts provided by the logic representation of text.
This assumption, also made by other recent abductive approaches (Moldovanetal., 2003), does not hold for several classes of examples. $$$$$ COGEX captures the syntax-based relationships such as the syntactic objects, syntactic subjects, prepositional attachments, complex nominals, and adverbial/adjectival adjuncts provided by the logic representation of text.
This assumption, also made by other recent abductive approaches (Moldovanetal., 2003), does not hold for several classes of examples. $$$$$ For example in the correct candidate answer for the question, “Which company created the Internet browser Mosaic?”, Internet browser Mosaic is referred to as Mosaic.

Analysis of results on some RTE examples along without guesses and confidence probabilities inference of (Moldovan et al, 2003) and have proposed a way to capture common cases of this phenomenon. $$$$$ The term Question Logic Form (QLF) refers to the questions posed to the Question Answering system represented in logic form.
Analysis of results on some RTE examples along without guesses and confidence probabilities inference of (Moldovan et al, 2003) and have proposed a way to capture common cases of this phenomenon. $$$$$ The search strategy used is the Set of Support Strategy, which partitions the axioms used during the course of a proof into those that have support and those that are considered auxiliary (Wos 1988).
Analysis of results on some RTE examples along without guesses and confidence probabilities inference of (Moldovan et al, 2003) and have proposed a way to capture common cases of this phenomenon. $$$$$ Similar to the above issue, a question may refer to the subject/object in an abbreviated form, while the answer will refer to the subject/object in its full, proper form.
Analysis of results on some RTE examples along without guesses and confidence probabilities inference of (Moldovan et al, 2003) and have proposed a way to capture common cases of this phenomenon. $$$$$ For example, in the question, “What was the length of the Wright brothers’ first flight?”, the candidate answer, “Flying machines, which got off the ground with a 120 - foot flight by the Wright brothers in 1903...” implies ownership using the preposition by to connect the Wright brothers to flight.

In COGEX (Moldovan et al, 2003), a recent QA system, authors used automated reasoning for QA and showed that it is feasible, effective and scalable. $$$$$ In date seeking questions in and of have interchangeable meanings as do at and in.
In COGEX (Moldovan et al, 2003), a recent QA system, authors used automated reasoning for QA and showed that it is feasible, effective and scalable. $$$$$ Taking the same approach as for open text, we have parsed and represented in logic forms more than 50,000 WordNet glosses.
In COGEX (Moldovan et al, 2003), a recent QA system, authors used automated reasoning for QA and showed that it is feasible, effective and scalable. $$$$$ Similar to the above issue, a question may refer to the subject/object in an abbreviated form, while the answer will refer to the subject/object in its full, proper form.

Moldovan et al (2003) describe a method similar to ours. $$$$$ The QA system includes traditional modules such as question processing, document retrieval, answer extraction, built in ontologies, as well as many tools such as syntactic parser, name entity recognizer, word sense disambiguation (Moldovan and Noviscki 2002), logic representation of text (Moldovan and Rus 2001) and others.
Moldovan et al (2003) describe a method similar to ours. $$$$$ This work was supported in part by the ARDA AQUAINT program.
Moldovan et al (2003) describe a method similar to ours. $$$$$ The predicate names consist of the base form of the word concatenated with the part of speech of the word.
Moldovan et al (2003) describe a method similar to ours. $$$$$ A logic prover brings several advantages to question answering, but at a high cost.

Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ COGEX captures the syntax-based relationships such as the syntactic objects, syntactic subjects, prepositional attachments, complex nominals, and adverbial/adjectival adjuncts provided by the logic representation of text.
Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ We wish to thank Mihai Surdeanu and Marius Pasca from LCC for their contribution to this work.
Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ Moreover, the trace of the proofs provide answer justifications.
Continuing this work Moldovan et al (Moldovan et al, 2003) built a logic prover for Question Answering. $$$$$ A logic prover brings several advantages to question answering, but at a high cost.

Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ It remains to create axioms for the ALF of the candidate answer and to start the proof.
Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ As shown in Figure 1, the inputs to COGEX consist of logic representations of questions, potential answer paragraphs, world knowledge and lexical information.
Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ This strategy restricts the search such that a new clause is inferred if and only if one of its parent clauses come from the Set of Support.
Wordnets and ontologies are very common resources and are employed in a wide variety of direct and indirect QA tasks, such as reasoning based on axioms extracted from WordNet (Moldovanetal., 2003). $$$$$ We wish to thank Mihai Surdeanu and Marius Pasca from LCC for their contribution to this work.

COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ In addition to the logic representations of questions and candidate answers, the QA Logic Prover needs world knowledge axioms to link question concepts to answer concepts.
COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ During the relaxation, arguments to predicates in the question are incrementally uncoupled, the proof score is reduced, and the justification is re-attempted.
COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ For example, in the question, “Where is Devil ’s Tower?”, the answer, “American Indians won another court battle over their right to worship without interference at Devils Tower National Monument in the northeast corner of Wyoming”, identifies Wyoming as the location of Devil ’s Tower by referring to the part of Wyoming in which it lies.
COGEX (Moldovan et al, 2003) uses its logic prover to extract lexical relationships between the question and its candidate answers. $$$$$ However, the implementation of a QA logic prover is expensive as it requires logic representation of text, world knowledge axioms and a large number of linguistic axioms, that all take time to develop.

a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ COGEX captures the syntax-based relationships such as the syntactic objects, syntactic subjects, prepositional attachments, complex nominals, and adverbial/adjectival adjuncts provided by the logic representation of text.
a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ Axioms placed in the Usable list are: (1) Extended WordNet axioms, (2) NLP axioms, and (3) axioms based on outside world knowledge, such as people and organizations.
a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ For example in the correct candidate answer for the question, “When was Microsoft established?”, Microsoft is referred to as Microsoft Corp. An axiom is built such that each noun of the complex nominal takes on the identifying argument of the complex nominal: all x1 x2 x3 ( microsoft nn(x1) & corp nn(x2) & nn nnc(x3,x1,x2) microsoft nn(x3) & corp nn(x3)) Similar axioms are used for coordinated conjunctions detected in the answer and the question.
a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf. (Moldovan et al., 2003)). $$$$$ The LF codification acknowledges syntax-based relationships such as: (1) syntactic subjects, (2) syntactic objects, (3) prepositional attachments, (4) complex nominals, and (5) adjectival/adverbial adjuncts.

WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004). $$$$$ This allows for the Logic Prover to see the difference between the role of the subjects and objects in a sentence that is not answerable in a keyword based situation.
WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004). $$$$$ We wish to thank Mihai Surdeanu and Marius Pasca from LCC for their contribution to this work.
WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004). $$$$$ For example in the correct candidate answer for the question, “Which company created the Internet browser Mosaic?”, Internet browser Mosaic is referred to as Mosaic.

Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ This work was supported in part by the ARDA AQUAINT program.
Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ The challenges one faces when using automated reasoning in the context of NLP include: logic representation of open text, need of world knowledge axioms, logic representation of semantically equivalent linguistic patterns, and others.
Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ The approach is to transform questions and answer passages into logic representations.
Scenario knowledge was also included in the form of axiomatic logic transformation developed in (Moldovan et al, 2003). $$$$$ World knowledge axioms as well as linguistic axioms are supplied to the prover which renders a deep understanding of the relationship between question text and answer text.

 $$$$$ Similar to the above issue, a question may refer to the subject/object in an abbreviated form, while the answer will refer to the subject/object in its full, proper form.
 $$$$$ A logic prover brings several advantages to question answering, but at a high cost.
 $$$$$ Logic Forms are derived from the grammar rules found in the parse tree of a sentence.
 $$$$$ This represents a significant improvement in the performance of the logic prover for QA over the one reported in (Moldovan 2002).
