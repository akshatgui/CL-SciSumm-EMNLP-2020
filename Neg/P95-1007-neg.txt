A concise review of this research area can be found in, for instance, Lauer (1995), which dates back to Finin (1980). $$$$$ Yet, far from being an obscure, endangered species, the noun compound is flourishing in modern language.
A concise review of this research area can be found in, for instance, Lauer (1995), which dates back to Finin (1980). $$$$$ While using windowed co-occurrence did not help here, it is possible that under more data sparse conditions better performance could be achieved by this method.
A concise review of this research area can be found in, for instance, Lauer (1995), which dates back to Finin (1980). $$$$$ For the pattern and two-word window training schemes, the guess rate is less than 4% for both models.

As Lauer (1995) pointed out, using (partial) parsing of the text is too costly. $$$$$ It is reproduced here for reference: Given three nouns n1, n2 and n3: Only more recently has it been suggested that corpus statistics might provide the oracle, and this idea is the basis of the three algorithms which use the adjacency model.
As Lauer (1995) pointed out, using (partial) parsing of the text is too costly. $$$$$ The model also has the further commendation that it predicts correctly the observed proportion of left-branching compounds found in two independently extracted test sets.

Lauer (1995) compared a dependency model with adjacency models, and found that the dependency model is better. $$$$$ Since no manually tagged training data is available for our corpus, the tagger's default rules were used (these rules were produced by Brill by training on the Brown corpus).
Lauer (1995) compared a dependency model with adjacency models, and found that the dependency model is better. $$$$$ By the assumption that words within a group behave similarly, this is constant given the two categories.
Lauer (1995) compared a dependency model with adjacency models, and found that the dependency model is better. $$$$$ Financial support is gratefully ack- 53 nowledged from the Microsoft Institute and the Australian Government.
Lauer (1995) compared a dependency model with adjacency models, and found that the dependency model is better. $$$$$ In all, the most accurate technique achieved an accuracy of 81% as compared to the 67% achieved by guessing left-branching.

This is an extension of left branch preference in Lauer (1995). $$$$$ These are: tion in the probability of categories.
This is an extension of left branch preference in Lauer (1995). $$$$$ In all experiments the dependency model provides a substantial advantage over the adjacency model, even though the latter is more prevalent in proposals within the literature.
This is an extension of left branch preference in Lauer (1995). $$$$$ This result is in accordance with the informal reasoning given in section 1.3.

 $$$$$ The most significant contributions have been made by Richard Buckland, nowledged from the Microsoft Institute and the Australian Government.
 $$$$$ The accuracy results are shown in figure 3.
 $$$$$ Three of the algorithms use what I will call the ADJACENCY MODEL, an analysis procedure that goes back to Marcus (1980, p253).
 $$$$$ In such cases, we observe that the test instance itself provides the information that the event 12 t3 can occur and we recalculate the ratio using Pr(12 19 = Jr for all possible categories 12,13 where k is any non-zero constant.

Lauer (1995): adjacency 68.90 Lauer (1995): dependency 77.50 Best Altavista 78.68 Lauer (1995): tuned 80.70 Upper bound 81.50 Table 9: Performance comparison with the literature for compound bracketing 1993). $$$$$ Consider the compound calcium ion exchange, which is typically left-branching (that is, the first two words are bracketed together).
Lauer (1995): adjacency 68.90 Lauer (1995): dependency 77.50 Best Altavista 78.68 Lauer (1995): tuned 80.70 Upper bound 81.50 Table 9: Performance comparison with the literature for compound bracketing 1993). $$$$$ The significance of the use of conceptual association deserves some mention.
Lauer (1995): adjacency 68.90 Lauer (1995): dependency 77.50 Best Altavista 78.68 Lauer (1995): tuned 80.70 Upper bound 81.50 Table 9: Performance comparison with the literature for compound bracketing 1993). $$$$$ All consecutive sequences of these words were extracted, and the three word sequences used to form the test set.

Lauer (1995) proposes an unsupervised method for estimating the frequencies of the competing bracketings based on a taxonomy or a thesaurus. $$$$$ Since no manually tagged training data is available for our corpus, the tagger's default rules were used (these rules were produced by Brill by training on the Brown corpus).
Lauer (1995) proposes an unsupervised method for estimating the frequencies of the competing bracketings based on a taxonomy or a thesaurus. $$$$$ The most significant contributions have been made by Richard Buckland, nowledged from the Microsoft Institute and the Australian Government.
Lauer (1995) proposes an unsupervised method for estimating the frequencies of the competing bracketings based on a taxonomy or a thesaurus. $$$$$ A marked improvement is observed for the adjacency model, while the dependency model is only slightly improved.
Lauer (1995) proposes an unsupervised method for estimating the frequencies of the competing bracketings based on a taxonomy or a thesaurus. $$$$$ The schemes used are: The accuracy on the test set for all these experiments is shown in figure 2.

Lauer (1995) tested both the adjacency and dependency models on 244 compounds extracted from Grolier's encyclopedia, a corpus of 8 million words. $$$$$ The experiments above demonstrate a number of important points.
Lauer (1995) tested both the adjacency and dependency models on 244 compounds extracted from Grolier's encyclopedia, a corpus of 8 million words. $$$$$ Since no manually tagged training data is available for our corpus, the tagger's default rules were used (these rules were produced by Brill by training on the Brown corpus).
Lauer (1995) tested both the adjacency and dependency models on 244 compounds extracted from Grolier's encyclopedia, a corpus of 8 million words. $$$$$ The most significant contributions have been made by Richard Buckland, nowledged from the Microsoft Institute and the Australian Government.

Lauer (1995) is the first to propose and evaluate an unsupervised probabilistic model of compound noun interpretation for domain independent text. $$$$$ In some cases, the sequence was not a noun compound (nouns can appear adjacent to one another across various constituent boundaries) and was marked as an error.
Lauer (1995) is the first to propose and evaluate an unsupervised probabilistic model of compound noun interpretation for domain independent text. $$$$$ The problem is analogous to the prepositional phrase attachment task explored in Hindle and Rooth (1993).
Lauer (1995) is the first to propose and evaluate an unsupervised probabilistic model of compound noun interpretation for domain independent text. $$$$$ Levi, 1978; Ryder, 1994) and computational linguistics (Finin, 1980; McDonald, 1982; Isabelle, 1984), techniques suitable for broad coverage parsing remain unavailable.

Lauer (1995) tested the model in (7) on 282 compounds that he selected randomly from Grolier's encyclopedia and annotated with their paraphrasing prepositions. $$$$$ In this study, conceptual association is used with groups consisting of all categories from the 1911 version of Roget's thesaurus.4 Given two thesaurus categories t1 and t2, there is a parameter which represents the degree of acceptability of the structure [n1n2j where ni is a noun appearing in t1 and n2 appears in t2.
Lauer (1995) tested the model in (7) on 282 compounds that he selected randomly from Grolier's encyclopedia and annotated with their paraphrasing prepositions. $$$$$ For example, when backup compiler disk is encountered, the analysis will be: The proposal of Liberman and Sproat (1992) is more sophisticated and allows for the frequency of the words in the compound.
Lauer (1995) tested the model in (7) on 282 compounds that he selected randomly from Grolier's encyclopedia and annotated with their paraphrasing prepositions. $$$$$ In all, the most accurate technique achieved an accuracy of 81% as compared to the 67% achieved by guessing left-branching.

The computational problem is thus deciding whether the three-word NC has a left or right-bracketing structure (Lauer, 1995). $$$$$ The metric used is a mutual information-like measure based on probabilities of modification relationships.
The computational problem is thus deciding whether the three-word NC has a left or right-bracketing structure (Lauer, 1995). $$$$$ Figure 5 shows the resulting accuracy, with accuracy values from figure 3 displayed with dotted lines.
The computational problem is thus deciding whether the three-word NC has a left or right-bracketing structure (Lauer, 1995). $$$$$ This is in contrast to previous work on conceptual association where it resulted in little improvement on a task which could already be performed.
The computational problem is thus deciding whether the three-word NC has a left or right-bracketing structure (Lauer, 1995). $$$$$ In all cases the estimates used are: Here ambig(w) is the number of categories in which w appears.

Mark Lauer (1995) only considered English noun compounds and applied a different disambiguation strategy based on word association scores. $$$$$ However, no correction is made to the probability estimates for Pr(ti t2) and Pr(ti 13) for unseen cases, thus putting the dependency model on an equal footing with the adjacency model above.
Mark Lauer (1995) only considered English noun compounds and applied a different disambiguation strategy based on word association scores. $$$$$ Following Lauer and Dras (1994) we can formally write this parameter as Pr(ti â€”.12) where the event ti t2 denotes the modification of a noun in t2 by a noun in t1.
Mark Lauer (1995) only considered English noun compounds and applied a different disambiguation strategy based on word association scores. $$$$$ Initial results from applying these methods to the EMA corpus have been obtained by Wilco ter Stal (1995), and support the conclusion that the dependency model is superior to the adjacency model.
Mark Lauer (1995) only considered English noun compounds and applied a different disambiguation strategy based on word association scores. $$$$$ This work has received valuable input from people too numerous to mention.

Several researchers have tackled the syntactic analysis (Lauer, 1995), (Pustejovsky et al, 1993), (Liber man and Church, 1992), usually using a variation of the idea of finding the subconstituents elsewhere in the corpus and using those to predict how the larger compounds are structured. $$$$$ Three training schemes have been used and the tuned analysis procedures applied to the test set.
Several researchers have tackled the syntactic analysis (Lauer, 1995), (Pustejovsky et al, 1993), (Liber man and Church, 1992), usually using a variation of the idea of finding the subconstituents elsewhere in the corpus and using those to predict how the larger compounds are structured. $$$$$ The experiments above demonstrate a number of important points.
Several researchers have tackled the syntactic analysis (Lauer, 1995), (Pustejovsky et al, 1993), (Liber man and Church, 1992), usually using a variation of the idea of finding the subconstituents elsewhere in the corpus and using those to predict how the larger compounds are structured. $$$$$ I am also indebted to Vance Gledhill, Mike Johnson, Philip Resnik, Richard Sproat, Wilco ter Stal, Lucy Vanderwende and Wobcke.

We also present empirical observations on the distribution of the syntax and meaning of noun phrases on two different corpora based on two state-of-the-art classification tag sets: Lauers set of 8 prepositions (Lauer, 1995) and our list of 22 semantic relations. $$$$$ Eight different training schemes have been used to estimate the parameters and each set of estimates used to analyse the test set under both the adjacency and the dependency model.
We also present empirical observations on the distribution of the syntax and meaning of noun phrases on two different corpora based on two state-of-the-art classification tag sets: Lauers set of 8 prepositions (Lauer, 1995) and our list of 22 semantic relations. $$$$$ This is in contrast to previous work on conceptual association where it resulted in little improvement on a task which could already be performed.
We also present empirical observations on the distribution of the syntax and meaning of noun phrases on two different corpora based on two state-of-the-art classification tag sets: Lauers set of 8 prepositions (Lauer, 1995) and our list of 22 semantic relations. $$$$$ If the probability estimate for Pr(t2 t9 is zero for all possible categories 12 and 13 then both the numerator and the denominator will be zero.

On the other hand, the majority of corpus statistics approaches to noun compound interpretation collect statistics on the occurrence frequency of the noun constituents and use them in a probabilistic model (Lauer, 1995). $$$$$ For instance, parsing noun compounds appears to require detailed world knowledge that is unavailable outside a limited domain (Sparck Jones, 1983).
On the other hand, the majority of corpus statistics approaches to noun compound interpretation collect statistics on the occurrence frequency of the noun constituents and use them in a probabilistic model (Lauer, 1995). $$$$$ This work has received valuable input from people too numerous to mention.
On the other hand, the majority of corpus statistics approaches to noun compound interpretation collect statistics on the occurrence frequency of the noun constituents and use them in a probabilistic model (Lauer, 1995). $$$$$ The most general of these is that even quite crude corpus statistics can provide information about the syntax of compound nouns.
On the other hand, the majority of corpus statistics approaches to noun compound interpretation collect statistics on the occurrence frequency of the noun constituents and use them in a probabilistic model (Lauer, 1995). $$$$$ The most significant contributions have been made by Richard Buckland, nowledged from the Microsoft Institute and the Australian Government.

They can vary from a few prepositions (Lauer, 1995) to hundreds or thousands specific semantic relations (Finin, 1980). $$$$$ This is in contrast to previous work on conceptual association where it resulted in little improvement on a task which could already be performed.
They can vary from a few prepositions (Lauer, 1995) to hundreds or thousands specific semantic relations (Finin, 1980). $$$$$ Eight different training schemes have been used to estimate the parameters and each set of estimates used to analyse the test set under both the adjacency and the dependency model.
They can vary from a few prepositions (Lauer, 1995) to hundreds or thousands specific semantic relations (Finin, 1980). $$$$$ Because the dependency model equations have two factors, they are affected more severely by data sparseness.
They can vary from a few prepositions (Lauer, 1995) to hundreds or thousands specific semantic relations (Finin, 1980). $$$$$ The most significant contributions have been made by Richard Buckland, nowledged from the Microsoft Institute and the Australian Government.

(Lauer, 1995) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps: adjacency and dependency. $$$$$ Comparisons are made across five dimensions: While Hindle and Rooth (1993) use a partial parser to acquire training data, such machinery appears unnecessary for noun compounds.
(Lauer, 1995) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps: adjacency and dependency. $$$$$ To distinguish nouns from other words, the University of Pennsylvania morphological analyser (described in Karp et al, 1992) was used to generate the set of words that can only be used as nouns (I shall henceforth call this set A).
(Lauer, 1995) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps: adjacency and dependency. $$$$$ Three of the algorithms use what I will call the ADJACENCY MODEL, an analysis procedure that goes back to Marcus (1980, p253).
(Lauer, 1995) points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps: adjacency and dependency. $$$$$ The accuracy results are shown in figure 3.

(Lauer and Dras, 1994) and (Lauer, 1995) address the issue of structural ambiguity by developing a dependency model where instead of computing the acceptability of A [YZ] one would compute the acceptability of A [XZ]. $$$$$ The most significant contributions have been made by Richard Buckland, nowledged from the Microsoft Institute and the Australian Government.
(Lauer and Dras, 1994) and (Lauer, 1995) address the issue of structural ambiguity by developing a dependency model where instead of computing the acceptability of A [YZ] one would compute the acceptability of A [XZ]. $$$$$ At the very least, this information can be applied in broad coverage parsing to assist in the control of search.
(Lauer and Dras, 1994) and (Lauer, 1995) address the issue of structural ambiguity by developing a dependency model where instead of computing the acceptability of A [YZ] one would compute the acceptability of A [XZ]. $$$$$ Financial support is gratefully ack- 53 nowledged from the Microsoft Institute and the Australian Government.

(Lauer, 1995) argues that the dependency model is not only more intuitive than the adjacency model, but also yields better results. $$$$$ Given the high frequency of occurrence of noun compounds in many texts, this suggests that the use of these techniques in probabilistic parsers will result in higher performance in broad coverage natural language processing.
(Lauer, 1995) argues that the dependency model is not only more intuitive than the adjacency model, but also yields better results. $$$$$ This work has received valuable input from people too numerous to mention.
(Lauer, 1995) argues that the dependency model is not only more intuitive than the adjacency model, but also yields better results. $$$$$ For comparison, the untuned accuracy figures are shown with dotted lines.
(Lauer, 1995) argues that the dependency model is not only more intuitive than the adjacency model, but also yields better results. $$$$$ This work has received valuable input from people too numerous to mention.

This method is tested using a set of general English nominal compounds developed by (Lauer, 1995) as well as a set of nominal compounds extracted from MEDLINE abstracts. $$$$$ While using windowed co-occurrence did not help here, it is possible that under more data sparse conditions better performance could be achieved by this method.
This method is tested using a set of general English nominal compounds developed by (Lauer, 1995) as well as a set of nominal compounds extracted from MEDLINE abstracts. $$$$$ This work has received valuable input from people too numerous to mention.
This method is tested using a set of general English nominal compounds developed by (Lauer, 1995) as well as a set of nominal compounds extracted from MEDLINE abstracts. $$$$$ The most significant contributions have been made by Richard Buckland, Robert Dale and Mark Dras.
