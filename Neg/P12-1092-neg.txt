The use of dimensionality reduction techniques, for instance Latent Semantic Analysis in (Pado and Lapata, 2007), the multi-prototype (Reisinger and Mooney, 2010) or examplar-based models (Erk and Pado, 2010), the Deep Learning approach of (Huang et al, 2012) or the redefinition of the distributional approach in a Bayesian framework (Kazama et al, 2010) can be classified into this second category. $$$$$ The scoring components are computed by two neural networks, one capturing local context and the other global context, as shown in Figure 1.
The use of dimensionality reduction techniques, for instance Latent Semantic Analysis in (Pado and Lapata, 2007), the multi-prototype (Reisinger and Mooney, 2010) or examplar-based models (Erk and Pado, 2010), the Deep Learning approach of (Huang et al, 2012) or the redefinition of the distributional approach in a Bayesian framework (Kazama et al, 2010) can be classified into this second category. $$$$$ We want g(s, d) to be larger than g(sw, d) by a margin of 1, for any other wordw in the vocabulary, which corresponds to the train ing objective of minimizing the ranking loss for each (s, d) found in the corpus: Cs,d = ? w?V max(0, 1?
The use of dimensionality reduction techniques, for instance Latent Semantic Analysis in (Pado and Lapata, 2007), the multi-prototype (Reisinger and Mooney, 2010) or examplar-based models (Erk and Pado, 2010), the Deep Learning approach of (Huang et al, 2012) or the redefinition of the distributional approach in a Bayesian framework (Kazama et al, 2010) can be classified into this second category. $$$$$ We introduced a new dataset with human judgments on similarity between pairs of words in context, so as to evaluate model?s abilities to capture homonymy and polysemy of words in context.
The use of dimensionality reduction techniques, for instance Latent Semantic Analysis in (Pado and Lapata, 2007), the multi-prototype (Reisinger and Mooney, 2010) or examplar-based models (Erk and Pado, 2010), the Deep Learning approach of (Huang et al, 2012) or the redefinition of the distributional approach in a Bayesian framework (Kazama et al, 2010) can be classified into this second category. $$$$$ Moti vated to evaluate composition models, Mitchell andLapata (2008) introduced a dataset where an intransitive verb, presented with a subject noun, is com pared to another verb chosen to be either similar or dissimilar to the intransitive verb in context.

We plan to extend this work by taking into account the notion of word sense as it is done in (Reisinger and Mooney, 2010) or (Huang et al, 2012): since werely on occurrences of words in texts, this extension should be quite straightforward by turning our word-in-context classifiers into true word sense classifiers. $$$$$ Vector-space models (VSM) represent word meanings with vectors that capture semantic and syntac tic information of words.
We plan to extend this work by taking into account the notion of word sense as it is done in (Reisinger and Mooney, 2010) or (Huang et al, 2012): since werely on occurrences of words in texts, this extension should be quite straightforward by turning our word-in-context classifiers into true word sense classifiers. $$$$$ Moreover, using all contexts of a homonymous or polysemous word to build a single prototype could hurt the representation, which cannot represent any one of the meanings well as it is influenced by all meanings of the word.
We plan to extend this work by taking into account the notion of word sense as it is done in (Reisinger and Mooney, 2010) or (Huang et al, 2012): since werely on occurrences of words in texts, this extension should be quite straightforward by turning our word-in-context classifiers into true word sense classifiers. $$$$$ Many datasets with human similarity ratings on pairs of words, such as WordSim-353 (Finkelstein et al, 2001), MC (Miller and Charles, 1991) and RG (Rubenstein and Goodenough, 1965), have beenwidely used to evaluate vector-space models.

We also experiment with publicly released word embeddings (Huang et al, 2012), which were trained using both local and global context. $$$$$ We introduced a new dataset with human judgments on similarity between pairs of words in context, so as to evaluate model?s abilities to capture homonymy and polysemy of words in context.
We also experiment with publicly released word embeddings (Huang et al, 2012), which were trained using both local and global context. $$$$$ In order to learn multiple prototypes, we firstgather the fixed-sized context windows of all occur rences of a word (we use 5 words before and after the word occurrence).
We also experiment with publicly released word embeddings (Huang et al, 2012), which were trained using both local and global context. $$$$$ Reisinger and Mooney (2010b) combined the twoapproaches and applied them to vector-space mod els, which was further improved in Reisinger and Mooney (2010a).
We also experiment with publicly released word embeddings (Huang et al, 2012), which were trained using both local and global context. $$$$$ We found that word embed dings move to good positions in the vector spacefaster when using mini-batch L-BFGS (Liu and Nocedal, 1989) with 1000 pairs of good and corrupt examples per batch for training, compared to stochas tic gradient descent.

In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al, 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). $$$$$ We now describe how each scoring component is computed.The score of local context uses the local word se quence s. We first represent the word sequence s as 874 an ordered list of vectors x = (x1, x2, ..., xm) where xi is the embedding of word i in the sequence, which is a column in the embedding matrix L ? Rn?|V | where |V | denotes the size of the vocabulary.
In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al, 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). $$$$$ Model In this section, we describe the training objective of our model, followed by a description of the neural network architecture, ending with a brief description of our model?s training method.
In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al, 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). $$$$$ We show how our 875model can readily adopt the multi-prototype ap proach.
In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al, 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). $$$$$ We then use spheri cal k-means to cluster these context representations, which has been shown to model semantic relations well (Dhillon and Modha, 2001).

Source embeddings: We employ three external embeddings (obtained from (Turian et al, 2010)) induced using the following models: 1) hierarchical log-bilinear model (HLBL) (Mnih and Hinton, 2009) and two neural network-based models, 2) Collobert and Weston's (C&W) deep-learning architecture, and 3) Huang et al's polysemous neural language model (HUANG) (Huang et al, 2012). $$$$$ results on this dataset.
Source embeddings: We employ three external embeddings (obtained from (Turian et al, 2010)) induced using the following models: 1) hierarchical log-bilinear model (HLBL) (Mnih and Hinton, 2009) and two neural network-based models, 2) Collobert and Weston's (C&W) deep-learning architecture, and 3) Huang et al's polysemous neural language model (HUANG) (Huang et al, 2012). $$$$$ This task only indirectly evaluates sim ilarity as only reranking of already similar words are evaluated.
Source embeddings: We employ three external embeddings (obtained from (Turian et al, 2010)) induced using the following models: 1) hierarchical log-bilinear model (HLBL) (Mnih and Hinton, 2009) and two neural network-based models, 2) Collobert and Weston's (C&W) deep-learning architecture, and 3) Huang et al's polysemous neural language model (HUANG) (Huang et al, 2012). $$$$$ Several studies in psychology have also shown that global context can help language comprehension (Hess et al., 1995) and acquisition (Li et al, 2000).We introduce a new neural-network-based lan guage model that distinguishes and uses both local and global context via a joint training objective.
Source embeddings: We employ three external embeddings (obtained from (Turian et al, 2010)) induced using the following models: 1) hierarchical log-bilinear model (HLBL) (Mnih and Hinton, 2009) and two neural network-based models, 2) Collobert and Weston's (C&W) deep-learning architecture, and 3) Huang et al's polysemous neural language model (HUANG) (Huang et al, 2012). $$$$$ It would be interesting to evaluate those models on our new dataset.

 $$$$$ 1
 $$$$$ When word meaning is still ambiguous given local context, information in global context can help disambiguation.
 $$$$$ It would be interesting to evaluate those models on our new dataset.
 $$$$$ However, one limitation of this evaluation is that the human judgments are on pairs 873 Global ContextLocal Context scorel scoreg Document he walks to the bank...

Huang et al (2012) compare, in passing, one count model and several predict DSMs on the standard WordSim353 benchmark (Table 3 of their paper). $$$$$ They used up to 3 previ ous head words and showed increased performance on language modeling.
Huang et al (2012) compare, in passing, one count model and several predict DSMs on the standard WordSim353 benchmark (Table 3 of their paper). $$$$$ The embedding matrix L is theword representations.
Huang et al (2012) compare, in passing, one count model and several predict DSMs on the standard WordSim353 benchmark (Table 3 of their paper). $$$$$ Since word interpretation in context is important especially for homonymous and polysemous words, we introduce a new dataset with human judgments on similarity between pairs of words in sentential context.
Huang et al (2012) compare, in passing, one count model and several predict DSMs on the standard WordSim353 benchmark (Table 3 of their paper). $$$$$ We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate ourmodel on it, showing that our model outper forms competitive baselines and other neural language models.

The cw approach is very popular (for example both Huang et al (2012) and Blacoe and Lapata (2012) used it in the studies we discussed in Section 1). $$$$$ Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of DARPA, AFRL, or the US government.
The cw approach is very popular (for example both Huang et al (2012) and Blacoe and Lapata (2012) used it in the studies we discussed in Section 1). $$$$$ Reisinger and Mooney (2010b) introduced a multi-prototype VSM whereword sense discrimination is first applied by clus tering contexts, and then prototypes are built using the contexts of the sense-labeled words.
The cw approach is very popular (for example both Huang et al (2012) and Blacoe and Lapata (2012) used it in the studies we discussed in Section 1). $$$$$ Many datasets with human similarity ratings on pairs of words, such as WordSim-353 (Finkelstein et al, 2001), MC (Miller and Charles, 1991) and RG (Rubenstein and Goodenough, 1965), have beenwidely used to evaluate vector-space models.
The cw approach is very popular (for example both Huang et al (2012) and Blacoe and Lapata (2012) used it in the studies we discussed in Section 1). $$$$$ 2.1 Training Objective.
