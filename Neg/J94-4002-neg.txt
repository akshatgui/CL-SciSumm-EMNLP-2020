our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ In Section 2 we present RAP and discuss its main properties.
our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.
our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.
our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ The algorithm successfully identifies the antecedent of the pronoun for 86% of these pronoun occurrences.

We have used the same weights, listed in table 2, proposed by Lappin and Leass (1994). $$$$$ It scored higher than a version of Hobbs' algorithm that we implemented for Slot Grammar.
We have used the same weights, listed in table 2, proposed by Lappin and Leass (1994). $$$$$ Hobbs' tree search procedure selects the first candidate encountered by a left— right depth first search of the tree outside of a minimal path to the pronoun that satisfies certain configurational constraints.
We have used the same weights, listed in table 2, proposed by Lappin and Leass (1994). $$$$$ In this model, semantic and real-world knowledge conditions apply to the output of an algorithm that resolves pronominal anaphora on the basis of syntactic measures of salience, recency, and frequency of mention.

 $$$$$ As with Slot Grammar systems in general (McCord 1989b, 1993, in press), an architecture was adopted that &quot;factors out&quot; language-specific elements of the algorithm.
 $$$$$ We refer to this algorithm as RAP (Resolution of Anaphora Procedure).
 $$$$$ Most of these examples are taken from the computer manual texts on which we trained the algorithm.
 $$$$$ Most of the copyright notices are embedded in the EXEC, but this keyword makes it possible for a user-supplied function to have its own copyright notice.

Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ If at least one discourse referent' satisfies the conditions for a given factor type, a new salience factor of that type is created, with the appropriate discourse referents in its scope.
Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ These conditions are invoked only in cases in which salience does not provide a clear-cut decision and/or there is substantial semantic—pragmatic support for one of the less salient candidates.'
Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ These conditions are invoked only in cases in which salience does not provide a clear-cut decision and/or there is substantial semantic—pragmatic support for one of the less salient candidates.'
Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ We provide examples of its output for different sorts of cases in Section 3.

Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ As a result, message receives a considerably higher statistical score than display.
Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ We have designed and implemented an algorithm for pronominal anaphora resolution that employs measures of discourse salience derived from syntactic structure and a simple dynamic model of attentional state.
Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ In our implementation of the algorithm, we have factored out the search procedure and substituted RAP's syntactic—morphological filter for Hobbs' procedural filter.
Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ We would like to thank Martin Chodorow, Ido Dagan, John Justeson, Slava Katz, Michael McCord, Hubert Lehman, Amnon Ribak, Ulrike Schwa11, and Marilyn Walker for helpful discussion of many of the ideas and proposals presented here.

In the heuristic salience-based algorithm for pronoun resolution, Lappin and Leass (1994) introduce a procedure for identifying anaphorically linked NP as a cluster for which a global salience value is computed as the sum of the salience values of its elements. $$$$$ We are also grateful to several anonymous reviewers of Computational Linguistics for helpful comments on earlier drafts of the paper.
In the heuristic salience-based algorithm for pronoun resolution, Lappin and Leass (1994) introduce a procedure for identifying anaphorically linked NP as a cluster for which a global salience value is computed as the sum of the salience values of its elements. $$$$$ The parallelism reward was introduced at this time, as it seemed to make a substantial contribution to the overall success rate.
In the heuristic salience-based algorithm for pronoun resolution, Lappin and Leass (1994) introduce a procedure for identifying anaphorically linked NP as a cluster for which a global salience value is computed as the sum of the salience values of its elements. $$$$$ Interestingly, this enhancement only marginally improves the algorithm's performance (by 2%).
In the heuristic salience-based algorithm for pronoun resolution, Lappin and Leass (1994) introduce a procedure for identifying anaphorically linked NP as a cluster for which a global salience value is computed as the sum of the salience values of its elements. $$$$$ 's initial setting places it on the back cover.

Lappin and Leass (1994), for example, use several heuristics to filter out expletive pronouns, including a check for patterns including modal adjectives. $$$$$ (2.1)8 ranks relatively low, as it is a possessive determiner—it scores lower than two candidates from the previous sentence.
Lappin and Leass (1994), for example, use several heuristics to filter out expletive pronouns, including a check for patterns including modal adjectives. $$$$$ The algorithm applies to the syntactic representations generated by McCord's Slot Grammar parser and relies on salience measures derived from syntactic structure and a simple dynamic model of attentional state.
Lappin and Leass (1994), for example, use several heuristics to filter out expletive pronouns, including a check for patterns including modal adjectives. $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.
Lappin and Leass (1994), for example, use several heuristics to filter out expletive pronouns, including a check for patterns including modal adjectives. $$$$$ We refer to this algorithm as RAP (Resolution of Anaphora Procedure).

We implemented a coreference resolution tool using a shallow rule-based approach inspired by Lappin and Leass (1994) and Bontcheva et al (2002). $$$$$ An early version of this paper was presented at the Cognitive Science Colloquium of the University of Pennsylvania, in January 1992, and we are grateful to the participants of the colloquium for their reactions and suggestions.
We implemented a coreference resolution tool using a shallow rule-based approach inspired by Lappin and Leass (1994) and Bontcheva et al (2002). $$$$$ It does not employ semantic conditions (beyond those implicit in grammatical number and gender agreement) or real-world knowledge in evaluating candidate antecedents; nor does it model intentional or global discourse structure (as in Grosz and Sidner 1986).
We implemented a coreference resolution tool using a shallow rule-based approach inspired by Lappin and Leass (1994) and Bontcheva et al (2002). $$$$$ Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.
We implemented a coreference resolution tool using a shallow rule-based approach inspired by Lappin and Leass (1994) and Bontcheva et al (2002). $$$$$ It relies on measures of salience derived from syntactic structure and a simple dynamic model of attentional state to select the antecedent noun phrase (NP) of a pronoun from a list of candidates.

The new tool combines Hobbs algorithm (Hobbs, 1978) and the Resolution of Anaphora Procedure (RAP) algorithm (Lappin and Leass, 1994). $$$$$ Our specification of Hobbs' algorithm for Slot Grammar is as follows: We ran this version of Hobbs' algorithm on the test set that we used for the blind test of RAP and RAPSTAT; the results appear in Table 5.
The new tool combines Hobbs algorithm (Hobbs, 1978) and the Resolution of Anaphora Procedure (RAP) algorithm (Lappin and Leass, 1994). $$$$$ The algorithm is compared with other approaches to anaphora resolution that have been proposed in the literature.
The new tool combines Hobbs algorithm (Hobbs, 1978) and the Resolution of Anaphora Procedure (RAP) algorithm (Lappin and Leass, 1994). $$$$$ Like the parser, the algorithm is implemented in Prolog.

(Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.
(Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. $$$$$ An early version of this paper was presented at the Cognitive Science Colloquium of the University of Pennsylvania, in January 1992, and we are grateful to the participants of the colloquium for their reactions and suggestions.

Definiteness (Lappin and Leass, 1994). $$$$$ The relative contributions of the algorithm's components to its overall success rate in this blind test are examined.
Definiteness (Lappin and Leass, 1994). $$$$$ The results also support the view that attentional state plays a significant role in pronominal anaphora resolution and demonstrate that even a simple model of attentional state can be quite effective.

Non-prepositional NP (Lappin and Leass, 1994). $$$$$ Interestingly, this enhancement only marginally improves the algorithm's performance (by 2%).
Non-prepositional NP (Lappin and Leass, 1994). $$$$$ An early version of this paper was presented at the Cognitive Science Colloquium of the University of Pennsylvania, in January 1992, and we are grateful to the participants of the colloquium for their reactions and suggestions.
Non-prepositional NP (Lappin and Leass, 1994). $$$$$ The authors' algorithm achieves a higher rate of success (4%) than Hobbs' algorithm.

Pleonastic (Lappin and Leass, 1994). $$$$$ An early version of this paper was presented at the Cognitive Science Colloquium of the University of Pennsylvania, in January 1992, and we are grateful to the participants of the colloquium for their reactions and suggestions.
Pleonastic (Lappin and Leass, 1994). $$$$$ Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.
Pleonastic (Lappin and Leass, 1994). $$$$$ Despite the comparatively small degradation in performance that resulted from turning off these elements individually, their combined effect is quite significant, as the results of IX show.
Pleonastic (Lappin and Leass, 1994). $$$$$ The algorithm is compared with other approaches to anaphora resolution that have been proposed in the literature.

Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ The relation of the algorithm to the centering approach is discussed, as well as to models of anaphora resolution that invoke a variety of informational factors in ranking antecedent candidates.
Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ It does not employ semantic conditions (beyond those implicit in grammatical number and gender agreement) or real-world knowledge in evaluating candidate antecedents; nor does it model intentional or global discourse structure (as in Grosz and Sidner 1986).
Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ The addition of statistically measured lexical preferences to the range of factors that the algorithm considers only marginally improved its performance on the blind test set.
Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ In this model, semantic and real-world knowledge conditions apply to the output of an algorithm that resolves pronominal anaphora on the basis of syntactic measures of salience, recency, and frequency of mention.

 $$$$$ We would like to thank Martin Chodorow, Ido Dagan, John Justeson, Slava Katz, Michael McCord, Hubert Lehman, Amnon Ribak, Ulrike Schwa11, and Marilyn Walker for helpful discussion of many of the ideas and proposals presented here.
 $$$$$ In Section 2 we present RAP and discuss its main properties.
 $$$$$ (1.3) and controller.
 $$$$$ (2.10), are ruled out by the syntactic filter.

Other works, however, distinguish between restrictions and preferences (e.g. Lappin and Leass (1994)). $$$$$ An early version of this paper was presented at the Cognitive Science Colloquium of the University of Pennsylvania, in January 1992, and we are grateful to the participants of the colloquium for their reactions and suggestions.
Other works, however, distinguish between restrictions and preferences (e.g. Lappin and Leass (1994)). $$$$$ In the case of lexical anaphors (reflexive or reciprocal pronouns), the possible antecedent binders were identified by the anaphor binding algorithm.
Other works, however, distinguish between restrictions and preferences (e.g. Lappin and Leass (1994)). $$$$$ Analysis of the results indicates that lexical preference information can be useful in cases in which the syntactic salience ranking does not provide a clear decision among the top candidates, and there is a strong lexical preference for one of the less salient candidates.
Other works, however, distinguish between restrictions and preferences (e.g. Lappin and Leass (1994)). $$$$$ The algorithm successfully identifies the antecedent of the pronoun for 86% of these pronoun occurrences.

Lappin and Leass (1994) describe an algorithm for pronominal anaphora resolution that achieves a high rate of correct analyses (85%). $$$$$ Analysis of the results indicates that lexical preference information can be useful in cases in which the syntactic salience ranking does not provide a clear decision among the top candidates, and there is a strong lexical preference for one of the less salient candidates.
Lappin and Leass (1994) describe an algorithm for pronominal anaphora resolution that achieves a high rate of correct analyses (85%). $$$$$ Let the Mods (modifiers) of a head H be the sisters of H in the Slot Grammar representation of the phrase that H heads.
Lappin and Leass (1994) describe an algorithm for pronominal anaphora resolution that achieves a high rate of correct analyses (85%). $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.
Lappin and Leass (1994) describe an algorithm for pronominal anaphora resolution that achieves a high rate of correct analyses (85%). $$$$$ We have designed and implemented an algorithm for pronominal anaphora resolution that employs measures of discourse salience derived from syntactic structure and a simple dynamic model of attentional state.

More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ We filtered the test set so that for each pronoun occurrence in the set, (i) RAP generates a candidate list with at least two elements, (ii) the actual antecedent NP appears in the candidate list, and (iii) there is a total tuple frequency greater than 1 for the candidate See Dagan 1992 and Dagan et al. (in press) for a discussion of this lexical statistical approach to ranking antecedent candidates and possible alternatives.
More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ The relatively high success rate of the algorithm suggests the viability of a computational model of anaphora resolution in which the relative salience of an NP in discourse is determined, in large part, by structural factors.
More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ ESC.(1.10).
More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ The authors' algorithm achieves a higher rate of success (4%) than Hobbs' algorithm.

Lappin and Leass (1994) has also been implemented in our system and an accuracy of 64% was attained. $$$$$ If conditions (i) and (ii) do not hold, RAPSTAT confirms RAP's selection of C1 as the preferred antecedent.
Lappin and Leass (1994) has also been implemented in our system and an accuracy of 64% was attained. $$$$$ Initially, it considers the first two elements C1 and C2 of L. If (i) the difference in salience scores between C1 and C2 does not exceed a parametrically specified value (the salience difference threshold) and (ii) the statistical score of C2 is significantly greater than that of C1, then RAPSTAT will substitute the former for the latter as the currently preferred candidate.
Lappin and Leass (1994) has also been implemented in our system and an accuracy of 64% was attained. $$$$$ This strong preference for intersentential antecedents is inappropriate for at least some text domains—in our corpus of computer manual texts, for example, we estimate that less than 20% of referentially used third person pronouns have intersentential antecedents.'

Implementation of constraints and preference scan be based on empirical insight (Lappin and Leass, 1994). $$$$$ 13 Proper resolution was determined by a consensus of three opinions, including that of the first author.
