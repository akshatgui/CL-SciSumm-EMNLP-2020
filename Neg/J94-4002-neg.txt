our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ The relation of the algorithm to the centering approach is discussed, as well as to models of anaphora resolution that invoke a variety of informational factors in ranking antecedent candidates.
our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ The selected candidate is declared to be the antecedent of the pronoun.
our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ The search splits to consider singular and plural antecedents separately (steps 4-6) to allow a general treatment of number ambiguity (as in the Spanish possessive pronoun su or the German pronoun sie occurring as an accusative object). c. The syntactic filter is applied, using the list of disjoint pronoun-NP pairs generated earlier.
our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. $$$$$ 24 An example will serve to illustrate the problem with this approach.

We have used the same weights, listed in table 2, proposed by Lappin and Leass (1994). $$$$$ This procedure relies on a correspondence of grammatical roles and linear precedence relations that holds for a comparatively small class of languages.
We have used the same weights, listed in table 2, proposed by Lappin and Leass (1994). $$$$$ The authors have tested it extensively on computer manual texts and conducted a blind test on manual text containing 360 pronoun occurrences.
We have used the same weights, listed in table 2, proposed by Lappin and Leass (1994). $$$$$ (1.8) are ranked equally, since both are subjects.
We have used the same weights, listed in table 2, proposed by Lappin and Leass (1994). $$$$$ Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.

 $$$$$ It relies on measures of salience derived from syntactic structure and a simple dynamic model of attentional state to select the antecedent noun phrase (NP) of a pronoun from a list of candidates.
 $$$$$ The relative contributions of the algorithm's components to its overall success rate in this blind test are examined.

Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ The algorithm successfully identifies the antecedent of the pronoun for 86% of these pronoun occurrences.
Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ The relation of the algorithm to the centering approach is discussed, as well as to models of anaphora resolution that invoke a variety of informational factors in ranking antecedent candidates.
Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ We have performed a blind test of this algorithm on a substantial set of cases taken from a corpus of computer manual text and found it to provide good coverage for this set.
Lappin and Leass (1994) extracted rules from the output of the English Slot Grammar (ESG) (McCord, 1993). $$$$$ Results of experiments with the test corpus show that the syntax-based elements of our salience weighting mechanism contribute in a complexly interdependent way to the overall effectiveness of the algorithm.

Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ As a result, they establish a strong preference for intersentential over intrasentential anaphora resolution.
Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ Because intersentential anaphora is relatively rare in our corpus of computer manual texts and because RAP's success rate for intrasentential anaphora is higher than Hobbs' (89% versus 81%), RAP's overall success rate on the blind test set is 4% higher than that of our version of Hobbs' algorithm.
Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ (1.8) are ranked equally, since both are subjects.
Only one of the four is explicitly aimed at personal-pronoun anaphora RAP (Resolution of Anaphora Procedure) (Lappin and Leass, 1994). $$$$$ The relation of the algorithm to the centering approach is discussed, as well as to models of anaphora resolution that invoke a variety of informational factors in ranking antecedent candidates.

In the heuristic salience-based algorithm for pronoun resolution, Lappin and Leass (1994) introduce a procedure for identifying anaphorically linked NP as a cluster for which a global salience value is computed as the sum of the salience values of its elements. $$$$$ Clausal representations of the previous four sentences in the text are retained in the Prolog workspace.
In the heuristic salience-based algorithm for pronoun resolution, Lappin and Leass (1994) introduce a procedure for identifying anaphorically linked NP as a cluster for which a global salience value is computed as the sum of the salience values of its elements. $$$$$ The authors have tested it extensively on computer manual texts and conducted a blind test on manual text containing 360 pronoun occurrences.

Lappin and Leass (1994), for example, use several heuristics to filter out expletive pronouns, including a check for patterns including modal adjectives. $$$$$ The algorithm applies to the syntactic representations generated by McCord's Slot Grammar parser and relies on salience measures derived from syntactic structure and a simple dynamic model of attentional state.
Lappin and Leass (1994), for example, use several heuristics to filter out expletive pronouns, including a check for patterns including modal adjectives. $$$$$ Finally, in Section 6 we compare RAP to several other approaches to anaphora resolution that have been proposed in the computational literature.

We implemented a coreference resolution tool using a shallow rule-based approach inspired by Lappin and Leass (1994) and Bontcheva et al (2002). $$$$$ In particular, the search procedure of Hobbs' algorithm was implemented in the Slot Grammar framework and applied to the sentences in the blind test set.
We implemented a coreference resolution tool using a shallow rule-based approach inspired by Lappin and Leass (1994) and Bontcheva et al (2002). $$$$$ We have taken inspiration from the discussions of scoring procedures in the works cited above, but we have avoided constraint sources involving complex inferencing mechanisms and real-world knowledge, typically required for evaluating the semantic/pragmatic suitability of antecedent candidates or for determining details of discourse structure.
We implemented a coreference resolution tool using a shallow rule-based approach inspired by Lappin and Leass (1994) and Bontcheva et al (2002). $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.

The new tool combines Hobbs algorithm (Hobbs, 1978) and the Resolution of Anaphora Procedure (RAP) algorithm (Lappin and Leass, 1994). $$$$$ Brennan, Friedman, and Pollard (1987), and Webber (1988) present different versions of this approach.
The new tool combines Hobbs algorithm (Hobbs, 1978) and the Resolution of Anaphora Procedure (RAP) algorithm (Lappin and Leass, 1994). $$$$$ Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.
The new tool combines Hobbs algorithm (Hobbs, 1978) and the Resolution of Anaphora Procedure (RAP) algorithm (Lappin and Leass, 1994). $$$$$ The remaining intrasentential candidate, scsym(name).
The new tool combines Hobbs algorithm (Hobbs, 1978) and the Resolution of Anaphora Procedure (RAP) algorithm (Lappin and Leass, 1994). $$$$$ It significantly restricts the size of the candidate list in most of the other cases, in which the antecedent is selected on the basis of salience ranking and proximity.

(Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. $$$$$ RAP generates the list of non-coreferential pronoun—NP pairs for the current sentence, the list of pleonastic pronouns, if any, in the current sentence, the list of possible antecedent NP—lexical anaphor pairs, if any, for the current sentence, and the list of pronoun—antecedent NP pairs that it has identified, for which antecedents may appear in preceding sentences in the text.
(Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.
(Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. $$$$$ It scored higher than a version of Hobbs' algorithm that we implemented for Slot Grammar.

Definiteness (Lappin and Leass, 1994). $$$$$ In general, these systems use composite scoring procedures that assign a global rank to an antecedent candidate on the basis of the scores that it receives from several evaluation metrics.
Definiteness (Lappin and Leass, 1994). $$$$$ We have performed a blind test of this algorithm on a substantial set of cases taken from a corpus of computer manual text and found it to provide good coverage for this set.
Definiteness (Lappin and Leass, 1994). $$$$$ These conditions are invoked only in cases in which salience does not provide a clear-cut decision and/or there is substantial semantic—pragmatic support for one of the less salient candidates.'
Definiteness (Lappin and Leass, 1994). $$$$$ The Brennan et al. centering algorithm does not require that the highest ranked element of Cf (Un_i ) actually be realized in Un, but only that Cb(1.1&quot;,) be the highest ranked element of Cf (Un_i) which is, in fact, realized in U. Antecedent selection is constrained by rules that sustain cohesion in the relations between the backward centers of successive utterances in a discourse, but it is not determined directly by the role hierarchy used to rank the forward centers of a previous utterance.

Non-prepositional NP (Lappin and Leass, 1994). $$$$$ The authors' algorithm achieves a higher rate of success (4%) than Hobbs' algorithm.
Non-prepositional NP (Lappin and Leass, 1994). $$$$$ The algorithm applies to the syntactic representations generated by McCord's Slot Grammar parser and relies on salience measures derived from syntactic structure and a simple dynamic model of attentional state.
Non-prepositional NP (Lappin and Leass, 1994). $$$$$ We present the results of a comparative blind test of RAP and this procedure.
Non-prepositional NP (Lappin and Leass, 1994). $$$$$ It significantly restricts the size of the candidate list in most of the other cases, in which the antecedent is selected on the basis of salience ranking and proximity.

Pleonastic (Lappin and Leass, 1994). $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.
Pleonastic (Lappin and Leass, 1994). $$$$$ We present the results in Table 4 and discuss their significance.
Pleonastic (Lappin and Leass, 1994). $$$$$ Like the parser, the algorithm is implemented in Prolog.

Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ The algorithm successfully identifies the antecedent of the pronoun for 86% of these pronoun occurrences.
Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ Degradation of salience weight for the candidate from the previous sentence is substantial enough to offset these factors.
Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ Pronominal forms in many languages are ambiguous as to number and gender; such ambiguities are taken into account by RAP's morphological filter and by the algorithm as a whole.
Syntactic Parallelism (Lappin and Leass, 1994). $$$$$ It relies on measures of salience derived from syntactic structure and a simple dynamic model of attentional state to select the antecedent noun phrase (NP) of a pronoun from a list of candidates.

 $$$$$ Most of the copyright notices are embedded in the EXEC, but this keyword makes it possible for a user-supplied function to have its own copyright notice.
 $$$$$ There is a second difficulty with the Brennan et al. centering algorithm.
 $$$$$ 2.1.2 Test for Pleonastic Pronouns.
 $$$$$ The blind test and evaluation of RAPSTAT reported here was done jointly with Ido Dagan, John Justeson, and Amnon Ribak.

Other works, however, distinguish between restrictions and preferences (e.g. Lappin and Leass (1994)). $$$$$ Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.
Other works, however, distinguish between restrictions and preferences (e.g. Lappin and Leass (1994)). $$$$$ The relation of the algorithm to the centering approach is discussed, as well as to models of anaphora resolution that invoke a variety of informational factors in ranking antecedent candidates.
Other works, however, distinguish between restrictions and preferences (e.g. Lappin and Leass (1994)). $$$$$ Lappin (1985) employs it as a salience hierarchy to state a non-coreference constraint for pronouns.

Lappin and Leass (1994) describe an algorithm for pronominal anaphora resolution that achieves a high rate of correct analyses (85%). $$$$$ The addition of statistically measured lexical preferences to the range of factors that the algorithm considers only marginally improved its performance on the blind test set.
Lappin and Leass (1994) describe an algorithm for pronominal anaphora resolution that achieves a high rate of correct analyses (85%). $$$$$ Four candidates receive a similar salience weighting in this example.
Lappin and Leass (1994) describe an algorithm for pronominal anaphora resolution that achieves a high rate of correct analyses (85%). $$$$$ The algorithm is compared with other approaches to anaphora resolution that have been proposed in the literature.

More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ We are also grateful to several anonymous reviewers of Computational Linguistics for helpful comments on earlier drafts of the paper.
More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm's decision procedure.
More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ In its original form, this factor contributed to the salience of any NP not contained in a subordinate clause or in an adverbial PP demarcated by a separator.
More recently, Kennedy and Boguraev (1996) propose an algorithm for anaphora resolution that is actually a modified and extended version of the one developed by Lappin and Leass (1994). $$$$$ The authors' algorithm achieves a higher rate of success (4%) than Hobbs' algorithm.

Lappin and Leass (1994) has also been implemented in our system and an accuracy of 64% was attained. $$$$$ The algorithm is compared with other approaches to anaphora resolution that have been proposed in the literature.
Lappin and Leass (1994) has also been implemented in our system and an accuracy of 64% was attained. $$$$$ The performance of the syntactic filter is degraded somewhat in this variant as well, since NPs that are anaphorically linked to an NP fulfilling the criteria for disjoint reference will no longer be rejected as antecedent candidates.
Lappin and Leass (1994) has also been implemented in our system and an accuracy of 64% was attained. $$$$$ (1.5) they.

Implementation of constraints and preference scan be based on empirical insight (Lappin and Leass, 1994). $$$$$ The algorithm is compared with other approaches to anaphora resolution that have been proposed in the literature.
Implementation of constraints and preference scan be based on empirical insight (Lappin and Leass, 1994). $$$$$ The clausal representation consists of a set of Prolog unit clauses that provide information on the head—argument and head—adjunct relations of the phrase structure that the Slot Grammar assigns to a sentence (phrase).
Implementation of constraints and preference scan be based on empirical insight (Lappin and Leass, 1994). $$$$$ In this model, semantic and real-world knowledge conditions apply to the output of an algorithm that resolves pronominal anaphora on the basis of syntactic measures of salience, recency, and frequency of mention.
Implementation of constraints and preference scan be based on empirical insight (Lappin and Leass, 1994). $$$$$ We have performed a blind test of this algorithm on a substantial set of cases taken from a corpus of computer manual text and found it to provide good coverage for this set.
