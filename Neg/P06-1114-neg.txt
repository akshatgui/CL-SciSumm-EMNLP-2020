For more information on the TE system described in this section, please see (Hickl et al, 2006b) and (Harabagiu and Hickl, 2006). $$$$$ 1 As currently defined, the RTE task requires systems to determine whether, given two text fragments, the meaning of one text could be reasonably inferred, or textually entailed, from the meaning of the other text.
For more information on the TE system described in this section, please see (Hickl et al, 2006b) and (Harabagiu and Hickl, 2006). $$$$$ The experiments reported in this paper suggest that current TE systems may be able to provide open-domain Q/A systems with the forms of semantic inference needed to perform accurate answer validation.
For more information on the TE system described in this section, please see (Hickl et al, 2006b) and (Harabagiu and Hickl, 2006). $$$$$ In this paper, we present three different methods for incorporating systems for textual entailment into the traditional Q/A architecture employed by many current systems.

Following (Harabagiu and Hickl, 2006), we used TE information in order to filter answers identified by the Q/A system that were not entailed by the user's original question. $$$$$ Our work suggests that considerable gains in performance can be obtained by incorporating TE during both answer processing and passage retrieval.
Following (Harabagiu and Hickl, 2006), we used TE information in order to filter answers identified by the Q/A system that were not entailed by the user's original question. $$$$$ In this task, systems were tasked with determining whether the meaning of a sentence (referred to as a hypothesis) could be reasonably inferred from the meaning of another sentence (known as a text).
Following (Harabagiu and Hickl, 2006), we used TE information in order to filter answers identified by the Q/A system that were not entailed by the user's original question. $$$$$ Under this method, answers that were not entailed by the question were removed from consideration; the top-ranked entailed answer was then returned as the system’s answer to the question.
Following (Harabagiu and Hickl, 2006), we used TE information in order to filter answers identified by the Q/A system that were not entailed by the user's original question. $$$$$ We expect that by adding features to TE system specifically designed to account for the semantic contributions of a question’s EAT, we may be able to boost the performance of this method.

While it has been shown that paraphrasing methods are useful for question answering (Harabagiu and Hickl, 2006) and relation extraction (Romano et al, 2006), this is, to the best of our knowledge, the first paper to perform semantic parsing through paraphrasing. $$$$$ Finally, the Classification Module employs a decision tree classifier in order to determine whether an entailment relationship exists for each pair of texts.
While it has been shown that paraphrasing methods are useful for question answering (Harabagiu and Hickl, 2006) and relation extraction (Romano et al, 2006), this is, to the best of our knowledge, the first paper to perform semantic parsing through paraphrasing. $$$$$ In this paper, we discussed three different ways that a state-of-the-art textual entailment system could be used to enhance the performance of an open-domain Q/A system.
While it has been shown that paraphrasing methods are useful for question answering (Harabagiu and Hickl, 2006) and relation extraction (Romano et al, 2006), this is, to the best of our knowledge, the first paper to perform semantic parsing through paraphrasing. $$$$$ Question-answer pairs deemed to be positive instances of entailment were then stored in a database and used as additional training data for the AutoQUAB module.
While it has been shown that paraphrasing methods are useful for question answering (Harabagiu and Hickl, 2006) and relation extraction (Romano et al, 2006), this is, to the best of our knowledge, the first paper to perform semantic parsing through paraphrasing. $$$$$ When no AGQs were found to be entailed by the original question, however, passages were ranked according to their entailment confidence and sent to AP for further processing and validation.

In order to improve QA systems' performance many research focus on different structures such as question processing (Huang et al., 2008), information retrieval (Clarke et al., 2006), information extraction (Saggion and Gaizauskas, 2006), textual entailment (TE) (Harabagiu and Hickl, 2006) for ranking, answer extraction, etc. $$$$$ We have shown that when textual entailment information is used to either filter or rank candidate answers returned by a Q/A system, Q/A accuracy can be improved from 32% to 52% (when an answer type can be detected) and from 30% to 40% (when no answer type can be detected).
In order to improve QA systems' performance many research focus on different structures such as question processing (Huang et al., 2008), information retrieval (Clarke et al., 2006), information extraction (Saggion and Gaizauskas, 2006), textual entailment (TE) (Harabagiu and Hickl, 2006) for ranking, answer extraction, etc. $$$$$ In this paper, we demonstrate how computational systems to recognize entailment can be used to enhance the accuracy of current open-domain automatic question answering (Q/A) systems.
In order to improve QA systems' performance many research focus on different structures such as question processing (Huang et al., 2008), information retrieval (Clarke et al., 2006), information extraction (Saggion and Gaizauskas, 2006), textual entailment (TE) (Harabagiu and Hickl, 2006) for ranking, answer extraction, etc. $$$$$ In contrast, when entailment information was used to rank passages and candidate answers, performance increased by 22% and 10% respectively.
In order to improve QA systems' performance many research focus on different structures such as question processing (Huang et al., 2008), information retrieval (Clarke et al., 2006), information extraction (Saggion and Gaizauskas, 2006), textual entailment (TE) (Harabagiu and Hickl, 2006) for ranking, answer extraction, etc. $$$$$ Our experimental results indicate that (even at their current level of performance) textual entailment systems can substantially improve the accuracy of Q/A, even when no other form of semantic inference is employed.

Implementation of different TE models has previously shown to improve the QA task using supervised learning methods (Harabagiu and Hickl, 2006). $$$$$ Once a ranking was established, answers that were not judged to be entailed by the question were also removed from final ranking.
Implementation of different TE models has previously shown to improve the QA task using supervised learning methods (Harabagiu and Hickl, 2006). $$$$$ In this paper, we demonstrate how computational systems to recognize entailment can be used to enhance the accuracy of current open-domain automatic question answering (Q/A) systems.
Implementation of different TE models has previously shown to improve the QA task using supervised learning methods (Harabagiu and Hickl, 2006). $$$$$ We believe the alignment of corresponding entities can be cast as a classification problem which uses lexico-semantic features in order to compute an alignment probability p(a), which corresponds to the likelihood that a term selected from one text entails a term from another text.

Instead of matching headline and first sentence of the document as in (Harabagiu and Hickl, 2006), we followed a different approach. $$$$$ Our experimental results indicate that (even at their current level of performance) textual entailment systems can substantially improve the accuracy of Q/A, even when no other form of semantic inference is employed.
Instead of matching headline and first sentence of the document as in (Harabagiu and Hickl, 2006), we followed a different approach. $$$$$ Two approaches were used to gather negative examples for our training set.
Instead of matching headline and first sentence of the document as in (Harabagiu and Hickl, 2006), we followed a different approach. $$$$$ Work on the semantics of questions has argued that the relation between a question and its answer(s) can be cast in terms of logical entailment.

In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al, 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. $$$$$ Method 1.
In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al, 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. $$$$$ We used constituency information from a chunk parser to decompose the pair of texts into a set of disjoint segments known as “alignable chunks”.
In cases where simple question formulation is not satisfactory, many advanced QA systems implement more sophisticated syntactic, semantic and contextual processing such as named-entity recognition (Molla et al, 2006), coreference resolution (Vicedo and Ferrandez, 2000), logical inferences (abduction or entailment) (Harabagiu and Hickl, 2006) translation (Ma and McKeowon, 2009), etc., to improve answer ranking. $$$$$ In this paper, we present three different methods for incorporating systems for textual entailment into the traditional Q/A architecture employed by many current systems.

Recent work on textual entailment has shown improvements on QA results (Harabagiu and Hickl, 2006), (Celikyilmaz et al, 2009), when used for filtering and ranking answers. $$$$$ In order to provide training data that replicated the task of recognizing entailment between a question and an answer, we assembled a corpus of 5000 question-answer pairs selected from answers that our baseline Q/A system returned in response to a new set of 1000 questions selected from the TREC test sets.
Recent work on textual entailment has shown improvements on QA results (Harabagiu and Hickl, 2006), (Celikyilmaz et al, 2009), when used for filtering and ranking answers. $$$$$ While best results were obtained using the Hybrid Method (which boosted performance by nearly 28% for questions with known EATs), each of the individual methods managed to boost the overall accuracy of the Q/A system by at least 7%.
Recent work on textual entailment has shown improvements on QA results (Harabagiu and Hickl, 2006), (Celikyilmaz et al, 2009), when used for filtering and ranking answers. $$$$$ We expect that by adding features to TE system specifically designed to account for the semantic contributions of a question’s EAT, we may be able to boost the performance of this method.
Recent work on textual entailment has shown improvements on QA results (Harabagiu and Hickl, 2006), (Celikyilmaz et al, 2009), when used for filtering and ranking answers. $$$$$ Results from this hybrid method are provided in Table 9.

For the task of Question Answering, (Harabagiu and Hickl, 2006) applied a TE component to rerank candidate answers returned by a retrieval step. $$$$$ We show that by incorporating features from TE into a Q/A system which employs no other form of textual inference, we can improve accuracy by more than 20% over a baseline.
For the task of Question Answering, (Harabagiu and Hickl, 2006) applied a TE component to rerank candidate answers returned by a retrieval step. $$$$$ The intense heat from a second eruption on Tuesday forced rescue operations to stop after 90 minutes.
For the task of Question Answering, (Harabagiu and Hickl, 2006) applied a TE component to rerank candidate answers returned by a retrieval step. $$$$$ The system then outputs a new set of ranked answers which do not contain any answers that are not entailed by the user’s question.

Techniques developed for RTE have now been successfully applied in the domains of Question Answering (Harabagiu and Hickl, 2006) and Machine Translation (Pado et al, 2009), (Mirkin et al, 2009). $$$$$ While probabilistic or web-based methods for answer validation have been previously explored in the literature (Magnini et al., 2002), these approaches have modeled the relationship between a question and a (correct) answer in terms of relevance and have not tried to approximate the deeper semantic phenomena that are involved in determining answerhood.
Techniques developed for RTE have now been successfully applied in the domains of Question Answering (Harabagiu and Hickl, 2006) and Machine Translation (Pado et al, 2009), (Mirkin et al, 2009). $$$$$ In this experiment, entailment information was used to rank passages returned by the PR module.
Techniques developed for RTE have now been successfully applied in the domains of Question Answering (Harabagiu and Hickl, 2006) and Machine Translation (Pado et al, 2009), (Mirkin et al, 2009). $$$$$ Results from this baseline are presented in Table 7.
Techniques developed for RTE have now been successfully applied in the domains of Question Answering (Harabagiu and Hickl, 2006) and Machine Translation (Pado et al, 2009), (Mirkin et al, 2009). $$$$$ In contrast, when entailment information was used to rank passages and candidate answers, performance increased by 22% and 10% respectively.

This includes finding question answer pairs (Cong et al, 2008) from online forums, auto-answering queries on a technical forum (Feng et al, 2006), ranking answers (Harabagiu and Hickl, 2006) etc. $$$$$ When no AGQs were found to be entailed by the original question, however, passages were ranked according to their entailment confidence and sent to AP for further processing and validation.
This includes finding question answer pairs (Cong et al, 2008) from online forums, auto-answering queries on a technical forum (Feng et al, 2006), ranking answers (Harabagiu and Hickl, 2006) etc. $$$$$ These machine-annotated examples were then used to train the Maximum Entropy-based classifier that was used in our TE system.

Being a challenging task, it has been shown that it is helpful to applications like question answering (Harabagiu and Hickl, 2006). $$$$$ Work on the semantics of questions has argued that the relation between a question and its answer(s) can be cast in terms of logical entailment.
Being a challenging task, it has been shown that it is helpful to applications like question answering (Harabagiu and Hickl, 2006). $$$$$ Our work suggests that considerable gains in performance can be obtained by incorporating TE during both answer processing and passage retrieval.
Being a challenging task, it has been shown that it is helpful to applications like question answering (Harabagiu and Hickl, 2006). $$$$$ Open-Domain Question Answering (Q/A) systems return a textual expression, identified from a vast document collection, as a response to a question asked in natural language.
Being a challenging task, it has been shown that it is helpful to applications like question answering (Harabagiu and Hickl, 2006). $$$$$ We have shown that when textual entailment information is used to either filter or rank candidate answers returned by a Q/A system, Q/A accuracy can be improved from 32% to 52% (when an answer type can be detected) and from 30% to 40% (when no answer type can be detected).

The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as question answering (Harabagiu and Hickl, 2006), information retrieval (Clinchant et al, 2006), information extraction (Romano et al, 2006), and document summarization (Lloret et al, 2008). $$$$$ In this paper, we discussed three different ways that a state-of-the-art textual entailment system could be used to enhance the performance of an open-domain Q/A system.
The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as question answering (Harabagiu and Hickl, 2006), information retrieval (Clinchant et al, 2006), information extraction (Romano et al, 2006), and document summarization (Lloret et al, 2008). $$$$$ We believe that these results suggest that current supervised machine learning approaches to the recognition of textual entailment may provide open-domain Q/A systems with the inferential information needed to develop viable answer validation systems.

TE has been successfully applied to a variety of natural language processing applications, including information extraction (Romano et al, 2006) and question answering (Harabagiu and Hickl, 2006). $$$$$ In our experiments, we show that when textual entailment information is used to either filter or rank answers returned by a Q/A system, accuracy can be increased by as much as 20% overall.
TE has been successfully applied to a variety of natural language processing applications, including information extraction (Romano et al, 2006) and question answering (Harabagiu and Hickl, 2006). $$$$$ When at least one of the AGQs generated by the AutoQUAB module is entailed by the original question, all AGQs that do not reach TE are filtered from consideration; remaining passages are assigned an entailment confidence score and are sent to the AP module in order to provide an exact answer to the question.
TE has been successfully applied to a variety of natural language processing applications, including information extraction (Romano et al, 2006) and question answering (Harabagiu and Hickl, 2006). $$$$$ Keywords – along with the question’s EAT – are then used by a PR module to retrieve a ranked list of paragraphs which may contain answers to the question.

Knowledge about entailment is beneficial for NLP tasks such as Question Answering (Harabagiu and Hickl, 2006). $$$$$ Work on the semantics of questions has argued that the relation between a question and its answer(s) can be cast in terms of logical entailment.
Knowledge about entailment is beneficial for NLP tasks such as Question Answering (Harabagiu and Hickl, 2006). $$$$$ In contrast, when entailment information was used to rank passages and candidate answers, performance increased by 22% and 10% respectively.
Knowledge about entailment is beneficial for NLP tasks such as Question Answering (Harabagiu and Hickl, 2006). $$$$$ Open-Domain Question Answering (Q/A) systems return a textual expression, identified from a vast document collection, as a response to a question asked in natural language.
Knowledge about entailment is beneficial for NLP tasks such as Question Answering (Harabagiu and Hickl, 2006). $$$$$ In this paper, we discussed three different ways that a state-of-the-art textual entailment system could be used to enhance the performance of an open-domain Q/A system.

Algorithms for computing semantic textual similarity (STS) are relevant for a variety of applications, including information extraction (Szpektor and Dagan, 2008), question answering (Harabagiu and Hickl, 2006) and machine translation (Mirkin et al, 2009). $$$$$ In this paper, we demonstrate how computational systems to recognize entailment can be used to enhance the accuracy of current open-domain automatic question answering (Q/A) systems.
Algorithms for computing semantic textual similarity (STS) are relevant for a variety of applications, including information extraction (Szpektor and Dagan, 2008), question answering (Harabagiu and Hickl, 2006) and machine translation (Mirkin et al, 2009). $$$$$ While probabilistic or web-based methods for answer validation have been previously explored in the literature (Magnini et al., 2002), these approaches have modeled the relationship between a question and a (correct) answer in terms of relevance and have not tried to approximate the deeper semantic phenomena that are involved in determining answerhood.
Algorithms for computing semantic textual similarity (STS) are relevant for a variety of applications, including information extraction (Szpektor and Dagan, 2008), question answering (Harabagiu and Hickl, 2006) and machine translation (Mirkin et al, 2009). $$$$$ Work on the semantics of questions has argued that the relation between a question and its answer(s) can be cast in terms of logical entailment.
