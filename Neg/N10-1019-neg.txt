Gamon (2010) proposes a hybrid system for preposition and article correction, by incorporating the scores of a language model and class probabilities of a maximum entropy model, both trained on native data, into a meta-classifier that is trained on a smaller amount of annotated ESL data. $$$$$ We can reduce the amount of training data for prepositions to 10% of the original data and still outperform the language model baseline.
Gamon (2010) proposes a hybrid system for preposition and article correction, by incorporating the scores of a language model and class probabilities of a maximum entropy model, both trained on native data, into a meta-classifier that is trained on a smaller amount of annotated ESL data. $$$$$ The meta-classifier in turn is trained on error-annotated learner data, optimizing the error detection and correction performance on this domain.
Gamon (2010) proposes a hybrid system for preposition and article correction, by incorporating the scores of a language model and class probabilities of a maximum entropy model, both trained on native data, into a meta-classifier that is trained on a smaller amount of annotated ESL data. $$$$$ Since the meta-classifier requires error-annotated data for training, we investigate how much training data is needed to improve results over the baseline of not using a meta-classifier.

In contrast to Gamon (2010) and Han et al (2010) that use annotated data for training, the system is trained on native data, but the native data are transformed to be more like L1 data through artificial article errors that mimic the error rates and error patterns of non-native writers. $$$$$ From the total set of candidate operations (substitutions, insertions, and deletions) that each combination of presence and choice classifier produces for prepositions, we consider only the top three highest-scoring operations2.
In contrast to Gamon (2010) and Han et al (2010) that use annotated data for training, the system is trained on native data, but the native data are transformed to be more like L1 data through artificial article errors that mimic the error rates and error patterns of non-native writers. $$$$$ We use the term primary models for both the initial errorspecific classifiers and a large generic language model.
In contrast to Gamon (2010) and Han et al (2010) that use annotated data for training, the system is trained on native data, but the native data are transformed to be more like L1 data through artificial article errors that mimic the error rates and error patterns of non-native writers. $$$$$ Learning correct article use is most difficult for native speakers of an L1 that does not overtly mark definiteness and indefiniteness as English does.
In contrast to Gamon (2010) and Han et al (2010) that use annotated data for training, the system is trained on native data, but the native data are transformed to be more like L1 data through artificial article errors that mimic the error rates and error patterns of non-native writers. $$$$$ Training data requirements for the meta-classifier vary significantly between article and preposition error detection.

Gamon (2010) shows precision/recall curves on the combined task of detecting missing, extraneous and confused prepositions. $$$$$ The meta-classifier in turn is trained on error-annotated learner data, optimizing the error detection and correction performance on this domain.
Gamon (2010) shows precision/recall curves on the combined task of detecting missing, extraneous and confused prepositions. $$$$$ Training data requirements for the meta-classifier vary significantly between article and preposition error detection.
Gamon (2010) shows precision/recall curves on the combined task of detecting missing, extraneous and confused prepositions. $$$$$ We present results from a range of experiments on article and preposition error correction for non-native speakers of English.

Gamon (2010) also considers missing and extraneous preposition errors. $$$$$ This is, at least in part, based on the recognition that non-native speakers of English now outnumber native speakers by 2:1 in some estimates, so any tool in this domain could be of tremendous value.
Gamon (2010) also considers missing and extraneous preposition errors. $$$$$ An example for insertion is seen in Please send me the letter back writing what happened.
Gamon (2010) also considers missing and extraneous preposition errors. $$$$$ Since the meta-classifier requires error-annotated data for training, we investigate how much training data is needed to improve results over the baseline of not using a meta-classifier.
Gamon (2010) also considers missing and extraneous preposition errors. $$$$$ One is that of frequent lower order n-grams that dominate the language model score.

Some recent work includes Chodorow et al (2007), De Felice and Pulman (2008), Gamon (2010), Han et al (2010), Izumi et al (2004), Tetreault and Chodorow (2008), Rozovskaya and Roth (2010a, 2010b). $$$$$ Similarly, for substitution, in Your experience is very interesting for our company, the language model suggests substituting for with to while the classifier gives the substitution a very low probability.
Some recent work includes Chodorow et al (2007), De Felice and Pulman (2008), Gamon (2010), Han et al (2010), Izumi et al (2004), Tetreault and Chodorow (2008), Rozovskaya and Roth (2010a, 2010b). $$$$$ For a potential location that contains a preposition/article, the possible operations include deletion of the existing token or substitution with another preposition/article from the candidate set.

Gamon et al (2008) and Gamon (2010) used a language model in addition to a classifier and combined the classifier output and language model scores in a meta classifier. $$$$$ Prepositions, on the other hand, pose difficulties for language learners from all L1 backgrounds (Dalgish, 1995; Bitchener et al., 2005).
Gamon et al (2008) and Gamon (2010) used a language model in addition to a classifier and combined the classifier output and language model scores in a meta classifier. $$$$$ This result, again, is consistent across prepositions and articles.
Gamon et al (2008) and Gamon (2010) used a language model in addition to a classifier and combined the classifier output and language model scores in a meta classifier. $$$$$ 2.
Gamon et al (2008) and Gamon (2010) used a language model in addition to a classifier and combined the classifier output and language model scores in a meta classifier. $$$$$ The final training, tuning and test set sizes are as follows (note that for prepositions we had to reduce the size of the training set by an additional 20% in order to avoid memory limitations of our decision tree tools).

Note that this use of a host of language model features is substantially different from using a single language model score on hypothesized error and potential correction to filter out unlikely correction candidates as in Gamon et al (2008) and Gamon (2010). $$$$$ This strong imbalance of the language model score causes the metaclassifier to assign a relatively high probability to this being a correct revision, even though the errorspecific classifier is on the right track and gives a relatively high probability for the presence of a preposition and the choice of by.
Note that this use of a host of language model features is substantially different from using a single language model score on hypothesized error and potential correction to filter out unlikely correction candidates as in Gamon et al (2008) and Gamon (2010). $$$$$ This result, again, is consistent across prepositions and articles.
Note that this use of a host of language model features is substantially different from using a single language model score on hypothesized error and potential correction to filter out unlikely correction candidates as in Gamon et al (2008) and Gamon (2010). $$$$$ Note, though, that the manual tuning was performed to optimize performance against a different data set (the Chinese Learners of English Corpus: CLEC), so the latter point is not really comparable and hence is not included in the charts.
Note that this use of a host of language model features is substantially different from using a single language model score on hypothesized error and potential correction to filter out unlikely correction candidates as in Gamon et al (2008) and Gamon (2010). $$$$$ Products of the above ratios/deltas and classifier choice/presence probabilities Type of operation: deletion, insertion, substitution (3 features) For each preposition/article choice: P(choice): 13 features for prepositions (12 prepositions and other for a preposition not in that set), 2 for articles Original token: none (for insertion) or the original preposition/article (13 features for prepositions, 2 for articles) Suggested token: none (for deletion) or the suggested preposition/article (13 features for prepositions, 2 for articles) The total number of features is 63 for prepositions and 36 for articles.

In Figure 4 we compare the sequence modeling results for prepositions with results from the preposition component of the current version of the system described in Gamon (2010) on the same test set. $$$$$ Using a meta-classifier for ensemble learning has been proven effective for many machine learning problems (see e.g.
In Figure 4 we compare the sequence modeling results for prepositions with results from the preposition component of the current version of the system described in Gamon (2010) on the same test set. $$$$$ Still, the overall amount of expensive error-annotated data is relatively small, and the meta-classification approach makes it possible to leverage large amounts of wellformed text in the primary models, tuning to the non-native domain in the meta-classifier.
In Figure 4 we compare the sequence modeling results for prepositions with results from the preposition component of the current version of the system described in Gamon (2010) on the same test set. $$$$$ In other words, we do not count as correct instances where the system's prediction matches a correct preposition/article.

 $$$$$ We have conducted a failure analysis on examples where the system produces a blatantly bad suggestion in order to see whether this decision could be attributed to the error-specific classifier or to the language model, or both, and what the underlying cause is.
 $$$$$ The error-specific classifier, however, assigns a probability of 0.65 for a preposition to be present, and 0.80 for that preposition to be on.

The heuristics are based on those used in Gamon (2010) (personal communication). $$$$$ While the language model assigns a high probability for deleting of, the error-specific classifier does not.
The heuristics are based on those used in Gamon (2010) (personal communication). $$$$$ As can be seen from the learner sentences cited above, often, even though the sentences are grammatical, they are not idiomatic, which can confuse all of the classifiers.

Obtaining better-quality training data is a major issue for machine learning applied to learner language, as the domain of writing is different from news-heavy training domains (Gamon, 2010). $$$$$ This allows us to address the problem of domain mismatch: We can leverage large well-formed data sets that are substantially different from real-life learner language for the primary models, and then fine-tune the output to learner English using a much smaller set of expensive and hard-to-come-by annotated learner writing.
Obtaining better-quality training data is a major issue for machine learning applied to learner language, as the domain of writing is different from news-heavy training domains (Gamon, 2010). $$$$$ For the purpose of this paper, we restrict ourselves to article and preposition errors.
Obtaining better-quality training data is a major issue for machine learning applied to learner language, as the domain of writing is different from news-heavy training domains (Gamon, 2010). $$$$$ Still, the overall amount of expensive error-annotated data is relatively small, and the meta-classification approach makes it possible to leverage large amounts of wellformed text in the primary models, tuning to the non-native domain in the meta-classifier.
Obtaining better-quality training data is a major issue for machine learning applied to learner language, as the domain of writing is different from news-heavy training domains (Gamon, 2010). $$$$$ Second, the combination of scores from the classifier and language model through a metaclassifier clearly outperforms either one of them in isolation.

This is a baseline run that represents the language model approach proposed by Gamon (2010). $$$$$ Research on the automatic correction of grammatical errors has undergone a renaissance in the past decade.
This is a baseline run that represents the language model approach proposed by Gamon (2010). $$$$$ While the language model assigns a high probability for deleting of, the error-specific classifier does not.

Correcting preposition errors requires more data to achieve performance comparable to article error correction, due to the task complexity (Gamon, 2010). $$$$$ We have conducted a failure analysis on examples where the system produces a blatantly bad suggestion in order to see whether this decision could be attributed to the error-specific classifier or to the language model, or both, and what the underlying cause is.
Correcting preposition errors requires more data to achieve performance comparable to article error correction, due to the task complexity (Gamon, 2010). $$$$$ The metaclassifier, in contrast, is trained on a smaller set of error-annotated learner data.
Correcting preposition errors requires more data to achieve performance comparable to article error correction, due to the task complexity (Gamon, 2010). $$$$$ At prediction time, the presence and choice classifiers produce a list of potential changes in preposition/article usage for the given context.
Correcting preposition errors requires more data to achieve performance comparable to article error correction, due to the task complexity (Gamon, 2010). $$$$$ For a potential preposition/article location where there is no preposition/article, each of the candidates is considered for an insertion operation.

A third alternative, that of selectively removing or correcting errors, is something of a middle road, and has been used in other work using the CLC data $$$$$ Consider the CLEC sentence I get to know the world outside the campus by newspaper and television.
A third alternative, that of selectively removing or correcting errors, is something of a middle road, and has been used in other work using the CLC data $$$$$ From the total set of candidate operations (substitutions, insertions, and deletions) that each combination of presence and choice classifier produces for prepositions, we consider only the top three highest-scoring operations2.
A third alternative, that of selectively removing or correcting errors, is something of a middle road, and has been used in other work using the CLC data $$$$$ We then vary that difference across all observed values in small increments, which affects precision and recall: the higher the difference, the fewer instances we find, but the higher the reliability of these instances is.
A third alternative, that of selectively removing or correcting errors, is something of a middle road, and has been used in other work using the CLC data $$$$$ The meta-classifier takes the output of the primary models (language model scores and class probabilities) as input.

Features used in classication include surrounding words, part-of-speech tags, language model scores (Gamon, 2010), and parse tree structures (Tetreault et al, 2010). $$$$$ Consider Whatever direction my leg fought to stretch, with the suggested insertion of on before my leg.
