This alternate decoding path model was developed by Birch et al (2007). $$$$$ 15
This alternate decoding path model was developed by Birch et al (2007). $$$$$ This paper is the first to suggest this approach for combining multiple information sources in machine translation.Although the addition of supertags to phrase based translation does show some improvement, their overall impact is limited.
This alternate decoding path model was developed by Birch et al (2007). $$$$$ The factored translation model allows for the inclusion of valuable sources of information in many dif ferent ways.
This alternate decoding path model was developed by Birch et al (2007). $$$$$ This work was supported in part under the GALE program of theDefense Advanced Research Projects Agency, Con tract No.

However, Birch et al (2007) showed that this approach captures the same re-ordering phenomena as lexicalized re-ordering models, which were not included in the baseline. $$$$$ Multiple dependencies require some form of backing off to simpler models in order to cover the cases where, for instance, the word has been seen intraining, but not with that particular supertag.
However, Birch et al (2007) showed that this approach captures the same re-ordering phenomena as lexicalized re-ordering models, which were not included in the baseline. $$$$$ One of the strengths of the factored model is it allows for n-gram distributions over factors on the target.
However, Birch et al (2007) showed that this approach captures the same re-ordering phenomena as lexicalized re-ordering models, which were not included in the baseline. $$$$$ Because these categories are lexicalised, 11they can easily be included into factored phrase based translation.
However, Birch et al (2007) showed that this approach captures the same re-ordering phenomena as lexicalized re-ordering models, which were not included in the baseline. $$$$$ Column None does not apply any language model.

Birch et al (2007) then investigated source-side CCG super tag features, but did not show an improvement for Dutch-English. $$$$$ However, this is a limited way of leveraging the rich syn tactic information available in the CCG categories.
Birch et al (2007) then investigated source-side CCG super tag features, but did not show an improvement for Dutch-English. $$$$$ Our solution is to extract two translation models: t?
Birch et al (2007) then investigated source-side CCG super tag features, but did not show an improvement for Dutch-English. $$$$$ 15
Birch et al (2007) then investigated source-side CCG super tag features, but did not show an improvement for Dutch-English. $$$$$ This work was supported in part under the GALE program of theDefense Advanced Research Projects Agency, Con tract No.

Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al, 2007) to pass both tables to the Moses SMT decoder (Koehn et al, 2003), instead of directly combining the phrase tables to perform domain adaptation. $$$$$ How ever, reliably learning powerful rules from parallel data is very difficult and prone to problems with sparsity and noise in the data.
Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al, 2007) to pass both tables to the Moses SMT decoder (Koehn et al, 2003), instead of directly combining the phrase tables to perform domain adaptation. $$$$$ This work was supported in part under the GALE program of theDefense Advanced Research Projects Agency, Con tract No.
Lastly, Koehn and Schroeder (2007) reported improvements from using multiple decoding paths (Birch et al, 2007) to pass both tables to the Moses SMT decoder (Koehn et al, 2003), instead of directly combining the phrase tables to perform domain adaptation. $$$$$ CCG supertags?

We have also shown in passing that the linear interpolation of translation models may work less well for translation model adaptation than the multiple paths decoding technique of (Birch et al, 2007). $$$$$ = argmax t { M?
We have also shown in passing that the linear interpolation of translation models may work less well for translation model adaptation than the multiple paths decoding technique of (Birch et al, 2007). $$$$$ Our first Dutch-English experiment seeks to estab lish what effect sequence models have on machinetranslation.
We have also shown in passing that the linear interpolation of translation models may work less well for translation model adaptation than the multiple paths decoding technique of (Birch et al, 2007). $$$$$ We propose using a logarithmic opinion pool (Smith et al, 2005) to combine the more specific models (which depend onboth words and supertags) with more general mod els (which only depends on words).
We have also shown in passing that the linear interpolation of translation models may work less well for translation model adaptation than the multiple paths decoding technique of (Birch et al, 2007). $$$$$ For both Arabic-English (Hassan et al, 2007) and our experiments in Dutch-English, n-gram models over CCG supertags improve the quality of translation.

Finally, Birch et al (2007) exploit factored phrase-based translation models to associate each word with a supertag, which contains most of the information needed to build a full parse. $$$$$ This is because there are words in the test sentence that have been seen before but not with the CCG supertag.
Finally, Birch et al (2007) exploit factored phrase-based translation models to associate each word with a supertag, which contains most of the information needed to build a full parse. $$$$$ The factored translation model allows for the inclusion of valuable sources of information in many dif ferent ways.
Finally, Birch et al (2007) exploit factored phrase-based translation models to associate each word with a supertag, which contains most of the information needed to build a full parse. $$$$$ In this experiment we investigate whether by using astronger language model the contribution of the sequence model will no longer be relevant.
Finally, Birch et al (2007) exploit factored phrase-based translation models to associate each word with a supertag, which contains most of the information needed to build a full parse. $$$$$ Similarly the phrase ?eats apples?

Birch et al (2007) also reported a significant improvement for Dutch-English translation by applying CCG supertags at a word level to a factorized SMT system (Koehn et al, 2007). $$$$$ HR0011-06-C-0022 and in part under theEuroMatrix project funded by the European Com mission (6th Framework Programme).
Birch et al (2007) also reported a significant improvement for Dutch-English translation by applying CCG supertags at a word level to a factorized SMT system (Koehn et al, 2007). $$$$$ However, these models, which are equivalent to finite-state machines (Kumar and Byrne, 2003), are unable to model long range word order differences.

We built two separate phrase tables for the two bi-texts, and we used them in the alter native decoding path model of Birch et al (2007). $$$$$ However, these models, which are equivalent to finite-state machines (Kumar and Byrne, 2003), are unable to model long range word order differences.
We built two separate phrase tables for the two bi-texts, and we used them in the alter native decoding path model of Birch et al (2007). $$$$$ We show that this results in an im provement in the quality of translation and that the value of syntactic supertags in flat structured phrase-based models is largely due to better local reorderings.
We built two separate phrase tables for the two bi-texts, and we used them in the alter native decoding path model of Birch et al (2007). $$$$$ Clark (2002) developed a suppertagger for CCG which uses a conditional maximum entropy model to estimate theprobability of words being assigned particular cat egories.

Birch et al (2007) and Hassan et al (2007) have shown the effectiveness of adding supertags on the target side, and Avramidis and Koehn (2008) have focused on the source side ,translating a morphologically-poor language (English) to a morphologically-rich language (Greek). $$$$$ Recently 1www.nist.gov/speech/tests/mt/mt06eval official results.html there have been a few syntax-based models that show performance comparable to the phrase-basedmodels (Chiang, 2005; Marcu et al, 2006).
Birch et al (2007) and Hassan et al (2007) have shown the effectiveness of adding supertags on the target side, and Avramidis and Koehn (2008) have focused on the source side ,translating a morphologically-poor language (English) to a morphologically-rich language (Greek). $$$$$ HR0011-06-C-0022 and in part under theEuroMatrix project funded by the European Com mission (6th Framework Programme).
Birch et al (2007) and Hassan et al (2007) have shown the effectiveness of adding supertags on the target side, and Avramidis and Koehn (2008) have focused on the source side ,translating a morphologically-poor language (English) to a morphologically-rich language (Greek). $$$$$ Sequence models over supertags clearly result in some improvementsin local reordering but syntactic information con tains long distance dependencies which are simply not utilised in phrase-based models.
Birch et al (2007) and Hassan et al (2007) have shown the effectiveness of adding supertags on the target side, and Avramidis and Koehn (2008) have focused on the source side ,translating a morphologically-poor language (English) to a morphologically-rich language (Greek). $$$$$ 15

Our approach is slightly different from (Birch et al, 2007) and (Hassan et al, 2007), who mainly used the super tags on the target language side, English. $$$$$ CCG supertags?
Our approach is slightly different from (Birch et al, 2007) and (Hassan et al, 2007), who mainly used the super tags on the target language side, English. $$$$$ Combinatorial Categorial Grammar (CCG) supertags present phrase-based machine translation with an opportunity to access rich syntactic information at a word level.The challenge is incorporating this informa tion into the translation process.
Our approach is slightly different from (Birch et al, 2007) and (Hassan et al, 2007), who mainly used the super tags on the target language side, English. $$$$$ Combinatorial Categorial Grammar (CCG) supertags present phrase-based machine translation with an opportunity to access rich syntactic information at a word level.The challenge is incorporating this informa tion into the translation process.

Probabilistic models for using only source tags were investigated by Birch et al (2007), who attached syntax hints in factored SMT models by having Combinatorial Categorial Grammar (CCG) super tags as factors on the input words, but in this case English was the target language. $$$$$ We have shown that the syntacticallyrich CCG supertags do improve the translation pro cess and we investigate the best way of including them in the factored model.
Probabilistic models for using only source tags were investigated by Birch et al (2007), who attached syntax hints in factored SMT models by having Combinatorial Categorial Grammar (CCG) super tags as factors on the input words, but in this case English was the target language. $$$$$ This work was supported in part under the GALE program of theDefense Advanced Research Projects Agency, Con tract No.
Probabilistic models for using only source tags were investigated by Birch et al (2007), who attached syntax hints in factored SMT models by having Combinatorial Categorial Grammar (CCG) super tags as factors on the input words, but in this case English was the target language. $$$$$ The data consists of 751,088 sentences of training data, 500 sentences of tuning data and3064 sentences of test data.
Probabilistic models for using only source tags were investigated by Birch et al (2007), who attached syntax hints in factored SMT models by having Combinatorial Categorial Grammar (CCG) super tags as factors on the input words, but in this case English was the target language. $$$$$ HR0011-06-C-0022 and in part under theEuroMatrix project funded by the European Com mission (6th Framework Programme).

In order to reduce these problems, decoding needed to consider alternative paths to translation tables trained with less or no factors (as Birch et al (2007) suggested), so as to cover instances where a word appears with a factor which it has not been trained with. $$$$$ Factoredtranslation models allow the inclusion of supertags as a factor in the source or target language.
In order to reduce these problems, decoding needed to consider alternative paths to translation tables trained with less or no factors (as Birch et al (2007) suggested), so as to cover instances where a word appears with a factor which it has not been trained with. $$$$$ 15
In order to reduce these problems, decoding needed to consider alternative paths to translation tables trained with less or no factors (as Birch et al (2007) suggested), so as to cover instances where a word appears with a factor which it has not been trained with. $$$$$ This is because there are words in the test sentence that have been seen before but not with the CCG supertag.
In order to reduce these problems, decoding needed to consider alternative paths to translation tables trained with less or no factors (as Birch et al (2007) suggested), so as to cover instances where a word appears with a factor which it has not been trained with. $$$$$ 15

Supertagging encapsulates more contextual information than POS tags and Birch et al (2007) report improvements when comparing a super tag language model to a baseline using a word language model only. $$$$$ This work was supported in part under the GALE program of theDefense Advanced Research Projects Agency, Con tract No.
Supertagging encapsulates more contextual information than POS tags and Birch et al (2007) report improvements when comparing a super tag language model to a baseline using a word language model only. $$$$$ We thank Hieu Hoang for assistance with Moses, Ju lia Hockenmaier for access to CCGbank lexicons in German and English, and Stephen Clark and James Curran for providing the supertagger.
Supertagging encapsulates more contextual information than POS tags and Birch et al (2007) report improvements when comparing a super tag language model to a baseline using a word language model only. $$$$$ M? m=1 ?mhm(sw, tw) + N?
Supertagging encapsulates more contextual information than POS tags and Birch et al (2007) report improvements when comparing a super tag language model to a baseline using a word language model only. $$$$$ The improvements in reordering shown here are reorderings over a relatively short distance, two or three positions.

Hassan et al (2007) and Birch et al (2007) use super tag n-gram LMs. $$$$$ Factoredtranslation models allow the inclusion of supertags as a factor in the source or target language.
Hassan et al (2007) and Birch et al (2007) use super tag n-gram LMs. $$$$$ However, these models, which are equivalent to finite-state machines (Kumar and Byrne, 2003), are unable to model long range word order differences.
Hassan et al (2007) and Birch et al (2007) use super tag n-gram LMs. $$$$$ Factoredtranslation models allow the inclusion of supertags as a factor in the source or target language.

Our approach is slightly different from (Birch et al, 2007) and (Hassan et al, 2007), who mainly used the supertags on the target language side, English. $$$$$ By preferring more likely sequences of supertags, it is conceivable that the output of the decoder is 9 more grammatical.
Our approach is slightly different from (Birch et al, 2007) and (Hassan et al, 2007), who mainly used the supertags on the target language side, English. $$$$$ The last experiment shows the effect of CCG supertags on the source, translating from German into English.

Factored translation models have also been used for the integration of CCG super tags (Birch et al, 2007), domain adaptation (Koehn and Schroeder, 2007) and for the improvement of English-Czech translation (Bojar, 2007). $$$$$ under the operation of forward application.
Factored translation models have also been used for the integration of CCG super tags (Birch et al, 2007), domain adaptation (Koehn and Schroeder, 2007) and for the improvement of English-Czech translation (Bojar, 2007). $$$$$ CCGs have syntactically rich lexicons and a small set of combinatory operators which assemble the parse-trees.
Factored translation models have also been used for the integration of CCG super tags (Birch et al, 2007), domain adaptation (Koehn and Schroeder, 2007) and for the improvement of English-Czech translation (Bojar, 2007). $$$$$ By preferring more likely sequences of supertags, it is conceivable that the output of the decoder is 9 more grammatical.
Factored translation models have also been used for the integration of CCG super tags (Birch et al, 2007), domain adaptation (Koehn and Schroeder, 2007) and for the improvement of English-Czech translation (Bojar, 2007). $$$$$ HR0011-06-C-0022 and in part under theEuroMatrix project funded by the European Com mission (6th Framework Programme).
