Recently, Snow, Jurafsky and Ng (2005) generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet (Snow et al, 2006). $$$$$ For the purposes of taxonomy induction, we would prefer an ancestor-distance specific set of classifiers over senses, i.e., for k E senses(i), l E senses(j), the set of classifiers estimating {P(H� kl|EH ij ), P(Hkl|EHij ), ... }.
Recently, Snow, Jurafsky and Ng (2005) generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet (Snow et al, 2006). $$$$$ We see that the baseline non-joint algorithm has higher precision than the NER oracle as 10,000 and 20,000 links; however, both are significantly outperformed by our joint algorithm, which maintains high coarse-grained precision (92%) even at 20,000 links.
Recently, Snow, Jurafsky and Ng (2005) generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet (Snow et al, 2006). $$$$$ We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.

Following Snow et al (2006), we derive two types of evidence from these patterns $$$$$ Many algorithms with the potential for automatically extending lexical resources have been proposed, including work in lexical acquisition (Riloff and Shepherd, 1997; Roark and Charniak, 1998) and in discovering instances, named entities, and alternate glosses (Etzioni et al., 2005; Pasc¸a, 2005).
Following Snow et al (2006), we derive two types of evidence from these patterns $$$$$ Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns.
Following Snow et al (2006), we derive two types of evidence from these patterns $$$$$ Our probabilistic architecture also includes a new model for learning coordinate terms based on (m, n)-cousin classification.
Following Snow et al (2006), we derive two types of evidence from these patterns $$$$$ In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).

 $$$$$ We use a set of more than 1000 distinct clusters of English nouns collected by their algorithm over 70 million webpages6, with each noun i having a score representing its cosine similarity to the centroid c of the cluster to which it belongs, cos(B(i, c)).
 $$$$$ The model’s ability to integrate heterogeneous evidence from different classifiers offers a solution to the key problem of choosing the correct word sense to which to attach a new hypernym.

Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al, 2006), tools and corpora. $$$$$ Thanks to Christiane Fellbaum, Rajat Raina, Bill MacCartney, and Allison Buckley for useful discussions and assistance annotating data.
Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al, 2006), tools and corpora. $$$$$ We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.
Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al, 2006), tools and corpora. $$$$$ Past work on semantic taxonomy induction includes the noun hypernym hierarchy created in (Caraballo, 2001), the part-whole taxonomies in (Girju, 2003), and a great deal of recent work described in (Buitelaar et al., 2005).
Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al, 2006), tools and corpora. $$$$$ Next, we iterate through each of the possible hypernym synsets l under which we might add the new word i; for each synset l we compute the change in taxonomy score resulting from adding the implied relations I(H1il) required by the taxonomic constraints of T. Since typically our set of all evidence involving i will be much smaller than the set of possible relations in I(H1il), we may efficiently check whether, for each sense s E senses(w), for all words where we have some evidence ERiw, whether s participates in some relation with i in the set of implied relations I(H1il).7 If there is more than one sense s E senses(w), we add to I(H1il) the single relationship Ris that maximizes the taxonomy likelihood, i.e. arg maxsEsenses(w) AT(Ris).

We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). $$$$$ We refer to the full set of novel relations implied by a new link Rij as I(Rij); we discuss the efficient computation of the set of implied links for the purpose of hyponym acquisition in Section 3.4.
We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). $$$$$ The addition of any new hypernym relation to a preexisting taxonomy will usually necessitate the addition of a set of other novel relations as implied by the taxonomic constraints.
We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). $$$$$ Applying these two independence assumptions we may express the conditional probability of our evidence given the taxonomy: Within our model we define the goal of taxonomy induction to be to find the taxonomy T� that maximizes the conditional probability of our observations E given the relationships of T, i.e., to find We propose a search algorithm for finding T� for the case of hyponym acquisition.
We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%). $$$$$ Two senses are typically considered to be “coordinate terms” or “taxonomic sisters” if they share an immediate parent in the hypernym hierarchy.

Snow et al (Snow et al, 2006) use known hypernym / hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns. $$$$$ Thanks to Christiane Fellbaum, Rajat Raina, Bill MacCartney, and Allison Buckley for useful discussions and assistance annotating data.
Snow et al (Snow et al, 2006) use known hypernym / hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns. $$$$$ We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.
Snow et al (Snow et al, 2006) use known hypernym / hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns. $$$$$ If two words i and j appear in a cluster together, with cluster centroid c, we set our single coordinate input feature to be the minimum cluster score min(cos(B(i, c)), cos(B(j, c))), and zero otherwise.

Snow (Snow et al, 2006) has extended the Word Net 2.1 by adding thousands of entries (synsets) at a relatively high precision. $$$$$ Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns.
Snow (Snow et al, 2006) has extended the Word Net 2.1 by adding thousands of entries (synsets) at a relatively high precision. $$$$$ We use the minimum of the two judges’ scores.
Snow (Snow et al, 2006) has extended the Word Net 2.1 by adding thousands of entries (synsets) at a relatively high precision. $$$$$ The goal of capturing structured relational knowledge about lexical terms has been the motivating force underlying many projects in lexical acquisition, information extraction, and the construction of semantic taxonomies.

 $$$$$ This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.
 $$$$$ Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns.
 $$$$$ The features used for predicting the hypernym relationship are obtained by parsing a large corpus of newswire and encyclopedia text with MINIPAR (Lin, 1998).

Snow et al (2006) add novel terms by greedily maximizing the conditional probability of a set of relational evidence given a taxonomy. $$$$$ From the resulting dependency trees the evidence EHij for each word pair (i, j) is constructed; the evidence takes the form of a vector of counts of occurrences that each labeled syntactic dependency path was found as the shortest path connecting i and j in some dependency tree.
Snow et al (2006) add novel terms by greedily maximizing the conditional probability of a set of relational evidence given a taxonomy. $$$$$ The model for predicting P(Hij|EHij ) is then trained using logistic regression, predicting the noun-pair hypernymy label from WordNet from the feature vector of lexico-syntactic patterns.
Snow et al (2006) add novel terms by greedily maximizing the conditional probability of a set of relational evidence given a taxonomy. $$$$$ While in principle we could use any number of relations, for simplicity we consider two primary sources of evidence: the probability of two words in WordNet being in a hypernym relation, and the probability of two words in WordNet being in a coordinate relation.

Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ Here we measure the precision of sense-disambiguation among all examples where each algorithm found a correct hyponym word; our calculation for disambiguation precision is c1/ (c1 + c2).
Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.

The work by Snow et al (2006) is the most similar to ours because they also took an incremental approach to construct taxonomies. $$$$$ Thanks to Christiane Fellbaum, Rajat Raina, Bill MacCartney, and Allison Buckley for useful discussions and assistance annotating data.
The work by Snow et al (2006) is the most similar to ours because they also took an incremental approach to construct taxonomies. $$$$$ Next, we iterate through each of the possible hypernym synsets l under which we might add the new word i; for each synset l we compute the change in taxonomy score resulting from adding the implied relations I(H1il) required by the taxonomic constraints of T. Since typically our set of all evidence involving i will be much smaller than the set of possible relations in I(H1il), we may efficiently check whether, for each sense s E senses(w), for all words where we have some evidence ERiw, whether s participates in some relation with i in the set of implied relations I(H1il).7 If there is more than one sense s E senses(w), we add to I(H1il) the single relationship Ris that maximizes the taxonomy likelihood, i.e. arg maxsEsenses(w) AT(Ris).
The work by Snow et al (2006) is the most similar to ours because they also took an incremental approach to construct taxonomies. $$$$$ Many algorithms with the potential for automatically extending lexical resources have been proposed, including work in lexical acquisition (Riloff and Shepherd, 1997; Roark and Charniak, 1998) and in discovering instances, named entities, and alternate glosses (Etzioni et al., 2005; Pasc¸a, 2005).

We compare system performance between (Snow et al, 2006) and our framework in Section 5. $$$$$ Rion Snow is supported by an NDSEG Fellowship sponsored by the DOD and AFOSR.
We compare system performance between (Snow et al, 2006) and our framework in Section 5. $$$$$ The 26 supersenses used in WordNet 2.1 are listed in Table 1; we label a hyponym link as correct in the coarse-grained evaluation if the novel hyponym is placed under the appropriate supersense.
We compare system performance between (Snow et al, 2006) and our framework in Section 5. $$$$$ The model’s ability to integrate heterogeneous evidence from different classifiers offers a solution to the key problem of choosing the correct word sense to which to attach a new hypernym.
We compare system performance between (Snow et al, 2006) and our framework in Section 5. $$$$$ Our probabilistic architecture also includes a new model for learning coordinate terms based on (m, n)-cousin classification.

To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P (Rij $$$$$ This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.
To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P (Rij $$$$$ The model’s ability to integrate heterogeneous evidence from different classifiers offers a solution to the key problem of choosing the correct word sense to which to attach a new hypernym.
To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P (Rij $$$$$ We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term classifiers with the knowledge in a preexisting semantaxonomy (WordNet 2.1).

An extension to WordNet was presented by (Snow et al, 2006). $$$$$ By contrast, our algorithm flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word’s coordinate terms to help in determining its hypernyms, and vice versa.
An extension to WordNet was presented by (Snow et al, 2006). $$$$$ For simplicity we make the following independence assumptions: first, we assume that each item of observed evidence ERij is independent of all other observed evidence given the taxonomy T, i.e., P(E|T) = 11ERijEE P(ERij|T).
An extension to WordNet was presented by (Snow et al, 2006). $$$$$ Another major shortfall in previous techniques for taxonomy induction has been the inability to handle lexical ambiguity.
An extension to WordNet was presented by (Snow et al, 2006). $$$$$ Such work has typically either focused on only inferring small taxonomies over a single relation, or as in (Caraballo, 2001), has used evidence for multiple relations independently from one another, by for example first focusing strictly on inferring clusters of coordinate terms, and then by inferring hypernyms over those clusters.

Snow et al (2006) use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, whose training examples are derived automatically from WordNet. $$$$$ A major strength of our model is its ability to correctly choose the sense of a hypernym to which to add a novel hyponym, despite collecting evidence over untagged word pairs.
Snow et al (2006) use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, whose training examples are derived automatically from WordNet. $$$$$ The labeled training set is constructed by labeling the collected feature vectors as positive “known hypernym” or negative “known non-hypernym” examples using WordNet 2.0; 49,922 feature vectors were labeled as positive training examples, and 800,828 noun pairs were labeled as negative training examples.
Snow et al (2006) use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, whose training examples are derived automatically from WordNet. $$$$$ For example, the relations in WordNet include hypernymy, holonymy, verb entailment, and many others; the objects of WordNet between which these relations hold are its word senses or synsets.
Snow et al (2006) use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, whose training examples are derived automatically from WordNet. $$$$$ This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.

Following the spirit of the fine-grained human evaluation in (Snow et al, 2006), we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above. $$$$$ Thanks to Christiane Fellbaum, Rajat Raina, Bill MacCartney, and Allison Buckley for useful discussions and assistance annotating data.
Following the spirit of the fine-grained human evaluation in (Snow et al, 2006), we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above. $$$$$ For example, the relations in WordNet include hypernymy, holonymy, verb entailment, and many others; the objects of WordNet between which these relations hold are its word senses or synsets.
Following the spirit of the fine-grained human evaluation in (Snow et al, 2006), we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above. $$$$$ We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term classifiers with the knowledge in a preexisting semantaxonomy (WordNet 2.1).

We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al, 2006)). $$$$$ We use the minimum of the two judges’ scores.
We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al, 2006)). $$$$$ In this paper we focus on two of the many possible relationships between senses: the hypernym relation and the coordinate term relation.
We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al, 2006)). $$$$$ Rion Snow is supported by an NDSEG Fellowship sponsored by the DOD and AFOSR.

For example, (Snow et al 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. $$$$$ Finally, we show that a taxonomy built using our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hypernym pairs.
For example, (Snow et al 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. $$$$$ We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.
For example, (Snow et al 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. $$$$$ We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.
For example, (Snow et al 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. $$$$$ For simplicity we make the following independence assumptions: first, we assume that each item of observed evidence ERij is independent of all other observed evidence given the taxonomy T, i.e., P(E|T) = 11ERijEE P(ERij|T).

More recently, Snow et al (2005) and Snow et al (2006) have described a method of hypernymy extraction using machine learning of 53 patterns. $$$$$ We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.
More recently, Snow et al (2005) and Snow et al (2006) have described a method of hypernymy extraction using machine learning of 53 patterns. $$$$$ This yields a list of 95,000 single links over threshold P(Rij) > 0.12.

Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al, 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)). $$$$$ Past work on semantic taxonomy induction includes the noun hypernym hierarchy created in (Caraballo, 2001), the part-whole taxonomies in (Girju, 2003), and a great deal of recent work described in (Buitelaar et al., 2005).
Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al, 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)). $$$$$ The model for predicting P(Hij|EHij ) is then trained using logistic regression, predicting the noun-pair hypernymy label from WordNet from the feature vector of lexico-syntactic patterns.
Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al, 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)). $$$$$ The key contribution of this work is to offer a solution to two crucial problems in taxonomy inProceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 801–808, Sydney, July 2006. c�2006 Association for Computational Linguistics duction and hyponym acquisition: the problem of combining heterogenous sources of evidence in a flexible way, and the problem of correctly identifying the appropriate word sense of each new word added to the taxonomy.1
Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al, 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)). $$$$$ In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).
