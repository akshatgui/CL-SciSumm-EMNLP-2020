Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ It is therefore reasonable to think that a more efficient reimplementation would result in across-the-board speedups.11The results shown here do not include the startup time re quired to load the data structures into memory.
Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ We are cur rently investigating this option in a C reimplementation.
Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ Load the source training text F , the suffix array.
Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ To see why the latter optimization is useful, consider a phrase abXcd.

However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ 11It is clear from the results that each of the op timizations is needed to sufficiently reduce lookuptime to practical levels.
However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ This model would bring statistical machine translation closer to convergence with so-called example-based translation, following current trends (Marcu, 2001;Och, 2002).
However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ Some recent models permit discontiguous phrases (Chiang, 2007; Quirket al, 2005; Simard et al, 2005).
However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.

We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ We close with a discussion that describes several applications of our work (?7).
We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ The best algo rithm for pattern matching with variable-length gaps in a suffix array is a recent algorithm by Rahman et al (2006).
We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ Both Callison-Burch et al (2005) and Zhang and Vogel (2005) solve this with sampling.

We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ Adjacent nonterminals are disallowed in the source side of a rule.
We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ Recently, Lopez and Resnik (2006) showed that most of the features used in standard phrase-based models do not help very much.
We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.

Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ Wedescribe new lookup algorithms for hierar chical phrase-based translation that reduce the empirical computation time by nearly two orders of magnitude, making on-the-fly lookup feasible for source phrases with gaps.
Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ This model would bring statistical machine translation closer to convergence with so-called example-based translation, following current trends (Marcu, 2001;Och, 2002).
Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ However, the suffix array returnsmatchings in lexicographical order, not numeric or der.

Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ A suffix array is a data structure representing all suf fixes of a corpus in lexicographical order (Manber and Myers, 1993).
Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ 6Minor modifications are required since we are computing collocation rather than intersection.
Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ In phrase-based models, this prob lem can be addressed by storing the training data in memory and using a suffix array asan efficient index to quickly lookup and extract rules on the fly.
Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ To analyze the problem, we measured the amount of CPU time per computation.

The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ SAF , the target training text E, and the align ment A into memory.
The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ Wedescribe new lookup algorithms for hierar chical phrase-based translation that reduce the empirical computation time by nearly two orders of magnitude, making on-the-fly lookup feasible for source phrases with gaps.
The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ We can improve on the algorithm of Rahman et al.

In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ We will additionally use ? and ? to denote(possibly empty) sequences containing both termi nals and nonterminals.
In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ Tight restrictions on phrase length curtail the power of phrase-basedmodels.
In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ Current statistical machine translation systems rely on very large rule sets.
In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ This research was supported in part by ONR MURI Contract FCPO.810548265 and the GALE program of the Defense AdvancedResearch Projects Agency, Contract No.

We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ The first case consists of all patterns prefixed with X . The paths to nodes representing these patterns 982 will all contain the X-edge originating at the rootnode.
We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ SAF , the target training text E, and the align ment A into memory.
We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ This rule states that a span of the input matching ? is replacedby ? in translation.

The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ An alternative approach introduced independently by both Callison-Burch et al (2005) and Zhang and Vogel (2005) is to store the training data itself inmemory, and use a suffix array as an efficient in dex to look up, extract, and score phrase pairs on the fly.
The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ We then describe a series of algorithms to address thisinefficiency (?5).
The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ Until recently, most approaches to this probleminvolved substantial tradeoffs.

Besides storing the whole grammar locally in memory, other approaches have been developed, such as suffix arrays, which lookup and extract rules on the fly from the phrase table (Lopez, 2007). $$$$$ To generate alignments,we used GIZA++ (Och and Ney, 2003).
Besides storing the whole grammar locally in memory, other approaches have been developed, such as suffix arrays, which lookup and extract rules on the fly from the phrase table (Lopez, 2007). $$$$$ The lexicalizedtranslation rules of the grammar may contain a sin gle nonterminal symbol, denoted X . We will use a, b, c and d to denote terminal symbols, and u, v, andw to denote (possibly empty) sequences of these ter minals.
Besides storing the whole grammar locally in memory, other approaches have been developed, such as suffix arrays, which lookup and extract rules on the fly from the phrase table (Lopez, 2007). $$$$$ Rules can span at most ten words.

The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ This representationenables fast lookup of any contiguous substring us ing binary search.
The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ However,we can exploit the fact that we must compute col locations multiple times for each input n-gram by caching the sorted set after we create it (The cachingstrategy is described in ?5.4).
The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.
The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ It is perhaps surprising that such a small sample size works as well as the full data.

This data structure has been used similarly to index whole training sentences for efficient retrieval (Lopez, 2007). $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.
This data structure has been used similarly to index whole training sentences for efficient retrieval (Lopez, 2007). $$$$$ Therefore, thetotal running time for an algorithm to find all con tiguous subpatterns and compute their collocations is O( ?I i=1 [|wi|+ log|T |+ ni log log |T |]).

(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ There is alsoa small number of patterns uXv that are very frequent.
(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ Zens and Ney (2007) use a disk-based prefix tree, enabling efficient access to phrase tables much too large to fit in main memory.
(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ Once we have found the closest sentences we cantranslate the matched portions in their entirety, re placing mismatches with appropriate word, phrase, or hierarchical phrase translations as needed.

 $$$$$ We will additionally use ? and ? to denote(possibly empty) sequences containing both termi nals and nonterminals.
 $$$$$ An alternative approach introduced independently by both Callison-Burch et al (2005) and Zhang and Vogel (2005) is to store the training data itself inmemory, and use a suffix array as an efficient in dex to look up, extract, and score phrase pairs on the fly.
 $$$$$ We will need another algorithmto find the source rules containing at least oneX surrounded by nonempty sequences of terminal sym bols.

The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ It works on a pattern w1Xw2X...wI consisting of I contiguous substrings w1, w2, ...wI ,each separated by a gap.
The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ aligned phrase e?

There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ This rule states that a span of the input matching ? is replacedby ? in translation.
There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ Although this is still rela tively slow, it is much closer to the decoding time of 10 seconds per sentence than the baseline.
There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ 4.2 Analysis.
There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ The runs using precomputation use the 1000 most frequent patterns.

This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ 5.
This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ 10 Timingresults are reported for machines with 8GB of mem ory and 4 3GHz Xeon processors running Red Hat linux 2.6.9.
This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ Lookup algorithms used for contiguous phrases nolonger apply and the best approximate pat tern matching algorithms are much too slow, taking several minutes per sentence.

This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ In order to avoid the full n|T | cost in memory, our implementation uses a mixed strategy.
This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.
This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ In that case, total lookup time is O(|w| + log|T |) for a contiguous pattern w. 4Often known in the literature as a van Emde Boas tree or van Emde Boas priority queue.

In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ 4.
In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ Using approximate pattern matching algo rithms, we imagine that machine translation could be treated very much like search in a protein database.
In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ They are crucial to keeping up with the ever-increasing size of parallel corpora, as well as the introduction of new data sources such as web-mined and comparable corpora.
In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ ... a c a c b a d c a d ... a c a d b a a d b d ... a d d b a a d a b c ... a d d b d a a b b a ... a d d b d d c a a a ...
