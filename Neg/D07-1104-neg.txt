Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ In that case, total lookup time is O(|w| + log|T |) for a contiguous pattern w. 4Often known in the literature as a van Emde Boas tree or van Emde Boas priority queue.
Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ If we search for this rule in the followinglogical suffix array fragment, we will find the bold faced matches.
Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ After identifying all ni occurrences of each wi in O(|wi| + log |T |) time, collocations thatmeet the gap constraints are computed using an ef ficient data structure called a stratified tree (van Emde Boas et al, 1977).
Due to space constraints, details and proof of correctness are available in Lopez (2007a). $$$$$ Wedescribe new lookup algorithms for hierar chical phrase-based translation that reduce the empirical computation time by nearly two orders of magnitude, making on-the-fly lookup feasible for source phrases with gaps.

However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ All of our experiments were performed on ChineseEnglish in the news domain.
However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ 5.4.3 Prefix Trees and Suffix Links Our search optimizations are easily captured in a prefix tree data structure augmented with suffix links.Formally, a prefix tree is an unminimized determin istic finite-state automaton that recognizes all of thepatterns in some set.
However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ tence with a standard decoding algorithm.
However, in machine translation most features can still be traced back to the IBM Models of 15 years ago (Lopez, 2007b). $$$$$ Hierarchical phrasebased translation introduces the added wrin kle of source phrases with gaps.

We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ Any opinions, findings, conclusions or recommendations expressed in this paper are those of the author and do not necessarily reflect the view of DARPA.
We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ Foreven moderately frequent subpatterns this term dom inates complexity.
We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ We used the first 50 sentences of the NIST 2003test set to compute timing results.
We built grammars using its implementation of the suffix array extraction method described in Lopez (2007). $$$$$ 984

We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ The problem statement for our work is: Given an input sentence, efficiently find all hierarchical phrase-based translation rules for that sentence in the training corpus.
We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ We tackle the problem using the online rule extraction method of Callison-Burch et al (2005) and Zhang and Vogel (2005).
We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ Formally, this model is a syn chronous context-free grammar.
We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively. $$$$$ It is perhaps surprising that such a small sample size works as well as the full data.

Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ Consider the rule aXbXc.
Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ A suffix link is a pointer from a node representing path a?
Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.
Lopez (2007) extracts rules on-the-fly from the training bi text during decoding, searching efficiently for rule patterns using suffix arrays. $$$$$ We can improve on the algorithm of Rahman et al.

Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ In order to understand the contributions of various improvements, we also ran the system with with various ablations.
Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ If a source phraseappears more than k times, they sample only k oc currences for rule extraction.
Joshua (Li et al, 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). $$$$$ Each node in the tree repre8Except when ? = X , in which case a and b must be collo cated within a window defined by the phrase length constraints.

The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ This can be done in one pass over the data.
The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ By comparison, decoding time persentence is roughly 10 seconds with moderately ag gressive pruning, using the Python implementation of Chiang (2007).
The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ Its prefix is represented by node (2), and node (2)?s suffix is represented by node (3).
The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003). $$$$$ Wedescribe new lookup algorithms for hierar chical phrase-based translation that reduce the empirical computation time by nearly two orders of magnitude, making on-the-fly lookup feasible for source phrases with gaps.

In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ If a source phraseappears more than k times, they sample only k oc currences for rule extraction.
In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ Lookup algorithms used for contiguous phrases nolonger apply and the best approximate pat tern matching algorithms are much too slow, taking several minutes per sentence.
In this system, we use the GIZA++toolkit (Och and Ney, 2003), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och, 2003) to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively. $$$$$ Both Callison-Burch et al (2005) and Zhang and Vogel (2005) solve this with sampling.

We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ 10 Timingresults are reported for machines with 8GB of mem ory and 4 3GHz Xeon processors running Red Hat linux 2.6.9.
We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ 1.
We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ We require that ? and ? con tain an equal number (possibly zero) of coindexed nonterminals.
We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively. $$$$$ Consider the rule aXbXc.

The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ We tackle the problem using the online rule extraction method of Callison-Burch et al (2005) and Zhang and Vogel (2005).
The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ We tackle the problem using the online rule extraction method of Callison-Burch et al (2005) and Zhang and Vogel (2005).
The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.
The hierarchical phrase-base translation grammar was extracted using a suffix array rule extractor (Lopez, 2007). $$$$$ Rules can contain at most five terminals.

Besides storing the whole grammar locally in memory, other approaches have been developed, such as suffix arrays, which lookup and extract rules on the fly from the phrase table (Lopez, 2007). $$$$$ If a source phraseappears more than k times, they sample only k oc currences for rule extraction.
Besides storing the whole grammar locally in memory, other approaches have been developed, such as suffix arrays, which lookup and extract rules on the fly from the phrase table (Lopez, 2007). $$$$$ Even though these suffixes are in lexicographicalorder, matching suffixes are interspersed with non matching suffixes.

The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ To generate alignments,we used GIZA++ (Och and Ney, 2003).
The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ The memory cost is one length-|T | array per index.
The pipeline extracts a Hiero-style synchronous context-free grammar (Chiang, 2007), employs suffix-array based rule extraction (Lopez, 2007), and tunes model parameters with minimum error rate training (Och,2003). $$$$$ We then describe a series of algorithms to address thisinefficiency (?5).

This data structure has been used similarly to index whole training sentences for efficient retrieval (Lopez, 2007). $$$$$ A major engineering challenge in statistical machine translation systems is the efficient representation of extremely large translationrulesets.
This data structure has been used similarly to index whole training sentences for efficient retrieval (Lopez, 2007). $$$$$ We analyze the memory use of our algorithms in ?5.5.

(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ 2.
(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ In practice it is often sublinear even if |Q| log |D| is somewhat larger than |D|.
(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ As shown in Callison-Burch et al (2005), we must keep an array for the source text F , its suffix array,the target text E, and alignment A in memory.
(Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). $$$$$ Zens and Ney (2007) use a disk-based prefix tree, enabling efficient access to phrase tables much too large to fit in main memory.

 $$$$$ 984
 $$$$$ In our Python implementation this takes several minutes, which in principle should be amortized over the cost for each sentence.
 $$$$$ We close with a discussion that describes several applications of our work (?7).

The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ Otherwise, we store the results at node (1) and add its successor patterns to the frontier for the next iteration.
The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ Tight restrictions on phrase length curtail the power of phrase-basedmodels.
The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ We are cur rently investigating this option in a C reimplementation.
The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. $$$$$ aligned phrase e?

There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ SAF , the target training text E, and the align ment A into memory.
There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ Our work solves a seemingly intractable problemand opens up a number of intriguing potential ap plications.
There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ Therefore, we can use the sentence id of each subpattern occurrence as a kind of hash key.
There is also an exponential number of discontinuous substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. $$$$$ However,just as Zens and Ney (2007) do for phrase tables, we could com pile our data structures into binary memory-mapped files, whichcan be read into memory in a matter of seconds.

This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ Zens and Ney (2007) use a disk-based prefix tree, enabling efficient access to phrase tables much too large to fit in main memory.
This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ This research was supported in part by ONR MURI Contract FCPO.810548265 and the GALE program of the Defense AdvancedResearch Projects Agency, Contract No.
This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). $$$$$ We require that ? and ? con tain an equal number (possibly zero) of coindexed nonterminals.

This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ We believe that the latter approach has several important applications (?7).So far, these techniques have focused on phrase based models using contiguous phrases (Koehn et al., 2003; Och and Ney, 2004).
This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ However, for real language data the per formance for sets of any significant size will be O( ?I i=1 [|wi|+ log|T |+ ni]), since most patterns will occur once in any given sentence.
This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ Any errors are my own.
This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. $$$$$ In phrase-based models, this prob lem can be addressed by storing the training data in memory and using a suffix array asan efficient index to quickly lookup and extract rules on the fly.

In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ If the computation required to look up a phrase is expensive, we would like to performthe lookup only once.
In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ 4.2 Analysis.
In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ tence with a standard decoding algorithm.
In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). $$$$$ The algorithm is illustrated in Figure 2.
