The entity grid approach has already been applied to many applications relying on local coherence estimation $$$$$ Text structuring algorithms (Lapata, 2003; Barzilay and Lee, 2004; Karamanis et al., 2004) are commonly evaluated by their performance at information-ordering.
The entity grid approach has already been applied to many applications relying on local coherence estimation $$$$$ We plan to investigate how to combine the two for improved prediction on both local and global levels, with the ultimate goal of handling longer texts.
The entity grid approach has already been applied to many applications relying on local coherence estimation $$$$$ Our work, however, not only validates these findings, but also quantitatively measures the predictive power of various linguistic features for the task of coherence assessment.

The experimental results demonstrate that our model is able to significantly outperform the state-of the-art coherence model by Barzilay and Lapata (2005), reducing the error rate of the previous approach by an average of 29% over three data sets against human upper bounds. $$$$$ We view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function.
The experimental results demonstrate that our model is able to significantly outperform the state-of the-art coherence model by Barzilay and Lapata (2005), reducing the error rate of the previous approach by an average of 29% over three data sets against human upper bounds. $$$$$ We employed leaveone-out resampling4 (Weiss and Kulikowski, 1991), by correlating the data obtained from each participant with the mean coherence ratings obtained from all other participants.
The experimental results demonstrate that our model is able to significantly outperform the state-of the-art coherence model by Barzilay and Lapata (2005), reducing the error rate of the previous approach by an average of 29% over three data sets against human upper bounds. $$$$$ We view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function.

To further refine the computation of the subsequence distribution, we follow (Barzilay and Lapata, 2005) and divide the matrix into a salient matrix and a non-salient matrix. $$$$$ The inter-subject agreement was r = .768.
To further refine the computation of the subsequence distribution, we follow (Barzilay and Lapata, 2005) and divide the matrix into a salient matrix and a non-salient matrix. $$$$$ In both experiments, our method yields a significant improvement over a state-of-the-art coherence model based on Latent Semantic Analysis (Foltz et al., 1998).
To further refine the computation of the subsequence distribution, we follow (Barzilay and Lapata, 2005) and divide the matrix into a salient matrix and a non-salient matrix. $$$$$ These parameters were tuned separately for each data set on the corresponding held-out development set.
To further refine the computation of the subsequence distribution, we follow (Barzilay and Lapata, 2005) and divide the matrix into a salient matrix and a non-salient matrix. $$$$$ Coherence ratings were obtained during an elicitation study by 177 unpaid volunteers, all native speakers of English.

 $$$$$ In our ranking experiments, we use Joachims’ (2002a) SVMlight package for training and testing with all parameters set to their default values.
 $$$$$ Our evaluation results demonstrate the effectiveness of our entity-based ranking model within the general framework of coherence assessment.
 $$$$$ This leaves only the coreference and salience information in the model, and the results are shown in Table 4 under (Coreference+Salience).

 $$$$$ These constraints are formulated in terms offocus, the most salient entity in a discourse segment, and transition of focus between adjacent sentences.
 $$$$$ This leaves only the coreference and salience information in the model, and the results are shown in Table 4 under (Coreference+Salience).
 $$$$$ These constraints are formulated in terms offocus, the most salient entity in a discourse segment, and transition of focus between adjacent sentences.

Barzilay and Lapata (2005) showed that their entity based model is able to distinguish a source text from its permutation accurately. $$$$$ For instance, Miltsakaki and Kukich (2000) annotate a corpus of student essays with transition information, and show that the distribution of transitions correlates with human grades.
Barzilay and Lapata (2005) showed that their entity based model is able to distinguish a source text from its permutation accurately. $$$$$ We present a novel entity-based representation of discourse which is inspired by Centering Theory and can be computed automatically from raw text.
Barzilay and Lapata (2005) showed that their entity based model is able to distinguish a source text from its permutation accurately. $$$$$ We view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function.

The results on the Earthquakes and Accidents data are quite similar to those published in (Barzilay and Lapata, 2005) (they reported 83.4% on Earthquakes and 89.7% on Accidents), validating the correctness of our reimplementation of their method. $$$$$ This approach has been shown to be highly effective in various tasks ranging from collaborative filtering (Joachims, 2002a) to parsing (Toutanova et al., 2004).
The results on the Earthquakes and Accidents data are quite similar to those published in (Barzilay and Lapata, 2005) (they reported 83.4% on Earthquakes and 89.7% on Accidents), validating the correctness of our reimplementation of their method. $$$$$ We describe how it can be computed and how entity transition patterns can be extracted.
The results on the Earthquakes and Accidents data are quite similar to those published in (Barzilay and Lapata, 2005) (they reported 83.4% on Earthquakes and 89.7% on Accidents), validating the correctness of our reimplementation of their method. $$$$$ First, an automatic coreference resolution tool expectedly decreases in accuracy because it was trained on well-formed human-authored texts.
The results on the Earthquakes and Accidents data are quite similar to those published in (Barzilay and Lapata, 2005) (they reported 83.4% on Earthquakes and 89.7% on Accidents), validating the correctness of our reimplementation of their method. $$$$$ Evaluation results conclude the paper.

This result supports the use of salience, in line with the conclusion drawn in (Barzilay and Lapata, 2005). $$$$$ Without loss of generality, we assume j > k. The goal of the training procedure is to find a parameter vector w� that yields a “ranking score” function w� · d3(xij), which minimizes the number of violations of pairwise rankings provided in the training set.
This result supports the use of salience, in line with the conclusion drawn in (Barzilay and Lapata, 2005). $$$$$ Once we have identified entity classes, the next step is to fill out grid entries with relevant syntactic information.
This result supports the use of salience, in line with the conclusion drawn in (Barzilay and Lapata, 2005). $$$$$ Furthermore, coherence constraints are often embedded in complex representations (e.g., Asher and Lascarides, 2003) which are hard to implement in a robust application.
This result supports the use of salience, in line with the conclusion drawn in (Barzilay and Lapata, 2005). $$$$$ The theory also establishes constraints on the linguistic realization of focus, suggesting that it is more likely to appear in prominent syntactic positions (such as subject or object), and to be referred to with anaphoric expressions.

The entity-based model of Barzilay and Lapata (2005) connects the local entity transition with textual coherence, while our model looks at the patterns of discourse relation transitions. $$$$$ The second includes narratives from the National Transportation Safety Board’s database2.
The entity-based model of Barzilay and Lapata (2005) connects the local entity transition with textual coherence, while our model looks at the patterns of discourse relation transitions. $$$$$ Cache language models (Kuhn and Mori, 1990) seem particularly promising in this context.
The entity-based model of Barzilay and Lapata (2005) connects the local entity transition with textual coherence, while our model looks at the patterns of discourse relation transitions. $$$$$ Second, we learn patterns of entity distribution from a corpus, without attempting to directly implement or refine Centering constraints.
The entity-based model of Barzilay and Lapata (2005) connects the local entity transition with textual coherence, while our model looks at the patterns of discourse relation transitions. $$$$$ While coreference resolution improved model performance in ordering, it caused a decrease in accuracy in summary evaluation.

This intuition has been formalized by (Barzilay and Lapata, 2005), who developed an entity-based statistical representation of local discourse and showed its usefulness for estimating coherence between sentences. $$$$$ These constraints are formulated in terms offocus, the most salient entity in a discourse segment, and transition of focus between adjacent sentences.
This intuition has been formalized by (Barzilay and Lapata, 2005), who developed an entity-based statistical representation of local discourse and showed its usefulness for estimating coherence between sentences. $$$$$ The similarity between two sentences was determined by measuring the cosine of their means.
This intuition has been formalized by (Barzilay and Lapata, 2005), who developed an entity-based statistical representation of local discourse and showed its usefulness for estimating coherence between sentences. $$$$$ In this paper we proposed a novel framework for representing and measuring text coherence.

Barzilay and Lapata (2005) exploited the use of the distributional and referential information of discourse entities to improve summary coherence. $$$$$ Table 1 illustrates a fragment of an entity grid constructed for the text in Table 2.
Barzilay and Lapata (2005) exploited the use of the distributional and referential information of discourse entities to improve summary coherence. $$$$$ To employ a machine learning algorithm to our problem, we encode transition sequences explicitly using a standard feature vector notation.
Barzilay and Lapata (2005) exploited the use of the distributional and referential information of discourse entities to improve summary coherence. $$$$$ A model that exhibits high agreement with human judges not only accurately captures the coherence properties of the summaries in question, but ultimately holds promise for the automatic evaluation of machine-generated texts.

In order to evaluate the local coherence of the reports generated by the system, we employed an automatic coherence evaluation method introduced by Barzilay and Lapata (2005). $$$$$ We show that coherent texts are characterized by transitions with particular properties which do not hold for all discourses.
In order to evaluate the local coherence of the reports generated by the system, we employed an automatic coherence evaluation method introduced by Barzilay and Lapata (2005). $$$$$ We present a novel entity-based representation of discourse which is inspired by Centering Theory and can be computed automatically from raw text.
In order to evaluate the local coherence of the reports generated by the system, we employed an automatic coherence evaluation method introduced by Barzilay and Lapata (2005). $$$$$ We do not aim to produce complete centering annotations; instead, our inference procedure is based on a discourse representation that preserves essential entity transition information, and can be computed automatically from raw text.
In order to evaluate the local coherence of the reports generated by the system, we employed an automatic coherence evaluation method introduced by Barzilay and Lapata (2005). $$$$$ Central to this framework is the entity grid representation of discourse which we argue captures important patterns of sentence transitions.

Our model is inspired by Centering (Grosz et al, 1995) and other entity-based models of coherence (Barzilay and Lapata, 2005) in which an entity is in focus through a sequence of sentences. $$$$$ This leaves only the coreference and salience information in the model, and the results are shown in Table 4 under (Coreference+Salience).
Our model is inspired by Centering (Grosz et al, 1995) and other entity-based models of coherence (Barzilay and Lapata, 2005) in which an entity is in focus through a sequence of sentences. $$$$$ The theory also establishes constraints on the linguistic realization of focus, suggesting that it is more likely to appear in prominent syntactic positions (such as subject or object), and to be referred to with anaphoric expressions.

 $$$$$ In the discourse literature, entity-based theories are primarily applied at the level of local coherence, while relational models, such as Rhetorical Structure Theory (Mann and Thomson, 1988; Marcu, 2000), are used to model the global structure of discourse.
 $$$$$ We compare our algorithm against the coherence model proposed by Foltz et al. (1998) which measures coherence as a function of semantic relatedness between adjacent sentences.
 $$$$$ Participants were asked to use a seven point scale to rate how coherent the summaries were without having seen the source texts.
 $$$$$ Karamanis et al. (2004) use a similar methodology to compare coherence metrics with respect to their usefulness for text planning in generation.

We expect that features such as entity grid (Barzilay and Lapata, 2005) will improve overall algorithm performance. $$$$$ A fundamental assumption underlying our approach is that the distribution of entities in coherent texts exhibits certain regularities reflected in grid topology.
We expect that features such as entity grid (Barzilay and Lapata, 2005) will improve overall algorithm performance. $$$$$ In sum, each text was represented by a single feature, its sentence-to-sentence semantic similarity.
We expect that features such as entity grid (Barzilay and Lapata, 2005) will improve overall algorithm performance. $$$$$ Central to this framework is the entity grid representation of discourse which we argue captures important patterns of sentence transitions.
We expect that features such as entity grid (Barzilay and Lapata, 2005) will improve overall algorithm performance. $$$$$ The evaluation of our coherence model was driven by two questions: (1) How does the proposed model compare to existing methods for coherence assessment that make use of distinct representations?

We present a model for discourse coherence which combines the local entity based approach of (Barzilay and Lapata, 2005) and the HMM-based content model of (Barzilay and Lee, 2004). $$$$$ This paper considers the problem of automatic assessment of local coherence.
We present a model for discourse coherence which combines the local entity based approach of (Barzilay and Lapata, 2005) and the HMM-based content model of (Barzilay and Lee, 2004). $$$$$ The study was conducted remotely over the Internet.
We present a model for discourse coherence which combines the local entity based approach of (Barzilay and Lapata, 2005) and the HMM-based content model of (Barzilay and Lee, 2004). $$$$$ An example of a feature space with transitions of length two is illustrated in Table 3.
We present a model for discourse coherence which combines the local entity based approach of (Barzilay and Lapata, 2005) and the HMM-based content model of (Barzilay and Lee, 2004). $$$$$ An ANOVA revealed a reliable effect of summary type: F(1;15) = 20.38, p < 0.01 indicating that human summaries are perceived as significantly more coherent than system-generated ones.

As the local component of our model we adapt (Barzilay and Lapata, 2005) by relaxing independence assumptions so that it is effective when estimated generatively. $$$$$ Our results on the ordering task indicate that models that take salience information into account consistently outperform models that do not.
As the local component of our model we adapt (Barzilay and Lapata, 2005) by relaxing independence assumptions so that it is effective when estimated generatively. $$$$$ The effect of salience is less pronounced for the summarization task when it is combined with coreference information (Coreference + Salience).
As the local component of our model we adapt (Barzilay and Lapata, 2005) by relaxing independence assumptions so that it is effective when estimated generatively. $$$$$ Finally, the judgments of our participants exhibit a significant correlation with DUC evaluations (r = .41, p < 0.01).
As the local component of our model we adapt (Barzilay and Lapata, 2005) by relaxing independence assumptions so that it is effective when estimated generatively. $$$$$ Central to this framework is the entity grid representation of discourse which we argue captures important patterns of sentence transitions.

Moreover, an accurate model can reveal information about document structure, aiding in such tasks as supervised summarization (Barzilay and Lapata, 2005). $$$$$ A fundamental assumption underlying our approach is that the distribution of entities in coherent texts exhibits certain regularities reflected in grid topology.
Moreover, an accurate model can reveal information about document structure, aiding in such tasks as supervised summarization (Barzilay and Lapata, 2005). $$$$$ This drop in performance can be attributed to two factors related to the nature of our corpus — machine-generated texts.
Moreover, an accurate model can reveal information about document structure, aiding in such tasks as supervised summarization (Barzilay and Lapata, 2005). $$$$$ An overall text coherence measure was obtained by averaging the cosines for all pairs of adjacent sentences.

Barzilay and Lapata (2005) uses the same grid representation, but treats the transition probabilities P (ri, j $$$$$ In this paper we proposed a novel framework for representing and measuring text coherence.
Barzilay and Lapata (2005) uses the same grid representation, but treats the transition probabilities P (ri, j $$$$$ We argue that this representation of discourse allows the system to learn the properties of locally coherent texts opportunistically from a given corpus, without recourse to manual annotation or a predefined knowledge base.
Barzilay and Lapata (2005) uses the same grid representation, but treats the transition probabilities P (ri, j $$$$$ Second, we compare the rankings produced by the model against human coherence judgments elicited for automatically generated summaries.

 $$$$$ Second, we compare the rankings produced by the model against human coherence judgments elicited for automatically generated summaries.
 $$$$$ Karamanis et al. (2004) use a similar methodology to compare coherence metrics with respect to their usefulness for text planning in generation.
 $$$$$ For instance, Miltsakaki and Kukich (2000) annotate a corpus of student essays with transition information, and show that the distribution of transitions correlates with human grades.
