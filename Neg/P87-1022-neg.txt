 $$$$$ The algorithm has been implemented in an HPSG natural language system which serves as the interface to a database query application.
 $$$$$ The proposed anchors represent all the cospecification relationships available for this utterance.
 $$$$$ This illustrates the extension in the same detail as the example we used in the algorithm.

 $$$$$ EXAMPLE: She often beats her.
 $$$$$ However, structural parallelism is a consequence of our ordering the Cf list by grammatical function and the preference for continuing over retaining.
 $$$$$ This illustrates the extension in the same detail as the example we used in the algorithm.

Centering models local coherence rather generally and has been applied to the generation of referring expressions (Kibble and Power, 2004), to resolve pronouns (Brennan et al, 1987, inter alia), to score essays (Miltsakaki and Kukich, 2004), to arrange sentences in the correct order (Karamanis et al, 2009), and to many other tasks. $$$$$ This example is characterized by its multiple ambiguous pronouns and by the fact that the final utterance achieves a shift (see figure 4).
Centering models local coherence rather generally and has been applied to the generation of referring expressions (Kibble and Power, 2004), to resolve pronouns (Brennan et al, 1987, inter alia), to score essays (Miltsakaki and Kukich, 2004), to arrange sentences in the correct order (Karamanis et al, 2009), and to many other tasks. $$$$$ EXAMPLE: She often beats her.
Centering models local coherence rather generally and has been applied to the generation of referring expressions (Kibble and Power, 2004), to resolve pronouns (Brennan et al, 1987, inter alia), to score essays (Miltsakaki and Kukich, 2004), to arrange sentences in the correct order (Karamanis et al, 2009), and to many other tasks. $$$$$ She drives too fast.

To our knowledge, there are only two focus-based pronoun resolution algorithms that are specified in enough detail to work on unrestricted naturally occurring text $$$$$ Anchors i, iv, v, viii, ix, xii, xiii, xvi are eliminated since [A9] and [A10] are contraindexed.
To our knowledge, there are only two focus-based pronoun resolution algorithms that are specified in enough detail to work on unrestricted naturally occurring text $$$$$ Indices for indefinites are generated from X1, .. â€¢
To our knowledge, there are only two focus-based pronoun resolution algorithms that are specified in enough detail to work on unrestricted naturally occurring text $$$$$ The example is the last utterance from figure 4.

In Section 4, I compare the results of my algorithm with the results of the centering algorithm (Brennan et al, 1987) with and without specifications for complex sentences (Kameyama, 1998). $$$$$ The typology of transitions is based on two factors: whether or not the center of attention, Cb, is the same from Un_1 to Un, and whether or not this entity coincides with the preferred center of Un.
In Section 4, I compare the results of my algorithm with the results of the centering algorithm (Brennan et al, 1987) with and without specifications for complex sentences (Kameyama, 1998). $$$$$ The proposed anchors represent all the cospecification relationships available for this utterance.

For their centering algorithm, Brennan et al (1987, henceforth BFP-algorithm) extend the notion of centering transition relations, which hold across adjacent utterances, to differentiate types of shift. $$$$$ This illustrates the extension in the same detail as the example we used in the algorithm.
For their centering algorithm, Brennan et al (1987, henceforth BFP-algorithm) extend the notion of centering transition relations, which hold across adjacent utterances, to differentiate types of shift. $$$$$ (a) Filter by contraindices.
For their centering algorithm, Brennan et al (1987, henceforth BFP-algorithm) extend the notion of centering transition relations, which hold across adjacent utterances, to differentiate types of shift. $$$$$ Note that the three items being examined in order to characterize the transition between each pair of anchor?' are the

To illustrate this algorithm, we consider example (1) (Brennan et al, 1987) which has two different final utterances (ld) and (ld~). $$$$$ In addition, languages that provide an identifiable topic function (e.g.
To illustrate this algorithm, we consider example (1) (Brennan et al, 1987) which has two different final utterances (ld) and (ld~). $$$$$ The goal of the current algorithm design was conceptual clarity rather than efficiency.

Table 1 shows the most common classification into the four types CONTINUE, RETAIN, SMOOTH-SHIFT, and ROUGH-SHIFT, which are predicted to be less and less coherent in this order (Brennan et al, 1987). $$$$$ A computational system for generation would try to plan a retention as a signal of an impending shift, so that after a retention, a shift would be preferred rather than a continuation.
Table 1 shows the most common classification into the four types CONTINUE, RETAIN, SMOOTH-SHIFT, and ROUGH-SHIFT, which are predicted to be less and less coherent in this order (Brennan et al, 1987). $$$$$ (a) Filter by contraindices.
Table 1 shows the most common classification into the four types CONTINUE, RETAIN, SMOOTH-SHIFT, and ROUGH-SHIFT, which are predicted to be less and less coherent in this order (Brennan et al, 1987). $$$$$ This definition of shifting does not consider whether the Cb of Un and the Cp of Un are equal.

Finally, the measure M.BFP (Brennan et al, 1987) uses a lexicographic ordering on 4-tupleswhich indicate whether the transition is a CONTINUE, RETAIN, SMOOTH-SHIFT, or ROUGH SHIFT. $$$$$ The example we use to illustrate the algorithm is in figure 2.
Finally, the measure M.BFP (Brennan et al, 1987) uses a lexicographic ordering on 4-tupleswhich indicate whether the transition is a CONTINUE, RETAIN, SMOOTH-SHIFT, or ROUGH SHIFT. $$$$$ The part of the HPSG system that uses the centering algorithm for pronoun binding is called the pragmatics processor.
Finally, the measure M.BFP (Brennan et al, 1987) uses a lexicographic ordering on 4-tupleswhich indicate whether the transition is a CONTINUE, RETAIN, SMOOTH-SHIFT, or ROUGH SHIFT. $$$$$ Many of our informants have no strong preference as to the co-specification of the unstressed &quot;She&quot; in Un+4.
Finally, the measure M.BFP (Brennan et al, 1987) uses a lexicographic ordering on 4-tupleswhich indicate whether the transition is a CONTINUE, RETAIN, SMOOTH-SHIFT, or ROUGH SHIFT. $$$$$ (a) Filter by contraindices.

Note that common centering algorithms (e.g., the one by Brennan et al (1987)) are specified only for the resolution of anaphors in Ui-1. $$$$$ The example is the last utterance from figure 4.
Note that common centering algorithms (e.g., the one by Brennan et al (1987)) are specified only for the resolution of anaphors in Ui-1. $$$$$ The numbering here corresponds to the numbered steps in the algorithm figure 7.
Note that common centering algorithms (e.g., the one by Brennan et al (1987)) are specified only for the resolution of anaphors in Ui-1. $$$$$ The numbering here corresponds to the numbered steps in the algorithm figure 7.

The rules are applied locally, across adjacent sequences of utterances (Brennan et al., 1987). $$$$$ It would be possible to classify and rank the proposed anchors before filtering them without any other changes to the algorithm.
The rules are applied locally, across adjacent sequences of utterances (Brennan et al., 1987). $$$$$ Even though [A4] and [A5] are contraindexed we have not proposed the same co-specifier due to agreement.
The rules are applied locally, across adjacent sequences of utterances (Brennan et al., 1987). $$$$$ How should the centering algorithm interact with an inferencing mechanism?

The ranking of the CFs other than the CP is defined according to the following preference on their gf (Brennan et al, 1987) $$$$$ Each step is discussed and illustrated in figure 7.
The ranking of the CFs other than the CP is defined according to the following preference on their gf (Brennan et al, 1987) $$$$$ The semantics processor has access to information such as the surface syntactic structure of the utterance.
The ranking of the CFs other than the CP is defined according to the following preference on their gf (Brennan et al, 1987) $$$$$ As described in [GJW86], the process of centering attention on entities in the discourse gives rise to the intersentential states of, retaining shiftpropose an extension to these states which handles some additional cases of multiple ambiguous pronouns.

We also make note of the preference between these transitions, known as Centering Rule 2 (Brennan et al, 1987). $$$$$ The example is the last utterance from figure 4.
We also make note of the preference between these transitions, known as Centering Rule 2 (Brennan et al, 1987). $$$$$ EXAMPLE: She often beats her.
We also make note of the preference between these transitions, known as Centering Rule 2 (Brennan et al, 1987). $$$$$ In this paper we present a formalization of the centering approach to modeling attentional structure in discourse and use it as the basis for an algorithm to track discourse context and bind pronouns.
We also make note of the preference between these transitions, known as Centering Rule 2 (Brennan et al, 1987). $$$$$ Anchors i, iv, v, viii, ix, xii, xiii, xvi are eliminated since [A9] and [A10] are contraindexed.

The main assumptions of the theory as presented by (Gross et al 1995 (GJW), Brennan et al1987). $$$$$ EXAMPLE: She often beats her.
The main assumptions of the theory as presented by (Gross et al 1995 (GJW), Brennan et al1987). $$$$$ She drives too fast.
The main assumptions of the theory as presented by (Gross et al 1995 (GJW), Brennan et al1987). $$$$$ The three filters in the filtering phase may be done in parallel.

For instance Passoneau (1998) refers to two variants of CT $$$$$ In a database query system, how should answers be incorporated into the discourse model?
For instance Passoneau (1998) refers to two variants of CT $$$$$ By [GJW86] a shift occurs whenever successive Cb's are not the same.
For instance Passoneau (1998) refers to two variants of CT $$$$$ Anchors i, iv, v, viii, ix, xii, xiii, xvi are eliminated since [A9] and [A10] are contraindexed.

The first strategy is clearly appropriate for interpretation (cf. Brennan et al 1987) but for generation the issue is less clear-cut. $$$$$ How does centering interact with a treatment of definite/indefinite NP's and quantifiers?
The first strategy is clearly appropriate for interpretation (cf. Brennan et al 1987) but for generation the issue is less clear-cut. $$$$$ A transition for Un is ranked more highly if Cb(Un) = CP(U); this state we call shifting-1 and it represents a more coherent way to shift.
The first strategy is clearly appropriate for interpretation (cf. Brennan et al 1987) but for generation the issue is less clear-cut. $$$$$ Thus when the proposed anchors are constructed there is no possibility of having an infinite number of potential Cf's for an utterance of finite length.

Brennan et al [1987] propose an algorithm for pronoun resolution based on centering theory. $$$$$ Even though [A4] and [A5] are contraindexed we have not proposed the same co-specifier due to agreement.
Brennan et al [1987] propose an algorithm for pronoun resolution based on centering theory. $$$$$ This definition of shifting does not consider whether the Cb of Un and the Cp of Un are equal.
Brennan et al [1987] propose an algorithm for pronoun resolution based on centering theory. $$$$$ First the proposed anchors are constructed, then they are filtered, and finally, they are classified and ranked.
Brennan et al [1987] propose an algorithm for pronoun resolution based on centering theory. $$$$$ This filter doesn't eliminate any of the proposed anchors.

The latter proposes the ranking subject, direct object, indirect object (Brennan et al 1987) and noun phrases which are parts of prepositional phrases are usually indirect objects. $$$$$ However, structural parallelism is a consequence of our ordering the Cf list by grammatical function and the preference for continuing over retaining.
The latter proposes the ranking subject, direct object, indirect object (Brennan et al 1987) and noun phrases which are parts of prepositional phrases are usually indirect objects. $$$$$ The [G3W86] centering model is based on the following assumptions.

Hard-core centering approaches only deal with the last sentence (Brennan et al, 1987). $$$$$ Speakers can avoid ambiguity by stressing a pronoun with respect to its phonological environment.
Hard-core centering approaches only deal with the last sentence (Brennan et al, 1987). $$$$$ The example is the last utterance from figure 4.
Hard-core centering approaches only deal with the last sentence (Brennan et al, 1987). $$$$$ However the constraints and rules from [GJW86] would fail to make a choice here between the co-specification possibilities for the pronouns in Un.

PF.BFP which is based on PF as well as the original formulation of CT in [Brennan et al, 1987]. $$$$$ The three filters in the filtering phase may be done in parallel.
PF.BFP which is based on PF as well as the original formulation of CT in [Brennan et al, 1987]. $$$$$ The proposed Cb was realized as a pronoun.
PF.BFP which is based on PF as well as the original formulation of CT in [Brennan et al, 1987]. $$$$$ First the proposed anchors are constructed, then they are filtered, and finally, they are classified and ranked.
PF.BFP which is based on PF as well as the original formulation of CT in [Brennan et al, 1987]. $$$$$ In this paper we present a formalization of the centering approach to modeling attentional structure in discourse and use it as the basis for an algorithm to track discourse context and bind pronouns.
