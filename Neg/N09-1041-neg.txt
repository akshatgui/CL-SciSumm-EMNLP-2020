In TOPICSUM (Haghighi and Vanderwende, 2009), each word is generated by a single topic which can be a corpus-wide background distribution over common words, a distribution of document-specific words or a distribution of the core content of a given cluster. $$$$$ We present an exploration of generative probabilistic models for multi-document summarization.
In TOPICSUM (Haghighi and Vanderwende, 2009), each word is generated by a single topic which can be a corpus-wide background distribution over common words, a distribution of document-specific words or a distribution of the core content of a given cluster. $$$$$ However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.
In TOPICSUM (Haghighi and Vanderwende, 2009), each word is generated by a single topic which can be a corpus-wide background distribution over common words, a distribution of document-specific words or a distribution of the core content of a given cluster. $$$$$ However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.

Models that use more structure in the representation of documents have also been proposed for generating more coherent and less redundant summaries, such as HIERSUM (Haghighi and Vanderwende, 2009) and TTM (Celikyilmaz and Hakkani-Tur, 2011). $$$$$ These parameters were minimally tuned (without reference to ROUGE results) in order to ensure that all topic distribution behaved as intended.
Models that use more structure in the representation of documents have also been proposed for generating more coherent and less redundant summaries, such as HIERSUM (Haghighi and Vanderwende, 2009) and TTM (Celikyilmaz and Hakkani-Tur, 2011). $$$$$ (3) Coherence: Which summary was more coherent?
Models that use more structure in the representation of documents have also been proposed for generating more coherent and less redundant summaries, such as HIERSUM (Haghighi and Vanderwende, 2009) and TTM (Celikyilmaz and Hakkani-Tur, 2011). $$$$$ Acknowledgements The authors would like to thank Bob Moore, Chris Brockett, Chris Quirk, and Kristina Toutanova for their useful discussions as well as the reviewers for their helpful comments.

In our experiments, we follow the same approach as in (Haghighi and Vanderwende, 2009) by greedily adding sentences to a summary so long as they decrease KL divergence. $$$$$ (2) Non-Redundancy: Which summary was less redundant?
In our experiments, we follow the same approach as in (Haghighi and Vanderwende, 2009) by greedily adding sentences to a summary so long as they decrease KL divergence. $$$$$ In particular, we utilize a variation of the hierarchical LDA topic model (Blei et al., 2004) to discover multiple specific ‘subtopics’ within a document set.
In our experiments, we follow the same approach as in (Haghighi and Vanderwende, 2009) by greedily adding sentences to a summary so long as they decrease KL divergence. $$$$$ Acknowledgements The authors would like to thank Bob Moore, Chris Brockett, Chris Quirk, and Kristina Toutanova for their useful discussions as well as the reviewers for their helpful comments.
In our experiments, we follow the same approach as in (Haghighi and Vanderwende, 2009) by greedily adding sentences to a summary so long as they decrease KL divergence. $$$$$ Concrete pseudo-count values will be given in section 4.

Once this is done, one of the learned collections can be used to generate the summary that best approximates this collection, using the greedy algorithm described by Haghighiand Vanderwende (2009). $$$$$ All topic models utilize Gibbs sampling for inference (Griffiths, 2002; Blei et al., 2004).
Once this is done, one of the learned collections can be used to generate the summary that best approximates this collection, using the greedy algorithm described by Haghighiand Vanderwende (2009). $$$$$ The task we will consider is extractive multidocument summarization.
Once this is done, one of the learned collections can be used to generate the summary that best approximates this collection, using the greedy algorithm described by Haghighiand Vanderwende (2009). $$$$$ In order to put HIERSUM and PYTHY on equalfooting with respect to R-2, we instead ran HIERSUM with each sentence consisting of a bag of bigrams instead of unigrams.24 All the details of the model remain the same.

The original implementations of SUMBASIC (Nenkova and Vanderwende, 2005) and TOPICSUM (Haghighiand Vanderwende, 2009) were defined over single words (unigrams). $$$$$ However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.
The original implementations of SUMBASIC (Nenkova and Vanderwende, 2005) and TOPICSUM (Haghighiand Vanderwende, 2009) were defined over single words (unigrams). $$$$$ In this paper we have presented an exploration of content models for multi-document summarization and demonstrated that the use of structured topic models can benefit summarization quality as measured by automatic and manual metrics.
The original implementations of SUMBASIC (Nenkova and Vanderwende, 2005) and TOPICSUM (Haghighiand Vanderwende, 2009) were defined over single words (unigrams). $$$$$ Our task will be to propose a summary S consisting of sentences in D totaling at most L words.3 Here as in much extractive summarization, we will view each sentence as a bag-of-words or more generally a bag-of-ngrams (see section 5.1).
The original implementations of SUMBASIC (Nenkova and Vanderwende, 2005) and TOPICSUM (Haghighiand Vanderwende, 2009) were defined over single words (unigrams). $$$$$ However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.

This model is very similar to the one used by Haghighi and Vanderwende (2009) in the context of text summarization. $$$$$ Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way.
This model is very similar to the one used by Haghighi and Vanderwende (2009) in the context of text summarization. $$$$$ In the common Document Understanding Conference (DUC) formulation of the task, a system takes as input a document set as well as a short description of desired summary focus and outputs a word length limited summary.1 To avoid the problem of generating cogent sentences, many systems opt for an extractive approach, selecting sentences from the document set which best reflect its core content.2 There are several approaches to modeling document content: simple word frequency-based methods (Luhn, 1958; Nenkova and Vanderwende, 2005), graph-based approaches (Radev, 2004; Wan and Yang, 2006), as well as more linguistically motivated techniques (Mckeown et al., 1999; Leskovec et al., 2005; Harabagiu et al., 2007).
This model is very similar to the one used by Haghighi and Vanderwende (2009) in the context of text summarization. $$$$$ First, we describe our topic model (see figure 1) which generates a collection of document sets.
This model is very similar to the one used by Haghighi and Vanderwende (2009) in the context of text summarization. $$$$$ A common concern in multi-document summarization is that without any indication of user interest or intent providing a single satisfactory summary to a user may not be feasible.

Effective ways of representing content and ensuring coverage are the subject of ongoing research in the field (e.g., Gillick et al 2009, Haghighi and Vanderwende 2009). $$$$$ The resulting model, HIERSUM (see section 3.4), can produce general summaries as well as summaries for any of the learned sub-topics.
Effective ways of representing content and ensuring coverage are the subject of ongoing research in the field (e.g., Gillick et al 2009, Haghighi and Vanderwende 2009). $$$$$ All summary sentence ordering was determined as follows: each sentence in the proposed summary was assigned a number in [0, 1] reflecting its relative sentence position in its source document, and sorted by this quantity.
Effective ways of representing content and ensuring coverage are the subject of ongoing research in the field (e.g., Gillick et al 2009, Haghighi and Vanderwende 2009). $$$$$ These parameters were minimally tuned (without reference to ROUGE results) in order to ensure that all topic distribution behaved as intended.
Effective ways of representing content and ensuring coverage are the subject of ongoing research in the field (e.g., Gillick et al 2009, Haghighi and Vanderwende 2009). $$$$$ Official DUC scoring utilizes the jackknife procedure and assesses significance using bootstrapping resampling (Lin, 2004).

The most relevant work is by (Haghighi and Vanderwende, 2009) on exploring content models for multi-document summarization. $$$$$ We present an exploration of generative probabilistic models for multi-document summarization.
The most relevant work is by (Haghighi and Vanderwende, 2009) on exploring content models for multi-document summarization. $$$$$ Acknowledgements The authors would like to thank Bob Moore, Chris Brockett, Chris Quirk, and Kristina Toutanova for their useful discussions as well as the reviewers for their helpful comments.
The most relevant work is by (Haghighi and Vanderwende, 2009) on exploring content models for multi-document summarization. $$$$$ Our model, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions.

Entity-aspect model is similar with 'HIERSUM' content model proposed by Haghighi and Vanderwende (2009). $$$$$ Rather than drawing a single CONTENT distribution 0C for a document collection, we now draw a general content distribution 0C0 from DIRICHLET(V,AG) as well as specific content distributions 0Ci for i = 1, ... , K each from DIRICHLET(V,AS).18 Our intent is that 0C0 represents the 18We choose K=3 in our experiments, but one could flexibly general content of the document collection and each 0Ci represents specific sub-stories.
Entity-aspect model is similar with 'HIERSUM' content model proposed by Haghighi and Vanderwende (2009). $$$$$ The reason for this might be that PYTHY is discriminatively trained to maximize ROUGE which does not directly penalize redundancy.
Entity-aspect model is similar with 'HIERSUM' content model proposed by Haghighi and Vanderwende (2009). $$$$$ Our model, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions.
Entity-aspect model is similar with 'HIERSUM' content model proposed by Haghighi and Vanderwende (2009). $$$$$ We also contend that they provide convenient building blocks for adding more structure to a summarization model.

In this baseline, we directly compare our method with "HIERSUM" proposed by (Haghighi and Vanderwende, 2009). $$$$$ However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.
In this baseline, we directly compare our method with "HIERSUM" proposed by (Haghighi and Vanderwende, 2009). $$$$$ Despite its simplicity, SUMBASIC yields 5.3 R-2 without stop words on DUC 2006 (see table 1).8 By comparison, the highest-performing ROUGE system at the DUC 2006 evaluation, SUMFOCUS, was built on top of SUMBASIC and yielded a 6.0, which is not a statistically significant improvement (Vanderwende et al., 2007).9 Intuitively, SUMBASIC is trying to select a summary which has sentences where most words have high likelihood under the document set unigram distribution.
In this baseline, we directly compare our method with "HIERSUM" proposed by (Haghighi and Vanderwende, 2009). $$$$$ We explore capacity to produce multiple ‘topical summaries’ in order to facilitate content discovery and navigation.
In this baseline, we directly compare our method with "HIERSUM" proposed by (Haghighi and Vanderwende, 2009). $$$$$ However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.

One could also think of this as a version of the KLSum summarization system (Haghighi and Vanderwende, 2009) that stops after one sentence. $$$$$ Ideally, a summarization criterion should be more recall oriented, penalizing summaries which omit moderately frequent document set words and quickly diminishing the reward for repeated use of word.
One could also think of this as a version of the KLSum summarization system (Haghighi and Vanderwende, 2009) that stops after one sentence. $$$$$ We present an exploration of generative probabilistic models for multi-document summarization.
One could also think of this as a version of the KLSum summarization system (Haghighi and Vanderwende, 2009) that stops after one sentence. $$$$$ Another strand of work (Barzilay and Lee, 2004; Daum´e III and Marcu, 2006; Eisenstein and Barzilay, 2008), has explored the use of structured probabilistic topic models to represent document content.

In more recent work, Haghighi and Vanderwende (2009) built a summarization system based on topic models, where both topics at general document level as well as those at specific subtopic levels were learnt. $$$$$ The most prevalent example of this data setting is document clusters found on news aggregator sites.
In more recent work, Haghighi and Vanderwende (2009) built a summarization system based on topic models, where both topics at general document level as well as those at specific subtopic levels were learnt. $$$$$ The task we will consider is extractive multidocument summarization.
In more recent work, Haghighi and Vanderwende (2009) built a summarization system based on topic models, where both topics at general document level as well as those at specific subtopic levels were learnt. $$$$$ The task we will consider is extractive multidocument summarization.

Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008). $$$$$ The task we will consider is extractive multidocument summarization.
Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008). $$$$$ Another strand of work (Barzilay and Lee, 2004; Daum´e III and Marcu, 2006; Eisenstein and Barzilay, 2008), has explored the use of structured probabilistic topic models to represent document content.
Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008). $$$$$ However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.

The following models are used as benchmark $$$$$ In this task we assume a document collection D consisting of documents Di, ... , D,,, describing the same (or closely related) narrative (Lapata, 2003). set of events.
The following models are used as benchmark $$$$$ Another tendency is for HIERSUM to select longer sentences typically chosen from an early sentence in a document.
The following models are used as benchmark $$$$$ We present a progression of models for multidocument summarization.
The following models are used as benchmark $$$$$ For each sentence S of each document D, draw a distribution ψT over topics (CONTENT, DOCSPECIFIC, BACKGROUND) from a Dirichlet prior with pseudo-counts (1.0, 5.0,10.0).14 For each word position in the sentence, we draw a topic Z from ψT, and a word W from the topic distribution Z indicates.

Haghighi and Vanderwende (2009) demonstrated that these models can improve the quality of generic multi-document summaries over simpler surface models. $$$$$ 13DIRICHLET(V,A) represents the symmetric Dirichlet prior distribution over V each with a pseudo-count of A.
Haghighi and Vanderwende (2009) demonstrated that these models can improve the quality of generic multi-document summaries over simpler surface models. $$$$$ For each document set in the DUC 2007 collection, a user was given a reference summary, a PYTHY summary, and a HIERSUM summary;25 note that the original documents in the set were not provided to the user, only a reference summary.
Haghighi and Vanderwende (2009) demonstrated that these models can improve the quality of generic multi-document summaries over simpler surface models. $$$$$ We present R-2 without stop words in the running text, but full development results are presented in table 1.

We re-implement the HIERSUM system from Haghighi and Vanderwende (2009), and show that using our objective dramatically improves the content of extracted summaries. $$$$$ Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way.
We re-implement the HIERSUM system from Haghighi and Vanderwende (2009), and show that using our objective dramatically improves the content of extracted summaries. $$$$$ HIERSUM can be used to extract several kinds of summaries.
We re-implement the HIERSUM system from Haghighi and Vanderwende (2009), and show that using our objective dramatically improves the content of extracted summaries. $$$$$ Another strand of work (Barzilay and Lee, 2004; Daum´e III and Marcu, 2006; Eisenstein and Barzilay, 2008), has explored the use of structured probabilistic topic models to represent document content.
We re-implement the HIERSUM system from Haghighi and Vanderwende (2009), and show that using our objective dramatically improves the content of extracted summaries. $$$$$ All summary sentence ordering was determined as follows: each sentence in the proposed summary was assigned a number in [0, 1] reflecting its relative sentence position in its source document, and sorted by this quantity.

This idea was first presented by Daume and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by Haghighi and Vanderwende (2009). $$$$$ Acknowledgements The authors would like to thank Bob Moore, Chris Brockett, Chris Quirk, and Kristina Toutanova for their useful discussions as well as the reviewers for their helpful comments.
This idea was first presented by Daume and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by Haghighi and Vanderwende (2009). $$$$$ In the common Document Understanding Conference (DUC) formulation of the task, a system takes as input a document set as well as a short description of desired summary focus and outputs a word length limited summary.1 To avoid the problem of generating cogent sentences, many systems opt for an extractive approach, selecting sentences from the document set which best reflect its core content.2 There are several approaches to modeling document content: simple word frequency-based methods (Luhn, 1958; Nenkova and Vanderwende, 2005), graph-based approaches (Radev, 2004; Wan and Yang, 2006), as well as more linguistically motivated techniques (Mckeown et al., 1999; Leskovec et al., 2005; Harabagiu et al., 2007).
This idea was first presented by Daume and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by Haghighi and Vanderwende (2009). $$$$$ Our model, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions.
This idea was first presented by Daume and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by Haghighi and Vanderwende (2009). $$$$$ As mentioned in section 3.2, the raw unigram distribution PD(·) may not best reflect the content of D for the purpose of summary extraction.

Haghighi and Vanderwende (2009) presented a version of HIERSUM that models documents as a bag of bigrams, and provides results comparable to PYTHY. $$$$$ In order to obtain a more accurate measure of summary quality, we performed a simple user study.
Haghighi and Vanderwende (2009) presented a version of HIERSUM that models documents as a bag of bigrams, and provides results comparable to PYTHY. $$$$$ In this paper we have presented an exploration of content models for multi-document summarization and demonstrated that the use of structured topic models can benefit summarization quality as measured by automatic and manual metrics.
Haghighi and Vanderwende (2009) presented a version of HIERSUM that models documents as a bag of bigrams, and provides results comparable to PYTHY. $$$$$ We present an exploration of generative probabilistic models for multi-document summarization.

These are based on the manual evaluation questions from DUC 2007, and are the same questions asked in Haghighi and Vanderwende (2009). $$$$$ In particular, we utilize R-1 (recall against unigrams), R-2 (recall against bigrams), and R-SU4 (recall against skip-4 bigrams)6.
These are based on the manual evaluation questions from DUC 2007, and are the same questions asked in Haghighi and Vanderwende (2009). $$$$$ The reference summary for each document set was selected according to highest R-2 without stop words against the remaining peer summaries.
These are based on the manual evaluation questions from DUC 2007, and are the same questions asked in Haghighi and Vanderwende (2009). $$$$$ The resulting model, HIERSUM (see section 3.4), can produce general summaries as well as summaries for any of the learned sub-topics.

Such models also provide a framework for adding additional structure to a summarization model (Haghighi and Vanderwende, 2009). $$$$$ Automated evaluation will utilize the standard DUC evaluation metric ROUGE (Lin, 2004) which represents recall over various n-grams statistics from a system-generated summary against a set of humangenerated peer summaries.5 We compute ROUGE scores with and without stop words removed from peer and proposed summaries.
Such models also provide a framework for adding additional structure to a summarization model (Haghighi and Vanderwende, 2009). $$$$$ Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way.
Such models also provide a framework for adding additional structure to a summarization model (Haghighi and Vanderwende, 2009). $$$$$ On the whole, HIERSUM summaries appear to be significantly less redundant than PYTHY and moderately less redundant than SUMBASIC.
Such models also provide a framework for adding additional structure to a summarization model (Haghighi and Vanderwende, 2009). $$$$$ These parameters were minimally tuned (without reference to ROUGE results) in order to ensure that all topic distribution behaved as intended.
