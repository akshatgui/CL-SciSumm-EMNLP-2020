Subsequently, we replicated Gildea's experiment with a complete emulation of Model 2 and presented additional evidence that bilexical statistics were barely getting used during decoding (Bikel, 2004), appearing to confirm the original result. $$$$$ In such cases, the chart item will contain a back pointer to the chart item that represents the base NP.
Subsequently, we replicated Gildea's experiment with a complete emulation of Model 2 and presented additional evidence that bilexical statistics were barely getting used during decoding (Bikel, 2004), appearing to confirm the original result. $$$$$ We also show a cleaner and equally well-performing method for the handling of punctuation and conjunction and reveal certain other probabilistic oddities about Collins’ parser.
Subsequently, we replicated Gildea's experiment with a complete emulation of Model 2 and presented additional evidence that bilexical statistics were barely getting used during decoding (Bikel, 2004), appearing to confirm the original result. $$$$$ For example, Gildea (2001) reimplemented Collins’ Model 1 but obtained results with roughly 16.7% more relative error than Collins’ reported results using that model.
Subsequently, we replicated Gildea's experiment with a complete emulation of Model 2 and presented additional evidence that bilexical statistics were barely getting used during decoding (Bikel, 2004), appearing to confirm the original result. $$$$$ This is especially true in an area like statistical parsing that has seen rapid maturation followed by a soft “plateau” in performance.

Subsequently, we duplicated Gildea's experiment with a complete emulation of Collins' Model 2, and found that when the decoder requested a smoothed estimate involving a bigram when testing on held-out data, it only received an estimate that made use of bilexical statistics a mere 1.49% of the time (Bikel, 2004). $$$$$ The final form of pruning employed is rather subtle: Within each cell of the chart that contains items covering some span of the sentence, Collins’ parser uses buckets of items that share the same root nonterminal label for their respective derivations.
Subsequently, we duplicated Gildea's experiment with a complete emulation of Collins' Model 2, and found that when the decoder requested a smoothed estimate involving a bigram when testing on held-out data, it only received an estimate that made use of bilexical statistics a mere 1.49% of the time (Bikel, 2004). $$$$$ Finally, we perform experiments that show that the true discriminative power of lexicalization appears to lie in the fact that unlexicalized syntactic structures are generated conditioning on the headword and its part of speech.
Subsequently, we duplicated Gildea's experiment with a complete emulation of Collins' Model 2, and found that when the decoder requested a smoothed estimate involving a bigram when testing on held-out data, it only received an estimate that made use of bilexical statistics a mere 1.49% of the time (Bikel, 2004). $$$$$ We call this constant the smoothing factor and denote it as ff.
Subsequently, we duplicated Gildea's experiment with a complete emulation of Collins' Model 2, and found that when the decoder requested a smoothed estimate involving a bigram when testing on held-out data, it only received an estimate that made use of bilexical statistics a mere 1.49% of the time (Bikel, 2004). $$$$$ These results regarding the lack of reliance on bilexical statistics suggest that generative models still have room for improvement through the employment of bilexical-class statistics, that is, dependencies among head-modifier word classes, where such classes may be defined by, say, WordNet synsets.

The results of (Bikel, 2004) suggested that the power of Collins-style parsing models did not lie primarily with the use of bilexical dependencies as was once thought, but in lexico-structural dependencies, that is, predicting syntactic structures conditioning on head words. $$$$$ We have documented what we believe is the complete set of heretofore unpublished details Collins used in his parser, such that, along with Collins’ (1999) thesis, thi s article contains all information necessary to duplicate Collins’ benchmark results.
The results of (Bikel, 2004) suggested that the power of Collins-style parsing models did not lie primarily with the use of bilexical dependencies as was once thought, but in lexico-structural dependencies, that is, predicting syntactic structures conditioning on head words. $$$$$ These results regarding the lack of reliance on bilexical statistics suggest that generative models still have room for improvement through the employment of bilexical-class statistics, that is, dependencies among head-modifier word classes, where such classes may be defined by, say, WordNet synsets.
The results of (Bikel, 2004) suggested that the power of Collins-style parsing models did not lie primarily with the use of bilexical dependencies as was once thought, but in lexico-structural dependencies, that is, predicting syntactic structures conditioning on head words. $$$$$ Recently, in order to continue our work combining word sense with parsing (Bikel 2000) and the study of language-dependent and -independent parsing features (Bikel and Chiang 2000), we built a multilingual parsing engine that is capable of instantiating a wide variety of generative statistical parsing models (Bikel 2002).1 As an appropriate baseline model, we chose to instantiate the parameters of Collins’ Model 2.

Furthermore, the work in this paper relates to Bikel (2004)'s work. $$$$$ As for effects involving dependence on the head tag th, observe that moving from Model Mtw,t to Model Mtw,φ results in a small drop in both recall and precision, whereas making an analogous move from Model Mt,t to Model Mt,φ results in a drop in recall, but a slight gain in precision (the two moves are analogous in that in both cases, th is dropped from the context of PMw).
Furthermore, the work in this paper relates to Bikel (2004)'s work. $$$$$ Many thanks to David Chiang and Dan Gildea for the many valuable discussions during the course of this work.
Furthermore, the work in this paper relates to Bikel (2004)'s work. $$$$$ Head-children are not exempt from being relabeled as arguments.

For Chinese, we experimented on the Penn Chinese Treebank 4.0 (CTB4) (Palmer et al, 2004) and we used the rules in (Bikel, 2004) for conversion. $$$$$ Together, PM and PMw generate a fully lexicalized modifying nonterminal.
For Chinese, we experimented on the Penn Chinese Treebank 4.0 (CTB4) (Palmer et al, 2004) and we used the rules in (Bikel, 2004) for conversion. $$$$$ In other words, to get the head label of an NP chart item, one must “peek through” the NPB and get at the NPB’s head label.
For Chinese, we experimented on the Penn Chinese Treebank 4.0 (CTB4) (Palmer et al, 2004) and we used the rules in (Bikel, 2004) for conversion. $$$$$ N66001-00-1-8915.
For Chinese, we experimented on the Penn Chinese Treebank 4.0 (CTB4) (Palmer et al, 2004) and we used the rules in (Bikel, 2004) for conversion. $$$$$ We also show a cleaner and equally well-performing method for the handling of punctuation and conjunction and reveal certain other probabilistic oddities about Collins’ parser.

They were then parsed using Bikel's parser (Bikel,2004) and corrected by hand using the Penn Tree bank Bracketing Guidelines (Bies et al, 1995). $$$$$ Accordingly, if a comma in an input Overall parsing results using only details found in Collins (1997, 1999).
They were then parsed using Bikel's parser (Bikel,2004) and corrected by hand using the Penn Tree bank Bracketing Guidelines (Bies et al, 1995). $$$$$ Note that if the modifying nonterminals were generated completely independently, the model would be very impoverished, but in actuality, because it includes the distance and subcategorization frame features, the model captures a crucial bit of linguistic reality, namely, that words often have well-defined sets of complements and adjuncts, occurring with some well-defined distribution in the right-hand sides of a (context-free) rewriting system.
They were then parsed using Bikel's parser (Bikel,2004) and corrected by hand using the Penn Tree bank Bracketing Guidelines (Bies et al, 1995). $$$$$ The Collins parsing model decomposes the generation of a parse tree into many small steps, using reasonable independence assumptions to make the parameter estimation problem tractable.
They were then parsed using Bikel's parser (Bikel,2004) and corrected by hand using the Penn Tree bank Bracketing Guidelines (Bies et al, 1995). $$$$$ Finally, we perform experiments that show that the true discriminative power of lexicalization appears to lie in the fact that unlexicalized syntactic structures are generated conditioning on the headword and its part of speech.

Conditioning on crossing punctuation could be of help then, playing a role similar to that of comma-counting (Collins, 1997, §2.1) — and 'verb intervening' (Bikel, 2004, §5.1) - in early head-outward models for supervised parsing. $$$$$ That is, the cv predicate returns true only for these preterminals and false for all other preterminals.
Conditioning on crossing punctuation could be of help then, playing a role similar to that of comma-counting (Collins, 1997, §2.1) — and 'verb intervening' (Bikel, 2004, §5.1) - in early head-outward models for supervised parsing. $$$$$ If this mapping were performed uniformly, then it would be identical to mapping low-frequency words prior to top-level event counting; this is not the case, however.
Conditioning on crossing punctuation could be of help then, playing a role similar to that of comma-counting (Collins, 1997, §2.1) — and 'verb intervening' (Bikel, 2004, §5.1) - in early head-outward models for supervised parsing. $$$$$ Many thanks to David Chiang and Dan Gildea for the many valuable discussions during the course of this work.
Conditioning on crossing punctuation could be of help then, playing a role similar to that of comma-counting (Collins, 1997, §2.1) — and 'verb intervening' (Bikel, 2004, §5.1) - in early head-outward models for supervised parsing. $$$$$ However, the specifics of how certain commas do not apply to the constraint is an “unpublished detail,” as mentioned in Section 7.2.

 $$$$$ Put another way, in order to emulate Collins’ model, we need to amend the definition of cv by stipulating that cv(NPB) = false.
 $$$$$ SBR-89-20239 and DARPA grant no.
 $$$$$ Also, we have separated the steps into their functional units; an implementation could combine steps that are independent of one another (for clarity, our implementation does not, however).

 $$$$$ M. University of Pennsylvania This article documents a large set of heretofore unpublished details Collins used in his parser, such that, along with Collins’ (1999) thesis, this article contains all information necessary to duplicate Collins’ benchmark results.
 $$$$$ That is, taken together, all the unpublished details have a significant effect on overall parsing performance.
 $$$$$ This insertion ensures that NPB nodes are always dominated by NP nodes.

 $$$$$ Finally, we perform experiments that show that the true discriminative power of lexicalization appears to lie in the fact that unlexicalized syntactic structures are generated conditioning on the headword and its part of speech.
 $$$$$ The modifying nonterminals L; and R; are generated conditioning on P and H, as well as a distance metric (based on what material intervenes between the currently generated modifying nonterminal and H) and an incremental subcategorization frame feature (a multiset containing the arguments of H that have yet to be generated on the side of H in which the currently generated nonterminal falls).
 $$$$$ For all other words, the chart is seeded with a separate item for each tag observed with that word in training.
 $$$$$ Every nonterminal label in every tree is lexicalized: the label is augmented to include a unique headword (and that headword’s part of speech) that the node dominates.

 $$$$$ M. University of Pennsylvania This article documents a large set of heretofore unpublished details Collins used in his parser, such that, along with Collins’ (1999) thesis, this article contains all information necessary to duplicate Collins’ benchmark results.
 $$$$$ Michael Collins’ (1996, 1997, 1999) parsing models have been quite influential in the field of natural language processing.
 $$$$$ Even with this change, there is still a problem.
 $$$$$ As it happens, the unknown-word threshold Collins uses in his parser for English is six, not five.14 To be absolutely unambiguous, words that occur fewer than six times, which is to say, words that occur five times or fewer, in the data are considered “unknown.” words into the parsing model, then, is simply to map all low-frequency words in the training data to some special +UNKNOWN+ token before counting top-level events for parameter estimation (where “low-frequency” means “below the unknown-word threshold”).

We used Bikel's reimplementation of Collins' parsing model 2 (Bikel, 2004). $$$$$ LR (labeled recall) and LP (labeled precision) are the primary scoring metrics.
We used Bikel's reimplementation of Collins' parsing model 2 (Bikel, 2004). $$$$$ This includes the stripping away of all function tags and indices marked by the Treebank annotators.
We used Bikel's reimplementation of Collins' parsing model 2 (Bikel, 2004). $$$$$ Finally, we perform experiments that show that the true discriminative power of lexicalization appears to lie in the fact that unlexicalized syntactic structures are generated conditioning on the headword and its part of speech.
We used Bikel's reimplementation of Collins' parsing model 2 (Bikel, 2004). $$$$$ N66001-00-1-8915.

Our best performing model incorporates three dimensions of parametrization and our best result (75.25%) is similar to the one obtained by the parser of (Bikel, 2004) for Modern Standard Arabic (75%) using a fully lexicalized model and a training corpus about three times as large as our newest MH tree bank. $$$$$ I would especially like to thank Mike Collins for his invaluable assistance and great generosity while I was replicating his thesis results and for his comments on a prerelease draft of this article.
Our best performing model incorporates three dimensions of parametrization and our best result (75.25%) is similar to the one obtained by the parser of (Bikel, 2004) for Modern Standard Arabic (75%) using a fully lexicalized model and a training corpus about three times as large as our newest MH tree bank. $$$$$ For example, Gildea (2001) reimplemented Collins’ Model 1 but obtained results with roughly 16.7% more relative error than Collins’ reported results using that model.
Our best performing model incorporates three dimensions of parametrization and our best result (75.25%) is similar to the one obtained by the parser of (Bikel, 2004) for Modern Standard Arabic (75%) using a fully lexicalized model and a training corpus about three times as large as our newest MH tree bank. $$$$$ This includes the stripping away of all function tags and indices marked by the Treebank annotators.

This was followed by (Bikel, 2004) who showed that bilexical-information is used in only 1.49% of the decisions in Collins' Model-2 parser, and that removing this information results in an exceedingly small drop in performance. $$$$$ The results are presented in Table 6.
This was followed by (Bikel, 2004) who showed that bilexical-information is used in only 1.49% of the decisions in Collins' Model-2 parser, and that removing this information results in an exceedingly small drop in performance. $$$$$ In actuality, the conditions are much stricter.
This was followed by (Bikel, 2004) who showed that bilexical-information is used in only 1.49% of the decisions in Collins' Model-2 parser, and that removing this information results in an exceedingly small drop in performance. $$$$$ We have not only analyzed the effect of the unpublished details but also reanalyzed the effect of certain well-known details, revealing that bilexical dependencies are barely used by the model and that head choice is not nearly as important to overall parsing performance as once thought.
This was followed by (Bikel, 2004) who showed that bilexical-information is used in only 1.49% of the decisions in Collins' Model-2 parser, and that removing this information results in an exceedingly small drop in performance. $$$$$ These results regarding the lack of reliance on bilexical statistics suggest that generative models still have room for improvement through the employment of bilexical-class statistics, that is, dependencies among head-modifier word classes, where such classes may be defined by, say, WordNet synsets.

We use 2-best parse trees of Berkeley parser (Petrov and Klein, 2007) and 1-best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003) as inputs to the full parsing based system. $$$$$ Note that if the modifying nonterminals were generated completely independently, the model would be very impoverished, but in actuality, because it includes the distance and subcategorization frame features, the model captures a crucial bit of linguistic reality, namely, that words often have well-defined sets of complements and adjuncts, occurring with some well-defined distribution in the right-hand sides of a (context-free) rewriting system.
We use 2-best parse trees of Berkeley parser (Petrov and Klein, 2007) and 1-best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003) as inputs to the full parsing based system. $$$$$ As it happens, the tag dictionary built up when training contains entries for every word observed, even low-frequency words.
We use 2-best parse trees of Berkeley parser (Petrov and Klein, 2007) and 1-best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003) as inputs to the full parsing based system. $$$$$ We also show a cleaner and equally well-performing method for the handling of punctuation and conjunction and reveal certain other probabilistic oddities about Collins’ parser.
We use 2-best parse trees of Berkeley parser (Petrov and Klein, 2007) and 1-best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003) as inputs to the full parsing based system. $$$$$ As a way to guarantee the consistency of the model, the model also generates two hidden +STOP+ nonterminals as the leftmost and rightmost children of every parent (see Figure 7).

This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). $$$$$ Not only did they achieve new performance benchmarks on parsing the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), and not only did they serve as the basis of Collins’ own future work (Collins 2000; Collins and Duffy 2002), but they also served as the basis of important work on parser selection (Henderson and Brill 1999), an investigation of corpus variation and the effectiveness of bilexical dependencies (Gildea 2001), sample selection (Hwa 2001), bootstrapping non-English parsers (Hwa, Resnik, and Weinberg 2002), and the automatic labeling of semantic roles and predicate-argument extraction (Gildea and Jurafsky 2000; Gildea and Palmer 2002), as well as that of other research efforts.
This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). $$$$$ One of the two components of this distance metric is what we will call the “verb intervening” feature, which is a predicate vi that is true if a verb has been generated somewhere in the surface string of the previously generated modifiers on the current side of the head.
This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). $$$$$ The threaded-gap feature is represented by appending -g to every node label in the chain.
This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). $$$$$ But what of the details that were published?

Collins's statistical parser (CBP; (Collins, 1997)), improved by Bikel (Bikel, 2004), is based on the probabilities between head-words in parse trees. $$$$$ The head-generation parameter class, PH, gap-generation parameter class, PG, and subcat-generation parameter classes, PsubcatL and PsubcatR, have back-off structures as follows: The two parameter classes for generating modifying nonterminals that are not dominated by a base NP, PM and PMw, have the following back-off structures.
Collins's statistical parser (CBP; (Collins, 1997)), improved by Bikel (Bikel, 2004), is based on the probabilities between head-words in parse trees. $$$$$ Curiously, however, Collins’ implementation considers the head label of the NP chart item not to be NPB, but rather the head label of the NPB chart item.
Collins's statistical parser (CBP; (Collins, 1997)), improved by Bikel (Bikel, 2004), is based on the probabilities between head-words in parse trees. $$$$$ Only 100 of the top-scoring items covering the same span with the same nonterminal label are kept in a particular bucket, meaning that if a new item is proposed and there are already 100 items covering the same span with the same label in the chart, then it will be compared to the lowest-scoring item in the bucket.
Collins's statistical parser (CBP; (Collins, 1997)), improved by Bikel (Bikel, 2004), is based on the probabilities between head-words in parse trees. $$$$$ PM is the parameter class for generating partially lexicalized modifying nonterminals (a nonterminal label and part of speech).

The English sentences were parsed using the Bikel parser (Bikel, 2004), and the sentences were aligned with GIZA++ (Och and Ney,2000). $$$$$ One such function of the history is the distance metric.
The English sentences were parsed using the Bikel parser (Bikel, 2004), and the sentences were aligned with GIZA++ (Och and Ney,2000). $$$$$ However, Gildea (2001) reimplemented Collins’ Model 1 (essentially Model 2 but without subcats) and altered the PLw and PRw parameters so that they no longer had the top level of context that included the headword (he removed back-off level 0, as depicted in Table 1).

For English we use the Bikel parser default head word rules (Bikel, 2004). $$$$$ 2 In the course of replicating Collins’ results, it was brought to our attention that several other researchers had also tried to do this and had also gotten performance that fell short of Collins’ published results.
For English we use the Bikel parser default head word rules (Bikel, 2004). $$$$$ We not only analyze the effect of the unpublished details, but also reanalyze the effect of certain well-known details, revealing that bilexical dependencies are barely used by the model and that head choice is not nearly as important to overall parsing performance as once thought.
For English we use the Bikel parser default head word rules (Bikel, 2004). $$$$$ This oddity entails that even some relatively short sentences get skipped because they have lots of tree structure.
For English we use the Bikel parser default head word rules (Bikel, 2004). $$$$$ Model Mtw,tw shows our baseline, and Model Mφ,φ shows the effect of removing all dependence on the headword and its part of speech, with the other models illustrating varying degrees of removing elements from the two parameter classes’ conditioning contexts.

 $$$$$ We have also shown a cleaner and equally well-performing method for the handling of punctuation and conjunction, and we have revealed certain other probabilistic oddities about Collins’ parser.
 $$$$$ Chart item equality is closely tied to the generative parameters used to construct theories: We want to treat two chart items as unequal if they represent derivation forests that would be considered unequal according to the output elements and conditioning contexts of the parameters used to generate them, subject to the independence assumptions of the model.
 $$$$$ N66001-00-1-8915.
 $$$$$ Indeed, these as-yet-unpublished details account for an 11% relative increase in error from an implementation including all details to a clean-room implementation of Collins’ model.
