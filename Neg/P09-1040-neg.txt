For MaltParser we used the projective Stack algorithm (Nivre, 2009) with default settings and a slightly enriched feature model. $$$$$ In Section 3, we first define a minimal transition system and explain how it can be used to perform projective dependency parsing in linear time; we then extend the system with a single transition for swapping the order of words in the input and demonstrate that the extended system can be used to parse unrestricted dependency trees with a time complexity that is quadratic in the worst case but still linear in the best case.
For MaltParser we used the projective Stack algorithm (Nivre, 2009) with default settings and a slightly enriched feature model. $$$$$ Given a set L of dependency labels, a dependency graph for a sentence x = w1, ... , wn is a directed graph G = (Vx, A), where The set Vx of nodes is the set of positive integers up to and including n, each corresponding to the linear position of a word in the sentence, plus an extra artificial root node 0.
For MaltParser we used the projective Stack algorithm (Nivre, 2009) with default settings and a slightly enriched feature model. $$$$$ Future research will include an in-depth error analysis to find out why the system works better for some languages than others and why the exact match score improves even when the attachment score goes down.

To deal with crossing arcs, Titov et al (2009) and Nivre (2009) designed a SWAP transition that switches the position of the two topmost nodes on the stack. $$$$$ Finally, the algorithm first described by Covington (2001) and used for data-driven parsing by Nivre (2007), is complete but has quadratic complexity even in the best case.
To deal with crossing arcs, Titov et al (2009) and Nivre (2009) designed a SWAP transition that switches the position of the two topmost nodes on the stack. $$$$$ For Arabic there is a very clear linear relationship in both cases with very few outliers.
To deal with crossing arcs, Titov et al (2009) and Nivre (2009) designed a SWAP transition that switches the position of the two topmost nodes on the stack. $$$$$ Looking first at the overall attachment score, we see that Su gives a substantial improvement over Sp (and outperforms Spp) for Czech and Slovene, where the scores achieved are rivaled only by the combo system MSTMalt.
To deal with crossing arcs, Titov et al (2009) and Nivre (2009) designed a SWAP transition that switches the position of the two topmost nodes on the stack. $$$$$ The set A of arcs is a set of triples (i, l, j), where i and j are nodes and l is a label.

Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martinset al, 2009). $$$$$ Hence, the worst-case complexity of the deterministic parser is O(n2).
Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martinset al, 2009). $$$$$ We have presented a novel transition system for dependency parsing that can handle unrestricted non-projective trees.
Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martinset al, 2009). $$$$$ It is worth pointing out that, although the system described in Nivre (2008b) uses four transitions bearing the same names as the transitions of Su, the two systems are not equivalent.
Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martinset al, 2009). $$$$$ In particular, the system of Nivre (2008b) is sound but not complete for the class of all dependency trees.

 $$$$$ There are also affinities to the system of Attardi (2006), which combines non-adjacent nodes on the stack instead of swapping nodes and is equivalent to a restricted version of our system, where no more than two consecutive SWAP transitions are permitted.
 $$$$$ Looking first at the overall attachment score, we see that Su gives a substantial improvement over Sp (and outperforms Spp) for Czech and Slovene, where the scores achieved are rivaled only by the combo system MSTMalt.
 $$$$$ We have presented a novel transition system for dependency parsing that can handle unrestricted non-projective trees.
 $$$$$ Current approaches to data-driven dependency parsing typically use one of two strategies to deal with non-projective trees (unless they ignore them completely).

 $$$$$ The rest of the paper is structured as follows.
 $$$$$ Experimental results also show that parsing accuracy is competitive, especially for languages like Czech and Slovene where nonprojective dependency structures are common, and especially with respect to the exact match score, where it has the best reported results for four out of five languages.
 $$$$$ The SWAP transition updates a configuration with stack [aJi, j] by moving the node i back to the buffer.
 $$$$$ This restriction preserves linear worstcase complexity at the expense of completeness.

 $$$$$ But allowing non-projective dependency trees also makes parsing empirically harder, because it requires that we model relations between nonadjacent structures over potentially unbounded distances, which often has a negative impact on parsing accuracy.
 $$$$$ The remaining three languages all lie somewhere in the middle, with Czech being closer to Arabic and Slovene closer to Danish.
 $$$$$ A transition system S is sound for a class G of dependency graphs iff, for every sentence x and transition sequence C0,m for x in S, Gcm E G. S is complete for G iff, for every sentence x and dependency graph G for x in G, there is a transition sequence C0,m for x in S such that Gcm = G. An oracle for a transition system S is a function o : C —* T. Ideally, o should always return the optimal transition t for a given configuration c, but all we require formally is that it respects the preconditions of transitions in T. That is, if o(c) = t then t is permissible in c. Given an oracle o, deterministic transition-based parsing can be achieved by the following simple algorithm: Starting in the initial configuration cs(x), the parser repeatedly calls the oracle function o for the current configuration c and updates c according to the oracle transition t. The iteration stops when a terminal configuration is reached.

 $$$$$ Processing non-projective trees by swapping the order of words has recently been proposed by both Nivre (2008b) and Titov et al. (2009), but these systems cannot handle unrestricted non-projective trees.
 $$$$$ Allowing non-projective trees generally makes parsing computationally harder.
 $$$$$ To test this hypothesis, we examine how the number of transitions varies as a function of sentence length.
 $$$$$ Assuming that the calls o(c) and t(c) can both be performed in constant time, the worst-case time complexity of a deterministic parser based on a transition system S is given by an upper bound on the length of transition sequences in S. When building practical parsing systems, the oracle can be approximated by a classifier trained on treebank data, a technique that has been used successfully in a number of systems (Yamada and Matsumoto, 2003; Nivre et al., 2004; Attardi, 2006).

 $$$$$ We will refer to the list E as the stack and the list B as the buffer, and we will use the variables Q and 0 for arbitrary sublists of E and B, respectively.
 $$$$$ A hallmark of many of these models is that they can be implemented very efficiently.
 $$$$$ The system reuses standard techniques for building projective trees by combining adjacent nodes (representing subtrees with adjacent yields), but adds a simple mechanism for swapping the order of nodes on the stack, which gives a system that is sound and complete for the set of all dependency trees over a given label set but behaves exactly like the standard system for the subset of projective trees.
 $$$$$ Assuming that the calls o(c) and t(c) can both be performed in constant time, the worst-case time complexity of a deterministic parser based on a transition system S is given by an upper bound on the length of transition sequences in S. When building practical parsing systems, the oracle can be approximated by a classifier trained on treebank data, a technique that has been used successfully in a number of systems (Yamada and Matsumoto, 2003; Nivre et al., 2004; Attardi, 2006).

 $$$$$ This should mean that the expected number of swaps per sentence is small, and that the running time is linear on average for the range of inputs that occur in natural languages.
 $$$$$ Thus, c = ([QIi], [j10], A) is a configuration with the node i on top of the stack E and the node j as the first node in the buffer B.
 $$$$$ We now consider what happens when we add the fourth transition from Figure 2 to get the extended transition set T,.

 $$$$$ In section 3.2, we hypothesized that the expected running time of a deterministic parser using the transition system 5,, would be linear, rather than quadratic.
 $$$$$ We have presented a novel transition system for dependency parsing that can handle unrestricted non-projective trees.
 $$$$$ For comparison, the table also includes results for the two best performing systems in the original CoNLL-X shared task, Malt-06 (Nivre et al., 2006) and MST-06 (McDonald et al., 2006), as well as the integrated system MSTMalt, which is a graph-based parser guided by the predictions of a transition-based parser and currently has the best reported results on the CoNLL-X data sets (Nivre and McDonald, 2008).

Despite this fact, it is possible to perform non-projective parsing in linear time in practice (Nivre, 2009). $$$$$ Adding the swapping operation changes the time complexity for deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora.
Despite this fact, it is possible to perform non-projective parsing in linear time in practice (Nivre, 2009). $$$$$ The difference is statistically significant with respect to all other systems except MSTMalt for Slovene, all except MSTMalt and Spp for Czech, and with respect to MSTMalt for Turkish.

Note that Nivre (2009) has a similar idea of performing projective and non-projective parsing selectively. $$$$$ Adding the swapping operation changes the time complexity for deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora.
Note that Nivre (2009) has a similar idea of performing projective and non-projective parsing selectively. $$$$$ Given a transition system 5 = (C, T, cs, Ct), a transition sequence for a sentence x is a sequence C0,m = (c0, c1, ... , cm) of configurations, such that The parse assigned to S by C0,m is the dependency graph Gcm = (Vx, Acm), where Acm is the set of arcs in cm.
Note that Nivre (2009) has a similar idea of performing projective and non-projective parsing selectively. $$$$$ We first measured the abstract running time on the training sets, using the oracle to derive the transition sequence for every sentence, to see how many transitions are required in the ideal case.

'Nivre' is Nivre's swap algorithm (Nivre, 2009), of which we use the implementation from MaltParser (maltparser.org). $$$$$ Our experiments are based on five data sets from the CoNLL-X shared task: Arabic, Czech, Danish, Slovene, and Turkish (Buchholz and Marsi, 2006).
'Nivre' is Nivre's swap algorithm (Nivre, 2009), of which we use the implementation from MaltParser (maltparser.org). $$$$$ The system reuses standard techniques for building projective trees by combining adjacent nodes (representing subtrees with adjacent yields), but adds a simple mechanism for swapping the order of nodes on the stack, which gives a system that is sound and complete for the set of all dependency trees over a given label set but behaves exactly like the standard system for the subset of projective trees.
'Nivre' is Nivre's swap algorithm (Nivre, 2009), of which we use the implementation from MaltParser (maltparser.org). $$$$$ However, one problem that still has not found a satisfactory solution in data-driven dependency parsing is the treatment of discontinuous syntactic constructions, usually modeled by non-projective dependency trees, as illustrated in Figure 1.

In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). $$$$$ If the words are not in projective order, we can use a combination of SHIFT and SWAP transitions to ensure that nodes are still pushed onto the stack in projective order.
In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). $$$$$ In Section 3, we first define a minimal transition system and explain how it can be used to perform projective dependency parsing in linear time; we then extend the system with a single transition for swapping the order of words in the input and demonstrate that the extended system can be used to parse unrestricted dependency trees with a time complexity that is quadratic in the worst case but still linear in the best case.
In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). $$$$$ We present a novel transition system for dependency parsing, which constructs arcs only between adjacent words but can parse arbitrary non-projective trees by swapping the order of words in the input.

Figure 1 $$$$$ As a result, the time complexity of deterministic parsing is O(n2) in the worst case, which is rare, but O(n) in the best case, which is common, and experimental results on data from five languages support the conclusion that expected running time is linear in the length of the sentence.
Figure 1 $$$$$ More precisely, if the next node in the projective order is the kth node in the buffer, we perform k SHIFT transitions, to get this node onto the stack, followed by k−1 SWAP transitions, to move the preceding k − 1 nodes back to the buffer.1 In this way, the parser can effectively sort the input nodes into projective order on the stack, repeatedly extracting the minimal element of <G from the buffer, and build a tree that is projective with respect to the sorted order.
Figure 1 $$$$$ In Section 3.2, we will add the fourth transition (SWAP) to get the full transition set Tu (u for unrestricted).

Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees. $$$$$ The difference is statistically significant with respect to all other systems except MSTMalt for Slovene, all except MSTMalt and Spp for Czech, and with respect to MSTMalt for Turkish.
Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees. $$$$$ (The results for Arabic are not very meaningful, given that there are only eleven non-projective arcs in the entire test set, of which the (pseudo-)projective parsers found two and Su one, while MSTMalt and MST-06 found none at all.)
Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees. $$$$$ For reasons of perspicuity, we will write E with its head (top) to the right and B with its head to the left.

Non-projective parsing algorithms for supervised dependency parsing have, for example, been presented in McDonald et al. (2005) and Nivre (2009). $$$$$ Our experiments are based on five data sets from the CoNLL-X shared task: Arabic, Czech, Danish, Slovene, and Turkish (Buchholz and Marsi, 2006).
Non-projective parsing algorithms for supervised dependency parsing have, for example, been presented in McDonald et al. (2005) and Nivre (2009). $$$$$ It is worth pointing out that, although the system described in Nivre (2008b) uses four transitions bearing the same names as the transitions of Su, the two systems are not equivalent.
Non-projective parsing algorithms for supervised dependency parsing have, for example, been presented in McDonald et al. (2005) and Nivre (2009). $$$$$ The difference is statistically significant with respect to all other systems except MSTMalt for Slovene, all except MSTMalt and Spp for Czech, and with respect to MSTMalt for Turkish.

 $$$$$ For these languages, there is no statistical difference between Su and MSTMalt, which are both significantly better than all the other parsers, except Spp for Czech (McNemar’s test, α = .05).
 $$$$$ Evaluation on data from five languages shows state-of-the-art accuracy, with especially good results for the labeled exact match score.
 $$$$$ For reasons of perspicuity, we will write E with its head (top) to the right and B with its head to the left.
 $$$$$ This restriction preserves linear worstcase complexity at the expense of completeness.

However, the goal of that transition is different from ours (selecting between projective and non-projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ It is worth pointing out that, although the system described in Nivre (2008b) uses four transitions bearing the same names as the transitions of Su, the two systems are not equivalent.
However, the goal of that transition is different from ours (selecting between projective and non-projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ In Section 3, we first define a minimal transition system and explain how it can be used to perform projective dependency parsing in linear time; we then extend the system with a single transition for swapping the order of words in the input and demonstrate that the extended system can be used to parse unrestricted dependency trees with a time complexity that is quadratic in the worst case but still linear in the best case.
However, the goal of that transition is different from ours (selecting between projective and non-projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ We discuss related work in Section 5 and conclude in Section 6.

Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ Even the best algorithms for deterministic parsing run in quadratic time, rather than linear (Nivre, 2008a), unless restricted to a subset of non-projective structures as in Attardi (2006) and Nivre (2007).
Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ Syntactic parsing using dependency structures has become a standard technique in natural language processing with many different parsing models, in particular data-driven models that can be trained on syntactically annotated corpora (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Attardi, 2006; Titov and Henderson, 2007).
Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ In Section 2, we define the formal representations needed and introduce the framework of transitionbased dependency parsing.
Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ Current approaches to data-driven dependency parsing typically use one of two strategies to deal with non-projective trees (unless they ignore them completely).
