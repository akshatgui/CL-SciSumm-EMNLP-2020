For MaltParser we used the projective Stack algorithm (Nivre, 2009) with default settings and a slightly enriched feature model. $$$$$ But allowing non-projective dependency trees also makes parsing empirically harder, because it requires that we model relations between nonadjacent structures over potentially unbounded distances, which often has a negative impact on parsing accuracy.
For MaltParser we used the projective Stack algorithm (Nivre, 2009) with default settings and a slightly enriched feature model. $$$$$ The total set of transitions that will be considered is given in Figure 2, but we will start in Section 3.1 with the subset Tp (p for projective) consisting of the first three.
For MaltParser we used the projective Stack algorithm (Nivre, 2009) with default settings and a slightly enriched feature model. $$$$$ There are also affinities to the system of Attardi (2006), which combines non-adjacent nodes on the stack instead of swapping nodes and is equivalent to a restricted version of our system, where no more than two consecutive SWAP transitions are permitted.

To deal with crossing arcs, Titov et al (2009) and Nivre (2009) designed a SWAP transition that switches the position of the two topmost nodes on the stack. $$$$$ For proofs of soundness and completeness, see Nivre (2008a).
To deal with crossing arcs, Titov et al (2009) and Nivre (2009) designed a SWAP transition that switches the position of the two topmost nodes on the stack. $$$$$ Experimental results also show that parsing accuracy is competitive, especially for languages like Czech and Slovene where nonprojective dependency structures are common, and especially with respect to the exact match score, where it has the best reported results for four out of five languages.
To deal with crossing arcs, Titov et al (2009) and Nivre (2009) designed a SWAP transition that switches the position of the two topmost nodes on the stack. $$$$$ We discuss related work in Section 5 and conclude in Section 6.

Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martinset al, 2009). $$$$$ In particular, the system of Nivre (2008b) is sound but not complete for the class of all dependency trees.
Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martinset al, 2009). $$$$$ In addition, we want to explore alternative oracle functions, which try to minimize the number of swaps by allowing the stack to be temporarily “unsorted”.
Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martinset al, 2009). $$$$$ In Section 4, we present experiments indicating that the expected running time of the new system on naturally occurring data is in fact linear and that the system achieves state-ofthe-art parsing accuracy.

 $$$$$ We will refer to the list E as the stack and the list B as the buffer, and we will use the variables Q and 0 for arbitrary sublists of E and B, respectively.
 $$$$$ Evaluation on data from five languages shows state-of-the-art accuracy, with especially good results for the labeled exact match score.
 $$$$$ Adding the swapping operation changes the time complexity for deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora.

 $$$$$ Future research will include an in-depth error analysis to find out why the system works better for some languages than others and why the exact match score improves even when the attachment score goes down.
 $$$$$ A transition system S is sound for a class G of dependency graphs iff, for every sentence x and transition sequence C0,m for x in S, Gcm E G. S is complete for G iff, for every sentence x and dependency graph G for x in G, there is a transition sequence C0,m for x in S such that Gcm = G. An oracle for a transition system S is a function o : C —* T. Ideally, o should always return the optimal transition t for a given configuration c, but all we require formally is that it respects the preconditions of transitions in T. That is, if o(c) = t then t is permissible in c. Given an oracle o, deterministic transition-based parsing can be achieved by the following simple algorithm: Starting in the initial configuration cs(x), the parser repeatedly calls the oracle function o for the current configuration c and updates c according to the oracle transition t. The iteration stops when a terminal configuration is reached.

 $$$$$ We present a novel transition system for dependency parsing, which constructs arcs only between adjacent words but can parse arbitrary non-projective trees by swapping the order of words in the input.

 $$$$$ To test this hypothesis, we examine how the number of transitions varies as a function of sentence length.
 $$$$$ As noted in section 2, the worst-case time complexity of a deterministic transition-based parser is given by an upper bound on the length of transition sequences.
 $$$$$ There are also affinities to the system of Attardi (2006), which combines non-adjacent nodes on the stack instead of swapping nodes and is equivalent to a restricted version of our system, where no more than two consecutive SWAP transitions are permitted.

 $$$$$ In Section 3, we first define a minimal transition system and explain how it can be used to perform projective dependency parsing in linear time; we then extend the system with a single transition for swapping the order of words in the input and demonstrate that the extended system can be used to parse unrestricted dependency trees with a time complexity that is quadratic in the worst case but still linear in the best case.
 $$$$$ The system reuses standard techniques for building projective trees by combining adjacent nodes (representing subtrees with adjacent yields), but adds a simple mechanism for swapping the order of nodes on the stack, which gives a system that is sound and complete for the set of all dependency trees over a given label set but behaves exactly like the standard system for the subset of projective trees.
 $$$$$ We present a novel transition system for dependency parsing, which constructs arcs only between adjacent words but can parse arbitrary non-projective trees by swapping the order of words in the input.

 $$$$$ In Section 3, we first define a minimal transition system and explain how it can be used to perform projective dependency parsing in linear time; we then extend the system with a single transition for swapping the order of words in the input and demonstrate that the extended system can be used to parse unrestricted dependency trees with a time complexity that is quadratic in the worst case but still linear in the best case.
 $$$$$ Adding the swapping operation changes the time complexity for deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora.
 $$$$$ Adding the swapping operation changes the time complexity for deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora.
 $$$$$ The system reuses standard techniques for building projective trees by combining adjacent nodes (representing subtrees with adjacent yields), but adds a simple mechanism for swapping the order of nodes on the stack, which gives a system that is sound and complete for the set of all dependency trees over a given label set but behaves exactly like the standard system for the subset of projective trees.

 $$$$$ The minimal transition set Tp for projective dependency parsing contains three transitions: The system Sp = (C, Tp, cs, Ct) is sound and complete for the set of projective dependency trees (over some label set L) and has been used, in slightly different variants, by a number of transition-based dependency parsers (Yamada and Matsumoto, 2003; Nivre, 2004; Attardi, 2006; Nivre, 2008a).
 $$$$$ This restriction preserves linear worstcase complexity at the expense of completeness.
 $$$$$ But allowing non-projective dependency trees also makes parsing empirically harder, because it requires that we model relations between nonadjacent structures over potentially unbounded distances, which often has a negative impact on parsing accuracy.
 $$$$$ This restriction preserves linear worstcase complexity at the expense of completeness.

Despite this fact, it is possible to perform non-projective parsing in linear time in practice (Nivre, 2009). $$$$$ In fact, the only significant differences in attachment score here are the positive differences between MSTMalt and all other systems for Arabic and Danish, and the negative difference between MST-06 and all other systems for Turkish.
Despite this fact, it is possible to perform non-projective parsing in linear time in practice (Nivre, 2009). $$$$$ In particular, the system of Nivre (2008b) is sound but not complete for the class of all dependency trees.
Despite this fact, it is possible to perform non-projective parsing in linear time in practice (Nivre, 2009). $$$$$ Empirical studies, based on data from a wide range of languages, have shown that dependency trees tend to be projective and that most non-projective trees only contain a small number of discontinuities (Nivre, 2006; Kuhlmann and Nivre, 2006; Havelka, 2007).

Note that Nivre (2009) has a similar idea of performing projective and non-projective parsing selectively. $$$$$ Finally, the simplicity of the system makes it very easy to implement.
Note that Nivre (2009) has a similar idea of performing projective and non-projective parsing selectively. $$$$$ We will refer to the list E as the stack and the list B as the buffer, and we will use the variables Q and 0 for arbitrary sublists of E and B, respectively.
Note that Nivre (2009) has a similar idea of performing projective and non-projective parsing selectively. $$$$$ The result for Arabic and Danish can be seen in Figure 5, where black dots represent training sentences (parsed with the oracle) and white dots represent test sentences (parsed with a classifier).

'Nivre' is Nivre's swap algorithm (Nivre, 2009), of which we use the implementation from MaltParser (maltparser.org). $$$$$ We conclude that Su may increase the probability of finding a completely correct analysis, which is sometimes reflected also in the overall attachment score, and we conjecture that the strength of the positive effect is dependent on the frequency of non-projective arcs in the language.
'Nivre' is Nivre's swap algorithm (Nivre, 2009), of which we use the implementation from MaltParser (maltparser.org). $$$$$ Adding the swapping operation changes the time complexity for deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora.
'Nivre' is Nivre's swap algorithm (Nivre, 2009), of which we use the implementation from MaltParser (maltparser.org). $$$$$ In addition, we want to explore alternative oracle functions, which try to minimize the number of swaps by allowing the stack to be temporarily “unsorted”.

In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). $$$$$ It is important to note that SWAP is only permissible when the two nodes on top of the stack are in the original word order, which prevents the same two nodes from being swapped more than once, and when the leftmost node i is distinct from the root node 0.
In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). $$$$$ Future research will include an in-depth error analysis to find out why the system works better for some languages than others and why the exact match score improves even when the attachment score goes down.

Figure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009). $$$$$ Exact inference for parsing models that allow non-projective trees is NP hard, except under very restricted independence assumptions (Neuhaus and Br¨oker, 1997; McDonald and Pereira, 2006; McDonald and Satta, 2007).
Figure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009). $$$$$ This restriction preserves linear worstcase complexity at the expense of completeness.
Figure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009). $$$$$ For completeness, we note first that projectivity is not a property of a dependency tree in itself, but of the tree in combination with a word order, and that a tree can always be made projective by reordering the nodes.
Figure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009). $$$$$ But allowing non-projective dependency trees also makes parsing empirically harder, because it requires that we model relations between nonadjacent structures over potentially unbounded distances, which often has a negative impact on parsing accuracy.

Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees. $$$$$ It is worth pointing out that, although the system described in Nivre (2008b) uses four transitions bearing the same names as the transitions of Su, the two systems are not equivalent.
Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees. $$$$$ The system reuses standard techniques for building projective trees by combining adjacent nodes (representing subtrees with adjacent yields), but adds a simple mechanism for swapping the order of nodes on the stack, which gives a system that is sound and complete for the set of all dependency trees over a given label set but behaves exactly like the standard system for the subset of projective trees.
Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees. $$$$$ This has the effect that the order of the nodes i and j in the appended list E+B is reversed compared to the original word order in the sentence.
Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees. $$$$$ Adding the swapping operation changes the time complexity for deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora.

Non-projective parsing algorithms for supervised dependency parsing have, for example, been presented in McDonald et al. (2005) and Nivre (2009). $$$$$ As noted in section 2, the worst-case time complexity of a deterministic transition-based parser is given by an upper bound on the length of transition sequences.
Non-projective parsing algorithms for supervised dependency parsing have, for example, been presented in McDonald et al. (2005) and Nivre (2009). $$$$$ For reasons of perspicuity, we will write E with its head (top) to the right and B with its head to the left.
Non-projective parsing algorithms for supervised dependency parsing have, for example, been presented in McDonald et al. (2005) and Nivre (2009). $$$$$ We present a novel transition system for dependency parsing, which constructs arcs only between adjacent words but can parse arbitrary non-projective trees by swapping the order of words in the input.

 $$$$$ Experimental results also show that parsing accuracy is competitive, especially for languages like Czech and Slovene where nonprojective dependency structures are common, and especially with respect to the exact match score, where it has the best reported results for four out of five languages.
 $$$$$ Evaluation on data from five languages shows state-of-the-art accuracy, with especially good results for the labeled exact match score.
 $$$$$ This is also the approach we will take in the experimental evaluation in Section 4.

However, the goal of that transition is different from ours (selecting between projective and non-projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ There are also affinities to the system of Attardi (2006), which combines non-adjacent nodes on the stack instead of swapping nodes and is equivalent to a restricted version of our system, where no more than two consecutive SWAP transitions are permitted.
However, the goal of that transition is different from ours (selecting between projective and non-projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ In particular, the system of Nivre (2008b) is sound but not complete for the class of all dependency trees.
However, the goal of that transition is different from ours (selecting between projective and non-projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ Hence, the worst-case complexity of the deterministic parser is O(n2).
However, the goal of that transition is different from ours (selecting between projective and non-projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. $$$$$ Future research will include an in-depth error analysis to find out why the system works better for some languages than others and why the exact match score improves even when the attachment score goes down.

Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ Either they employ a non-standard parsing algorithm that can combine non-adjacent substructures (McDonald et al., 2005b; Attardi, 2006; Nivre, 2007), or they try to recover nonprojective dependencies by post-processing the output of a strictly projective parser (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006).
Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time. $$$$$ Hence, the worst-case complexity of the deterministic parser is O(n2).
