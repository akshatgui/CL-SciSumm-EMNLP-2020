Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ 3 can be solved by finding each ti and then mapping mi independently as in a local approach, but still enforces some degree of coherence among the disambiguations.
Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ Both approaches have limitations.
Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ Linker accuracy is defined as the fraction of all mentions for which the linker outputs the correct disambiguation (note that, when the title produced by the ranker is incorrect, this penalizes linker accuracy).
Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ In an attempt to generate more challenging data, we extracted 10,000 random paragraphs for which choosing the top disambiguation according to P(t|m) results in at least a 10% ranker error rate.

We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ Both approaches have limitations.
We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ The MSNBC data set contains 747 mentions mapped to non-null Wikipedia pages, but some mentions within the same document refer to the same titles.
We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ This approach utilizes only a fraction of the available mentions for context, and relies on the presence of unambiguous mentions with high disambiguation utility.
We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ The majority of the terms selected in all summaries refer to the general issues related to China, such as “legalism, reform, military, control, etc.”, while a minority of the terms actually allow disambiguation between the candidates.

The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ 2 is NPhard, and approximations are required (Cucerzan, 2007).
The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework.
The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ The table shows the number of annotated mentions which were hyperlinked to non-null Wikipedia pages, and the number of titles in the documents (without counting repetitions).

Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ As we demonstrate in our experiments, by utilizing a more accurate disambiguation context, GLOW is able to achieve better performance.
Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ It is equal to the fraction of these mentions for which the ranker returns the correct disambiguation.
Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ Listed is the fraction of identified mentions m whose target disambiguation t is among the top k candidates ranked in descending order of P(t|m). and the predicted anotation is: { (China, People’s Republic of China), (China, History of China), (Taiwan, null), (Jiangsu, Jiangsu), (republic, Government)} , then the BOT for the gold annotation is: {People’s Republic of China, Taiwan, Jiangsu} , and the BOT for the predicted annotation is: {People’s Republic of China, History of China, Jiangsu} .
Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ The majority of the terms selected in all summaries refer to the general issues related to China, such as “legalism, reform, military, control, etc.”, while a minority of the terms actually allow disambiguation between the candidates.

In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ For example, consider the disambiguation candidates of “China’ and their TF-IDF summaries in Figure 1.
In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ Following previous work, we use Wikipedia hyperlinks to perform these steps.
In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ Our contributions are as follows: (1) We present a formulation of the D2W task as an optimization problem with local and global variants, and identify the strengths and the weaknesses of each, (2) Using this formulation, we present a new global D2W system, called GLOW.
In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ Our global features are refinements of previously proposed semantic relatedness measures between Wikipedia titles.

Additionally, while (Rahman and Ng, 2011) uses the union of all possible meanings a mention may have in Wikipedia, we deploy GLOW (Ratinov et al., 2011), a context-sensitive system for disambiguation to Wikipedia. $$$$$ The title Government is not included in the BOT for predicted annotation, because its associate mention republic did not appear as a mention in the gold annotation.
Additionally, while (Rahman and Ng, 2011) uses the union of all possible meanings a mention may have in Wikipedia, we deploy GLOW (Ratinov et al., 2011), a context-sensitive system for disambiguation to Wikipedia. $$$$$ The first data set, from (Milne and Witten, 2008b), is a subset of the AQUAINT corpus of newswire text that is annotated to mimic the hyperlink structure in Wikipedia.
Additionally, while (Rahman and Ng, 2011) uses the union of all possible meanings a mention may have in Wikipedia, we deploy GLOW (Ratinov et al., 2011), a context-sensitive system for disambiguation to Wikipedia. $$$$$ Our contributions are as follows: (1) We present a formulation of the D2W task as an optimization problem with local and global variants, and identify the strengths and the weaknesses of each, (2) Using this formulation, we present a new global D2W system, called GLOW.

We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ Previous studies on Wikification differ with respect to the corpora they address and the subset of expressions they attempt to link.
We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ Disambiguating concepts and entities in a context sensitive way is a fundamental problem in natural language processing.
We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ Wikification is the task of identifying and linking expressions in text to their referent Wikipedia pages.
We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ In an attempt to generate more challenging data, we extracted 10,000 random paragraphs for which choosing the top disambiguation according to P(t|m) results in at least a 10% ranker error rate.
