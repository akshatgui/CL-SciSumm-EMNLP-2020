Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.
Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ For computational efficiency, we utilize only the top 20 most frequent target pages for the anchor text; the accuracy impact of this optimization is analyzed in Section 6.
Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ These features capture the intuition that a given Wikipedia title t is more likely to be referred to by mention m appearing in document d if the Wikipedia page for t has high textual similarity to d, or if the context surrounding hyperlinks to t are similar to m’s context in d. For each Wikipedia title t, we construct a top200 token TF-IDF summary of the Wikipedia page t, which we denote as Text(t) and a top-200 token TF-IDF summary of the context within which t was hyperlinked to in Wikipedia, which we denote as Context(t).
Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Stro?tgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al, 2011). $$$$$ Following previous work, we use Wikipedia hyperlinks to perform these steps.

We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ Often, mentions correspond to a concept without a Wikipedia page; we treat this case by adding a special null title to the set W. The D2W task can be visualized as finding a many-to-one matching on a bipartite graph, with mentions forming one partition and Wikipedia titles the other (see Figure 1).
We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ However, since each ambiguous mention required a separate SVM model, the experiment was on a very limited scale.
We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ Error analysis has shown that in many cases the summaries of the different disambiguation candidates for the same surface form s were very similar.
We tagged each sentence with Wikipedia terms using the Illinois Wikifier (Ratinov et al, 2011) and with UMLS (Bodenreider, 2004) terms using Health Term Finder (LipskyGorman and Elhadad, 2011). $$$$$ Mihalcea and Csomai applied Word Sense Disambiguation methods to the Disambiguation to Wikipedia task (2007).

The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ In the second step, we construct for each mention mi a limited set of candidate Wikipedia titles Ti that mi may refer to.
The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ The MSNBC data set contains 747 mentions mapped to non-null Wikipedia pages, but some mentions within the same document refer to the same titles.
The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ Recent work on D2W has tended to focus on more sophisticated global approaches to the problem, in which all mentions in a document are disambiguated simultaneously to arrive at a coherent set of disambiguations (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009).
The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents (Ratinov et al, 2011), and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (Babych and Hartley, 2003) and question answering (Leidner et al, 2003). $$$$$ Disambiguation to Wikipedia is similar to a traditional Word Sense Disambiguation task, but distinct in that the Wikipedia link structure provides additional information about which disambiguations are compatible.

Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ We then solve the easier problem: ence of unambiguous mentions in the input document, and the second approach inevitably adds irrelevant titles to the disambiguation context.
Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ The common approach is to utilize the Wikipedia link graph to obtain an estimate pairwise relatedness between titles 0(ti, tj) and to efficiently generate a disambiguation context Γ′, a rough approximation to the optimal Γ*.
Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ As we demonstrate in our experiments, by utilizing a more accurate disambiguation context, GLOW is able to achieve better performance.
Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010). $$$$$ We expect, all else being equal, that the correct disambiguations will form a “coherent” set of related concepts.

In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ In our scenario, the TF of the a token is the original TF-IDF summary score (a real number), and the IDF term is the sum of all the TF-IDF scores for the token within the set of disambiguation candidates for m. This adds 4 more “reweighted local” features in Global approaches require a disambiguation context V and a relatedness measure 0 in Eq.
In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.
In fact, (Ratinov et al, 2011) show that even though global approaches can be improved, local methods based on only similarity sim (d, e) of context d and entity e are hard to beat. $$$$$ We then solve the easier problem: ence of unambiguous mentions in the input document, and the second approach inevitably adds irrelevant titles to the disambiguation context.

Additionally, while (Rahman and Ng, 2011) uses the union of all possible meanings a mention may have in Wikipedia, we deploy GLOW (Ratinov et al., 2011), a context-sensitive system for disambiguation to Wikipedia. $$$$$ In BOT, we compare the set of titles output for a document with the gold set of titles for that document (ignoring duplicates), and utilize standard precision, recall, and F1 measures.
Additionally, while (Rahman and Ng, 2011) uses the union of all possible meanings a mention may have in Wikipedia, we deploy GLOW (Ratinov et al., 2011), a context-sensitive system for disambiguation to Wikipedia. $$$$$ That is, if the gold annotation is { (China, People’s Republic of China), (Taiwan, Taiwan), (Jiangsu, Jiangsu)} of the number of generated disambiguation candidates.

We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ In this work we analyze approaches that utilize this information to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches.
We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ Eq.
We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ Our contributions are as follows: (1) We present a formulation of the D2W task as an optimization problem with local and global variants, and identify the strengths and the weaknesses of each, (2) Using this formulation, we present a new global D2W system, called GLOW.
We uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates. $$$$$ Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009).
