WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky 1995) (Resnik 1997). $$$$$ This observation suggests the following simple algorithm for disambiguation by selectional preference.
WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky 1995) (Resnik 1997). $$$$$ Problems with this approach arise, however, as soon as the domain of interest becomes too large or too rich to specify semantic features and selection restrictions accurately by hand.

Previous work on selectional preferences has used them primarily for natural language analytic tasks such as word sense disambiguation (Resnik, 1997), dependency parsing (Zhou et al 2011), and semantic role labeling (Gildea and Jurafsky, 2002). $$$$$ One main message to take away from this experiment is the observation that, although selectional preferences are widely viewed as an important factor in disambiguation, their practical broad-coverage application appears limited — at least when disambiguating nouns — because many verbs and modifiers simply do not select strongly enough to make a significant difference.
Previous work on selectional preferences has used them primarily for natural language analytic tasks such as word sense disambiguation (Resnik, 1997), dependency parsing (Zhou et al 2011), and semantic role labeling (Gildea and Jurafsky, 2002). $$$$$ Although the definition of selectional preference strength is motivated by the use of relative entropy in information theory, selectional association is not; the approach would benefit from experimentation with alternative statistical association measures, particularly a comparison with simple mutual information and with the likelihood ratio.
Previous work on selectional preferences has used them primarily for natural language analytic tasks such as word sense disambiguation (Resnik, 1997), dependency parsing (Zhou et al 2011), and semantic role labeling (Gildea and Jurafsky, 2002). $$$$$ Given the frequencies, probabilities are currently estimated using maximum likelihood; the use of word classes is itself a form of smoothing (cf.

I followed (Resnik, 1993)/ (Resnik, 1997) who defined selectional preference as the amount of information a verb provides about its semantic argument classes. $$$$$ The prior distribution PrR(c) captures the probability of a class occurring as the argument in predicate-argument relation R, regardless of the identity of the predicate.
I followed (Resnik, 1993)/ (Resnik, 1997) who defined selectional preference as the amount of information a verb provides about its semantic argument classes. $$$$$ In effect, the automatic selection of a class higher in the taxonomy as having the highest score provides the same coarse category that might be provided by a homograph/sense distinction in another setting.

The annotation of word senses such as used by machine-learning based word sense disambiguation (WSD) tools corresponds to the task of selecting the correct semantic class or concept for a word from an underlying ontology such as WordNet (Resnik, 1997). $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.
The annotation of word senses such as used by machine-learning based word sense disambiguation (WSD) tools corresponds to the task of selecting the correct semantic class or concept for a word from an underlying ontology such as WordNet (Resnik, 1997). $$$$$ They may provide some evidence, but most likely only as a complement to other sources of information such as frequency-based priors, topical context, and the like.
The annotation of word senses such as used by machine-learning based word sense disambiguation (WSD) tools corresponds to the task of selecting the correct semantic class or concept for a word from an underlying ontology such as WordNet (Resnik, 1997). $$$$$ Test and training materials were derived from the Brown corpus of American English, all of which has been parsed and manually verified by the Penn Treebank project (Marcus et al., 1993) and parts of which have been manually sense-tagged by the WordNet group (Miller et al., 1993).

Resnik (1997) described a method to acquire a set of conceptual classes for word senses, employing selectional preferences, based on the idea that certain linguistic predicates constraint the semantic interpretation of underlying words into certain classes. $$$$$ The approach combines statistical and knowledge-based methods, but unlike many recent corpus-based approaches to sense disambiguation (Yarowsky, 1993; Bruce and Wiebe, 1994; Miller et al., 1994), it takes as its starting point the assumption that senseannotated training text is not available.
Resnik (1997) described a method to acquire a set of conceptual classes for word senses, employing selectional preferences, based on the idea that certain linguistic predicates constraint the semantic interpretation of underlying words into certain classes. $$$$$ However, once the identity of the predicate is taken into account, the probabilities can change — if the verb is buzz, then the probability for (insect) can be expected to be higher than its prior, and (person) will likely be lower.
Resnik (1997) described a method to acquire a set of conceptual classes for word senses, employing selectional preferences, based on the idea that certain linguistic predicates constraint the semantic interpretation of underlying words into certain classes. $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.
Resnik (1997) described a method to acquire a set of conceptual classes for word senses, employing selectional preferences, based on the idea that certain linguistic predicates constraint the semantic interpretation of underlying words into certain classes. $$$$$ In marked contrast to annotated training material for partof-speech tagging, (a) there is no coarse-level set of sense distinctions widely agreed upon (whereas part-of-speech tag sets tend to differ in the details); (b) sense annotation has a comparatively high error rate (Miller, personal communication, reports an upper bound for human annotators of around 90% for ambiguous cases, using a non-blind evaluation method that may make even this estimate overly optimistic); and (c) no fully automatic method provides high enough quality output to support the &quot;annotate automatically, correct manually&quot; methodology used to provide high volume annotation by data providers like the Penn 'Treebank project (Marcus et al., 1993).

 $$$$$ Given the frequencies, probabilities are currently estimated using maximum likelihood; the use of word classes is itself a form of smoothing (cf.
 $$$$$ If taxonomic classes were labeled explicitly in a training corpus, estimation of probabilities in the model would be fairly straightforward.
 $$$$$ Selectional preference is traditionally connected with sense ambiguity; this paper explores how a statistical model of selectional preference, requiring neither manual annotation of selection restrictions nor supervised training, can be used in sense disambiguation.

These promising results enable a number of future researches $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.
These promising results enable a number of future researches $$$$$ Since only one sense of letter has this class as an ancestor, this method of determining argument plausibility has, in essence, performed sense disambiguation as a side effect.
These promising results enable a number of future researches $$$$$ Discussion.

Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). $$$$$ The best results reported for an unsupervised sense disambiguation method are those of Yarowsky (1992), who uses evidence from a wider context (a window of 100 surrounding words) to build up a co-occurrence model using classes from Roget's thesaurus.
Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). $$$$$ Motivating this assumption is not only the limited availability of such text at present, but skepticism that the situation will change any time soon.
Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). $$$$$ The choice of coarser category varies dynamically with the context: as the argument in rural town, the same two senses still tie, but with (region) (a subclass of (location)) as the common ancestor that determines the score.

A large, high-quality database of preferences has the potential to improve the performance of a wide range of NLP tasks including semantic role labeling (Gildea and Jurafsky, 2002), pronoun resolution (Bergsma et al, 2008), textual inference (Pantel et al, 2007), word-sense disambiguation (Resnik,1997), and many more. $$$$$ The prior distribution PrR(c) captures the probability of a class occurring as the argument in predicate-argument relation R, regardless of the identity of the predicate.
A large, high-quality database of preferences has the potential to improve the performance of a wide range of NLP tasks including semantic role labeling (Gildea and Jurafsky, 2002), pronoun resolution (Bergsma et al, 2008), textual inference (Pantel et al, 2007), word-sense disambiguation (Resnik,1997), and many more. $$$$$ This paper concerns the use of selectional constraints for automatic sense disambiguation in such broad-coverage settings.
A large, high-quality database of preferences has the potential to improve the performance of a wide range of NLP tasks including semantic role labeling (Gildea and Jurafsky, 2002), pronoun resolution (Bergsma et al, 2008), textual inference (Pantel et al, 2007), word-sense disambiguation (Resnik,1997), and many more. $$$$$ Pereira et al. (1993)).1 This estimation method is similar to that used by Yarowsky (1992) for Roget's thesaurus categories, and works for similar reasons.

We adopted the association measure proposed by Resnik (1993) and successfully applied to a number of tasks in NLP including word sense disambiguation (Resnik, 1997). $$$$$ Selectional preference is traditionally connected with sense ambiguity; this paper explores how a statistical model of selectional preference, requiring neither manual annotation of selection restrictions nor supervised training, can be used in sense disambiguation.
We adopted the association measure proposed by Resnik (1993) and successfully applied to a number of tasks in NLP including word sense disambiguation (Resnik, 1997). $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.

To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules. $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.
To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules. $$$$$ Table 1 presents a selected sample of Resnik's (1993a) comparison with argument plausibility judgments made by human subjects.
To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules. $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.
To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules. $$$$$ Selectional preference is traditionally connected with sense ambiguity; this paper explores how a statistical model of selectional preference, requiring neither manual annotation of selection restrictions nor supervised training, can be used in sense disambiguation.

In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ The prior distribution PrR(c) captures the probability of a class occurring as the argument in predicate-argument relation R, regardless of the identity of the predicate.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ Although the definition of selectional preference strength is motivated by the use of relative entropy in information theory, selectional association is not; the approach would benefit from experimentation with alternative statistical association measures, particularly a comparison with simple mutual information and with the likelihood ratio.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.
In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007). $$$$$ This means that the observed countverb-obj (drink, coffee) = 1 will be distributed by adding A to the joint frequency with drink for each of the 13 classes containing coffee.

We used the training sets, test sets, and evaluation method described in (Resnik, 1997). $$$$$ Motivating this assumption is not only the limited availability of such text at present, but skepticism that the situation will change any time soon.

Automatically or semi automatically acquired selectional preferences, as means for constraining the number of possible senses that a word might have, based on the relation it has with other words in context (Resnik, 1997). $$$$$ In order to approximate its plausibility as the object of write, the selectional association with write was computed for all 19 classes, and the highest value returned — in this case, (writing) (&quot;anything expressed in letters; reading matter&quot;).
Automatically or semi automatically acquired selectional preferences, as means for constraining the number of possible senses that a word might have, based on the relation it has with other words in context (Resnik, 1997). $$$$$ But since text corpora contain words, not classes, it is necessary to treat each occurrence of a word in an argument position as if it might represent any of the conceptual classes to which it belongs, and assign frequency counts accordingly.
Automatically or semi automatically acquired selectional preferences, as means for constraining the number of possible senses that a word might have, based on the relation it has with other words in context (Resnik, 1997). $$$$$ absence of is a real problem for corpus-based approaches to sense disambiguation, one that is unlikely to be solved soon.
Automatically or semi automatically acquired selectional preferences, as means for constraining the number of possible senses that a word might have, based on the relation it has with other words in context (Resnik, 1997). $$$$$ Problems with this approach arise, however, as soon as the domain of interest becomes too large or too rich to specify semantic features and selection restrictions accurately by hand.
