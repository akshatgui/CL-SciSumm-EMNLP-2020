See Caraballo (1999) for a detailed description of a method to construct such a hierarchy. $$$$$ The hyponym-hypernym pairs found by Hearst's algorithm include some that Hearst describes as &quot;context and point-of-view dependent,&quot; such as &quot;Washington/nationalist&quot; and &quot;aircraft/target&quot; .
See Caraballo (1999) for a detailed description of a method to construct such a hierarchy. $$$$$ Since the hierarchy is learned from sample text, it could be trained on domainspecific text to create a hierarchy that is more applicable to a particular domain than a general-purpose resource such as WordNet.
See Caraballo (1999) for a detailed description of a method to construct such a hierarchy. $$$$$ Thanks to Eugene Charniak for helpful discussions and for the data used in this project.
See Caraballo (1999) for a detailed description of a method to construct such a hierarchy. $$$$$ WordNet has been an important research tool, but it is insufficient for domainspecific text, such as that encountered in the MUCs (Message Understanding Conferences).

In Caraballo (1999), we construct a hierarchy of nouns, including hypernym relations. $$$$$ Roark and Charniak (1998) built on that work by actually using conjunction and appositive data for noun clustering, as we do here.
In Caraballo (1999), we construct a hierarchy of nouns, including hypernym relations. $$$$$ (&quot;Conductor&quot; seems out-of-place on this list; see the next section for discussion.)
In Caraballo (1999), we construct a hierarchy of nouns, including hypernym relations. $$$$$ We want to move this node's children directly under the nearest labeled ancestor.
In Caraballo (1999), we construct a hierarchy of nouns, including hypernym relations. $$$$$ By reducing the number of nouns to be read, a much nicer structure is obtained.

Caraballo (1999) proposed the first attempt, which used conjunction and apposition features to build noun clusters. $$$$$ Of the 50 noise words, a few of them were actually rated as correct as well, as shown in Table 3.
Caraballo (1999) proposed the first attempt, which used conjunction and apposition features to build noun clusters. $$$$$ WordNet has been an important research tool, but it is insufficient for domainspecific text, such as that encountered in the MUCs (Message Understanding Conferences).
Caraballo (1999) proposed the first attempt, which used conjunction and apposition features to build noun clusters. $$$$$ This data is extracted from the parsed text, and for each noun we construct a vector of hypernyms, with a value of 1 if a word has been seen as a hypernym for this noun and 0 otherwise.

Caraballo (1999) uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns. $$$$$ The labeled tree constructed in the previous section tends to be extremely redundant.
Caraballo (1999) uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns. $$$$$ If a hypernym has occurred with only one of the descendant nouns, it is not listed as one of the best hypernyms, since we have insufficient evidence that the word could describe this class of nouns.
Caraballo (1999) uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns. $$$$$ (They also use noun compound data, but in a separate stage of processing.)
Caraballo (1999) uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns. $$$$$ With our current hardware, the largest array we The way we handled this limitation is to process the nouns in batches.

The built-in ambiguity in the hyponymy hierarchy presented in (Caraballo, 1999) is primarily an effect of the fact that all information is composed into one tree. $$$$$ Three human judges were asked to evaluate for each noun and each of the (up to) three hypernyms listed as &quot;best&quot; for that cluster, whether they were actually in a hyponym-hypernym relation.
The built-in ambiguity in the hyponymy hierarchy presented in (Caraballo, 1999) is primarily an effect of the fact that all information is composed into one tree. $$$$$ We have shown that hypernym hierarchies of nouns can be constructed automatically from text with similar performance to semantic lexicons built automatically for hand-selected hypernyms.
The built-in ambiguity in the hyponymy hierarchy presented in (Caraballo, 1999) is primarily an effect of the fact that all information is composed into one tree. $$$$$ This work goes a step further by automatically creating not just clusters of related words, but a hierarchy of nouns and their hypernyms, akin to the hand-built hierarchy in WordNet.

As was also reported by Caraballo (1999), the judges sometimes found proper nouns (as hyponyms) hard to evaluate. $$$$$ A discussion of the difficulties in deciding how much of a noun phrase to use can be found in Hearst.
As was also reported by Caraballo (1999), the judges sometimes found proper nouns (as hyponyms) hard to evaluate. $$$$$ For example, we have a cluster including many forms of currency, but because there is little data for these particular words, the only hypernym found was &quot;product&quot;.
As was also reported by Caraballo (1999), the judges sometimes found proper nouns (as hyponyms) hard to evaluate. $$$$$ This work goes a step further by automatically creating not just clusters of related words, but a hierarchy of nouns and their hypernyms, akin to the hand-built hierarchy in WordNet.
As was also reported by Caraballo (1999), the judges sometimes found proper nouns (as hyponyms) hard to evaluate. $$$$$ Thanks also to Brian Roark, Heidi J.

It is difficult to compare these results with results from other studies such as that of Caraballo (1999), as the data used is not the same. $$$$$ This research is supported in part by NSF grant IRI-9319516 and by ONR grant N0014-96-1-0549.
It is difficult to compare these results with results from other studies such as that of Caraballo (1999), as the data used is not the same. $$$$$ Thanks to Eugene Charniak for helpful discussions and for the data used in this project.
It is difficult to compare these results with results from other studies such as that of Caraballo (1999), as the data used is not the same. $$$$$ This work shares with ours the feature that it does not need large amounts of data to learn a hypernym; unlike in much statistical work, a single occurrence is sufficient.

Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy that had at least twenty descendants. $$$$$ We have shown that hypernym hierarchies of nouns can be constructed automatically from text with similar performance to semantic lexicons built automatically for hand-selected hypernyms.
Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy that had at least twenty descendants. $$$$$ Since the hierarchy is learned from sample text, it could be trained on domainspecific text to create a hierarchy that is more applicable to a particular domain than a general-purpose resource such as WordNet.
Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy that had at least twenty descendants. $$$$$ The &quot;bank/firm/station&quot; cluster consists largely of investment firms, which were marked as incorrect for &quot;bank&quot;, resulting in the poor performance on the Hypernym 1 measures for this cluster.
Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy that had at least twenty descendants. $$$$$ This research is supported in part by NSF grant IRI-9319516 and by ONR grant N0014-96-1-0549.

In Section 4, we show how correctly extracted relationships can be used as "seed-cases" to extract several more relationships, thus improving recall; this work shares some similarities with that of Caraballo (1999). $$$$$ Our work is somewhat less sensitive to this kind of problem since only the most common hypernym of an entire cluster of nouns is reported, so much of the noise is filtered.
In Section 4, we show how correctly extracted relationships can be used as "seed-cases" to extract several more relationships, thus improving recall; this work shares some similarities with that of Caraballo (1999). $$$$$ For example, we have a cluster including many forms of currency, but because there is little data for these particular words, the only hypernym found was &quot;product&quot;.

Another definition is given by Caraballo (1999). $$$$$ In many cases, a group of nouns really do not have an inherent tree structure, for example, a cluster of countries.
Another definition is given by Caraballo (1999). $$$$$ We compress the tree using the following very simple algorithm: in depth-first order, examine the children of each internal node.

First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in (Caraballo, 1999), perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node. $$$$$ Hearst (1992) introduced the idea of learning hypernym-hyponym relationships from text and gives several examples of patterns that can be used to detect these relationships including those used here, along with an algorithm for identifying new patterns.
First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in (Caraballo, 1999), perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node. $$$$$ However, if the hierarchy were to be used for text from the financial domain, these labels may be preferred.
First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in (Caraballo, 1999), perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node. $$$$$ Both of these projects have the goal of building a single cluster of, e.g., vehicles, and both use seed words to initialize a cluster with nouns belonging to it.
First of all, it would be interesting to apply LSA to a system for building an entire hypernym-labelled ontology in roughly the way described in (Caraballo, 1999), perhaps by using an LSA-weighted voting method to determine which hypernym would be used to label each node. $$$$$ These tend to be nouns for which little data was available, generally proper nouns (e.g., Reindel, Yaghoubi, Igoe).

As stated in (Caraballo, 1999), WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts. $$$$$ There are 20,014 leaves (nouns) and 654 internal nodes in the final tree (reduced from 20,013 internal nodes in the uncompressed tree).
As stated in (Caraballo, 1999), WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts. $$$$$ Roark and Charniak (1998) built on that work by actually using conjunction and appositive data for noun clustering, as we do here.
As stated in (Caraballo, 1999), WordNet has been an important lexical knowledge base, but it is insufficient for domain specific texts. $$$$$ It is not yet clear whether corpus data will provide sufficient data for hypernyms at such a high level of the tree, but depending on the intended application for the hierarchy, this level of generality might not be required.

So, many attempts have been made to automatically produce taxonomies (Grefenstette, 1994), but (Caraballo, 1999) is certainly the first work which proposes a complete overview of the problem by (1) automatically building a hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A. $$$$$ Since the hierarchy is learned from sample text, it could be trained on domainspecific text to create a hierarchy that is more applicable to a particular domain than a general-purpose resource such as WordNet.
So, many attempts have been made to automatically produce taxonomies (Grefenstette, 1994), but (Caraballo, 1999) is certainly the first work which proposes a complete overview of the problem by (1) automatically building a hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A. $$$$$ Some nouns, especially proper nouns, were not recognized by the judges.
So, many attempts have been made to automatically produce taxonomies (Grefenstette, 1994), but (Caraballo, 1999) is certainly the first work which proposes a complete overview of the problem by (1) automatically building a hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A. $$$$$ Since the hierarchy is learned from sample text, it could be trained on domainspecific text to create a hierarchy that is more applicable to a particular domain than a general-purpose resource such as WordNet.
So, many attempts have been made to automatically produce taxonomies (Grefenstette, 1994), but (Caraballo, 1999) is certainly the first work which proposes a complete overview of the problem by (1) automatically building a hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as B is a kind of A. $$$$$ A large binary tree of countries would ideally have &quot;country&quot; (or &quot;nation&quot;) as the best hypernym at every level.

Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters. $$$$$ We would like to combine these subtrees into a single parent labeled &quot;country&quot; or &quot;nation&quot;, with each country appearing as a leaf directly beneath this parent.
Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters. $$$$$ If the child is itself an internal node, and it either has no best hypernym or the same three best hypernyms as its parent, delete this child and make its children into children of the parent instead.
Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters. $$$$$ Furthermore, if we loosen our criteria to consider also the second- and third-best hypernyms, 60% of the nouns evaluated were assigned to at least one correct hypernym according to at least one judge.
Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters. $$$$$ The tree they construct is also binary with some internal nodes which seem to be &quot;artificial&quot;, but for evaluation purposes they disregard the tree structure and consider only the leaf nodes.

(Caraballo, 1999B) also used contextual information to determine the specificity of nouns. $$$$$ Our work is somewhat less sensitive to this kind of problem since only the most common hypernym of an entire cluster of nouns is reported, so much of the noise is filtered.
(Caraballo, 1999B) also used contextual information to determine the specificity of nouns. $$$$$ Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998).
(Caraballo, 1999B) also used contextual information to determine the specificity of nouns. $$$$$ Riloff and Shepherd (1997) suggested using conjunction and appositive data to cluster nouns; however, they approximated this data by just looking at the nearest NP on each side of a particular NP.
(Caraballo, 1999B) also used contextual information to determine the specificity of nouns. $$$$$ Since the tree's root is labeled, somewhere above this node there is necessarily a node labeled with a hypernym which applies to its descendant nouns, including those which are a descendant of this node.

Contrary, domain specific terms don't tend to be modified by other words, because they have sufficient information in themselves (Caraballo, 1999B). $$$$$ This research is supported in part by NSF grant IRI-9319516 and by ONR grant N0014-96-1-0549.
Contrary, domain specific terms don't tend to be modified by other words, because they have sufficient information in themselves (Caraballo, 1999B). $$$$$ These numbers do not add up to 20,014 because 1,288 nouns are attached directly to the root, meaning that they couldn't be clustered to any greater level of detail.
Contrary, domain specific terms don't tend to be modified by other words, because they have sufficient information in themselves (Caraballo, 1999B). $$$$$ We have shown that hypernym hierarchies of nouns can be constructed automatically from text with similar performance to semantic lexicons built automatically for hand-selected hypernyms.
Contrary, domain specific terms don't tend to be modified by other words, because they have sufficient information in themselves (Caraballo, 1999B). $$$$$ From this phrase we can extract that Z is likely a hypernym for both X and Y.

 $$$$$ For each internal node of the tree, we construct a vector of hypernyms by adding together the vectors of its children.
 $$$$$ Nouns are clustered based on conjunction and appositive data collected from the Wall Street Journal corpus.
 $$$$$ Thanks also to Brian Roark, Heidi J.
 $$$$$ These vectors are associated with the leaves of the binary tree constructed in the previous section.

Caraballo (1999) uses conjunction and appositive annotations in the vector representation. $$$$$ We have shown that hypernym hierarchies of nouns can be constructed automatically from text with similar performance to semantic lexicons built automatically for hand-selected hypernyms.
Caraballo (1999) uses conjunction and appositive annotations in the vector representation. $$$$$ We now only consider nouns with a vector of length at least 2.
Caraballo (1999) uses conjunction and appositive annotations in the vector representation. $$$$$ This work goes a step further by automatically creating not just clusters of related words, but a hierarchy of nouns and their hypernyms, akin to the hand-built hierarchy in WordNet.
Caraballo (1999) uses conjunction and appositive annotations in the vector representation. $$$$$ We would like to combine these subtrees into a single parent labeled &quot;country&quot; or &quot;nation&quot;, with each country appearing as a leaf directly beneath this parent.

Other approaches use natural language data, sometimes just by analyzing the corpus (Sanderson and Croft 1999), (Caraballo 1999) or by learning to expand WordNet with clusters of terms from a corpus, e.g., (Girju et al 2003). $$$$$ With the addition of some improvements we have identified, we believe that these automatic methods can be used to construct truly useful hierarchies.
Other approaches use natural language data, sometimes just by analyzing the corpus (Sanderson and Croft 1999), (Caraballo 1999) or by learning to expand WordNet with clusters of terms from a corpus, e.g., (Girju et al 2003). $$$$$ (&quot;Conductor&quot; seems out-of-place on this list; see the next section for discussion.)
Other approaches use natural language data, sometimes just by analyzing the corpus (Sanderson and Croft 1999), (Caraballo 1999) or by learning to expand WordNet with clusters of terms from a corpus, e.g., (Girju et al 2003). $$$$$ With the addition of some improvements we have identified, we believe that these automatic methods can be used to construct truly useful hierarchies.

For example, based on (Caraballo 1999), each parent of a leaf node could be viewed as a cluster label for its children, with the weight of a parent-child link being determined based on how strongly the child is associated with the cluster. $$$$$ Table 2 presents the results of this evaluation.
For example, based on (Caraballo 1999), each parent of a leaf node could be viewed as a cluster label for its children, with the weight of a parent-child link being determined based on how strongly the child is associated with the cluster. $$$$$ Riloff and Shepherd (1997) suggested using conjunction and appositive data to cluster nouns; however, they approximated this data by just looking at the nearest NP on each side of a particular NP.
For example, based on (Caraballo 1999), each parent of a leaf node could be viewed as a cluster label for its children, with the weight of a parent-child link being determined based on how strongly the child is associated with the cluster. $$$$$ Previous work has shown that automatic methods can be used in building semantic lexicons.
