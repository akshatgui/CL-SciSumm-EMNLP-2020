Toutanova et al (2008) presented a re-ranking model to jointly learn the semantic roles of multiple constituents in the SRL task. $$$$$ This work was supported in part by the Disruptive Technology Organization (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.
Toutanova et al (2008) presented a re-ranking model to jointly learn the semantic roles of multiple constituents in the SRL task. $$$$$ Other methods have also been proposed, as we discussed in Section 2 (M`arquez et al. 2005; Pradhan, Ward et al.
Toutanova et al (2008) presented a re-ranking model to jointly learn the semantic roles of multiple constituents in the SRL task. $$$$$ Semantic role labeling is very sensitive to the correctness of the given parse tree, as the results show.

We also compare with the multi parse system of (Toutanova et al, 2008) which uses a global joint model using multiple parse trees. $$$$$ False negative is the number of spans whose correct label is non-NONE and whose guessed label is not the same as the correct one (possibly NONE).
We also compare with the multi parse system of (Toutanova et al, 2008) which uses a global joint model using multiple parse trees. $$$$$ We explored a simple approach of choosing from among the top k parses from Charniak’s parser, which resulted in an improvement.
We also compare with the multi parse system of (Toutanova et al, 2008) which uses a global joint model using multiple parse trees. $$$$$ We describe our argument-based measures in detail here in case researchers are interested in replicating our results for the February 2004 data.
We also compare with the multi parse system of (Toutanova et al, 2008) which uses a global joint model using multiple parse trees. $$$$$ The proposed model substantially outperforms a similar state-of-the-art local model that does not include dependencies among different arguments.

Consider the following examples, due to Toutanova et al (2008) $$$$$ For gold-standard parse trees, we preprocess the trees to discard empty constituents and strip functional tags.
Consider the following examples, due to Toutanova et al (2008) $$$$$ The third issue is that when using automatic parsers, some of the constituents that are fillers of semantic roles are not recovered by the parser.

The complex SRL architectures proposed (usually combining local and global, i.e. joint, models of argument classification, e.g. (Toutanova et al., 2008)) require a large number of annotated examples. $$$$$ If a necessary role is missing or if an unusual set of arguments is assigned by the local model, this additional factor can correct some of the mistakes.
The complex SRL architectures proposed (usually combining local and global, i.e. joint, models of argument classification, e.g. (Toutanova et al., 2008)) require a large number of annotated examples. $$$$$ There has been a substantial amount of work on automatic semantic role labeling, starting with the statistical model of Gildea and Jurafsky (2002).
The complex SRL architectures proposed (usually combining local and global, i.e. joint, models of argument classification, e.g. (Toutanova et al., 2008)) require a large number of annotated examples. $$$$$ We tested the upper bound in performance due to our conversion scheme in the following way: Take the gold-standard CoNLL annotations for the development set (including referring and continuing labels), convert these to basic argument labels of the form ARGX, then convert the resulting labeling to CoNLL-style labeling using our rules to recover the referring and continuing annotations.
The complex SRL architectures proposed (usually combining local and global, i.e. joint, models of argument classification, e.g. (Toutanova et al., 2008)) require a large number of annotated examples. $$$$$ We will show that much larger gains are possible from joint modeling, adding richer sources of joint information using a more flexible statistical model.

Most of the CoNLL 2005 systems show a significant performance drop when the tested corpus, i.e. Brown, differs from the training one (i.e. Wall Street Journal), e.g. (Toutanova et al, 2008). $$$$$ For automatic parse trees, the error reductions are all and core arguments, respectively.
Most of the CoNLL 2005 systems show a significant performance drop when the tested corpus, i.e. Brown, differs from the training one (i.e. Wall Street Journal), e.g. (Toutanova et al, 2008). $$$$$ The confusions between modifier labels and NONE are quite numerous.
Most of the CoNLL 2005 systems show a significant performance drop when the tested corpus, i.e. Brown, differs from the training one (i.e. Wall Street Journal), e.g. (Toutanova et al, 2008). $$$$$ The method of Punyakanok, Roth, and Yih (2005) uses ILP to derive a consistent set of arguments, each of which could be derived using a different parse tree.
Most of the CoNLL 2005 systems show a significant performance drop when the tested corpus, i.e. Brown, differs from the training one (i.e. Wall Street Journal), e.g. (Toutanova et al, 2008). $$$$$ There has been a substantial amount of work on automatic semantic role labeling, starting with the statistical model of Gildea and Jurafsky (2002).

Learning from richer linguistic descriptions of more complex structures is proposed in (Toutanova et al, 2008). $$$$$ If verbs were disambiguated for sense, the semantic roles of phrases would be closer to independent given the sense of the verb.
Learning from richer linguistic descriptions of more complex structures is proposed in (Toutanova et al, 2008). $$$$$ This work was supported in part by the Disruptive Technology Organization (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.
Learning from richer linguistic descriptions of more complex structures is proposed in (Toutanova et al, 2008). $$$$$ In order for a model over these variables to capture, for example, the statistical tendency of some semantic roles to occur at most once (e.g., that there is usually at most one constituent labeled AGENT), there must be a dependency link between any two variables.
Learning from richer linguistic descriptions of more complex structures is proposed in (Toutanova et al, 2008). $$$$$ We propose such a model, with a very rich graphical model structure, which is globally conditioned on the observation (the parse tree).2 Such a model is formally a Conditional Random Field (CRF) (Lafferty, McCallum, and Pereira 2001).

In (Toutanova et al, 2008) a SRL model over Propbank that effectively exploits the semantic argument frame as a joint structure, is presented. $$$$$ Because perfect syntactic parsers do not yet exist and the major bottleneck to the performance of current semantic role labeling systems is syntactic parser performance, the more important question is how to improve performance in the presence of parser errors.
In (Toutanova et al, 2008) a SRL model over Propbank that effectively exploits the semantic argument frame as a joint structure, is presented. $$$$$ There has been a substantial amount of work on automatic semantic role labeling, starting with the statistical model of Gildea and Jurafsky (2002).
In (Toutanova et al, 2008) a SRL model over Propbank that effectively exploits the semantic argument frame as a joint structure, is presented. $$$$$ In order for a model over these variables to capture, for example, the statistical tendency of some semantic roles to occur at most once (e.g., that there is usually at most one constituent labeled AGENT), there must be a dependency link between any two variables.
In (Toutanova et al, 2008) a SRL model over Propbank that effectively exploits the semantic argument frame as a joint structure, is presented. $$$$$ A classifier is local if it assigns a probability (or score) to the label of an individual parse tree node ni independently of the labels of other nodes.

This approach effectively introduces a new step in SRL, also called Joint Re-ranking, (RR), e.g. (Toutanova et al., 2008) or (Moschitti et al., 2008). $$$$$ We show how to incorporate these strong dependencies in a statistical joint model with a rich set of features over multiple argument phrases.
This approach effectively introduces a new step in SRL, also called Joint Re-ranking, (RR), e.g. (Toutanova et al., 2008) or (Moschitti et al., 2008). $$$$$ We also present results on the CoNLL 2005 shared task data set.
This approach effectively introduces a new step in SRL, also called Joint Re-ranking, (RR), e.g. (Toutanova et al., 2008) or (Moschitti et al., 2008). $$$$$ Additionally, we explore considering multiple syntactic analyses to cope with parser noise and uncertainty.
This approach effectively introduces a new step in SRL, also called Joint Re-ranking, (RR), e.g. (Toutanova et al., 2008) or (Moschitti et al., 2008). $$$$$ There has been a substantial amount of work on automatic semantic role labeling, starting with the statistical model of Gildea and Jurafsky (2002).

Toutanova et al (2008), Johansson and Nugues (2008), and Bjorkelund et al (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. $$$$$ We show how to incorporate these strong dependencies in a statistical joint model with a rich set of features over multiple argument phrases.
Toutanova et al (2008), Johansson and Nugues (2008), and Bjorkelund et al (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. $$$$$ This work was supported in part by the Disruptive Technology Organization (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.
Toutanova et al (2008), Johansson and Nugues (2008), and Bjorkelund et al (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. $$$$$ Additionally, we explore considering multiple syntactic analyses to cope with parser noise and uncertainty.
Toutanova et al (2008), Johansson and Nugues (2008), and Bjorkelund et al (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. $$$$$ We thank the journal reviewers and the reviewers and audience at ACL 2005 and CoNLL 2005 for their helpful comments.

While there are a number of existing tools for performing these tasks based on the linguistic context (e.g., Toutanova et al, 2008, Erk and Pado, 2006), their performance is only moderate (e.g., Agirre et al 2007). $$$$$ Researchers have worked on defining new useful features, and different system architectures and models.
While there are a number of existing tools for performing these tasks based on the linguistic context (e.g., Toutanova et al, 2008, Erk and Pado, 2006), their performance is only moderate (e.g., Agirre et al 2007). $$$$$ This research was carried out while all the authors were at Stanford University.
While there are a number of existing tools for performing these tasks based on the linguistic context (e.g., Toutanova et al, 2008, Erk and Pado, 2006), their performance is only moderate (e.g., Agirre et al 2007). $$$$$ However, linguistic theory tells us that a core argument frame is a joint structure, with strong dependencies between arguments.
While there are a number of existing tools for performing these tasks based on the linguistic context (e.g., Toutanova et al, 2008, Erk and Pado, 2006), their performance is only moderate (e.g., Agirre et al 2007). $$$$$ Previous work has shown that these are strongly correlated with the word sense of the verb (Roland and Jurafsky 2002).

Supervised SRL systems have mostly used local classifiers that assign a role to each constituent independently of others, and only modeled limited correlations among roles in a sequence (Toutanova et al., 2008). $$$$$ Here we review the work most closely related to ours, concentrating on methods for incorporating joint information and for increasing robustness to parser error.
Supervised SRL systems have mostly used local classifiers that assign a role to each constituent independently of others, and only modeled limited correlations among roles in a sequence (Toutanova et al., 2008). $$$$$ F-Measure (F1).
Supervised SRL systems have mostly used local classifiers that assign a role to each constituent independently of others, and only modeled limited correlations among roles in a sequence (Toutanova et al., 2008). $$$$$ We evaluate the gains from incorporating this joint information on the Propbank corpus, when using correct syntactic parse trees as input, and when using automatically derived parse trees.

Similar to Toutanova et al (2008), we propose to use global role ordering preferences but in a generative model in contrast to their discriminative one. $$$$$ It is most closely related to the method described in Finkel, Manning, and Ng (2006) and can be seen as an approximation of that method.
Similar to Toutanova et al (2008), we propose to use global role ordering preferences but in a generative model in contrast to their discriminative one. $$$$$ For comparison, the system we submitted to CoNLL 2005 had an F-Measure of 78.45 on the WSJ Test set.
Similar to Toutanova et al (2008), we propose to use global role ordering preferences but in a generative model in contrast to their discriminative one. $$$$$ For gold-standard parse trees, we preprocess the trees to discard empty constituents and strip functional tags.
Similar to Toutanova et al (2008), we propose to use global role ordering preferences but in a generative model in contrast to their discriminative one. $$$$$ This could be done more intelligently by the machine learning model.

Toutanova et al (2008) currently have the best performing SRL system on the Brown corpus test set with an F1 score of 68.81 (80.8 for the WSJtest). $$$$$ Here we review the work most closely related to ours, concentrating on methods for incorporating joint information and for increasing robustness to parser error.
Toutanova et al (2008) currently have the best performing SRL system on the Brown corpus test set with an F1 score of 68.81 (80.8 for the WSJtest). $$$$$ The label C-ARGX is used to represent multi-constituent arguments.
Toutanova et al (2008) currently have the best performing SRL system on the Brown corpus test set with an F1 score of 68.81 (80.8 for the WSJtest). $$$$$ Here we review the work most closely related to ours, concentrating on methods for incorporating joint information and for increasing robustness to parser error.

Indeed, when SRL systems use gold standard parses, they tend to perform extremely well (Toutanova et al, 2008). $$$$$ For example, one global constraint is that the argument phrases cannot overlap—that is, if a node is labeled with a non-NONE label, all of its descendants have to be labeled NONE.
Indeed, when SRL systems use gold standard parses, they tend to perform extremely well (Toutanova et al, 2008). $$$$$ The gains amount to 24.1% error reduction on all arguments and 36.8% on core arguments for gold-standard parse trees on Propbank.
Indeed, when SRL systems use gold standard parses, they tend to perform extremely well (Toutanova et al, 2008). $$$$$ We show how to incorporate these strong dependencies in a statistical joint model with a rich set of features over multiple argument phrases.
Indeed, when SRL systems use gold standard parses, they tend to perform extremely well (Toutanova et al, 2008). $$$$$ Here we review the work most closely related to ours, concentrating on methods for incorporating joint information and for increasing robustness to parser error.

 $$$$$ We also thank Dan Jurafsky for his insightful comments and useful discussions.
 $$$$$ The most basic is to limit occurrences of each kind of argument.
 $$$$$ This research was carried out while all the authors were at Stanford University.

 $$$$$ The gains amount to 24.1% error reduction on all arguments and 36.8% on core arguments for gold-standard parse trees on Propbank.
 $$$$$ We present a model for semantic role labeling that effectively captures the linguistic intuition that a semantic argument frame is a joint structure, with strong dependencies among the arguments.
 $$$$$ The complexity of this algorithm is linear in the number of nodes in the parse tree, which is usually much less than the square of the number of words in the sentence (l2), the complexity of the Punyakanok and Roth (2001) algorithm.
 $$$$$ The weighting parameter for the parser probabilities was R = 1.

These approaches have been shown to be successful for tasks such as parsing and named entity recognition in newswire data (Finkel and Manning, 2009) or semantic role labeling in the Penn Treebank and Brown corpus (Toutanova et al,2008). $$$$$ Figure 13 shows the percentage of argument constituents that are missing in the automatic parse trees produced by Charniak’s parser.
These approaches have been shown to be successful for tasks such as parsing and named entity recognition in newswire data (Finkel and Manning, 2009) or semantic role labeling in the Penn Treebank and Brown corpus (Toutanova et al,2008). $$$$$ Additionally, we explore considering multiple syntactic analyses to cope with parser noise and uncertainty.
These approaches have been shown to be successful for tasks such as parsing and named entity recognition in newswire data (Finkel and Manning, 2009) or semantic role labeling in the Penn Treebank and Brown corpus (Toutanova et al,2008). $$$$$ In order for a model over these variables to capture, for example, the statistical tendency of some semantic roles to occur at most once (e.g., that there is usually at most one constituent labeled AGENT), there must be a dependency link between any two variables.
These approaches have been shown to be successful for tasks such as parsing and named entity recognition in newswire data (Finkel and Manning, 2009) or semantic role labeling in the Penn Treebank and Brown corpus (Toutanova et al,2008). $$$$$ For automatic parse trees, the error reductions are all and core arguments, respectively.

Toutanova et al (2008) and Punyakanok et al (2008) presented a re-ranking model and an integer linear programming model respectively to jointly learn a global optimal semantic roles assignment. $$$$$ However, the arguments of a predicate can be arbitrarily far from each other in the syntactic parse tree and therefore a tree-CRF model is limited in its ability to model dependencies among different arguments.
Toutanova et al (2008) and Punyakanok et al (2008) presented a re-ranking model and an integer linear programming model respectively to jointly learn a global optimal semantic roles assignment. $$$$$ Additionally, we report results for the joint model using the top five Charniak parse trees according to the algorithm described in Section 6.1.
Toutanova et al (2008) and Punyakanok et al (2008) presented a re-ranking model and an integer linear programming model respectively to jointly learn a global optimal semantic roles assignment. $$$$$ A method that models joint information in a different way was proposed by Cohn and Blunsom (2005).
Toutanova et al (2008) and Punyakanok et al (2008) presented a re-ranking model and an integer linear programming model respectively to jointly learn a global optimal semantic roles assignment. $$$$$ This was probably due to the fact that at test time the local classifier produces very poor argument frames near the bottom of the top n for large n. Because the re-ranking model is trained on relatively few good argument frames, it cannot easily rule out very bad frames.

Reranking has become a popular technique for solving various structured prediction tasks, such as phrase-structure (Collins, 2000) and dependency parsing (Hall, 2007), semantic role labeling (Toutanova et al 2008) and machine translation (Shen et al 2004). $$$$$ In addition to performance measures, the figure shows the number of binary features included in the model.
Reranking has become a popular technique for solving various structured prediction tasks, such as phrase-structure (Collins, 2000) and dependency parsing (Hall, 2007), semantic role labeling (Toutanova et al 2008) and machine translation (Shen et al 2004). $$$$$ There has been a substantial amount of work on automatic semantic role labeling, starting with the statistical model of Gildea and Jurafsky (2002).
Reranking has become a popular technique for solving various structured prediction tasks, such as phrase-structure (Collins, 2000) and dependency parsing (Hall, 2007), semantic role labeling (Toutanova et al 2008) and machine translation (Shen et al 2004). $$$$$ Additionally, we explore considering multiple syntactic analyses to cope with parser noise and uncertainty.
Reranking has become a popular technique for solving various structured prediction tasks, such as phrase-structure (Collins, 2000) and dependency parsing (Hall, 2007), semantic role labeling (Toutanova et al 2008) and machine translation (Shen et al 2004). $$$$$ We show how to incorporate these strong dependencies in a statistical joint model with a rich set of features over multiple argument phrases.

For instance, the confusion matrix in (Toutanova et al, 2008) indicates that their model scores 99.5% accuracy on this task. $$$$$ For argument labeling, the number of possible assignments is ≈ 20m, if m is the number of arguments of a verb (typically between 2 and 5), and 20 is the approximate number of possible labels if considering both core and modifying arguments.
For instance, the confusion matrix in (Toutanova et al, 2008) indicates that their model scores 99.5% accuracy on this task. $$$$$ In accord with standard linguistic assumptions, we have shown that there are substantial gains to be had by jointly modeling the argument frames of verbs.
