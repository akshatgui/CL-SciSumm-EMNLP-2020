Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ Therefore, we believe that our results are portable to other frameworks and differently annotated corpora such as dependency corpora.
Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ Each argument node is labeled with two kinds of roles: a surface syntactic role and a deep syntactic role.
Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ Semsubcat.
Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ This two-step approach greatly increases performance over the corresponding SEM-TAG based approach.

However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ Because TAG localizes dependencies, the corresponding values for Supertag path in these sentences would be identical.
However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ Furthermore, not all of the complement semantic roles are found in our test corpus.
However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ We also show that predicting labels from a “lightweight” parser that generates deep syntactic features performs comparably to using a full parser that generates only surface syntactic features.
However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ For example, given the sentence Prices are falling, a supertagger might return the supertagged sentence in Figure 4.

(Chenand Rambow, 2003) use LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing) for SRL. $$$$$ Since each verb meaning corresponds to exactly one roleset, these terms are often used interchangeably.
(Chenand Rambow, 2003) use LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing) for SRL. $$$$$ The outline of this paper is as follows.
(Chenand Rambow, 2003) use LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing) for SRL. $$$$$ The manner in which this is done depends on the kind of grammar that is used.

Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ We first experiment with prediction of semantic roles given gold-standard parses from the test corpus.
Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ Srole.
Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ Aside from voice, we posit that other deep linguistic features may be useful to predict semantic role.
Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ In a further 7% of predicates (tokens), the set of semantic labels on the arguments of that predicate completely disambiguates the roleset.

Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ Improvements along this line may be attained by use of a full TAG parser, such as Chiang (2000) for example.
Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ Our extracted TAGs are derived from Sections 02-21 of the PTB.
Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ The results are shown in Table 3.
Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ As a consequence, adjunct semantic roles (ARGM’s) are basically absent from our test corpus.

Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features.
Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features.
Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ Certain aspects of this trial are always checked for correctness.
Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ Furthermore, not all of the complement semantic roles are found in our test corpus.

Another possibility is to directly extract PropBank-style semantic representations by reforming the grammar extraction algorithm (Chen and Rambow, 2003), and to estimate a disambiguation model using the PropBank. $$$$$ The output of LDA is a partial dependency parse annotated with TAG structures.
Another possibility is to directly extract PropBank-style semantic representations by reforming the grammar extraction algorithm (Chen and Rambow, 2003), and to estimate a disambiguation model using the PropBank. $$$$$ So far, attention has focused on parsing, because the semantically annotated corpora required for learning semantic interpretation have not been available.
Another possibility is to directly extract PropBank-style semantic representations by reforming the grammar extraction algorithm (Chen and Rambow, 2003), and to estimate a disambiguation model using the PropBank. $$$$$ There are also features that specify the syntactic transformations that an elementary tree exhibits.

As a result some of the features that undo long distance movement via trace information in the TreeBank as used in (Chen and Rambow, 2003) cannot be exploited in our model. $$$$$ Improvements along this line may be attained by use of a full TAG parser, such as Chiang (2000) for example.
As a result some of the features that undo long distance movement via trace information in the TreeBank as used in (Chen and Rambow, 2003) cannot be exploited in our model. $$$$$ This should not be taken to mean that deep syntax features are not important.
As a result some of the features that undo long distance movement via trace information in the TreeBank as used in (Chen and Rambow, 2003) cannot be exploited in our model. $$$$$ We believe that such improvement is due to these features better capturing the syntactic information that is relevant for the task of semantic labeling.

(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ Next, we give results on two sets of experiments.
(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ This paper is based upon work supported by the National Science Foundation under the KDD program through a supplement to Grant No.
(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ Section 5 specifies how training and test data that are used in our experiments are derived from the PropBank.
(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features.

Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ In this work, we explore the use of more general, deeper syntax features.
Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ For example, in their inclusion of voice, Gildea and Palmer (2002) note that this deep syntax feature plays an important role in connecting semantic role with surface grammatical function.
Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ Section 23 is used for test data.
Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ The roleset also includes a “descriptor” field which is intended for use during annotation and as documentation, but which does not have any theoretical standing.

As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ Therefore, we believe that our results are portable to other frameworks and differently annotated corpora such as dependency corpora.
As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ For our current work, we use the head percolation table to determine heads of phrases.
As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ In this case, we use the highest performing model from Section 6 in order to label arguments with semantic roles.
As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ Also, these features represent syntactic categories about which there is a broad consensus in the literature.

The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a phrase-structure based SRL framework; (Chenand Rambow, 2003) only considers those complement/adjunct semantic roles that can be localized in LTAG elementary trees, which leads to a loss of over 17% instances of semantic roles even from gold-standard trees. $$$$$ We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features.
The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a phrase-structure based SRL framework; (Chenand Rambow, 2003) only considers those complement/adjunct semantic roles that can be localized in LTAG elementary trees, which leads to a loss of over 17% instances of semantic roles even from gold-standard trees. $$$$$ The features they use in their experiments can be listed as follows.
The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a phrase-structure based SRL framework; (Chenand Rambow, 2003) only considers those complement/adjunct semantic roles that can be localized in LTAG elementary trees, which leads to a loss of over 17% instances of semantic roles even from gold-standard trees. $$$$$ The outline of this paper is as follows.
The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a phrase-structure based SRL framework; (Chenand Rambow, 2003) only considers those complement/adjunct semantic roles that can be localized in LTAG elementary trees, which leads to a loss of over 17% instances of semantic roles even from gold-standard trees. $$$$$ We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features.
