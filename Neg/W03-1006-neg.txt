Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ As a consequence, adjunct semantic roles (ARGM’s) are basically absent from our test corpus.
Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ It takes advantage of the fact that supertagging provides an almost-parse in order to dependency parse the sentence in a simple, deterministic fashion.
Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ Gildea and Palmer (2002) show that semantic role labels can be predicted given syntactic features derived from the PTB with fairly high accuracy.
Similarly, Chen and Rambow (2003) argue that the kind of deep linguistic features we harvest from FrameNet is beneficial for the successful assignment of PropBank roles to constituents, in this case using TAGs generated from PropBank to generate the relevant features. $$$$$ Semantic information includes semantic role as well as semantic subcategorization information.

However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features.
However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ Argument labels are numbered and used consistently across syntactic alternations for the same verb meaning, as shown in Figure 1.
However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ In order to perform this task, we parse this raw text using a combination of supertagging and LDA, which is a method that yields partial dependency parses annotated with TAG structures.
However, in most cases they can only provide a local dependency between predicate and argument for 87% of the argument constituents (Chen and Rambow, 2003), which is too low to provide high SRL accuracy. $$$$$ We have presented various alternative approaches to predicting PropBank role labels using forms of linguistic information that are deeper than the PTB’s surface-syntax labels.

(Chenand Rambow, 2003) use LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing) for SRL. $$$$$ This paper is based upon work supported by the National Science Foundation under the KDD program through a supplement to Grant No.
(Chenand Rambow, 2003) use LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing) for SRL. $$$$$ They may be composed by several well-defined operations to form parse trees.
(Chenand Rambow, 2003) use LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing) for SRL. $$$$$ We believe that such improvement is due to these features better capturing the syntactic information that is relevant for the task of semantic labeling.
(Chenand Rambow, 2003) use LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing) for SRL. $$$$$ Furthermore, not all of the complement semantic roles are found in our test corpus.

Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ Currently there are frames for about 1600 verbs in the corpus, with a total of 2402 rolesets.
Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ These features may either be directly derived from a TAG, such as Supertag path, or indirectly via aspects of supertags, such Task: determine Recall Precision F base + arg 0.65 0.75 0.70 base + bnd 0.48 0.55 0.51 base + bnd + arg 0.48 0.55 0.51 as deep syntactic features like Drole.
Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ As an example, the entry for the verb kick, is given in Figure 2.
Path feature from the derived tree, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ For example, we determine the deep syntactic role of a whmoved element by “undoing” the wh-movement by using the trace information in the PTB.

Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ Basic LDA is a two step procedure.
Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the National Science Foundation.
Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ For example, in their inclusion of voice, Gildea and Palmer (2002) note that this deep syntax feature plays an important role in connecting semantic role with surface grammatical function.
Prop was extracted using the PropBank annotations for ar gument/modifier distinction by a method similar to Chen and Rambow (2003). $$$$$ This paper is based upon work supported by the National Science Foundation under the KDD program through a supplement to Grant No.

Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ The corresponding model for SYNT-TAG performs with 80.34% accuracy.
Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ In particular, we only include as semantic roles those instances in the propbank such that in the extracted TAG they are localized in the same elementary tree.
Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ We now experiment with our surface syntax features: Pred HW, Arg HW, Ssubcat, and Srole.
Although the results can not directly be compared with another work using LTAG (Chen and Rambow, 2003) because their target annotations were limited to those localized in an elementary tree, considering that their target annotations were 87% of core arguments, our results are competitive with their results (82.57/71.41). $$$$$ In a further 7% of predicates (tokens), the set of semantic labels on the arguments of that predicate completely disambiguates the roleset.

Another possibility is to directly extract PropBank-style semantic representations by reforming the grammar extraction algorithm (Chen and Rambow, 2003), and to estimate a disambiguation model using the PropBank. $$$$$ This paper is based upon work supported by the National Science Foundation under the KDD program through a supplement to Grant No.
Another possibility is to directly extract PropBank-style semantic representations by reforming the grammar extraction algorithm (Chen and Rambow, 2003), and to estimate a disambiguation model using the PropBank. $$$$$ This is statistically significant (t-test, p < 0.05), albeit a small improvement.
Another possibility is to directly extract PropBank-style semantic representations by reforming the grammar extraction algorithm (Chen and Rambow, 2003), and to estimate a disambiguation model using the PropBank. $$$$$ We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features.
Another possibility is to directly extract PropBank-style semantic representations by reforming the grammar extraction algorithm (Chen and Rambow, 2003), and to estimate a disambiguation model using the PropBank. $$$$$ Since each verb meaning corresponds to exactly one roleset, these terms are often used interchangeably.

As a result some of the features that undo long distance movement via trace information in the TreeBank as used in (Chen and Rambow, 2003) cannot be exploited in our model. $$$$$ We use the feature set mentioned in Section 3 as well as features derived from TAGs mentioned in Section 4.
As a result some of the features that undo long distance movement via trace information in the TreeBank as used in (Chen and Rambow, 2003) cannot be exploited in our model. $$$$$ Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the National Science Foundation.
As a result some of the features that undo long distance movement via trace information in the TreeBank as used in (Chen and Rambow, 2003) cannot be exploited in our model. $$$$$ We first experiment with prediction of semantic roles given gold-standard parses from the test corpus.
As a result some of the features that undo long distance movement via trace information in the TreeBank as used in (Chen and Rambow, 2003) cannot be exploited in our model. $$$$$ We also show that predicting labels from a “lightweight” parser that generates deep syntactic features performs comparably to using a full parser that generates only surface syntactic features.

(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ These features may either be directly derived from a TAG, such as Supertag path, or indirectly via aspects of supertags, such Task: determine Recall Precision F base + arg 0.65 0.75 0.70 base + bnd 0.48 0.55 0.51 base + bnd + arg 0.48 0.55 0.51 as deep syntactic features like Drole.
(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ The extraction procedure determines the structure of each elementary tree by localizing dependencies through the use of heuristics.
(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ Improvements along this line may be attained by use of a full TAG parser, such as Chiang (2000) for example.
(Chen and Rambow, 2003) discuss amodel for SRL that uses LTAG-based decomposition of parse trees (as is typically done for statistical LTAG parsing). $$$$$ Therefore, we believe that our results are portable to other frameworks and differently annotated corpora such as dependency corpora.

Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ In particular, we only include as semantic roles those instances in the propbank such that in the extracted TAG they are localized in the same elementary tree.
Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ IIS-98-17434.
Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ This may in itself generate useful features because TAG structures typically relate closely syntactic arguments with their corresponding predicate.
Instead of using the typical parse tree features used in typical SRL models, (Chen and Rambow, 2003) uses the path within the elementary tree from the predicate to the constituent argument. $$$$$ Also, these features represent syntactic categories about which there is a broad consensus in the literature.

As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ IIS-98-17434.
As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ We use the feature set mentioned in Section 3 as well as features derived from TAGs mentioned in Section 4.
As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ So far, attention has focused on parsing, because the semantically annotated corpora required for learning semantic interpretation have not been available.
As a result, if we do not compare the machine learning methods involved in the two approaches, but rather the features used in learning, our features are a natural generalization of (Chen and Rambow, 2003). $$$$$ We also experiment with semantic features derived from the PropBank.

The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG $$$$$ Furthermore, training data for our experiments are always derived from these sections.
The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG $$$$$ Phrase Type.
The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG $$$$$ This paper is based upon work supported by the National Science Foundation under the KDD program through a supplement to Grant No.
The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG $$$$$ Argument labels are numbered and used consistently across syntactic alternations for the same verb meaning, as shown in Figure 1.
