A similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi (2002). $$$$$ Unfortunately, the state of the art in NLP does not provide us access to semantic interpreters and general purpose knowledge bases that would support these kinds of inferences.
A similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi (2002). $$$$$ We have also built a six-way classifier to distinguish between all six relation types.
A similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi (2002). $$$$$ We assume that a discourse relation that holds between two text spans, , is determined by the word pairs in the cartesian product defined over the words in the two text spans .
A similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi (2002). $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.

Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi (2002) in two important ways. $$$$$ This result is consistent with the discourse model proposed by Knott et al. (2001), who suggest that ELABORATION relations are too ill-defined to be part of any discourse theory.
Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi (2002) in two important ways. $$$$$ Acknowledgments.
Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi (2002) in two important ways. $$$$$ To test this hypothesis, we decided to carry out a second experiment that used as predictors only a subset of the word pairs in the cartesian product defined over the words in two given text spans.

Inspired by Marcu and Echihabi (2002), to construct relatively low noise discourse instances for unsupervised methods using cue phrases, we grouped the 13 relations into the following 5 relations: Contrast is a union of Antithesis, Concession, Otherwise and Contrast from RST. $$$$$ We determine the most likely discourse relation that holds between two text spans and by taking the maximum over , which according to Bayes rule, amounts to taking the maximum over .
Inspired by Marcu and Echihabi (2002), to construct relatively low noise discourse instances for unsupervised methods using cue phrases, we grouped the 13 relations into the following 5 relations: Contrast is a union of Antithesis, Concession, Otherwise and Contrast from RST. $$$$$ We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.
Inspired by Marcu and Echihabi (2002), to construct relatively low noise discourse instances for unsupervised methods using cue phrases, we grouped the 13 relations into the following 5 relations: Contrast is a union of Antithesis, Concession, Otherwise and Contrast from RST. $$$$$ We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.
Inspired by Marcu and Echihabi (2002), to construct relatively low noise discourse instances for unsupervised methods using cue phrases, we grouped the 13 relations into the following 5 relations: Contrast is a union of Antithesis, Concession, Otherwise and Contrast from RST. $$$$$ To build such systems, we train a family of Naive Bayes classifiers on a large set of examples that are generated automatically from two corpora: a corpus of 41,147,805 English sentences that have no annotations, and BLIPP, a corpus of 1,796,386 automatically parsed English sentences (Charniak, 2000), which is available from the Linguistic Data Consortium (www.ldc.upenn.edu).

Cue-phrase-based patterns could find only limited number of discourse instances with high precision (Marcu and Echihabi, 2002). $$$$$ The learning curves in Figure 1 are illuminating as they show that if one uses as features only the most representative word pairs, one needs only about 100,000 training examples to achieve the same level of performance one achieves using 1,000,000 training examples and features defined over all word pairs.
Cue-phrase-based patterns could find only limited number of discourse instances with high precision (Marcu and Echihabi, 2002). $$$$$ John is good in math and sciences.
Cue-phrase-based patterns could find only limited number of discourse instances with high precision (Marcu and Echihabi, 2002). $$$$$ We did this because when trying to determine whether a CONTRAST relation holds between two spans of texts separated by the cue phrase “but”, for example, we want to take advantage of the cue phrase occurrence as well.

Nouns (except for named entities) and verbs were most representative words in discourse recognition (Marcu and Echihabi, 2002). $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.
Nouns (except for named entities) and verbs were most representative words in discourse recognition (Marcu and Echihabi, 2002). $$$$$ For example, the RST-annotated corpus of Carlson et al. (2001) contains 238 CONTRAST relations that hold between two adjacent elementary discourse units.
Nouns (except for named entities) and verbs were most representative words in discourse recognition (Marcu and Echihabi, 2002). $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.
Nouns (except for named entities) and verbs were most representative words in discourse recognition (Marcu and Echihabi, 2002). $$$$$ We employed our classifiers on the manually labeled examples extracted from Carlson et al.’s corpus (2001).

 $$$$$ Overall, the performance of the systems trained on the most representative word pairs in the BLIPP corpus is clearly lower than the performance of the systems trained on all the word pairs in the Raw corpus.
 $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.
 $$$$$ Rather, it raises some new, interesting questions because the lexical patterns learned by our algorithms can be interpreted as empirical proof of existence for discourse relations.
 $$$$$ In the field of discourse research, it is now widely agreed that sentences/clauses are usually not understood in isolation, but in relation to other sentences/clauses.

Presently, there exist methods for learning oppositional terms (Marcu and Echihabi, 2002) and paraphrase learning has been thoroughly studied, but successfully extending these techniques to learn incompatible phrases poses difficulties because of the data distribution. $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.
Presently, there exist methods for learning oppositional terms (Marcu and Echihabi, 2002) and paraphrase learning has been thoroughly studied, but successfully extending these techniques to learn incompatible phrases poses difficulties because of the data distribution. $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.

Some of existing works attempt to perform relation recognition without hand-annotated corpora (Marcu and Echihabi, 2002), (Sporleder and Lascarides, 2008) and (Blair-Goldensohn, 2007). $$$$$ To test this hypothesis, we need to solve two problems.
Some of existing works attempt to perform relation recognition without hand-annotated corpora (Marcu and Echihabi, 2002), (Sporleder and Lascarides, 2008) and (Blair-Goldensohn, 2007). $$$$$ As previous research in linguistics (Halliday and Hasan, 1976; Schiffrin, 1987) and computational linguistics (Marcu, 2000) show, some occurrences of “but” and “because” do not have a discourse function; and others signal other relations than CONTRAST and CAUSE-EXPLANATION.
Some of existing works attempt to perform relation recognition without hand-annotated corpora (Marcu and Echihabi, 2002), (Sporleder and Lascarides, 2008) and (Blair-Goldensohn, 2007). $$$$$ We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.
Some of existing works attempt to perform relation recognition without hand-annotated corpora (Marcu and Echihabi, 2002), (Sporleder and Lascarides, 2008) and (Blair-Goldensohn, 2007). $$$$$ So what shall we do when no discourse markers are used?

(Marcu and Echihabi, 2002) used a pattern based approach to extract instances of discourse relations such as Contrast and Elaboration from unlabeled corpora. $$$$$ The extraction patterns described in Table 2 enable us to solve this problem.1 Second, given vast amounts of training material, we need a means to learn which pairs of lexical items are likely to co-occur in conjunction with each discourse relation and a means to apply the learned parameters to any pair of text spans in order to determine the discourse relation that holds between them.
(Marcu and Echihabi, 2002) used a pattern based approach to extract instances of discourse relations such as Contrast and Elaboration from unlabeled corpora. $$$$$ Consider, for example, the sentence/clause pairs below. from the sale of expensive, high-technology systems like laser-designated missiles, aircraft electronic warfare systems, tactical radios, anti-radiation bombs and battlefield mobility systems.
(Marcu and Echihabi, 2002) used a pattern based approach to extract instances of discourse relations such as Contrast and Elaboration from unlabeled corpora. $$$$$ We did this because when trying to determine whether a CONTRAST relation holds between two spans of texts separated by the cue phrase “but”, for example, we want to take advantage of the cue phrase occurrence as well.
(Marcu and Echihabi, 2002) used a pattern based approach to extract instances of discourse relations such as Contrast and Elaboration from unlabeled corpora. $$$$$ In order to collect training cases, we mined in an unsupervised manner two corpora.

There are other efforts that attempt to extend the work of (Marcu and Echihabi, 2002). $$$$$ However, when we run our CONTRAST vs. ELABORATION classifier on these examples, we can label correctly 60 of the 61 cue-phrase marked relations and, in addition, we can also label 123 of the 177 relations that are not marked explicitly with cue phrases.
There are other efforts that attempt to extend the work of (Marcu and Echihabi, 2002). $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.
There are other efforts that attempt to extend the work of (Marcu and Echihabi, 2002). $$$$$ To these examples, we added 58,000 NO-RELATION-SAME-TEXT and 58,000 NO-RELATION-DIFFERENT-TEXTS relations.

(Saito et al., 2006) followed the method of (Marcu and Echihabi, 2002) and conducted experiments with combination of cross-argument word pairs and phrasal patterns as features to recognize implicit relations between adjacent sentences in a Japanese corpus. $$$$$ We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.
(Saito et al., 2006) followed the method of (Marcu and Echihabi, 2002) and conducted experiments with combination of cross-argument word pairs and phrasal patterns as features to recognize implicit relations between adjacent sentences in a Japanese corpus. $$$$$ First, we need a means to acquire vast amounts of background knowledge from which we can derive, for example, that the word pairs good – fails and embargo – legally are good indicators of CONTRAST relations.
(Saito et al., 2006) followed the method of (Marcu and Echihabi, 2002) and conducted experiments with combination of cross-argument word pairs and phrasal patterns as features to recognize implicit relations between adjacent sentences in a Japanese corpus. $$$$$ If we had access to robust semantic interpreters, we could, for example, infer from sentence 1.a that “cannot buy arms legally(libya)”, infer from sentence 1.b that “can buy arms legally(rwanda)”, use our background knowledge in order to infer that “similar(libya,rwanda)”, and apply Hobbs’s (1990) definitions of discourse relations to arrive at the conclusion that a CONTRAST relation holds between the sentences in (1).

(Blair-Goldensohn, 2007) extended the work of (Marcu and Echihabi, 2002) by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing. $$$$$ As in the case of CONTRAST and CONDITION, the NO-RELATION examples are also noisy because long distance relations are common in well-written texts.
(Blair-Goldensohn, 2007) extended the work of (Marcu and Echihabi, 2002) by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing. $$$$$ We wrote a simple program that extracted the nouns, verbs, and cue phrases in each sentence/clause.

To overcome the shortage of manually annotated training data, (Marcu and Echihabi, 2002) proposed a pattern-based approach to automatically generate training data from raw corpora. $$$$$ We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.

(Sporleder and Lascarides, 2008) conducted a study of the pattern-based approach presented by (Marcu and Echihabi, 2002) and showed that the model built on synthetical implicit data has not generalize well on natural implicit data. $$$$$ We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.
(Sporleder and Lascarides, 2008) conducted a study of the pattern-based approach presented by (Marcu and Echihabi, 2002) and showed that the model built on synthetical implicit data has not generalize well on natural implicit data. $$$$$ The discourse relation definitions proposed by others (Mann and Thompson, 1988; Lascarides and Asher, 1993; Knott and Sanders, 1998) are not easier to apply either because they assume the ability to automatically derive, in addition to the semantics of the text spans, the intentions and illocutions associated with them as well.
(Sporleder and Lascarides, 2008) conducted a study of the pattern-based approach presented by (Marcu and Echihabi, 2002) and showed that the model built on synthetical implicit data has not generalize well on natural implicit data. $$$$$ In Hobbs’s theory (1990), we would also label the relation between 2.a and 2.b as EXPLANATION because the event asserted by 2.b CAUSED or could CAUSE the event asserted in 2.a.
(Sporleder and Lascarides, 2008) conducted a study of the pattern-based approach presented by (Marcu and Echihabi, 2002) and showed that the model built on synthetical implicit data has not generalize well on natural implicit data. $$$$$ If we assume that the word pairs in the cartesian product are independent, is equivalent to .


(Marcu and Echihabi 2002) proposed a method to identify discourse relations between text segments using Naive Bayes classifiers trained on a huge corpus. $$$$$ In our paper, we show that massive amounts of data can have a major impact on discourse processing research as well.
(Marcu and Echihabi 2002) proposed a method to identify discourse relations between text segments using Naive Bayes classifiers trained on a huge corpus. $$$$$ First, a discourse relation recognizer would enable the development of improved discourse parsers and, consequently, of high performance single document summarizers (Marcu, 2000).
(Marcu and Echihabi 2002) proposed a method to identify discourse relations between text segments using Naive Bayes classifiers trained on a huge corpus. $$$$$ Over the last thirty years, the nature, number, and taxonomy of discourse relations have been among the most controversial issues in text/discourse linguistics.

When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc., the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by (Marcu and Echihabi 2002) of 49.7%. $$$$$ The analysis above is informative only from a machine learning perspective.
When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc., the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by (Marcu and Echihabi 2002) of 49.7%. $$$$$ Our results suggest that it may be possible to develop fully automatic techniques for defining empirically justified discourse relations.
When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc., the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by (Marcu and Echihabi 2002) of 49.7%. $$$$$ What the experiments manually labeled RST relations that hold between elementary discourse units.
When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc., the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by (Marcu and Echihabi 2002) of 49.7%. $$$$$ But ultimately, all these theories acknowledge that there are such things as CONTRAST, CAUSE, and EXPLANATION relations.

An unsupervised approach was proposed to recognize discourse relations in (Marcu and Echihabi, 2002), which extracts discourse relations that hold between arbitrary spans of text making use of cue phrases. $$$$$ To each text span in the BLIPP corpus corresponds a parse tree (Charniak, 2000).
An unsupervised approach was proposed to recognize discourse relations in (Marcu and Echihabi, 2002), which extracts discourse relations that hold between arbitrary spans of text making use of cue phrases. $$$$$ We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.

We adopt the approach of Marcu and Echihabi (2002), using a small set of patterns to build relation models, and extend their work by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing. $$$$$ We hypothesize that we can determine that a CONTRAST relation holds between the sentences in (3) even if we cannot semantically interpret the two sentences, simply because our background knowledge tells us that good and fails are good indicators of contrastive statements.
We adopt the approach of Marcu and Echihabi (2002), using a small set of patterns to build relation models, and extend their work by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing. $$$$$ In Lascarides and Asher’s theory (1993), we would label the relation between 2.a and 2.b as EXPLANATION because the event in 2.b explains why the event in 2.a happened (perhaps by CAUSING it).
We adopt the approach of Marcu and Echihabi (2002), using a small set of patterns to build relation models, and extend their work by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing. $$$$$ For example, the results show that the classifiers can be used to distinguish between CONTRAST and CAUSE-EXPLANATION-EVIDENCE relations, as defined in RST, but not so well between ELABORATION and any other relation.

We draw on and extend the work of Marcu and Echihabi (2002). $$$$$ In order to build a discourse relation classifier, one first needs to decide what relation definitions one is going to use.
We draw on and extend the work of Marcu and Echihabi (2002). $$$$$ Given the high level of interest in explaining the nature of these relations and in providing definitions for them (Mann and Thompson, 1988; Hobbs, 1990; Martin, 1992; Lascarides and Asher, 1993; Hovy and Maier, 1993; Knott and Sanders, 1998), it is surprising that there are no robust programs capable of identifying discourse relations that hold between arbitrary spans of text.
We draw on and extend the work of Marcu and Echihabi (2002). $$$$$ This work was supported by the National Science Foundation under grant number IIS-0097846 and by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program under contract number MDA908-02-C-0007.
We draw on and extend the work of Marcu and Echihabi (2002). $$$$$ First, a discourse relation recognizer would enable the development of improved discourse parsers and, consequently, of high performance single document summarizers (Marcu, 2000).
