For the identification and labeling steps, we train a maximum entropy classifier (Berger et al, 1996) over sections 02-21 of a version of the CCGbank corpus (Hockenmaier and Steedman, 2007) that has been augmented by projecting the Propbank semantic annotations (Boxwell and White, 2008). $$$$$ Hockenmaier and Steedman (2002) show that this lexical coverage problem does in practice have a significant impact on overall parsing accuracy.
For the identification and labeling steps, we train a maximum entropy classifier (Berger et al, 1996) over sections 02-21 of a version of the CCGbank corpus (Hockenmaier and Steedman, 2007) that has been augmented by projecting the Propbank semantic annotations (Boxwell and White, 2008). $$$$$ This lexicon could be used by any CCG parser, although morphological generalization (which is beyond the scope of the present paper) and ways to treat unknown words are likely to be necessary to obtain a more complete lexicon.
For the identification and labeling steps, we train a maximum entropy classifier (Berger et al, 1996) over sections 02-21 of a version of the CCGbank corpus (Hockenmaier and Steedman, 2007) that has been augmented by projecting the Propbank semantic annotations (Boxwell and White, 2008). $$$$$ It also provides a “surface-compositional” syntax–semantics interface, in which monotonic rules of semantic composition are paired one-to-one with rules of syntactic composition.

We used the CCGbank-style dependency output of the parser (Hockenmaier and Steedman,2007), which is a directed graph of head-child relations labelled with the head's lexical category and the argument slot filled by the child. $$$$$ MJS acknowledges support from the Scottish Enterprise Edinburgh–Stanford Link (NSF IIS-041628 (R39058)) and EU IST grant PACOPLUS (FP6-2004-IST-4-27657).
We used the CCGbank-style dependency output of the parser (Hockenmaier and Steedman,2007), which is a directed graph of head-child relations labelled with the head's lexical category and the argument slot filled by the child. $$$$$ In this, they differ crucially from the bilexical surface dependencies used by the parsing models of Collins (1999) and Charniak (2000) and returned by the dependency parser of McDonald, Crammer, and Pereira (2005).
We used the CCGbank-style dependency output of the parser (Hockenmaier and Steedman,2007), which is a directed graph of head-child relations labelled with the head's lexical category and the argument slot filled by the child. $$$$$ The resulting corpus, CCGbank, includes 99.4% of the sentences in the Penn Treebank.
We used the CCGbank-style dependency output of the parser (Hockenmaier and Steedman,2007), which is a directed graph of head-child relations labelled with the head's lexical category and the argument slot filled by the child. $$$$$ JH also acknowledges support by an EPSRC studentship and the Edinburgh Language Technology Group, and by NSF ITR grant 0205456 at the University of Pennsylvania.

CCGbank (Hockenmaier and Steedman, 2007) is a corpus of CCG derivations that was semiautomatically converted from the Wall Street Journal section of the Penn treebank. $$$$$ Infinitival and Participial VPs, Gerunds.
CCGbank (Hockenmaier and Steedman, 2007) is a corpus of CCG derivations that was semiautomatically converted from the Wall Street Journal section of the Penn treebank. $$$$$ We discuss the implications of our findings for the extraction of other linguistically expressive grammars from the Treebank, and for the design offuture treebanks.
CCGbank (Hockenmaier and Steedman, 2007) is a corpus of CCG derivations that was semiautomatically converted from the Wall Street Journal section of the Penn treebank. $$$$$ The resulting corpus, CCGbank, includes 99.4% of the sentences in the Penn Treebank.
CCGbank (Hockenmaier and Steedman, 2007) is a corpus of CCG derivations that was semiautomatically converted from the Wall Street Journal section of the Penn treebank. $$$$$ The resulting corpus, CCGbank, includes 99.4% of the sentences in the Penn Treebank.

For example, declarative sentences are S [dcl], wh-questions are S [wq] and sentence fragments are S [frg] (Hockenmaier and Steedman, 2007). $$$$$ article presents an algorithm for translating the Penn Treebank into a corpus of Combinatory Categorial Grammar (CCG) derivations augmented with local and long-range word–word dependencies.
For example, declarative sentences are S [dcl], wh-questions are S [wq] and sentence fragments are S [frg] (Hockenmaier and Steedman, 2007). $$$$$ The resulting corpus, CCGbank, includes 99.4% of the sentences in the Penn Treebank.
For example, declarative sentences are S [dcl], wh-questions are S [wq] and sentence fragments are S [frg] (Hockenmaier and Steedman, 2007). $$$$$ The translation algorithm presumes that the trees in the Penn Treebank map directly to the desired CCG derivations.

Bos et al (2009) created a CCGbank from an Italian dependency tree bank by converting dependency trees into phrase structure trees and then applying an algorithm similar to Hockenmaier and Steedman (2007). $$$$$ In a future version of CCGbank, it may be possible to follow Shen and Joshi (2005) in using the semantic roles of the Proposition Bank (Palmer, Gildea, and Kingsbury 2005) to distinguish arguments and adjuncts.
Bos et al (2009) created a CCGbank from an Italian dependency tree bank by converting dependency trees into phrase structure trees and then applying an algorithm similar to Hockenmaier and Steedman (2007). $$$$$ If these rules apply recursively to their own output, they can generate an infinite set of category types, leading to a shift in generative power from context-free to recursively enumerable (Carpenter 1991, 1992).
Bos et al (2009) created a CCGbank from an Italian dependency tree bank by converting dependency trees into phrase structure trees and then applying an algorithm similar to Hockenmaier and Steedman (2007). $$$$$ In order to eliminate some of the noise in the original annotation and to obtain linguistically adequate derivations that conform to the “correct” analyses proposed in the literature, considerable preprocessing was necessary.

The resource used for building wide-coverage CCG parsers of English is CCGbank (Hockenmaier and Steedman, 2007), a version of the Penn Treebank in which each phrase-structure tree has been transformed into a normal-form CCG derivation. $$$$$ In the Treebank, this information is not explicit.
The resource used for building wide-coverage CCG parsers of English is CCGbank (Hockenmaier and Steedman, 2007), a version of the Penn Treebank in which each phrase-structure tree has been transformed into a normal-form CCG derivation. $$$$$ The other case where small clauses are used in the Treebank includes absolute with and though constructions (with the limit in effect).
The resource used for building wide-coverage CCG parsers of English is CCGbank (Hockenmaier and Steedman, 2007), a version of the Penn Treebank in which each phrase-structure tree has been transformed into a normal-form CCG derivation. $$$$$ The Treebank uses various types of null elements and traces to encode non-local dependencies.
The resource used for building wide-coverage CCG parsers of English is CCGbank (Hockenmaier and Steedman, 2007), a version of the Penn Treebank in which each phrase-structure tree has been transformed into a normal-form CCG derivation. $$$$$ It is available from the Linguistic Data Consortium, and has been used to train widecoverage statistical parsers that obtain state-of-the-art rates of dependency recovery.

Our experiments were performed using CCGBank (Hockenmaier and Steedman, 2007), which was split into three subsets for training (Sections 02-21), development testing (Section 00) and the final test (Section 23). $$$$$ It is a distinctive property of CCG that all syntactic rules are purely type-driven, unlike traditional structure-dependent transformations.
Our experiments were performed using CCGBank (Hockenmaier and Steedman, 2007), which was split into three subsets for training (Sections 02-21), development testing (Section 00) and the final test (Section 23). $$$$$ In order to obtain linguistically adequate CCG analyses, and to eliminate noise and inconsistencies in the original annotation, an extensive analysis of the constructions and annotations in the Penn Treebank was called for, and a substantial number of changes to the Treebank were necessary.
Our experiments were performed using CCGBank (Hockenmaier and Steedman, 2007), which was split into three subsets for training (Sections 02-21), development testing (Section 00) and the final test (Section 23). $$$$$ CCGbank does not distinguish between control and raising.
Our experiments were performed using CCGBank (Hockenmaier and Steedman, 2007), which was split into three subsets for training (Sections 02-21), development testing (Section 00) and the final test (Section 23). $$$$$ Noun Phrases and Quantifier Phrases.

CCGbank was derived from the PTB, and so it might be considered that converting back to the PTB would be a relatively easy task, by essentially reversing the mapping Hockenmaier and Steedman (2007) used to create CCGbank. $$$$$ This article presents an algorithm for translating the Penn Treebank into a corpus of Combinatory Categorial Grammar (CCG) derivations augmented with local and long-range word–word dependencies.
CCGbank was derived from the PTB, and so it might be considered that converting back to the PTB would be a relatively easy task, by essentially reversing the mapping Hockenmaier and Steedman (2007) used to create CCGbank. $$$$$ A correct analysis would assign a functor category S[nom]\NP (or perhaps NP[prd]\NP) to predicative NP arguments of verbs like makes, not only in these examples, but also in copular sentences and appositives.
CCGbank was derived from the PTB, and so it might be considered that converting back to the PTB would be a relatively easy task, by essentially reversing the mapping Hockenmaier and Steedman (2007) used to create CCGbank. $$$$$ A fundamental assumption behind attempts at the automatic translation of syntactically annotated corpora into different grammatical formalisms such as CCG, TAG, HPSG, or LFG is that the analyses that are captured in the original annotation can be mapped directly (or, at least, without too much additional work) into the desired analyses in the target formalism.

In our experience, trying to add number and animacy agreement constraints to a grammar induced from the CCGbank (Hockenmaier and Steedman, 2007) turned out to be surprisingly difficult, as hard constraints often ended up breaking examples that were working without such constraints, due to exceptions, sub-regularities and acceptable variation in the data. $$$$$ In the Penn Treebank, all relative clauses are attached at the noun phrase level.
In our experience, trying to add number and animacy agreement constraints to a grammar induced from the CCGbank (Hockenmaier and Steedman, 2007) turned out to be surprisingly difficult, as hard constraints often ended up breaking examples that were working without such constraints, due to exceptions, sub-regularities and acceptable variation in the data. $$$$$ Similarly, if C is of the form X\$, all outermost backward arguments \$ (and syntactic features) are stripped off from C to obtain C'.
In our experience, trying to add number and animacy agreement constraints to a grammar induced from the CCGbank (Hockenmaier and Steedman, 2007) turned out to be surprisingly difficult, as hard constraints often ended up breaking examples that were working without such constraints, due to exceptions, sub-regularities and acceptable variation in the data. $$$$$ Because of this preprocessing, the dependency structures in CCGbank are likely to be more consistent than those extracted directly from the Treebank via heuristics such as those given by Magerman (1994) and Collins (1999), and therefore may also be of immediate use for dependency-based approaches.

For example, CCGbank (Hockenmaier and Steedman, 2007) contains 1241 distinct supertags (lexical categories) and the most ambiguous word has 126 supertags. $$$$$ Lexical categories have one lexical head, the word itself—for example, He for the first NP, and is for the (S[dcl]\NP)/(S[b]\NP).
For example, CCGbank (Hockenmaier and Steedman, 2007) contains 1241 distinct supertags (lexical categories) and the most ambiguous word has 126 supertags. $$$$$ Although it is tempting to analyze them similarly to parentheticals, quotations often span sentence boundaries, and consequently quotation marks appear to be unbalanced at the sentence level.
For example, CCGbank (Hockenmaier and Steedman, 2007) contains 1241 distinct supertags (lexical categories) and the most ambiguous word has 126 supertags. $$$$$ NPs are flat as well, with all complex modifiers appearing at the same NP level, and compound nouns typically lacking any internal structure.

CCGbank was created by semiautomatically converting the Penn Treebank to CCG derivations (Hockenmaier and Steedman, 2007). $$$$$ Typical examples of rare but correct and necessary categories are relative pronouns in pied-piping constructions, or verbs which take expletive subjects.
CCGbank was created by semiautomatically converting the Penn Treebank to CCG derivations (Hockenmaier and Steedman, 2007). $$$$$ The dummy nodes inserted during binarization receive the same category as the conjuncts, but additionally carry a feature [conj]: An additional modification of the grammar is necessary to deal with “unlike coordinate phrases” (UCP), namely, coordinate constructions where the conjuncts do not belong to the same syntactic category: Such constructions are difficult for any formalism.
CCGbank was created by semiautomatically converting the Penn Treebank to CCG derivations (Hockenmaier and Steedman, 2007). $$$$$ It is available from the Linguistic Data Consortium, and has been used to train widecoverage statistical parsers that obtain state-of-the-art rates of dependency recovery.
CCGbank was created by semiautomatically converting the Penn Treebank to CCG derivations (Hockenmaier and Steedman, 2007). $$$$$ As shown in Figure 1, in many cases, a more elegant (and general) analysis can be obtained if we allow modifiers to compose with the head.

By automatically transforming the constituent structure trees annotated in PTB to other linguistic formalisms, such as dependency grammar, and combinatory categorical grammar (Hockenmaier and Steedman, 2007), many syntactic parser other than the CFG formalism were also developed. $$$$$ Multi-Word Expressions.
By automatically transforming the constituent structure trees annotated in PTB to other linguistic formalisms, such as dependency grammar, and combinatory categorical grammar (Hockenmaier and Steedman, 2007), many syntactic parser other than the CFG formalism were also developed. $$$$$ Here, we also assume that the subordinating conjunction takes the individual constituents in the small clause as complements, and with obtains therefore the category ((S/S)/PP)/NP.
By automatically transforming the constituent structure trees annotated in PTB to other linguistic formalisms, such as dependency grammar, and combinatory categorical grammar (Hockenmaier and Steedman, 2007), many syntactic parser other than the CFG formalism were also developed. $$$$$ It is available from the Linguistic Data Consortium, and has been used to train widecoverage statistical parsers that obtain state-of-the-art rates of dependency recovery.
By automatically transforming the constituent structure trees annotated in PTB to other linguistic formalisms, such as dependency grammar, and combinatory categorical grammar (Hockenmaier and Steedman, 2007), many syntactic parser other than the CFG formalism were also developed. $$$$$ In the Treebank, this information is not explicit.

We agree; however, our ultimate motivation is to use this work to tackle bootstrapping from very small tag dictionaries or dictionaries obtained from linguists or resources other than a corpus, and for tag sets that are more ambiguous (e.g., super tagging for CCGbank (Hockenmaier and Steedman, 2007)). $$$$$ The fact that both category types and rule instances are also Zipfian for CCGbank, despite its binarized rules, shows that the phenomenon is not just due to the Treebank annotation with its very flat rules.
We agree; however, our ultimate motivation is to use this work to tackle bootstrapping from very small tag dictionaries or dictionaries obtained from linguists or resources other than a corpus, and for tag sets that are more ambiguous (e.g., super tagging for CCGbank (Hockenmaier and Steedman, 2007)). $$$$$ The Treebank treats constructions such as the following as small clauses: Pollard and Sag (1992) and Steedman (1996) argue against this analysis on the basis of extractions like what does the country want forgiven, which suggest that these cases should rather be treated as involving two complements.

This logical form can be expressed in many ways; we will focus on the dependency representation used in CCGbank (Hockenmaier and Steedman, 2007). $$$$$ Although some non-terminal nodes carry additional function tags, such as -SBJ (subject) or -TMP (temporal modifier), truly problematic cases such as prepositional phrases are often marked with tags such as -CLR (“closely related”) or -DIR (“direction”), which are not always reliable or consistent indicators that a constituent is a modifier or an argument.
This logical form can be expressed in many ways; we will focus on the dependency representation used in CCGbank (Hockenmaier and Steedman, 2007). $$$$$ Although some non-terminal nodes carry additional function tags, such as -SBJ (subject) or -TMP (temporal modifier), truly problematic cases such as prepositional phrases are often marked with tags such as -CLR (“closely related”) or -DIR (“direction”), which are not always reliable or consistent indicators that a constituent is a modifier or an argument.
This logical form can be expressed in many ways; we will focus on the dependency representation used in CCGbank (Hockenmaier and Steedman, 2007). $$$$$ Their treatment is discussed in Sections 6.2 and 6.3.
This logical form can be expressed in many ways; we will focus on the dependency representation used in CCGbank (Hockenmaier and Steedman, 2007). $$$$$ There seems to be a similar ordering over alternative formalisms from straightforward to less straightforward for this approach.

All experiments were conducted on CCGBank (Hockenmaier and Steedman, 2007), a right-most normal-form CCG version of the Penn Treebank. $$$$$ Although these dependencies are only an approximation of the full semantic interpretation that can in principle be obtained from a CCG, they may prove useful for tasks such as summarization and question answering (Clark, Steedman, and Curran 2004).
All experiments were conducted on CCGBank (Hockenmaier and Steedman, 2007), a right-most normal-form CCG version of the Penn Treebank. $$$$$ Without function composition, the category of regularly would have to be ((S\NP)/NP)\((S\NP)/NP), but (crossed) composition allows the ordinary category (S\NP)\(S\NP) to also work in this case.
All experiments were conducted on CCGBank (Hockenmaier and Steedman, 2007), a right-most normal-form CCG version of the Penn Treebank. $$$$$ (47) 6.4.1 Argument Cluster Coordination.

The grammar is automatically extracted from a version of the CCGbank (Hockenmaier and Steedman, 2007) with Propbank (Palmer et al, 2005) roles projected onto it (Boxwell and White, 2008). $$$$$ Disregarding the most common preprocessing step (the insertion of a noun level, which is required in virtually all sentences), preprocessing affects almost 43% of all sentences.
The grammar is automatically extracted from a version of the CCGbank (Hockenmaier and Steedman, 2007) with Propbank (Palmer et al, 2005) roles projected onto it (Boxwell and White, 2008). $$$$$ In order to obtain linguistically adequate CCG analyses, and to eliminate noise and inconsistencies in the original annotation, an extensive analysis of the constructions and annotations in the Penn Treebank was called for, and a substantial number of changes to the Treebank were necessary.

Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al, 1993). $$$$$ In this article and in CCGbank, we approximate such semantic interpretations with dependency graphs that include most semantically relevant non-anaphoric local and long-range dependencies.
Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al, 1993). $$$$$ NPs are flat as well, with all complex modifiers appearing at the same NP level, and compound nouns typically lacking any internal structure.
Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al, 1993). $$$$$ Two missing rules are instances of type-raised argument types combining with a verb of a rare type.
Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al, 1993). $$$$$ Therefore, we need to insert an additional noun level, which also includes the adjuncts Dutch and publishing, which receive both the category N/N: However, because nominal compounds in the Treebank have no internal bracketing, we always assume a right-branching analysis, and are therefore not able to obtain the correct dependencies for cases such as (lung cancer) deaths.

We use CCGBank (Hockenmaier and Steedman, 2007) for experimental data. $$$$$ It has been successfully applied to the analysis of coordination, relative clauses and related constructions, intonation structure, binding and control, and quantifier scope alternation, in a number of languages—see Steedman and Baldridge (2006) for a recent review.
We use CCGBank (Hockenmaier and Steedman, 2007) for experimental data. $$$$$ NPs are flat as well, with all complex modifiers appearing at the same NP level, and compound nouns typically lacking any internal structure.
We use CCGBank (Hockenmaier and Steedman, 2007) for experimental data. $$$$$ The resulting corpus, CCGbank, includes 99.4% of the sentences in the Penn Treebank.
We use CCGBank (Hockenmaier and Steedman, 2007) for experimental data. $$$$$ A completely integrated approach that is based on a syntactic representation which allows direct recovery of the underlying predicate–argument structure might therefore be preferable.

A well known work is transforming Penn Treebank into resources for various deep linguistic processing, including LTAG (Xia, 1999), CCG (Hockenmaier and Steedman, 2007), HPSG (Miyao et al, 2004) and LFG (Cahill et al, 2002). $$$$$ Then we will extend this algorithm to deal with coordination, and introduce a modification to cope with the fact that certain word classes, such as participials, can act as modifiers of a large number of constituent types.
A well known work is transforming Penn Treebank into resources for various deep linguistic processing, including LTAG (Xia, 1999), CCG (Hockenmaier and Steedman, 2007), HPSG (Miyao et al, 2004) and LFG (Cahill et al, 2002). $$$$$ For formalisms like LTAG, the relation is more complex, but the work of Joshi and Kulick (1996), who “unfold” CCG categories into TAG elementary trees via partial proof trees, and Shen and Joshi (2005), who define LTAG “spines” that resemble categories, suggest that this is possible.
A well known work is transforming Penn Treebank into resources for various deep linguistic processing, including LTAG (Xia, 1999), CCG (Hockenmaier and Steedman, 2007), HPSG (Miyao et al, 2004) and LFG (Cahill et al, 2002). $$$$$ This paper has presented an algorithm which translates Penn Treebank phrase-structure trees into CCG derivations augmented with word–word dependencies that approximate the underlying predicate–argument structure.
A well known work is transforming Penn Treebank into resources for various deep linguistic processing, including LTAG (Xia, 1999), CCG (Hockenmaier and Steedman, 2007), HPSG (Miyao et al, 2004) and LFG (Cahill et al, 2002). $$$$$ article presents an algorithm for translating the Penn Treebank into a corpus of Combinatory Categorial Grammar (CCG) derivations augmented with local and long-range word–word dependencies.

CCGbank (Hockenmaier and Steedman, 2007) extends this grammar with a set of type-changing rules, designed to strike a better balance between sparsity in the category set and ambiguity in the grammar. $$$$$ An alternative approach, advocated by Clark and Curran (2004), is to use a supertagger which predicts lexical CCG categories in combination with a discriminative parsing model.
CCGbank (Hockenmaier and Steedman, 2007) extends this grammar with a set of type-changing rules, designed to strike a better balance between sparsity in the category set and ambiguity in the grammar. $$$$$ In this article and in CCGbank, we approximate such semantic interpretations with dependency graphs that include most semantically relevant non-anaphoric local and long-range dependencies.
CCGbank (Hockenmaier and Steedman, 2007) extends this grammar with a set of type-changing rules, designed to strike a better balance between sparsity in the category set and ambiguity in the grammar. $$$$$ Furthermore, constructions that are difficult to analyze do not need to be given a detailed analysis.
CCGbank (Hockenmaier and Steedman, 2007) extends this grammar with a set of type-changing rules, designed to strike a better balance between sparsity in the category set and ambiguity in the grammar. $$$$$ CCGbank does not distinguish between control and raising.
