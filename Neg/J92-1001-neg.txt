Those relations between the sense and its defining words are reflected in semantic dusters that are termed categorical, functional, and situational clusters in McRoy (1992). $$$$$ In either case, a concept that subsumes only a few senses is stronger information than a concept that subsumes more.
Those relations between the sense and its defining words are reflected in semantic dusters that are termed categorical, functional, and situational clusters in McRoy (1992). $$$$$ We have also created a number of concept-cluster definitions describing common semantic contexts and a conceptual hierarchy that acts as a sense-disambiguated thesaurus.
Those relations between the sense and its defining words are reflected in semantic dusters that are termed categorical, functional, and situational clusters in McRoy (1992). $$$$$ The strategy of favoring the most specific information has several advantages.
Those relations between the sense and its defining words are reflected in semantic dusters that are termed categorical, functional, and situational clusters in McRoy (1992). $$$$$ When tested on a sample of 25,000 words of text from the Wall Street Journal, the system covered 98% of non-proper noun, non-abbreviated word occurrences (and 91% of all words).

Moreover, those relations have been shown to be very effective knowledge sources for WSD (McRoy 1992) and interpretation of noun sequences (Vanderwende 1994). $$$$$ We will describe a method of combining cues on the basis their individual than a fixed ranking among cue-types.
Moreover, those relations have been shown to be very effective knowledge sources for WSD (McRoy 1992) and interpretation of noun sequences (Vanderwende 1994). $$$$$ However, current approaches make use of only small subsets of this information.
Moreover, those relations have been shown to be very effective knowledge sources for WSD (McRoy 1992) and interpretation of noun sequences (Vanderwende 1994). $$$$$ Here we will describe how to use the whole range of information.
Moreover, those relations have been shown to be very effective knowledge sources for WSD (McRoy 1992) and interpretation of noun sequences (Vanderwende 1994). $$$$$ To apply this information most efficiently, the approach introduces a preprocessing phase that uses preference information available prior to parsing to eliminate some of the lexical ambiguity and establish baseline preferences.

Even if most of the techniques for WSD are presented as stand-alone, it is our belief, following the ideas of (McRoy, 1992), that full-fledged lexical ambiguity resolution should combine several information sources and techniques. $$$$$ We expect to evaluate our approach on tasks in information retrieval, and, later, machine translation, to determine the likelihood of achieving substantive improvements through sense-based semantic analysis.
Even if most of the techniques for WSD are presented as stand-alone, it is our belief, following the ideas of (McRoy, 1992), that full-fledged lexical ambiguity resolution should combine several information sources and techniques. $$$$$ We expect to evaluate our approach on tasks in information retrieval, and, later, machine translation, to determine the likelihood of achieving substantive improvements through sense-based semantic analysis.
Even if most of the techniques for WSD are presented as stand-alone, it is our belief, following the ideas of (McRoy, 1992), that full-fledged lexical ambiguity resolution should combine several information sources and techniques. $$$$$ We will also discuss an application of the approach in a system that computes sense tags for arbitrary texts, even when it is unable to determine a single syntactic or semantic representation for some sentences.
Even if most of the techniques for WSD are presented as stand-alone, it is our belief, following the ideas of (McRoy, 1992), that full-fledged lexical ambiguity resolution should combine several information sources and techniques. $$$$$ This paper addresses the problem of how to identify the intended meaning of individual words in unrestricted texts, without necessarily having access to complete representations of sentences.

 $$$$$ Since the preferred interpretation also fixes the preferred sense of each word, it is at this point that the text can be given semantic tags, thus allowing sense-based information retrieval.
 $$$$$ Because determining this information accurately is knowledge-intensive, the analyzer should be as flexible as possible, requiring a minimum amount of customization for different domains.
 $$$$$ When senses share constraints (not the case in this example), they can be encoded at the level of the word entry.

 $$$$$ I am grateful to Paul Jacobs for his comments and his encouragement of my work on natural language processing at GE; to George Krupka for helping me integrate my work with TRUMP, and for continuing to improve the system; to Graeme Hirst for his many comments and suggestions on this article; and to Jan Wiebe and Evan Steeg for their comments on earlier drafts.
 $$$$$ This paper addresses the problem of how to identify the intended meaning of individual words in unrestricted texts, without necessarily having access to complete representations of sentences.
 $$$$$ To demonstrate that the approach is sufficiently robust for practical tasks, the article will also discuss the incorporation of the approach into an existing system, TRUMP (Jacobs 1986, 1987, 1989), and the application of it to unrestricted texts.

(McRoy, 1992) was one of the first to use multiple kinds of features for word sense disambiguation in the semantic interpretation system, TRUMP. $$$$$ I am grateful to Paul Jacobs for his comments and his encouragement of my work on natural language processing at GE; to George Krupka for helping me integrate my work with TRUMP, and for continuing to improve the system; to Graeme Hirst for his many comments and suggestions on this article; and to Jan Wiebe and Evan Steeg for their comments on earlier drafts.
(McRoy, 1992) was one of the first to use multiple kinds of features for word sense disambiguation in the semantic interpretation system, TRUMP. $$$$$ For example, if a preference is for the concept c-obj ect, which has a positive specificity of 1, and this concept fails to match the input, then the preference value for the cue will be â€”9.
(McRoy, 1992) was one of the first to use multiple kinds of features for word sense disambiguation in the semantic interpretation system, TRUMP. $$$$$ This paper addresses the problem of how to identify the intended meaning of individual words in unrestricted texts, without necessarily having access to complete representations of sentences.

 $$$$$ Once preprocessing is complete, the parsing phase begins.
 $$$$$ However, having access to sense tags allows for easy improvement by more knowledge-intensive methods.
 $$$$$ When tested on a sample of 25,000 words of text from the Wall Street Journal, the system covered 98% of non-proper noun, non-abbreviated word occurrences (and 91% of all words).
 $$$$$ Role-related preferences of reachl for the preposition by.

 $$$$$ When tested on a sample of 25,000 words of text from the Wall Street Journal, the system covered 98% of non-proper noun, non-abbreviated word occurrences (and 91% of all words).
 $$$$$ It is encouraging to note that, even if our encoding scheme is not entirely &quot;correct&quot; according to human intuition, as long as it is consistent, in theory it should lead to capabilities that are no worse, with zero customization, than word-based methods for information retrieval.
 $$$$$ We will describe a method of combining cues on the basis of their individual specificity, rather than a fixed ranking among cue-types.
 $$$$$ One show will ask viewers to vote on their favorite all-time players through telephone polls.

 $$$$$ Figure 20 gives an example of the sense tagging that the system gives to the following segment of Wall Street Journal text:
 $$$$$ Improving the quality of our sense tagging requires a fair amount of straightforward but time-consuming work.
 $$$$$ We expect to evaluate our approach on tasks in information retrieval, and, later, machine translation, to determine the likelihood of achieving substantive improvements through sense-based semantic analysis.
 $$$$$ Our approach to word sense discrimination uses information drawn from the knowledge base and the structure of the text, combining the strongest, most obvious sense preferences created by syntactic tags, word frequencies, collocations, semantic context (clusters), selectional restrictions, and syntactic cues.

 $$$$$ When a slight relaxation of the preference is satisfiable, a system should take the cautious route, and assume it has a case of overspecification and is at worst a weak failure.
 $$$$$ I acknowledge the financial support of the General Electric Company, the University of Toronto, and the Natural Sciences and Engineering Research Council of Canada.
 $$$$$ I acknowledge the financial support of the General Electric Company, the University of Toronto, and the Natural Sciences and Engineering Research Council of Canada.

We propose a tagger that makes use of several types of information (dictionary definitions, parts-of-speech, domain codes, selectional preferences and collocates) in the tradition of McRoy (McRoy, 1992) although, the information sources we use are orthogonal, unlike the sources he used, making it easier to evaluate the performance of the various modules. $$$$$ Our approach to word sense discrimination uses information drawn from the knowledge base and the structure of the text, combining the strongest, most obvious sense preferences created by syntactic tags, word frequencies, collocations, semantic context (clusters), selectional restrictions, and syntactic cues.
We propose a tagger that makes use of several types of information (dictionary definitions, parts-of-speech, domain codes, selectional preferences and collocates) in the tradition of McRoy (McRoy, 1992) although, the information sources we use are orthogonal, unlike the sources he used, making it easier to evaluate the performance of the various modules. $$$$$ We expect to evaluate our approach on tasks in information retrieval, and, later, machine translation, to determine the likelihood of achieving substantive improvements through sense-based semantic analysis.
We propose a tagger that makes use of several types of information (dictionary definitions, parts-of-speech, domain codes, selectional preferences and collocates) in the tradition of McRoy (McRoy, 1992) although, the information sources we use are orthogonal, unlike the sources he used, making it easier to evaluate the performance of the various modules. $$$$$ It is the job of the semantic interpreter to identify the possible relations that link the structures being combined, identify the preferences associated with each possible combination of head, role (relation), and filler (the argument or modifier), and then rank competing semantic interpretations.
We propose a tagger that makes use of several types of information (dictionary definitions, parts-of-speech, domain codes, selectional preferences and collocates) in the tradition of McRoy (McRoy, 1992) although, the information sources we use are orthogonal, unlike the sources he used, making it easier to evaluate the performance of the various modules. $$$$$ â€¢ preferences associated with the semantic &quot;fit&quot; between any two of the head, the role, and the filler, for example: filler and role e.g., foods make good fillers for the PATIENT role of eating activities; filler and head e.g., colors make good modifiers of physical objects; head and role e.g., monetary objects expect to be qualified by some QUANTITY.

This approach as been recently used by (McRoy, 1992) and (Mahesh and Beale, 1996). $$$$$ I am grateful to Paul Jacobs for his comments and his encouragement of my work on natural language processing at GE; to George Krupka for helping me integrate my work with TRUMP, and for continuing to improve the system; to Graeme Hirst for his many comments and suggestions on this article; and to Jan Wiebe and Evan Steeg for their comments on earlier drafts.
This approach as been recently used by (McRoy, 1992) and (Mahesh and Beale, 1996). $$$$$ Here we will describe how to use the whole range of information.
This approach as been recently used by (McRoy, 1992) and (Mahesh and Beale, 1996). $$$$$ The lexical entry for agree marks this preference by giving it : TYPE *primary* (see Figure 15).
This approach as been recently used by (McRoy, 1992) and (Mahesh and Beale, 1996). $$$$$ This paper addresses the problem of how to identify the intended meaning of individual words in unrestricted texts, without necessarily having access to complete representations of sentences.

There are a variety of methods for combining multiple knowledge sources (linguistic cues) (McRoy, 1992). $$$$$ Although collocations seem to have a semantic basis, many collocations are best recognized by their syntactic form.
There are a variety of methods for combining multiple knowledge sources (linguistic cues) (McRoy, 1992). $$$$$ This presents a bit of a paradox: the greater the specificity of a concept, the more information there is about it, but the less information there may be about a corresponding preference.
There are a variety of methods for combining multiple knowledge sources (linguistic cues) (McRoy, 1992). $$$$$ We expect to evaluate our approach on tasks in information retrieval, and, later, machine translation, to determine the likelihood of achieving substantive improvements through sense-based semantic analysis.

McRoy (1992) describes a study of different sources useful for word sense disambiguation, including morphological information. $$$$$ There are some encouraging results from applying the system to sense tagging of arbitrary text.
McRoy (1992) describes a study of different sources useful for word sense disambiguation, including morphological information. $$$$$ We will describe a method of combining cues on the basis of their individual specificity, rather than a fixed ranking among cue-types.
McRoy (1992) describes a study of different sources useful for word sense disambiguation, including morphological information. $$$$$ Twelve percent of the senses the system selected were derivatives.
McRoy (1992) describes a study of different sources useful for word sense disambiguation, including morphological information. $$$$$ Failure to meet a general preference is always significant, whereas failure to meet a very specific preference is only strong information when a slight relaxation of the preference does not eliminate the failure.
