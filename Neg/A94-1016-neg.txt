Other approaches combine lattices or N-best lists from several different MT systems (Frederking and Nirenburg, 1994). $$$$$ After processing (see rows 9 through 22), each element is the score for the best set of components covering the input from word i to word j (the best cover for this substring)2.

that is hopefully better than any of its ingredients, an idea pionieered in (Frederking and Nirenburg, 1994). $$$$$ Statistically generating such a model is feasible, since it does not rely on knowing correspondences between source and target languages.

Frederking and Nirenburg (1994) produced the first MEMT system by combining outputs from three different MT engines based on their knowledge of the inner workings of the engines. $$$$$ Results of multi-engine MT were fed in our experiment into a translator's workstation (TWS) (Cohen et al., 1993), through which a translator either approved the system's output or modified it.
Frederking and Nirenburg (1994) produced the first MEMT system by combining outputs from three different MT engines based on their knowledge of the inner workings of the engines. $$$$$ The user sees the original source language text in one editor window, and phrases marked by double angle brackets in another, each of which is the first translation from a candidate chosen by the chart walk.

Similar advances have been made in machine translation (Frederking and Nirenburg, 1994), speech recognition (Fiscus, 1997), named entity recognition (Borthwick et al, 1998), partial parsing (Inui and Inui, 2000), word sense disambiguation (Florian and Yarowsky, 2002) and question answering (Chu-Carroll et al, 2003). $$$$$ This is a sentence from one of the 1993 ARPA MT evaluation texts.
Similar advances have been made in machine translation (Frederking and Nirenburg, 1994), speech recognition (Fiscus, 1997), named entity recognition (Borthwick et al, 1998), partial parsing (Inui and Inui, 2000), word sense disambiguation (Florian and Yarowsky, 2002) and question answering (Chu-Carroll et al, 2003). $$$$$ It is a weaker approach, but should go some distance in selecting between otherwise indistinguishable outputs.

Now back in machine translation, we do find some work addressing such concern: Frederking and Nirenburg (1994) develop a multi-engine MT or MEMT architecture which operates by combining outputs from three different engines based on the knowledge it has about inner workings of each of the component engines. $$$$$ The most important effect of this change is that accurate quality scores become much more important, since the first choice becomes the only choice.
Now back in machine translation, we do find some work addressing such concern: Frederking and Nirenburg (1994) develop a multi-engine MT or MEMT architecture which operates by combining outputs from three different engines based on the knowledge it has about inner workings of each of the component engines. $$$$$ When the element in the top-right corner is produced (5.78), the algorithm is finished, and the associated set of components is the final chart walk result shown in Figure 2.
Now back in machine translation, we do find some work addressing such concern: Frederking and Nirenburg (1994) develop a multi-engine MT or MEMT architecture which operates by combining outputs from three different engines based on the knowledge it has about inner workings of each of the component engines. $$$$$ (In rows 1 through 7, the array has not yet been operated on, so it still shows its initial state.)
Now back in machine translation, we do find some work addressing such concern: Frederking and Nirenburg (1994) develop a multi-engine MT or MEMT architecture which operates by combining outputs from three different engines based on the knowledge it has about inner workings of each of the component engines. $$$$$ As the databases for this are quite large (all together, over 400,000 entries), adding scores to individual entries is, in the short run, prohibitive.

Brown and Frederking (1995) is a continuation of Frederking and Nirenburg (1994) with an addition of a n-gram based mechanism for a candidate selection. $$$$$ For example, to calculate element (8,10), we compute the length-weighted averages of the scores of the best walks over the pair of elements (8,8) and (9,10) versus the pair (8,9) and (10,10), and compare them with the scores of any single chart components going from 8 to 10 (there were none), and take the maximum.
Brown and Frederking (1995) is a continuation of Frederking and Nirenburg (1994) with an addition of a n-gram based mechanism for a candidate selection. $$$$$ The main option for human interaction in TWS currently is the Component Machine-Aided Translation (CMAT) editor (Frederking et al., 1993a).
Brown and Frederking (1995) is a continuation of Frederking and Nirenburg (1994) with an addition of a n-gram based mechanism for a candidate selection. $$$$$ Menus, function keys and mouse clicks are used to perform both regular and enhanced editing actions.

The first example of this approach was the multi-engine MT system (Frederking and Nirenburg, 1994), which builds a chart using the translation units inside each input system and then uses a chart walk algorithm to find the best cover of the source sentence. Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ A less ambitious version of this idea would be to run the low-scoring engines only where there are gaps in the normally high-scoring engines.
The first example of this approach was the multi-engine MT system (Frederking and Nirenburg, 1994), which builds a chart using the translation units inside each input system and then uses a chart walk algorithm to find the best cover of the source sentence. Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ It is clear from the above table that the multi-engine configuration works better than any of our available individual engines, though it still does not reach the quality of a Level 2 translator.
The first example of this approach was the multi-engine MT system (Frederking and Nirenburg, 1994), which builds a chart using the translation units inside each input system and then uses a chart walk algorithm to find the best cover of the source sentence. Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ Statistically generating such a model is feasible, since it does not rely on knowing correspondences between source and target languages.

System combination procedures, on the other hand, generate translations from the output of multiple component systems (Frederking and Nirenburg, 1994). $$$$$ Automatically assessing the utility of the multiengine system relative to the engines taken separately would be a useful development tool.
System combination procedures, on the other hand, generate translations from the output of multiple component systems (Frederking and Nirenburg, 1994). $$$$$ The most important enhancement provided is the ability to select an alternate translation with a popup menu, and instantly replace the system's initially chosen candidate translation string, which becomes the first alternative in this menu if it is used again.
System combination procedures, on the other hand, generate translations from the output of multiple component systems (Frederking and Nirenburg, 1994). $$$$$ We calculate the combined score for a sequence of D 2 components as the weighted average of their individual scores.
System combination procedures, on the other hand, generate translations from the output of multiple component systems (Frederking and Nirenburg, 1994). $$$$$ Figure 4 shows an intermediate point in the filling of the array.

In Machine Translation (MT), there is a long tradition of combining multiple machine translations, as through a Multi-Engine MT (MEMT) architecture; the origins of this are generally credited to Frederking and Nirenburg (1994). $$$$$ A sample test on a passage of 2060 characters from the June 1993 evaluation of Pangloss is shown in figure 6.
In Machine Translation (MT), there is a long tradition of combining multiple machine translations, as through a Multi-Engine MT (MEMT) architecture; the origins of this are generally credited to Frederking and Nirenburg (1994). $$$$$ Automatically assessing the utility of the multiengine system relative to the engines taken separately would be a useful development tool.
In Machine Translation (MT), there is a long tradition of combining multiple machine translations, as through a Multi-Engine MT (MEMT) architecture; the origins of this are generally credited to Frederking and Nirenburg (1994). $$$$$ It is clear from the above table that the multi-engine configuration works better than any of our available individual engines, though it still does not reach the quality of a Level 2 translator.

System combination procedures, on the other hand, generate translations from the output of multiple component systems by combining the best fragments of these outputs (Frederking and Nirenburg, 1994). $$$$$ Ultimately, a multi-engine system depends on the quality of each particular engine.
System combination procedures, on the other hand, generate translations from the output of multiple component systems by combining the best fragments of these outputs (Frederking and Nirenburg, 1994). $$$$$ A less ambitious version of this idea would be to run the low-scoring engines only where there are gaps in the normally high-scoring engines.

It has been proven that such consensus translations are usually better than the output of individual systems (Frederking and Nirenburg, 1994). $$$$$ This assumes that we can reliably estimate scores in advance (not currently true for the expensive engines), and that the engines can be run on fragments.

It proves that such consensus translations are usually better than the output of individual systems (Frederking and Nirenburg, 1994). $$$$$ It is a weaker approach, but should go some distance in selecting between otherwise indistinguishable outputs.
It proves that such consensus translations are usually better than the output of individual systems (Frederking and Nirenburg, 1994). $$$$$ We have begun an experiment with a fully-automated mode, with the understanding that the quality will drop.
It proves that such consensus translations are usually better than the output of individual systems (Frederking and Nirenburg, 1994). $$$$$ The first wins because contaba con has a high score as an idiom from the glossary.

In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994). $$$$$ We expect the performance of KBMT and EBMT to grow.
In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994). $$$$$ The chart-oriented integration of MT engines does not easily support deviations from the linear order of the source text elements, as when discontinuous constituents translate contiguous strings or in the case of cross-component substring order differences.
In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994). $$$$$ Results of multi-engine MT were fed in our experiment into a translator's workstation (TWS) (Cohen et al., 1993), through which a translator either approved the system's output or modified it.
In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994). $$$$$ The best method we could find was counting the number of keystrokes in the TWS to convert the outputs of individual engines and the multi-engine configuration to a &quot;canonical&quot; human translation.

Combinations of MT systems into multi-engine architectures have a long tradition, starting perhaps with (Frederking and Nirenburg, 1994). $$$$$ A sample test on a passage of 2060 characters from the June 1993 evaluation of Pangloss is shown in figure 6.
Combinations of MT systems into multi-engine architectures have a long tradition, starting perhaps with (Frederking and Nirenburg, 1994). $$$$$ The normalization levels were empirically determined in the initial experiment by having several individuals judge the comparative average quality of the outputs in an actual translation run.
Combinations of MT systems into multi-engine architectures have a long tradition, starting perhaps with (Frederking and Nirenburg, 1994). $$$$$ It is clear from the above table that the multi-engine configuration works better than any of our available individual engines, though it still does not reach the quality of a Level 2 translator.
Combinations of MT systems into multi-engine architectures have a long tradition, starting perhaps with (Frederking and Nirenburg, 1994). $$$$$ It is also clear that using keystrokes as a measure is not very satisfactory.
