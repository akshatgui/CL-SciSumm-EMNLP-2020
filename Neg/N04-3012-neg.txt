Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al, 2004). $$$$$ It is available from the Comprehensive Perl Archive Network (http://search.cpan.org/dist/WordNet-Similarity) and via SourceForge, an Open Source development platform (http://wn-similarity.sourceforge.net).
Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al, 2004). $$$$$ This was converted into the object oriented WordNet::Similarity package, which was first released in April 2003 as version 0.03.
Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al, 2004). $$$$$ WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets).
Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al, 2004). $$$$$ WordNet::Similarity is written in Perl and is freely distributed under the Gnu Public License.

Work based on WordNet-like lexical networks for building semantic similarity measures such as (Budanitsky and Hirst, 2006) or (Pedersen et al, 2004) falls into this category. $$$$$ It provides six measures of similarity, and three measures of relatedness, all of which are based on the lexical database WordNet.
Work based on WordNet-like lexical networks for building semantic similarity measures such as (Budanitsky and Hirst, 2006) or (Pedersen et al, 2004) falls into this category. $$$$$ The depth of a synset is returned by getDepthOfSynset() and getTaxonomyDepth() provides the maximum depth for a given is–a hierarchy.
Work based on WordNet-like lexical networks for building semantic similarity measures such as (Budanitsky and Hirst, 2006) or (Pedersen et al, 2004) falls into this category. $$$$$ As such WordNet provides relations beyond is–a, including has–part, is–made–of, and is–an–attribute–of.
Work based on WordNet-like lexical networks for building semantic similarity measures such as (Budanitsky and Hirst, 2006) or (Pedersen et al, 2004) falls into this category. $$$$$ Thereafter Siddharth Patwardhan ported this measure to WordNet::Similarity.

For replacement using semantic similarity measures, we used WordNet::Similarity 2.05 package by Pedersen et al (2004). $$$$$ There are three such measures in the package: hso (Hirst and St-Onge, 1998), lesk (Banerjee and Pedersen, 2003), and vector (Patwardhan, 2003).
For replacement using semantic similarity measures, we used WordNet::Similarity 2.05 package by Pedersen et al (2004). $$$$$ WordNet::Similarity is written in Perl and is freely distributed under the Gnu Public License.
For replacement using semantic similarity measures, we used WordNet::Similarity 2.05 package by Pedersen et al (2004). $$$$$ However, there are also utility programs available with WordNet::Similarity that allow a user to compute information content values from the Brown Corpus, the Penn Treebank, the British National Corpus, or any given corpus of raw text.
For replacement using semantic similarity measures, we used WordNet::Similarity 2.05 package by Pedersen et al (2004). $$$$$ For example, a wheel is a part of a car, night is the opposite of day, snow is made up of water, a knife is used to cut bread, and so forth.

We use the Lesk (overlap) similarity as implemented by the WordNet::similarity package (Pedersen et al, 2004). $$$$$ (McCarthy et al., 2004) use it in conjunction with a thesaurus derived from raw text in order to automatically identify the predominent sense of a word.
We use the Lesk (overlap) similarity as implemented by the WordNet::similarity package (Pedersen et al, 2004). $$$$$ The comparisons are based on correlation with human relatedness values, as well as the TOEFL synonym identification tasks.
We use the Lesk (overlap) similarity as implemented by the WordNet::similarity package (Pedersen et al, 2004). $$$$$ It is available from the Comprehensive Perl Archive Network (http://search.cpan.org/dist/WordNet-Similarity) and via SourceForge, an Open Source development platform (http://wn-similarity.sourceforge.net).
We use the Lesk (overlap) similarity as implemented by the WordNet::similarity package (Pedersen et al, 2004). $$$$$ (Baldwin et al., 2003) use WordNet::Similarity to provide an evaluation tool for multiword expressions that are identified via Latent Semantic Analysis.

SR-AW finds the sense of each word that is most related or most similar to those of its neighbors in the sentence, according to any of the ten measures available in WordNet::Similarity (Pedersen et al, 2004). $$$$$ However, there are also utility programs available with WordNet::Similarity that allow a user to compute information content values from the Brown Corpus, the Penn Treebank, the British National Corpus, or any given corpus of raw text.
SR-AW finds the sense of each word that is most related or most similar to those of its neighbors in the sentence, according to any of the ten measures available in WordNet::Similarity (Pedersen et al, 2004). $$$$$ WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets).
SR-AW finds the sense of each word that is most related or most similar to those of its neighbors in the sentence, according to any of the ten measures available in WordNet::Similarity (Pedersen et al, 2004). $$$$$ For example, for the measures that rely on path lengths (lch, wup, path) the tracing shows all the paths found between the concepts.

Then the value of vi is assigned as follows, where the similarity function SIM (ti ,wj) is calculated according to the path measure (Pedersen et al., 2004) using the WordNet. $$$$$ These are necessary since there is multiple inheritance of concepts in WordNet, and different LCS can be selected for a pair of concepts if one or both of them have multiple parents in an is–a hiearchy. getLCSbyIC() chooses the LCS for a pair of concepts that has the highest information content, getLCSbyDepth() selects the LCS with the greatest depth, and getLCSbyPath() selects the LCS that results in the shortest path.
Then the value of vi is assigned as follows, where the similarity function SIM (ti ,wj) is calculated according to the path measure (Pedersen et al., 2004) using the WordNet. $$$$$ The default source for information content for concepts is the sense–tagged corpus SemCor.
Then the value of vi is assigned as follows, where the similarity function SIM (ti ,wj) is calculated according to the path measure (Pedersen et al., 2004) using the WordNet. $$$$$ This allows for similarity measures to be applied to any pair of nouns or verbs.
Then the value of vi is assigned as follows, where the similarity function SIM (ti ,wj) is calculated according to the path measure (Pedersen et al., 2004) using the WordNet. $$$$$ This allows for similarity measures to be applied to any pair of nouns or verbs.

We used the Wordnet::Similarity software package (Pedersen et al, 2004) to calculate the similarity between every two words at first. $$$$$ If the hypothetical root nodes are off, then concepts must be in the same physical hierarchy for a measurement to be taken.
We used the Wordnet::Similarity software package (Pedersen et al, 2004) to calculate the similarity between every two words at first. $$$$$ PathFinder.pm provides getAllPaths(), which finds all of the paths and their lengths between two input synsets, and getShortestPath() which determines the length of the shortest path between two concepts.
We used the Wordnet::Similarity software package (Pedersen et al, 2004) to calculate the similarity between every two words at first. $$$$$ For example, a wheel is a part of a car, night is the opposite of day, snow is made up of water, a knife is used to cut bread, and so forth.

The measures vary from simple edge-counting to attempt to factor in peculiarities of the network structure by considering link direction, relative path, and density, such as vector, lesk, hso, lch, wup, path, res, lin and jcn (Pedersen et al, 2004). $$$$$ The distance.pl program and all versions of WordNet::Similarity up to and including 0.06 were designed and implemented by Siddharth Patwardhan as a part of his Master’s thesis at the University of Minnesota, Duluth.
The measures vary from simple edge-counting to attempt to factor in peculiarities of the network structure by considering link direction, relative path, and density, such as vector, lesk, hso, lch, wup, path, res, lin and jcn (Pedersen et al, 2004). $$$$$ Note that these values are pre–computed, so these methods are simply reading from an information content file.
The measures vary from simple edge-counting to attempt to factor in peculiarities of the network structure by considering link direction, relative path, and density, such as vector, lesk, hso, lch, wup, path, res, lin and jcn (Pedersen et al, 2004). $$$$$ (Baldwin et al., 2003) use WordNet::Similarity to provide an evaluation tool for multiword expressions that are identified via Latent Semantic Analysis.
The measures vary from simple edge-counting to attempt to factor in peculiarities of the network structure by considering link direction, relative path, and density, such as vector, lesk, hso, lch, wup, path, res, lin and jcn (Pedersen et al, 2004). $$$$$ It is available from the Comprehensive Perl Archive Network (http://search.cpan.org/dist/WordNet-Similarity) and via SourceForge, an Open Source development platform (http://wn-similarity.sourceforge.net).

We use the WordNet word-to-word similarity metrics (Pedersen et al, 2004) and Latent Semantic Analysis (Landauer et al, 2007). $$$$$ WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets).
We use the WordNet word-to-word similarity metrics (Pedersen et al, 2004) and Latent Semantic Analysis (Landauer et al, 2007). $$$$$ The most current version as of this writing is 0.07, which was released in March 2004.
We use the WordNet word-to-word similarity metrics (Pedersen et al, 2004) and Latent Semantic Analysis (Landauer et al, 2007). $$$$$ The distance.pl program and all versions of WordNet::Similarity up to and including 0.06 were designed and implemented by Siddharth Patwardhan as a part of his Master’s thesis at the University of Minnesota, Duluth.
We use the WordNet word-to-word similarity metrics (Pedersen et al, 2004) and Latent Semantic Analysis (Landauer et al, 2007). $$$$$ WordNet::Similarity is written in Perl and is freely distributed under the Gnu Public License.

 $$$$$ When on, one root node subsumes all of the noun concepts, and another subsumes all of the verb concepts.
 $$$$$ WordNet::Similarity can be utilized via a command line interface provided by the utility program similarity.pl.
 $$$$$ WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets).
 $$$$$ If the hypothetical root nodes are off, then concepts must be in the same physical hierarchy for a measurement to be taken.

Yet, other resources of semantically-related terms can be beneficial, such as WordNet::Similarity (Pedersen et al, 2004), statistical resources like that of Lin (1998) or DIRECT (Kotlerman et al, 2010), thesauri, Wikipedia (Hu et al., 2009), ontologies (Suchanek et al, 2007) etc. $$$$$ WordNet::Similarity is written in Perl and is freely distributed under the Gnu Public License.
Yet, other resources of semantically-related terms can be beneficial, such as WordNet::Similarity (Pedersen et al, 2004), statistical resources like that of Lin (1998) or DIRECT (Kotlerman et al, 2010), thesauri, Wikipedia (Hu et al., 2009), ontologies (Suchanek et al, 2007) etc. $$$$$ The lesk measure finds overlaps between the glosses of concepts A and B, as well as concepts that are directly linked to A and B.
Yet, other resources of semantically-related terms can be beneficial, such as WordNet::Similarity (Pedersen et al, 2004), statistical resources like that of Lin (1998) or DIRECT (Kotlerman et al, 2010), thesauri, Wikipedia (Hu et al., 2009), ontologies (Suchanek et al, 2007) etc. $$$$$ It provides six measures of similarity, and three measures of relatedness, all of which are based on the lexical database WordNet.
Yet, other resources of semantically-related terms can be beneficial, such as WordNet::Similarity (Pedersen et al, 2004), statistical resources like that of Lin (1998) or DIRECT (Kotlerman et al, 2010), thesauri, Wikipedia (Hu et al., 2009), ontologies (Suchanek et al, 2007) etc. $$$$$ Three of the six measures of similarity are based on the information content of the least common subsumer (LCS) of concepts A and B.

where d(.) is a WordNet based relatedness measure (Pedersen et al, 2004). $$$$$ WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets).
where d(.) is a WordNet based relatedness measure (Pedersen et al, 2004). $$$$$ It is available from the Comprehensive Perl Archive Network (http://search.cpan.org/dist/WordNet-Similarity) and via SourceForge, an Open Source development platform (http://wn-similarity.sourceforge.net).
where d(.) is a WordNet based relatedness measure (Pedersen et al, 2004). $$$$$ All of this information can be brought to bear in creating measures of relatedness.

The thresholds were thoroughly selected depending on our analysis for the WordNet hierarchary and semantic similarity measures (Pedersen et al, 2004). $$$$$ These measures include res (Resnik, 1995), lin (Lin, 1998), and jcn (Jiang and Conrath, 1997).
The thresholds were thoroughly selected depending on our analysis for the WordNet hierarchary and semantic similarity measures (Pedersen et al, 2004). $$$$$ It is available from the Comprehensive Perl Archive Network (http://search.cpan.org/dist/WordNet-Similarity) and via SourceForge, an Open Source development platform (http://wn-similarity.sourceforge.net).
The thresholds were thoroughly selected depending on our analysis for the WordNet hierarchary and semantic similarity measures (Pedersen et al, 2004). $$$$$ Then the getRelatedness() method can be called for a pair of word senses, and this will return the relatedness value.
The thresholds were thoroughly selected depending on our analysis for the WordNet hierarchary and semantic similarity measures (Pedersen et al, 2004). $$$$$ As a result these measures tend to be more flexible, and allow for relatedness values to be assigned across parts of speech (e.g., the verb murder and the noun gun).

For example, WordNet similarities (Pedersen et al, 2004) or Latent Semantic Analysis over a large corpus are widely used in many applications and for the definition of kernel functions. $$$$$ The hso measures classifies relations in WordNet as having direction, and then establishes the relatedness between two concepts A and B by finding a path that is neither too long nor that changes direction too often.
For example, WordNet similarities (Pedersen et al, 2004) or Latent Semantic Analysis over a large corpus are widely used in many applications and for the definition of kernel functions. $$$$$ The utility similarity.pl allows a user to measure specific pairs of concepts when given in word#pos#sense form.
For example, WordNet similarities (Pedersen et al, 2004) or Latent Semantic Analysis over a large corpus are widely used in many applications and for the definition of kernel functions. $$$$$ Is–a relations in WordNet do not cross part of speech boundaries, so similarity measures are limited to making judgments between noun pairs (e.g., cat and dog) and verb pairs (e.g., run and walk).

It is worth mentioning that the LSA similarity measure depends on the selected corpus but it benefits from a higher computation speed in comparison to the construction of the similarity matrix based on the WordNet Similarity package (Pedersen et al, 2004). $$$$$ WordNet::Similarity implements measures of similarity and relatedness that are all in some way based on the structure and content of WordNet.
It is worth mentioning that the LSA similarity measure depends on the selected corpus but it benefits from a higher computation speed in comparison to the construction of the similarity matrix based on the WordNet Similarity package (Pedersen et al, 2004). $$$$$ The vector measure creates a co–occurrence matrix for each word used in the WordNet glosses from a given corpus, and then represents each gloss/concept with a vector that is the average of these co–occurrence vectors.
It is worth mentioning that the LSA similarity measure depends on the selected corpus but it benefits from a higher computation speed in comparison to the construction of the similarity matrix based on the WordNet Similarity package (Pedersen et al, 2004). $$$$$ The lesk and vector measures incorporate information from WordNet glosses.

Additionally, we used the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) computed with wn::similarity package (Pedersen et al, 2004) to measure the similarity between T and H. $$$$$ The lesk measure in WordNet::Similarity was originally designed and implemented by Satanjeev Banerjee, who developed this measure as a part of his Master’s thesis at the University of Minnesota, Duluth.
Additionally, we used the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) computed with wn::similarity package (Pedersen et al, 2004) to measure the similarity between T and H. $$$$$ These measures are implemented as Perl modules which take as input two concepts, and return a numeric value that represents the degree to which they are similar or related.
Additionally, we used the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) computed with wn::similarity package (Pedersen et al, 2004) to measure the similarity between T and H. $$$$$ Is–a relations in WordNet do not cross part of speech boundaries, so similarity measures are limited to making judgments between noun pairs (e.g., cat and dog) and verb pairs (e.g., run and walk).
Additionally, we used the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) computed with wn::similarity package (Pedersen et al, 2004) to measure the similarity between T and H. $$$$$ The lesk and vector measures incorporate information from WordNet glosses.

Moreover, Table 4 shows that the computation of the LSA matrix on Wikipedia is faster than using the WordNet similarity software (Pedersen et al, 2004). $$$$$ PathFinder.pm provides getAllPaths(), which finds all of the paths and their lengths between two input synsets, and getShortestPath() which determines the length of the shortest path between two concepts.
Moreover, Table 4 shows that the computation of the LSA matrix on Wikipedia is faster than using the WordNet similarity software (Pedersen et al, 2004). $$$$$ The depth of a synset is returned by getDepthOfSynset() and getTaxonomyDepth() provides the maximum depth for a given is–a hierarchy.
Moreover, Table 4 shows that the computation of the LSA matrix on Wikipedia is faster than using the WordNet similarity software (Pedersen et al, 2004). $$$$$ PathFinder.pm provides getAllPaths(), which finds all of the paths and their lengths between two input synsets, and getShortestPath() which determines the length of the shortest path between two concepts.
Moreover, Table 4 shows that the computation of the LSA matrix on Wikipedia is faster than using the WordNet similarity software (Pedersen et al, 2004). $$$$$ Measures of similarity use information found in an is– a hierarchy of concepts (or synsets), and quantify how much concept A is like (or is similar to) concept B.

We use the default configuration of the measure in WordNet::Similarity-0.12 package (Pedersen et al, 2004), and, with a single exception, the measure performed below Gic; see BP in table 1. $$$$$ This work has been partially supported by a National Science Foundation Faculty Early CAREER Development award (#0092784), and by a Grant-in-Aid of Research, Artistry and Scholarship from the Office of the Vice President for Research and the Dean of the Graduate School of the University of Minnesota.
We use the default configuration of the measure in WordNet::Similarity-0.12 package (Pedersen et al, 2004), and, with a single exception, the measure performed below Gic; see BP in table 1. $$$$$ The distance.pl program and all versions of WordNet::Similarity up to and including 0.06 were designed and implemented by Siddharth Patwardhan as a part of his Master’s thesis at the University of Minnesota, Duluth.
We use the default configuration of the measure in WordNet::Similarity-0.12 package (Pedersen et al, 2004), and, with a single exception, the measure performed below Gic; see BP in table 1. $$$$$ WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets).
We use the default configuration of the measure in WordNet::Similarity-0.12 package (Pedersen et al, 2004), and, with a single exception, the measure performed below Gic; see BP in table 1. $$$$$ (Diab, 2003) combines a number of similarity measures that are then used as a feature in the disambiguation of verb senses.

We use (Pedersen et al., 2004) implementation with a minor alteration. $$$$$ Measures of relatedness are more general in that they can be made across part of speech boundaries, and they are not limited to considering is-a relations.
We use (Pedersen et al., 2004) implementation with a minor alteration. $$$$$ Note that these values are pre–computed, so these methods are simply reading from an information content file.
We use (Pedersen et al., 2004) implementation with a minor alteration. $$$$$ Measures of relatedness are more general in that they can be made across part of speech boundaries, and they are not limited to considering is-a relations.

The WordNet::Similarity package provides a flexible implementation of many of these measures (Pedersen et al, 2004). $$$$$ WordNet::Similarity is written in Perl and is freely distributed under the Gnu Public License.
The WordNet::Similarity package provides a flexible implementation of many of these measures (Pedersen et al, 2004). $$$$$ It uses the WordNet::QueryData package (Rennie, 2000) to create an object representing WordNet.
The WordNet::Similarity package provides a flexible implementation of many of these measures (Pedersen et al, 2004). $$$$$ Then the getRelatedness() method can be called for a pair of word senses, and this will return the relatedness value.
The WordNet::Similarity package provides a flexible implementation of many of these measures (Pedersen et al, 2004). $$$$$ PathFinder.pm provides getAllPaths(), which finds all of the paths and their lengths between two input synsets, and getShortestPath() which determines the length of the shortest path between two concepts.
