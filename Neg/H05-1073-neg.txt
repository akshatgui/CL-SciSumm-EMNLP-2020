Alm et al (2005) and Francisco and Gervas (2006) worked on fairy tales. $$$$$ (Scherer,2003), (Litman and Forbes-Riley, 2004), this appears not to be the case for text-to-speech synthe sis (TTS).
Alm et al (2005) and Francisco and Gervas (2006) worked on fairy tales. $$$$$ Thus, inorder to make text-to-speech synthesis sound as natural and engaging as possible, it is important to con vey the emotional stance in the text.
Alm et al (2005) and Francisco and Gervas (2006) worked on fairy tales. $$$$$ For the nouns andany identical verbal homonyms, synonyms and hy ponyms were extracted manually.3 Feature group 13used a short list of 22 interjections collected manu ally by browsing educational ESL sites, whereas theaffective word list of 771 words consisted of a combination of the non-neutral words from (Johnson Laird and Oatley, 1989) and (Siegle, online).

They later use this corpus to construct a reasonably accurate classifier for emotional states of sentences (Alm et al., 2005). $$$$$ We also thank two anonymous reviewers for comments.
They later use this corpus to construct a reasonably accurate classifier for emotional states of sentences (Alm et al., 2005). $$$$$ (Scherer,2003), (Litman and Forbes-Riley, 2004), this appears not to be the case for text-to-speech synthe sis (TTS).
They later use this corpus to construct a reasonably accurate classifier for emotional states of sentences (Alm et al., 2005). $$$$$ This comes as no surprise, given the subjectivenature of the task, and the rather low interannota tor agreement, reported above.
They later use this corpus to construct a reasonably accurate classifier for emotional states of sentences (Alm et al., 2005). $$$$$ Interjections and affective words.

The second is the frequency with which the character is associated with emotional language - their emotional trajectory (Alm et al 2005). $$$$$ The goal is to classify the emotional affinity of sentences in the narra tive domain of children?s fairy tales, forsubsequent usage in appropriate expressive rendering of text-to-speech synthe sis.
The second is the frequency with which the character is associated with emotional language - their emotional trajectory (Alm et al 2005). $$$$$ This work was funded by NSF under award ITR-#0205731, and NS ITR IIS-0428472.
The second is the frequency with which the character is associated with emotional language - their emotional trajectory (Alm et al 2005). $$$$$ The goal is to determine a mapping function f : s ? emi, such that we obtain an ordered labeled pair (s, emi).

These tools and resources have been already used in a large number of applications, including expressive text-to-speech synthesis (Alm et al, 2005), tracking sentiment timelines in on line forums and news (Balog et al, 2006), analysis of political debates (Carvalho et al, 2011), question answering (Oh et al., 2012), conversation summarization (Carenini et al., 2008), and citation sentiment detection (Athar and Teufel, 2012). $$$$$ Next, section 4 explains the empirical study, including the machine learning model, thecorpus, the feature set, parameter tuning, etc. Section 5 presents experimental results from two classi fication tasks and feature set modifications.
These tools and resources have been already used in a large number of applications, including expressive text-to-speech synthesis (Alm et al, 2005), tracking sentiment timelines in on line forums and news (Balog et al, 2006), analysis of political debates (Carvalho et al, 2011), question answering (Oh et al., 2012), conversation summarization (Carenini et al., 2008), and citation sentiment detection (Athar and Teufel, 2012). $$$$$ Observations from tales indicate that some emotions are more likely to be prolonged than others.
These tools and resources have been already used in a large number of applications, including expressive text-to-speech synthesis (Alm et al, 2005), tracking sentiment timelines in on line forums and news (Balog et al, 2006), analysis of political debates (Carvalho et al, 2011), question answering (Oh et al., 2012), conversation summarization (Carenini et al., 2008), and citation sentiment detection (Athar and Teufel, 2012). $$$$$ emotional strength based on the ra tio of times a word or a sentence was judged to fall into a particular emotion bucket, given the number of human subjects.
These tools and resources have been already used in a large number of applications, including expressive text-to-speech synthesis (Alm et al, 2005), tracking sentiment timelines in on line forums and news (Balog et al, 2006), analysis of political debates (Carvalho et al, 2011), question answering (Oh et al., 2012), conversation summarization (Carenini et al., 2008), and citation sentiment detection (Athar and Teufel, 2012). $$$$$ Initial experiments on a preliminarydata set of 22 fairy tales show encourag ing results over a na??ve baseline and BOW approach for classification of emotional versus non-emotional contents, with some dependency on parameter tuning.
