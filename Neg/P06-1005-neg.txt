 $$$$$ Significant gains in performance are observed on several datasets.
 $$$$$ We present an approach to pronoun resolution based on syntactic paths.
 $$$$$ Several reliable features are used as hard constraints, removing candidates before consideration by the scoring algorithm.
 $$$$$ We include the score from picking the noun immediately preceding the pronoun (after our hard filters are applied).

We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.
We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.
We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ Highly coreferent paths also allow mining of precise probabilistic gender/number information.
We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ After a sufficient number of occurrences of agreement or disagreement, there is a strong statistical indication of whether the path is coreferent (terminal nouns tend to refer to the same entity) or non-coreferent (nouns refer to different entities).

Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text. $$$$$ Also, by bootstrapping with the coreferent paths, we are able to build the most complete and accurate table of probabilistic gender information yet available.
Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text. $$$$$ Preliminary experiments show path coreference bootstrapping can also provide a means of identifying pleonastic pronouns, where pleonastic neutral pronouns are often followed in a dependency path by a terminal noun of different gender, and cataphoric constructions, where the pronouns are often followed by nouns of matching gender.
Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text. $$$$$ The time delay of using an Internet search engine within a large-scale anaphora resolution effort is currently impractical.

Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. $$$$$ Consider: “Alex gave her money.” Minipar parses her as a possessive, when it is more likely an object, “Alex gave money to her.” Without a correct parse, we cannot rule out the link between her and Alex through Binding Theory.
Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. $$$$$ Like path coreference, semantic compatibility can be considered a form of world knowledge needed for more challenging pronoun resolution instances.
Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. $$$$$ Cases such as “John needs her support” or “They need his support” are much more frequent in text than cases where the subject noun and pronoun terminals agree in gender/number.

 $$$$$ On ANC and AQT, each of the probabilistic features results in a statistically significant gain in performance over a model trained and tested with that feature absent.5 On the smaller MUC set, none of the differences in 3-6 are statistically significant, however, the relative contribution of the various features remains reassuringly constant.
 $$$$$ Noun says pronoun intends...
 $$$$$ A dependency path is defined as the sequence of dependency links between two potentially coreferent entities in a parse tree.

 $$$$$ Candidate antecedents are considered in the current and previous sentence only.
 $$$$$ Also, by bootstrapping with the coreferent paths, we are able to build the most complete and accurate table of probabilistic gender information yet available.
 $$$$$ This path information enables us to handle previously challenging resolution instances, and also robustly addresses traditional syntactic coreference constraints.

Gender and Animacy processor $$$$$ We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.
Gender and Animacy processor $$$$$ Several reliable features are used as hard constraints, removing candidates before consideration by the scoring algorithm.
Gender and Animacy processor $$$$$ Our method for determining path coreference is similar to an algorithm for discovering paraphrases in text (Lin and Pantel, 2001).
Gender and Animacy processor $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.

In the closed track, systems were limited to the provided data, plus the use of two pre-specified external resources $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.
In the closed track, systems were limited to the provided data, plus the use of two pre-specified external resources $$$$$ Gender is our most powerful probabilistic feature.
In the closed track, systems were limited to the provided data, plus the use of two pre-specified external resources $$$$$ Our algorithm determines that the dependency path linking the Noun and pronoun is very likely to connect coreferent entities for the path “Noun needs pronoun’s friend,” while it is rarely coreferent for the path “Noun needs pronoun’s support.” This likelihood can be learned by simply counting how often we see a given path in text with an initial Noun and a final pronoun that are from the same/different gender/number classes.
In the closed track, systems were limited to the provided data, plus the use of two pre-specified external resources $$$$$ This path information enables us to handle previously challenging resolution instances, and also robustly addresses traditional syntactic coreference constraints.

 $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.
 $$$$$ We present an approach to pronoun resolution based on syntactic paths.
 $$$$$ Bean and Riloff (2004) used bootstrapping to extend their semantic compatibility model, which they called contextual-role knowledge, by identifying certain cases of easily-resolved anaphors and antecedents.
 $$$$$ We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.

As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ Constraints and preferences have also been applied together as decision nodes on a decision tree (Aone and Bennett, 1995).
As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ Preliminary experiments show path coreference bootstrapping can also provide a means of identifying pleonastic pronouns, where pleonastic neutral pronouns are often followed in a dependency path by a terminal noun of different gender, and cataphoric constructions, where the pronouns are often followed by nouns of matching gender.
As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ Coreference resolution is generally conducted as a pairwise classification task, using various constraints and preferences to determine whether two expressions corefer.
As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ This path information enables us to handle previously challenging resolution instances, and also robustly addresses traditional syntactic coreference constraints.

We assign number attributes based on $$$$$ We present an approach to pronoun resolution based on syntactic paths.
We assign number attributes based on $$$$$ Traditional pronoun resolution systems are not designed to distinguish between these cases.
We assign number attributes based on $$$$$ Significant gains in performance are observed on several datasets.
We assign number attributes based on $$$$$ Our training set is the anaphora-annotated portion of the American National Corpus (ANC) used in Bergsma (2005), containing 1270 anaphoric pronouns4.

All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ Our algorithm determines that the dependency path linking the Noun and pronoun is very likely to connect coreferent entities for the path “Noun needs pronoun’s friend,” while it is rarely coreferent for the path “Noun needs pronoun’s support.” This likelihood can be learned by simply counting how often we see a given path in text with an initial Noun and a final pronoun that are from the same/different gender/number classes.
All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.
All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ Parameters were set using cross-validation on the training set; test sets were used only once to obtain the final performance values.
All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ However, because “Noun gets ... for pronoun’s husband” is a coreferent path, we could capture the above relationship by adding a parent:rel:node for every pronoun connected to a noun phrase along a coreferent path in text.

Both Ge et al (1998) and Bergsma and Lin (2006) show that learned gender is the most important feature in their pronoun resolution systems. $$$$$ Constraints and preferences have also been applied together as decision nodes on a decision tree (Aone and Bennett, 1995).
Both Ge et al (1998) and Bergsma and Lin (2006) show that learned gender is the most important feature in their pronoun resolution systems. $$$$$ In each of the following sentences, a pronoun resolution system must determine what the pronoun his refers to: In (1), John and his corefer.
Both Ge et al (1998) and Bergsma and Lin (2006) show that learned gender is the most important feature in their pronoun resolution systems. $$$$$ Indeed, coreference resolution research has focused on the importance of the strategy for combining well known constraints and preferences (Mitkov, 1997; Ng and Cardie, 2002), devoting little attention to the development of new features for these difficult cases.
Both Ge et al (1998) and Bergsma and Lin (2006) show that learned gender is the most important feature in their pronoun resolution systems. $$$$$ The noun-pronoun path coreference can be used directly as a feature in a pronoun resolution system.

We use the approach of Bergsma and Lin (2006), both because it achieves state-of-the-art gender classification performance, and because a database of the obtained noun genders is available online. $$$$$ We use add-one smoothing for data sparsity.
We use the approach of Bergsma and Lin (2006), both because it achieves state-of-the-art gender classification performance, and because a database of the obtained noun genders is available online. $$$$$ We include both the MI between the noun and the pronoun’s parent as well as the MI between the pronoun and the noun’s parent as features in our pronoun resolution classifier.
We use the approach of Bergsma and Lin (2006), both because it achieves state-of-the-art gender classification performance, and because a database of the obtained noun genders is available online. $$$$$ Candidate antecedents are considered in the current and previous sentence only.

We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ Through a simple bootstrapping procedure, we learn the likelihood of coreference between a pronoun and a candidate noun based on the path in the parse tree between the two entities.
We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ Indeed, coreference resolution research has focused on the importance of the strategy for combining well known constraints and preferences (Mitkov, 1997; Ng and Cardie, 2002), devoting little attention to the development of new features for these difficult cases.
We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ In fact, inspecting our system’s decisions, gender often rules out coreference regardless of path coreference.
We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ Some example gender/number probabilities are given in Table 4 (cf.

For English, number and gender for common nouns are computed via a comparison of head lemma to head and using the number and gender data of Bergsma and Lin (2006). $$$$$ Through a simple bootstrapping procedure, we learn the likelihood of coreference between a pronoun and a candidate noun based on the path in the parse tree between the two entities.
For English, number and gender for common nouns are computed via a comparison of head lemma to head and using the number and gender data of Bergsma and Lin (2006). $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.

 $$$$$ We include the score from picking the noun immediately preceding the pronoun (after our hard filters are applied).
 $$$$$ In each of the following sentences, a pronoun resolution system must determine what the pronoun his refers to: In (1), John and his corefer.
 $$$$$ ... put Noun at the top of pronoun’s list.
 $$$$$ Pronoun resolution is a difficult but vital part of the overall coreference resolution task.

For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.
For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ Aside from missing antecedents due to the hard filters, the main sources of error include inaccurate statistical data and a classifier bias toward preceding pronouns of the same gender/number.
For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ Likewise, although Binding Theory (Principle A) could identify the reflexive pronominal relationship of Example 4 in Table 1, most cases cannot be resolved through syntax alone.
For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ More than one candidate can be useful in ambiguous cases, and not every resolution need be used.

Bergsma and Lin (2006) built a statistical model from paths that include the lemma of the intermediate tokens, but replace the end nodes with noun, pronoun, or pronoun-self for nouns, pronouns, and reflexive pronouns, respectively. $$$$$ Highly coreferent paths also allow mining of precise probabilistic gender/number information.
Bergsma and Lin (2006) built a statistical model from paths that include the lemma of the intermediate tokens, but replace the end nodes with noun, pronoun, or pronoun-self for nouns, pronouns, and reflexive pronouns, respectively. $$$$$ If a noun is connected to a pronoun of a particular gender along a coreferent path, we count this as an instance of that noun being that gender.
Bergsma and Lin (2006) built a statistical model from paths that include the lemma of the intermediate tokens, but replace the end nodes with noun, pronoun, or pronoun-self for nouns, pronouns, and reflexive pronouns, respectively. $$$$$ Through a simple bootstrapping procedure, we learn the likelihood of coreference between a pronoun and a candidate noun based on the path in the parse tree between the two entities.
Bergsma and Lin (2006) built a statistical model from paths that include the lemma of the intermediate tokens, but replace the end nodes with noun, pronoun, or pronoun-self for nouns, pronouns, and reflexive pronouns, respectively. $$$$$ As a short-form, we write the dependency path in this case as “Noun needs pronoun’s support.” The path itself does not include the terminal nouns “John” and “his.” Our algorithm finds the likelihood of coreference along dependency paths by counting the number of times they occur with terminals that are either likely coreferent or non-coreferent.

For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ The newspaper says it intends to file a lawsuit.
For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ When they disagree, they refer to different entities.
For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ Also, by bootstrapping with the coreferent paths, we are able to build the most complete and accurate table of probabilistic gender information yet available.
For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ ... created Noun and populated pronoun.
