 $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.
 $$$$$ We include both the MI between the noun and the pronoun’s parent as well as the MI between the pronoun and the noun’s parent as features in our pronoun resolution classifier.
 $$$$$ In each of the following sentences, a pronoun resolution system must determine what the pronoun his refers to: In (1), John and his corefer.

We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ Varying this distance varies the precision-recall (PR) of the overall resolution.
We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.
We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ Coreference resolution is generally conducted as a pairwise classification task, using various constraints and preferences to determine whether two expressions corefer.
We follow the closed track setting where systems may only be trained on the provided training data, with the exception of the English gender and number data compiled by Bergsma and Lin (2006). $$$$$ Preliminary experiments show path coreference bootstrapping can also provide a means of identifying pleonastic pronouns, where pleonastic neutral pronouns are often followed in a dependency path by a terminal noun of different gender, and cataphoric constructions, where the pronouns are often followed by nouns of matching gender.

Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text. $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.
Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text. $$$$$ Building a model from enough text may be the key.
Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text. $$$$$ Since no such corpus exists, researchers have used coarser features learned from smaller sets through supervised learning (Soon et al., 2001; Ng and Cardie, 2002), manually-defined coreference patterns to mine specific kinds of data (Bean and Riloff, 2004; Bergsma, 2005), or accepted the noise inherent in unsupervised schemes (Ge et al., 1998; Cherry and Bergsma, 2005).
Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text. $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.

Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.
Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.
Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. $$$$$ This path information enables us to handle previously challenging resolution instances, and also robustly addresses traditional syntactic coreference constraints.
Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. $$$$$ Since the SVM ranks antecedent candidates, we can test this ranking by selecting more than the top candidate (Topn) and evaluating coverage of the true antecedents.

 $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.
 $$$$$ In each of the following sentences, a pronoun resolution system must determine what the pronoun his refers to: In (1), John and his corefer.
 $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.
 $$$$$ Parameters were set using cross-validation on the training set; test sets were used only once to obtain the final performance values.

 $$$$$ In (2), his refers to some other, perhaps previously evoked entity.
 $$$$$ Thus we attempted to duplicate Bergsma’s corpus-based extraction of gender and number, where the information can be stored in advance in a table, but using a much larger data set.
 $$$$$ In each of the following sentences, a pronoun resolution system must determine what the pronoun his refers to: In (1), John and his corefer.

Gender and Animacy processor: This modules collects gender information from the gender corpus (Bergsma and Lin, 2006) and checks a self-made corpus for profession (teacher, doctor, etc) and family relations (mother, father, etc), extracted from web searches. $$$$$ Our algorithm determines that the dependency path linking the Noun and pronoun is very likely to connect coreferent entities for the path “Noun needs pronoun’s friend,” while it is rarely coreferent for the path “Noun needs pronoun’s support.” This likelihood can be learned by simply counting how often we see a given path in text with an initial Noun and a final pronoun that are from the same/different gender/number classes.
Gender and Animacy processor: This modules collects gender information from the gender corpus (Bergsma and Lin, 2006) and checks a self-made corpus for profession (teacher, doctor, etc) and family relations (mother, father, etc), extracted from web searches. $$$$$ We show that including path coreference information enables significant performance gains on three third-person pronoun resolution experiments.
Gender and Animacy processor: This modules collects gender information from the gender corpus (Bergsma and Lin, 2006) and checks a self-made corpus for profession (teacher, doctor, etc) and family relations (mother, father, etc), extracted from web searches. $$$$$ Gender is our most powerful probabilistic feature.
Gender and Animacy processor: This modules collects gender information from the gender corpus (Bergsma and Lin, 2006) and checks a self-made corpus for profession (teacher, doctor, etc) and family relations (mother, father, etc), extracted from web searches. $$$$$ For example, we assumed two pronouns from the same pronoun group were coreferent, and deduced path coreference from the accumulated counts.

In the closed track, systems were limited to the provided data, plus the use of two pre-specified external resources: i) WordNet and ii) a pre-computed number and gender table by Bergsma and Lin (2006). $$$$$ Constraints can be applied as a preprocessing step to scoring candidates based on distance, grammatical role, etc., with scores developed either manually (Lappin and Leass, 1994), or through a machine-learning algorithm (Kehler et al., 2004).
In the closed track, systems were limited to the provided data, plus the use of two pre-specified external resources: i) WordNet and ii) a pre-computed number and gender table by Bergsma and Lin (2006). $$$$$ We are pleased to be able to share our gender and number data with the NLP community.2 In Section 6, we show the benefit of this data as a probabilistic feature in our pronoun resolution system.
In the closed track, systems were limited to the provided data, plus the use of two pre-specified external resources: i) WordNet and ii) a pre-computed number and gender table by Bergsma and Lin (2006). $$$$$ Coreference resolution is generally conducted as a pairwise classification task, using various constraints and preferences to determine whether two expressions corefer.

 $$$$$ We present an approach to pronoun resolution based on syntactic paths.
 $$$$$ Due to the hard filters and limited search window, it is not possible for our system to resolve every noun to a correct antecedent.
 $$$$$ We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.
 $$$$$ Different paths are not compared in any way; each path is individually assigned a coreference likelihood.

As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ We could use this fact to prevent us from resolving “his” to “John” when “John needs his support” is presented to a pronoun resolution system.
As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ These particular corpora were chosen so we could test our approach using the same data as comparable machine-learned systems exploiting probabilistic information sources.
As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier.
As noted above, systems were allowed to make use of gender and number predictions for NPs using the table from Bergsma and Lin (Bergsma and Lin, 2006). $$$$$ Varying this distance varies the precision-recall (PR) of the overall resolution.

We assign number attributes based on: (a) a static list for pronouns; (b) NER labels: mentions marked as a named entity are considered singular with the exception of organizations, which can be both singular or plural; (c) part of speech tags: NN*S tags are plural and all other NN* tags are singular; and (d) a static dictionary from (Bergsma and Lin, 2006). $$$$$ Through a simple bootstrapping procedure, we learn the likelihood of coreference between a pronoun and a candidate noun based on the path in the parse tree between the two entities.
We assign number attributes based on: (a) a static list for pronouns; (b) NER labels: mentions marked as a named entity are considered singular with the exception of organizations, which can be both singular or plural; (c) part of speech tags: NN*S tags are plural and all other NN* tags are singular; and (d) a static dictionary from (Bergsma and Lin, 2006). $$$$$ The features are thus set when coreference between the pronoun and candidate noun is likely (a coreferent path) or unlikely (a non-coreferent path).
We assign number attributes based on: (a) a static list for pronouns; (b) NER labels: mentions marked as a named entity are considered singular with the exception of organizations, which can be both singular or plural; (c) part of speech tags: NN*S tags are plural and all other NN* tags are singular; and (d) a static dictionary from (Bergsma and Lin, 2006). $$$$$ Highly coreferent paths also allow mining of precise probabilistic gender/number information.
We assign number attributes based on: (a) a static list for pronouns; (b) NER labels: mentions marked as a named entity are considered singular with the exception of organizations, which can be both singular or plural; (c) part of speech tags: NN*S tags are plural and all other NN* tags are singular; and (d) a static dictionary from (Bergsma and Lin, 2006). $$$$$ Our analysis shows that successfully handling cases that may have been handled with Binding Theory constitutes only a small portion of the total performance gain using path coreference.

All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ Indeed, coreference resolution research has focused on the importance of the strategy for combining well known constraints and preferences (Mitkov, 1997; Ng and Cardie, 2002), devoting little attention to the development of new features for these difficult cases.
All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.
All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ We have introduced a novel feature for pronoun resolution called path coreference, and demonstrated its significant contribution to a state-of-theart pronoun resolution system.
All the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of WordNet (Miller, 1995), gender and number information (Bergsma and Lin, 2006) and sense inventories. $$$$$ ... Noun into pronoun’s pool Max put the floaties into their pool.

Both Ge et al (1998) and Bergsma and Lin (2006) show that learned gender is the most important feature in their pronoun resolution systems. $$$$$ Preliminary experiments show path coreference bootstrapping can also provide a means of identifying pleonastic pronouns, where pleonastic neutral pronouns are often followed in a dependency path by a terminal noun of different gender, and cataphoric constructions, where the pronouns are often followed by nouns of matching gender.
Both Ge et al (1998) and Bergsma and Lin (2006) show that learned gender is the most important feature in their pronoun resolution systems. $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.
Both Ge et al (1998) and Bergsma and Lin (2006) show that learned gender is the most important feature in their pronoun resolution systems. $$$$$ This allows us to learn general syntactic constraints not dependent on the surface forms of the words (including, but not limited to, the Binding Theory principles).

We use the approach of Bergsma and Lin (2006), both because it achieves state-of-the-art gender classification performance, and because a database of the obtained noun genders is available online. $$$$$ They give the example “Mr.
We use the approach of Bergsma and Lin (2006), both because it achieves state-of-the-art gender classification performance, and because a database of the obtained noun genders is available online. $$$$$ Consider: “Alex gave her money.” Minipar parses her as a possessive, when it is more likely an object, “Alex gave money to her.” Without a correct parse, we cannot rule out the link between her and Alex through Binding Theory.
We use the approach of Bergsma and Lin (2006), both because it achieves state-of-the-art gender classification performance, and because a database of the obtained noun genders is available online. $$$$$ A separate set of these noncoreferent paths is also used as a feature in our sys'As desired, this modification allows the first example to provide two instances of noun-pronoun paths with terminals from the same gender/number group, linking each “its” to the subject noun “Company A”, rather than to each other.
We use the approach of Bergsma and Lin (2006), both because it achieves state-of-the-art gender classification performance, and because a database of the obtained noun genders is available online. $$$$$ This is not surprising, since we based the acquisition of C(p) on gender.

We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ Consider the phrase, “Saddam’s wife got a Jordanian lawyer for her husband.” It is unlikely we would see “wife’s husband” in text; in other words, we would not know that husband:gen:wife is, in fact, semantically compatible and thereby we would discourage selection of “wife” as the antecedent at resolution time.
We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ Preliminary experiments show path coreference bootstrapping can also provide a means of identifying pleonastic pronouns, where pleonastic neutral pronouns are often followed in a dependency path by a terminal noun of different gender, and cataphoric constructions, where the pronouns are often followed by nouns of matching gender.
We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ Preliminary experiments show path coreference bootstrapping can also provide a means of identifying pleonastic pronouns, where pleonastic neutral pronouns are often followed in a dependency path by a terminal noun of different gender, and cataphoric constructions, where the pronouns are often followed by nouns of matching gender.
We can regard the Bergsma and Lin (2006) approach and our discriminative system as two orthogonal views of gender, in a co-training sense (Blum and Mitchell, 1998). $$$$$ When previous resolution systems handle cases like (1) and (2), where no disagreement or syntactic violation occurs, coreference is therefore determined by the weighting of features or learned decisions of the resolution classifier.

For English, number and gender for common nouns are computed via a comparison of head lemma to head and using the number and gender data of Bergsma and Lin (2006). $$$$$ A standard set of features is used along with the bootstrapped gender/number, semantic compatibility, and path coreference information.
For English, number and gender for common nouns are computed via a comparison of head lemma to head and using the number and gender data of Bergsma and Lin (2006). $$$$$ Likewise, although Binding Theory (Principle A) could identify the reflexive pronominal relationship of Example 4 in Table 1, most cases cannot be resolved through syntax alone.
For English, number and gender for common nouns are computed via a comparison of head lemma to head and using the number and gender data of Bergsma and Lin (2006). $$$$$ Varying this distance varies the precision-recall (PR) of the overall resolution.

 $$$$$ We learn coreference is unlikely between the nouns in “Bob married his mother,” or “Sue wrote her obituary.” The fact you don’t marry your own mother or write your own obituary is perhaps obvious, but this is the first time this kind of knowledge has been made available computationally.
 $$$$$ Our work does not need to store the terminals themselves, only whether they are from the same pronoun group.
 $$$$$ Therefore, rather than using path coreference directly, we have features that are true if C(p) is above or below certain thresholds.
 $$$$$ Coreference resolution is generally conducted as a pairwise classification task, using various constraints and preferences to determine whether two expressions corefer.

For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ We present an approach to pronoun resolution based on syntactic paths.
For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ Let NS(p) be the number of times the two terminal pronouns of a path, p, are from the same pronoun group, and let ND(p) be the number of times they are from different groups.
For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ We developed context models with and without these path enhancements, but ultimately we could find no subset of coreferent paths that improve the semantic compatibility’s contribution to training set accuracy.
For non pronominal mentions, we used the number and gender data (Bergsma and Lin, 2006) provided by the task organizers and queried it for the head word of the mention. $$$$$ If they are from different groups, like I and his, then they are non-coreferent.

Bergsma and Lin (2006) built a statistical model from paths that include the lemma of the intermediate tokens, but replace the end nodes with noun, pronoun, or pronoun-self for nouns, pronouns, and reflexive pronouns, respectively. $$$$$ A standard set of features is used along with the bootstrapped gender/number, semantic compatibility, and path coreference information.
Bergsma and Lin (2006) built a statistical model from paths that include the lemma of the intermediate tokens, but replace the end nodes with noun, pronoun, or pronoun-self for nouns, pronouns, and reflexive pronouns, respectively. $$$$$ Also, by bootstrapping with the coreferent paths, we are able to build the most complete and accurate table of probabilistic gender information yet available.

For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ Nevertheless, note the decrease in performance on each of the datasets when C(p) is excluded (#5).
For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ This feature aids coreference decisions in many situations not handled by traditional coreference systems.
For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ Cases such as “John needs her support” or “They need his support” are much more frequent in text than cases where the subject noun and pronoun terminals agree in gender/number.
For the gender task that we study in our experiments, we acquire class instances by filtering the dataset of nouns and their genders created by Bergsma and Lin (2006). $$$$$ Preliminary experiments show path coreference bootstrapping can also provide a means of identifying pleonastic pronouns, where pleonastic neutral pronouns are often followed in a dependency path by a terminal noun of different gender, and cataphoric constructions, where the pronouns are often followed by nouns of matching gender.
