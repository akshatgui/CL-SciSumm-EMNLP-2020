Consider the following example (see Figure 1 for an illustration): In recent work dealing with pronoun resolution in spoken dialogue (Strube and Muller, 2003), different types of expressions (noun phrases, verb phrases, whole utterances and disfluencies) had to be annotated. $$$$$ It does so in terms of the sum of the individual words’ IC.
Consider the following example (see Figure 1 for an illustration): In recent work dealing with pronoun resolution in spoken dialogue (Strube and Muller, 2003), different types of expressions (noun phrases, verb phrases, whole utterances and disfluencies) had to be annotated. $$$$$ We apply a decision tree based approach to pronoun resolution in spoken dialogue.
Consider the following example (see Figure 1 for an illustration): In recent work dealing with pronoun resolution in spoken dialogue (Strube and Muller, 2003), different types of expressions (noun phrases, verb phrases, whole utterances and disfluencies) had to be annotated. $$$$$ Finally, the feature wdist ic (25) measures the word-based distance between two expressions.
Consider the following example (see Figure 1 for an illustration): In recent work dealing with pronoun resolution in spoken dialogue (Strube and Muller, 2003), different types of expressions (noun phrases, verb phrases, whole utterances and disfluencies) had to be annotated. $$$$$ We refined distance features and used metrics from information retrieval for determining non-NP-antecedents.

 $$$$$ It has been demonstrated that systems based on these approaches achieve a performance that is comparable to hand-crafted systems.
 $$$$$ By adding the feature ante exp type the classifier is enabled to address NP- and non-NP-antecedents differently, which results in a considerable gain in performance.
 $$$$$ However, these features did not show up in the final models since they did not lead to an improvement.

 $$$$$ That way we are able to determine relatively powerful yet computationally cheap features.
 $$$$$ E.g., Dagan & Itai (1991) presented a corpus-based approach to the resolution of the pronoun it, but they use a written text corpus and do not mention non-NP-antecedents at all.

Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e.g. rewriting rule sets. $$$$$ We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features.
Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e.g. rewriting rule sets. $$$$$ Coreference-level features, on the other hand, describe the relation between antecedent and anaphor in terms of e.g. distance (in words, markables and sentences), compatibility in terms of agreement and identity of syntactic function.
Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e.g. rewriting rule sets. $$$$$ The underlying assumption is that the higher the importance of a non-NP expression, the higher the probability of its being referred back to.
Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e.g. rewriting rule sets. $$$$$ We built upon a system we used for anaphora resolution in written text and extended it with a set of features designed for spoken dialogue.

 $$$$$ The feature ante ic (24) as an alternative to ante tfidf is based on the same assumptions as the former.
 $$$$$ Our system deals with pronouns with NPand non-NP-antecedents.
 $$$$$ Acknowledgements.

 $$$$$ While we were (almost) satisfied with the performance of these features, the major problem for a spoken dialogue pronoun resolution algorithm is the abundance of pronouns without antecedents.
 $$$$$ Corpus-based methods and machine learning techniques have been applied to anaphora resolution in written text with considerable success (Soon et al., 2001; Ng & Cardie, 2002, among others).
 $$$$$ The underlying assumption is that the higher the importance of a non-NP expression, the higher the probability of its being referred back to.
 $$$$$ We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron’s (2002) manually tuned system.

 $$$$$ Our system deals with pronouns with NPand non-NP-antecedents.

Strube and Mu?ller (2003) propose a similar idea, but aim instead at finding a subset of the available features with which the resulting coreference classifier yields the best clustering-level accuracy on held-out data. $$$$$ This is in contrast to the majority of other work on feature selection for anaphora resolution, which was hardly ever done systematically.
Strube and Mu?ller (2003) propose a similar idea, but aim instead at finding a subset of the available features with which the resulting coreference classifier yields the best clustering-level accuracy on held-out data. $$$$$ Finally, the feature wdist ic (25) measures the word-based distance between two expressions.
Strube and Mu?ller (2003) propose a similar idea, but aim instead at finding a subset of the available features with which the resulting coreference classifier yields the best clustering-level accuracy on held-out data. $$$$$ We apply a decision tree based approach to pronoun resolution in spoken dialogue.

 $$$$$ Our system deals with pronouns with NPand non-NP-antecedents.
 $$$$$ Corpus-based methods and machine learning techniques have been applied to anaphora resolution in written text with considerable success (Soon et al., 2001; Ng & Cardie, 2002, among others).
 $$$$$ We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features.

 $$$$$ Instead, rather simple distance metrics were preferred.
 $$$$$ We apply a decision tree based approach to pronoun resolution in spoken dialogue.
 $$$$$ Acknowledgements.
 $$$$$ A1: ... [he] ’s nine months old.... A2: [He] likes to dig around a little bit.

 $$$$$ To our knowledge the work presented here describes the first implemented system for corpus-based anaphora resolution dealing also with non-NP-antecedents.
 $$$$$ We again choose the best performing classifier and add the corresponding new feature to the model.
 $$$$$ The remaining expressions were then combined with the potential anaphor.
 $$$$$ E.g., Dagan & Itai (1991) presented a corpus-based approach to the resolution of the pronoun it, but they use a written text corpus and do not mention non-NP-antecedents at all.

 $$$$$ Our system deals with pronouns with NPand non-NP-antecedents.
 $$$$$ We distinguish two classes of features: NP-level features specify e.g. the grammatical function, NP form, morpho-syntax, grammatical case and the depth of embedding in the syntactical structure.
 $$$$$ Previous research could avoid dealing with this phenomenon by either applying the algorithm by hand (Eckert & Strube, 2000) or excluding these cases (Byron, 2002) from the evaluation.
 $$$$$ We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features.

 $$$$$ As for the first two pronouns in (B4), following Eckert & Strube (2000) and Byron (2002) we assume that referring expressions in disfluencies, abandoned utterances etc. are excluded from the resolution.
 $$$$$ For our purposes, we calculated TF for every word by counting its frequency in each of our twenty Switchboard dialogues separately.
 $$$$$ Corpus studies have shown that a significant amount of pronouns in spoken dialogue have non-NP-antecedents: Byron & Allen (1998) report that about 50% of the pronouns in the TRAINS93 corpus have non-NP-antecedents.

This suggests that a robust model of discourse structure could complement current robust interpretation systems, which tend to focus on only one aspect of the semantically ambiguous material, such as pronouns (e.g., Strube and Muller (2003)), definite descriptions (e.g., Vieira and Poesio (2000)), or temporal expressions (e.g., Wiebe et al (1998)). $$$$$ These anaphors then have VP-antecedents (“it ” in (B6) below) or sentential antecedents (“that ” in (B5)).
This suggests that a robust model of discourse structure could complement current robust interpretation systems, which tend to focus on only one aspect of the semantically ambiguous material, such as pronouns (e.g., Strube and Muller (2003)), definite descriptions (e.g., Vieira and Poesio (2000)), or temporal expressions (e.g., Wiebe et al (1998)). $$$$$ However, pronouns with NP-antecedents (like 3rd pers. masculine/feminine pronouns, cf. he in the example below) still constitute the largest fraction of all coreferential pronouns in the Switchboard corpus.
This suggests that a robust model of discourse structure could complement current robust interpretation systems, which tend to focus on only one aspect of the semantically ambiguous material, such as pronouns (e.g., Strube and Muller (2003)), definite descriptions (e.g., Vieira and Poesio (2000)), or temporal expressions (e.g., Wiebe et al (1998)). $$$$$ Paul et al. (1999) presented a corpus-based anaphora resolution algorithm for spoken dialogue.
This suggests that a robust model of discourse structure could complement current robust interpretation systems, which tend to focus on only one aspect of the semantically ambiguous material, such as pronouns (e.g., Strube and Muller (2003)), definite descriptions (e.g., Vieira and Poesio (2000)), or temporal expressions (e.g., Wiebe et al (1998)). $$$$$ The underlying assumption is that if a verb preceding a personal or demonstrative pronoun preferentially subcategorizes sentences or VPs, then the pronoun will be likely to have a nonNP-antecedent.

 $$$$$ The work presented here has been partially funded by the German Ministry of Research and Technology as part of the EMBASSI project (01 IL 904 D/2) and by the Klaus Tschira Foundation.
 $$$$$ Only a small fraction of these pronouns are true expletives (i.e., they precede a “weather” verb or are in constructions like “It seems that... ”.
 $$$$$ Previous research could avoid dealing with this phenomenon by either applying the algorithm by hand (Eckert & Strube, 2000) or excluding these cases (Byron, 2002) from the evaluation.

 $$$$$ Semantic filtering relies on knowledge about semantic restrictions associated with verbs, like semantic compatibility between subject and predicative noun or predicative adjective.
 $$$$$ If we removed them from there, the recall of our experiments would approach the 51% Byron (2002) mentioned for her system using only domain-independent semantic restrictions.
 $$$$$ This process was triggered by the markable at the current position being it or that.

 $$$$$ The third column gives the total number of coreference links (1250) in the corpus.
 $$$$$ For these features, each instance contains one value for the antecedent and one for the anaphor.
 $$$$$ As Byron admits, the major limitation of her algorithm is its dependence on domain-dependent resources which cover the domain entirely.
 $$$$$ The remaining three columns show precision, recall and f-measure, respectively.

 $$$$$ Because we included these cases in our evaluation we consider our approach at least comparable to Byron’s system when she uses only domain-independent semantics.
 $$$$$ E.g., utterance (B2) in the previous example does not contain any referring expressions.
 $$$$$ These anaphors then have VP-antecedents (“it ” in (B6) below) or sentential antecedents (“that ” in (B5)).
 $$$$$ The features are based on a verb list compiled from 553 Switchboard dialogues.3 For every verb occurring in the corpus, this list contains up to three entries giving the absolute count of cases where the verb has a direct argument of type NP, VP or S. When the verb list was produced, pronominal arguments were ignored.

 $$$$$ Soon et al. (2001) only compared baseline systems consisting of one feature each, only three of which yielded an f-measure greater than zero.
 $$$$$ We apply a decision tree based approach to pronoun resolution in spoken dialogue.
 $$$$$ We believe that our system is more robust than hers and that it can more easily be ported to new domains.
 $$$$$ Previous research could avoid dealing with this phenomenon by either applying the algorithm by hand (Eckert & Strube, 2000) or excluding these cases (Byron, 2002) from the evaluation.

 $$$$$ These pronouns are either expletive or vague, and cause the most trouble for a pronoun resolution algorithm, which will usually attempt to find an antecedent nonetheless.
 $$$$$ Spoken dialogue contains more pronouns with nonNP-antecedents than written text does.
 $$$$$ We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features.
 $$$$$ Finally, the feature wdist ic (25) measures the word-based distance between two expressions.
