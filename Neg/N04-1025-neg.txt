Si and Callan (2001) and Collins-Thompson and Callan (2004) have demonstrated the use of language models is more robust for web documents and passages. $$$$$ All of these use some type of word list to estimate semantic difficulty: Lexile (version 1.0) uses the Carroll-Davies-Richman corpus of 86,741 types (Carroll et al., 1971); Dale-Chall uses the Dale 3000 word list; and Fry's Short Passage Measure uses Dale & O'Rourke's ‘The Living Word Vocabulary’ of 43,000 types (Dale and O'Rourke, 1981).
Si and Callan (2001) and Collins-Thompson and Callan (2004) have demonstrated the use of language models is more robust for web documents and passages. $$$$$ The word ‘red’ does indeed show a steady decline in usage with grade level, while the probability of the word ‘determine’ increases.
Si and Callan (2001) and Collins-Thompson and Callan (2004) have demonstrated the use of language models is more robust for web documents and passages. $$$$$ We observed both types of behavior in our Web corpus.
Si and Callan (2001) and Collins-Thompson and Callan (2004) have demonstrated the use of language models is more robust for web documents and passages. $$$$$ There are numerous commercial reading comprehension tests available that have graded passages, but this would have reduced the emphasis we wanted on Web documents.

 $$$$$ For example, suppose we wish to estimate P(w|G) for a type w in a grade model G. If the type w occurs in at least one grade language model, we can perform regression with a Gaussian kernel (Hastie et al., 2001, p. 165) across all grade models to obtain a smoothed value for P(w|G).
 $$$$$ This work was supported by NSF grant IIS-0096139 and Dept. of Education grant R305G03123.
 $$$$$ For comparison, using the type/token ratio gave a mean correlation of 0.48.
 $$$$$ For English Web pages, we trained 12 language models corresponding to the 12 American grade levels.

In order to adjust search result presentation to the user's reading ability, we estimate the reading difficulty of each retrieved document using the Smoothed Unigram Model, a variation of a Multinomial Bayes classifier (Collins-Thompson and Callan, 2004). $$$$$ Each of these word lists may be thought of as a simplified language model.
In order to adjust search result presentation to the user's reading ability, we estimate the reading difficulty of each retrieved document using the Smoothed Unigram Model, a variation of a Multinomial Bayes classifier (Collins-Thompson and Callan, 2004). $$$$$ We derive L(Gi  |T) from (1) via Bayes’ Rule, which is: However, we first make two further assumptions: Substituting (1) into (2), simplifying, and taking logarithms, we obtain: where log Z represents combined factors involving passage length and the uniform prior P(Gi) which, according to our assumptions, do not influence the prediction outcome and may be ignored.
In order to adjust search result presentation to the user's reading ability, we estimate the reading difficulty of each retrieved document using the Smoothed Unigram Model, a variation of a Multinomial Bayes classifier (Collins-Thompson and Callan, 2004). $$$$$ The results of the evaluation are summarized in Table 1.
In order to adjust search result presentation to the user's reading ability, we estimate the reading difficulty of each retrieved document using the Smoothed Unigram Model, a variation of a Multinomial Bayes classifier (Collins-Thompson and Callan, 2004). $$$$$ In contrast, the Smoothed Unigram method had good accuracy across all test sets.

The latter has been found to be more effective as the former when approaching the reading level of subjects in primary and secondary school age (Collins-Thompson and Callan, 2004). $$$$$ This work was supported by NSF grant IIS-0096139 and Dept. of Education grant R305G03123.
The latter has been found to be more effective as the former when approaching the reading level of subjects in primary and secondary school age (Collins-Thompson and Callan, 2004). $$$$$ Instead, we use a mixture of grade models, which greatly improves accuracy.
The latter has been found to be more effective as the former when approaching the reading level of subjects in primary and secondary school age (Collins-Thompson and Callan, 2004). $$$$$ As an example of retraining, we showed that the classifier obtained good correlation with difficulty for at least two languages, English and French, with the only algorithm difference being a change in the morphology handling during feature processing.
The latter has been found to be more effective as the former when approaching the reading level of subjects in primary and secondary school age (Collins-Thompson and Callan, 2004). $$$$$ Another benefit of a language modeling approach is that we obtain a probability distribution across all grade models, not just a single grade prediction.

Collins-Thompson and Callan (2004) adopted a similar approach and used a smoothed unigram model to predict the grade levels of short passages and web documents. $$$$$ The important functions of relative likelihood appear to be general indicators such as the grade when a word is first introduced into usage, whether it generally increases or decreases with grade level, and whether it is most frequent in a particular grade range.
Collins-Thompson and Callan (2004) adopted a similar approach and used a smoothed unigram model to predict the grade levels of short passages and web documents. $$$$$ The resulting classifier is not specific to any particular subject and can be trained with relatively little labeled data.
Collins-Thompson and Callan (2004) adopted a similar approach and used a smoothed unigram model to predict the grade levels of short passages and web documents. $$$$$ Further study is required to explore just how much this model of vocabulary usage can be generalized to other languages.
Collins-Thompson and Callan (2004) adopted a similar approach and used a smoothed unigram model to predict the grade levels of short passages and web documents. $$$$$ Each of these word lists may be thought of as a simplified language model.

First, a language modeling approach generally gives much better accuracy for Web documents and short passages (Collins-Thompson and Callan, 2004). $$$$$ Chall, 1983, p. 63) have also observed that concrete words like ‘red’ become less likely in higher grades.
First, a language modeling approach generally gives much better accuracy for Web documents and short passages (Collins-Thompson and Callan, 2004). $$$$$ This is a well-known issue in language model applications, and it is standard to compensate for this sparseness by smoothing the frequencies in the trained models.
First, a language modeling approach generally gives much better accuracy for Web documents and short passages (Collins-Thompson and Callan, 2004). $$$$$ Any opinions, findings, conclusions, or recommendations expressed in this material are the authors’, and do not necessarily reflect those of the sponsors.
First, a language modeling approach generally gives much better accuracy for Web documents and short passages (Collins-Thompson and Callan, 2004). $$$$$ A token is defined as any word occurrence in the collection.

However, there are other important criteria for the user besides relevance, such as readability (Collins-Thompson and Callan, 2004), novelty (Harman, 2003), and authority (Kleinberg, 1998). $$$$$ Although this is a weak model, it can be trained from less data than more complex models, and turns out to give good accuracy for our problem.
However, there are other important criteria for the user besides relevance, such as readability (Collins-Thompson and Callan, 2004), novelty (Harman, 2003), and authority (Kleinberg, 1998). $$$$$ We thank the anonymous reviewers for their comments and Luo Si for helpful discussions.
However, there are other important criteria for the user besides relevance, such as readability (Collins-Thompson and Callan, 2004), novelty (Harman, 2003), and authority (Kleinberg, 1998). $$$$$ Their work was limited to a single subject domain - science - and three broad ranges of difficulty.

 $$$$$ Data from each of the 12 grades in the corpus are shown, ordered by ascending grade level.
 $$$$$ Error bars show 95% confidence interval.
 $$$$$ With training, we found the optimal kernel width to be 2.5 grade levels.

Advanced NLP-based readability metrics developed so far typically deal with English, with a few attempts devoted to other languages, namely French (Collins-Thompson and Callan, 2004), Portuguese (Aluisio et al, 2010) and German (Bruck, 2008). $$$$$ We found that we could reduce prediction variance with two changes to the model.
Advanced NLP-based readability metrics developed so far typically deal with English, with a few attempts devoted to other languages, namely French (Collins-Thompson and Callan, 2004), Portuguese (Aluisio et al, 2010) and German (Bruck, 2008). $$$$$ Similarly, higher grade levels use more abstract words with increased frequency.
Advanced NLP-based readability metrics developed so far typically deal with English, with a few attempts devoted to other languages, namely French (Collins-Thompson and Callan, 2004), Portuguese (Aluisio et al, 2010) and German (Bruck, 2008). $$$$$ An example of the set of log-likelihoods calculated across all 12 grade models, with a maximum point clearly evident, is shown in Figure 2.
Advanced NLP-based readability metrics developed so far typically deal with English, with a few attempts devoted to other languages, namely French (Collins-Thompson and Callan, 2004), Portuguese (Aluisio et al, 2010) and German (Bruck, 2008). $$$$$ While simple methods like modified naïve Bayes give reasonably good results, more sophisticated techniques may give more accurate predictions, especially at lower grades, where vocabulary progress is measured in months, not years.

Collins-Thompson and Callan (2004) used a smoothed unigram language model to predict the grade reading levels of web page documents and short passages. $$$$$ While simple methods like modified naïve Bayes give reasonably good results, more sophisticated techniques may give more accurate predictions, especially at lower grades, where vocabulary progress is measured in months, not years.
Collins-Thompson and Callan (2004) used a smoothed unigram language model to predict the grade reading levels of web page documents and short passages. $$$$$ Other words like ‘perimeter’ attain maximum probability in a specific grade range, perhaps corresponding to the period in which these concepts are emphasized in the curriculum.
Collins-Thompson and Callan (2004) used a smoothed unigram language model to predict the grade reading levels of web page documents and short passages. $$$$$ A unigram language model is defined by a list of types (words) and their individual probabilities.
Collins-Thompson and Callan (2004) used a smoothed unigram language model to predict the grade reading levels of web page documents and short passages. $$$$$ It was also unknown how much training data would be required to get good vocabulary coverage on Web data.

As a learning model, we use unigram language modelling introduced in (Collins-Thompson and Callan, 2004) to model the reading level of subjects in primary and secondary school. $$$$$ As we show in our evaluation, this generally results in better accuracy for Web documents and very short passages (less than 10 words).
As a learning model, we use unigram language modelling introduced in (Collins-Thompson and Callan, 2004) to model the reading level of subjects in primary and secondary school. $$$$$ This work was supported by NSF grant IIS-0096139 and Dept. of Education grant R305G03123.
As a learning model, we use unigram language modelling introduced in (Collins-Thompson and Callan, 2004) to model the reading level of subjects in primary and secondary school. $$$$$ Their work was limited to a single subject domain - science - and three broad ranges of difficulty.
As a learning model, we use unigram language modelling introduced in (Collins-Thompson and Callan, 2004) to model the reading level of subjects in primary and secondary school. $$$$$ The classifier's effectiveness is improved by explicitly modeling class relationships and smoothing frequency data across classes as well as within each class.

In some of the early works on statistical readability assessment, Si and Callan (2001) and Collins-Thompson and Callan (2004) reported the impact of using unigram language models to estimate the grade level of a given text. $$$$$ We do this for all language models, and select the one with maximum likelihood.
In some of the early works on statistical readability assessment, Si and Callan (2001) and Collins-Thompson and Callan (2004) reported the impact of using unigram language models to estimate the grade level of a given text. $$$$$ A token is defined as any word occurrence in the collection.
In some of the early works on statistical readability assessment, Si and Callan (2001) and Collins-Thompson and Callan (2004) reported the impact of using unigram language models to estimate the grade level of a given text. $$$$$ We thank the anonymous reviewers for their comments and Luo Si for helpful discussions.
In some of the early works on statistical readability assessment, Si and Callan (2001) and Collins-Thompson and Callan (2004) reported the impact of using unigram language models to estimate the grade level of a given text. $$$$$ First, smoothing across classes greatly reduces the training data required for individual grade models.

The widely used Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al, 1975) (as cited in (Collins-Thompson and Callan, 2004)). $$$$$ This helps explain the type coverage of about 90% on our test data.
The widely used Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al, 1975) (as cited in (Collins-Thompson and Callan, 2004)). $$$$$ For both English and French, the classifier maintains consistently good correlation with labeled grade level (0.63 to 0.79) across all test sets.
The widely used Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al, 1975) (as cited in (Collins-Thompson and Callan, 2004)). $$$$$ We thank the anonymous reviewers for their comments and Luo Si for helpful discussions.
The widely used Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al, 1975) (as cited in (Collins-Thompson and Callan, 2004)). $$$$$ While our model is also initially based on naïve Bayes, we do not treat each class as independent.

classifier to better capture the variance in word usage across grade levels (Collins-Thompson and Callan, 2004). $$$$$ While word difficulty is well-known to be an excellent predictor of reading difficulty (Chall & Edgar, 1995), it was not at all clear how effective our language model approach would be for predicting Web page reading difficulty.
classifier to better capture the variance in word usage across grade levels (Collins-Thompson and Callan, 2004). $$$$$ All of these use some type of word list to estimate semantic difficulty: Lexile (version 1.0) uses the Carroll-Davies-Richman corpus of 86,741 types (Carroll et al., 1971); Dale-Chall uses the Dale 3000 word list; and Fry's Short Passage Measure uses Dale & O'Rourke's ‘The Living Word Vocabulary’ of 43,000 types (Dale and O'Rourke, 1981).
classifier to better capture the variance in word usage across grade levels (Collins-Thompson and Callan, 2004). $$$$$ The classification algorithm was identical to that used for English except for a minor change in the feature selection step.

Other related work has used models of vocabulary (Collins-Thompson and Callan, 2004). $$$$$ We found that, because of the inflected nature of French and the relatively small training set, we obtained better accuracy by normalizing types into ‘type families’ by using a simplified stemming algorithm that removed plurals, masculine/feminine endings, and basic verb endings.
Other related work has used models of vocabulary (Collins-Thompson and Callan, 2004). $$$$$ By ‘borrowing’ word frequency data from nearby grades, the effective number of types for each grade model is multiplied by a factor of five or more.
Other related work has used models of vocabulary (Collins-Thompson and Callan, 2004). $$$$$ We demonstrate a new research approach to the problem of predicting the reading difficulty of a text passage, by recasting readability in terms of statistical language modeling.
Other related work has used models of vocabulary (Collins-Thompson and Callan, 2004). $$$$$ This is the trade-off that must be considered between overall RMS accuracy and the cost of gathering labeled data.

Early work on automatic readability analysis framed the problem as a classification task $$$$$ While this data is less-rigorously graded, such material also greatly reduces the cost of creating a readability measure, making it easy to modify for specific tasks or populations.
Early work on automatic readability analysis framed the problem as a classification task $$$$$ ‘Traditional’ readability measures are those that rely on two main factors: the familiarity of semantic units (words or phrases) and the complexity of syntax.
Early work on automatic readability analysis framed the problem as a classification task $$$$$ Some traditional semantic variables such as type-token ratio gave the best performance on commercial calibrated test passages, while our language modeling approach gave better accuracy for Web documents and very short passages (less than 10 words).

It is also the last formula published for French L1, if we except the adaptation of the model by Collins-Thompson and Callan (2004) to French. $$$$$ Section 4 defines the modified multinomial naïve Bayes model.
It is also the last formula published for French L1, if we except the adaptation of the model by Collins-Thompson and Callan (2004) to French. $$$$$ Further study is needed to explore ways to avoid over-fitting the classifier while reducing the expense of removing possibly useful features.
It is also the last formula published for French L1, if we except the adaptation of the model by Collins-Thompson and Callan (2004) to French. $$$$$ Some traditional variables like type/token ratio gave excellent correlation with difficulty on commercial leveled passages, but the same statistics performed inconsistently on Web-based test sets.
It is also the last formula published for French L1, if we except the adaptation of the model by Collins-Thompson and Callan (2004) to French. $$$$$ First, we define the following standard terms when referring to word frequencies in a corpus.
