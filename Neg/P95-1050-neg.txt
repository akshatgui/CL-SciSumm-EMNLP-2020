A similar idea is later applied by (Rapp 1995) to show the plausibility of correlations between words in non-parallel text. $$$$$ However, the minimum-curve in figure 1 suggests that there are some deep minima of the similarity function even in cases when many word correspondences are incorrect.
A similar idea is later applied by (Rapp 1995) to show the plausibility of correlations between words in non-parallel text. $$$$$ 'The logarithm has been removed from the mutual information measure since it is not defined for zero cooccurrences.
A similar idea is later applied by (Rapp 1995) to show the plausibility of correlations between words in non-parallel text. $$$$$ This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts.
A similar idea is later applied by (Rapp 1995) to show the plausibility of correlations between words in non-parallel text. $$$$$ Starting from an English vocabulary of six words and the corresponding German translations, table la and b show an English and a German co-occurrence matrix.

Theoretically, it is possible to use these methods to build a translation lexicon from scratch [Rapp, 1995]. $$$$$ The method proposed is based on the assumption that there is a correlation between the patterns of word cooccurrences in texts of different languages.
Theoretically, it is possible to use these methods to build a translation lexicon from scratch [Rapp, 1995]. $$$$$ It can be expected that with such a method the quality of the results depends on the thematic comparability of the corpora, but not on their degree of parallelism.
Theoretically, it is possible to use these methods to build a translation lexicon from scratch [Rapp, 1995]. $$$$$ For the prediction of word associations they achieved best results when modifying each entry in the cooccurrence matrix using the following formula: Hereby f(i&j) is the frequency of common occurrence of the two words i and j, and f(i) is the corpus frequency of word i.

 $$$$$ However, despite serious efforts in the compilation of corpora (Church & Mercer, 1993; Armstrong & Thompson, 1995) the availability of a large enough parallel corpus in a specific field and for a given pair of languages will always be the exception, not the rule.
 $$$$$ Equivalently, the German co-occurrence matrix was created by counting the co-occurrences of German word pairs in the German corpus.
 $$$$$ A simulation experiment was conducted in order to see whether the above assumptions concerning the similarity of co-occurrence patterns actually hold.
 $$$$$ In general, word order in the lines and columns of a co-occurrence matrix is independent of each other, but for the purpose of this paper can always be assumed to be equal without loss of generality.

 $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.
 $$$$$ The simulation was conducted by randomly permuting the word order of the German matrix and then computing the similarity s to the English matrix.
 $$$$$ For the prediction of word associations they achieved best results when modifying each entry in the cooccurrence matrix using the following formula: Hereby f(i&j) is the frequency of common occurrence of the two words i and j, and f(i) is the corpus frequency of word i.
 $$$$$ This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts.

 $$$$$ An algorithm currently under construction therefore searches for many local minima, and tries to find out what word correspondences are the most reliable ones.
 $$$$$ 'The logarithm has been removed from the mutual information measure since it is not defined for zero cooccurrences.
 $$$$$ The English corpus consists of the Brown Corpus, texts from the Wall Street Journal, Grolier 's Electronic Encyclopedia and scientific abstracts from different fields.
 $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.

 $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.
 $$$$$ Common algorithms for sentence and word-alignment allow the automatic identification of word translations from parallel texts.
 $$$$$ This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts.

Rapp (1995), Grefenstette (1998), Fung and Lo (1998), and Kaji (2003) derived bilingual lexicons or word senses from such corpora. $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.
Rapp (1995), Grefenstette (1998), Fung and Lo (1998), and Kaji (2003) derived bilingual lexicons or word senses from such corpora. $$$$$ The method proposed is based on the assumption that there is a correlation between the patterns of word cooccurrences in texts of different languages.
Rapp (1995), Grefenstette (1998), Fung and Lo (1998), and Kaji (2003) derived bilingual lexicons or word senses from such corpora. $$$$$ 2 Normalization was conducted in such a way that the sum of all matrix entries adds up to the number of fields in the matrix. of the English and the German matrix and the number of non-corresponding word positions c for 3 formulas.
Rapp (1995), Grefenstette (1998), Fung and Lo (1998), and Kaji (2003) derived bilingual lexicons or word senses from such corpora. $$$$$ Most of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other.

Rapp (1995) proposed a computationally demanding matrix permutation method which maximizes a similarity between co-occurrence matrices in two languages. $$$$$ Thanks also to Graham Russell and three anonymous reviewers for valuable comments on the manuscript.
Rapp (1995) proposed a computationally demanding matrix permutation method which maximizes a similarity between co-occurrence matrices in two languages. $$$$$ Most of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other.
Rapp (1995) proposed a computationally demanding matrix permutation method which maximizes a similarity between co-occurrence matrices in two languages. $$$$$ The dotted curves in figure 1 are the minimum and maximum values in each set of 1000 similarity values for formula 1.
Rapp (1995) proposed a computationally demanding matrix permutation method which maximizes a similarity between co-occurrence matrices in two languages. $$$$$ Thanks also to Graham Russell and three anonymous reviewers for valuable comments on the manuscript.

In order to expand the dictionaries using a set of monolingual comparable corpora, the basic approach pioneered by Fung and McKeown (1997) and Rapp (1995, 1999) is to be further developed and refined in the second phase of the project as to obtain a practical tool that can be used in an industrial context. $$$$$ 2 Normalization was conducted in such a way that the sum of all matrix entries adds up to the number of fields in the matrix. of the English and the German matrix and the number of non-corresponding word positions c for 3 formulas.
In order to expand the dictionaries using a set of monolingual comparable corpora, the basic approach pioneered by Fung and McKeown (1997) and Rapp (1995, 1999) is to be further developed and refined in the second phase of the project as to obtain a practical tool that can be used in an industrial context. $$$$$ Thanks also to Graham Russell and three anonymous reviewers for valuable comments on the manuscript.
In order to expand the dictionaries using a set of monolingual comparable corpora, the basic approach pioneered by Fung and McKeown (1997) and Rapp (1995, 1999) is to be further developed and refined in the second phase of the project as to obtain a practical tool that can be used in an industrial context. $$$$$ The common occurrence of two words was defined as both words being separated by at most 11 other words.
In order to expand the dictionaries using a set of monolingual comparable corpora, the basic approach pioneered by Fung and McKeown (1997) and Rapp (1995, 1999) is to be further developed and refined in the second phase of the project as to obtain a practical tool that can be used in an industrial context. $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.

In particular, we extend the long line of work on inducing translation lexicons (beginning with Rapp (1995)) and propose to use multiple independent cues present in monolingual texts to estimate lexical and phrasal translation probabilities for large, MT-scale phrase-tables. $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.
In particular, we extend the long line of work on inducing translation lexicons (beginning with Rapp (1995)) and propose to use multiple independent cues present in monolingual texts to estimate lexical and phrasal translation probabilities for large, MT-scale phrase-tables. $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.
In particular, we extend the long line of work on inducing translation lexicons (beginning with Rapp (1995)) and propose to use multiple independent cues present in monolingual texts to estimate lexical and phrasal translation probabilities for large, MT-scale phrase-tables. $$$$$ The word co-occurrences were computed on the basis of an English corpus of 33 and a German corpus of 46 million words.

Rapp (1995) was the first to propose using non-parallel texts to learn the translations of words. $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.
Rapp (1995) was the first to propose using non-parallel texts to learn the translations of words. $$$$$ The results achieved with these algorithms have been found useful for the compilation of dictionaries, for checking the consistency of terminological usage in translations, and for assisting the terminological work of translators and interpreters.
Rapp (1995) was the first to propose using non-parallel texts to learn the translations of words. $$$$$ In this experiment, for an equivalent English and German vocabulary two co-occurrence matrices were computed and then compared.
Rapp (1995) was the first to propose using non-parallel texts to learn the translations of words. $$$$$ In these matrices the entries belonging to those pairs of words that in texts co-occur more frequently than expected have been marked with a dot.

Previous research on bilingual lexicon induction learned translations only for a small number of high frequency words (e.g. 100 nouns in Rapp (1995), 1,000 most frequent words nouin Koehn and Knight (2002), or 2,000 most frequent nouns in Haghighi et al (2008)). $$$$$ However, in this paper it is further assumed that the co-occurrence patterns in original texts are not fundamentally different from those in translated texts.
Previous research on bilingual lexicon induction learned translations only for a small number of high frequency words (e.g. 100 nouns in Rapp (1995), 1,000 most frequent words nouin Koehn and Knight (2002), or 2,000 most frequent nouns in Haghighi et al (2008)). $$$$$ The dotted curves in figure 1 are the minimum and maximum values in each set of 1000 similarity values for formula 1.
Previous research on bilingual lexicon induction learned translations only for a small number of high frequency words (e.g. 100 nouns in Rapp (1995), 1,000 most frequent words nouin Koehn and Knight (2002), or 2,000 most frequent nouns in Haghighi et al (2008)). $$$$$ The dotted curves in figure 1 are the minimum and maximum values in each set of 1000 similarity values for formula 1.
Previous research on bilingual lexicon induction learned translations only for a small number of high frequency words (e.g. 100 nouns in Rapp (1995), 1,000 most frequent words nouin Koehn and Knight (2002), or 2,000 most frequent nouns in Haghighi et al (2008)). $$$$$ The results achieved with these algorithms have been found useful for the compilation of dictionaries, for checking the consistency of terminological usage in translations, and for assisting the terminological work of translators and interpreters.

Building a dictionary from scratch is not possible this way or at least computationally un-feasible (see Rapp, 1995). $$$$$ If now the word order of the English matrix is permuted until the resulting pattern of dots is most similar to that of the German matrix (see table lc), then this increases the likelihood that the English and German words are in corresponding order.
Building a dictionary from scratch is not possible this way or at least computationally un-feasible (see Rapp, 1995). $$$$$ It can be expected that with such a method the quality of the results depends on the thematic comparability of the corpora, but not on their degree of parallelism.
Building a dictionary from scratch is not possible this way or at least computationally un-feasible (see Rapp, 1995). $$$$$ • Ambiguities in word translations can be taken into account by working with continuous probabilities to judge whether a word translation is correct instead of making a binary decision.
Building a dictionary from scratch is not possible this way or at least computationally un-feasible (see Rapp, 1995). $$$$$ However, despite serious efforts in the compilation of corpora (Church & Mercer, 1993; Armstrong & Thompson, 1995) the availability of a large enough parallel corpus in a specific field and for a given pair of languages will always be the exception, not the rule.

Approaches for lexicon extraction from comparable corpora have been proposed that use the bag of-words model to find words that occur in similar lexical contexts (Rapp, 1995). $$$$$ The common occurrence of two words was defined as both words being separated by at most 11 other words.
Approaches for lexicon extraction from comparable corpora have been proposed that use the bag of-words model to find words that occur in similar lexical contexts (Rapp, 1995). $$$$$ Most of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other.
Approaches for lexicon extraction from comparable corpora have been proposed that use the bag of-words model to find words that occur in similar lexical contexts (Rapp, 1995). $$$$$ Since the acquisition of non-parallel texts is usually much easier, it would be desirable to have a program that can determine the translations of words from comparable or even unrelated texts.
Approaches for lexicon extraction from comparable corpora have been proposed that use the bag of-words model to find words that occur in similar lexical contexts (Rapp, 1995). $$$$$ The monotonically increasing character of the curves in figure 1 indicates that in principle it should be possible to find word correspondences in two matrices of different languages by randomly permuting one of the matrices until the similarity function s reaches a minimum and thus indicates maximum similarity.

One of the first works in the area of comparable corpora mining was based on word co-occurrence based approach (Rapp, 1995). $$$$$ 'The logarithm has been removed from the mutual information measure since it is not defined for zero cooccurrences.
One of the first works in the area of comparable corpora mining was based on word co-occurrence based approach (Rapp, 1995). $$$$$ Equivalently, the German co-occurrence matrix was created by counting the co-occurrences of German word pairs in the German corpus.
One of the first works in the area of comparable corpora mining was based on word co-occurrence based approach (Rapp, 1995). $$$$$ It is assumed that there is a correlation between the co-occurrences of words which are translations of each other.
One of the first works in the area of comparable corpora mining was based on word co-occurrence based approach (Rapp, 1995). $$$$$ This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts.

The idea to acquire translation candidates based on comparable and unrelated corpora comes from (Rapp, 1995). $$$$$ If now the word order of the English matrix is permuted until the resulting pattern of dots is most similar to that of the German matrix (see table lc), then this increases the likelihood that the English and German words are in corresponding order.
The idea to acquire translation candidates based on comparable and unrelated corpora comes from (Rapp, 1995). $$$$$ Since the acquisition of non-parallel texts is usually much easier, it would be desirable to have a program that can determine the translations of words from comparable or even unrelated texts.
The idea to acquire translation candidates based on comparable and unrelated corpora comes from (Rapp, 1995). $$$$$ As a measure for matrix similarity the sum of the absolute differences of the values at corresponding matrix positions was used.
The idea to acquire translation candidates based on comparable and unrelated corpora comes from (Rapp, 1995). $$$$$ This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts.

Rapp (1995) suggested his idea about the usage of context vectors in order to find the words that are the translation of each other in comparable corpora. $$$$$ I thank Susan Armstrong and Manfred Wettler for their support of this project.
Rapp (1995) suggested his idea about the usage of context vectors in order to find the words that are the translation of each other in comparable corpora. $$$$$ Most of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other.
Rapp (1995) suggested his idea about the usage of context vectors in order to find the words that are the translation of each other in comparable corpora. $$$$$ The results achieved with these algorithms have been found useful for the compilation of dictionaries, for checking the consistency of terminological usage in translations, and for assisting the terminological work of translators and interpreters.

The underlying assumption is that translations of words that are related in one language are also related in the other language (Rapp 1995). $$$$$ The English corpus consists of the Brown Corpus, texts from the Wall Street Journal, Grolier 's Electronic Encyclopedia and scientific abstracts from different fields.
The underlying assumption is that translations of words that are related in one language are also related in the other language (Rapp 1995). $$$$$ As a measure for matrix similarity the sum of the absolute differences of the values at corresponding matrix positions was used.
The underlying assumption is that translations of words that are related in one language are also related in the other language (Rapp 1995). $$$$$ Starting from an English vocabulary of six words and the corresponding German translations, table la and b show an English and a German co-occurrence matrix.
The underlying assumption is that translations of words that are related in one language are also related in the other language (Rapp 1995). $$$$$ Since the acquisition of non-parallel texts is usually much easier, it would be desirable to have a program that can determine the translations of words from comparable or even unrelated texts.

In this situation, Rapp (1995) proposed using a clue different from the three mentioned above: His co-occurrence clue is based on the assumption that there is a correlation between co occurrence patterns in different languages. $$$$$ This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts.
In this situation, Rapp (1995) proposed using a clue different from the three mentioned above: His co-occurrence clue is based on the assumption that there is a correlation between co occurrence patterns in different languages. $$$$$ If now the word order of the English matrix is permuted until the resulting pattern of dots is most similar to that of the German matrix (see table lc), then this increases the likelihood that the English and German words are in corresponding order.
In this situation, Rapp (1995) proposed using a clue different from the three mentioned above: His co-occurrence clue is based on the assumption that there is a correlation between co occurrence patterns in different languages. $$$$$ The German corpus is a compilation of mainly newspaper texts from Frankfurter Rundschau, Die Zeit and Mannheimer Morgen.
In this situation, Rapp (1995) proposed using a clue different from the three mentioned above: His co-occurrence clue is based on the assumption that there is a correlation between co occurrence patterns in different languages. $$$$$ 'The logarithm has been removed from the mutual information measure since it is not defined for zero cooccurrences.

By presupposing a lexicon of seed words, she avoids the prohibitively expensive computational effort encountered by Rapp (1995). $$$$$ If — for example — in a text of one language two words A and B co-occur more often than expected from chance, then in a text of another language those words which are translations of A and B should also co-occur more frequently than expected.
By presupposing a lexicon of seed words, she avoids the prohibitively expensive computational effort encountered by Rapp (1995). $$$$$ This similarity measure leads to a value of zero for identical matrices, and to a value of 20 000 in the case that a non-zero entry in one of the 100 * 100 matrices always corresponds to a zero-value in the other.
By presupposing a lexicon of seed words, she avoids the prohibitively expensive computational effort encountered by Rapp (1995). $$$$$ An algorithm currently under construction therefore searches for many local minima, and tries to find out what word correspondences are the most reliable ones.
