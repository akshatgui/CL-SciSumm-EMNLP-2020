Cardie and Wagstaff (1999) combined the use of WordNet with proper name gazetteers in order to obtain information on the compatibility of coreferential NPs in their clustering algorithm. $$$$$ In contrast to other approaches to coreference resolution, ours is unsupervised and offers several potential advantages over existing methods: no annotated training data is required, the distance metric can be easily extended to account for additional linguistic information as it becomes available to the NLP system, and the clustering approach provides a flexible mechanism for combining a variety of constraints and preferences to impose a partitioning on the noun phrases in a text into coreference equivalence classes.
Cardie and Wagstaff (1999) combined the use of WordNet with proper name gazetteers in order to obtain information on the compatibility of coreferential NPs in their clustering algorithm. $$$$$ Nevertheless, the approach can be improved in a number of ways.

Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ The second baseline marks as coreferent any two noun phrases that have a word in common.
Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ First, each noun phrase in a document is represented as a vector of attribute-value pairs.
Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ While human audiences have little trouble mapping a collection of noun phrases onto the same entity, this task of noun phrase (NP) coreference resolution can present a formidable challenge to an NLP system.
Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ The remaining (unbracketed) noun phrases have no coreferent NPs and are considered singleton equivalence classes.

The feature semantic class used by Cardie and Wagstaff (1999) seems to be a domain-dependent one which can only be used for the MUC domain and similar ones. $$$$$ We would like to thank David Pierce for his formatting and technical advice.
The feature semantic class used by Cardie and Wagstaff (1999) seems to be a domain-dependent one which can only be used for the MUC domain and similar ones. $$$$$ Most implemented a series of linguistic constraints similar in spirit to those employed in our system.
The feature semantic class used by Cardie and Wagstaff (1999) seems to be a domain-dependent one which can only be used for the MUC domain and similar ones. $$$$$ This work was supported in part by NSF Grant IRI9624639 and a National Science Foundation Graduate fellowship.
The feature semantic class used by Cardie and Wagstaff (1999) seems to be a domain-dependent one which can only be used for the MUC domain and similar ones. $$$$$ Evaluation of the approach appears in Section 4.

Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ Ge et al. (1998) present a probabilistic model for pronoun resolution trained on a small subset of the Penn Treebank Wall Street Journal corpus (Marcus et al., 1993).
Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ While human audiences have little trouble mapping a collection of noun phrases onto the same entity, this task of noun phrase (NP) coreference resolution can present a formidable challenge to an NLP system.
Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ We would like to thank David Pierce for his formatting and technical advice.
Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ We would also like to make use of cues from centering theory and plan to explore the possibility of learning the weights associated with each term in the distance metric.

However, the cost is the decrease in performance to about 53% F-measure on the same data (Cardie and Wagstaff, 1999) which may be unsuitable for a lot of tasks. $$$$$ We would like to thank David Pierce for his formatting and technical advice.
However, the cost is the decrease in performance to about 53% F-measure on the same data (Cardie and Wagstaff, 1999) which may be unsuitable for a lot of tasks. $$$$$ Many natural language processing (NLP) applications require accurate noun phrase coreference resolution: They require a means for determining which noun phrases in a text or dialogue refer to the same real-world entity.
However, the cost is the decrease in performance to about 53% F-measure on the same data (Cardie and Wagstaff, 1999) which may be unsuitable for a lot of tasks. $$$$$ This work was supported in part by NSF Grant IRI9624639 and a National Science Foundation Graduate fellowship.

Although approaches to coreference resolution that rely only on clustering could easily enforce transitivity (as in Cardie and Wagstaff (1999)), they have not performed as well as state-of-the-art approaches to coreference. $$$$$ The clustering algorithm appears to provide a flexible mechanism for coordinating the application of context-independent and context-dependent constraints and preferences for accurate partitioning of noun phrases into coreference equivalence classes.
Although approaches to coreference resolution that rely only on clustering could easily enforce transitivity (as in Cardie and Wagstaff (1999)), they have not performed as well as state-of-the-art approaches to coreference. $$$$$ Azzam et al. (1998), for example, describe a focus-based approach that incorporates discourse information when resolving pronouns.
Although approaches to coreference resolution that rely only on clustering could easily enforce transitivity (as in Cardie and Wagstaff (1999)), they have not performed as well as state-of-the-art approaches to coreference. $$$$$ As supervised learning algorithms, both systems require a fairly large amount of training data that has been annotated with coreference resolution information.
Although approaches to coreference resolution that rely only on clustering could easily enforce transitivity (as in Cardie and Wagstaff (1999)), they have not performed as well as state-of-the-art approaches to coreference. $$$$$ Most implemented a series of linguistic constraints similar in spirit to those employed in our system.

 $$$$$ Our methods for producing the noun phrase feature vector are also overly simplistic.
 $$$$$ Nevertheless, the approach can be improved in a number of ways.
 $$$$$ We would like to thank David Pierce for his formatting and technical advice.

Cardie and Wagstaff (1999) have proposed an unsupervised approach which also incorporates cluster information into consideration. $$$$$ Furthermore, our approach has a number of important advantages over existing learning and non-learning methods for coreference resolution: As a result, we believe that viewing noun phrase coreference as clustering provides a promising framework for corpus-based coreference resolution.
Cardie and Wagstaff (1999) have proposed an unsupervised approach which also incorporates cluster information into consideration. $$$$$ Here, NPi subsumes NP2, giving them a distance of â€”oo via the word substring term; however, NPi's semantic class is COMPANY, and NP2's class is OBJECT, generating a distance of oo via the semantic class feature.
Cardie and Wagstaff (1999) have proposed an unsupervised approach which also incorporates cluster information into consideration. $$$$$ Given the feature vector for each noun phrase, the clustering algorithm coordinates the application of context-independent and context-dependent coreference constraints and preferences to partition the noun phrases into equivalence classes, one class for each real-world entity mentioned in the text.

The closest comparable unsupervised system is Cardie and Wagstaff (1999) who use pairwise NP distances to cluster document mentions. $$$$$ This work was supported in part by NSF Grant IRI9624639 and a National Science Foundation Graduate fellowship.
The closest comparable unsupervised system is Cardie and Wagstaff (1999) who use pairwise NP distances to cluster document mentions. $$$$$ This work was supported in part by NSF Grant IRI9624639 and a National Science Foundation Graduate fellowship.
The closest comparable unsupervised system is Cardie and Wagstaff (1999) who use pairwise NP distances to cluster document mentions. $$$$$ Our current distance metric and noun phrase instance representation are only first, and admittedly very coarse, approximations to those ultimately required for handling the wide variety of anaphoric expressions that comprise noun phrase coreference.
The closest comparable unsupervised system is Cardie and Wagstaff (1999) who use pairwise NP distances to cluster document mentions. $$$$$ It differs from existing methods in that it views coreference resolution as a clustering task.

Similarly, approaches to coreference resolution (Cardie and Wagstaff, 1999) use clustering to identify groups of references to the same entity. $$$$$ Despite a large corpus (150 million words), their approach suffers from sparse data problems, but works well when enough relevant data is available.
Similarly, approaches to coreference resolution (Cardie and Wagstaff, 1999) use clustering to identify groups of references to the same entity. $$$$$ More importantly, the clustering approach outperforms the only MUC-6 system to treat coreference resolution as a learning problem.
Similarly, approaches to coreference resolution (Cardie and Wagstaff, 1999) use clustering to identify groups of references to the same entity. $$$$$ Handling the JS class alone requires recognizing coreferent NPs in appositive and genitive constructions as well as those that occur as proper names, possessive pronouns, and definite NPs.
Similarly, approaches to coreference resolution (Cardie and Wagstaff, 1999) use clustering to identify groups of references to the same entity. $$$$$ The noun phrase instances for this fragment are shown in Table 3.

The system of Cardie and Wagstaff (1999) uses the node distance in WordNet (with an upper limit of 4) as one component in the distance measure that guides their clustering algorithm. $$$$$ It is commonly observed that a human speaker or author avoids repetition by using a variety of noun phrases to refer to the same entity.
The system of Cardie and Wagstaff (1999) uses the node distance in WordNet (with an upper limit of 4) as one component in the distance measure that guides their clustering algorithm. $$$$$ We would like to thank David Pierce for his formatting and technical advice.
The system of Cardie and Wagstaff (1999) uses the node distance in WordNet (with an upper limit of 4) as one component in the distance measure that guides their clustering algorithm. $$$$$ They also make use of more extensive syntactic information (such as the thematic role each noun phrase plays), and thus require a fuller parse of the input text.
The system of Cardie and Wagstaff (1999) uses the node distance in WordNet (with an upper limit of 4) as one component in the distance measure that guides their clustering algorithm. $$$$$ This work was supported in part by NSF Grant IRI9624639 and a National Science Foundation Graduate fellowship.

For the first subtask we use the same set of features as in Cardie and Wagstaff (1999). $$$$$ It differs from existing methods in that it views coreference resolution as a clustering task.
For the first subtask we use the same set of features as in Cardie and Wagstaff (1999). $$$$$ By separating context-independent and recall levels are fairly low.
For the first subtask we use the same set of features as in Cardie and Wagstaff (1999). $$$$$ Azzam et al. (1998), for example, describe a focus-based approach that incorporates discourse information when resolving pronouns.

Coreference resolution on text datasets is well studied (e.g., (Cardie and Wagstaff, 1999)). $$$$$ Ge et al. (1998) present a probabilistic model for pronoun resolution trained on a small subset of the Penn Treebank Wall Street Journal corpus (Marcus et al., 1993).
Coreference resolution on text datasets is well studied (e.g., (Cardie and Wagstaff, 1999)). $$$$$ We would also like to make use of cues from centering theory and plan to explore the possibility of learning the weights associated with each term in the distance metric.
Coreference resolution on text datasets is well studied (e.g., (Cardie and Wagstaff, 1999)). $$$$$ The clustering algorithm appears to provide a flexible mechanism for coordinating the application of context-independent and context-dependent constraints and preferences for accurate partitioning of noun phrases into coreference equivalence classes.
Coreference resolution on text datasets is well studied (e.g., (Cardie and Wagstaff, 1999)). $$$$$ In an evaluation on the MUC-6 coreference resolution corpus, the algorithm achieves an F-measure of 53.6%, placing it firmly between the worst (40%) and best (65%) systems in the MUC-6 evaluation.

We employ a set of verbal features that is similar to the features used by state-of-the-art coreference resolution systems that operate on text (e.g., (Cardieand Wagstaff, 1999)). $$$$$ The main advantage of our approach is that all constraints and preferences are represented neatly in the distance metric (and radius r), allowing for simple modification of this measure to incorporate new knowledge sources.
We employ a set of verbal features that is similar to the features used by state-of-the-art coreference resolution systems that operate on text (e.g., (Cardieand Wagstaff, 1999)). $$$$$ Additional analysis and evaluation on new corpora are required to determine the generality of the approach.
We employ a set of verbal features that is similar to the features used by state-of-the-art coreference resolution systems that operate on text (e.g., (Cardieand Wagstaff, 1999)). $$$$$ All results are reported using the standard measures of recall and precision or F-measure (which combines recall and precision equally).

Coreference resolution is often performed in two phases $$$$$ We have presented a new approach to noun phrase coreference resolution that treats the problem as a clustering task.
Coreference resolution is often performed in two phases $$$$$ In an evaluation on the MUC-6 coreference resolution corpus, the algorithm achieves an F-measure of 53.6%, placing it firmly between the worst (40%) and best (65%) systems in the MUC-6 evaluation.
Coreference resolution is often performed in two phases $$$$$ In an evaluation on the MUC-6 coreference resolution corpus, the algorithm achieves an F-measure of 53.6%, placing it firmly between the worst (40%) and best (65%) systems in the MUC-6 evaluation.
Coreference resolution is often performed in two phases $$$$$ Nevertheless, the relatively strong performance of the technique indicates that clustering constitutes a powerful and natural approach to noun phrase coreference resolution.

The verbal features that we have included are a representative sample from the literature (e.g., (Cardie and Wagstaff, 1999)). $$$$$ Our approach, on the other hand, uses unsupervised learning4 and requires no training data.5 In addition, both MLR and RESOLVE require an additional mechanism to coordinate the collection of pairwise coreference decisions.
The verbal features that we have included are a representative sample from the literature (e.g., (Cardie and Wagstaff, 1999)). $$$$$ Additional analysis and evaluation on new corpora are required to determine the generality of the approach.
The verbal features that we have included are a representative sample from the literature (e.g., (Cardie and Wagstaff, 1999)). $$$$$ We would like to thank David Pierce for his formatting and technical advice.
The verbal features that we have included are a representative sample from the literature (e.g., (Cardie and Wagstaff, 1999)). $$$$$ As will be explained below, however, two such NPs can be merged into the same equivalence class by the clustering algorithm if there is enough other evidence that they are similar (i.e. there are other, coreferent noun phrase(s) sufficiently close to both).

An unsupervised approach to the resolution of definite NPs was applied by Cardie and Wagstaff (1999). $$$$$ Evaluation of the approach appears in Section 4.
An unsupervised approach to the resolution of definite NPs was applied by Cardie and Wagstaff (1999). $$$$$ Furthermore, our approach has a number of important advantages over existing learning and non-learning methods for coreference resolution: As a result, we believe that viewing noun phrase coreference as clustering provides a promising framework for corpus-based coreference resolution.
An unsupervised approach to the resolution of definite NPs was applied by Cardie and Wagstaff (1999). $$$$$ While human audiences have little trouble mapping a collection of noun phrases onto the same entity, this task of noun phrase (NP) coreference resolution can present a formidable challenge to an NLP system.

Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ We would also like to make use of cues from centering theory and plan to explore the possibility of learning the weights associated with each term in the distance metric.
Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ This paper introduces a new, unsupervised algorithm for noun phrase coreference resolution.
Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ We have presented a new approach to noun phrase coreference resolution that treats the problem as a clustering task.
Cardie and Wagstaff (1999) describe an unsupervised clustering approach to noun phrase coreference resolution in which features are assigned to single noun phrases only. $$$$$ In an evaluation on the MUC-6 coreference resolution corpus, the algorithm achieves an F-measure of 53.6%, placing it firmly between the worst (40%) and best (65%) systems in the MUC-6 evaluation.

The feature semantic class used by Cardie and Wagstaff (1999) seems to be a domain-dependent one which can only be used for the MUC domain and similar ones. $$$$$ We would like to thank David Pierce for his formatting and technical advice.
The feature semantic class used by Cardie and Wagstaff (1999) seems to be a domain-dependent one which can only be used for the MUC domain and similar ones. $$$$$ Additional analysis and evaluation on new corpora are required to determine the generality of the approach.
The feature semantic class used by Cardie and Wagstaff (1999) seems to be a domain-dependent one which can only be used for the MUC domain and similar ones. $$$$$ This work was supported in part by NSF Grant IRI9624639 and a National Science Foundation Graduate fellowship.

Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ First, each noun phrase in a document is represented as a vector of attribute-value pairs.
Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ This work was supported in part by NSF Grant IRI9624639 and a National Science Foundation Graduate fellowship.
Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ Handling the JS class alone requires recognizing coreferent NPs in appositive and genitive constructions as well as those that occur as proper names, possessive pronouns, and definite NPs.
Cardie and Wagstaff (1999) report a performance of 53.6% F-measure (evaluated according to Vilain et al (1995)). $$$$$ The clustering algorithm is given in Figure 2.
