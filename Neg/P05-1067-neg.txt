Dependency trees capture important aspects of functional relationships between words and have been shown to be useful in many applications including relation extraction (Culotta and Sorensen, 2004), paraphrase acquisition (Shinyama et al, 2002) and machine translation (Ding and Palmer, 2005). $$$$$ The evaluation shows that the SDIG system outperforms an IBM Model 4 based system in both speed and quality.
Dependency trees capture important aspects of functional relationships between words and have been shown to be useful in many applications including relation extraction (Culotta and Sorensen, 2004), paraphrase acquisition (Shinyama et al, 2002) and machine translation (Ding and Palmer, 2005). $$$$$ Note that this is a nondeterministic process.
Dependency trees capture important aspects of functional relationships between words and have been shown to be useful in many applications including relation extraction (Culotta and Sorensen, 2004), paraphrase acquisition (Shinyama et al, 2002) and machine translation (Ding and Palmer, 2005). $$$$$ A graphical model for the transducer is defined and a polynomial time decoding algorithm is introduced.

A syntax-based system might be able to check this sort of agreement if it produced a target-side dependency tree as in Ding and Palmer (2005). $$$$$ However, we did notice that this simple “ostrich” treatment caused outputs such as “foreign financial institutions the president of”.
A syntax-based system might be able to check this sort of agreement if it produced a target-side dependency tree as in Ding and Palmer (2005). $$$$$ Synchronous Tree Adjoining Grammars, proposed by (Shieber and Schabes, 1990), were introduced primarily for semantics but were later also proposed for translation.
A syntax-based system might be able to check this sort of agreement if it produced a target-side dependency tree as in Ding and Palmer (2005). $$$$$ Second, we describe the graphical model for the machine translation task, which can also be viewed as a stochastic tree-to-tree transducer.
A syntax-based system might be able to check this sort of agreement if it produced a target-side dependency tree as in Ding and Palmer (2005). $$$$$ The final NIST and Bleu scores are marked with bold fonts.

Ding and Palmer (2005) improve over word-based MT baseline with a formalism very similar to STSG. $$$$$ Section 4 defines the tree-to-tree transducer and the graphical model for the stochastic tree-to-tree transduction process and introduces a polynomial time decoding algorithm for the transducer.
Ding and Palmer (2005) improve over word-based MT baseline with a formalism very similar to STSG. $$$$$ (Wu, 1997) introduced a polynomial-time solution for the alignment problem based on synchronous binary trees.
Ding and Palmer (2005) improve over word-based MT baseline with a formalism very similar to STSG. $$$$$ Second, we describe the graphical model for the machine translation task, which can also be viewed as a stochastic tree-to-tree transducer.
Ding and Palmer (2005) improve over word-based MT baseline with a formalism very similar to STSG. $$$$$ Future work includes a full-fledged version of SDIG and a more sophisticated MT pipeline with possibly a tri-gram language model for decoding.

Dependency parsing is useful for applications such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). $$$$$ A synchronous derivation process for the two syntactic structures of both languages suggests the level of cross-lingual isomorphism between the two trees (e.g.
Dependency parsing is useful for applications such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). $$$$$ We believe difficulties in inducing a synchronous grammar or a set of tree transduction rules from large scale parallel corpora are caused by: Hajic et al. (2002) limited non-isomorphism by n-to-m matching of nodes in the two trees.
Dependency parsing is useful for applications such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). $$$$$ We evaluate the outputs of our MT system using the NIST and Bleu automatic MT evaluation software.
Dependency parsing is useful for applications such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). $$$$$ However, we did notice that this simple “ostrich” treatment caused outputs such as “foreign financial institutions the president of”.

Ding and Palmer (2005) introduced a version of probabilistic extension of Synchronous Dependency Insertion Grammars (SDIG) to deal with the pervasive structure divergence. $$$$$ In our implementation, the different decompositions of the input dependency tree are stored in a shared forest structure, utilizing the dynamic programming property of the tree structures explicitly.
Ding and Palmer (2005) introduced a version of probabilistic extension of Synchronous Dependency Insertion Grammars (SDIG) to deal with the pervasive structure divergence. $$$$$ Synchronous dependency insertion grammars are a version of synchronous grammars defined on dependency trees.
Ding and Palmer (2005) introduced a version of probabilistic extension of Synchronous Dependency Insertion Grammars (SDIG) to deal with the pervasive structure divergence. $$$$$ For a word pair (ei, fj)for the tentative partitioning operation, we briefly describe the heuristics: the foreign words in the current tree.

Dependency trees have been used in a variety of NLP applications, such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). $$$$$ The MaxEnt model is trained using the same word level aligned parallel corpus as the one in Section 3.1.
Dependency trees have been used in a variety of NLP applications, such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). $$$$$ We used the development test data from the 2001 NIST MT evaluation workshop as our test data for the MT system performance.
Dependency trees have been used in a variety of NLP applications, such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). $$$$$ In comparison, we deployed the GIZA++ MT modeling tool kit, which is an implementation of the IBM Models 1 to 4 (Brown et al., 1993; AlOnaizan et al., 1999; Och and Ney, 2003).

Recently, it is widely adopted by the popular applications of natural language processing techniques, such as machine translation (Ding and Palmer, 2005), synonym generation (Shinyama et al, 2002), relation extraction (Culotta and Sorensen, 2004) and lexical resource augmentation (Snow et al, 2004). $$$$$ In this paper, we present a syntax-based statistical matranslation system based on a probabilistic synchronous dependency insertion grammar.
Recently, it is widely adopted by the popular applications of natural language processing techniques, such as machine translation (Ding and Palmer, 2005), synonym generation (Shinyama et al, 2002), relation extraction (Culotta and Sorensen, 2004) and lexical resource augmentation (Snow et al, 2004). $$$$$ The input sentence is first parsed using an automatic parser and a dependency tree is derived.
Recently, it is widely adopted by the popular applications of natural language processing techniques, such as machine translation (Ding and Palmer, 2005), synonym generation (Shinyama et al, 2002), relation extraction (Culotta and Sorensen, 2004) and lexical resource augmentation (Snow et al, 2004). $$$$$ While HMM is defined on a sequence our model is defined on the derivation tree of ETs.
Recently, it is widely adopted by the popular applications of natural language processing techniques, such as machine translation (Ding and Palmer, 2005), synonym generation (Shinyama et al, 2002), relation extraction (Culotta and Sorensen, 2004) and lexical resource augmentation (Snow et al, 2004). $$$$$ The placement of the dependency arcs reflects the relative word order between a parent node and all its immediate children.

 $$$$$ We implemented the above approach for a Chinese-English machine translation system.
 $$$$$ (Ding and Palmer, 2004a) gave a polynomial time solution for learning parallel sub-sentential dependency structures from non-isomorphic dependency trees.
 $$$$$ We have: For any ET v in a given ET derivation tree d , let Root(d) be the root ET of d , and let Parent(v) denote the parent ET of v .

Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insertion grammar. $$$$$ In our implementation, the different decompositions of the input dependency tree are stored in a shared forest structure, utilizing the dynamic programming property of the tree structures explicitly.
Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insertion grammar. $$$$$ It can be expected that the total decoding time for SDIG can be as short as 0.1 second per sentence.
Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insertion grammar. $$$$$ In Eq.
Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insertion grammar. $$$$$ Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.

It is not rare to see dependency relations used as features, in tasks such as relation extraction (Bunescu and Mooney, 2005) and machine translation (Ding and Palmer, 2005). $$$$$ We then used the algorithm in (Xia 2001) to convert the phrasal structure trees to dependency trees to acquire the parallel dependency trees.
It is not rare to see dependency relations used as features, in tasks such as relation extraction (Bunescu and Mooney, 2005) and machine translation (Ding and Palmer, 2005). $$$$$ Admittedly, we benefited from the fact that both Chinese and English are SVO languages, and that many of orderings between the arguments and adjuncts can be kept the same.
It is not rare to see dependency relations used as features, in tasks such as relation extraction (Bunescu and Mooney, 2005) and machine translation (Ding and Palmer, 2005). $$$$$ Currently, all the ETs are attached to each other at their root nodes.
It is not rare to see dependency relations used as features, in tasks such as relation extraction (Bunescu and Mooney, 2005) and machine translation (Ding and Palmer, 2005). $$$$$ While HMM is defined on a sequence our model is defined on the derivation tree of ETs.

Lately, this formalism has been used as an alternative to phrase-based parsing for a variety of tasks, ranging from machine translation (Ding and Palmer, 2005) to relation extraction (Culotta and Sorensen, 2004) and question answering (Wang et al, 2007). $$$$$ Fox (2002) collected the statistics mainly on French and English data: in dependency representations, the percentage of head crossings per chance (case [b] in the graph) is 12.62%.
Lately, this formalism has been used as an alternative to phrase-based parsing for a variety of tasks, ranging from machine translation (Ding and Palmer, 2005) to relation extraction (Culotta and Sorensen, 2004) and question answering (Wang et al, 2007). $$$$$ Second, we describe the graphical model for the machine translation task, which can also be viewed as a stochastic tree-to-tree transducer.
Lately, this formalism has been used as an alternative to phrase-based parsing for a variety of tasks, ranging from machine translation (Ding and Palmer, 2005) to relation extraction (Culotta and Sorensen, 2004) and question answering (Wang et al, 2007). $$$$$ The input sentence is first parsed using an automatic parser and a dependency tree is derived.

As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. $$$$$ However, if we view each dependency tree as an assembly of indivisible sub-sentential elementary trees (ETs), we can find a proper way to transduce the input tree to the output tree.

 $$$$$ We noticed that the SDIG system outputs tend to be longer than those of the IBM Model 4 system, and are closer to human translations in length.
 $$$$$ Similar to (Ding and Palmer, 2004a), we also use a heuristic function in Step 1(a) of the algorithm to rank all the word pairs for the tentative tree partitioning operation.
 $$$$$ Our approach, while similar to (Ding and Palmer, 2004a) in that we also iteratively partition the parallel dependency trees based on a heuristic function, departs (Ding and Palmer, 2004a) in three ways: (1) we base the hierarchical tree partitioning operations on the categories of the dependency trees; (2) the statistics of the resultant tree pairs from the partitioning operation are collected at each iteration rather than at the end of the algorithm; (3) we do not re-train the word to word probabilities at each iteration.

It is no longer rare to see dependency relations used as features, in tasks such as machine translation (Ding and Palmer, 2005) and relation extraction (Bunescu and Mooney, 2005). $$$$$ Such broken and crossing dependencies can be modeled by SDIG if they appear inside a pair of elementary trees.
It is no longer rare to see dependency relations used as features, in tasks such as machine translation (Ding and Palmer, 2005) and relation extraction (Bunescu and Mooney, 2005). $$$$$ A graphical model for the transducer is defined and a polynomial time decoding algorithm is introduced.
It is no longer rare to see dependency relations used as features, in tasks such as machine translation (Ding and Palmer, 2005) and relation extraction (Bunescu and Mooney, 2005). $$$$$ Suppose the input sentence has n words and the shared forest representation has m nodes.

(Ding and Palmer, 2005) presents a translation model based on Synchronous Dependency Insertion Grammar (SDIG), which handles some of the non-isomorphism but requires both source and target dependency structures. $$$$$ We evaluate the outputs of our MT system using the NIST and Bleu automatic MT evaluation software.
(Ding and Palmer, 2005) presents a translation model based on Synchronous Dependency Insertion Grammar (SDIG), which handles some of the non-isomorphism but requires both source and target dependency structures. $$$$$ Let f be the input sentence (foreign language), and e be the output sentence (English).
(Ding and Palmer, 2005) presents a translation model based on Synchronous Dependency Insertion Grammar (SDIG), which handles some of the non-isomorphism but requires both source and target dependency structures. $$$$$ The relative orders between the parent and child ETs in the output tree is currently kept the same as the orders in the input tree.
(Ding and Palmer, 2005) presents a translation model based on Synchronous Dependency Insertion Grammar (SDIG), which handles some of the non-isomorphism but requires both source and target dependency structures. $$$$$ Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.

This has been shown through their successful use in many standard natural language processing tasks, including machine translation (Ding and Palmer, 2005), sentence compression (McDonald, 2006), and textual inference (Haghighi et al, 2005). $$$$$ The IBM models were trained on the same training data as our system.
This has been shown through their successful use in many standard natural language processing tasks, including machine translation (Ding and Palmer, 2005), sentence compression (McDonald, 2006), and textual inference (Haghighi et al, 2005). $$$$$ The MT decoding starts first by decomposing the input dependency tree in to elementary trees.

Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insert grammar, a version of synchronous grammars defined on dependency trees. $$$$$ In comparison, we deployed the GIZA++ MT modeling tool kit, which is an implementation of the IBM Models 1 to 4 (Brown et al., 1993; AlOnaizan et al., 1999; Och and Ney, 2003).
Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insert grammar, a version of synchronous grammars defined on dependency trees. $$$$$ We evaluate the outputs of our MT system using the NIST and Bleu automatic MT evaluation software.
Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insert grammar, a version of synchronous grammars defined on dependency trees. $$$$$ In this paper, we present a syntax-based statistical matranslation system based on a probabilistic synchronous dependency insertion grammar.

 $$$$$ For each tree pair in the corpus, do { a) For the tentative synchronous partitioning operation, use a heuristic function to select the BEST word pair (ei*, f j*) , where both ei*, f j* are NOT “chosen”, Category(ei*) E C and Category(f j*) E C. b) If (ei*, fj*) is found in (a), mark ei*, fj* as “chosen” and go back to (a), else go to (c).
 $$$$$ Although the training corpus isn’t large, the fact that we only have a handful of parameters to fit eased the problem.
 $$$$$ It is worth noting that the set of derived parallel dependency Elementary Trees is not a full-fledged SDIG yet.

 $$$$$ A synchronous derivation process for the two syntactic structures of both languages suggests the level of cross-lingual isomorphism between the two trees (e.g.
 $$$$$ However, if we view each dependency tree as an assembly of indivisible sub-sentential elementary trees (ETs), we can find a proper way to transduce the input tree to the output tree.
 $$$$$ While statistical modeling of children reordering is one possible remedy for this problem, we believe simple linguistic treatment is another, as the output of the SDIG system is an English dependency tree rather than a string of words.
 $$$$$ The input sentence is first parsed using an automatic parser and a dependency tree is derived.
