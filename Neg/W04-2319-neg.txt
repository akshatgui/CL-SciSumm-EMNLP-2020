Following the work of Shriberg et al (2004), we use the 5 general tags in our experiments $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
Following the work of Shriberg et al (2004), we use the 5 general tags in our experiments $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
Following the work of Shriberg et al (2004), we use the 5 general tags in our experiments $$$$$ We provide a brief summary of the annotation system and labeling procedure, inter-annotator reliability statistics, overall distributional statistics, a description of auxiliary files distributed with the corpus, and information on how to obtain the data.
Following the work of Shriberg et al (2004), we use the 5 general tags in our experiments $$$$$ Because of the large number of unique full label combinations, we report Kappa values in Table 2 using various class mappings distributed with the corpus.

Like the Switchboard corpus, the ICSI Meeting Room DA (MRDA) corpus (Shriberg et al, 2004) was annotated using a variant of the DAMSL tag set, similar but not identical to the Switchboard DAMSL annotation. $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
Like the Switchboard corpus, the ICSI Meeting Room DA (MRDA) corpus (Shriberg et al, 2004) was annotated using a variant of the DAMSL tag set, similar but not identical to the Switchboard DAMSL annotation. $$$$$ We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
Like the Switchboard corpus, the ICSI Meeting Room DA (MRDA) corpus (Shriberg et al, 2004) was annotated using a variant of the DAMSL tag set, similar but not identical to the Switchboard DAMSL annotation. $$$$$ If instead we look at only the 11 obligatory general tags, for which there is one per DA, and if we split labels at the pipe bar, the total is 113,560 (excluding tags that only include a disruption label).

The differences (and a translation between the two sets) can be seen in Shriberg et al (2004). $$$$$ Word-level time information is available, based on alignments from an automatic speech recognizer.
The differences (and a translation between the two sets) can be seen in Shriberg et al (2004). $$$$$ We include other useful information with the corpus.
The differences (and a translation between the two sets) can be seen in Shriberg et al (2004). $$$$$ The distribution of general tags is shown in Table 4.
The differences (and a translation between the two sets) can be seen in Shriberg et al (2004). $$$$$ The meetings were recorded at the International Computer Science Institute (ICSI) as part of the ICSI Meeting Recorder Project [9].

To facilitate cross-corpus classification, we will cluster these labels as described in Shriberg et al (2004). $$$$$ We include other useful information with the corpus.
To facilitate cross-corpus classification, we will cluster these labels as described in Shriberg et al (2004). $$$$$ Finally, the corpus contains information that may be useful in for developing automatic modeling of prosody, such as hand-marked annotation of rising intonation.
To facilitate cross-corpus classification, we will cluster these labels as described in Shriberg et al (2004). $$$$$ This work was supported by an ICSI subcontract to the University of Washington on a DARPA Communicator project, ICSI NSF ITR Award IIS-0121396, SRI NASA Award NCC2-1256, SRI NSF IRI-9619921, an SRI DARPA ROAR project, an ICSI award from the Swiss National Science Foundation through the research network IM2, and by the EU Framework 6 project on Augmented Multi-party Interaction (AMI).

We also used additional annotation that has been developed to support higher-level analyses of meeting structure, in particular the ICSI Meeting Recorder Dialog act (MRDA) corpus (Shriberg et al., 2004). $$$$$ We provide a brief summary of the annotation system and labeling procedure, inter-annotator reliability statistics, overall distributional statistics, a description of auxiliary files distributed with the corpus, and information on how to obtain the data.
We also used additional annotation that has been developed to support higher-level analyses of meeting structure, in particular the ICSI Meeting Recorder Dialog act (MRDA) corpus (Shriberg et al., 2004). $$$$$ In the mapping of MRDA tags to SWBD-DAMSL tags here, we have retained the same overall ordering of tags within the table, but we do not explicitly mark the higher-level SWBD-DAMSL categories in order to avoid confusion, since categorical structure differs in the two systems (see [7]).
We also used additional annotation that has been developed to support higher-level analyses of meeting structure, in particular the ICSI Meeting Recorder Dialog act (MRDA) corpus (Shriberg et al., 2004). $$$$$ Finally, the corpus contains information that may be useful in for developing automatic modeling of prosody, such as hand-marked annotation of rising intonation.

The following experiments used manual meeting transcripts and relied on manual dialogue act segmentation (Shriberg et al, 2004). $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
The following experiments used manual meeting transcripts and relied on manual dialogue act segmentation (Shriberg et al, 2004). $$$$$ For example, within only half a minute, speaker c5 has interacted with speakers c3 and c6, and speaker c6 has interacted with speakers c2 and c5.
The following experiments used manual meeting transcripts and relied on manual dialogue act segmentation (Shriberg et al, 2004). $$$$$ Furthermore, 6 of the 19 total utterances express some form of agreement or disagreement (arp, aa, and nd) with previous utterances.

All of them have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and abstractive and extractive summaries in the AMI project (Murray et al, 2005). $$$$$ We suggest various ways to group the large set of labels into a smaller set of classes, depending on the research focus.
All of them have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and abstractive and extractive summaries in the AMI project (Murray et al, 2005). $$$$$ The corpus is currently available online for research purposes [16], and we plan a future release through the LDC.
All of them have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and abstractive and extractive summaries in the AMI project (Murray et al, 2005). $$$$$ We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
All of them have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and abstractive and extractive summaries in the AMI project (Murray et al, 2005). $$$$$ The distribution of general tags is shown in Table 4.

While there are related tags for dialogue act tagging schema? like DAMSL (Core and Allen, 1997), which includes tags such as Action-Directive and Commit, and the ICSI MRDA schema (Shriberg et al, 2004) which includes a committag these classes are too general to allow identification of action items specifically. $$$$$ In addition to the obvious high degree of overlap—roughly one third of all words are overlapped—note the explicit struggle for the floor indicated by the two failed floor grabbers (fg) by speakers c5 and c6.
While there are related tags for dialogue act tagging schema? like DAMSL (Core and Allen, 1997), which includes tags such as Action-Directive and Commit, and the ICSI MRDA schema (Shriberg et al, 2004) which includes a committag these classes are too general to allow identification of action items specifically. $$$$$ We provide basic statistics based on the dialog act labels for the 75 meetings.
While there are related tags for dialogue act tagging schema? like DAMSL (Core and Allen, 1997), which includes tags such as Action-Directive and Commit, and the ICSI MRDA schema (Shriberg et al, 2004) which includes a committag these classes are too general to allow identification of action items specifically. $$$$$ We provide a brief summary of the annotation system and labeling procedure, inter-annotator reliability statistics, overall distributional statistics, a description of auxiliary files distributed with the corpus, and information on how to obtain the data.
While there are related tags for dialogue act tagging schema? like DAMSL (Core and Allen, 1997), which includes tags such as Action-Directive and Commit, and the ICSI MRDA schema (Shriberg et al, 2004) which includes a committag these classes are too general to allow identification of action items specifically. $$$$$ We provide basic statistics based on the dialog act labels for the 75 meetings.

All the meetings have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and extractive summaries (Murray et al, 2005). $$$$$ In addition to the obvious high degree of overlap—roughly one third of all words are overlapped—note the explicit struggle for the floor indicated by the two failed floor grabbers (fg) by speakers c5 and c6.
All the meetings have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and extractive summaries (Murray et al, 2005). $$$$$ We thank Chuck Wooters, Don Baron, Chris Oei, and Andreas Stolcke for software assistance, Ashley Krupski for contributions to the annotation scheme, Andrei Popescu-Belis for analysis and comments on a release of the 50 meetings, and Barbara Peskin and Jane Edwards for general advice and feedback.
All the meetings have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and extractive summaries (Murray et al, 2005). $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
All the meetings have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and extractive summaries (Murray et al, 2005). $$$$$ The distribution of general tags is shown in Table 4.

First, it is rare to have sub DAs labeled in training data, and indeed this is true of the corpus (Shriberg et al, 2004) that we use. $$$$$ Values are shown by labeler pair.
First, it is rare to have sub DAs labeled in training data, and indeed this is true of the corpus (Shriberg et al, 2004) that we use. $$$$$ We provide a brief summary of the annotation system and labeling procedure, inter-annotator reliability statistics, overall distributional statistics, a description of auxiliary files distributed with the corpus, and information on how to obtain the data.
First, it is rare to have sub DAs labeled in training data, and indeed this is true of the corpus (Shriberg et al, 2004) that we use. $$$$$ Furthermore, 6 of the 19 total utterances express some form of agreement or disagreement (arp, aa, and nd) with previous utterances.
First, it is rare to have sub DAs labeled in training data, and indeed this is true of the corpus (Shriberg et al, 2004) that we use. $$$$$ This work was supported by an ICSI subcontract to the University of Washington on a DARPA Communicator project, ICSI NSF ITR Award IIS-0121396, SRI NASA Award NCC2-1256, SRI NSF IRI-9619921, an SRI DARPA ROAR project, an ICSI award from the Swiss National Science Foundation through the research network IM2, and by the EU Framework 6 project on Augmented Multi-party Interaction (AMI).

We evaluate our methods on the ICSI meeting recorder dialog act (MRDA) (Shriberg et al, 2004) corpus, and find that our novel hidden back off model can significantly improve dialog tagging accuracy. $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
We evaluate our methods on the ICSI meeting recorder dialog act (MRDA) (Shriberg et al, 2004) corpus, and find that our novel hidden back off model can significantly improve dialog tagging accuracy. $$$$$ We provide a brief summary of the annotation system and labeling procedure, inter-annotator reliability statistics, overall distributional statistics, a description of auxiliary files distributed with the corpus, and information on how to obtain the data.
We evaluate our methods on the ICSI meeting recorder dialog act (MRDA) (Shriberg et al, 2004) corpus, and find that our novel hidden back off model can significantly improve dialog tagging accuracy. $$$$$ We provide a brief summary of the annotation system and labeling procedure, inter-annotator reliability statistics, overall distributional statistics, a description of auxiliary files distributed with the corpus, and information on how to obtain the data.
We evaluate our methods on the ICSI meeting recorder dialog act (MRDA) (Shriberg et al, 2004) corpus, and find that our novel hidden back off model can significantly improve dialog tagging accuracy. $$$$$ If we ignore the tag marking rising intonation (rt), since this is not a DA tag, we find 180,218 total tags.

In all our models, to simplify we assume that the sentence change information is known (as is common with this corpus (Shriberg et al, 2004)). $$$$$ There are two disruption forms (%-, %--), two types of indecipherable utterances (x, %) and a non-DA tag to denote rising tone (rt).
In all our models, to simplify we assume that the sentence change information is known (as is common with this corpus (Shriberg et al, 2004)). $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
In all our models, to simplify we assume that the sentence change information is known (as is common with this corpus (Shriberg et al, 2004)). $$$$$ We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
In all our models, to simplify we assume that the sentence change information is known (as is common with this corpus (Shriberg et al, 2004)). $$$$$ We provide basic statistics based on the dialog act labels for the 75 meetings.

We evaluated our hidden back off model on the ICSI meeting recorder dialog act (MRDA) corpus (Shriberg et al, 2004). $$$$$ This work was supported by an ICSI subcontract to the University of Washington on a DARPA Communicator project, ICSI NSF ITR Award IIS-0121396, SRI NASA Award NCC2-1256, SRI NSF IRI-9619921, an SRI DARPA ROAR project, an ICSI award from the Swiss National Science Foundation through the research network IM2, and by the EU Framework 6 project on Augmented Multi-party Interaction (AMI).
We evaluated our hidden back off model on the ICSI meeting recorder dialog act (MRDA) corpus (Shriberg et al, 2004). $$$$$ We find in related work that regions of high overlap correlate with high speaker involvement, or “hot spots” [15].
We evaluated our hidden back off model on the ICSI meeting recorder dialog act (MRDA) corpus (Shriberg et al, 2004). $$$$$ For example, within only half a minute, speaker c5 has interacted with speakers c3 and c6, and speaker c6 has interacted with speakers c2 and c5.
We evaluated our hidden back off model on the ICSI meeting recorder dialog act (MRDA) corpus (Shriberg et al, 2004). $$$$$ The philosophy is that any difference in words at the beginning and/or end of a DA could result in a different label for that DA, and the more words that are mismatched, the more likely the difference in label.

All the meetings have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and extractive summaries (Murray et al, 2005). $$$$$ For example, within only half a minute, speaker c5 has interacted with speakers c3 and c6, and speaker c6 has interacted with speakers c2 and c5.
All the meetings have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and extractive summaries (Murray et al, 2005). $$$$$ The last set includes 2 very interesting meetings involving the corpus transcribers as participants (example included in [16]).
All the meetings have been transcribed and annotated with dialog acts (DA) (Shriberg et al, 2004), topics, and extractive summaries (Murray et al, 2005). $$$$$ Reflecting the makeup of the Institute, there are more male than female speakers (40 and 13, respectively).

In our future work, we plan to examine initiative conflicts in face-to-face multi-party conversation, such as the ICSI corpus (Shriberg et al, 2004). $$$$$ 2 Data We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
In our future work, we plan to examine initiative conflicts in face-to-face multi-party conversation, such as the ICSI corpus (Shriberg et al, 2004). $$$$$ This work was supported by an ICSI subcontract to the University of Washington on a DARPA Communicator project, ICSI NSF ITR Award IIS-0121396, SRI NASA Award NCC2-1256, SRI NSF IRI-9619921, an SRI DARPA ROAR project, an ICSI award from the Swiss National Science Foundation through the research network IM2, and by the EU Framework 6 project on Augmented Multi-party Interaction (AMI).
In our future work, we plan to examine initiative conflicts in face-to-face multi-party conversation, such as the ICSI corpus (Shriberg et al, 2004). $$$$$ Word-level time information is available, based on alignments from an automatic speech recognizer.

This GUI showed both their textual summary and the orthographic transcription, without topic segmentation but with one line per dialogue act based on the pre-existing MRDA coding (Shriberg et al, 2004). $$$$$ Furthermore, 6 of the 19 total utterances express some form of agreement or disagreement (arp, aa, and nd) with previous utterances.

We use only the forced alignments of these meetings, available in the accompanying MRDA Corpus (Shriberg et al 2004). $$$$$ We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
We use only the forced alignments of these meetings, available in the accompanying MRDA Corpus (Shriberg et al 2004). $$$$$ We modified the system in [11] a number of ways, as indicated in Figure 1 and as explained further in [7].
We use only the forced alignments of these meetings, available in the accompanying MRDA Corpus (Shriberg et al 2004). $$$$$ We describe a new corpus of over 180,000 handannotated dialog act tags and accompanying adjacency pair annotations for roughly 72 hours of speech from 75 naturally-occurring meetings.
We use only the forced alignments of these meetings, available in the accompanying MRDA Corpus (Shriberg et al 2004). $$$$$ Although our meetings were natural, and thus had real agenda items, the dialog was less like human-human or human-machine task-oriented dialog added in MRDA.

Experiments are performed using all train/test pairs among three conversational speech corpora $$$$$ Annotator comments are also provided.
Experiments are performed using all train/test pairs among three conversational speech corpora $$$$$ Word-level time information is available, based on alignments from an automatic speech recognizer.
Experiments are performed using all train/test pairs among three conversational speech corpora $$$$$ We provide basic statistics based on the dialog act labels for the 75 meetings.
Experiments are performed using all train/test pairs among three conversational speech corpora $$$$$ The ordering of tags in the table is explained as follows: In the mapping of DAMSL tags to SWBD-DAMSL tags in the SWBDDAMSL manual, tags were ordered in categories such as “Communication Status”, “Information Requests”, and so on.

Each channel was manually transcribed and timed, then annotated with dialogue act and adjacency pair information (Shriberg et al, 2004). $$$$$ We provide a brief summary of the annotation system and labeling procedure, inter-annotator reliability statistics, overall distributional statistics, a description of auxiliary files distributed with the corpus, and information on how to obtain the data.
Each channel was manually transcribed and timed, then annotated with dialogue act and adjacency pair information (Shriberg et al, 2004). $$$$$ If we ignore the tag marking rising intonation (rt), since this is not a DA tag, we find 180,218 total tags.
Each channel was manually transcribed and timed, then annotated with dialogue act and adjacency pair information (Shriberg et al, 2004). $$$$$ This work was supported by an ICSI subcontract to the University of Washington on a DARPA Communicator project, ICSI NSF ITR Award IIS-0121396, SRI NASA Award NCC2-1256, SRI NSF IRI-9619921, an SRI DARPA ROAR project, an ICSI award from the Swiss National Science Foundation through the research network IM2, and by the EU Framework 6 project on Augmented Multi-party Interaction (AMI).
Each channel was manually transcribed and timed, then annotated with dialogue act and adjacency pair information (Shriberg et al, 2004). $$$$$ Meetings were divided into 10 minute chunks; labeling time averaged about 3 hours per chunk, although this varied considerably depending on the complexity of the dialog.
