 $$$$$ This work was partially supported under the GALE program of the Defense Advanced Research Projects Agency, Contract No.
 $$$$$ We downloaded comparable data from three online news sites: the BBC, and the Romanian newspapers “Evenimentul Zilei” and “Ziua”.
 $$$$$ We also presented a method for computing a probabilistic lexicon based on the LLR statistic, which produces a higher quality lexicon.
 $$$$$ In order to evaluate the importance of the LLRLex lexicon, we also performed fragment extraction experiments that do not use this lexicon, but only GIZA-Lex.

We employ the same algorithm used in (Munteanu and Marcu, 2006) which first use the GI ZA++ (with grow-diag-final-and heuristic) to obtain the word alignment between source and target words, and then calculate the association strength between the aligned words. $$$$$ This is the aim of our work.
We employ the same algorithm used in (Munteanu and Marcu, 2006) which first use the GI ZA++ (with grow-diag-final-and heuristic) to obtain the word alignment between source and target words, and then calculate the association strength between the aligned words. $$$$$ This work was partially supported under the GALE program of the Defense Advanced Research Projects Agency, Contract No.
We employ the same algorithm used in (Munteanu and Marcu, 2006) which first use the GI ZA++ (with grow-diag-final-and heuristic) to obtain the word alignment between source and target words, and then calculate the association strength between the aligned words. $$$$$ We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.
We employ the same algorithm used in (Munteanu and Marcu, 2006) which first use the GI ZA++ (with grow-diag-final-and heuristic) to obtain the word alignment between source and target words, and then calculate the association strength between the aligned words. $$$$$ We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora.

Munteanu and Marcu (2006) first extract the candidate parallel sentences from the comparable corpora and further extract the accurate sub-sentential bilingual fragments from the candidate parallel sentences using the in-domain probabilistic bilingual lexicon. $$$$$ Thus, they include in the search document pairs which are dissimilar.
Munteanu and Marcu (2006) first extract the candidate parallel sentences from the comparable corpora and further extract the accurate sub-sentential bilingual fragments from the candidate parallel sentences using the in-domain probabilistic bilingual lexicon. $$$$$ Munteanu and Marcu (2005) analyze sentence pairs in isolation from their context, and classify them as parallel or non-parallel.
Munteanu and Marcu (2006) first extract the candidate parallel sentences from the comparable corpora and further extract the accurate sub-sentential bilingual fragments from the candidate parallel sentences using the in-domain probabilistic bilingual lexicon. $$$$$ HR001106-C-0022.
Munteanu and Marcu (2006) first extract the candidate parallel sentences from the comparable corpora and further extract the accurate sub-sentential bilingual fragments from the candidate parallel sentences using the in-domain probabilistic bilingual lexicon. $$$$$ The fact that the source and target signal are filtered separately is also a weakness; a joint analysis should produce better results.

They are neither parallel nor comparable because we cannot even extract a small number of parallel sentence pairs from this monolingual data using the method of (Munteanu and Marcu, 2006). $$$$$ This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs.
They are neither parallel nor comparable because we cannot even extract a small number of parallel sentence pairs from this monolingual data using the method of (Munteanu and Marcu, 2006). $$$$$ We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.
They are neither parallel nor comparable because we cannot even extract a small number of parallel sentence pairs from this monolingual data using the method of (Munteanu and Marcu, 2006). $$$$$ HR001106-C-0022.
They are neither parallel nor comparable because we cannot even extract a small number of parallel sentence pairs from this monolingual data using the method of (Munteanu and Marcu, 2006). $$$$$ This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs.

Munteanu and Marcu (2006) proposed a method for extracting parallel sub sentential fragments from very non-parallel bilingual corpora. $$$$$ Giving special attention to such cases should help get rid of these errors, and improve the precision of the method.
Munteanu and Marcu (2006) proposed a method for extracting parallel sub sentential fragments from very non-parallel bilingual corpora. $$$$$ The best way to make use of this sentence pair is to extract and use for training just the translated (highlighted) fragments.
Munteanu and Marcu (2006) proposed a method for extracting parallel sub sentential fragments from very non-parallel bilingual corpora. $$$$$ However, we believe that very non-parallel corpora have none or few good sentence pairs; most of their parallel data exists at the sub-sentential level.

Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ After one round of sentence extraction, the list is enriched with additional documents, and the system iterates.
Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ We showed that using this lexicon helps improve the precision of our extraction method.
Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ However, a good solution to this problem would have a strong impact on parallel data acquisition efforts.
Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ It shows two sentences belonging to the articles in Figure 1, and highlights and connects their parallel fragments.

 $$$$$ This ensures that differences in performance are caused only by differences in the parallel training data.
 $$$$$ This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs.
 $$$$$ However, a good solution to this problem would have a strong impact on parallel data acquisition efforts.
 $$$$$ This is a difficult task, requiring the ability to recognize translationally equivalent fragments even in non-parallel sentence pairs.

Similarly, Munteanu and Marcu (2006) propose a method to extract sub sentential fragments from non-parallel corpora. $$$$$ We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora.
Similarly, Munteanu and Marcu (2006) propose a method to extract sub sentential fragments from non-parallel corpora. $$$$$ Both methods extend algorithms designed to perform sentence alignment of parallel texts: they use dynamic programming to do sentence alignment of documents hypothesized to be similar.
Similarly, Munteanu and Marcu (2006) propose a method to extract sub sentential fragments from non-parallel corpora. $$$$$ The sizes of the extracted datasets, measured in million English tokens, are presented in Table 2.
Similarly, Munteanu and Marcu (2006) propose a method to extract sub sentential fragments from non-parallel corpora. $$$$$ This work was partially supported under the GALE program of the Defense Advanced Research Projects Agency, Contract No.

 $$$$$ We perform experiments in the context of Romanian to English machine translation.
 $$$$$ The high-level architecture of our parallel fragment extraction system is presented in Figure 3.
 $$$$$ Our approach can be improved in several aspects.
 $$$$$ This is a difficult task, requiring the ability to recognize translationally equivalent fragments even in non-parallel sentence pairs.

Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ HR001106-C-0022.
Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ Enabling the exploitation of corpora that do not share parallel sentences would greatly increase the amount of comparable data that can be used for SMT.
Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora.
Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. $$$$$ The research reported by Fung and Cheung (2004a; 2004b), Cheung and Fung (2004) and Wu and Fung (2005) is aimed explicitly at “very non-parallel corpora”.

The approach that is closest to our work is that of Munteanu and Marcu (2006) $$$$$ Thus, for each initial parallel corpus and each comparable corpus, we extract three datasets: FragmentExtract, SentenceExtract, and Fragment-noLLR.
The approach that is closest to our work is that of Munteanu and Marcu (2006) $$$$$ These approaches are only applicable to corpora which are at most “noisy-parallel”, i.e. contain documents which are fairly similar, both in content and in sentence ordering.
The approach that is closest to our work is that of Munteanu and Marcu (2006) $$$$$ We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora.
The approach that is closest to our work is that of Munteanu and Marcu (2006) $$$$$ The research reported by Fung and Cheung (2004a; 2004b), Cheung and Fung (2004) and Wu and Fung (2005) is aimed explicitly at “very non-parallel corpora”.

Our first technique resembles the technique of Munteanu and Marcu (2006) who also perform phrase extraction by combining clean alignment lexica for initial signals with heuristics to smooth alignments for final fragment extraction. $$$$$ The fact that the source and target signal are filtered separately is also a weakness; a joint analysis should produce better results.
Our first technique resembles the technique of Munteanu and Marcu (2006) who also perform phrase extraction by combining clean alignment lexica for initial signals with heuristics to smooth alignments for final fragment extraction. $$$$$ HR001106-C-0022.
Our first technique resembles the technique of Munteanu and Marcu (2006) who also perform phrase extraction by combining clean alignment lexica for initial signals with heuristics to smooth alignments for final fragment extraction. $$$$$ Figure 2 illustrates our goals.
Our first technique resembles the technique of Munteanu and Marcu (2006) who also perform phrase extraction by combining clean alignment lexica for initial signals with heuristics to smooth alignments for final fragment extraction. $$$$$ One limitation of all these methods is that they are designed to find only full sentences.

The first attempt to detect sub-sentential fragments from comparable sentences is (Munteanuand Marcu, 2006). $$$$$ Munteanu and Marcu (2005) analyze sentence pairs in isolation from their context, and classify them as parallel or non-parallel.
The first attempt to detect sub-sentential fragments from comparable sentences is (Munteanuand Marcu, 2006). $$$$$ Divide all terms by the corresponding normalizing factors to obtain .
The first attempt to detect sub-sentential fragments from comparable sentences is (Munteanuand Marcu, 2006). $$$$$ Table 1 summarizes the relevant information concerning these corpora.

 $$$$$ We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora.
 $$$$$ This work addresses a major bottleneck in the development of Statistical MT (SMT) systems: the lack of sufficiently large parallel corpora for most language pairs.
 $$$$$ We have presented a simple and effective method for extracting sub-sentential fragments from comparable corpora.
 $$$$$ The details of the procedure are presented below, and also illustrated in Figure 5.

Munteanu and Marcu (2006) extract sub sentential translation pairs from comparable corpora using the log-likelihood-ratio of word translation probability. $$$$$ The fact that the source and target signal are filtered separately is also a weakness; a joint analysis should produce better results.
Munteanu and Marcu (2006) extract sub sentential translation pairs from comparable corpora using the log-likelihood-ratio of word translation probability. $$$$$ The sizes of the extracted datasets, measured in million English tokens, are presented in Table 2.
Munteanu and Marcu (2006) extract sub sentential translation pairs from comparable corpora using the log-likelihood-ratio of word translation probability. $$$$$ To all remaining sentence pairs we apply the fragment detection method (described in Section 2.3), which produces the output of the system.
Munteanu and Marcu (2006) extract sub sentential translation pairs from comparable corpora using the log-likelihood-ratio of word translation probability. $$$$$ This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs.

We mainly follow our previous approach (Wang and CallisonBurch, 2011), which is a modified version of an approach by Munteanu and Marcu (2006) on translation fragment extraction. $$$$$ We perform experiments in the context of Romanian to English machine translation.
We mainly follow our previous approach (Wang and CallisonBurch, 2011), which is a modified version of an approach by Munteanu and Marcu (2006) on translation fragment extraction. $$$$$ The scores are presented in Figure 6.

It also can be quantified as the rate of successful extraction of translation equivalents by automated tools, such as proposed in Munteanu and Marcu (2006). $$$$$ We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.
It also can be quantified as the rate of successful extraction of translation equivalents by automated tools, such as proposed in Munteanu and Marcu (2006). $$$$$ We showed that using this lexicon helps improve the precision of our extraction method.
It also can be quantified as the rate of successful extraction of translation equivalents by automated tools, such as proposed in Munteanu and Marcu (2006). $$$$$ We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora.
It also can be quantified as the rate of successful extraction of translation equivalents by automated tools, such as proposed in Munteanu and Marcu (2006). $$$$$ This work was partially supported under the GALE program of the Defense Advanced Research Projects Agency, Contract No.

At last, the goal that we aim to exploit monolingual corpora to help MT is in-spirit similar to the goal of using non-parallel corpora to help MT as aimed in a large amount of work (see Munteanu and Marcu (2006) and references therein). $$$$$ The signal filtering function is very simple; more advanced filters might work better, and eliminate the need of applying additional heuristics (such as our requirement that the extracted fragments have at least 3 words).
At last, the goal that we aim to exploit monolingual corpora to help MT is in-spirit similar to the goal of using non-parallel corpora to help MT as aimed in a large amount of work (see Munteanu and Marcu (2006) and references therein). $$$$$ We compute ,the LLR score for words and , using the formula presented by Moore (2004b), which we do not repeat here due to lack of space.
At last, the goal that we aim to exploit monolingual corpora to help MT is in-spirit similar to the goal of using non-parallel corpora to help MT as aimed in a large amount of work (see Munteanu and Marcu (2006) and references therein). $$$$$ This work was partially supported under the GALE program of the Defense Advanced Research Projects Agency, Contract No.
