We turned to TextRunner (Yates et al, 2007) as a large source of background knowledge about pre-existing relations between nominals. $$$$$ We performed a head-to-head comparison with a state-of-the-art traditional information extraction system, called KNOWITALL.
We turned to TextRunner (Yates et al, 2007) as a large source of background knowledge about pre-existing relations between nominals. $$$$$ (Etzioni et al., 2005) On a set of ten high-frequency relations, TEXTRUNNER found nearly as many correct extractions as KNOWITALL (11,631 to 11,476), while reducing the error rate of KNOWITALL by 33% (18% to 12%).

Yates (2009) considers the output from an open information extraction system (Yates et al, 2007) and clusters predicates and arguments using string similarity and a combination of constraints. $$$$$ On our test corpus of 9 million Web documents, TEXTRUNNER extracted 7.8 million well-formed tuples.
Yates (2009) considers the output from an open information extraction system (Yates et al, 2007) and clusters predicates and arguments using string similarity and a combination of constraints. $$$$$ If the classifier deems the relationship trustworthy, a tuple of the form t = (ei, rj, ek) is extracted, where ei, ek are entities and rj is the relation between them.
Yates (2009) considers the output from an open information extraction system (Yates et al, 2007) and clusters predicates and arguments using string similarity and a combination of constraints. $$$$$ In response to these challenges, TEXTRUNNER includes several novel components, which we now summarize (see (Banko et al., 2007) for details).

Two example systems implementing this paradigm are TEXTRUNNER (Yates et al, 2007) and REVERB (Fader et al, 2011). $$$$$ Because TEXTRUNNER has no pre-defined relations, it may extract many different strings representing the same relation.
Two example systems implementing this paradigm are TEXTRUNNER (Yates et al, 2007) and REVERB (Fader et al, 2011). $$$$$ Corpus Heterogeneity on the Web, which makes tools like parsers and named-entity taggers less accurate because the corpus is different from the data used to train the tools.
Two example systems implementing this paradigm are TEXTRUNNER (Yates et al, 2007) and REVERB (Fader et al, 2011). $$$$$ Using several heuristic constraints, we automatically label a set of parsed sentences as trustworthy or untrustworthy extractions (positive and negative examples, respectively).
Two example systems implementing this paradigm are TEXTRUNNER (Yates et al, 2007) and REVERB (Fader et al, 2011). $$$$$ The classifier is then able to decide whether a sequence of POS-tagged words is a correct extraction with high accuracy.

In contrast, when research focuses on any relation, as in TextRunner (Yates et al, 2007), there is no standardized manner for re-using the pattern learned. $$$$$ We have built a fast user interface for querying the results.
In contrast, when research focuses on any relation, as in TextRunner (Yates et al, 2007), there is no standardized manner for re-using the pattern learned. $$$$$ Our first public demonstration of the TEXTRUNNER system shows the results of performing OIE on a set of 117 million web pages.
In contrast, when research focuses on any relation, as in TextRunner (Yates et al, 2007), there is no standardized manner for re-using the pattern learned. $$$$$ It demonstrates the power of TEXTRUNNER in terms of the raw number of facts it has extracted, as well as its precision using our novel assessment mechanism.
In contrast, when research focuses on any relation, as in TextRunner (Yates et al, 2007), there is no standardized manner for re-using the pattern learned. $$$$$ We have built a fast user interface for querying the results.

The online demo of TextRunner (Yates et al, 2007) actually allowed us to collect the arguments for all our semantic relations. $$$$$ It demonstrates the power of TEXTRUNNER in terms of the raw number of facts it has extracted, as well as its precision using our novel assessment mechanism.
The online demo of TextRunner (Yates et al, 2007) actually allowed us to collect the arguments for all our semantic relations. $$$$$ Our first public demonstration of the TEXTRUNNER system shows the results of performing OIE on a set of 117 million web pages.
