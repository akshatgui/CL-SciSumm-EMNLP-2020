Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ The second term in Equation (19) is an expectation over all derivations for each sentence.
Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ This figure is increased to over 91% when the tagger is run in n-best mode, but at a considerable cost in ambiguity, with 8 supertags per word.
Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ A contribution of this section has been to highlight the difficulties associated with cross-formalism parser comparisons.
Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ Currently we do not use the probabilities assigned to the lexical categories by the supertagger as part of the parse selection process.

From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ The model was also designed to test whether the inclusion of predicate–argument dependencies improves parsing accuracy.
From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ The dependency structure, πmax, which maximizes the expected recall is: where πi ranges over the dependency structures for S. The expectation for a single dependency structure π is realized as a weighted intersection over all possible dependency structures πi for S. The intuition is that, if πi is the gold standard, then the number of dependencies recalled in π is |π ∩ πi|.
From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ We decided to include these rules because they are trivial to implement and significantly affect the score, and we felt that, without these changes, the CCG parser would be unfairly penalized.
From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ Note that the difficulties are not unique to CCG, and many would apply to any cross-formalism comparison, especially with parsers using automatically extracted grammars.

However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ However, in the sentence Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group., the supertagger correctly assigns one category to is for all values of β.
However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ For these features the counting was done across all derivations licensed by the gold-standard lexical category sequences and a frequency cutoff of 10 was applied.
However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ In CCGbank there is a distinction between the direct object of a transitive verb and ditransitive verb, for example, whereas in DepBank these would both be dobj.
However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ One solution is to only keep a small number of charts in memory at any one time, and to keep reading in the charts on each iteration.

Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ The same cutoff was applied to the features in the dependency model, except for the rule instantiation feature types.
Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ The results in Table 16 were obtained by parsing the sentences from CCGbank corresponding to those in the 560-sentence test set used by Briscoe, Carroll, and Watson (2006).
Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ The CKY algorithm applies naturally to CCG because the grammar is binary.
Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ Geman and Johnson (2002) propose a similar method in the context of LFG parsing; an implementation is described in Kaplan et al. (2004).

Clark and Curran (2007) gives a more precise definition. $$$$$ The subtype slot specifies additional information about the GR; examples include the value obj in a passive ncsubj, indicating that the subject is an underlying object; the value num in ncmod, indicating a numerical quantity; and prt in ncmod to indicate a verb particle.
Clark and Curran (2007) gives a more precise definition. $$$$$ However, given that the L-BFGS algorithm takes hundreds of iterations to converge, this approach would be infeasibly slow.
Clark and Curran (2007) gives a more precise definition. $$$$$ Thus the evaluation on CCGbank overstates the accuracy of the parser, because it is tuned to produce the output in CCGbank, including constructions where the analysis is incorrect.
Clark and Curran (2007) gives a more precise definition. $$$$$ We restrict the categories which can be assigned to a word by using a tag dictionary: for words seen at least k times in the training data, the tagger can only assign categories which have been seen with the word in the data.

We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ Again, we implemented this change by fixing the head annotation in the lexical categories which apply to relative pronouns.
We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ The estimation process attempts to make the expectations in Equation (17) equal (ignoring the Gaussian prior term).
We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ Relations on which the CCG parser performs particularly well, relative to RASP, are conj, det, ncmod, cmod, ncsubj, dobj, obj2, and ccomp.
We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ The first set of rule features encode the combining categories and the result category; the second set of features extend the first by also encoding the head of the result category; and the third set generalizes the second using POS tags.

The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ Miyao and Tsujii (2005) address the issue of practical estimation using an automatically extracted HPSG grammar.
The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ Hockenmaier (2003a) gives a detailed description of the procedure used to create CCGbank.
The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ In this case the likelihood function is the product of the conditional probabilities of the syntactic analyses in the data, each probability conditioned on the respective sentence.
The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ The evaluation on DepBank raises a number of issues regarding parser evaluation.

The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ However, the optimal setting on the supertagger for training purposes can only be used when the constraints are applied, because otherwise the memory requirements are prohibitive.
The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ The work in this article began as part of the Edinburgh wide-coverage CCG parsing project (2000–2004).
The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ We demonstrate that both accurate and highly efficient parsing is possible with CCG.
The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ The Clark and Curran paper shows this set to have very high coverage on unseen data.

Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ We have found the tag dictionary to be beneficial in terms of both efficiency and accuracy.
Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ This rule can be implemented by assuming the following category schema for a coordination term: (X\X)/X, where X can be any category.
Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ Because the number of lexical categories assigned to a word can be high, some strategy is needed to make parsing practical; Hockenmaier, for example, uses a beam search to discard chart entries with low scores.
Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ The idea is to maintain some POS tag ambiguity for later parts of the parsing process, using the tag probabilities to decide which tags to maintain.

When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ TAG grammars have been automatically extracted from the Penn Treebank, using techniques similar to those used by Hockenmaier (Chen and Vijay-Shanker 2000; Xia, Palmer, and Joshi 2000).
When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ The overall F-score for the CCG parser, 81.14%, is only 3.6 points below that for CCGbank, which provides an upper bound for the CCG parser.
When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ Abney’s motivation for using log-linear models is to overcome various problems in applying models based on PCFGs directly to attributevalue grammars.
When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ This value was chosen to maximize the coverage of the parser, so that the evaluation is performed on as much of the unseen data as possible.

The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ Calculating EΛ fi requires summing over all derivations ω which include fi for each sentence S in the training data.
The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ However, the meaning of parse differs in the two cases.
The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ The results for parsing accuracy were obtained using Section 00 as development data and Section 23 as the final test data.
The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ For the dependency model, the highest scoring dependency structure is required.

However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ In addition these features are generalized in three ways using POS tags, with the word–word pair replaced with word–POS, POS–word, and POS–POS.
However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ The parser is also evaluated on DepBank and compared against the RASP parser, outperforming RASP overall and on the majority of relation types.
However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ The CKY algorithm applies naturally to CCG because the grammar is binary.
However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ Each machine in the cluster deals with a subset of the training data, holding the packed charts for that subset in memory.

We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ This approach is different from that of Clark, Hockenmaier, and Steedman (2002), who define the probability of a dependency structure simply in terms of the dependencies.
We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ The highest-scoring subderivations can be calculated recursively using the highest-scoring equivalence classes that were combined to create the individual entry.
We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ The equivalence classes were defined so that any other individual entry cannot be part of the highest scoring derivation for the sentence.
We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ The training of the dependency model already uses most of the RAM available on the cluster.

We compare the CCG parser of Clark and Curran (2007) with a state-of-the-art PennTreebank (PTB) parser. $$$$$ We use the the Message Passing Interface (MPI) standard for the implementation (Gropp et al. 1996).
We compare the CCG parser of Clark and Curran (2007) with a state-of-the-art PennTreebank (PTB) parser. $$$$$ It reduces the size of the charts considerably compared with naive methods for assigning lexical categories, which is crucial for practical discriminative training.
We compare the CCG parser of Clark and Curran (2007) with a state-of-the-art PennTreebank (PTB) parser. $$$$$ The limited memory BFGS (L-BFGS) algorithm is a general purpose numerical optimization algorithm (Nocedal and Wright 1999).

Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ This sum can be calculated efficiently using a variant of the forward–backward algorithm.
Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ For these features the counting was done across all derivations licensed by the gold-standard lexical category sequences and a frequency cutoff of 10 was applied.
Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ The results for parsing accuracy were obtained using Section 00 as development data and Section 23 as the final test data.
Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ With automatically assigned POS tags, using the POS tagger of Curran and Clark (2003), the accuracies drop to 91.5% and 32.5%.

The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ In words, the probability of category yi, given the sentence, is the sum of the probabilities of all sequences containing yi.
The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ This article provides a comprehensive blueprint for building a wide-coverage CCG parser.
The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ These nonstandard derivations are an integral part of the formalism, and we have answered the question of whether efficent estimation and parsing algorithms can be defined for models which use these derivations.
The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ It includes all lexical catgeories which appear at least 10 times in Sections 02–21 of CCGbank, resulting in a set of 425 categories.

The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ We were able to annotate approximately 1, 000 questions in around a week, which led to an accurate supertagger and, combined with the Penn Treebank parsing model, an accurate parser of questions.
The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ The only exception is during evaluation, when some of these dependencies are ignored in order to be consistent with the predicate–argument dependencies in CCGbank, and also DepBank.
The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ In practice this means changing the annotation of all the relevant lexical categories in the markedup file.8 The majority of the categories to which this applies are those creating aux relations.
The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ There are also the three distance measures which encode the distance between the two head words of the combining categories, as for the dependency model.

Since this short paper reports a small, focused research contribution, we refer readers to Clark and Curran (2007) and Petrov and Klein (2007) for details of the two parsers. $$$$$ The set of categories assigned to a word is considered correct if it contains the correct category.
Since this short paper reports a small, focused research contribution, we refer readers to Clark and Curran (2007) and Petrov and Klein (2007) for details of the two parsers. $$$$$ Here the distance feature encodes the combining categories, the result category, the head of the result category (either as a word or POS tag), and the distance between the two head words.
Since this short paper reports a small, focused research contribution, we refer readers to Clark and Curran (2007) and Petrov and Klein (2007) for details of the two parsers. $$$$$ The first, following Hockenmaier (2003a), is to define a model in terms of normal-form derivations (Eisner 1996).
Since this short paper reports a small, focused research contribution, we refer readers to Clark and Curran (2007) and Petrov and Klein (2007) for details of the two parsers. $$$$$ There are various hyperparameters in the parsing system, for example the frequency cutoff for features, the σ parameter in the Gaussian prior term, the R values used in the supertagger, and so on.

The schemas were developed by manual inspection using section 00 of CCGbank and the PTB as a development set, following the oracle methodology of Clark and Curran (2007), in which gold standard derivations from CCGbank are converted to the new representation and compared with the gold standard for that representation. $$$$$ The limited memory BFGS (L-BFGS) algorithm is a general purpose numerical optimization algorithm (Nocedal and Wright 1999).
The schemas were developed by manual inspection using section 00 of CCGbank and the PTB as a development set, following the oracle methodology of Clark and Curran (2007), in which gold standard derivations from CCGbank are converted to the new representation and compared with the gold standard for that representation. $$$$$ All of these were set experimentally using Section 00 as development data.
The schemas were developed by manual inspection using section 00 of CCGbank and the PTB as a development set, following the oracle methodology of Clark and Curran (2007), in which gold standard derivations from CCGbank are converted to the new representation and compared with the gold standard for that representation. $$$$$ In the implementation used here the forward–backward sum is limited to those sequences allowed by the tag dictionary.

While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ The distance features encode the dependency relation and the word associated with the lexical category (but not the argument word), plus some measure of distance between the two dependent words.
While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ The algorithm used to build the packed charts is the CKY chart parsing algorithm (Kasami 1965; Younger 1967) described in Steedman (2000).
While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ Discriminative training is used to estimate the models, which requires incorrect parses for each sentence in the training data as well as the correct parse.
While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ The overall F-score for the CCG parser, 81.14%, is only 3.6 points below that for CCGbank, which provides an upper bound for the CCG parser.
