Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ The techniques that we have developed, including the use of a supertagger to limit the size of the charts and the use of parallel estimation, could be applied to log-linear parsing models using other grammar formalisms.
Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ For estimating both the normal-form model and the dependency model, the following expectation of each feature fi, with respect to some model A, is required: where ρ(S) is the set of all parses for sentence S, and λ is the vector of weights for A.
Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ Of course some of these advantages could be obtained with other grammar formalisms, such as TAG, LFG, and HPSG, although CCG is especially well-suited to analysing coordination and long-range dependencies.
Clark and Curran (2007) show that both accurate and highly efficient parsing is possible using a CCG. $$$$$ In words, the probability of category yi, given the sentence, is the sum of the probabilities of all sequences containing yi.

From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ For example, we have developed a method for training the dependency model which requires lexical category data only (Clark and Curran 2006).
From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ We use a single smoothing parameter σ, so that σi = σ for all i; however, grouping the features into classes and using a different σ for each class is worth investigating and may improve the results.
From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ Calculating EΛ fi requires summing over all derivations ω which include fi for each sentence S in the training data.
From a parsing perspective, the C & C parser (Clark and Curran, 2007) has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations (Clark and Curran, 2007), Penn Treebank phrase structure trees (Clark and Curran, 2009), and unbounded dependencies (Rimell et al, 2009). $$$$$ A small number of local trees in CCGbank—consisting of a parent and one or two children—do not correspond to any of the CCG combinatory rules, or the type-changing rules or punctuation rules.

However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ 2002; Riezler et al. 2002; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be enumerated.
However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ The features used in the models are the words and POS tags in the five-word window, plus the two previously assigned lexical categories to the left.
However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ This gives us a practical framework for developing a statistical parser.
However, the parsing work by Clark and Curran (2007), and also Hockenmaier (2003) and Fowler and Penn (2010), has only considered chart-parsing. $$$$$ The CCG dependencies were transformed into GRs in two stages.

Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ The log-linear modeling framework allows considerable flexibility for representing the parse space in terms of features.
Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ There are some constructions in CCGbank— noun compounds being a prominent example—which are often incorrectly analyzed, simply because the required information is not in the Penn Treebank.
Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ The MPI library handles all aspects of the parallelization, including finding the optimal way of summing across the nodes of the Beowulf cluster (typically it is done using a tree algorithm).
Following Clark and Curran (2007), we assume that each input word has been assigned a POS-tag (from the Penn Treebank tag set) and a set of CCG lexical categories. $$$$$ In this article we consider the opposite approach: Start with a very restrictive setting of the supertagger, and only assign more categories if the parser cannot find an analysis spanning the sentence.

Clark and Curran (2007) gives a more precise definition. $$$$$ The evaluation on DepBank raises a number of issues regarding parser evaluation.
Clark and Curran (2007) gives a more precise definition. $$$$$ Surprisingly, given CCG’s “spurious ambiguity,” the parsing speeds are significantly higher than those reported for comparable parsers in the literature.
Clark and Curran (2007) gives a more precise definition. $$$$$ The drop in accuracy is expected, given the importance of POS tags as features.
Clark and Curran (2007) gives a more precise definition. $$$$$ Because we do not know which πi is the gold standard, then we calculate the expected recall by summing the recall of π relative to each πi, weighted by the probability of πi.

We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ Thus the evaluation on CCGbank overstates the accuracy of the parser, because it is tuned to produce the output in CCGbank, including constructions where the analysis is incorrect.
We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ However, there are still considerable difficulties associated with a cross-formalism comparison, which we describe.
We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ We also extend the existing parsing techniques for CCG by developing a new model and efficient parsing algorithm which exploits all derivations, including CCG’s nonstandard derivations.
We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release. $$$$$ This latter sum can be calculated efficiently using inside and outside scores: where φc is the inside score and ψc is the outside score for node c; C is the set of conjunctive nodes in the packed chart for sentence S and deps(c) is the set of dependencies on conjunctive node c. The intuition behind the expected recall score is that a dependency structure scores highly if it has dependencies produced by high probability derivations.4 The reason for rewriting the score in terms of individual dependencies is to make use of the packed chart: The score for an individual dependency can be calculated using dynamic programming (as explained previously), and the highest scoring dependency structure can be found using dynamic programming also.

The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ We have found the tag dictionary to be beneficial in terms of both efficiency and accuracy.
The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ Even here we experienced some unexpected difficulties, because some of the tokenization is different between DepBank and CCGbank (even though both resources are based on the Penn Treebank), and there are some sentences in DepBank which have been significantly shortened (for no apparent reason) compared to the original Penn Treebank sentences.
The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ In our case, every node needs to be holding a copy of the master sum, so we use an all reduce operation.
The numbers for C & C are for the hybrid model, copied from Clark and Curran (2007). $$$$$ The constraints are also useful for training.

The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ This article describes a number of log-linear parsing models for an automatically extracted lexicalized grammar.
The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ In words, the probability of category yi, given the sentence, is the sum of the probabilities of all sequences containing yi.
The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ We also extend the existing parsing techniques for CCG by developing a new model and efficient parsing algorithm which exploits all derivations, including CCG’s nonstandard derivations.
The numbers for the normal-form model are evaluated by running the publicly available parser, while those for the hybrid dependency model are from Clark and Curran (2007). $$$$$ In practice large numbers of such conjunctive nodes lead to very long parse times.

Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ One of the problems with modeling approaches which require very long estimation times is that it is difficult to test different configurations of the system, for example different feature sets.
Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ We demonstrate that both accurate and highly efficient parsing is possible with CCG.
Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ There has perhaps been a perception in the NLP community that parsing with CCG is necessarily ineffficient because of CCG’s “spurious” ambiguity.
Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank (Hockenmaier and Steedman, 2007), rather than defining the combinatory rule schema manually as in Clark and Curran (2007). $$$$$ The combination of discriminative training and an automatically extracted grammar leads to a significant memory requirement (up to 25 GB), which is satisfied using a parallel implementation of the BFGS optimization algorithm running on a Beowulf cluster.

When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ Example derivation using type-raising and forward composition. by > B (because B is the symbol used by Curry to denote function composition in combinatory logic; Curry and Feys 1958): Forward composition is often used in conjunction with type-raising (T), as in Figure 2.
When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ In the implementation used here the forward–backward sum is limited to those sequences allowed by the tag dictionary.
When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ First, for many applications predicate–argument dependencies provide a more useful output than derivations, and the parser evaluation is over dependencies; hence it would seem reasonable to optimize over the dependencies rather than the derivation.
When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via super tagging (Clark and Curran, 2007) on the input sequence. $$$$$ Another advantage of parallelization, as discussed in Section 5.5, is the reduction in estimation time.

The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ It includes all lexical catgeories which appear at least 10 times in Sections 02–21 of CCGbank, resulting in a set of 425 categories.
The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ Steedman (2000) gives a more precise definition of generalized forward composition.
The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ The key to performing this sum efficiently is to write the sum in terms of inside and outside scores for each conjunctive node.
The average number of lexical categories per word drops to 1.3 when equals 0.075, which is the value used for parsing newspaper text in Clark and Curran (2007). $$$$$ Rather than define a model in terms of parser moves, Abney defines a model directly over the syntactic structures licensed by the grammar.

However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ The GRs are described in Briscoe (2006), Briscoe and Carroll (2006), and Briscoe, Carroll, and Watson (2006).
However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ As an alternative to finding the most probable dependency structure, we have developed an algorithm which maximizes the expected labeled recall over dependencies.
However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ Finally, the lexicalized nature of CCG has implications for the engineering of a widecoverage parser.
However, compared to the 93% lexical category accuracy of a CCG parser (Clark and Curran, 2007), which also uses a level of 0.075 for the majority of sentences, the accuracy of our grammaticality improvement system is much lower. $$$$$ The CCG grammar used in this article is automatically extracted, has wide coverage, and can produce an extremely large number of derivations for some sentences, far too many to enumerate.

We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ Watson, Carroll, and Briscoe (2005) have also applied our algorithm to the grammatical relations output by the RASP parser.
We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ This article describes a number of log-linear parsing models for an automatically extracted lexicalized grammar.
We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ The estimation process can also be thought of in terms of the framework of Della Pietra, Della Pietra, and Lafferty (1997), because setting the gradient in Equation (17) to zero yields the usual maximum entropy constraints, namely that the expected value of each feature is equal to its empirical value (again ignoring the Gaussian prior term).
We parsed both corpora using the C & C parser (Clark and Curran, 2007) as we employ both GR and POS information in our learning method. $$$$$ The parallel implementation is a straightforward extension of the BFGS algorithm.

We compare the CCG parser of Clark and Curran (2007) with a state-of-the-art PennTreebank (PTB) parser. $$$$$ One difference is that we use a Maximum Entropy tagger which allows more flexibility in terms of the features that can be encoded; for example, we have found that using Penn Treebank POS tags as features significantly improves supertagging accuracy.
We compare the CCG parser of Clark and Curran (2007) with a state-of-the-art PennTreebank (PTB) parser. $$$$$ On the other hand the relatively low upper bound for the CCG parser on DepBank demonstrates the considerable disadvantage of evaluating on a resource which uses a different annotation scheme to the parser.
We compare the CCG parser of Clark and Curran (2007) with a state-of-the-art PennTreebank (PTB) parser. $$$$$ There are various hyperparameters in the parsing system, for example the frequency cutoff for features, the σ parameter in the Gaussian prior term, the R values used in the supertagger, and so on.
We compare the CCG parser of Clark and Curran (2007) with a state-of-the-art PennTreebank (PTB) parser. $$$$$ In order to increase the number of words assigned the correct category, we develop a CCG multitagger, which is able to assign more than one category to each word.

Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ One aspect of the CCGbank evaluation which is more demanding than the DepBank evaluation is the set of labeled dependencies used.
Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ The second difficulty in creating the transformation is that not all the GRs are binary relations, whereas the CCG dependencies are all binary.
Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ There are a number of features defined over derivations which are common to the dependency model and the normal-form model.5 First, there are features which represent each (word, lexical-category) pair in a derivation, and generalizations of these which represent (POS, lexical-category) pairs.
Examples of this approach include Riezler et al (2002), Miyao and Tsujii (2005), Briscoe and Carroll (2006), and Clark and Curran (2007). $$$$$ The larger cutoff was used because the productivity of the grammar can lead to very large numbers of these features.

The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ A packed chart efficiently represents all derivations for a sentence.
The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ The larger cutoff was used because the productivity of the grammar can lead to very large numbers of these features.
The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ The accuracy of this hybrid dependency model is given in Table 7.
The formalism-based parser we use is the CCG parser of Clark and Curran (2007), which is based on CCGbank (Hockenmaier and Steedman, 2007), a CCG version of the Penn Treebank. $$$$$ The second type of constraint, shown in the third line of the table, checks the lexical category of the word filling the argument slot.

The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ A key component of the parsing system, for both training and testing, is a Maximum Entropy supertagger which assigns CCG lexical categories to words in a sentence.
The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ There are some constructions in CCGbank— noun compounds being a prominent example—which are often incorrectly analyzed, simply because the required information is not in the Penn Treebank.
The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ Thus the scores at the most general level in the GR hierarchy (dependent) correspond to unlabeled accuracy scores.
The CCG parser has been extensively evaluated elsewhere (Clark and Curran, 2007), and arguably GRs or predicate-argument structures provide a more suitable test set for the CCG parser than PTB phrase-structure trees. $$$$$ We show how to maintain some POS ambiguity through to the supertagging phase, using a multi-POS tagger, and also how POS tag probabilities can be encoded as real-valued features in the supertagger.

Since this short paper reports a small, focused research contribution, we refer readers to Clark and Curran (2007) and Petrov and Klein (2007) for details of the two parsers. $$$$$ These feature types and frequency cutoffs led to 475,537 features for the normal-form model and 632,591 features for the dependency model.
Since this short paper reports a small, focused research contribution, we refer readers to Clark and Curran (2007) and Petrov and Klein (2007) for details of the two parsers. $$$$$ This latter sum can be calculated efficiently using inside and outside scores: where φc is the inside score and ψc is the outside score for node c; C is the set of conjunctive nodes in the packed chart for sentence S and deps(c) is the set of dependencies on conjunctive node c. The intuition behind the expected recall score is that a dependency structure scores highly if it has dependencies produced by high probability derivations.4 The reason for rewriting the score in terms of individual dependencies is to make use of the packed chart: The score for an individual dependency can be calculated using dynamic programming (as explained previously), and the highest scoring dependency structure can be found using dynamic programming also.
Since this short paper reports a small, focused research contribution, we refer readers to Clark and Curran (2007) and Petrov and Klein (2007) for details of the two parsers. $$$$$ The MPI library handles all aspects of the parallelization, including finding the optimal way of summing across the nodes of the Beowulf cluster (typically it is done using a tree algorithm).

The schemas were developed by manual inspection using section 00 of CCGbank and the PTB as a development set, following the oracle methodology of Clark and Curran (2007), in which gold standard derivations from CCGbank are converted to the new representation and compared with the gold standard for that representation. $$$$$ However, there are some differences between the dependency scheme used by our parser and CCGbank.
The schemas were developed by manual inspection using section 00 of CCGbank and the PTB as a development set, following the oracle methodology of Clark and Curran (2007), in which gold standard derivations from CCGbank are converted to the new representation and compared with the gold standard for that representation. $$$$$ One of our aims was to provide a self contained estimation code base, and so we implemented our own version of the L-BFGS algorithm as described in Nocedal and Wright (1999).
The schemas were developed by manual inspection using section 00 of CCGbank and the PTB as a development set, following the oracle methodology of Clark and Curran (2007), in which gold standard derivations from CCGbank are converted to the new representation and compared with the gold standard for that representation. $$$$$ In other words, to get a dependency correct in the CCGbank evaluation, the lexical category—typically a subcategorization frame—has to be correct.

While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ We also extend the existing parsing techniques for CCG by developing a new model and efficient parsing algorithm which exploits all derivations, including CCG’s nonstandard derivations.
While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ Because of the small number of questions in the Penn Treebank, the performance of the parser was extremely poor— well below that required for a working QA system.
While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ Because the generative model uses local features similar to those in our log-linear models, it could be incorporated into the estimation and decoding processes without the need for reranking.
While high quality syntactic parsers are able to efficiently annotate large quantities of English text (Clark and Curran, 2007), existing approaches to query do not work on the same scale. $$$$$ The resulting F-score of 89.60% shows the increase obtained from using gold-standard GRs generated from CCGbank rather than the CCGbank dependencies themselves (for which the F-score was 85.20%).
