We used a bilingual corpus (Utiyama and Isahara, 2003) to examine which semantic frames of BFN contained LUs relevant to the Japanese verb osou. $$$$$ As of late-October 2002, we have been distributing the alignment data discussed in this paper for research and educational purposes.12 All the information on the article and sentence alignments are numerically encoded so that users who have the Yomiuri data can recover the results of alignments.
We used a bilingual corpus (Utiyama and Isahara, 2003) to examine which semantic frames of BFN contained LUs relevant to the Japanese verb osou. $$$$$ We first used a method based on cross-language information retrieval (CLIR) to align the Japanese and English articles and then used a method based on dynamic programming (DP) matching to align the Japanese and English sentences in these articles.
We used a bilingual corpus (Utiyama and Isahara, 2003) to examine which semantic frames of BFN contained LUs relevant to the Japanese verb osou. $$$$$ Thus, SntScore is more reliable than SIM.
We used a bilingual corpus (Utiyama and Isahara, 2003) to examine which semantic frames of BFN contained LUs relevant to the Japanese verb osou. $$$$$ The number of English articles used was 35,318, which is 68 percent of all of the articles.

The bilingual corpus used for our experiments was obtained from an automatically sentence aligned Japanese/English Yomiuri newspaper corpus consisting of 180K sentence pairs (refer to Table1) (Utiyama and Isahara, 2003). $$$$$ Using these measures, we have successfully constructed a largescale article and sentence alignment corpus available to the public.
The bilingual corpus used for our experiments was obtained from an automatically sentence aligned Japanese/English Yomiuri newspaper corpus consisting of 180K sentence pairs (refer to Table1) (Utiyama and Isahara, 2003). $$$$$ We have proposed two measures for extracting valid article and sentence alignments.
The bilingual corpus used for our experiments was obtained from an automatically sentence aligned Japanese/English Yomiuri newspaper corpus consisting of 180K sentence pairs (refer to Table1) (Utiyama and Isahara, 2003). $$$$$ Using these measures, we have successfully constructed a largescale article and sentence alignment corpus available to the public.
The bilingual corpus used for our experiments was obtained from an automatically sentence aligned Japanese/English Yomiuri newspaper corpus consisting of 180K sentence pairs (refer to Table1) (Utiyama and Isahara, 2003). $$$$$ The results of evaluations are in Table 1.8 Here, “ratio” means the ratio of the number of articles judged to correspond to the respective category against the total number of articles.

Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. $$$$$ Therefore, SntScore is more appropriate than SIM if we want to compare sentence alignments in different article alignments, because, in general, a sentence alignment in a reliable article alignment is more reliable than one in an unreliable article alignment.
Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. $$$$$ It has attracted the attention of people both inside and outside the NLP community.
Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. $$$$$ About half of these were NLPrelated.
Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. $$$$$ The results of evaluations are in Table 1.8 Here, “ratio” means the ratio of the number of articles judged to correspond to the respective category against the total number of articles.

We used 1000 sentence pairs extracted from pre-aligned data (Utiyama and Isahara, 2003) as a gold standard. $$$$$ BM25 and its variants have been proven to be quite efficient in information retrieval.
We used 1000 sentence pairs extracted from pre-aligned data (Utiyama and Isahara, 2003) as a gold standard. $$$$$ However, it gives us some idea into a comparison of MT and DTL.
We used 1000 sentence pairs extracted from pre-aligned data (Utiyama and Isahara, 2003) as a gold standard. $$$$$ Original Japanese articles may be restructured to conform to the style of English newspapers, additional descriptions may be added to fill cultural gaps, and detailed descriptions may be omitted.

For example, Munteanu and Marcu (2005) apply the Lemur IR toolkit, Utiyama and Isahara (2003) use the BM25 similarity measure, and Fung and Cheung (2004) use cosine similarity. $$$$$ In this paper, we first discuss the basic statistics on the Japanese and English newspapers.
For example, Munteanu and Marcu (2005) apply the Lemur IR toolkit, Utiyama and Isahara (2003) use the BM25 similarity measure, and Fung and Cheung (2004) use cosine similarity. $$$$$ However, the results included many incorrect alignments.
For example, Munteanu and Marcu (2005) apply the Lemur IR toolkit, Utiyama and Isahara (2003) use the BM25 similarity measure, and Fung and Cheung (2004) use cosine similarity. $$$$$ We regard alignments that were judged to be A or B to be suitable for NLP because of their relatively large overlap.
For example, Munteanu and Marcu (2005) apply the Lemur IR toolkit, Utiyama and Isahara (2003) use the BM25 similarity measure, and Fung and Cheung (2004) use cosine similarity. $$$$$ To achieve this, a reliable measure of the validity of sentence alignments is necessary.

For example, Zhao and Vogel (2002), Utiyama and Isahara (2003), and Munteanu and Marcu (2005) all acquire their comparable corpora from a collection of news articles which are either downloaded from the Web or archived by LDC. $$$$$ We use simple heuristics to obtain JZ x EZ, i.e., a one-to-one correspondence between the words in JZ and EZ, by looking up JapaneseEnglish and English-Japanese dictionaries made up by combining entries in the EDR Japanese-English bilingual dictionary and the EDR English-Japanese bilingual dictionary.
For example, Zhao and Vogel (2002), Utiyama and Isahara (2003), and Munteanu and Marcu (2005) all acquire their comparable corpora from a collection of news articles which are either downloaded from the Web or archived by LDC. $$$$$ We first convert each of the Japanese articles into a set of English words.
For example, Zhao and Vogel (2002), Utiyama and Isahara (2003), and Munteanu and Marcu (2005) all acquire their comparable corpora from a collection of news articles which are either downloaded from the Web or archived by LDC. $$$$$ Thus, SntScore is more reliable than SIM.
For example, Zhao and Vogel (2002), Utiyama and Isahara (2003), and Munteanu and Marcu (2005) all acquire their comparable corpora from a collection of news articles which are either downloaded from the Web or archived by LDC. $$$$$ This means that a threshold value is set for each of 19962001 and 1989-1996 so that valid alignments can be extracted by selecting alignments whose AVSIM is larger than the threshold.

Works aimed at discovering parallel sentences include (Utiyama and Isahara, 2003), who use cross-language information retrieval techniques and dynamic programming to extract sentences from an English-Japanese comparable corpus. $$$$$ They were 0.71 for 1996-2001 and 0.44 for 1989-1996.
Works aimed at discovering parallel sentences include (Utiyama and Isahara, 2003), who use cross-language information retrieval techniques and dynamic programming to extract sentences from an English-Japanese comparable corpus. $$$$$ Our sentence alignment program aligns sentences accurately if the English sentences are literal translations of the Japanese as discussed in Section 3.2.
Works aimed at discovering parallel sentences include (Utiyama and Isahara, 2003), who use cross-language information retrieval techniques and dynamic programming to extract sentences from an English-Japanese comparable corpus. $$$$$ However, in Table 7, there were 98 A’s and 2 D’s for samples from the top 38,090 alignments.
Works aimed at discovering parallel sentences include (Utiyama and Isahara, 2003), who use cross-language information retrieval techniques and dynamic programming to extract sentences from an English-Japanese comparable corpus. $$$$$ However, in Table 6, the number of A’s was 491 and D’s was 9, for the 500 samples extracted from the top-150,000 alignments.

The translations published on MNH are used to make a parallel corpus by using a sentence alignment method (Utiyama and Isahara, 2003). $$$$$ 10The notion of “appropriate (correct) sentence alignment” depends on applications.
The translations published on MNH are used to make a parallel corpus by using a sentence alignment method (Utiyama and Isahara, 2003). $$$$$ There were 89 A’s and 11 D’s.
The translations published on MNH are used to make a parallel corpus by using a sentence alignment method (Utiyama and Isahara, 2003). $$$$$ We then evaluate the effectiveness of the proposed measures.

These values of the parameter are determined using English sentences from Reuters articles (Utiyama and Isahara, 2003). $$$$$ The number of English articles used was 35,318, which is 68 percent of all of the articles.
These values of the parameter are determined using English sentences from Reuters articles (Utiyama and Isahara, 2003). $$$$$ A few requests were from high-school and junior-highschool teachers of English.
These values of the parameter are determined using English sentences from Reuters articles (Utiyama and Isahara, 2003). $$$$$ The measure for article alignment uses similarities in sentences aligned by DP matching and that for sentence alignment uses similarities in articles aligned by CLIR.
These values of the parameter are determined using English sentences from Reuters articles (Utiyama and Isahara, 2003). $$$$$ To achieve this, a reliable measure of the validity of sentence alignments is necessary.

Unlike other language pairs, the availability of Japanese-English parallel corpora is quite limited $$$$$ Each of the constructed dictionaries has over 300,000 entries.
Unlike other language pairs, the availability of Japanese-English parallel corpora is quite limited $$$$$ Let JZ and EZ be the words of Japanese and English sentences for i-th alignment.
Unlike other language pairs, the availability of Japanese-English parallel corpora is quite limited $$$$$ Therefore this comparison is not as objective as it could be.
Unlike other language pairs, the availability of Japanese-English parallel corpora is quite limited $$$$$ We select two English words for each of the Japanese words using simple heuristic rules based on the frequencies of English words.

The earliest efforts in this direction are those of Zhao and Vogel (2002) and Utiyama and Isahara (2003). $$$$$ We compared SntScore with SIM and found that SntScore is more reliable than SIM in discriminating between correct and incorrect alignments.
The earliest efforts in this direction are those of Zhao and Vogel (2002) and Utiyama and Isahara (2003). $$$$$ The English articles as of mid-July 1996 have tags indicating whether they are translated from Japanese articles or not, though they don’t have explicit links to the original Japanese articles.
The earliest efforts in this direction are those of Zhao and Vogel (2002) and Utiyama and Isahara (2003). $$$$$ We randomly extracted 100 samples from each of 10 blocks ranked at the top-300,000 alignments.

This database was an aggregate of several Japanese-English corpora, notably the Yomiuri newspaper corpus (Utiyama and Isahara, 2003) and the JST paper abstract corpus created at NICT (www.nict.go.jp) through (Utiyama and Isahara, 2007). $$$$$ The sentences5 in the aligned Japanese and English articles are aligned by a method based on DP matching (Gale and Church, 1993; Utsuro et al., 1994).
This database was an aggregate of several Japanese-English corpora, notably the Yomiuri newspaper corpus (Utiyama and Isahara, 2003) and the JST paper abstract corpus created at NICT (www.nict.go.jp) through (Utiyama and Isahara, 2007). $$$$$ We have proposed two measures for extracting valid article and sentence alignments.
This database was an aggregate of several Japanese-English corpora, notably the Yomiuri newspaper corpus (Utiyama and Isahara, 2003) and the JST paper abstract corpus created at NICT (www.nict.go.jp) through (Utiyama and Isahara, 2007). $$$$$ Comparing these figures with those in Table 1, we concluded that first and second evaluations were consistent.
This database was an aggregate of several Japanese-English corpora, notably the Yomiuri newspaper corpus (Utiyama and Isahara, 2003) and the JST paper abstract corpus created at NICT (www.nict.go.jp) through (Utiyama and Isahara, 2007). $$$$$ There were 89 A’s and 11 D’s.
