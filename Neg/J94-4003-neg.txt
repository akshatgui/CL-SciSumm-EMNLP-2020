Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ This evaluation was later used to judge the selections of the algorithm.
Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ Therefore, it suffices to check the odds ratio only for /51/152.
Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ Since we evaluated the method only on a relatively small number of random sentences, we first constructed the set of all &quot;relevant&quot; target tuples, i.e., tuples that should be considered for the test sentences.
Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ The remaining 27 examples were distributed according to Table 3.

Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ Thus were deleted.
Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ Since different relations may favor different translations for an ambiguous word, we should devise a strategy for selecting a consistent translation for all words in the sentence.
Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ However, our work shows that the differences between languages enable us to avoid any form of manual tagging of the corpus (including translation).
Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ Since the corresponding syntactic tuples would typically not be found in the corpora, they would be eliminated by our module.

We used two measurements, applicability and precision (Dagan and Itai 1994), to evaluate the performance of our method. $$$$$ Alternatively, it is possible to combine our method with other disambiguation methods that have been developed in a monolingual context (see the next section).
We used two measurements, applicability and precision (Dagan and Itai 1994), to evaluate the performance of our method. $$$$$ We also thank the anonymous reviewers for their detailed comments, which resulted in additional discussions and clarifications.
We used two measurements, applicability and precision (Dagan and Itai 1994), to evaluate the performance of our method. $$$$$ Our approach is first to use a bilingual lexicon to find all possible translations of each lexically ambiguous word in the source sentence and then use statistical information gathered from target language corpora to choose the most appropriate alternative.
We used two measurements, applicability and precision (Dagan and Itai 1994), to evaluate the performance of our method. $$$$$ Brown et al. (1991) make even weaker approximations, using only a stochastic part of speech tagger, and defining relations such as &quot;the first verb to the right&quot; or &quot;the first noun to the left.&quot; Finally, Dagan et al.

In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ The paper includes a detailed comparative analysis of statistical sense disambiguation methods.
In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ As discussed in Section 6.2, it is possible to increase the applicability (coverage) of the selection method by considering word co-occurrence in a limited context and/or by using similarity-based methods that reduce the problem of data sparseness.
In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ Within this framework, a possible (though partial) alternative to using manually constructed knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora (e.g., Grishman, Hirschman, and Nhan 1986).
In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ Now it is possible to collect co-occurrence statistics automatically from a corpus of the other language, without requiring manual tagging of senses.'

The idea of obtaining linguistic information about a text in one language by exploiting parallel or comparable texts in another language has been explored in the field of Word Sense Disambiguation (WSD) since the early 90's, the most representative works being (Brown et al, 1991), (Gale et al, 1992), and (Dagan and Itai, 1994). $$$$$ Denote the source language syntactic tuple T and let there be k alternative target tuples for T, denoted by Th • • , Tk.
The idea of obtaining linguistic information about a text in one language by exploiting parallel or comparable texts in another language has been explored in the field of Word Sense Disambiguation (WSD) since the early 90's, the most representative works being (Brown et al, 1991), (Gale et al, 1992), and (Dagan and Itai, 1994). $$$$$ The table demonstrates that our algorithm corrects 22 erroneous decisions of the Word Frequencies method, but makes only 2 errors that the Word Frequencies method translates correctly.
The idea of obtaining linguistic information about a text in one language by exploiting parallel or comparable texts in another language has been explored in the field of Word Sense Disambiguation (WSD) since the early 90's, the most representative works being (Brown et al, 1991), (Gale et al, 1992), and (Dagan and Itai, 1994). $$$$$ For tuple 4 we obtain nine alternative target tuples, since each of the words hit qaddmut and say maps to three different English words.

Note that, unlike Dagan and Itai (1994), we give no consideration to statistical confidence as we are after 100% recall, whatever the cost to precision. $$$$$ In this sentence (but not in others), the ambiguous word qshura can equally well be translated to either 'related' or 'connected.'
Note that, unlike Dagan and Itai (1994), we give no consideration to statistical confidence as we are after 100% recall, whatever the cost to precision. $$$$$ Preparing one test set by hand may still be reasonable, though time consuming.
Note that, unlike Dagan and Itai (1994), we give no consideration to statistical confidence as we are after 100% recall, whatever the cost to precision. $$$$$ After acquiring all the relevant data, the algorithm of Section 3.3 was executed for each of the test sentences.
Note that, unlike Dagan and Itai (1994), we give no consideration to statistical confidence as we are after 100% recall, whatever the cost to precision. $$$$$ Preparing one test set by hand may still be reasonable, though time consuming.

It may, therefore, be desirable to apply a dynamic threshold on the discriminative ratio (cf. (Dagan and Itai, 1994)) to accept only those translation pairs with sufficiently high statistical confidence, for example. $$$$$ The method presented in this paper takes advantage of two linguistic phenomena, both proven to be very useful for sense disambiguation: the different mapping between words and word senses among different languages, and the importance of lexical co-occurrence within syntactic relations.
It may, therefore, be desirable to apply a dynamic threshold on the discriminative ratio (cf. (Dagan and Itai, 1994)) to accept only those translation pairs with sufficiently high statistical confidence, for example. $$$$$ This postprocessing routine dealt mainly with function words and prepositional phrases to get a set of more informative relations.
It may, therefore, be desirable to apply a dynamic threshold on the discriminative ratio (cf. (Dagan and Itai, 1994)) to accept only those translation pairs with sufficiently high statistical confidence, for example. $$$$$ The preferred senses are then selected according to statistics on lexical relations in the target language.
It may, therefore, be desirable to apply a dynamic threshold on the discriminative ratio (cf. (Dagan and Itai, 1994)) to accept only those translation pairs with sufficiently high statistical confidence, for example. $$$$$ The method was evaluated using three sets of Hebrew and German examples and was found to be very useful for disambiguation.

However, most of previous research has focused on using multilingual resources typically used in SMT systems to improve WSD accuracy Dagan and Itai (1994). $$$$$ This enables us to map an ambiguous construct from one language to another, obtaining representations in which each sense corresponds to a distinct word.
However, most of previous research has focused on using multilingual resources typically used in SMT systems to improve WSD accuracy Dagan and Itai (1994). $$$$$ The presented algorithm identifies syntactic relations between words, using a source language parser, and maps the alternative interpretations of these relations to the target language, using a bilingual lexicon.
However, most of previous research has focused on using multilingual resources typically used in SMT systems to improve WSD accuracy Dagan and Itai (1994). $$$$$ As explained in Section 7, this method has significant practical and theoretical advantages over the use of aligned bilingual corpora.

For example, Dagan and Itai (1994) carried out WSD experiments using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ Clearly, statistics on lexical relations can also be useful for target word selection.
For example, Dagan and Itai (1994) carried out WSD experiments using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ The paper concentrates on the problem of target word selection in machine translation, for which the approach is directly applicable.
For example, Dagan and Itai (1994) carried out WSD experiments using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ Section 2.3: A procedure for mapping the source language syntactic relations to those of the target language.
For example, Dagan and Itai (1994) carried out WSD experiments using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ Finally, our method was evaluated by simulating realistic machine translation lexicons, on randomly selected examples, and yielded high performance in two different broad domains (foreign news articles and a software manual).

Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ An optimal method may exploit both types of corpora, in which the somewhat more accurate, but more expensive, data of a bilingual corpus are augmented by the data of a much larger monolingual corpus.13 quantities of shallow information.
Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ These senses should be distinguished by most applications of Hebrew understanding programs.
Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ A promising approach may be to use aligned bilingual corpora, especially for augmenting existing lexicons with domain-specific terminology (Brown et al. 1993; Dagan, Church, and Gale 1993).
Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ As explained above, such constraints cannot be acquired automatically and therefore are usually limited in their coverage.

The work of (Dagan and Itai, 1994) has also successfully used WSD to improve the accuracy of machine translation. $$$$$ In other words, the Word Frequencies method prefers the alternative that has the highest a priori probability of appearing in the target language corpus.
The work of (Dagan and Itai, 1994) has also successfully used WSD to improve the accuracy of machine translation. $$$$$ The presented algorithm identifies syntactic relations between words, using a source language parser, and maps the alternative interpretations of these relations to the target language, using a bilingual lexicon.
The work of (Dagan and Itai, 1994) has also successfully used WSD to improve the accuracy of machine translation. $$$$$ The preferred senses are then selected according to statistics on lexical relations in the target language.
The work of (Dagan and Itai, 1994) has also successfully used WSD to improve the accuracy of machine translation. $$$$$ To that end, we should define a selection algorithm whose outcome depends on all the syntactic tuples in the sentence.

Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ Special thanks are due to Ulrike Schwa11 for her fruitful collaboration.
Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ For every source language word, the translator searched all possible translations using a Hebrew–English dictionary (Alcalay 1990).
Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ However, we wish to point out that we do not see the statistical considerations, as expressed in the model, as fully reflecting the linguistic considerations (syntactic, semantic, or pragmatic) that determine the correct translation.

The first method is based on a decision threshold (Dagan and Itai, 1994) $$$$$ This means that when translating T we are counting occurrences of T2 that correspond to both T and T', &quot;misleading&quot; the selection criterion.
The first method is based on a decision threshold (Dagan and Itai, 1994) $$$$$ In the experiment we conducted we chose the parameters a = 0.1, for which Za -= 1.282, and 0 = 0.2.

As in (Dagan and Itai, 1994), we adjusted the measure to the amount of evidence. $$$$$ The presented algorithm identifies syntactic relations between words, using a source language parser, and maps the alternative interpretations of these relations to the target language, using a bilingual lexicon.
As in (Dagan and Itai, 1994), we adjusted the measure to the amount of evidence. $$$$$ Hence, the results we report measure the performance of just the target word selection module and not the performance of a complete translation system.
As in (Dagan and Itai, 1994), we adjusted the measure to the amount of evidence. $$$$$ If such an occurrence can be disambiguated automatically with high confidence, the system acquires additional statistics from this occurrence, as if it were tagged by hand.

(Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew). $$$$$ Now it is possible to collect co-occurrence statistics automatically from a corpus of the other language, without requiring manual tagging of senses.'
(Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew). $$$$$ Redundancy relates to the fact that different informants (such as different lexical relations or deep understanding) tend to support rather than contradict one another, and therefore the chance of picking a &quot;wrong&quot; informant is low.
(Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew). $$$$$ From a general perspective, these two types of information represent a common trade-off in statistical language processing: the first type is related to a limited amount of deeper, and more precise linguistic information, whereas the second type provides a large amount of shallow information, which can be applied in a more robust manner.
(Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew). $$$$$ The paper concentrates on the problem of target word selection in machine translation, for which the approach is directly applicable.
