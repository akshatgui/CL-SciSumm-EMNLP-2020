Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ However, this might not be the case because Assumption 3 is contradicted.
Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ It is denoted by the name of the syntactic relation followed by a sequence of words that satisfies the relation, appearing in their base form (without morphological inflections).
Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ Section 5 presents and analyzes the results of the experiment and cites additional results (Dagan, Marcus, and Markovitch 1993).
Due to the recent availability of large text corpora, various statistical approaches have been tried including using 1) parallel corpora (Brown et al., 1990), (Brown et al., 1991), (Brown, 1997), 2) non-parallel bilingual corpora tagged with topic area (Yamabana et al., 1998) and 3) un-tagged mono-language corpora in the target language (Dagan and Itai, 1994), (Tanaka and Iwasaki, 1996), (Kikui, 1998). $$$$$ This approach exploits the differences between mappings of words to senses in different languages.

Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ The selection is based on a statistical model and on a constraint propagation algorithm, which simultaneously handles all ambiguities in the sentence.
Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ For instance, it seems reasonable that the object of a noun should receive greater weight in selecting the noun's sense than the verb for which this noun serves as a complement.
Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ 40-41).
Dagan and Itai (1994) have also addressed the lexical selection problem from the TL point of view. $$$$$ , Tk.

We used two measurements, applicability and precision (Dagan and Itai 1994), to evaluate the performance of our method. $$$$$ Finally, our method was evaluated by simulating realistic machine translation lexicons, on randomly selected examples, and yielded high performance in two different broad domains (foreign news articles and a software manual).
We used two measurements, applicability and precision (Dagan and Itai 1994), to evaluate the performance of our method. $$$$$ The most reasonable assumption is to choose the tuple with the highest estimated probability, that is Ti—the tuple with the largest observed frequency According to the model, the probability that T1 is the right choice is estimated as This criterion should be subject to the condition that the difference between the alternative probabilities is significant.

In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ The remaining 27 examples were distributed according to Table 3.
In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ We also thank the anonymous reviewers for their detailed comments, which resulted in additional discussions and clarifications.
In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ We are grateful to Mon Rimon, Peter Brown, Ayala Cohen, Ulrike Rackow, Herb Leass, and Bill Gale for their help and comments.
In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. $$$$$ The method was evaluated using three sets of Hebrew and German examples and was found to be very useful for disambiguation.

The idea of obtaining linguistic information about a text in one language by exploiting parallel or comparable texts in another language has been explored in the field of Word Sense Disambiguation (WSD) since the early 90's, the most representative works being (Brown et al, 1991), (Gale et al, 1992), and (Dagan and Itai, 1994). $$$$$ This word has several translations, two of which are 'state' and 'position.'
The idea of obtaining linguistic information about a text in one language by exploiting parallel or comparable texts in another language has been explored in the field of Word Sense Disambiguation (WSD) since the early 90's, the most representative works being (Brown et al, 1991), (Gale et al, 1992), and (Dagan and Itai, 1994). $$$$$ The preferred senses are then selected according to statistics on lexical relations in the target language.
The idea of obtaining linguistic information about a text in one language by exploiting parallel or comparable texts in another language has been explored in the field of Word Sense Disambiguation (WSD) since the early 90's, the most representative works being (Brown et al, 1991), (Gale et al, 1992), and (Dagan and Itai, 1994). $$$$$ Computationally, the syntactic methods are the most affordable, but are of no avail in the frequent situation when the different senses of the word show the same syntactic behavior, having the same part of speech and even the same subcategorization frame.
The idea of obtaining linguistic information about a text in one language by exploiting parallel or comparable texts in another language has been explored in the field of Word Sense Disambiguation (WSD) since the early 90's, the most representative works being (Brown et al, 1991), (Gale et al, 1992), and (Dagan and Itai, 1994). $$$$$ We are grateful to Mon Rimon, Peter Brown, Ayala Cohen, Ulrike Rackow, Herb Leass, and Bill Gale for their help and comments.

Note that, unlike Dagan and Itai (1994), we give no consideration to statistical confidence as we are after 100% recall, whatever the cost to precision. $$$$$ This paper presents a new approach for resolving lexical ambiguities in one language using statistical data from a monolingual corpus of another language.
Note that, unlike Dagan and Itai (1994), we give no consideration to statistical confidence as we are after 100% recall, whatever the cost to precision. $$$$$ To facilitate further the mapping of syntactic relations and to avoid errors due to fine distinctions between them, we grouped related syntactic relations into a single &quot;general class&quot; and mapped this class to the target language.

It may, therefore, be desirable to apply a dynamic threshold on the discriminative ratio (cf. (Dagan and Itai, 1994)) to accept only those translation pairs with sufficiently high statistical confidence, for example. $$$$$ The use of these general classes, which was intended to facilitate the mapping of syntactic relations from one language to another, also facilitated our simulation method and caused it to produce realistic output.
It may, therefore, be desirable to apply a dynamic threshold on the discriminative ratio (cf. (Dagan and Itai, 1994)) to accept only those translation pairs with sufficiently high statistical confidence, for example. $$$$$ The preferred senses are then selected according to statistics on lexical relations in the target language.

However, most of previous research has focused on using multilingual resources typically used in SMT systems to improve WSD accuracy Dagan and Itai (1994). $$$$$ In our opinion, the method proposed in this paper may have immediate practical value, beyond its theoretical aspects.
However, most of previous research has focused on using multilingual resources typically used in SMT systems to improve WSD accuracy Dagan and Itai (1994). $$$$$ Therefore, these instances should not be considered for the current example, which includes the preposition 'to.'
However, most of previous research has focused on using multilingual resources typically used in SMT systems to improve WSD accuracy Dagan and Itai (1994). $$$$$ (1992a).
However, most of previous research has focused on using multilingual resources typically used in SMT systems to improve WSD accuracy Dagan and Itai (1994). $$$$$ In this section we give a detailed analysis of the selections performed by the algorithm and, in particular, analyze the cases when it failed.

For example, Dagan and Itai (1994) carried out WSD experiments using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ Since we did not have a Hebrew parser, we have simulated the two steps of determining the source syntactic tuples and mapping them to English by reversing the order of these steps, in the following way: First, the sample sentences were translated manually, as literally as possible, into English.
For example, Dagan and Itai (1994) carried out WSD experiments using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ The TWS' method still assumes that the source sentence to be translated is being parsed, in order to identify the words that are syntactically related to an ambiguous word.
For example, Dagan and Itai (1994) carried out WSD experiments using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ This approach exploits the differences between mappings of words to senses in different languages.

Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ Substantial effort may be required for collecting a sufficiently large target language corpus.
Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ The model reflects only part of the relevant data and in addition makes statistical assumptions that are only partially satisfied.
Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ It seems, however, that Brown et al. expect that target word selection would be determined mainly by translation probabilities (the second factor in the above term), which should be derived from a bilingual corpus (Brown et al.
Dagan and Itai (1994) indicate that two languages are more informative than one; an English corpus is very helpful in disambiguating polysemous words in Hebrew text. $$$$$ The method was evaluated using three sets of Hebrew and German examples and was found to be very useful for disambiguation.

The work of (Dagan and Itai, 1994) has also successfully used WSD to improve the accuracy of machine translation. $$$$$ For example, if /51 -= 0.51 and /52 = 0.49, the expected success rate in choosing T1 is approximately 0.5.
The work of (Dagan and Itai, 1994) has also successfully used WSD to improve the accuracy of machine translation. $$$$$ For these values Ba -= 1.137.

Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ The selection is based on a statistical model and on a constraint propagation algorithm, which simultaneously handles all ambiguities in the sentence.
Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ We compare the precision of our method, which we term TWS (for Target Word Selection), with that of the Word Frequencies procedure, which always selects the most frequent target word.
Dagan and Itai (1994) proposed an approach to WSD using monolingual corpora, a bilingual lexicon and a parser for the source language. $$$$$ The selection is based on a statistical model and on a constraint propagation algorithm, which simultaneously handles all ambiguities in the sentence.

The first method is based on a decision threshold (Dagan and Itai, 1994): the algorithm rejects decisions taken when the difference of the maximum likelihood among the competing senses is not big enough. $$$$$ The paper concentrates on the problem of target word selection in machine translation, for which the approach is directly applicable.
The first method is based on a decision threshold (Dagan and Itai, 1994): the algorithm rejects decisions taken when the difference of the maximum likelihood among the competing senses is not big enough. $$$$$ The presented algorithm identifies syntactic relations between words, using a source language parser, and maps the alternative interpretations of these relations to the target language, using a bilingual lexicon.
The first method is based on a decision threshold (Dagan and Itai, 1994): the algorithm rejects decisions taken when the difference of the maximum likelihood among the competing senses is not big enough. $$$$$ Hence, the results we report measure the performance of just the target word selection module and not the performance of a complete translation system.

As in (Dagan and Itai, 1994), we adjusted the measure to the amount of evidence. $$$$$ For example (subj—verb: man walk) is a syntactic tuple, which occurs in the sentence 'The man walked home.'
As in (Dagan and Itai, 1994), we adjusted the measure to the amount of evidence. $$$$$ The identification of syntactic relations in the source sentence is available in any machine translation system that uses some form of syntactic parsing.
As in (Dagan and Itai, 1994), we adjusted the measure to the amount of evidence. $$$$$ It thus demonstrates a possible trade-off between these two types of probabilities: using more informative statistics of the target language may compensate for the lack of translation probabilities.

(Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew). $$$$$ In the three experiments we reported, there were 61 cases in which the two types of information contradicted each other, favoring different target words.
(Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew). $$$$$ The meaning of this criterion is that only if we know with confidence of at least 1 — a that ln(pi /p2) > 0, will we select the most frequent tuple T1 as the appropriate one.
(Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew). $$$$$ The remaining 173 examples were distributed according to Table 4.
