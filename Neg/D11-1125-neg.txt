 $$$$$ The results in Figure 3 indicate that as the dimensionality of the problem increases MERT rapidly loses the ability to learn w∗.
 $$$$$ The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05.
 $$$$$ Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software.
 $$$$$ This lack of scalability is a significant weakness, as it inhibits systems from using more than a couple dozen features to discriminate between candidate translations and stymies feature development innovation.

RAMPION settings were as described in (Gimpel and Smith, 2012), and PRO settings as described in (Hopkins and May, 2011), with PRO requiring regularization tuning in order to be competitive with the other optimizers. $$$$$ Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.
RAMPION settings were as described in (Gimpel and Smith, 2012), and PRO settings as described in (Hopkins and May, 2011), with PRO requiring regularization tuning in order to be competitive with the other optimizers. $$$$$ A policy of candidate space (A, I, J, f, e, x) is a function that maps each member i E I to a member of J(i).
RAMPION settings were as described in (Gimpel and Smith, 2012), and PRO settings as described in (Hopkins and May, 2011), with PRO requiring regularization tuning in order to be competitive with the other optimizers. $$$$$ However, it is often claimed that MERT does not scale well with dimensionality.

We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.
We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.
We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.
We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ Several researchers have attempted to address this weakness.

Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ For the example in Figure 1, policy p1 = 11 �-+ 2, 2 �-+ 31 corresponds to the choice of “he does not go” for the first source sentence and “I do not go” for the second source sentence.
Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted.
Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research.
Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ In the pairwise approach, the learning task is framed as the classification of candidate pairs into two categories: correctly ordered and incorrectly ordered.

Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.
Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ In Figure 1, we show an example candidate space, defined as a tuple (A, I, J, f, e, x) where: The example candidate space has two source sentences, three candidate translations for each source sentence, and feature vectors of dimension 2.
Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.
Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ MERT is well-understood, easy to implement, and runs quickly, but can behave erratically and does not scale beyond a handful of features.

 $$$$$ Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data.
 $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.
 $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.
 $$$$$ Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations.

It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible. $$$$$ The exact loss function ls,(Hw, G) optimized depends on the choice of classifier.4 Typical approaches to pairwise ranking enumerate all difference vectors as training data.
It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible. $$$$$ It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours.
It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible. $$$$$ In practice, tuning optimizes over a finite subset of source sentences3 and a finite subset of candidate translations as well.

We cast MT tuning as pairwise ranking (Herbrich et al, 1999, inter alia), which Hopkins and May (2011) applied to MT. $$$$$ A policy corresponds to a choice of one candidate translation for each source sentence.
We cast MT tuning as pairwise ranking (Herbrich et al, 1999, inter alia), which Hopkins and May (2011) applied to MT. $$$$$ A policy corresponds to a choice of one candidate translation for each source sentence.
We cast MT tuning as pairwise ranking (Herbrich et al, 1999, inter alia), which Hopkins and May (2011) applied to MT. $$$$$ Policy p2 = 11 �-+ 3, 2 �-+ 11 corresponds to the inferior translations “she not go” and “I go not.” We assume the MT system distinguishes between policies using a scoring function for candidate translations of the form hw(i, j) = w · x(i, j), where w is a weight vector of the same dimension as feature vector x(i, j).

Introduced by Hopkins and May (2011), Pairwise Ranking Optimization (PRO) aims to handle large feature sets inside the traditional MERT architecture. $$$$$ However, the technique is complex and architecturally quite different from MERT.
Introduced by Hopkins and May (2011), Pairwise Ranking Optimization (PRO) aims to handle large feature sets inside the traditional MERT architecture. $$$$$ We implore the reader to avoid the natural tendency to compare results using baseline vs. extended features or between PBMT and SBMT on the same language pair.
Introduced by Hopkins and May (2011), Pairwise Ranking Optimization (PRO) aims to handle large feature sets inside the traditional MERT architecture. $$$$$ Chiang et al. (2009), Section 4.1):10 We used the following feature classes in PBMT extended scenarios only: The feature classes and number of features used within those classes for each language pair are summarized in Table 3.

Hopkins and May (2011) advocate a maximum-entropy version of PRO, which is what we evaluate in our empirical comparison. $$$$$ We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.
Hopkins and May (2011) advocate a maximum-entropy version of PRO, which is what we evaluate in our empirical comparison. $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.
Hopkins and May (2011) advocate a maximum-entropy version of PRO, which is what we evaluate in our empirical comparison. $$$$$ A policy of candidate space (A, I, J, f, e, x) is a function that maps each member i E I to a member of J(i).
Hopkins and May (2011) advocate a maximum-entropy version of PRO, which is what we evaluate in our empirical comparison. $$$$$ Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.

We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.
We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ Mindful that many would-be enhancements to the state-of-the-art are false positives that only show improvement in a narrowly defined setting or with limited data, we validate our claims on both syntax and phrase-based systems, using multiple language pairs and large data sets.
We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement.
We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours.

Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ (2008b; 2009).
Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009).
Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.
Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ We show an example g in Figure 1.

Hopkins and May (2011) presented a method that uses a binary classifier. $$$$$ Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.
Hopkins and May (2011) presented a method that uses a binary classifier. $$$$$ The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation.
Hopkins and May (2011) presented a method that uses a binary classifier. $$$$$ In practice, tuning optimizes over a finite subset of source sentences3 and a finite subset of candidate translations as well.
Hopkins and May (2011) presented a method that uses a binary classifier. $$$$$ The exact loss function ls,(Hw, G) optimized depends on the choice of classifier.4 Typical approaches to pairwise ranking enumerate all difference vectors as training data.

Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999).
Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ For the example in Figure 1, policy p1 = 11 �-+ 2, 2 �-+ 31 corresponds to the choice of “he does not go” for the first source sentence and “I do not go” for the second source sentence.
Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ We can then feed this training data directly to any off-the-shelf classification tool that returns a linear classifier, in order to obtain a weight vector w that optimizes the above condition.
Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ However, it is often claimed that MERT does not scale well with dimensionality.

Following Hopkins and May (2011), we used the following parameters for the sampling task $$$$$ MERT has proven itself effective at tuning candidate spaces with low dimensionality.
Following Hopkins and May (2011), we used the following parameters for the sampling task $$$$$ Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted.
Following Hopkins and May (2011), we used the following parameters for the sampling task $$$$$ If MERT cannot scale in this simple scenario, it has little hope of succeeding in a high-dimensionality deployment scenario.

 $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.
 $$$$$ Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.
 $$$$$ During optimization, the weight vector w is optimized to minimize loss ls,(Hw, G).
 $$$$$ For its candidate generation phase, MERT generates the k-best candidate translations for each source sentence according to hw, where w is the weight vector from the previous optimization phase (or an arbitrary weight vector for the first iteration).

Like Hopkins and May (2011), we optimize ranking in n-best lists, but learn parameters in an online fashion. $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.
Like Hopkins and May (2011), we optimize ranking in n-best lists, but learn parameters in an online fashion. $$$$$ The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009).
Like Hopkins and May (2011), we optimize ranking in n-best lists, but learn parameters in an online fashion. $$$$$ The training data for Arabic English is that made available in the constrained track in the NIST 2008 MT evaluation.
Like Hopkins and May (2011), we optimize ranking in n-best lists, but learn parameters in an online fashion. $$$$$ This scoring function extends to a policy p by summing the cost of each of the policy’s candidate translations: Hw(p) = Ei∈I hw(i, p(i)).

Unlike Hopkins and May (2011), we do not randomly sample from all the pairs in the n-best translations, but extract pairs by selecting one oracle translation and one other translation in the n-bests other than those in ORACLE. $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.
Unlike Hopkins and May (2011), we do not randomly sample from all the pairs in the n-best translations, but extract pairs by selecting one oracle translation and one other translation in the n-bests other than those in ORACLE. $$$$$ Specifically, we use 15 baseline features for PBMT, similar to the baseline features described by Watanabe et al. (2007).
Unlike Hopkins and May (2011), we do not randomly sample from all the pairs in the n-best translations, but extract pairs by selecting one oracle translation and one other translation in the n-bests other than those in ORACLE. $$$$$ To test this claim, we devised the following synthetic data experiment: We used line optimization in the standard way, by generating 20 random starting weight vectors and hill-climbing on each independently until no further progress is made, then choosing the final weight vector that minimizes loss.
Unlike Hopkins and May (2011), we do not randomly sample from all the pairs in the n-best translations, but extract pairs by selecting one oracle translation and one other translation in the n-bests other than those in ORACLE. $$$$$ We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations.

Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research.
Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research.
Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.
Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999).

Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ It is an example of a finite candidate space, defined as a candidate space for which I is finite and J maps each index of I to a finite set.
Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.
Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ We can re-express this condition: Thus optimization reduces to a classic binary classification problem.
Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.
