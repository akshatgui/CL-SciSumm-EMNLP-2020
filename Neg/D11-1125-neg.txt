 $$$$$ To test this claim, we devised the following synthetic data experiment: We used line optimization in the standard way, by generating 20 random starting weight vectors and hill-climbing on each independently until no further progress is made, then choosing the final weight vector that minimizes loss.
 $$$$$ We describe tuning in abstract and somewhat formal terms in Section 2, describe the MERT algorithm in the context of those terms and illustrate its scalability issues via a synthetic experiment in Section 3, introduce our pairwise ranking optimization method in Section 4, present numerous large-scale MT experiments to validate our claims in Section 5, discuss some related work in Section 6, and conclude in Section 7.
 $$$$$ MERT has proven itself effective at tuning candidate spaces with low dimensionality.
 $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.

RAMPION settings were as described in (Gimpel and Smith, 2012), and PRO settings as described in (Hopkins and May, 2011), with PRO requiring regularization tuning in order to be competitive with the other optimizers. $$$$$ The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05.
RAMPION settings were as described in (Gimpel and Smith, 2012), and PRO settings as described in (Hopkins and May, 2011), with PRO requiring regularization tuning in order to be competitive with the other optimizers. $$$$$ Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations.
RAMPION settings were as described in (Gimpel and Smith, 2012), and PRO settings as described in (Hopkins and May, 2011), with PRO requiring regularization tuning in order to be competitive with the other optimizers. $$$$$ We for the most part follow the MIRA algorithm for machine translation as described by Chiang et al. (2009)12 but instead of using the 10-best of each of the best hw, hw +g, and hw-g, we use the 30-best according to hw.13 We use the same sentence-level BLEU calculated in the context of previous 1-best translations as Chiang et al.
RAMPION settings were as described in (Gimpel and Smith, 2012), and PRO settings as described in (Hopkins and May, 2011), with PRO requiring regularization tuning in order to be competitive with the other optimizers. $$$$$ Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement.

We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ Policy p2 = 11 �-+ 3, 2 �-+ 11 corresponds to the inferior translations “she not go” and “I go not.” We assume the MT system distinguishes between policies using a scoring function for candidate translations of the form hw(i, j) = w · x(i, j), where w is a weight vector of the same dimension as feature vector x(i, j).
We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ It is an example of a finite candidate space, defined as a candidate space for which I is finite and J maps each index of I to a finite set.
We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ (2008b) have developed tuning methods using the MIRA algorithm (Crammer and Singer, 2003) as a nucleus.
We found similar fluctuations for the cdec implementations of PRO (Hopkins and May, 2011) or hyper graph-MERT (Kumar et al, 2009) both of which depend on hyper graph sampling. $$$$$ It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours.

Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.
Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data.
Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.
Additionally, we present Joshua's implementation of the pairwise ranking optimization (Hopkins and May, 2011) approach to translation model tuning. $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.

Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research.
Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.
Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement.
Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation. $$$$$ Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.

 $$$$$ We quantified PRO’s stability as compared to MERT by repeating the Urdu-English baseline PBMT experiment five times with each configuration.
 $$$$$ The results of the noisy synthetic experiments, but still The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors.
 $$$$$ This information is provided by a “gold” scoring function G that maps each policy to a real-valued score.
 $$$$$ For its candidate generation phase, MERT generates the k-best candidate translations for each source sentence according to hw, where w is the weight vector from the previous optimization phase (or an arbitrary weight vector for the first iteration).

It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible. $$$$$ Note that this induces a ranking on the candidate translations for each source sentence.
It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible. $$$$$ For its candidate generation phase, MERT generates the k-best candidate translations for each source sentence according to hw, where w is the weight vector from the previous optimization phase (or an arbitrary weight vector for the first iteration).
It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible. $$$$$ The G we optimize is tokenized, lower-cased 4-gram BLEU (Papineni et al., 2002).
It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible. $$$$$ Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts.

We cast MT tuning as pairwise ranking (Herbrich et al, 1999, inter alia), which Hopkins and May (2011) applied to MT. $$$$$ The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation.
We cast MT tuning as pairwise ranking (Herbrich et al, 1999, inter alia), which Hopkins and May (2011) applied to MT. $$$$$ Tillmann and Zhang (2005) used a customized form of multi-class stochastic gradient descent to learn feature weights for an MT model.
We cast MT tuning as pairwise ranking (Herbrich et al, 1999, inter alia), which Hopkins and May (2011) applied to MT. $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.

Introduced by Hopkins and May (2011), Pairwise Ranking Optimization (PRO) aims to handle large feature sets inside the traditional MERT architecture. $$$$$ While intuitive, the MERT optimization module focuses attention on Hw’s best policy, and not on its overall prowess at ranking policies.
Introduced by Hopkins and May (2011), Pairwise Ranking Optimization (PRO) aims to handle large feature sets inside the traditional MERT architecture. $$$$$ The classic tuning architecture used in the dominant MERT approach (Och, 2003) forms the translation subset and learns weight vector w via Algorithm TUNE(s, G): space s = hA, I, J, f, e, xi w.r.t. gold function G. a feedback loop consisting of two phases.
Introduced by Hopkins and May (2011), Pairwise Ranking Optimization (PRO) aims to handle large feature sets inside the traditional MERT architecture. $$$$$ We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.
Introduced by Hopkins and May (2011), Pairwise Ranking Optimization (PRO) aims to handle large feature sets inside the traditional MERT architecture. $$$$$ Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT.

Hopkins and May (2011) advocate a maximum-entropy version of PRO, which is what we evaluate in our empirical comparison. $$$$$ The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system.
Hopkins and May (2011) advocate a maximum-entropy version of PRO, which is what we evaluate in our empirical comparison. $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.
Hopkins and May (2011) advocate a maximum-entropy version of PRO, which is what we evaluate in our empirical comparison. $$$$$ However, the technique is complex and architecturally quite different from MERT.

We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.
We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ Figure 2 shows the pseudocode.
We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ Mindful that many would-be enhancements to the state-of-the-art are false positives that only show improvement in a narrowly defined setting or with limited data, we validate our claims on both syntax and phrase-based systems, using multiple language pairs and large data sets.
We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011). $$$$$ We can re-express this condition: Thus optimization reduces to a classic binary classification problem.

Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations.
Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data.
Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ It is an example of a finite candidate space, defined as a candidate space for which I is finite and J maps each index of I to a finite set.
Feature weights were re-tuned with PRO (Hopkins and May, 2011) for Czech-English and batch MIRA (Cherry and Foster, 2012) for French-English and Spanish-English because these worked best for the baseline. $$$$$ We would like to modify MERT so that it scales well to high-dimensionality candidate spaces.

Hopkins and May (2011) presented a method that uses a binary classifier. $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.
Hopkins and May (2011) presented a method that uses a binary classifier. $$$$$ Mindful that many would-be enhancements to the state-of-the-art are false positives that only show improvement in a narrowly defined setting or with limited data, we validate our claims on both syntax and phrase-based systems, using multiple language pairs and large data sets.
Hopkins and May (2011) presented a method that uses a binary classifier. $$$$$ Of primary concern to us is the ease of adoption of our proposed technique.

Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ A policy of candidate space (A, I, J, f, e, x) is a function that maps each member i E I to a member of J(i).
Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.
Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ We can re-express this condition: Thus optimization reduces to a classic binary classification problem.
Hopkins and May (2011) introduced the method of pairwise ranking optimization (PRO), which casts the problem of tuning as a ranking problem between pairs of translation candidates. $$$$$ It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research.

Following Hopkins and May (2011), we used the following parameters for the sampling task: For each sentence, the decoder generates the 1500 best candidate translations (k= 1500), and the sampler samples 5000 pairs (n= 5000). $$$$$ This lack of scalability is a significant weakness, as it inhibits systems from using more than a couple dozen features to discriminate between candidate translations and stymies feature development innovation.
Following Hopkins and May (2011), we used the following parameters for the sampling task: For each sentence, the decoder generates the 1500 best candidate translations (k= 1500), and the sampler samples 5000 pairs (n= 5000). $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.
Following Hopkins and May (2011), we used the following parameters for the sampling task: For each sentence, the decoder generates the 1500 best candidate translations (k= 1500), and the sampler samples 5000 pairs (n= 5000). $$$$$ We used the following feature classes in SBMT and PBMT extended scenarios: We used the following feature classes in SBMT extended scenarios only (cf.
Following Hopkins and May (2011), we used the following parameters for the sampling task: For each sentence, the decoder generates the 1500 best candidate translations (k= 1500), and the sampler samples 5000 pairs (n= 5000). $$$$$ Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement.

 $$$$$ (2008b; 2009).
 $$$$$ We trained a 3-gram English language model on the English side of the training data.
 $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.
 $$$$$ As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8.

Like Hopkins and May (2011), we optimize ranking in n-best lists, but learn parameters in an online fashion. $$$$$ Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model.
Like Hopkins and May (2011), we optimize ranking in n-best lists, but learn parameters in an online fashion. $$$$$ We now detail the three language pairs, two feature scenarios, and two MT models used for our experiments.
Like Hopkins and May (2011), we optimize ranking in n-best lists, but learn parameters in an online fashion. $$$$$ The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system.

Unlike Hopkins and May (2011), we do not randomly sample from all the pairs in the n-best translations, but extract pairs by selecting one oracle translation and one other translation in the n-bests other than those in ORACLE. $$$$$ Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.
Unlike Hopkins and May (2011), we do not randomly sample from all the pairs in the n-best translations, but extract pairs by selecting one oracle translation and one other translation in the n-bests other than those in ORACLE. $$$$$ We tried various dimensionalities from 10 to 1000.
Unlike Hopkins and May (2011), we do not randomly sample from all the pairs in the n-best translations, but extract pairs by selecting one oracle translation and one other translation in the n-bests other than those in ORACLE. $$$$$ We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.

Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ The results in Figure 3 indicate that as the dimensionality of the problem increases MERT rapidly loses the ability to learn w∗.
Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.
Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.
Hopkins and May (2011) applied a MERT-like procedure in Alg 1 in which Equation 4 was solved to obtain new parameters in each iteration. $$$$$ As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8.

Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ In Figure 1, we show an example candidate space, defined as a tuple (A, I, J, f, e, x) where: The example candidate space has two source sentences, three candidate translations for each source sentence, and feature vectors of dimension 2.
Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT.
Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.
Hopkins and May (2011) minimized logistic loss sampled from the merged n-bests, and sentence-BLEU was used for determining ranks. $$$$$ Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.
