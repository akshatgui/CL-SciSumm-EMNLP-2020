However, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses (Navigli, 2006). $$$$$ Overall, 4,599 out of the 5,077 WordNet senses had a corresponding sense in ODE (i.e. the ODE covered 90.58% of the WordNet senses in the data set), while 2,053 out of the 2,600 ODE senses had an analogous entry in WordNet (i.e.
However, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses (Navigli, 2006). $$$$$ Unfortunately, the approach is not described in detail and no evaluation is provided.
However, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses (Navigli, 2006). $$$$$ For example, some of the relations found between concepts in dsem contributing to the final value of the function on the two senses: Due to the normalization factor in the denominator, these values are generally low, but unrelated senses have values much closer to 0.

Navigli (2006) proposed an automatic approach for mapping WordNet senses to the coarse grained sense distinctions of the Oxford Dictionary of English (ODE). $$$$$ The reliability of our data set is substantiated by a quantitative assessment: 548 WordNet senses of 60 words were mapped to ODE entries by both annotators, with a pairwise mapping agreement of 92.7%.
Navigli (2006) proposed an automatic approach for mapping WordNet senses to the coarse grained sense distinctions of the Oxford Dictionary of English (ODE). $$$$$ As the semantic method outperformed the lexical overlap in the evaluations of previous Section, we decided to acquire a clustering on the entire WordNet sense inventory using this approach.
Navigli (2006) proposed an automatic approach for mapping WordNet senses to the coarse grained sense distinctions of the Oxford Dictionary of English (ODE). $$$$$ Compared to our approach, most of these methods do not evaluate the clustering produced with respect to a gold-standard clustering.

The classifier also made use of resources such as topic signatures data (Agirre and de Lacalle, 2004), the WordNet domain dataset (Magnini and Cavaglia`, 2000), and the mappings of WordNet senses to ODE senses produced by Navigli (2006). $$$$$ In this paper, we present a method for reducing the granularity of the WordNet sense inventory based on the mapping to a manually crafted dictionary encoding sense hierarchies, namely the Oxford Dictionary of English.
The classifier also made use of resources such as topic signatures data (Agirre and de Lacalle, 2004), the WordNet domain dataset (Magnini and Cavaglia`, 2000), and the mappings of WordNet senses to ODE senses produced by Navigli (2006). $$$$$ Also, most of the present research and standard data sets focus on WordNet.
The classifier also made use of resources such as topic signatures data (Agirre and de Lacalle, 2004), the WordNet domain dataset (Magnini and Cavaglia`, 2000), and the mappings of WordNet senses to ODE senses produced by Navigli (2006). $$$$$ While we are not against this possibility, there are problems that cannot be solved at present: the ODE does not encode semantic relations and is not freely available.

In addition, we show in Table 7 the F-score results provided by Snow et al (2007) for their SVM-based system and for the mapping-based approach of Navigli (2006), denoted by ODE. $$$$$ Also, the ODE provides a sense (ginger root) which is not taken into account in WordNet.
In addition, we show in Table 7 the F-score results provided by Snow et al (2007) for their SVM-based system and for the mapping-based approach of Navigli (2006), denoted by ODE. $$$$$ Interestingly, Ng et al. (1999) show that, when a coarse-grained sense inventory is adopted, the increase in interannotator agreement is much higher than the reduction of the polysemy degree.
In addition, we show in Table 7 the F-score results provided by Snow et al (2007) for their SVM-based system and for the mapping-based approach of Navigli (2006), denoted by ODE. $$$$$ The reliability of our data set is substantiated by a quantitative assessment: 548 WordNet senses of 60 words were mapped to ODE entries by both annotators, with a pairwise mapping agreement of 92.7%.
In addition, we show in Table 7 the F-score results provided by Snow et al (2007) for their SVM-based system and for the mapping-based approach of Navigli (2006), denoted by ODE. $$$$$ We assess the quality of the mapping and the induced clustering, and evaluate the performance of coarse WSD systems in the Senseval-3 English all-words task.

Navigli (2006) has induced clusters by mapping WordNet senses to a more coarse-grained lexical resource. $$$$$ Another approach exploits the (dis)agreements of human annotators to derive coarse-grained sense clusters (Chklovski and Mihalcea, 2003), where sense similarity is computed from confusion matrices.
Navigli (2006) has induced clusters by mapping WordNet senses to a more coarse-grained lexical resource. $$$$$ In this paper, we present a method for reducing the granularity of the WordNet sense inventory based on the mapping to a manually crafted dictionary encoding sense hierarchies, namely the Oxford Dictionary of English.
Navigli (2006) has induced clusters by mapping WordNet senses to a more coarse-grained lexical resource. $$$$$ We show that this method is well-founded and accurate with respect to manually-made clusterings (Section 3).

(Navigli, 2006) presents an automatic approach for mapping between sense inventories; here similarities in gloss definition and structured relations between the two sense inventories are exploited in order to map between WordNet senses and distinctions made within the coarser-grained Oxford English Dictionary. $$$$$ Vickrey et al. (2005) and Stokoe (2005)), the present performance of the best ranking WSD systems does not provide a sufficient degree of accuracy to enable real-world, language-aware applications.
(Navigli, 2006) presents an automatic approach for mapping between sense inventories; here similarities in gloss definition and structured relations between the two sense inventories are exploited in order to map between WordNet senses and distinctions made within the coarser-grained Oxford English Dictionary. $$$$$ To this end, we aim to set up an Open Mind-like experiment for the validation of the entire mapping from WordNet to ODE, so that only a minimal error rate would affect the experiments to come.
(Navigli, 2006) presents an automatic approach for mapping between sense inventories; here similarities in gloss definition and structured relations between the two sense inventories are exploited in order to map between WordNet senses and distinctions made within the coarser-grained Oxford English Dictionary. $$$$$ Word Sense Disambiguation (WSD) is undoubtedly one of the hardest tasks in the field of Natural Language Processing.
(Navigli, 2006) presents an automatic approach for mapping between sense inventories; here similarities in gloss definition and structured relations between the two sense inventories are exploited in order to map between WordNet senses and distinctions made within the coarser-grained Oxford English Dictionary. $$$$$ As expected, the automatic clusterings have a lower purity when compared to the Senseval-2 noun grouping as the granularity of the latter is much finer than ODE (entropy is only partially affected by this difference, indicating that we are producing larger groups).

Finally, we use as a feature the mappings produced in (Navigli, 2006) of WordNet senses to Oxford English Dictionary senses. $$$$$ Following these observations, the main question that we tackle in this paper is: can we produce and evaluate coarse-grained sense distinctions and show that they help boost disambiguation on standard test sets?
Finally, we use as a feature the mappings produced in (Navigli, 2006) of WordNet senses to Oxford English Dictionary senses. $$$$$ An evaluation of the heuristics provided leads to a polysemy reduction of 39% and an error rate of 5.6%.
Finally, we use as a feature the mappings produced in (Navigli, 2006) of WordNet senses to Oxford English Dictionary senses. $$$$$ This approach to sense descriptions is general enough to be applicable to any other dictionary with similar characteristics (e.g. the Longman Dictionary of Contemporary English in place of ODE).

In order to evaluate the entire sense-clustered taxonomy, we have employed an evaluation method inspired by Word Sense Disambiguation (this is similar to an evaluation used in Navigli, 2006, however we do not remove monosemous clusters). $$$$$ These figures exclude monosemous senses and derivatives in WordNet.
In order to evaluate the entire sense-clustered taxonomy, we have employed an evaluation method inspired by Word Sense Disambiguation (this is similar to an evaluation used in Navigli, 2006, however we do not remove monosemous clusters). $$$$$ Finally, McCarthy (2006) proposes the use of ranked lists, based on distributionally nearest neighbours, to relate word senses.
In order to evaluate the entire sense-clustered taxonomy, we have employed an evaluation method inspired by Word Sense Disambiguation (this is similar to an evaluation used in Navigli, 2006, however we do not remove monosemous clusters). $$$$$ The WordNet clustering induced by the manual mapping was 49.85% of the original size and the average degree of polysemy decreased from 6.65 to 3.32.
In order to evaluate the entire sense-clustered taxonomy, we have employed an evaluation method inspired by Word Sense Disambiguation (this is similar to an evaluation used in Navigli, 2006, however we do not remove monosemous clusters). $$$$$ Collocations are acquired from existing resources (like the Oxford Collocations, the Longman Language Activator, collocation web sites, etc.).

To tackle the granularity issue, we produced a coarser-grained version of the WordNet sense inventory based on the procedure described by Navigli (2006). $$$$$ Peters et al. (1998) exploit specific patterns in the WordNet hierarchy (e.g. sisters, autohyponymy, twins, etc.) to group word senses.
To tackle the granularity issue, we produced a coarser-grained version of the WordNet sense inventory based on the procedure described by Navigli (2006). $$$$$ Second, we evaluate the performance of WSD systems when using coarse-grained sense inventories (Section 4).
To tackle the granularity issue, we produced a coarser-grained version of the WordNet sense inventory based on the procedure described by Navigli (2006). $$$$$ Agirre and Lopez (2003) analyze a set of methods to cluster WordNet senses based on the use of confusion matrices from the results of WSD systems, translation equivalences, and topic signatures (word co-occurrences extracted from the web).
To tackle the granularity issue, we produced a coarser-grained version of the WordNet sense inventory based on the procedure described by Navigli (2006). $$$$$ While we are not against this possibility, there are problems that cannot be solved at present: the ODE does not encode semantic relations and is not freely available.

The data were annotated with coarse-grained senses which were obtained by clustering senses from the Word Net 2.1 sense inventory based on the procedure proposed by Navigli (2006). $$$$$ The purity of a sense group G E c(w) is defined as: i.e., the normalized size of the largest subset of G contained in a single group GË† of the manual clustering.
The data were annotated with coarse-grained senses which were obtained by clustering senses from the Word Net 2.1 sense inventory based on the procedure proposed by Navigli (2006). $$$$$ Unfortunately, the approach is not described in detail and no evaluation is provided.
The data were annotated with coarse-grained senses which were obtained by clustering senses from the Word Net 2.1 sense inventory based on the procedure proposed by Navigli (2006). $$$$$ The WordNet clustering induced by the manual mapping was 49.85% of the original size and the average degree of polysemy decreased from 6.65 to 3.32.
The data were annotated with coarse-grained senses which were obtained by clustering senses from the Word Net 2.1 sense inventory based on the procedure proposed by Navigli (2006). $$$$$ Peters et al. (1998) exploit specific patterns in the WordNet hierarchy (e.g. sisters, autohyponymy, twins, etc.) to group word senses.

 $$$$$ Another approach exploits the (dis)agreements of human annotators to derive coarse-grained sense clusters (Chklovski and Mihalcea, 2003), where sense similarity is computed from confusion matrices.
 $$$$$ We assess the quality of the mapping and the induced clustering, and evaluate the performance of coarse WSD systems in the Senseval-3 English all-words task.
 $$$$$ In this paper, we present a method for reducing the granularity of the WordNet sense inventory based on the mapping to a manually crafted dictionary encoding sense hierarchies, namely the Oxford Dictionary of English.
 $$$$$ Unfortunately, WordNet is a fine-grained resource, encoding sense distinctions that are often difficult to recognize even for human annotators (Edmonds and Kilgariff, 1998).

This clustering was created automatically with the aid of a methodology described in (Navigli, 2006). $$$$$ It seems therefore that the major obstacle to effective WSD is the fine granularity of the WordNet sense inventory, rather than the performance of the best disambiguation systems.

 $$$$$ The increase in recall is mostly due to the fact that different senses belonging to the same cluster now contribute together to the choice of that cluster (rather than individually to the choice of a fine-grained sense).
 $$$$$ In this paper, we present a method for reducing the granularity of the WordNet sense inventory based on the mapping to a manually crafted dictionary encoding sense hierarchies, namely the Oxford Dictionary of English.
 $$$$$ In a future work, we plan to investigate the contribution of coarse disambiguation to such real-world applications.
 $$$$$ The contribution of a single interconnection is given by the reciprocal of its length, calculated as the number of edges connecting its ends.

Automatically creating new alignments is difficult because of word ambiguities, different granularities of senses, or language specific conceptualizations (Navigli, 2006). $$$$$ Excluding monosemous senses, the ODE has an average number of 2.56 senses per word compared to the average polysemy of 3.21 in WordNet on the same words (with peaks for verbs of 2.73 and 3.75 senses, respectively).
Automatically creating new alignments is difficult because of word ambiguities, different granularities of senses, or language specific conceptualizations (Navigli, 2006). $$$$$ Agirre and Lopez (2003) analyze a set of methods to cluster WordNet senses based on the use of confusion matrices from the results of WSD systems, translation equivalences, and topic signatures (word co-occurrences extracted from the web).
Automatically creating new alignments is difficult because of word ambiguities, different granularities of senses, or language specific conceptualizations (Navigli, 2006). $$$$$ We show that this method is well-founded and accurate with respect to manually-made clusterings (Section 3).
Automatically creating new alignments is difficult because of word ambiguities, different granularities of senses, or language specific conceptualizations (Navigli, 2006). $$$$$ To this end, we aim to set up an Open Mind-like experiment for the validation of the entire mapping from WordNet to ODE, so that only a minimal error rate would affect the experiments to come.
