The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ The sampling error can be dealt with (Brent, 1991) but predetermined cutoff percentages still require eye-balling the data.
The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ (Church, 1988) to distinguish between to as an infinitive marker and to as a preposition.
The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ This work was supported in part by National Science Foundation grant DCR-85552543 under a Presidential Young Investigator Award to Professor Robert C. Berwick.
The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ The program judges an open-class word to be a main verb if it is adjacent to a pronoun or proper name that would otherwise lack case.

Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ Ultimately, I expect to provide a large SF dictionary to the NLP community and to train dictionaries for specific corpora.
Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ In that case it might be worthwhile to admit &quot;is V-ing&quot;, where V is known to be a (possibly ambiguous) verb root, as a verb, independent of the Case Filter mechanism.
Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ Ultimately, I expect to provide a large SF dictionary to the NLP community and to train dictionaries for specific corpora.

Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ The grammars for each of these are presented in Figure 1.
Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ In a histogram sorting verbs by their apparent frequency of occurrence with infinitival complements, those that in fact have appeared with purpose adjuncts and not true subcategorized infinitives will be clustered at the low frequencies.
Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ Thanks to Don Hindle, Lila Gleitman, and Jane Grimshaw for useful and encouraging conversations.
Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ The solution is based on the following insights: Rather than take the obvious approach of looking for &quot;V NP to V&quot;, my approach is to wait for clear cases like &quot;V PRONOUN to V&quot;.

Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ These are estimated independently of the error rates for verb detection.
Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ It might be interesting to try building a verb categorization scheme based on Church's mutual information measure, but to the best of our knowledge no such work has been reported.
Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ Thanks to Don Hindle, Lila Gleitman, and Jane Grimshaw for useful and encouraging conversations.
