The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ Unlike our system, Church's approach does not aim to decide whether or not a verb occurs with an infinitival complement â€” example (1) showed that being followed by an infinitive is not the same as taking an infinitival complement.
The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ Thanks to Don Hindle, Lila Gleitman, and Jane Grimshaw for useful and encouraging conversations.
The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ This work was supported in part by National Science Foundation grant DCR-85552543 under a Presidential Young Investigator Award to Professor Robert C. Berwick.
The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English. $$$$$ Such a pronoun or proper name is either the subject or the direct object of the verb.

Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ False positive rates are one to three percent of observations.
Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ Further, they are often incomplete in arbitrary ways.
Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo, 1987)), problems such as verb detection, raised in (Brent, 1991), are negligible. $$$$$ The technique I developed for finding verbs is based on the Case Filter of Rouvret and Vergnaud (1980).

Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ Efficiency of verb detection was assessed by running the SF detection module in the normal mode, where verbs were detected using the Case Filter technique, and then running it again with the Penn Tags substituted for the verb detection module.
Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ The question of sample size leads back to an evaluation of the initial priorities, which favored simplicity, speed, and accuracy, over efficient use of the corpus.
Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective sub categorization information specified both in the field of traditional linguistics and that of computational linguistics. $$$$$ The completeness of the output list increases monotonically with the total number of occurrences of each verb in the corpus.

Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ Verbs are detected by a novel technique based on the Case Filter of Rouvret and Vergnaud (1980).
Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ False positive rates are one to three percent of observations.
Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ Any word ending in &quot;Iy&quot; or belonging to a list of 25 irregular adverbs is ignored for purposes of adjacency.
Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. $$$$$ In addition, they tend not to include rare usages or specialized vocabularies like financial or military jargon.
