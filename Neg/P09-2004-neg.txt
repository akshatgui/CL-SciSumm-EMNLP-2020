The same assumption underlies methods for automatically identifying DRMs (Pitler and Nenkova, 2009). $$$$$ Including pair-wise interaction features between the connective and each syntactic feature (features like connective=alsoRightSibling=SBAR) raised the f-score about 1.5%, to 93.63%.
The same assumption underlies methods for automatically identifying DRMs (Pitler and Nenkova, 2009). $$$$$ These results taken
The same assumption underlies methods for automatically identifying DRMs (Pitler and Nenkova, 2009). $$$$$ Discourse connectives are words or such as and contrary explicitly signal the presence of a discourse relation.

Such semantic information is based on external lists of lexical items and on the output of the add Discourse tagger (Pitler and Nenkova, 2009). $$$$$ For be either a temporal discourse connective or a simply a word meaning “formerly”.
Such semantic information is based on external lists of lexical items and on the output of the add Discourse tagger (Pitler and Nenkova, 2009). $$$$$ For both tasks we report high classification accuracies close to 95%.
Such semantic information is based on external lists of lexical items and on the output of the add Discourse tagger (Pitler and Nenkova, 2009). $$$$$ This feature is especially helpful for disambiguating cases similar to example (1b) above in which the parent of and would be an NP (the noun phrase “blue and green”), which will rarely be the case when and has a discourse function.

The handling of explicit connectives can be split into three tasks (Pitler and Nenkova, 2009). $$$$$ Including syntactic features also helps sense class identification, and we have already attained results at the level of human annotator agreement.
The handling of explicit connectives can be split into three tasks (Pitler and Nenkova, 2009). $$$$$ These results taken
The handling of explicit connectives can be split into three tasks (Pitler and Nenkova, 2009). $$$$$ First, a word can be ambiguous between discourse or non-discourse usage.
The handling of explicit connectives can be split into three tasks (Pitler and Nenkova, 2009). $$$$$ In these cases where the connective itself is not helpful in classifying the sense of the relation, it may be useful to incorporate features that were developed for classifying implicit relations (Sporleder and Lascarides, 2008).

The syntactic features (Syn) are inspired by (Pitler and Nenkova, 2009). $$$$$ The only comprehensive study of discourse vs. non-discourse usage in written text1 was done in the context of developing a complete discourse parser for unrestricted text using surface features (Marcu, 2000).
The syntactic features (Syn) are inspired by (Pitler and Nenkova, 2009). $$$$$ Prosodic and acoustic features are the most powerful indicators of discourse vs. non-discourse usage in that genre (Hirschberg and Litman, 1993; Gravano et al., 2007) instance can signal either a temporal or a causal relation as shown in the following examples from Miltsakaki et al. (2005): (3a) There have been more than 100 mergers and acquisitions within the European paper industry since the most recent wave of friendly takeovers was completed in the U.S. in 1986.
The syntactic features (Syn) are inspired by (Pitler and Nenkova, 2009). $$$$$ These results taken
The syntactic features (Syn) are inspired by (Pitler and Nenkova, 2009). $$$$$ Including pair-wise interaction features between the connective and each syntactic feature (features like connective=alsoRightSibling=SBAR) raised the f-score about 1.5%, to 93.63%.

Models M2-M4 do not rely on gold standard annotation or parsing (in contrast to the models for English in (Pitler and Nenkova, 2009)). $$$$$ We have shown that using a few syntactic features leads to state-of-the-art accuracy for discourse vs. non-discourse usage classification.
Models M2-M4 do not rely on gold standard annotation or parsing (in contrast to the models for English in (Pitler and Nenkova, 2009)). $$$$$ Most prior work on relation sense identification reports results obtained on data consisting of both explicit and implicit relations (Wellner et al., 2006; Soricut and Marcu, 2003).
Models M2-M4 do not rely on gold standard annotation or parsing (in contrast to the models for English in (Pitler and Nenkova, 2009)). $$$$$ These results amount to a 10% absolute improvement over those obtained by Marcu (2000) in his corpus-based approach which achieves an f-score of 84.9%3 for identifying discourse connectives in text.
Models M2-M4 do not rely on gold standard annotation or parsing (in contrast to the models for English in (Pitler and Nenkova, 2009)). $$$$$ We have shown that using a few syntactic features leads to state-of-the-art accuracy for discourse vs. non-discourse usage classification.

Prior work (Pitler and Nenkova, 2009) showed that where explicit markers exist, the class of the relation can be disambiguated with f-scores higher than 90%. Predicting the class of implicit discourse relations, however, is much more difficult. $$$$$ In example (1a), this feature would be “NONE”, while in example (1b), the left sibling of and is “NP”.
Prior work (Pitler and Nenkova, 2009) showed that where explicit markers exist, the class of the relation can be disambiguated with f-scores higher than 90%. Predicting the class of implicit discourse relations, however, is much more difficult. $$$$$ For training and testing, we used explicit discourse connectives annotated in the PDTB as positive examples and occurrences of the same strings in the PDTB texts that were not annotated as explicit connectives as negative examples.
Prior work (Pitler and Nenkova, 2009) showed that where explicit markers exist, the class of the relation can be disambiguated with f-scores higher than 90%. Predicting the class of implicit discourse relations, however, is much more difficult. $$$$$ Consider the example below: and where.
Prior work (Pitler and Nenkova, 2009) showed that where explicit markers exist, the class of the relation can be disambiguated with f-scores higher than 90%. Predicting the class of implicit discourse relations, however, is much more difficult. $$$$$ We have shown that using a few syntactic features leads to state-of-the-art accuracy for discourse vs. non-discourse usage classification.

We identify discourse connectives and their senses (TEMPORAL, COMPARISON, CONTINGENCY or EXPANSION) in each reference segment using the system in Pitler and Nenkova (2009). $$$$$ We have shown that using a few syntactic features leads to state-of-the-art accuracy for discourse vs. non-discourse usage classification.
We identify discourse connectives and their senses (TEMPORAL, COMPARISON, CONTINGENCY or EXPANSION) in each reference segment using the system in Pitler and Nenkova (2009). $$$$$ Including pair-wise interaction features between the connective and each syntactic feature (features like connective=alsoRightSibling=SBAR) raised the f-score about 1.5%, to 93.63%.
We identify discourse connectives and their senses (TEMPORAL, COMPARISON, CONTINGENCY or EXPANSION) in each reference segment using the system in Pitler and Nenkova (2009). $$$$$ First, a word can be ambiguous between discourse or non-discourse usage.

The state of-the-art for recognizing all types of explicit connectives in English is therefore already high, at 97% accuracy for disambiguating discourse vs. non discourse uses (Lin et al, 2010) and 94% for disambiguating the four main senses from the PDTB hierarchy (Pitler and Nenkova, 2009). $$$$$ Note that having no left sibling implies that the connective is the first substring inside its Parent Category.

The sense of the connective feature (F2) extracted from PDTB for the base system, though for the fully automatic one (Ghosh et al, 2011b) it needs the PTB (Penn TreeBank)-style syntactic parse trees as input (Pitler and Nenkova, 2009). $$$$$ Interestingly, using only the syntactic features, ignoring the identity of the connective, is even better, resulting in an f-score of 88.19% and accuracy of 92.25%.
The sense of the connective feature (F2) extracted from PDTB for the base system, though for the fully automatic one (Ghosh et al, 2011b) it needs the PTB (Penn TreeBank)-style syntactic parse trees as input (Pitler and Nenkova, 2009). $$$$$ Error Analysis While Temporal relations are the least frequent of the four senses, making up only 19% of the explicit relations, more than half of the errors involve the Temporal class.
The sense of the connective feature (F2) extracted from PDTB for the base system, though for the fully automatic one (Ghosh et al, 2011b) it needs the PTB (Penn TreeBank)-style syntactic parse trees as input (Pitler and Nenkova, 2009). $$$$$ The results are shown in Table 3.
The sense of the connective feature (F2) extracted from PDTB for the base system, though for the fully automatic one (Ghosh et al, 2011b) it needs the PTB (Penn TreeBank)-style syntactic parse trees as input (Pitler and Nenkova, 2009). $$$$$ Including syntactic features also helps sense class identification, and we have already attained results at the level of human annotator agreement.

The labeling of the four main senses from the PDTB sense hierarchy (temporal, contingency, comparison, expansion) reaches 94% ac curacy (Pitler and Nenkova, 2009) however, the baseline accuracy is already around 85% when using only the connective token as a feature. $$$$$ These results taken
The labeling of the four main senses from the PDTB sense hierarchy (temporal, contingency, comparison, expansion) reaches 94% ac curacy (Pitler and Nenkova, 2009) however, the baseline accuracy is already around 85% when using only the connective token as a feature. $$$$$ There are two types of ambiguity that need to be resolved during discourse processing.
The labeling of the four main senses from the PDTB sense hierarchy (temporal, contingency, comparison, expansion) reaches 94% ac curacy (Pitler and Nenkova, 2009) however, the baseline accuracy is already around 85% when using only the connective token as a feature. $$$$$ Here we report results using a maximum entropy classifier2 using ten-fold cross-validation over sections 2-22.
The labeling of the four main senses from the PDTB sense hierarchy (temporal, contingency, comparison, expansion) reaches 94% ac curacy (Pitler and Nenkova, 2009) however, the baseline accuracy is already around 85% when using only the connective token as a feature. $$$$$ In this paper, we explore the predictive power of syntactic features for both the discourse vs. nondiscourse usage (Section 3) and discourse relation sense (Section 4) prediction tasks for explicit connectives in written text.

The state of the art for recognizing explicit connectives in English is therefore already high, at a level of 94% for disambiguating the four main senses on the first level of the PDTB sense hierarchy (Pitler and Nenkova, 2009). $$$$$ For example since is often a Temporal relation, but also often indicates Contingency.
The state of the art for recognizing explicit connectives in English is therefore already high, at a level of 94% for disambiguating the four main senses on the first level of the PDTB sense hierarchy (Pitler and Nenkova, 2009). $$$$$ Discourse connectives are words or such as and contrary explicitly signal the presence of a discourse relation.
The state of the art for recognizing explicit connectives in English is therefore already high, at a level of 94% for disambiguating the four main senses on the first level of the PDTB sense hierarchy (Pitler and Nenkova, 2009). $$$$$ Including syntactic features also helps sense class identification, and we have already attained results at the level of human annotator agreement.
The state of the art for recognizing explicit connectives in English is therefore already high, at a level of 94% for disambiguating the four main senses on the first level of the PDTB sense hierarchy (Pitler and Nenkova, 2009). $$$$$ In sentence (1a), and is a discourse connective between the two clauses linked by an elaboration/expansion relation; in sentence (1b), the occurrence of and is non-discourse.

For instance, Pitler and Nenkova (2009) report an accuracy of 85.86% for correctly classified connectives (with the 4 main senses), when using the connective token as the only feature. $$$$$ For example since is often a Temporal relation, but also often indicates Contingency.
For instance, Pitler and Nenkova (2009) report an accuracy of 85.86% for correctly classified connectives (with the 4 main senses), when using the connective token as the only feature. $$$$$ Secondly, some connectives are ambiguous in terms of the they mark.
For instance, Pitler and Nenkova (2009) report an accuracy of 85.86% for correctly classified connectives (with the 4 main senses), when using the connective token as the only feature. $$$$$ Including syntactic features also helps sense class identification, and we have already attained results at the level of human annotator agreement.
For instance, Pitler and Nenkova (2009) report an accuracy of 85.86% for correctly classified connectives (with the 4 main senses), when using the connective token as the only feature. $$$$$ Most prior work on relation sense identification reports results obtained on data consisting of both explicit and implicit relations (Wellner et al., 2006; Soricut and Marcu, 2003).
