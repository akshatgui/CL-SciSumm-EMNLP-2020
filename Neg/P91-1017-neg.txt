 $$$$$ In order to decide which alternative is the most probable, we count the frequencies of all the alternative target relations in very large corpora.
 $$$$$ To illustrate the selection algorithm, we give the details for example (6).
 $$$$$ Thus, they are doomed to fail when disambiguation can rely only on deep understanding of the text and no other surface cues are available.

It is well known that two languages are more informative than one (Dagan et al, 1991). $$$$$ Using a naive approach of choosing the most frequent word yields (3) *That issue prevented the two countries from closing a peace contract.
It is well known that two languages are more informative than one (Dagan et al, 1991). $$$$$ An experiment was conducted to test the performance of the statistical model in translation from Hebrew and German to English.
It is well known that two languages are more informative than one (Dagan et al, 1991). $$$$$ The model was evaluated using two sets of Hebrew and German examples and was found to be very useful for disambiguation.

However, bilingual parallel corpora have mostly been used for tasks related to word sense disambiguation such as target word selection (Dagan et al, 1991) and separation of senses (Dyvik, 1998). $$$$$ The source language sentences are considered as a noisy source for target language sentences, and our task is to devise a target language model that prefers the most reasonable translation.
However, bilingual parallel corpora have mostly been used for tasks related to word sense disambiguation such as target word selection (Dagan et al, 1991) and separation of senses (Dyvik, 1998). $$$$$ We approximate the variance by the delta method (e.g.
However, bilingual parallel corpora have mostly been used for tasks related to word sense disambiguation such as target word selection (Dagan et al, 1991) and separation of senses (Dyvik, 1998). $$$$$ Moreover, such methods fail to reflect word usages.
However, bilingual parallel corpora have mostly been used for tasks related to word sense disambiguation such as target word selection (Dagan et al, 1991) and separation of senses (Dyvik, 1998). $$$$$ In sentences with several relations, we consider the best two alternatives for each relation, and take the relation for which Ba is largest.

For example, Brown et al (1991) and Gale et al (1992a, 1993) used the parallel, aligned Hansard Corpus of Canadian Parhamentary debates for WSD, and Dagan et al (1991) and Dagan and Ital (1994) used monolingual corpora of Hebrew and German and a bilingual dictionary. $$$$$ As explained before, such constraints cannot be acquired automatically and therefore are usually limited in their coverage.
For example, Brown et al (1991) and Gale et al (1992a, 1993) used the parallel, aligned Hansard Corpus of Canadian Parhamentary debates for WSD, and Dagan et al (1991) and Dagan and Ital (1994) used monolingual corpora of Hebrew and German and a bilingual dictionary. $$$$$ As explained before, this should be done using a source language parser, and then mapping the source relations to the target relations.
