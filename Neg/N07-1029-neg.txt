This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ Generalized linear models (GLMs) have been applied for confidence estimation in speech recognition (Siu and Gish, 1999).
This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ Note that each phrase in one hypothesis is similar to another hypothesis at only one similarity level, so one hypothesis can contribute to at only one similarity level.
This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ The logit model, which models the log odds of an event as a linear function of the features, can be used in confidence estimation.
This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ Minimum Bayes Risk decoding under translation edit rate was used to select the skeleton.

The improved system combination method was compared to a simple confusion network decoding without system weights and the method proposed in (Rosti et al, 2007) on the Arabic to English and Chinese to English NIST MT05 tasks. $$$$$ All systems were tuned on NIST MT02 evaluation sets with four references.
The improved system combination method was compared to a simple confusion network decoding without system weights and the method proposed in (Rosti et al, 2007) on the Arabic to English and Chinese to English NIST MT05 tasks. $$$$$ This paper describes three different approaches to MT system combination.
The improved system combination method was compared to a simple confusion network decoding without system weights and the method proposed in (Rosti et al, 2007) on the Arabic to English and Chinese to English NIST MT05 tasks. $$$$$ However, this is specific to log-linear models and cannot be easily extended for more complicated functions.
The improved system combination method was compared to a simple confusion network decoding without system weights and the method proposed in (Rosti et al, 2007) on the Arabic to English and Chinese to English NIST MT05 tasks. $$$$$ HTER is computed as the minimum translation edit rate (TER) between a system output and a targeted reference which preserves the meaning and fluency of the sentence (Snover et al., 2006).

Compared to the baseline from (Rosti et al, 2007), the new method improves the BLEU scores significantly. $$$$$ The agreement is measured by four levels of similarity: represents the similarity of a given phrase to all the hypotheses in the system at the similarity level .
Compared to the baseline from (Rosti et al, 2007), the new method improves the BLEU scores significantly. $$$$$ However, this is specific to log-linear models and cannot be easily extended for more complicated functions.
Compared to the baseline from (Rosti et al, 2007), the new method improves the BLEU scores significantly. $$$$$ The word-level combination provides the most robust gains but the best results on the development test sets (NIST MT05 and the newsgroup portion of GALE 2006 dry-run) were achieved by combining all three methods.

The subnetworks in the latter approach may be weighted by prior probabilities estimated from the alignment statistics (Rosti et al, 2007a). $$$$$ The number of tunable combination weights, in addition to normal decoder weights, is where is the number of systems and is the number of similarity levels; i.e., free system weights, similarity score weights and two free interpolation weights.
The subnetworks in the latter approach may be weighted by prior probabilities estimated from the alignment statistics (Rosti et al, 2007a). $$$$$ A standard phrasal decoder with the new phrase table was used to produce the final combination output.
The subnetworks in the latter approach may be weighted by prior probabilities estimated from the alignment statistics (Rosti et al, 2007a). $$$$$ The authors would like to thank ISI and University of Edinburgh for sharing their MT system outputs.
The subnetworks in the latter approach may be weighted by prior probabilities estimated from the alignment statistics (Rosti et al, 2007a). $$$$$ Section 2 describes the evaluation metrics and a generic discriminative optimization technique used in tuning of the various system combination weights.

Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al, 2007a; Huang and Papineni, 2007). $$$$$ HR0011-06-C-0022 under the GALE program (approved for public release, distribution unlimited).
Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al, 2007a; Huang and Papineni, 2007). $$$$$ Second, system weights were trained for combining six systems (TER/BLEU 6 in the tables).
Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al, 2007a; Huang and Papineni, 2007). $$$$$ Combined with the latest advances in phrase-based translation systems, it has become more attractive to take advantage of the various outputs in forming consensus translations (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006).

Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al 2007). $$$$$ HR0011-06-C-0022 under the GALE program (approved for public release, distribution unlimited).
Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al 2007). $$$$$ The weights through are constrained to sum to one; i.e., there are three free parameters.
Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al 2007). $$$$$ Internal HTER experiments showed that BLEU 8 yielded lower scores after post-editing even though no weights 6 had lower automatic TER score.

Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ Experimental results on Arabic and Chinese to English newswire and newsgroup test data are presented in Section 6.
Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ This paper is organized as follows.
Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ Compared to the best possible skeleton decision – according to an oracle experiment – further gains might be obtained by using better decision approach.
Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ The word-level combination is based on consensus network decoding.

Similar to (Rosti et al, 2007a), each word in the hypothesis is assigned with a rank-based score of 1/(1+r), where r is the rank of the hypothesis. $$$$$ Note that each phrase in one hypothesis is similar to another hypothesis at only one similarity level, so one hypothesis can contribute to at only one similarity level.
Similar to (Rosti et al, 2007a), each word in the hypothesis is assigned with a rank-based score of 1/(1+r), where r is the rank of the hypothesis. $$$$$ Experimental results on Arabic and Chinese to English newswire and newsgroup test data are presented in Section 6.
Similar to (Rosti et al, 2007a), each word in the hypothesis is assigned with a rank-based score of 1/(1+r), where r is the rank of the hypothesis. $$$$$ Currently there are several approaches to machine translation (MT) based on different paradigms; e.g., phrasal, hierarchical and syntax-based.

The system used in this paper is a variant of the one proposed in Rosti et al (2007a), which we now describe in detail. $$$$$ The combination yields slight gains on the tuning set.
The system used in this paper is a variant of the one proposed in Rosti et al (2007a), which we now describe in detail. $$$$$ The decoder features are: a trigram language model score, number of target phrases, number of target words, phrase distortion, phrase distortion computed over the original translations and phrase translation confidences estimated in Section 4.1.
The system used in this paper is a variant of the one proposed in Rosti et al (2007a), which we now describe in detail. $$$$$ Minimum Bayes Risk decoding under translation edit rate was used to select the skeleton.
The system used in this paper is a variant of the one proposed in Rosti et al (2007a), which we now describe in detail. $$$$$ Basically, if there is a similar phrase in a given hypothesis in the system to the phrase , the similarity score is increased by .

Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. $$$$$ This paper describes three different approaches to MT system combination.
Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. $$$$$ These three approaches yield similar translation accuracy despite using fairly different levels of linguistic knowledge.
Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. $$$$$ Finally, all six system outputs as well as the sentence and phrase-level combination outputs were combined with system weights (TER/BLEU 8 in the tables).

We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ Currently there are several approaches to machine translation (MT) based on different paradigms; e.g., phrasal, hierarchical and syntax-based.
We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ The agreement is measured by four levels of similarity: represents the similarity of a given phrase to all the hypotheses in the system at the similarity level .
We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ To allow a variety of outputs with different degrees of confidence to be combined, system weights may be used.
We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ All systems were tuned on NIST MT02 evaluation sets with four references.

 $$$$$ However, this is specific to log-linear models and cannot be easily extended for more complicated functions.
 $$$$$ In the experiments, feature scaling factors were estimated from the tuning data to limit the feature values between .
 $$$$$ The NIST BLEU-4 is a variant of BLEU (Papineni et al., 2002) and is computed as where is the precision of -grams in the hypothesis given the reference and is a brevity penalty.
 $$$$$ The optimization starts at a random initial point in the -dimensional parameter space, first searching through an initial set of basis vectors.

The current state-of-the-art is confusion-network-based MT system combination as described by Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). $$$$$ The same scaling factors have to be applied to the features obtained from the test data.
The current state-of-the-art is confusion-network-based MT system combination as described by Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). $$$$$ The links in this lattice represent the alternative words (including nulls) at the corresponding position in the string.

Bangalore et al (2001) used a multiple string matching algorithm based on Levenshtein edit distance, and later Sim et al (2007) and Rosti et al (2007) extended it to a TER-based method for hypothesis alignment. $$$$$ In the experiments, feature scaling factors were estimated from the tuning data to limit the feature values between .
Bangalore et al (2001) used a multiple string matching algorithm based on Levenshtein edit distance, and later Sim et al (2007) and Rosti et al (2007) extended it to a TER-based method for hypothesis alignment. $$$$$ To prevent overflow in exponentiating the summation in Equation 3, the features have to be scaled.
Bangalore et al (2001) used a multiple string matching algorithm based on Levenshtein edit distance, and later Sim et al (2007) and Rosti et al (2007) extended it to a TER-based method for hypothesis alignment. $$$$$ The word-level combination yields about 2.0%-3.0% gain in TER and 2.0%-4.0% gain in BLEU on the tuning sets.

Similar to (Rosti et al, 2007), each word in the confusion network is associated with a word posterior probability. $$$$$ This work was supported by DARPA/IPTO Contract No.
Similar to (Rosti et al, 2007), each word in the confusion network is associated with a word posterior probability. $$$$$ However, machine translation outputs do not have this constraint as the word order may be different between the source and target languages.

Various techniques include hypothesis selection from different systems using sentence-level scores, re-decoding source sentences using phrases that are used by individual systems (Rosti et al., 2007a; Huang and Papineni, 2007) and word-based combination techniques using confusion networks (Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007b). $$$$$ The tuning uses -best lists of hypotheses with various feature scores.
Various techniques include hypothesis selection from different systems using sentence-level scores, re-decoding source sentences using phrases that are used by individual systems (Rosti et al., 2007a; Huang and Papineni, 2007) and word-based combination techniques using confusion networks (Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007b). $$$$$ The confidence of the phrase table entry is increased if several systems agree on the target words.
Various techniques include hypothesis selection from different systems using sentence-level scores, re-decoding source sentences using phrases that are used by individual systems (Rosti et al., 2007a; Huang and Papineni, 2007) and word-based combination techniques using confusion networks (Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007b). $$$$$ The agreement is measured by four levels of similarity: represents the similarity of a given phrase to all the hypotheses in the system at the similarity level .
Various techniques include hypothesis selection from different systems using sentence-level scores, re-decoding source sentences using phrases that are used by individual systems (Rosti et al., 2007a; Huang and Papineni, 2007) and word-based combination techniques using confusion networks (Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007b). $$$$$ Basically, if there is a similar phrase in a given hypothesis in the system to the phrase , the similarity score is increased by .

Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ However, machine translation outputs do not have this constraint as the word order may be different between the source and target languages.
Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ This work was supported by DARPA/IPTO Contract No.

For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b). $$$$$ The handling of the alignments from non-phrasal decoders may not be optimal, though.
For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b). $$$$$ This paper has provided evidence that outputs from six very different MT systems, tuned for two different evaluation metrics, may be combined to yield better outputs in terms of different evaluation metrics.
For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b). $$$$$ The word-level combination provides the most robust gains but the best results on the development test sets (NIST MT05 and the newsgroup portion of GALE 2006 dry-run) were achieved by combining all three methods.

Rosti et al (2007) look at sentence-level combinations (as well as word and phrase-level), using reranking of n-best lists and confidence scores derived from generalised linear models with probabilistic features from n-best lists. $$$$$ The 6-way combination weights were tuned on merged NIST MT03 and MT04 evaluation sets and the 8-way combination weights were tuned only on NIST MT04 since the sentence and phraselevel combination methods were already tuned on NIST MT03.
Rosti et al (2007) look at sentence-level combinations (as well as word and phrase-level), using reranking of n-best lists and confidence scores derived from generalised linear models with probabilistic features from n-best lists. $$$$$ The total confidence score of hypothesis is obtained from the system confidences as where is the number of systems generating the hypothesis (i.e., the number of non-zero for ) and is the number of systems.
Rosti et al (2007) look at sentence-level combinations (as well as word and phrase-level), using reranking of n-best lists and confidence scores derived from generalised linear models with probabilistic features from n-best lists. $$$$$ Each aligned word is assigned a score relative to the votes or word confidence scores (Fiscus, 1997; Mangu et al., 2000) derived from the hypotheses.

A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ This method does not generate new hypotheses – unlike the phrase and word-level methods.
A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ To prevent overflow in exponentiating the summation in Equation 3, the features have to be scaled.
A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ The availability of such a variety of systems has led to a growing interest toward finding better translations by combining outputs from multiple systems.
A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ On Chinese, the sentence-level combination yields higher BLEU scores than the phrase-level combination.
