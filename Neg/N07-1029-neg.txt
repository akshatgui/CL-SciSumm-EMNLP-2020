This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ The confidence of the phrase table entry is increased if several systems agree on the target words.
This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ In this paper, the minimum average TER score of one hypothesis against all other hypotheses was used as follows This may be viewed as the MBR hypothesis under TER given uniform target sentence posterior distribution (Sim et al., 2007).
This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ Various other features may be explored in this framework although the tuning may be limited by the chosen optimization method in the higher dimensional parameter space.
This work was extended in (Rosti et al, 2007) by introducing system weights for word confidences. $$$$$ A confusion network may be represented as a standard word lattice with all paths traveling via all nodes.

The improved system combination method was compared to a simple confusion network decoding without system weights and the method proposed in (Rosti et al, 2007) on the Arabic to English and Chinese to English NIST MT05 tasks. $$$$$ Each aligned word is assigned a score relative to the votes or word confidence scores (Fiscus, 1997; Mangu et al., 2000) derived from the hypotheses.
The improved system combination method was compared to a simple confusion network decoding without system weights and the method proposed in (Rosti et al, 2007) on the Arabic to English and Chinese to English NIST MT05 tasks. $$$$$ The word-level combination provides the most robust gains but the best results on the development test sets (NIST MT05 and the newsgroup portion of GALE 2006 dry-run) were achieved by combining all three methods.
The improved system combination method was compared to a simple confusion network decoding without system weights and the method proposed in (Rosti et al, 2007) on the Arabic to English and Chinese to English NIST MT05 tasks. $$$$$ In the case of multiple references, the edits are counted against all references, is the average number of words in the reference translations and the final TER is computed using the minimum number of edits.

Compared to the baseline from (Rosti et al, 2007), the new method improves the BLEU scores significantly. $$$$$ On the tuning sets, both methods yield about 0.5%1.0% gain in TER and BLEU.
Compared to the baseline from (Rosti et al, 2007), the new method improves the BLEU scores significantly. $$$$$ The phrase-level combination tuning can be summarized as follows: Testing the phrase-level combination is performed by following steps 1 through 4.
Compared to the baseline from (Rosti et al, 2007), the new method improves the BLEU scores significantly. $$$$$ The phrase-level combination yields fairly good gains on the tuning sets.
Compared to the baseline from (Rosti et al, 2007), the new method improves the BLEU scores significantly. $$$$$ The feature scores may be combined with tunable weights forming an arbitrary scoring function.

The subnetworks in the latter approach may be weighted by prior probabilities estimated from the alignment statistics (Rosti et al, 2007a). $$$$$ The skeleton determines the general word order of the combined hypothesis.
The subnetworks in the latter approach may be weighted by prior probabilities estimated from the alignment statistics (Rosti et al, 2007a). $$$$$ The features used in this work were: If the system did not generate the hypothesis , the confidence is set to zero.
The subnetworks in the latter approach may be weighted by prior probabilities estimated from the alignment statistics (Rosti et al, 2007a). $$$$$ The word-level combination yields about 2.0%-3.0% gain in TER and 2.0%-4.0% gain in BLEU on the tuning sets.

Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al, 2007a; Huang and Papineni, 2007). $$$$$ Internal HTER experiments showed that BLEU 8 yielded lower scores after post-editing even though no weights 6 had lower automatic TER score.
Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al, 2007a; Huang and Papineni, 2007). $$$$$ In machine translation, aligning hypotheses is more complicated compared to speech recognition since the target words do not necessarily appear in the same order.
Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al, 2007a; Huang and Papineni, 2007). $$$$$ All combination methods use weights which may be tuned using Powellâ€™s method (Brent, 1973) on -best lists.
Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al, 2007a; Huang and Papineni, 2007). $$$$$ As usual, the phrasal decoder can generate -best lists which were used successfully in the word-level combination method as new system outputs.

Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al 2007). $$$$$ The first combination method is based on re-ranking a merged -best list.
Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al 2007). $$$$$ In the case of multiple references, the edits are counted against all references, is the average number of words in the reference translations and the final TER is computed using the minimum number of edits.
Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al 2007). $$$$$ However, machine translation outputs do not have this constraint as the word order may be different between the source and target languages.

Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ The optimization starts at a random initial point in the -dimensional parameter space, first searching through an initial set of basis vectors.
Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ Both sentence and phrase-level combination methods can generate best lists which may also be used as new system outputs in the word-level combination.
Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ The phrase-level combination is based on extracting sentence-specific phrase translation tables from system outputs with alignments to source and running a phrasal decoder with this new translation table.
Sim et al (2007), Rosti et al (2007a), and Rosti et al (2007b) used minimum Translation Error Rate (TER) (Snover et al, 2006) alignment to build the confusion network. $$$$$ Finally, all six system outputs as well as the sentence and phrase-level combination outputs were combined with system weights (TER/BLEU 8 in the tables).

Similar to (Rosti et al, 2007a), each word in the hypothesis is assigned with a rank-based score of 1/(1+r), where r is the rank of the hypothesis. $$$$$ Translation edit rate (TER) (Snover et al., 2006) is used to align the hypotheses and minimum Bayes risk decoding under TER (Sim et al., 2007) is used to select the alignment hypothesis.
Similar to (Rosti et al, 2007a), each word in the hypothesis is assigned with a rank-based score of 1/(1+r), where r is the rank of the hypothesis. $$$$$ The phrase-level combination is based on extracting sentence-specific phrase translation tables from system outputs with alignments to source and running a phrasal decoder with this new translation table.
Similar to (Rosti et al, 2007a), each word in the hypothesis is assigned with a rank-based score of 1/(1+r), where r is the rank of the hypothesis. $$$$$ This paper describes three different approaches to MT system combination.

The system used in this paper is a variant of the one proposed in Rosti et al (2007a), which we now describe in detail. $$$$$ First, simple confusion network decoding with six systems without system weights was performed (no weights 6 in the tables).
The system used in this paper is a variant of the one proposed in Rosti et al (2007a), which we now describe in detail. $$$$$ As discussed in Section 2, the system combination tuning metric was chosen so that gains were observed in both TER and BLEU on development test sets.
The system used in this paper is a variant of the one proposed in Rosti et al (2007a), which we now describe in detail. $$$$$ For example, hierarchical (Chiang, 2005) and syntax-based (Galley et al., 2006) systems have recently improved in both accuracy and scalability.

Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. $$$$$ The authors would like to thank ISI and University of Edinburgh for sharing their MT system outputs.
Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. $$$$$ If the alignments are not available, they can be automatically generated; e.g., using GIZA++ (Och and Ney, 2003).
Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. $$$$$ The handling of the alignments from non-phrasal decoders may not be optimal, though.
Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. $$$$$ The number of words is commonly used in LM rescoring to balance the LM scores between hypotheses of different lengths.

We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ The 6-way combination weights were tuned on merged NIST MT03 and MT04 evaluation sets and the 8-way combination weights were tuned only on NIST MT04 since the sentence and phraselevel combination methods were already tuned on NIST MT03.
We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ All parameters may be tuned using Powellâ€™s method on -best lists as described in Section 2.
We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ The word-level combination yields about 2.0%-3.0% gain in TER and 2.0%-4.0% gain in BLEU on the tuning sets.
We also implemented the word-level system combination (Rosti et al, 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). $$$$$ The number of tunable combination weights, in addition to normal decoder weights, is where is the number of systems and is the number of similarity levels; i.e., free system weights, similarity score weights and two free interpolation weights.

 $$$$$ This work was supported by DARPA/IPTO Contract No.
 $$$$$ The phrase-level combination was based on deriving a new phrase translation table from the alignments to source provided in all system outputs.
 $$$$$ Minimum Bayes Risk decoding under translation edit rate was used to select the skeleton.
 $$$$$ Re-rank the -best list using the new weights.

The current state-of-the-art is confusion-network-based MT system combination as described by Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). $$$$$ The alignment of speech recognition outputs is fairly straightforward due to the strict constraint in word order.
The current state-of-the-art is confusion-network-based MT system combination as described by Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). $$$$$ LM re-scoring might alleviate this problem.
The current state-of-the-art is confusion-network-based MT system combination as described by Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). $$$$$ The tuning uses -best lists of hypotheses with various feature scores.
The current state-of-the-art is confusion-network-based MT system combination as described by Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). $$$$$ The outputs were evaluated on both TER and BLEU.

Bangalore et al (2001) used a multiple string matching algorithm based on Levenshtein edit distance, and later Sim et al (2007) and Rosti et al (2007) extended it to a TER-based method for hypothesis alignment. $$$$$ The feature scores may be combined with tunable weights forming an arbitrary scoring function.
Bangalore et al (2001) used a multiple string matching algorithm based on Levenshtein edit distance, and later Sim et al (2007) and Rosti et al (2007) extended it to a TER-based method for hypothesis alignment. $$$$$ The features used in this work were: If the system did not generate the hypothesis , the confidence is set to zero.
Bangalore et al (2001) used a multiple string matching algorithm based on Levenshtein edit distance, and later Sim et al (2007) and Rosti et al (2007) extended it to a TER-based method for hypothesis alignment. $$$$$ When combining several systems based on different translation paradigms and feature sets, the system scores may not be comparable.
Bangalore et al (2001) used a multiple string matching algorithm based on Levenshtein edit distance, and later Sim et al (2007) and Rosti et al (2007) extended it to a TER-based method for hypothesis alignment. $$$$$ The combination yields slight gains on the tuning set.

Similar to (Rosti et al, 2007), each word in the confusion network is associated with a word posterior probability. $$$$$ This paper has provided evidence that outputs from six very different MT systems, tuned for two different evaluation metrics, may be combined to yield better outputs in terms of different evaluation metrics.
Similar to (Rosti et al, 2007), each word in the confusion network is associated with a word posterior probability. $$$$$ The availability of such a variety of systems has led to a growing interest toward finding better translations by combining outputs from multiple systems.

Various techniques include hypothesis selection from different systems using sentence-level scores, re-decoding source sentences using phrases that are used by individual systems (Rosti et al., 2007a; Huang and Papineni, 2007) and word-based combination techniques using confusion networks (Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007b). $$$$$ The optimization starts at a random initial point in the -dimensional parameter space, first searching through an initial set of basis vectors.
Various techniques include hypothesis selection from different systems using sentence-level scores, re-decoding source sentences using phrases that are used by individual systems (Rosti et al., 2007a; Huang and Papineni, 2007) and word-based combination techniques using confusion networks (Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007b). $$$$$ One of the most successful approaches is consensus network decoding (Mangu et al., 2000) which assumes that the confidence of a word in a certain position is based on the sum of confidences from each system output having the word in that position.
Various techniques include hypothesis selection from different systems using sentence-level scores, re-decoding source sentences using phrases that are used by individual systems (Rosti et al., 2007a; Huang and Papineni, 2007) and word-based combination techniques using confusion networks (Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007b). $$$$$ The logit model, which models the log odds of an event as a linear function of the features, can be used in confidence estimation.

Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ The authors would like to thank ISI and University of Edinburgh for sharing their MT system outputs.
Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ If the alignments are not available, they can be automatically generated; e.g., using GIZA++ (Och and Ney, 2003).
Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ HR0011-06-C-0022 under the GALE program (approved for public release, distribution unlimited).
Rosti et al (2007a) collect source-to-target correspondences from the input systems, create a new translation option table using only these phrases, and re-decode the source sentence to generate better translations. $$$$$ Systems A and B were tuned to minimize TER, the other systems were tuned to maximize BLEU.

For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b). $$$$$ All systems were tuned on NIST MT02 evaluation sets with four references.
For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b). $$$$$ Merge individual -best lists to form a large -best list with unique hypotheses; the system weights are constrained to sum to one.
For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b). $$$$$ The phrasal decoder used in the phrase-level combination is based on standard beam search (Koehn, 2004).
For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b). $$$$$ LM re-scoring might alleviate this problem.

Rosti et al (2007) look at sentence-level combinations (as well as word and phrase-level), using reranking of n-best lists and confidence scores derived from generalised linear models with probabilistic features from n-best lists. $$$$$ Even though the underlying modeling techniques are similar, many systems produce very different outputs with approximately the same accuracy.
Rosti et al (2007) look at sentence-level combinations (as well as word and phrase-level), using reranking of n-best lists and confidence scores derived from generalised linear models with probabilistic features from n-best lists. $$$$$ The TER of a translation is computed as where is the total number of words in the reference translation .
Rosti et al (2007) look at sentence-level combinations (as well as word and phrase-level), using reranking of n-best lists and confidence scores derived from generalised linear models with probabilistic features from n-best lists. $$$$$ Three systems were phrase-based (A, C and E), two hierarchical (B and D) and one syntax-based (F).
Rosti et al (2007) look at sentence-level combinations (as well as word and phrase-level), using reranking of n-best lists and confidence scores derived from generalised linear models with probabilistic features from n-best lists. $$$$$ NIST MT05 comprising only newswire data (1056 Arabic and 1082 Chinese sentences) with four reference translations and the newsgroup portion of the GALE 2006 dry-run (203 Arabic and 126 Chinese sentences) with one reference translation were used as the test sets.

A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ The scaling factors may be tuned to optimize the evaluation metric in the same fashion as the logit model weights in Section 3.1.
A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ However, nese NIST MT05 (newswire) and the newsgroups portion of the GALE 2006 dry-run data. minimizing TER on Chinese resulted in significantly lower BLEU.
A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ This work was supported by DARPA/IPTO Contract No.
A new search space is constructed from these backbone-aligned outputs, and then a voting procedure or feature-based model predicts a final consensus translation (Rosti et al, 2007). $$$$$ Sentence, phrase and word-level system combination methods are presented in Sections 3, 4 and 5.
