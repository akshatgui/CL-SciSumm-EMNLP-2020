Johnson (2002) proposes an algorithm that is able to find long-distance dependencies, as a post processing step, after parsing. $$$$$ Precision, recall and f-score are defined for these augmented representations as before.
Johnson (2002) proposes an algorithm that is able to find long-distance dependencies, as a post processing step, after parsing. $$$$$ This paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in a goldstandard corpus.
Johnson (2002) proposes an algorithm that is able to find long-distance dependencies, as a post processing step, after parsing. $$$$$ To evaluate co-indexation of empty nodes and their antecedents, we augment the representation of empty nodes as follows.

As our interest lies in trace detection and antecedent recovery, we adopt the evaluation measures introduced by Johnson (2002). $$$$$ We experimented with lexicalizing patterns, but the simple method we tried did not improve results.
As our interest lies in trace detection and antecedent recovery, we adopt the evaluation measures introduced by Johnson (2002). $$$$$ This paper describes a simple patternmatching algorithm for recovering empty nodes and identifying their co-indexed antecedents in phrase structure trees that do not contain this information.
As our interest lies in trace detection and antecedent recovery, we adopt the evaluation measures introduced by Johnson (2002). $$$$$ This paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in a goldstandard corpus.
As our interest lies in trace detection and antecedent recovery, we adopt the evaluation measures introduced by Johnson (2002). $$$$$ Evaluating the algorithm on the output of Charniak’s parser (Charniak, 2000) and the Penn treebank (Marcus et al., 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.

 $$$$$ This paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in a goldstandard corpus.
 $$$$$ This paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in a goldstandard corpus.
 $$$$$ If the parser makes a single parsing error anywhere in the tree fragment matched by a pattern, the pattern will no longer match.

In this section, we validate the two-step approach, by applying the parser to the output of the trace tagger, and comparing the antecedent recovery accuracy to Johnson (2002). $$$$$ This paper describes a simple patternmatching algorithm for recovering empty nodes and identifying their co-indexed antecedents in phrase structure trees that do not contain this information.
In this section, we validate the two-step approach, by applying the parser to the output of the trace tagger, and comparing the antecedent recovery accuracy to Johnson (2002). $$$$$ This paper also proposes an evaluation procedure for empty node recovery procedures which is independent of most of the details of phrase structure, which makes it possible to compare the performance of empty node recovery on parser output with the empty node annotations in a goldstandard corpus.
In this section, we validate the two-step approach, by applying the parser to the output of the trace tagger, and comparing the antecedent recovery accuracy to Johnson (2002). $$$$$ This paper describes a simple patternmatching algorithm for recovering empty nodes and identifying their co-indexed antecedents in phrase structure trees that do not contain this information.
In this section, we validate the two-step approach, by applying the parser to the output of the trace tagger, and comparing the antecedent recovery accuracy to Johnson (2002). $$$$$ The previous section described an algorithm for restoring empty nodes and co-indexing their antecedents.

 $$$$$ Evaluating the algorithm on the output of Charniak’s parser (Charniak, 2000) and the Penn treebank (Marcus et al., 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.
 $$$$$ (The intuition behind this is that we do not want to penalize the empty node antecedentfinding algorithm if the parser misattaches modifiers to the antecedent).
 $$$$$ It seems that in the cases where the parser does not construct a phrase in the appropriate location to serve as the antecedent for an empty node, the syntactic structure is typically so distorted that either the pattern-matcher fails or the head-finding algorithm does not return the “correct” head either.

Comparing our results to Johnson (2002), we find that the NOINSERT model outperforms that of Johnson by 4.6% (see Table 7). $$$$$ This paper describes a simple patternmatching algorithm for recovering empty nodes and identifying their co-indexed antecedents in phrase structure trees that do not contain this information.
Comparing our results to Johnson (2002), we find that the NOINSERT model outperforms that of Johnson by 4.6% (see Table 7). $$$$$ Alternatively, one might try to design a “sloppy” pattern matching algorithm which in effect recognizes and corrects common parser errors in these constructions.

Excluding Johnson (2002)'s pattern-matching algorithm, most recent work on finding head - dependencies with statistical parser has used statistical versions of deep grammar formalisms, such as CCG (Clark et al, 2002) or LFG (Riezler et al, 2002). $$$$$ This paper described a simple pattern-matching algorithm for restoring empty nodes in parse trees that do not contain them, and appropriately indexing these nodes with their antecedents.
Excluding Johnson (2002)'s pattern-matching algorithm, most recent work on finding head - dependencies with statistical parser has used statistical versions of deep grammar formalisms, such as CCG (Clark et al, 2002) or LFG (Riezler et al, 2002). $$$$$ It suggests that one might improve performance by integrating parsing, empty node recovery and antecedent finding in a single system, in which case the current algorithm might serve as a useful baseline.
Excluding Johnson (2002)'s pattern-matching algorithm, most recent work on finding head - dependencies with statistical parser has used statistical versions of deep grammar formalisms, such as CCG (Clark et al, 2002) or LFG (Riezler et al, 2002). $$$$$ The patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.

Finally, it is not clear that their numbers are in fact comparable to those of Dienes and Dubey on parsed data because the metrics used are not quite equivalent, particularly for (NP*) s $$$$$ The patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.
Finally, it is not clear that their numbers are in fact comparable to those of Dienes and Dubey on parsed data because the metrics used are not quite equivalent, particularly for (NP*) s $$$$$ The previous section described an algorithm for restoring empty nodes and co-indexing their antecedents.
Finally, it is not clear that their numbers are in fact comparable to those of Dienes and Dubey on parsed data because the metrics used are not quite equivalent, particularly for (NP*) s $$$$$ The algorithm is described in detail in section 2.
Finally, it is not clear that their numbers are in fact comparable to those of Dienes and Dubey on parsed data because the metrics used are not quite equivalent, particularly for (NP*) s $$$$$ The patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.

Johnson (2002) used corpus-induced patterns to insert gaps into both gold standard trees and parser output. $$$$$ This section describes two evaluation procedures for such algorithms.
Johnson (2002) used corpus-induced patterns to insert gaps into both gold standard trees and parser output. $$$$$ (Usually this set of antecedents is either empty or contains a single node).
Johnson (2002) used corpus-induced patterns to insert gaps into both gold standard trees and parser output. $$$$$ (Also, while we did not systematically investigate this, there seems to be a number of errors in the annotation of free vs. co-indexed NP * in the treebank).

We compare our algorithm under a variety of conditions to the work of (Johnson, 2002) and (Gabbard et al, 2006). $$$$$ Performance drops considerably when using trees produced by the parser, even though this parser’s precision and recall is around 0.9.
We compare our algorithm under a variety of conditions to the work of (Johnson, 2002) and (Gabbard et al, 2006). $$$$$ The broad-coverage statistical parsers just mentioned produce a simpler tree structure for such a relative clause that contains neither of the empty nodes just indicated.

The first metric, which was introduced by Johnson (2002), has been widely reported by researchers investigating gap insertion. $$$$$ We used sections 2–21 of the Penn Treebank as the training corpus; section 24 was used as the development corpus for experimentation and tuning, while the test corpus (section 23) was used exactly once (to obtain the results in section 3).
The first metric, which was introduced by Johnson (2002), has been widely reported by researchers investigating gap insertion. $$$$$ If an empty node does not bear an index, its pattern is just the local tree containing it.
The first metric, which was introduced by Johnson (2002), has been widely reported by researchers investigating gap insertion. $$$$$ If p is a pattern and t is a tree, then p matches t iff t is an extension of p ignoring empty nodes in p. For example, the pattern displayed in Figure 4 matches the subtree rooted under SBAR depicted in Figure 2.
The first metric, which was introduced by Johnson (2002), has been widely reported by researchers investigating gap insertion. $$$$$ Presumably this is because the pattern matching technique requires that the parser correctly identify large tree fragments that encode long-range dependencies not captured by the parser.

Correct dependency recovery for object extraction is also difficult for shallow methods such as Johnson (2002) and Dienes and Dubey (2003). $$$$$ Evaluating the algorithm on the output of Charniak’s parser (Charniak, 2000) and the Penn treebank (Marcus et al., 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.
Correct dependency recovery for object extraction is also difficult for shallow methods such as Johnson (2002) and Dienes and Dubey (2003). $$$$$ (Note that because empty nodes dominate the empty string, their left and right string positions of empty nodes are always identical).
Correct dependency recovery for object extraction is also difficult for shallow methods such as Johnson (2002) and Dienes and Dubey (2003). $$$$$ As a comparison of tables 3 and 4 shows, the pattern-matching algorithm’s biggest weakness is its inability to correctly distinguish co-indexed NP * (i.e., NP PRO) from free (i.e., unindexed) NP *.

While Charniak's parser does not generate empty category information, Johnson (2002) has developed an algorithm that extracts patterns from the Treebank which can be used to insert empty categories into the parser's output. $$$$$ 0.93 0.83 0.88 0.95 0.87 0.91 0.93 0.88 0.91 0.94 0.99 0.96 0.92 0.98 0.95 0.98 0.83 0.90 0.91 0.52 0.66 0.90 0.63 0.74 0.75 0.79 0.77 0.85 0.74 0.79 0.86 0.79 0.82 0.85 0.77 0.81 0.86 0.89 0.88 0.87 0.96 0.92 0.97 0.81 0.88 0.84 0.42 0.56 0.88 0.58 0.70 0.48 0.46 0.47
While Charniak's parser does not generate empty category information, Johnson (2002) has developed an algorithm that extracts patterns from the Treebank which can be used to insert empty categories into the parser's output. $$$$$ There are modications and variations on this algorithm that are worth exploring in future work.
While Charniak's parser does not generate empty category information, Johnson (2002) has developed an algorithm that extracts patterns from the Treebank which can be used to insert empty categories into the parser's output. $$$$$ The patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.
While Charniak's parser does not generate empty category information, Johnson (2002) has developed an algorithm that extracts patterns from the Treebank which can be used to insert empty categories into the parser's output. $$$$$ This section describes two evaluation procedures for such algorithms.

Johnson (2002) was the first post-processing approach to non-local dependency recovery, using a simple pattern-matching algorithm on context-free trees. $$$$$ Evaluating the algorithm on the output of Charniak’s parser (Charniak, 2000) and the Penn treebank (Marcus et al., 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.
Johnson (2002) was the first post-processing approach to non-local dependency recovery, using a simple pattern-matching algorithm on context-free trees. $$$$$ The patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.

This approach contrasts with Johnson (2002), who treats empty/antecedent identification as a joint task, and with Dienes and Dubey (2003a, b), who always identify empties first and determine antecedents later. $$$$$ Precision, recall and f-score are defined for these augmented representations as before.
This approach contrasts with Johnson (2002), who treats empty/antecedent identification as a joint task, and with Dienes and Dubey (2003a, b), who always identify empties first and determine antecedents later. $$$$$ Evaluating the algorithm on the output of Charniak’s parser (Charniak, 2000) and the Penn treebank (Marcus et al., 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.
This approach contrasts with Johnson (2002), who treats empty/antecedent identification as a joint task, and with Dienes and Dubey (2003a, b), who always identify empties first and determine antecedents later. $$$$$ Since empty nodes are typically located in the most embedded local trees of patterns (i.e., movement is usually “upward” in a tree), if two different patterns (corresponding to different non-local dependencies) could potentially insert empty nodes into the same tree fragment in t, the deeper pattern will match at a higher node in t, and hence will be substituted.

in an abstract sense it mediates the gap-threading information incorporated into GPSG-style (Gazdar et al., 1985) parsers, and in concrete terms it closely matches the information derived from Johnson (2002)'s connected local tree set patterns. $$$$$ To evaluate co-indexation of empty nodes and their antecedents, we augment the representation of empty nodes as follows.
in an abstract sense it mediates the gap-threading information incorporated into GPSG-style (Gazdar et al., 1985) parsers, and in concrete terms it closely matches the information derived from Johnson (2002)'s connected local tree set patterns. $$$$$ This paper describes a simple patternmatching algorithm for recovering empty nodes and identifying their co-indexed antecedents in phrase structure trees that do not contain this information.
in an abstract sense it mediates the gap-threading information incorporated into GPSG-style (Gazdar et al., 1985) parsers, and in concrete terms it closely matches the information derived from Johnson (2002)'s connected local tree set patterns. $$$$$ For patterns of the kind described here, patterns can be indexed on their topmost local tree (i.e., the pattern’s root node label and the sequence of node labels of its children).

Our algorithm's performance can be compared with the work of Johnson (2002) and Dienes and Dubey (2003a) on WSJ. $$$$$ (The intuition behind this is that we do not want to penalize the empty node antecedentfinding algorithm if the parser misattaches modifiers to the antecedent).
Our algorithm's performance can be compared with the work of Johnson (2002) and Dienes and Dubey (2003a) on WSJ. $$$$$ For this kind of pattern we define pattern matching informally as follows.
Our algorithm's performance can be compared with the work of Johnson (2002) and Dienes and Dubey (2003a) on WSJ. $$$$$ Let G be the set of such empty node representations derived from the “gold standard” evaluation corpus and T the set of empty node representations column is the number of times the pattern was found, and the Match column is an estimate of the number of times that this pattern matches some subtree in the training corpus during empty node recovery, as explained in the text. derived from the corpus to be evaluated.
Our algorithm's performance can be compared with the work of Johnson (2002) and Dienes and Dubey (2003a) on WSJ. $$$$$ The patterns are minimal connected tree fragments containing an empty node and all other nodes co-indexed with it.

For purposes of comparability with Johnson (2002) we used Charniak's 2000 parser as P. $$$$$ Let G be the set of such empty node representations derived from the “gold standard” evaluation corpus and T the set of empty node representations column is the number of times the pattern was found, and the Match column is an estimate of the number of times that this pattern matches some subtree in the training corpus during empty node recovery, as explained in the text. derived from the corpus to be evaluated.
For purposes of comparability with Johnson (2002) we used Charniak's 2000 parser as P. $$$$$ This seems to be a hard problem, and lexical information (especially the class of the governing verb) seems relevant.
For purposes of comparability with Johnson (2002) we used Charniak's 2000 parser as P. $$$$$ This paper describes a simple patternmatching algorithm for recovering empty nodes and identifying their co-indexed antecedents in phrase structure trees that do not contain this information.
For purposes of comparability with Johnson (2002) we used Charniak's 2000 parser as P. $$$$$ To avoid this over-estimation, after we have matched all patterns against a node of a training corpus tree we determine the correct pattern (if any) to apply in order to recover the empty nodes that were originally present, and reinsert the relevant empty nodes.

P is parser, G is string-to-context-free-gold-tree mapping, A is present remapping algorithm, J is Johnson 2002, D is the COMBINED model of Dienes 2003. $$$$$ Possibly there is a way to use both skeletal and the original kind of patterns in a single system.
P is parser, G is string-to-context-free-gold-tree mapping, A is present remapping algorithm, J is Johnson 2002, D is the COMBINED model of Dienes 2003. $$$$$ In fact this head-based antecedent representation yields scores very similiar to those obtained using the phrase-based representation.
P is parser, G is string-to-context-free-gold-tree mapping, A is present remapping algorithm, J is Johnson 2002, D is the COMBINED model of Dienes 2003. $$$$$ This section describes two evaluation procedures for such algorithms.
P is parser, G is string-to-context-free-gold-tree mapping, A is present remapping algorithm, J is Johnson 2002, D is the COMBINED model of Dienes 2003. $$$$$ Many current linguistic theories of non-local dependencies are extremely complex, and would be difficult to apply with the kind of broad coverage described here.

To further compare the results of our algorithm with previous work, we obtained the output trees produced by Johnson (2002) and Dienes (2003) and evaluated them on typed dependency performance. $$$$$ The second phase of the algorithm uses these extracted patterns to insert empty nodes and index their antecedents in trees that do not contain empty nodes.
To further compare the results of our algorithm with previous work, we obtained the output trees produced by Johnson (2002) and Dienes (2003) and evaluated them on typed dependency performance. $$$$$ If this set is non-empty we substitute the highest ranked pattern in the set into the subtree, inserting an empty node and (if required) co-indexing it with its antecedents.
To further compare the results of our algorithm with previous work, we obtained the output trees produced by Johnson (2002) and Dienes (2003) and evaluated them on typed dependency performance. $$$$$ The previous section described an algorithm for restoring empty nodes and co-indexing their antecedents.
To further compare the results of our algorithm with previous work, we obtained the output trees produced by Johnson (2002) and Dienes (2003) and evaluated them on typed dependency performance. $$$$$ 0.93 0.83 0.88 0.95 0.87 0.91 0.93 0.88 0.91 0.94 0.99 0.96 0.92 0.98 0.95 0.98 0.83 0.90 0.91 0.52 0.66 0.90 0.63 0.74 0.75 0.79 0.77 0.85 0.74 0.79 0.86 0.79 0.82 0.85 0.77 0.81 0.86 0.89 0.88 0.87 0.96 0.92 0.97 0.81 0.88 0.84 0.42 0.56 0.88 0.58 0.70 0.48 0.46 0.47
