Biographic Data Past work on this task (e.g. Bagga and Baldwin, 1998) has primarily approached personal name disambiguation using document context profiles or vectors, which recognize and distinguish identical name instances based on partially indicative words in context such as computer or car in the Clark case. $$$$$ This information about the entity is gathered by the SentenceExtractor module and is used by the VSM-Disambiguate module for disambiguation purposes.
Biographic Data Past work on this task (e.g. Bagga and Baldwin, 1998) has primarily approached personal name disambiguation using document context profiles or vectors, which recognize and distinguish identical name instances based on partially indicative words in context such as computer or car in the Clark case. $$$$$ As a novel research problem, cross document coreference provides an different perspective from related phenomenon like named entity recognition and within document coreference.
Biographic Data Past work on this task (e.g. Bagga and Baldwin, 1998) has primarily approached personal name disambiguation using document context profiles or vectors, which recognize and distinguish identical name instances based on partially indicative words in context such as computer or car in the Clark case. $$$$$ In the model-theoretic description of the algorithm that follows, the term &quot;key&quot; refers to the manually annotated coreference chains (the truth) while the term &quot;response&quot; refers to the coreference chains output by a system.
Biographic Data Past work on this task (e.g. Bagga and Baldwin, 1998) has primarily approached personal name disambiguation using document context profiles or vectors, which recognize and distinguish identical name instances based on partially indicative words in context such as computer or car in the Clark case. $$$$$ It ranked among the top systems in the coreference task during the MUC-6 and the MUC-7 evaluations.

Some refer to the task as cross-document co reference resolution (Bagga and Baldwin, 1998), name discrimination (Pedersen et al, 2005) or Web People Search (WebPS) (Artiles et al, 2007). $$$$$ The shortcomings of the MUC scoring algorithm when used for the cross-document coreference task forced us to develop a second algorithm.
Some refer to the task as cross-document co reference resolution (Bagga and Baldwin, 1998), name discrimination (Pedersen et al, 2005) or Web People Search (WebPS) (Artiles et al, 2007). $$$$$ In comparison, for this task, named-entity tools like NetOwl and Textract would mark all the John Smiths the same.
Some refer to the task as cross-document co reference resolution (Bagga and Baldwin, 1998), name discrimination (Pedersen et al, 2005) or Web People Search (WebPS) (Artiles et al, 2007). $$$$$ The system is built upon the University of Pennsylvania's within document coreference system, CAMP, which participated in the Seventh Message Understanding Conference (MUC-7) within document coreference task (MUC7 1998).
Some refer to the task as cross-document co reference resolution (Bagga and Baldwin, 1998), name discrimination (Pedersen et al, 2005) or Web People Search (WebPS) (Artiles et al, 2007). $$$$$ Cross-document coreference occurs when the same person, place, event, or concept is discussed in more than one text source.

In our experiments, we use the training texts to acquire co reference classifiers and evaluate the resulting systems on the test texts with respect to two commonly-used co reference scoring programs: the MUC scorer (Vilain et al, 1995) and the B-CUBED scorer (Bagga and Baldwin, 1998). $$$$$ We have also tested our system on other classes of cross-document coreference like names of companies, and events.
In our experiments, we use the training texts to acquire co reference classifiers and evaluate the resulting systems on the test texts with respect to two commonly-used co reference scoring programs: the MUC scorer (Vilain et al, 1995) and the B-CUBED scorer (Bagga and Baldwin, 1998). $$$$$ There were 35 different John Smiths mentioned in the articles.
In our experiments, we use the training texts to acquire co reference classifiers and evaluate the resulting systems on the test texts with respect to two commonly-used co reference scoring programs: the MUC scorer (Vilain et al, 1995) and the B-CUBED scorer (Bagga and Baldwin, 1998). $$$$$ Cross-document coreference occurs when the same person, place, event, or concept is discussed in more than one text source.

Four-fold cross validation is employed and B-CUBED metric (Bagga and Baldwin, 1998) is adopted to evaluate the clustering results. $$$$$ These summaries are a special case of the query sensitive techniques being developed at Penn using CAMP.
Four-fold cross validation is employed and B-CUBED metric (Bagga and Baldwin, 1998) is adopted to evaluate the clustering results. $$$$$ Our system takes summaries about an entity of interest and uses various information retrieval metrics to rank the similarity of the summaries.
Four-fold cross validation is employed and B-CUBED metric (Bagga and Baldwin, 1998) is adopted to evaluate the clustering results. $$$$$ Our system takes as input the coreference processed documents output by CAMP.
Four-fold cross validation is employed and B-CUBED metric (Bagga and Baldwin, 1998) is adopted to evaluate the clustering results. $$$$$ The Vector Space Model in this case constructed the space of terms only from the summaries extracted by SentenceExtractor.

We employed the B-CUBED metric (Bagga and Baldwin, 1998) to evaluate the clustering results. $$$$$ *?Smithr regular expression.
We employed the B-CUBED metric (Bagga and Baldwin, 1998) to evaluate the clustering results. $$$$$ Consider the following examples: suppose the truth contains two large coreference chains and one small one (Figure 6), and suppose Figures 7 and 8 show two different responses.
We employed the B-CUBED metric (Bagga and Baldwin, 1998) to evaluate the clustering results. $$$$$ &quot;We will have continued growth in the future,&quot; said Kelly, who will serve for two years.

Bagga and Baldwin (1998) proposed entity based cross-document co-referencing which uses co-reference chains of each document to generate its summary and then use the summary rather than the whole article to select informative words to be the features of the document. $$$$$ In addition, the problems encountered during within document coreference are compounded when looking for coreferences across documents because the underlying principles of linguistics and discourse context no longer apply across documents.
Bagga and Baldwin (1998) proposed entity based cross-document co-referencing which uses co-reference chains of each document to generate its summary and then use the summary rather than the whole article to select informative words to be the features of the document. $$$$$ Cross-document coreference also differs in substantial ways from within-document coreference.
Bagga and Baldwin (1998) proposed entity based cross-document co-referencing which uses co-reference chains of each document to generate its summary and then use the summary rather than the whole article to select informative words to be the features of the document. $$$$$ &quot;There's been a lot of changes and there will be continued changes as we head into the year 2000.&quot; Details about each of the main steps of the crossdocument coreference algorithm are given below. consider the two extracts in Figures 2 and 4.
Bagga and Baldwin (1998) proposed entity based cross-document co-referencing which uses co-reference chains of each document to generate its summary and then use the summary rather than the whole article to select informative words to be the features of the document. $$$$$ *?Smithr regular expression.

BCubed (Bagga and Baldwin, 1998) is an attractive measure that addresses both completeness and homogeneity. $$$$$ \MI + 42 + + 4n is the cosine normalization factor and is equal to the Euclidean length of the vector Si.
BCubed (Bagga and Baldwin, 1998) is an attractive measure that addresses both completeness and homogeneity. $$$$$ And it is this fact which actually helps VSM-Disambiguate decide that the two John Perrys in doc.36 and doc.38 are the same person.
BCubed (Bagga and Baldwin, 1998) is an attractive measure that addresses both completeness and homogeneity. $$$$$ As a result we wanted to model the accuracy of the system on a per-document basis and then build a more global score based on the sum of the user's experiences.
BCubed (Bagga and Baldwin, 1998) is an attractive measure that addresses both completeness and homogeneity. $$$$$ Details about both these algorithms follow.

Similar approach was developed by (Bagga and Baldwin, 1998), who created first order context vectors that represent the instance in which the ambiguous name occurs. $$$$$ In this paper we describe a cross-document coreference resolution algorithm which uses the Vector Space Model to resolve ambiguities between people having the same name.
Similar approach was developed by (Bagga and Baldwin, 1998), who created first order context vectors that represent the instance in which the ambiguous name occurs. $$$$$ Cross-document coreference can also be used as the central tool for producing summaries from multiple documents, and for information fusion, both of which have been identified as advanced areas of research by the TIPSTER Phase III program.
Similar approach was developed by (Bagga and Baldwin, 1998), who created first order context vectors that represent the instance in which the ambiguous name occurs. $$$$$ The second error occurs when the two large coreference chains are related by the errant coreferent link (Figure 8).

In this paper, we present a new text semantic similarity approach for fine-grained person name categorization and discrimination which is similar to those of (Pedersen et al, 2005) and (Bagga and Baldwin, 1998), but instead of simple word co-occurrences, we consider the whole text segment and relate the deduced semantic information of Latent Semantic Analysis (LSA) to trace the text cohesion between thousands of sentences containing named entities which belong to different fine-grained categories or individuals. $$$$$ These summaries are a special case of the query sensitive techniques being developed at Penn using CAMP.
In this paper, we present a new text semantic similarity approach for fine-grained person name categorization and discrimination which is similar to those of (Pedersen et al, 2005) and (Bagga and Baldwin, 1998), but instead of simple word co-occurrences, we consider the whole text segment and relate the deduced semantic information of Latent Semantic Analysis (LSA) to trace the text cohesion between thousands of sentences containing named entities which belong to different fine-grained categories or individuals. $$$$$ In comparison, the MUC algorithm computes a precision of 90% for both the responses (Figure 9).
In this paper, we present a new text semantic similarity approach for fine-grained person name categorization and discrimination which is similar to those of (Pedersen et al, 2005) and (Bagga and Baldwin, 1998), but instead of simple word co-occurrences, we consider the whole text segment and relate the deduced semantic information of Latent Semantic Analysis (LSA) to trace the text cohesion between thousands of sentences containing named entities which belong to different fine-grained categories or individuals. $$$$$ This was done by creating a meta document consisting Of the file names of each of the documents that the system was run on.
In this paper, we present a new text semantic similarity approach for fine-grained person name categorization and discrimination which is similar to those of (Pedersen et al, 2005) and (Bagga and Baldwin, 1998), but instead of simple word co-occurrences, we consider the whole text segment and relate the deduced semantic information of Latent Semantic Analysis (LSA) to trace the text cohesion between thousands of sentences containing named entities which belong to different fine-grained categories or individuals. $$$$$ Cross-document coreference was also identified as one of the potential tasks for the Sixth Message Understanding Conference (MUC-6) but was not included as a formal task because it was considered too ambitious (Grishman 94).

The original work in (Bagga and Baldwin, 1998) proposed a CDC system by first performing WDC and then disambiguating based on the summary sentences of the chains. $$$$$ There were 35 different John Smiths mentioned in the articles.
The original work in (Bagga and Baldwin, 1998) proposed a CDC system by first performing WDC and then disambiguating based on the summary sentences of the chains. $$$$$ We had mentioned earlier that the error of linking the the two large chains in the second response is more damaging than the error of linking one of the large chains with the smaller chain in the first response.
The original work in (Bagga and Baldwin, 1998) proposed a CDC system by first performing WDC and then disambiguating based on the summary sentences of the chains. $$$$$ Cross-document coreference is a distinct technology from Named Entity recognizers like IsoQuest's NetOwl and IBM's Textract because it attempts to determine whether name matches are actually the same individual (not all John Smiths are the same).
The original work in (Bagga and Baldwin, 1998) proposed a CDC system by first performing WDC and then disambiguating based on the summary sentences of the chains. $$$$$ We have also looked at the possibilities of using other weighting schemes.

Mann and Yarowsky (2003) have proposed a Web based clustering technique relying on a feature space combining biographic facts and associated names, whereas Bagga and Baldwin (1998) have looked for coreference chains within each document, take the context of these chains for creating summaries about each entity and convert these summaries into a bag of words. $$$$$ Cross-document coreference also differs in substantial ways from within-document coreference.
Mann and Yarowsky (2003) have proposed a Web based clustering technique relying on a feature space combining biographic facts and associated names, whereas Bagga and Baldwin (1998) have looked for coreference chains within each document, take the context of these chains for creating summaries about each entity and convert these summaries into a bag of words. $$$$$ In order to score the cross-document coreference chains output by the system, we had to map the cross-document coreference scoring problem to a within-document coreference scoring problem.
Mann and Yarowsky (2003) have proposed a Web based clustering technique relying on a feature space combining biographic facts and associated names, whereas Bagga and Baldwin (1998) have looked for coreference chains within each document, take the context of these chains for creating summaries about each entity and convert these summaries into a bag of words. $$$$$ While the (Vilain 95) provides intuitive results for coreference scoring, it however does not work as well in the context of evaluating cross document coreference.
Mann and Yarowsky (2003) have proposed a Web based clustering technique relying on a feature space combining biographic facts and associated names, whereas Bagga and Baldwin (1998) have looked for coreference chains within each document, take the context of these chains for creating summaries about each entity and convert these summaries into a bag of words. $$$$$ All errors are considered to be equal.

We base our work partly on previous work done by Bagga and Baldwin (Bagga and Baldwin, 1998), which has also been used in later work (Chen and Martin, 2007). $$$$$ Cross-document coreference is a distinct technology from Named Entity recognizers like IsoQuest's NetOwl and IBM's Textract because it attempts to determine whether name matches are actually the same individual (not all John Smiths are the same).
We base our work partly on previous work done by Bagga and Baldwin (Bagga and Baldwin, 1998), which has also been used in later work (Chen and Martin, 2007). $$$$$ Details about both these algorithms follow.
We base our work partly on previous work done by Bagga and Baldwin (Bagga and Baldwin, 1998), which has also been used in later work (Chen and Martin, 2007). $$$$$ The system is built upon the University of Pennsylvania's within document coreference system, CAMP, which participated in the Seventh Message Understanding Conference (MUC-7) within document coreference task (MUC7 1998).
We base our work partly on previous work done by Bagga and Baldwin (Bagga and Baldwin, 1998), which has also been used in later work (Chen and Martin, 2007). $$$$$ We found it quite challenging to arrive at a scoring metric that satisfied our intuitions about what was good system output v.s. bad, but we have developed a scoring algorithm that is an improvement for this class of data over other within document coreference scoring algorithms.

To score the output of a coreference model, we employ three scoring programs: MUC (Vilain et al, 1995), B3 (Bagga and Baldwin, 1998), and 3 -CEAF (Luo, 2005). $$$$$ On the other hand, the summary produced by SentenceExtractor for the coreference chain of interest in doc.38 is only the first sentence of the extract because the only element of the coreference chain appears in this sentence.
To score the output of a coreference model, we employ three scoring programs: MUC (Vilain et al, 1995), B3 (Bagga and Baldwin, 1998), and 3 -CEAF (Luo, 2005). $$$$$ We found it quite challenging to arrive at a scoring metric that satisfied our intuitions about what was good system output v.s. bad, but we have developed a scoring algorithm that is an improvement for this class of data over other within document coreference scoring algorithms.
To score the output of a coreference model, we employ three scoring programs: MUC (Vilain et al, 1995), B3 (Bagga and Baldwin, 1998), and 3 -CEAF (Luo, 2005). $$$$$ In addition, the problems encountered during within document coreference are compounded when looking for coreferences across documents because the underlying principles of linguistics and discourse context no longer apply across documents.
To score the output of a coreference model, we employ three scoring programs: MUC (Vilain et al, 1995), B3 (Bagga and Baldwin, 1998), and 3 -CEAF (Luo, 2005). $$$$$ The first was the standard algorithm for within-document coreference chains which was used for the evaluation of the systems participating in the MUC-6 and the MUC-7 coreference tasks.

The aforementioned complication does not arise from the construction of the mapping, but from the fact that Bagga and Baldwin (1998) and Luo (2005) do not specify how to apply B3 and CEAF to score partitions generated from system mentions. $$$$$ In addition, we also describe a scoring algorithm for evaluating the cross-document coreference chains produced by our system and we compare our algorithm to the scoring algorithm used in the MUC-6 (within document) coreference task.
The aforementioned complication does not arise from the construction of the mapping, but from the fact that Bagga and Baldwin (1998) and Luo (2005) do not specify how to apply B3 and CEAF to score partitions generated from system mentions. $$$$$ Cross-document coreference is a distinct technology from Named Entity recognizers like IsoQuest's NetOwl and IBM's Textract because it attempts to determine whether name matches are actually the same individual (not all John Smiths are the same).
The aforementioned complication does not arise from the construction of the mapping, but from the fact that Bagga and Baldwin (1998) and Luo (2005) do not specify how to apply B3 and CEAF to score partitions generated from system mentions. $$$$$ Neither NetOwl or Textract have mechanisms which try to keep same-named individuals distinct if they are different people.

We use the B3 (Bagga and Baldwin, 1998) evaluation measure as well as precision, recall, and F1 measured on the (positive) pairwise decisions. $$$$$ And it is this fact which actually helps VSM-Disambiguate decide that the two John Perrys in doc.36 and doc.38 are the same person.
We use the B3 (Bagga and Baldwin, 1998) evaluation measure as well as precision, recall, and F1 measured on the (positive) pairwise decisions. $$$$$ The system is built upon the University of Pennsylvania's within document coreference system, CAMP, which participated in the Seventh Message Understanding Conference (MUC-7) within document coreference task (MUC7 1998).
We use the B3 (Bagga and Baldwin, 1998) evaluation measure as well as precision, recall, and F1 measured on the (positive) pairwise decisions. $$$$$ *?Smithr regular expression.
We use the B3 (Bagga and Baldwin, 1998) evaluation measure as well as precision, recall, and F1 measured on the (positive) pairwise decisions. $$$$$ &quot;We will have continued growth in the future,&quot; said Kelly, who will serve for two years.

Early work in the field of name disambiguation is that of (Bagga and Baldwin, 1998) who proposed cross-document coreference resolution algorithm which uses vector space model to resolve the ambiguities between people sharing the same name. $$$$$ Cross-document coreference also differs in substantial ways from within-document coreference.
Early work in the field of name disambiguation is that of (Bagga and Baldwin, 1998) who proposed cross-document coreference resolution algorithm which uses vector space model to resolve the ambiguities between people sharing the same name. $$$$$ Cross-document coreference can also be used as the central tool for producing summaries from multiple documents, and for information fusion, both of which have been identified as advanced areas of research by the TIPSTER Phase III program.
Early work in the field of name disambiguation is that of (Bagga and Baldwin, 1998) who proposed cross-document coreference resolution algorithm which uses vector space model to resolve the ambiguities between people sharing the same name. $$$$$ Details about both these algorithms follow.
Early work in the field of name disambiguation is that of (Bagga and Baldwin, 1998) who proposed cross-document coreference resolution algorithm which uses vector space model to resolve the ambiguities between people sharing the same name. $$$$$ There were 35 different John Smiths mentioned in the articles.

On this dataset, our proposed model yields a B3 (Bagga and Baldwin, 1998) F1 score of 73.7%, improving over the baseline by 16% absolute (corresponding to 38% error reduction). $$$$$ In particular, resolving cross-document coreferences allows a user to identify trends and dependencies across documents.
On this dataset, our proposed model yields a B3 (Bagga and Baldwin, 1998) F1 score of 73.7%, improving over the baseline by 16% absolute (corresponding to 38% error reduction). $$$$$ And it is this fact which actually helps VSM-Disambiguate decide that the two John Perrys in doc.36 and doc.38 are the same person.
On this dataset, our proposed model yields a B3 (Bagga and Baldwin, 1998) F1 score of 73.7%, improving over the baseline by 16% absolute (corresponding to 38% error reduction). $$$$$ If the similarity computed is above a pre-defined threshold, then the entity of interest in the two summaries are considered to be coreferent.
On this dataset, our proposed model yields a B3 (Bagga and Baldwin, 1998) F1 score of 73.7%, improving over the baseline by 16% absolute (corresponding to 38% error reduction). $$$$$ We used two different scoring algorithms for scoring the output.

One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. $$$$$ The importance of using CAMP to extract summaries is verified by comparing the highest FMeasures achieved by the system for the two cases.
One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. $$$$$ If the similarity computed is above a pre-defined threshold, then the entity of interest in the two summaries are considered to be coreferent.
One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. $$$$$ In this model, each summary extracted by the SentenceExtractor module is stored as a vector of terms.

The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense Disambiguation (WSD) (Agirre and Edmonds, 2006) and Cross-document Coreference (CDC) (Bagga and Baldwin, 1998). $$$$$ In the model-theoretic description of the algorithm that follows, the term &quot;key&quot; refers to the manually annotated coreference chains (the truth) while the term &quot;response&quot; refers to the coreference chains output by a system.

Cross document coreference (CDC) (Bagga and Baldwin, 1998) is a distinct technology that consolidates named entities across documents according to their real referents. $$$$$ *?Smithr regular expression.
Cross document coreference (CDC) (Bagga and Baldwin, 1998) is a distinct technology that consolidates named entities across documents according to their real referents. $$$$$ In addition, we also describe a scoring algorithm for evaluating the cross-document coreference chains produced by our system and we compare our algorithm to the scoring algorithm used in the MUC- 6 (within document) coreference task.
Cross document coreference (CDC) (Bagga and Baldwin, 1998) is a distinct technology that consolidates named entities across documents according to their real referents. $$$$$ Oliver &quot;Biff&quot; Kelly of Weymouth succeeds John Perry as president of the Massachusetts Golf Association.
Cross document coreference (CDC) (Bagga and Baldwin, 1998) is a distinct technology that consolidates named entities across documents according to their real referents. $$$$$ Their performance using our Threshold Figure 11: Precision, Recall, and F-Measure Using the B-CUBED Algorithm With Training On the Summaries scoring algorithm is 23% precision, and 100% recall.
