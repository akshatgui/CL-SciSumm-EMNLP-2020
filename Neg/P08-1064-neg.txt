This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al, 2008a). $$$$$ As a result, it is more robust to the issue of non-syntactic phrase usage and non-isomorphic structure alignment.
This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al, 2008a). $$$$$ The model leverages on the strengths of both phrase-based and linguistically syntax-based method.
This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al, 2008a). $$$$$ The model leverages on the strengths of both phrase-based and linguistically syntax-based method.
This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al, 2008a). $$$$$ Otherwise, we replace the nonterminal leaf nodes of the current abstract rule with their corresponding spans’ translations that are already translated in previous steps (line 7).

Works that apply the TTT model include Gildea (2003) and Zhang et al (2008). $$$$$ Compared with previous models, it not only captures non-syntactic phrases and discontinuous phrases with linguistically structured features, but also supports multi-level structure reordering of tree typology with larger span.
Works that apply the TTT model include Gildea (2003) and Zhang et al (2008). $$$$$ However, no further significant improvement is achieved when the model is made sensitive to syntactic structures by adding a constituent feature (Chiang, 2005).
Works that apply the TTT model include Gildea (2003) and Zhang et al (2008). $$$$$ mzhang@i2r.a-star.edu.sg hfjiang@mtlab.hit.edu.cn tancl@comp.nus.edu.sg aaiti@i2r.a-star.edu.sg lisheng@hit.edu.cn hli@i2r.a-star.edu.sg Abstract This paper presents a translation model that is based on tree sequence alignment, where a tree sequence refers to a single sequence of subtrees that covers a phrase.

These works mainly try to incorporate non-syntatic phrases into a syntax-based model $$$$$ (3) formulates the tree sequence alignmentbased translation model.
These works mainly try to incorporate non-syntatic phrases into a syntax-based model $$$$$ We are also interested in comparing our method with the forestto-string model (Liu et al., 2007).
These works mainly try to incorporate non-syntatic phrases into a syntax-based model $$$$$ Our study also finds that in our model the tree sequence rules are very useful since they can model non-syntactic phrases and reorderings with rich linguistic structure features while discontinuous phrases and tree sequence rules with more than three sub-trees have less impact on performance.

In particular, I will investigate settings that incorporate non syntactic phrases, using methods similar to Liu et al (2006) and Zhang et al (2008). $$$$$ Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying.
In particular, I will investigate settings that incorporate non syntactic phrases, using methods similar to Liu et al (2006) and Zhang et al (2008). $$$$$ Due to space limitation, we skip the details here.
In particular, I will investigate settings that incorporate non syntactic phrases, using methods similar to Liu et al (2006) and Zhang et al (2008). $$$$$ In the following, we review four representatives of them.
In particular, I will investigate settings that incorporate non syntactic phrases, using methods similar to Liu et al (2006) and Zhang et al (2008). $$$$$ Finally, we investigate the impact of maximal sub-tree number and sub-tree depth in our model.

For the TTS systems (one for each translation direction), the training set will be lexically aligned using GIZA++ and for the TTT system, its syntactic trees will be aligned using techniques similar to the ones proposed by Gildea (2003) and by Zhang et al (2008). $$$$$ When translating a span, if the usable rule is an initial rule, then the tree sequence on the target side of the rule is a candidate translation (lines 4-5).
For the TTS systems (one for each translation direction), the training set will be lexically aligned using GIZA++ and for the TTT system, its syntactic trees will be aligned using techniques similar to the ones proposed by Gildea (2003) and by Zhang et al (2008). $$$$$ There are many interesting research topics on the tree sequence-based translation model worth exploring in the future.
For the TTS systems (one for each translation direction), the training set will be lexically aligned using GIZA++ and for the TTT system, its syntactic trees will be aligned using techniques similar to the ones proposed by Gildea (2003) and by Zhang et al (2008). $$$$$ When translating a span, if the usable rule is an initial rule, then the tree sequence on the target side of the rule is a candidate translation (lines 4-5).
For the TTS systems (one for each translation direction), the training set will be lexically aligned using GIZA++ and for the TTT system, its syntactic trees will be aligned using techniques similar to the ones proposed by Gildea (2003) and by Zhang et al (2008). $$$$$ Then we study the model’s expressive ability by comparing the contributions made by different kinds of rules, including strict tree sequence rules, non-syntactic phrase rules, structure reordering rules and discontinuous tured by the two syntax-based models through tree node operations.

Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar $$$$$ It automatically learns aligned tree sequence pairs with mapping probabilities from word-aligned biparsed parallel texts.
Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar $$$$$ 2) The lexicalized TSRs make the major contribution since they can capture non-syntactic phrases with syntactic structure features. refers to the structure reordering rules that have at least two non-terminal leaf nodes with inverted order in the source and target sides, which are usually not captured by phrase-based models.
Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar $$$$$ This makes our abstract rules more powerful in handling global structure reordering.
Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar $$$$$ Moreover, by configuring these parameters we can implement other translation models easily: 1) STSG-based model when d =1 ; 2) SCFG-based model when d =1 and h = 2 ; 3) phrase-based translation model only (no reordering model) when c = 0 and h =1. co-indexing the pairs of non-terminals that rooting the removed source and target parts

Synchronous tree-sequence substitution grammar (STSSG) al lows either side of a rule to comprise a sequence of trees instead of a single tree (Zhang et al, 2008). $$$$$ Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well.
Synchronous tree-sequence substitution grammar (STSSG) al lows either side of a rule to comprise a sequence of trees instead of a single tree (Zhang et al, 2008). $$$$$ We carried out a number of experiments to examine the proposed tree sequence alignment-based translation model.
Synchronous tree-sequence substitution grammar (STSSG) al lows either side of a rule to comprise a sequence of trees instead of a single tree (Zhang et al, 2008). $$$$$ 13: output the hypothesis with the highest score in h[1, J] as the final best translation The decoder is a span-based beam search together with a function for mapping the source derivations to the target ones.
Synchronous tree-sequence substitution grammar (STSSG) al lows either side of a rule to comprise a sequence of trees instead of a single tree (Zhang et al, 2008). $$$$$ To the best of our knowledge, this is the first attempt to empirically explore the tree sequence alignment based model in SMT.

Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al (2008a), Zhang et al (2008b), and Sun et al (2009). $$$$$ Finally, we would also like to study unsupervised learningbased bilingual parsing for SMT.
Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al (2008a), Zhang et al (2008b), and Sun et al (2009). $$$$$ If leaf nodes of TS(f jj2 ) and TS(e1) .
Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al (2008a), Zhang et al (2008b), and Sun et al (2009). $$$$$ Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems.
Finally, STSSG, which have been derived from rational tree relations (Raoult, 1997), have been discussed by Zhang et al (2008a), Zhang et al (2008b), and Sun et al (2009). $$$$$ Otherwise, we replace the nonterminal leaf nodes of the current abstract rule with their corresponding spans’ translations that are already translated in previous steps (line 7).

However, Zhang et al (2008b) and Sunet al (2009) demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality. $$$$$ This strategy can guarantee that when translating the current span, all spans smaller than the current one have already been translated before if they are translatable (line 7).
However, Zhang et al (2008b) and Sunet al (2009) demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality. $$$$$ It is straightforward to extract initial rules.
However, Zhang et al (2008b) and Sunet al (2009) demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality. $$$$$ We set three baseline systems: Moses (Koehn et al., 2007), and SCFG-based and STSG-based treeto-tree translation models (Zhang et al., 2007).
However, Zhang et al (2008b) and Sunet al (2009) demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality. $$$$$ However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006).

A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al (2008a), Zhanget al (2008b), and Sun et al (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. $$$$$ Recently, many syntax-based models have been proposed to address the above deficiencies 2003).
A model that is even more powerful than LMBOT is the non-contiguous version of STSSG (synchronous tree-sequence substitution grammar) of Zhang et al (2008a), Zhanget al (2008b), and Sun et al (2009), which allows sequences of trees on both sides of rules [see also (Raoult, 1997)]. $$$$$ This strategy can guarantee that when translating the current span, all spans smaller than the current one have already been translated before if they are translatable (line 7).

Chiang (2005) and Graehl et al (2008) argue that STSG have sufficient expressive power for syntax based machine translation, but Zhang et al (2008a) show that the additional expressive power of tree sequences helps the translation process. $$$$$ Otherwise, we replace the nonterminal leaf nodes of the current abstract rule with their corresponding spans’ translations that are already translated in previous steps (line 7).
Chiang (2005) and Graehl et al (2008) argue that STSG have sufficient expressive power for syntax based machine translation, but Zhang et al (2008a) show that the additional expressive power of tree sequences helps the translation process. $$$$$ This gives our model stronger expressive power than other reported models.
Chiang (2005) and Graehl et al (2008) argue that STSG have sufficient expressive power for syntax based machine translation, but Zhang et al (2008a) show that the additional expressive power of tree sequences helps the translation process. $$$$$ There are many interesting research topics on the tree sequence-based translation model worth exploring in the future.
Chiang (2005) and Graehl et al (2008) argue that STSG have sufficient expressive power for syntax based machine translation, but Zhang et al (2008a) show that the additional expressive power of tree sequences helps the translation process. $$$$$ Finally, we would also like to study unsupervised learningbased bilingual parsing for SMT.

Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar $$$$$ mzhang@i2r.a-star.edu.sg hfjiang@mtlab.hit.edu.cn tancl@comp.nus.edu.sg aaiti@i2r.a-star.edu.sg lisheng@hit.edu.cn hli@i2r.a-star.edu.sg Abstract This paper presents a translation model that is based on tree sequence alignment, where a tree sequence refers to a single sequence of subtrees that covers a phrase.
Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar $$$$$ Compared with previous models, it not only captures non-syntactic phrases and discontinuous phrases with linguistically structured features, but also supports multi-level structure reordering of tree typology with larger span.
Recent research on tree based systems shows that relaxing the restriction from tree structure to tree sequence structure (Synchronous Tree Sequence Substitution Grammar $$$$$ We model it using our tree sequence-based translation rules.

 $$$$$ 1) Hassan et al. (2007) integrate supertags (a kind of lexicalized syntactic description) into the target side of translation model and language model under the phrase-based translation framework, resulting in good performance improvement.
 $$$$$ Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insertion grammar.
 $$$$$ We set three baseline systems: Moses (Koehn et al., 2007), and SCFG-based and STSG-based treeto-tree translation models (Zhang et al., 2007).
 $$$$$ To speed up the decoder, we use several thresholds to limit search beams for each span: It is worth noting that the decoder does not force a complete target parse tree to be generated.

Similar to the definition of tree sequence used in a single parse tree defined in Liu et al (2007) and Zhang et al (2008a), a tree sequence in a forest also refers to an ordered sub-tree sequence that covers a continuous phrase without overlapping. $$$$$ If no rules can be used to generate a complete target parse tree, the decoder just outputs whatever have phrase rules2.
Similar to the definition of tree sequence used in a single parse tree defined in Liu et al (2007) and Zhang et al (2008a), a tree sequence in a forest also refers to an ordered sub-tree sequence that covers a continuous phrase without overlapping. $$$$$ It clearly indicates that SRRs are very effective in reordering structures, which improve performance by 1.45 (26.07-24.62) BLEU score.

 $$$$$ Many of them are redundant, which make decoding very slow.
 $$$$$ Then we study the model’s expressive ability by comparing the contributions made by different kinds of rules, including strict tree sequence rules, non-syntactic phrase rules, structure reordering rules and discontinuous tured by the two syntax-based models through tree node operations.

Among them, Zhang et al (2008a) acquire the non-contiguous phrasal rules from the contiguous tree sequence pairs, and find them useless via real syntax-based translation systems. $$$$$ It shows that around 30% rules are shared by the two kinds of rule sets.
Among them, Zhang et al (2008a) acquire the non-contiguous phrasal rules from the contiguous tree sequence pairs, and find them useless via real syntax-based translation systems. $$$$$ In order to control the number of rules, we set three constraints for both finally extracted initial and abstract rules: 1) The depth of a tree in a rule is not greater than h .
Among them, Zhang et al (2008a) acquire the non-contiguous phrasal rules from the contiguous tree sequence pairs, and find them useless via real syntax-based translation systems. $$$$$ Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems.
Among them, Zhang et al (2008a) acquire the non-contiguous phrasal rules from the contiguous tree sequence pairs, and find them useless via real syntax-based translation systems. $$$$$ We then derive abstract rules from initial rules by removing one or more of its sub initial rules.

In our opinion, the non-contiguous phrasal rules themselves may not play a trivial role, as reported in Zhang et al (2008a). $$$$$ It translates each span iteratively from small one to large one (lines 1-2).
In our opinion, the non-contiguous phrasal rules themselves may not play a trivial role, as reported in Zhang et al (2008a). $$$$$ As is inherent in a tree-to-string framework, Liu et al.’s method defines a kind of auxiliary rules to integrate forestto-string rules into tree-to-string models.
In our opinion, the non-contiguous phrasal rules themselves may not play a trivial role, as reported in Zhang et al (2008a). $$$$$ It automatically learns aligned tree sequence pairs with mapping probabilities from word-aligned biparsed parallel texts.
In our opinion, the non-contiguous phrasal rules themselves may not play a trivial role, as reported in Zhang et al (2008a). $$$$$ There are many interesting research topics on the tree sequence-based translation model worth exploring in the future.

tree-to-tree translation model based on tree sequence alignment (Zhang et al 2008a) without losing of generality to most syntactic tree based models. $$$$$ The model leverages on the strengths of both phrase-based and linguistically syntax-based method.
tree-to-tree translation model based on tree sequence alignment (Zhang et al 2008a) without losing of generality to most syntactic tree based models. $$$$$ Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems.
tree-to-tree translation model based on tree sequence alignment (Zhang et al 2008a) without losing of generality to most syntactic tree based models. $$$$$ Due to space limitation, we skip the details here.

By means of the Initial rules, we derive the Abstract rules similarly as in Zhang et al (2008a). $$$$$ Huang et al. (2006) study a TSG-based tree-to-string alignment model.
By means of the Initial rules, we derive the Abstract rules similarly as in Zhang et al (2008a). $$$$$ Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems.
By means of the Initial rules, we derive the Abstract rules similarly as in Zhang et al (2008a). $$$$$ The model leverages on the strengths of both phrase-based and linguistically syntax-based method.

ncPR refers to non-contiguous phrasal rules derived from contiguous tree sequence pairs with at least one non-terminal leaf node between two lexicalized leaf nodes (i.e., all non-contiguous rules in STSSG defined as in Zhang et al (2008a). $$$$$ In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment.
ncPR refers to non-contiguous phrasal rules derived from contiguous tree sequence pairs with at least one non-terminal leaf node between two lexicalized leaf nodes (i.e., all non-contiguous rules in STSSG defined as in Zhang et al (2008a). $$$$$ In the last two years, many research efforts were devoted to integrating the strengths of phrasebased and syntax-based methods.
ncPR refers to non-contiguous phrasal rules derived from contiguous tree sequence pairs with at least one non-terminal leaf node between two lexicalized leaf nodes (i.e., all non-contiguous rules in STSSG defined as in Zhang et al (2008a). $$$$$ 2) The number of non-terminals as leaf nodes is not greater than c .
ncPR refers to non-contiguous phrasal rules derived from contiguous tree sequence pairs with at least one non-terminal leaf node between two lexicalized leaf nodes (i.e., all non-contiguous rules in STSSG defined as in Zhang et al (2008a). $$$$$ Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying.
