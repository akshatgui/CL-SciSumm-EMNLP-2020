The research most similar to ours is the work of Diab and Resnik (2002). $$$$$ A second issue that affects recall is the lack of variability in pseudo-translations.
The research most similar to ours is the work of Diab and Resnik (2002). $$$$$ This work has been supported, in part, by ONR MiTRI Contract FCP0.810548265, NSA RD-02-5700, and DARPA/ITO Cooperative Agreement N660010028910.
The research most similar to ours is the work of Diab and Resnik (2002). $$$$$ In of the
The research most similar to ours is the work of Diab and Resnik (2002). $$$$$ In this paper we focus primarily ort the first goal.

TransCont is an enhancement over an existing approach that leverages multilingual evidence through projection, SALAAM, described in detail in (Diab and Resnik, 2002). $$$$$ The English BCSV1SV2WSJ was translated into French and Spanish, resulting in four parallel corpora: BCSV1SV2WSJ paired with the French GL translation (yielding parallel corpus FRGL), with French SYS translation (FRSYS), with Spanish GL (SPGL), and with Spanish SYS (SPSYS).4 Each of the four parallel corpora just described (FRGL, FRSYS, SPGL, SPSYS) represents a separate experimental variant.
TransCont is an enhancement over an existing approach that leverages multilingual evidence through projection, SALAAM, described in detail in (Diab and Resnik, 2002). $$$$$ In this paper we focus primarily ort the first goal.
TransCont is an enhancement over an existing approach that leverages multilingual evidence through projection, SALAAM, described in detail in (Diab and Resnik, 2002). $$$$$ Because it achieves this performance using crosslanguage data alone, it is likely that improved results can be obtained by also taking advantage of monolingual contextual evidence.
TransCont is an enhancement over an existing approach that leverages multilingual evidence through projection, SALAAM, described in detail in (Diab and Resnik, 2002). $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.

TransCont is based on the WSD system SALAAM (Diab and Resnik, 2002), henceforth (DR02). $$$$$ Moreover, noisy annotations can serve as seeds both for monolingual supervised methods and for bootstrapping cross-linguistic sense disambiguation and sense inventories, complementing other research ori the complex problem of mapping sense tags cross linguistically (e.g.
TransCont is based on the WSD system SALAAM (Diab and Resnik, 2002), henceforth (DR02). $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.
TransCont is based on the WSD system SALAAM (Diab and Resnik, 2002), henceforth (DR02). $$$$$ In of the

The parallel data we experiment with are the same standard data sets as in (Diab and Resnik, 2002), namely, Senseval 2 English AW data sets (SV2AW) (Palmer et al, 2001), and Seneval 3 English AW (SV3AW) data set. $$$$$ The motivation behind using two MT systems stems from a desire to more closely approximate the variability of human translation in a very large corpus, where one translator would be unlikely to have performed the entire task, and to help offset the possible tendency of any single MT system to be unnaturally consistent in its lexical selection.
The parallel data we experiment with are the same standard data sets as in (Diab and Resnik, 2002), namely, Senseval 2 English AW data sets (SV2AW) (Palmer et al, 2001), and Seneval 3 English AW (SV3AW) data set. $$$$$ In this paper we focus primarily ort the first goal.
The parallel data we experiment with are the same standard data sets as in (Diab and Resnik, 2002), namely, Senseval 2 English AW data sets (SV2AW) (Palmer et al, 2001), and Seneval 3 English AW (SV3AW) data set. $$$$$ In this evaluation, partial credit is given in cases where a system assigns multiple sense tags.5 We report results using the &quot;fine-grained&quot; scoring variant; this is the strictest variant, which sometimes requires systems to discern among WordNet senses that even linguists have a difficult time distinguishing.

Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al, 2001), and statistical machine translation. $$$$$ Here we briefly consider issues that bear on recall and precision, respectively.
Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al, 2001), and statistical machine translation. $$$$$ Section 2 describes the approach.
Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al, 2001), and statistical machine translation. $$$$$ Looking at parallel translations, it becomes evident that two factors are at play.

Diab and Resnik (2002) presented an unsupervised method for WSD using the same type of resource. $$$$$ A sensible alternative would be apply automatic clustering techniques to the target sets (e.g.
Diab and Resnik (2002) presented an unsupervised method for WSD using the same type of resource. $$$$$ After identifying and tokenizing sentences, we obtain word-level alignments for the parallel corpus using the GIZA++ implementation of the IBM statistical MT models (Och and Ney, 2000).
Diab and Resnik (2002) presented an unsupervised method for WSD using the same type of resource. $$$$$ Section 3 lays out evaluation experiments, using SENSEVAL-2 data, showing the results of several different variations of the approach and comparing performance with other SENSEVAL-2 systems.

Diab and Resnik (2002) present an unsupervised approach to WSD that exploits translational correspondences in parallel corpora that were artificially created by applying commercial MT systems on a sense-tagged English corpus. $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.
Diab and Resnik (2002) present an unsupervised approach to WSD that exploits translational correspondences in parallel corpora that were artificially created by applying commercial MT systems on a sense-tagged English corpus. $$$$$ Conversely, there are some parallel corpora large enough for training alignment models, but to our knowledge none of these have been even partially sense tagged.

This assumption of similar meaning when multiple phrases map onto a single foreign language phrase is the converse of the assumption made in the word sense disambiguation work of Diab and Resnik (2002) which posits different word senses when a single English word maps onto different words in the foreign language. $$$$$ In of the
This assumption of similar meaning when multiple phrases map onto a single foreign language phrase is the converse of the assumption made in the word sense disambiguation work of Diab and Resnik (2002) which posits different word senses when a single English word maps onto different words in the foreign language. $$$$$ We needed: Meeting all three requirements simultaneously presented something of a challenge.
This assumption of similar meaning when multiple phrases map onto a single foreign language phrase is the converse of the assumption made in the word sense disambiguation work of Diab and Resnik (2002) which posits different word senses when a single English word maps onto different words in the foreign language. $$$$$ The process we described can be viewed more abstractly as follows: forming target sets that were translated into the same orthographic form in the source corpus.
This assumption of similar meaning when multiple phrases map onto a single foreign language phrase is the converse of the assumption made in the word sense disambiguation work of Diab and Resnik (2002) which posits different word senses when a single English word maps onto different words in the foreign language. $$$$$ In the fourth and final step, we take advantage of the English-side tagging and the wordlevel alignment to project the sense tags on 3Since we use WordNet as our sense inventory, we also adopt the information-theoretic measure of semantic similarity based on that taxonomy.

As mentioned in Section 1, the way that we extract paraphrases is the converse of the methodology employed in word sense disambiguation work that uses parallel corpora (Diab and Resnik, 2002). $$$$$ tion using statistical models of Roget's categories on large corpora.
As mentioned in Section 1, the way that we extract paraphrases is the converse of the methodology employed in word sense disambiguation work that uses parallel corpora (Diab and Resnik, 2002). $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.
As mentioned in Section 1, the way that we extract paraphrases is the converse of the methodology employed in word sense disambiguation work that uses parallel corpora (Diab and Resnik, 2002). $$$$$ The results show that the performance of our approach is comparable or superior to most other unsupervised systems, even though it is based on cross-language lexical correspondences, a radically different source of evidence, and even though those correspondences were derived from machine translations rather than clean human translations.
As mentioned in Section 1, the way that we extract paraphrases is the converse of the methodology employed in word sense disambiguation work that uses parallel corpora (Diab and Resnik, 2002). $$$$$ In of the

Diab and Resnik (2002) use multilingual information to create an English sense tagged corpus to train a monolingual WSD approach. $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.
Diab and Resnik (2002) use multilingual information to create an English sense tagged corpus to train a monolingual WSD approach. $$$$$ At the end of the third step, we highlight the significance of variability in translation: since the method relies on semantic similarities between multiple items in a target set, the target set must contain at least two members.
Diab and Resnik (2002) use multilingual information to create an English sense tagged corpus to train a monolingual WSD approach. $$$$$ This work has been supported, in part, by ONR MiTRI Contract FCP0.810548265, NSA RD-02-5700, and DARPA/ITO Cooperative Agreement N660010028910.
Diab and Resnik (2002) use multilingual information to create an English sense tagged corpus to train a monolingual WSD approach. $$$$$ On the other hand, that handful of words is rarely a singleton set evert for a single word/sense, because the preferences of different translators and the demands of context produce semantically similar words that differ in their nuances.

In order to accomplish these steps, Bhattacharya et al (2004) used the pseudo-translation approach of Diab and Resnik (2002) $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.
In order to accomplish these steps, Bhattacharya et al (2004) used the pseudo-translation approach of Diab and Resnik (2002) $$$$$ In this evaluation, partial credit is given in cases where a system assigns multiple sense tags.5 We report results using the &quot;fine-grained&quot; scoring variant; this is the strictest variant, which sometimes requires systems to discern among WordNet senses that even linguists have a difficult time distinguishing.

Pivot Language methods were also used for translation dictionary induction (Schafer and Yarowsky, 2002), word sense disambiguation (Diab and Resnik, 2002), and so on. $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.
Pivot Language methods were also used for translation dictionary induction (Schafer and Yarowsky, 2002), word sense disambiguation (Diab and Resnik, 2002), and so on. $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.
Pivot Language methods were also used for translation dictionary induction (Schafer and Yarowsky, 2002), word sense disambiguation (Diab and Resnik, 2002), and so on. $$$$$ For example, the word types adolescence, idol, teen, and teenager form a target set for the French source word adolescence, and the presence of idol has a negative impact ort the sense assignment for the other members of the set.

A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ In extracting correspondences we take advantage of WordNet to identify English nominal compounds in order to help reduce the number of ambiguous terms in the target set.2 For example, without nominal compound identification on the English side, the target set for French abeille will contain bee, winch is ambiguous (SPELLING-BEE VS. INSECT).
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ There are a few human-tagged English corpora available for word sense disambiguation, but most are relatively small by model-training standards and none have associated translations in other languages.
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ On the other hand, that handful of words is rarely a singleton set evert for a single word/sense, because the preferences of different translators and the demands of context produce semantically similar words that differ in their nuances.
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ The authors would like to thank the anonymous reviewers for their comments, Rebecca Hwa and Okan Kolak for helpful assistance and discussion, Franz Josef Och for his help with GIZA++, Adwait Ratnaparkhi for the use of MXTERMINATOR, and our collaborators at Johns Hopkins for the use of their computing facilities in parts of this work.

They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al, 2002), and inducing statistical machine translation models (Koehn et al., 2003). $$$$$ For these sentences, therefore, no attempt could be made at disambiguation.
They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al, 2002), and inducing statistical machine translation models (Koehn et al., 2003). $$$$$ Consider the target set {disaster, tragedy, situation}: to the human reader, the juxtaposition of these words within a single set automatically brings certain senses 2We used a small set of compound-matching rules considering a window of two tokens to the right and left, and also used the &quot;satellite&quot; annotations in SENSEVAL data as part of our preprocessing. to the foreground.
They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al, 2002), and inducing statistical machine translation models (Koehn et al., 2003). $$$$$ Looking at parallel translations, it becomes evident that two factors are at play.
They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al, 2002), and inducing statistical machine translation models (Koehn et al., 2003). $$$$$ The motivation behind using two MT systems stems from a desire to more closely approximate the variability of human translation in a very large corpus, where one translator would be unlikely to have performed the entire task, and to help offset the possible tendency of any single MT system to be unnaturally consistent in its lexical selection.

Cross-language tagging is the goal of the work by Diab and Resnik (2002), who present a method for word sense tagging both the source and target texts of parallel bilingual corpora with the WordNet sense inventory. $$$$$ second, achieving sense tagging using that same sense inventory for the second language, thus creating a sense-tagged corpus and automatically making a connection to the first language's sense inventory.
Cross-language tagging is the goal of the work by Diab and Resnik (2002), who present a method for word sense tagging both the source and target texts of parallel bilingual corpora with the WordNet sense inventory. $$$$$ A word that has multiple senses in one language is often translated as distinct words in another language, with the particular choice depending ort the translator and the contextualized meaning; thus the corresponding translation can be thought of as a sense indicator for the instance of the word in its context.
Cross-language tagging is the goal of the work by Diab and Resnik (2002), who present a method for word sense tagging both the source and target texts of parallel bilingual corpora with the WordNet sense inventory. $$$$$ This work has been supported, in part, by ONR MiTRI Contract FCP0.810548265, NSA RD-02-5700, and DARPA/ITO Cooperative Agreement N660010028910.
Cross-language tagging is the goal of the work by Diab and Resnik (2002), who present a method for word sense tagging both the source and target texts of parallel bilingual corpora with the WordNet sense inventory. $$$$$ If throughout the parallel corpus the translator always chose to translate the French word catastrophe to tragedy, the target set for catastrophe will contain only a single element.

Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al, 2001), and statistical machine translation. $$$$$ The English BCSV1SV2WSJ was translated into French and Spanish, resulting in four parallel corpora: BCSV1SV2WSJ paired with the French GL translation (yielding parallel corpus FRGL), with French SYS translation (FRSYS), with Spanish GL (SPGL), and with Spanish SYS (SPSYS).4 Each of the four parallel corpora just described (FRGL, FRSYS, SPGL, SPSYS) represents a separate experimental variant.
Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al, 2001), and statistical machine translation. $$$$$ In of the
Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al, 2001), and statistical machine translation. $$$$$ Some of the sentences in the test corpus could not be automatically aligned because our aligner discards sentence pairs that are longer than a pre-defined limit.
Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al, 2001), and statistical machine translation. $$$$$ tion using statistical models of Roget's categories on large corpora.

The first model, which we call the Sense model, builds on the work of Diab and Resnik (2002) that uses both parallel text and a sense inventory for the target language, and recasts their approach in a probabilistic framework. $$$$$ Section 3 lays out evaluation experiments, using SENSEVAL-2 data, showing the results of several different variations of the approach and comparing performance with other SENSEVAL-2 systems.
The first model, which we call the Sense model, builds on the work of Diab and Resnik (2002) that uses both parallel text and a sense inventory for the target language, and recasts their approach in a probabilistic framework. $$$$$ Section 3 lays out evaluation experiments, using SENSEVAL-2 data, showing the results of several different variations of the approach and comparing performance with other SENSEVAL-2 systems.
The first model, which we call the Sense model, builds on the work of Diab and Resnik (2002) that uses both parallel text and a sense inventory for the target language, and recasts their approach in a probabilistic framework. $$$$$ In this paper we focus primarily ort the first goal.
The first model, which we call the Sense model, builds on the work of Diab and Resnik (2002) that uses both parallel text and a sense inventory for the target language, and recasts their approach in a probabilistic framework. $$$$$ In of the

The main inspiration for our work is Diab and Resnik (2002), who use translations and linguistic knowledge for disambiguation and automatic sense tagging. $$$$$ For each French word instance f, we collect the word instance e with which it is aligned.
The main inspiration for our work is Diab and Resnik (2002), who use translations and linguistic knowledge for disambiguation and automatic sense tagging. $$$$$ tion using statistical models of Roget's categories on large corpora.
The main inspiration for our work is Diab and Resnik (2002), who use translations and linguistic knowledge for disambiguation and automatic sense tagging. $$$$$ Of the English nouns that are aligned with sourcelanguage words, approximately 35% are always aligned with the same word, rendering them untaggable using an approach based ort semantic similarity within target sets.
The main inspiration for our work is Diab and Resnik (2002), who use translations and linguistic knowledge for disambiguation and automatic sense tagging. $$$$$ The remainder of this paper is organized as follows.

Bengio and Kermorvant (2003) present a graphical model that is an attempt to formalize probabilistically the main ideas in Diab and Resnik (2002). $$$$$ This work has been supported, in part, by ONR MiTRI Contract FCP0.810548265, NSA RD-02-5700, and DARPA/ITO Cooperative Agreement N660010028910.
Bengio and Kermorvant (2003) present a graphical model that is an attempt to formalize probabilistically the main ideas in Diab and Resnik (2002). $$$$$ Because the algorithm for disambiguating noun groupings returns a confidence value for every sense of a word, some threshold or other criterion is needed to decide which sense or senses to actually assign.
Bengio and Kermorvant (2003) present a graphical model that is an attempt to formalize probabilistically the main ideas in Diab and Resnik (2002). $$$$$ The observation behind the approach, that words having the same translation often share some dimension of meaning, leads to art algorithm in which the correct sense of a word is reinforced by the semantic similarity of other words with which it shares those dimensions of meaning.

We show that this improves on the results of Diab and Resnik (2002). $$$$$ These problems reflect the algorithm's implicit assumption that the source words are monosemous, reflected in its attempt to have every word in a target set influence the semantics of every other word.
We show that this improves on the results of Diab and Resnik (2002). $$$$$ Although in the end all unsupervised systems are likely to produce precision results inferior to the best supervised algorithms, they are often more practical to apply in a broad-vocabulary setting.
We show that this improves on the results of Diab and Resnik (2002). $$$$$ French canon (cannon, cannonball, canon, theologian) bandes (band, gang, mob, strip, streak, tape), and baie (bay, berry, cove).
We show that this improves on the results of Diab and Resnik (2002). $$$$$ Moreover, noisy annotations can serve as seeds both for monolingual supervised methods and for bootstrapping cross-linguistic sense disambiguation and sense inventories, complementing other research ori the complex problem of mapping sense tags cross linguistically (e.g.
