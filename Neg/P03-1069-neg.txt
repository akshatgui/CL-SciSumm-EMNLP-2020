Furthermore, to provide some assessment of the quality of the predicted orderings themselves, we follow Lapata (2003) in employing Kendall's t, which is a measure of how much an ordering differs from the OSO --- the underlying assumption is that most reasonable sentence orderings should be fairly similar to it. $$$$$ So far our evaluation metric measures order similarities or dissimilarities.
Furthermore, to provide some assessment of the quality of the predicted orderings themselves, we follow Lapata (2003) in employing Kendall's t, which is a measure of how much an ordering differs from the OSO --- the underlying assumption is that most reasonable sentence orderings should be fairly similar to it. $$$$$ This information is captured more adequately by VDND and not by NL that only keeps a record of the entities in the sentence.
Furthermore, to provide some assessment of the quality of the predicted orderings themselves, we follow Lapata (2003) in employing Kendall's t, which is a measure of how much an ordering differs from the OSO --- the underlying assumption is that most reasonable sentence orderings should be fairly similar to it. $$$$$ Comparison between Model 1 and Model 3 would give a i of 0.244 even though the orders between the two models are identical modulo the beginning and the end.
Furthermore, to provide some assessment of the quality of the predicted orderings themselves, we follow Lapata (2003) in employing Kendall's t, which is a measure of how much an ordering differs from the OSO --- the underlying assumption is that most reasonable sentence orderings should be fairly similar to it. $$$$$ The author was supported by EPSRC grant number R40036.

 $$$$$ Examples of applications that require some form of text structuring, are single- and multidocument summarization as well as question answering.
 $$$$$ Thanks also to Stephen Clark, Nikiforos Karamanis, Frank Keller, Alex Lascarides, Katja Markert, and Miles Osborne for helpful comments and suggestions.

 $$$$$ In cases of noun compounds, only the compound head (i.e., rightmost noun) was taken into account.
 $$$$$ The model is particularly relevant for multidocument summarization since it could provide an alternative to chronological ordering especially for documents where publication date information is unavailable or uninformative (e.g., all documents have the same date).
 $$$$$ Fortunately, they propose a simple greedy algorithm that provides an approximate solution which can be easily modified for our task (see also Barzilay et al. 2002).
 $$$$$ We are grateful to Regina Barzilay and Noemie Elhadad for making available their software and for providing valuable comments on this work.

The same data and similar methods were used by Barzilay and Lee (2004) to compare their probabilistic approach for ordering sentences with that of Lapata (2003). $$$$$ The probawhere f(ai,j,ai−1,k) is the number of times feature ai,j is preceded by feature ai−1,k in the corpus.
The same data and similar methods were used by Barzilay and Lee (2004) to compare their probabilistic approach for ordering sentences with that of Lapata (2003). $$$$$ Barzilay et al. (2002) address the problem of information ordering in multidocument summarization and show that naive ordering algorithms such as majority ordering (selects most frequent orders across input documents) and chronological ordering (orders facts according to publication date) do not always yield coherent summaries although the latter produces good results when the information is eventbased.
The same data and similar methods were used by Barzilay and Lee (2004) to compare their probabilistic approach for ordering sentences with that of Lapata (2003). $$$$$ As in the case of Mellish et al. (1998) we construct an acceptable ordering rather than the best possible one.
The same data and similar methods were used by Barzilay and Lee (2004) to compare their probabilistic approach for ordering sentences with that of Lapata (2003). $$$$$ We performed Post-hoc Tukey tests to further examine whether there are any significant differences among the different features and between our model and the baseline.

It is typically applicable in the text generation field, both for concept-to-text generation and text-to text generation (Lapata, 2003), such as multiple document summarization (MDS), question answering and so on. $$$$$ The probabilities P(ai,j|ai−1,k) will be unreliable when the frequency estimates for f (ai, j,ai−1,k) are small, and undefined in cases where the feature combinations are unattested in the corpus.
It is typically applicable in the text generation field, both for concept-to-text generation and text-to text generation (Lapata, 2003), such as multiple document summarization (MDS), question answering and so on. $$$$$ This way they ensured that orderings were not influenced by mistakes their system could have made.
It is typically applicable in the text generation field, both for concept-to-text generation and text-to text generation (Lapata, 2003), such as multiple document summarization (MDS), question answering and so on. $$$$$ The feature VDND subsumes several other features and does expectedly better: it captures entity-based coherence, the interrelations among verbs, the structure of sentences and also preserves information about argument structure (who is doing what to whom).
It is typically applicable in the text generation field, both for concept-to-text generation and text-to text generation (Lapata, 2003), such as multiple document summarization (MDS), question answering and so on. $$$$$ The author was supported by EPSRC grant number R40036.

For works taking no use of source document, Lapata (2003) proposed a probabilistic model which learns constraints on sentence ordering from a corpus of texts. $$$$$ The probability P(S3|S2) will be calculated by taking the product of P(h|e), P(h |f), P(h|g), P(i|e), P(i |f), and P(i|g).
For works taking no use of source document, Lapata (2003) proposed a probabilistic model which learns constraints on sentence ordering from a corpus of texts. $$$$$ Thanks also to Stephen Clark, Nikiforos Karamanis, Frank Keller, Alex Lascarides, Katja Markert, and Miles Osborne for helpful comments and suggestions.
For works taking no use of source document, Lapata (2003) proposed a probabilistic model which learns constraints on sentence ordering from a corpus of texts. $$$$$ Nouns.
For works taking no use of source document, Lapata (2003) proposed a probabilistic model which learns constraints on sentence ordering from a corpus of texts. $$$$$ In the future we plan to experiment with larger widths (e.g., two or three) and also take into account features that express semantic similarities across documents either by relying on WordNet or on automatic clustering methods.

The probability model originates from (Lapata, 2003), and we implement the model with four features of lemmatized noun, verb, adjective or adverb, and verb and noun related dependency. $$$$$ Note that the noun and verb features do not capture the structure of the sentences to be ordered.
The probability model originates from (Lapata, 2003), and we implement the model with four features of lemmatized noun, verb, adjective or adverb, and verb and noun related dependency. $$$$$ We also assess the appropriateness of such a model for multidocument summarization.
The probability model originates from (Lapata, 2003), and we implement the model with four features of lemmatized noun, verb, adjective or adverb, and verb and noun related dependency. $$$$$ From the Treebank parses we extracted the verbs contained in each sentence.
The probability model originates from (Lapata, 2003), and we implement the model with four features of lemmatized noun, verb, adjective or adverb, and verb and noun related dependency. $$$$$ Ordering information is a critical task for natural language generation applications.

In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). $$$$$ Their results reveal that although the generated orders differ from subject to subject, topically related sentences always appear together.
In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). $$$$$ The problem of finding an acceptable ordering does not arise solely in concept-to-text generation but also in the emerging field of text-to-text generation (Barzilay, 2003).
In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). $$$$$ We evaluate the automatically generated orderings against authored texts from our corpus and against human subjects that are asked to mimic the model’s task.

 $$$$$ Barzilay et al. (2002) collected ten sets of articles each consisting of two to three articles reporting the same event and simulated MULTIGEN by manually selecting the sentences to be included in the final summary.
 $$$$$ As can be seen in Figure 2 for each vertex we keep track of the most probable edge that ends in that vertex, thus setting th beam search width to one.
 $$$$$ The structured text is typically assumed to be a tree (i.e., to have a hierarchical structure) whose leaves express the content being communicated and whose nodes specify how this content is grouped via rhetorical or discourse relations (e.g., contrast, sequence, elaboration).
 $$$$$ While this is clearly a naive view of text coherence, our model has some notion of the types of sentences that typically go together, even though it is agnostic about the specific rhetorical relations that glue sentences into a coherent text.

 $$$$$ The author was supported by EPSRC grant number R40036.
 $$$$$ The average story length is 19.2 sentences.
 $$$$$ This will admittedly introduce some noise, given that some dependencies will be spurious, but the model can be easily retrained for different domains for which different feature combinations will be important.

In contrast, the greedy algorithm of Lapata (2003) makes grave search errors. $$$$$ Local coherence is thus operationalized by sentence proximity in the training corpus.
In contrast, the greedy algorithm of Lapata (2003) makes grave search errors. $$$$$ In the future we plan to experiment with larger widths (e.g., two or three) and also take into account features that express semantic similarities across documents either by relying on WordNet or on automatic clustering methods.
In contrast, the greedy algorithm of Lapata (2003) makes grave search errors. $$$$$ We are grateful to Regina Barzilay and Noemie Elhadad for making available their software and for providing valuable comments on this work.
In contrast, the greedy algorithm of Lapata (2003) makes grave search errors. $$$$$ We are grateful to Regina Barzilay and Noemie Elhadad for making available their software and for providing valuable comments on this work.

The genetic algorithms of Mellish et al (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. $$$$$ We also assess the appropriateness of such a model for multidocument summarization.
The genetic algorithms of Mellish et al (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. $$$$$ We first evaluate the model by attempting to reproduce the structure of unseen texts from the BLLIP corpus, i.e., the corpus on which the model is trained on.
The genetic algorithms of Mellish et al (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. $$$$$ We evaluate the automatically generated orderings against authored texts from our corpus and against human subjects that are asked to mimic the model’s task.
The genetic algorithms of Mellish et al (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. $$$$$ All our results are reported on the test set.

Adjacency of sentences has been previously used to model local coherence (Lapata, 2003). $$$$$ We are grateful to Regina Barzilay and Noemie Elhadad for making available their software and for providing valuable comments on this work.
Adjacency of sentences has been previously used to model local coherence (Lapata, 2003). $$$$$ We describe a model that learns constraints on sentence order from a corpus of domainspecific texts and an algorithm that yields the most likely order among several alternatives.
Adjacency of sentences has been previously used to model local coherence (Lapata, 2003). $$$$$ Thanks also to Stephen Clark, Nikiforos Karamanis, Frank Keller, Alex Lascarides, Katja Markert, and Miles Osborne for helpful comments and suggestions.
Adjacency of sentences has been previously used to model local coherence (Lapata, 2003). $$$$$ The results are shown in table 5, again average pairwise i is reported.

Corpus-based methods inspired by the notion of schemata have been explored in the past by Lapata (2003) and Barzilay and Lee (2004) for ordering sentences extracted in a multi-document summarisation application. $$$$$ The greedy algorithm implements a search procedure with a beam of width one.
Corpus-based methods inspired by the notion of schemata have been explored in the past by Lapata (2003) and Barzilay and Lee (2004) for ordering sentences extracted in a multi-document summarisation application. $$$$$ We also assess the appropriateness of such a model for multidocument summarization.
Corpus-based methods inspired by the notion of schemata have been explored in the past by Lapata (2003) and Barzilay and Lee (2004) for ordering sentences extracted in a multi-document summarisation application. $$$$$ But before we outline the details of our experiments we discuss our choice of metric for comparing different orders.

In this respect, this is similar to work by Lapata (2003), who builds a conditional model of words across adjacent sentences, focusing on words in particular semantic roles. $$$$$ The author was supported by EPSRC grant number R40036.
In this respect, this is similar to work by Lapata (2003), who builds a conditional model of words across adjacent sentences, focusing on words in particular semantic roles. $$$$$ This may be due to the fact that entity-based coherence is not as important as temporal coherence for the news articles summaries.
In this respect, this is similar to work by Lapata (2003), who builds a conditional model of words across adjacent sentences, focusing on words in particular semantic roles. $$$$$ The Cartesian product over the features in Si and Si−1 is an attempt to capture inter-sentential dependencies.
In this respect, this is similar to work by Lapata (2003), who builds a conditional model of words across adjacent sentences, focusing on words in particular semantic roles. $$$$$ This is important for our domain, as texts seem to be rather formulaic and similar syntactic structures are often used (e.g., direct and indirect speech, restrictive relative clauses, predicative structures).

Lapata (2003) has suggested a probabilistic model of text structuring and its application to the sentence ordering. $$$$$ Several improvements can take place with respect to the model.
Lapata (2003) has suggested a probabilistic model of text structuring and its application to the sentence ordering. $$$$$ We evaluate the automatically generated orderings against authored texts from our corpus and against human subjects that are asked to mimic the model’s task.
Lapata (2003) has suggested a probabilistic model of text structuring and its application to the sentence ordering. $$$$$ We describe a model that learns constraints on sentence order from a corpus of domainspecific texts and an algorithm that yields the most likely order among several alternatives.

Even though we could not compare our experiment with the probabilistic approach (Lapata, 2003) directly due to the difference of the text corpora, the Kendall coefficient reported higher agreement than Lapata's experiment (Kendall=0.48 with lemmatized nouns and Kendall=0.56 with verb-noun dependencies). $$$$$ We are grateful to Regina Barzilay and Noemie Elhadad for making available their software and for providing valuable comments on this work.
Even though we could not compare our experiment with the probabilistic approach (Lapata, 2003) directly due to the difference of the text corpora, the Kendall coefficient reported higher agreement than Lapata's experiment (Kendall=0.48 with lemmatized nouns and Kendall=0.56 with verb-noun dependencies). $$$$$ We will therefore estimate P(Si|Si−1) from features that express its structure and content (these features are described in detail in Section 3): where ai,1,ai,2 ...ai,n are features relevant for sentence Si and ai−1,1,ai−1,2 ...ai−1,m for sentence Si−1.
Even though we could not compare our experiment with the probabilistic approach (Lapata, 2003) directly due to the difference of the text corpora, the Kendall coefficient reported higher agreement than Lapata's experiment (Kendall=0.48 with lemmatized nouns and Kendall=0.56 with verb-noun dependencies). $$$$$ Nouns.
Even though we could not compare our experiment with the probabilistic approach (Lapata, 2003) directly due to the difference of the text corpora, the Kendall coefficient reported higher agreement than Lapata's experiment (Kendall=0.48 with lemmatized nouns and Kendall=0.56 with verb-noun dependencies). $$$$$ An ANOVA yielded a significant effect of feature type (F(3,27) = 15.25; p < 0.01).

Lapata (2003) proposed an algorithm that computes the probability of two sentences being adjacent for ordering sentences. $$$$$ We propose an automatic method of evaluating the orders generated by our model by measuring closeness or distance from the gold standard, a collection of orders produced by humans.
Lapata (2003) proposed an algorithm that computes the probability of two sentences being adjacent for ordering sentences. $$$$$ Barzilay et al. (2002) address the problem of information ordering in multidocument summarization and show that naive ordering algorithms such as majority ordering (selects most frequent orders across input documents) and chronological ordering (orders facts according to publication date) do not always yield coherent summaries although the latter produces good results when the information is eventbased.
Lapata (2003) proposed an algorithm that computes the probability of two sentences being adjacent for ordering sentences. $$$$$ So far our evaluation metric measures order similarities or dissimilarities.
Lapata (2003) proposed an algorithm that computes the probability of two sentences being adjacent for ordering sentences. $$$$$ So far our evaluation metric measures order similarities or dissimilarities.

Lapata (2003) employed the probability of two sentences being adjacent as determined from a corpus. $$$$$ The set of orders can be represented as a complete graph, where the set of vertices V is equal to the set of sentences S and each edge u  v has a weight, the probability P(u|v).
Lapata (2003) employed the probability of two sentences being adjacent as determined from a corpus. $$$$$ Ordering information is a critical task for natural language generation applications.
Lapata (2003) employed the probability of two sentences being adjacent as determined from a corpus. $$$$$ Recall that in our case vertices are sentences and their probabilities can be calculated by taking the product of the probabilities of their features.
Lapata (2003) employed the probability of two sentences being adjacent as determined from a corpus. $$$$$ Our results indicate that the model can successfully generate orders for texts taken from the corpus on which it is trained.

As the features, Lapata (2003) proposed the Cartesian product of content words in adjacent sentences. $$$$$ Ordering information is a critical task for natural language generation applications.
As the features, Lapata (2003) proposed the Cartesian product of content words in adjacent sentences. $$$$$ This simplification is reasonable if one has text-to-text generation mind.
As the features, Lapata (2003) proposed the Cartesian product of content words in adjacent sentences. $$$$$ The author was supported by EPSRC grant number R40036.
As the features, Lapata (2003) proposed the Cartesian product of content words in adjacent sentences. $$$$$ We conclude with a discussion in Section 5.
