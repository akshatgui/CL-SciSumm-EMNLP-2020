We used the method of extraction by Ng and Lee (1996) and encoded all keywords in a binary bag of words model. $$$$$ Condition 2 reduces the possibility of selecting a keyword based on spurious occurrence.
We used the method of extraction by Ng and Lee (1996) and encoded all keywords in a binary bag of words model. $$$$$ Improvement in the accuracy of identifying the correct word sense will result in better machine translation systems, information retrieval systems, etc.
We used the method of extraction by Ng and Lee (1996) and encoded all keywords in a binary bag of words model. $$$$$ These are words that are not morphologically inflected, such as &quot;interest&quot; (as opposed to the plural form &quot;interests&quot;), &quot;fall&quot; (as opposed to the other inflected forms like &quot;fell&quot;, &quot;fallen&quot;, &quot;falling&quot;, &quot;falls&quot;), etc.
We used the method of extraction by Ng and Lee (1996) and encoded all keywords in a binary bag of words model. $$$$$ Since WORDNET only provides sense definitions for content words, (i.e., words in the parts of speech (POS) noun, verb, adjective, and adverb), LEXAS is only concerned with disambiguating the sense of content words.

Likewise, (Ng and Lee, 1996) report overall accuracy for the noun interest of 87%, and find that that when their feature set only consists of co-occurrence features the accuracy only drops to 80%. $$$$$ Specifically, LEXAS uses the following set of features to form a training example: L3, L2, L1, R1, R2, R3, M, Ki, • • • , Km, C1, • • • C9, V The value of feature Li is the part of speech (POS) of the word i-th position to the left of w. The value of Ri is the POS of the word i-th position to the right of w. Feature M denotes the morphological form of w in the sentence s. For a noun, the value for this feature is either singular or plural; for a verb, the value is one of infinitive (as in the uninflected form of a verb like &quot;fall&quot;), present-third-person-singular (as in &quot;falls&quot;), past (as in &quot;fell&quot;), present-participle (as in &quot;falling&quot;) or past-participle (as in &quot;fallen&quot;). keywords that frequently co-occur with word w in the same sentence.
Likewise, (Ng and Lee, 1996) report overall accuracy for the noun interest of 87%, and find that that when their feature set only consists of co-occurrence features the accuracy only drops to 80%. $$$$$ There is now a large body of past work on WSD.
Likewise, (Ng and Lee, 1996) report overall accuracy for the noun interest of 87%, and find that that when their feature set only consists of co-occurrence features the accuracy only drops to 80%. $$$$$ When tested on a large, separately collected data set, our program performs better than the default strategy of picking the most frequent sense.
Likewise, (Ng and Lee, 1996) report overall accuracy for the noun interest of 87%, and find that that when their feature set only consists of co-occurrence features the accuracy only drops to 80%. $$$$$ In the output, each word occurrence w is tagged with its correct sense (according to the context) in the form of a sense number i, where i corresponds to the i-th sense definition of w as given in some dictionary.

 $$$$$ For each of the nine collocation features, LEXAS concatenates the words between the left and right offset positions.
 $$$$$ In this paper, we have presented a new approach for WSD using an exemplar based learning algorithm.
 $$$$$ One important problem of Natural Language Processing (NLP) is figuring out what a word means when it is used in a particular context.

 $$$$$ From the training examples formed, the distance between any two values for a feature f is computed based on the above formula.
 $$$$$ To illustrate, when disambiguating the noun &quot;interest&quot;, some of the selected keywords are: expressed, acquiring, great, attracted, expressions, pursue, best, conflict, served, short, minority, rates, rate, bonds, lower, payments.
 $$$$$ LEXAS achieves a higher accuracy on the common data set, and performs better than the most frequent heuristic on the highly ambiguous words in the large corpus tagged with the refined senses of WORDNET.
 $$$$$ We tested our WSD program, named LEXAS, on both a common data set used in previous work, as well as on a large sense-tagged corpus that we separately constructed.

Previous experiments (Ng and Lee, 1996) have explored the relative contribution of different knowledge sources to WSD and have concluded that collocational information is more important than syntactic information. $$$$$ LEXAS achieves a higher accuracy on the common data set, and performs better than the most frequent heuristic on the highly ambiguous words in the large corpus tagged with the refined senses of WORDNET.
Previous experiments (Ng and Lee, 1996) have explored the relative contribution of different knowledge sources to WSD and have concluded that collocational information is more important than syntactic information. $$$$$ If there is a tie among several training examples with the same minimum distance to the test example, LEXAS randomly selects one of these training examples as the closet matching training example in order to break the tie.
Previous experiments (Ng and Lee, 1996) have explored the relative contribution of different knowledge sources to WSD and have concluded that collocational information is more important than syntactic information. $$$$$ This approach integrates a diverse set of knowledge sources to disambiguate word sense, including part of speech (POS) of neighboring words, morphological form, the unordered set of surrounding words, local collocations, and verb-object syntactic relation.

The DSO collection (Ng and Lee, 1996) focuses on 191 frequent and polysemous words (nouns and verbs), and contains around 1,000 sentences per word. $$$$$ The processing speed of LEXAS is satisfactory.
The DSO collection (Ng and Lee, 1996) focuses on 191 frequent and polysemous words (nouns and verbs), and contains around 1,000 sentences per word. $$$$$ Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96% are readily available to assign POS to unrestricted English sentences (Brill, 1992; Cutting et al., 1992).
The DSO collection (Ng and Lee, 1996) focuses on 191 frequent and polysemous words (nouns and verbs), and contains around 1,000 sentences per word. $$$$$ LEXAS follows this convention by first converting each word in an input sentence into its morphological root using the morphological analyzer of WORD NET, before assigning the appropriate word sense to the root form.
The DSO collection (Ng and Lee, 1996) focuses on 191 frequent and polysemous words (nouns and verbs), and contains around 1,000 sentences per word. $$$$$ In contrast, we adopt a different strategy of collecting the training data set.

Exemplar-based method makes use of typical contexts (exemplars) of a word sense, e.g., verb noun collocations or adjective-noun collocations, and identifies the correct sense of a word in a particular context by comparing the context with the exemplars (Ng and Lee, 1996). $$$$$ We compared the classification accuracy of LEXAS against the default strategy of picking the most frequent sense.

Moreover, the effectiveness of this method on disambiguating words in large-scale corpora into fine-grained sense distinctions needs to be further investigated (Ng and Lee, 1996). $$$$$ For example, in machine translation, knowing the correct word sense helps to select the appropriate target words to use in order to translate into a target language.
Moreover, the effectiveness of this method on disambiguating words in large-scale corpora into fine-grained sense distinctions needs to be further investigated (Ng and Lee, 1996). $$$$$ Improvement in the accuracy of identifying the correct word sense will result in better machine translation systems, information retrieval systems, etc.
Moreover, the effectiveness of this method on disambiguating words in large-scale corpora into fine-grained sense distinctions needs to be further investigated (Ng and Lee, 1996). $$$$$ When tested on a common data set, our WSD program gives higher classification accuracy than previous work on WSD.

Hence, besides gathering examples from the widely usedSEMCOR corpus, we also gathered training examples from 6 English-Chinese parallel corpora and the DSO corpus (Ng and Lee, 1996). $$$$$ Moreover, to test the scalability of LEXAS, we have acquired a corpus in which 192,800 word occurrences have been manually tagged with senses from WORDNET, which is a public domain lexical database containing about 95,000 word forms and 70,000 lexical concepts (Miller, 1990).
Hence, besides gathering examples from the widely usedSEMCOR corpus, we also gathered training examples from 6 English-Chinese parallel corpora and the DSO corpus (Ng and Lee, 1996). $$$$$ Since WORDNET only provides sense definitions for content words, (i.e., words in the parts of speech (POS) noun, verb, adjective, and adverb), LEXAS is only concerned with disambiguating the sense of content words.
Hence, besides gathering examples from the widely usedSEMCOR corpus, we also gathered training examples from 6 English-Chinese parallel corpora and the DSO corpus (Ng and Lee, 1996). $$$$$ For each training sentence with an occurrence of w, LEXAS extracts the parts of speech (POS) of words surrounding w, the morphological form of w, the words that frequently co-occur with w in the same sentence, and the local collocations containing w. For disambiguating a noun w, the verb which takes the current noun w as the object is also identified.

Besides SEMCOR, the DSO corpus (Ng and Lee, 1996) also contains manually annotated examples for WSD. $$$$$ In order to evaluate the relative contribution of the knowledge sources, including (1) POS and morphological form; (2) unordered set of surrounding words; (3) local collocations; and (4) verb to the left (verb-object syntactic relation), we conducted 4 separate runs of 100 random trials each.
Besides SEMCOR, the DSO corpus (Ng and Lee, 1996) also contains manually annotated examples for WSD. $$$$$ Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96% are readily available to assign POS to unrestricted English sentences (Brill, 1992; Cutting et al., 1992).
Besides SEMCOR, the DSO corpus (Ng and Lee, 1996) also contains manually annotated examples for WSD. $$$$$ These are words that are not morphologically inflected, such as &quot;interest&quot; (as opposed to the plural form &quot;interests&quot;), &quot;fall&quot; (as opposed to the other inflected forms like &quot;fell&quot;, &quot;fallen&quot;, &quot;falling&quot;, &quot;falls&quot;), etc.
Besides SEMCOR, the DSO corpus (Ng and Lee, 1996) also contains manually annotated examples for WSD. $$$$$ When tested on a large, separately collected data set, our program performs better than the default strategy of picking the most frequent sense.

Our approach to memory-based all-words WSD follows the memory based approach of (Ng and Lee, 1996), and the work by (Veenstra et al, 2000) on a memory based approach to the English lexical sample task of SENSEVAL-1. $$$$$ The choice of which sense definitions to use (and according to which dictionary) is agreed upon in advance.
Our approach to memory-based all-words WSD follows the memory based approach of (Ng and Lee, 1996), and the work by (Veenstra et al, 2000) on a memory based approach to the English lexical sample task of SENSEVAL-1. $$$$$ To our knowledge, this is the first time that a WSD program has been tested on such a large scale, and yielding results better than the most frequent heuristic on highly ambiguous words with the refined senses of WORDNET.
Our approach to memory-based all-words WSD follows the memory based approach of (Ng and Lee, 1996), and the work by (Veenstra et al, 2000) on a memory based approach to the English lexical sample task of SENSEVAL-1. $$$$$ For example, the collocation &quot;in the interest of&quot; always implies the &quot;advantage, advancement, favor&quot; sense of the noun &quot;interest&quot; Note that the method for extraction of keywords that we described earlier will fail to find the words &quot;in&quot;, &quot;the&quot;, &quot;of&quot; as keywords, since these words will appear in many different positions in a sentence for many senses of the noun &quot;interest&quot;.
Our approach to memory-based all-words WSD follows the memory based approach of (Ng and Lee, 1996), and the work by (Veenstra et al, 2000) on a memory based approach to the English lexical sample task of SENSEVAL-1. $$$$$ To our knowledge, this is the first time that a WSD program has been tested on such a large scale, and yielding results better than the most frequent heuristic on highly ambiguous words with the refined senses of WORDNET.

The keywords were selected through a selection method suggested by (Ng and Lee, 1996) within three sentences around the ambiguous word; only content words were used as candidates. $$$$$ This approach integrates a diverse set of knowledge sources to disambiguate word sense.
The keywords were selected through a selection method suggested by (Ng and Lee, 1996) within three sentences around the ambiguous word; only content words were used as candidates. $$$$$ Another assignment method is to determine the most frequently occurring sense in the training sentences, and to assign this sense to all test sentences.
The keywords were selected through a selection method suggested by (Ng and Lee, 1996) within three sentences around the ambiguous word; only content words were used as candidates. $$$$$ The work of (Miller et al., 1994) is the only prior work we know of which attempted to evaluate WSD on a large data set and using the refined sense distinction of WORDNET.
The keywords were selected through a selection method suggested by (Ng and Lee, 1996) within three sentences around the ambiguous word; only content words were used as candidates. $$$$$ No local collocation knowledge is used.

In the following testing phase, a word is classified into senses (Mihalcea, 2002) (Ng and Lee, 1996). $$$$$ LEXAS achieves a mean accuracy of 87.4% on this data set, which is higher than the accuracy of 78% reported in (Bruce and Wiebe, 1994).
In the following testing phase, a word is classified into senses (Mihalcea, 2002) (Ng and Lee, 1996). $$$$$ For every word in the two lists, up to 1,500 sentences each containing an occurrence of the word are extracted from the combined corpus.

This feature set is similar to the one used by (Ngand Lee, 1996), as well as by a number of state-of the-art word sense disambiguation systems participating in the SENSEVAL-2 and SENSEVAL-3evaluations. $$$$$ This approach integrates a diverse set of knowledge sources to disambiguate word sense, including part of speech of neighboring words, morphological form, the unordered set of surrounding words, local collocations, and verb-object syntactic relation.
This feature set is similar to the one used by (Ngand Lee, 1996), as well as by a number of state-of the-art word sense disambiguation systems participating in the SENSEVAL-2 and SENSEVAL-3evaluations. $$$$$ It is only when these words appear in the exact order &quot;in the interest of&quot; around the noun &quot;interest&quot; that strongly implies the &quot;advantage, advancement, favor&quot; sense.
This feature set is similar to the one used by (Ngand Lee, 1996), as well as by a number of state-of the-art word sense disambiguation systems participating in the SENSEVAL-2 and SENSEVAL-3evaluations. $$$$$ There is now a large body of past work on WSD.

The high accuracy of the LEXAS system (Ng and Lee, 1996) is due in part to the use of large corpora. $$$$$ The input to a WSD program consists of unrestricted, real-world English sentences.
The high accuracy of the LEXAS system (Ng and Lee, 1996) is due in part to the use of large corpora. $$$$$ For example, the collocation &quot;in the interest of&quot; always implies the &quot;advantage, advancement, favor&quot; sense of the noun &quot;interest&quot; Note that the method for extraction of keywords that we described earlier will fail to find the words &quot;in&quot;, &quot;the&quot;, &quot;of&quot; as keywords, since these words will appear in many different positions in a sentence for many senses of the noun &quot;interest&quot;.
The high accuracy of the LEXAS system (Ng and Lee, 1996) is due in part to the use of large corpora. $$$$$ However, the work of (Black, 1988; Zernik, 1990; Yarowsky, 1992) were not based on the present set of sentences, so the comparison is only suggestive.
The high accuracy of the LEXAS system (Ng and Lee, 1996) is due in part to the use of large corpora. $$$$$ For a sentence s, the value of feature Ki is one if the keyword Ki appears somewhere in sentence s, else the value of K2 is zero.

The disambiguation is then done using k-NN (Ng and Lee, 1996) where the k nearest neighbors of the test sentence are identified using this scoring function. $$$$$ The classification accuracy of LEXAS is always better than the default strategy of picking the most frequent sense.
The disambiguation is then done using k-NN (Ng and Lee, 1996) where the k nearest neighbors of the test sentence are identified using this scoring function. $$$$$ LEXAS achieves a higher accuracy on the common data set, and performs better than the most frequent heuristic on the highly ambiguous words in the large corpus tagged with the refined senses of WORDNET.
The disambiguation is then done using k-NN (Ng and Lee, 1996) where the k nearest neighbors of the test sentence are identified using this scoring function. $$$$$ However, almost all existing work in WSD deals only with disambiguating content words too.

The idea of using supervised machine learning for WSD is not new and was used for example in (Ng and Lee, 1996). $$$$$ The different meanings of a word are listed as its various senses in a dictionary.
The idea of using supervised machine learning for WSD is not new and was used for example in (Ng and Lee, 1996). $$$$$ Instead of tagging every word in a running text, as is done in SEMCOR, we only concentrate on the set of 191 most frequently occurring and most ambiguous words, and collected large enough training data for these words only.

We report results of comparing our lexicon with theWordNet cousins as well as the inter-annotator disagreement observed between two semantically an notated corpora $$$$$ Since WORDNET only provides sense definitions for content words, (i.e., words in the parts of speech (POS) noun, verb, adjective, and adverb), LEXAS is only concerned with disambiguating the sense of content words.
We report results of comparing our lexicon with theWordNet cousins as well as the inter-annotator disagreement observed between two semantically an notated corpora $$$$$ Since WORDNET only provides sense definitions for content words, (i.e., words in the parts of speech (POS) noun, verb, adjective, and adverb), LEXAS is only concerned with disambiguating the sense of content words.
We report results of comparing our lexicon with theWordNet cousins as well as the inter-annotator disagreement observed between two semantically an notated corpora $$$$$ In contrast, LEXAS learns from tagged sentences, without human engineering of complex rules.

To test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated corpora $$$$$ One important problem of Natural Language Processing (NLP) is figuring out what a word means when it is used in a particular context.
To test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated corpora $$$$$ When tested on this large data set, LEXAS performs better than the default strategy of picking the most frequent sense.
To test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated corpora $$$$$ An example of such a collocation is &quot;in the interest of&quot;.
To test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated corpora $$$$$ The noun &quot;interest&quot; occurs in six different senses in this data set.

The set of features needed for the training of the system is described in figure 1, and is based on the feature selection made by Ng and Lee (1996) and Escudero et al (2000). $$$$$ The different meanings of a word are listed as its various senses in a dictionary.
The set of features needed for the training of the system is described in figure 1, and is based on the feature selection made by Ng and Lee (1996) and Escudero et al (2000). $$$$$ The work of (Bruce and Wiebe, 1994) used parts of speech (POS) and morphological form, in addition to surrounding words.
The set of features needed for the training of the system is described in figure 1, and is based on the feature selection made by Ng and Lee (1996) and Escudero et al (2000). $$$$$ We tested our WSD program, named LEXAS, on both a common data set used in previous work, as well as on a large sense-tagged corpus that we separately constructed.
The set of features needed for the training of the system is described in figure 1, and is based on the feature selection made by Ng and Lee (1996) and Escudero et al (2000). $$$$$ This approach integrates a diverse set of knowledge sources to disambiguate word sense, including part of speech (POS) of neighboring words, morphological form, the unordered set of surrounding words, local collocations, and verb-object syntactic relation.
