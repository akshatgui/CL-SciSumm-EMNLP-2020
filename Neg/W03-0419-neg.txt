For comparison, we also computed two baselines: one in which each character is labeled with its most frequent label (Baseline1 in Table 2), and one in which each entity that was seen in training data is labeled with its most frequent classification (Baseline2 in Table 2 this baseline is computed using the software provided with the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003)). $$$$$ This sentence contains three named entities: Ekeus is a person, U.N. is a organization and Baghdad is a location.
For comparison, we also computed two baselines: one in which each character is labeled with its most frequent label (Baseline1 in Table 2), and one in which each entity that was seen in training data is labeled with its most frequent classification (Baseline2 in Table 2 this baseline is computed using the software provided with the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003)). $$$$$ When a named entity is embedded in another named entity, usually only the top level entity has been annotated.

 $$$$$ The participants were given access to the corpus after some linguistic preprocessing had been done: for all data, a tokenizer, part-of-speech tagger, and a chunker were applied to the raw data.

In addition to the conceptual simplicity of this approach, it also seems to perform better experimentally (Tjong Kim Sang and De Meulder, 2003). $$$$$ The shared task of CoNLL-2003 concerns language-independent named entity recognition.
In addition to the conceptual simplicity of this approach, it also seems to perform better experimentally (Tjong Kim Sang and De Meulder, 2003). $$$$$ Eleven teams have incorporated information other than the training data in their system.

The first source is the CoNLL 2003 shared task date (Tjong Kim Sang and De Meulder, 2003) and the second source is the 2004 NIST Automatic Content Extraction (Weischedel, 2004). $$$$$ There has been a lot of work on named entity recognition, especially for English (see Borthwick (1999) for an overview).
The first source is the CoNLL 2003 shared task date (Tjong Kim Sang and De Meulder, 2003) and the second source is the 2004 NIST Automatic Content Extraction (Weischedel, 2004). $$$$$ De Meulder is supported by a BOF grant supplied by the University of Antwerp.
The first source is the CoNLL 2003 shared task date (Tjong Kim Sang and De Meulder, 2003) and the second source is the 2004 NIST Automatic Content Extraction (Weischedel, 2004). $$$$$ Three systems used Maximum Entropy Models in isolation (Bender et al., 2003; Chieu and Ng, 2003; Curran and Clark, 2003).

Named entities with (Chieu and Ng, 2003), based on Maximum-Entropy classifiers, and following the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003). $$$$$ The Message Understanding Conferences (MUC) have offered developers the opportunity to evaluate systems for English on the same data in a competition.
Named entities with (Chieu and Ng, 2003), based on Maximum-Entropy classifiers, and following the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003). $$$$$ De Meulder is supported by a BOF grant supplied by the University of Antwerp.
Named entities with (Chieu and Ng, 2003), based on Maximum-Entropy classifiers, and following the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003). $$$$$ The participants were given access to the corpus after some linguistic preprocessing had been done: for all data, a tokenizer, part-of-speech tagger, and a chunker were applied to the raw data.
Named entities with (Chieu and Ng, 2003), based on Maximum-Entropy classifiers, and following the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003). $$$$$ They have also produced a scheme for entity annotation (Chinchor et al., 1999).

Supervised NE Tagging has been studied extensively over the past decade (Bikel et al 1999, Baluja et. al. 1999, Tjong Kim Sang and De Meulder 2003). $$$$$ The CoNLL-2003 named entity data consists of eight files covering two languages: English and German1.
Supervised NE Tagging has been studied extensively over the past decade (Bikel et al 1999, Baluja et. al. 1999, Tjong Kim Sang and De Meulder 2003). $$$$$ This sentence contains three named entities: Ekeus is a person, U.N. is a organization and Baghdad is a location.
Supervised NE Tagging has been studied extensively over the past decade (Bikel et al 1999, Baluja et. al. 1999, Tjong Kim Sang and De Meulder 2003). $$$$$ De Meulder is supported by a BOF grant supplied by the University of Antwerp.
Supervised NE Tagging has been studied extensively over the past decade (Bikel et al 1999, Baluja et. al. 1999, Tjong Kim Sang and De Meulder 2003). $$$$$ The shared task of CoNLL-2002 dealt with named entity recognition for Spanish and Dutch (Tjong Kim Sang, 2002).

The annotation is distributed in the standard column based BIO format applied for e.g. CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003) and JNLPBA (Kim et al, 2004) data, among other established datasets. $$$$$ The shared task of CoNLL-2003 concerns language-independent named entity recognition.

The IOB2 strategy, which is very popular, having been used in public challenges such as those of CoNLL (Tjong Kim Sang and De Meulder, 2003) and JNLPBA (Kim et al, 2004), has been found to be indeed the best of all established tagging strategies. $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.
The IOB2 strategy, which is very popular, having been used in public challenges such as those of CoNLL (Tjong Kim Sang and De Meulder, 2003) and JNLPBA (Kim et al, 2004), has been found to be indeed the best of all established tagging strategies. $$$$$ Most of the participants have attempted to use information other than the available training data.
The IOB2 strategy, which is very popular, having been used in public challenges such as those of CoNLL (Tjong Kim Sang and De Meulder, 2003) and JNLPBA (Kim et al, 2004), has been found to be indeed the best of all established tagging strategies. $$$$$ Named entity recognition is an important task of information extraction systems.

Named Entities predicted with the Maximum Entropy based tagger of Chieu and Ng (2003). The tagger follows the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003), and thus is not developed with WSJ data. $$$$$ The portion of data that was used for this task, was extracted from the German newspaper Frankfurter Rundshau.
Named Entities predicted with the Maximum Entropy based tagger of Chieu and Ng (2003). The tagger follows the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003), and thus is not developed with WSJ data. $$$$$ Florian et al. (2003) have also obtained the highest F0=1 rate for the German data.

We benchmark the performance of our baseline MaxEnt classifier using the feature set from Section 5.1 (MaxEnt-A henceforth) on the CoNLL 2003 shared task dataset (Tjong Kim Sang and De Meulder, 2003), the de-facto standard for evaluating coarse-grained NERC systems. $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.
We benchmark the performance of our baseline MaxEnt classifier using the feature set from Section 5.1 (MaxEnt-A henceforth) on the CoNLL 2003 shared task dataset (Tjong Kim Sang and De Meulder, 2003), the de-facto standard for evaluating coarse-grained NERC systems. $$$$$ Four of them have obtained error reductions of 15% or more for English and one has managed this for German.
We benchmark the performance of our baseline MaxEnt classifier using the feature set from Section 5.1 (MaxEnt-A henceforth) on the CoNLL 2003 shared task dataset (Tjong Kim Sang and De Meulder, 2003), the de-facto standard for evaluating coarse-grained NERC systems. $$$$$ Four groups examined the usability of unannotated data, either for extracting training instances (Bender et al., 2003; Hendrickx and Van den Bosch, 2003) or obtaining extra named entities for gazetteers (De Meulder and Daelemans, 2003; McCallum and Li, 2003).
We benchmark the performance of our baseline MaxEnt classifier using the feature set from Section 5.1 (MaxEnt-A henceforth) on the CoNLL 2003 shared task dataset (Tjong Kim Sang and De Meulder, 2003), the de-facto standard for evaluating coarse-grained NERC systems. $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.

This scheme was initially introduced in CoNLL's (Tjong Kim Sang, 2002a) and (Tjong Kim Sang and De Meulder, 2003) NER competitions, and we decided to adapt it for our experimental work. $$$$$ Four of them have obtained error reductions of 15% or more for English and one has managed this for German.
This scheme was initially introduced in CoNLL's (Tjong Kim Sang, 2002a) and (Tjong Kim Sang and De Meulder, 2003) NER competitions, and we decided to adapt it for our experimental work. $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.
This scheme was initially introduced in CoNLL's (Tjong Kim Sang, 2002a) and (Tjong Kim Sang and De Meulder, 2003) NER competitions, and we decided to adapt it for our experimental work. $$$$$ Whenever two entities of type XXX are immediately next to each other, the first word of the second entity will be tagged B-XXX in order to show that it starts another entity.
This scheme was initially introduced in CoNLL's (Tjong Kim Sang, 2002a) and (Tjong Kim Sang and De Meulder, 2003) NER competitions, and we decided to adapt it for our experimental work. $$$$$ The German data was lemmatized, tagged and chunked by the decision tree tagger Treetagger (Schmid, 1995).

Entity tagging has been thoroughly addressed by many statistical machine learning techniques, obtaining greater than 90% F1 on many datasets (Tjong Kim Sang and De Meulder, 2003). $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.
Entity tagging has been thoroughly addressed by many statistical machine learning techniques, obtaining greater than 90% F1 on many datasets (Tjong Kim Sang and De Meulder, 2003). $$$$$ Aff: affix information (n-grams); bag: bag of words; cas: global case information; chu: chunk tags; doc: global document information; gaz: gazetteers; lex: lexical features; ort: orthographic information; pat: orthographic patterns (like Aa0); pos: part-of-speech tags; pre: previously predicted NE tags; quo: flag signing that the word is between quotes; tri: trigger words. with β=1 (Van Rijsbergen, 1975).
Entity tagging has been thoroughly addressed by many statistical machine learning techniques, obtaining greater than 90% F1 on many datasets (Tjong Kim Sang and De Meulder, 2003). $$$$$ The participants of the 2003 shared task have been offered training and test data for two other European languages: English and German.
Entity tagging has been thoroughly addressed by many statistical machine learning techniques, obtaining greater than 90% F1 on many datasets (Tjong Kim Sang and De Meulder, 2003). $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.

We consider the problem of named-entity recognition (NER) and use the English data from the CoNLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003). $$$$$ We have described the CoNLL-2003 shared task: language-independent named entity recognition.
We consider the problem of named-entity recognition (NER) and use the English data from the CoNLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003). $$$$$ They have used the data for developing a named-entity recognition system that includes a machine learning component.
We consider the problem of named-entity recognition (NER) and use the English data from the CoNLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003). $$$$$ Maximum Entropy Models seem to be a good choice for this kind of task: the top three results for English and the top two results for German were obtained by participants who employed them in one way or another.

The ACE data was morphologically annotated with a tokenizer based on manual rules adapted from the one used in CoNLL (Tjong Kim Sang and De Meulder, 2003), with TnT 2.2, a trigram POS tagger based on Markov models (Brants, 2000), and with the built-in WordNet lemmatizer (Fellbaum, 1998). $$$$$ Apart from the training data, this system also employed gazetteers and the output of two externally trained named entity recognizers.
The ACE data was morphologically annotated with a tokenizer based on manual rules adapted from the one used in CoNLL (Tjong Kim Sang and De Meulder, 2003), with TnT 2.2, a trigram POS tagger based on Markov models (Brants, 2000), and with the built-in WordNet lemmatizer (Fellbaum, 1998). $$$$$ The shared task of CoNLL-2003 concerns language-independent named entity recognition.
The ACE data was morphologically annotated with a tokenizer based on manual rules adapted from the one used in CoNLL (Tjong Kim Sang and De Meulder, 2003), with TnT 2.2, a trigram POS tagger based on Markov models (Brants, 2000), and with the built-in WordNet lemmatizer (Fellbaum, 1998). $$$$$ Florian et al. (2003) have also obtained the highest F0=1 rate for the German data.

Finaly, combining models has been a successful way of achieving good results, such as those of Florian et al (2003) who had the top performance in the named entity recognition shared task of CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003). $$$$$ De Meulder is supported by a BOF grant supplied by the University of Antwerp.
Finaly, combining models has been a successful way of achieving good results, such as those of Florian et al (2003) who had the top performance in the named entity recognition shared task of CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003). $$$$$ De Meulder is supported by a BOF grant supplied by the University of Antwerp.
Finaly, combining models has been a successful way of achieving good results, such as those of Florian et al (2003) who had the top performance in the named entity recognition shared task of CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003). $$$$$ The raw data were taken from the months of September to December 1992.

Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ Example: [ORG U.N. ] official [PER Ekeus ] heads for [LOC Baghdad ] .
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ Two more systems used them in combination with other techniques (Florian et al., 2003; Klein et al., 2003).
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ The shared task of CoNLL-2003 concerns language-independent named entity recognition.

All our results for NER are reported on the CoNLL-2003 shared task dataset (Tjong Kim Sangand De Meulder, 2003). $$$$$ De Meulder is supported by a BOF grant supplied by the University of Antwerp.
All our results for NER are reported on the CoNLL-2003 shared task dataset (Tjong Kim Sangand De Meulder, 2003). $$$$$ This tagging scheme is the IOB scheme originally put forward by Ramshaw and Marcus (1995).
All our results for NER are reported on the CoNLL-2003 shared task dataset (Tjong Kim Sangand De Meulder, 2003). $$$$$ A named entity is correct only if it is an exact match of the corresponding entity in the data file.

language newspaper domain (English data set of the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003)). $$$$$ More recently, there have been other system development competitions which dealt with different languages (IREX and CoNLL-2002).
language newspaper domain (English data set of the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003)). $$$$$ The raw data were taken from the months of September to December 1992.
language newspaper domain (English data set of the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003)). $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.

 $$$$$ Systems that employed unannotated data, obtained performance gains around 5%.
 $$$$$ The best performance for both languages has been obtained by a combined learning system that used Maximum Entropy Models, transformation-based learning, Hidden Markov Models as well as robust risk minimization (Florian et al., 2003).
 $$$$$ The best performance for both languages has been obtained by a combined learning system that used Maximum Entropy Models, transformation-based learning, Hidden Markov Models as well as robust risk minimization (Florian et al., 2003).
 $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.

The fourth type, called miscellaneous, was introduced in the CoNLL NER tasks in 2002 (Tjong Kim Sang, 2002) and 2003 (Tjong Kim Sang and De Meulder, 2003), and includes proper names falling outside the three classic types. $$$$$ All data files contain one word per line with empty lines representing sentence boundaries.
The fourth type, called miscellaneous, was introduced in the CoNLL NER tasks in 2002 (Tjong Kim Sang, 2002) and 2003 (Tjong Kim Sang and De Meulder, 2003), and includes proper names falling outside the three classic types. $$$$$ Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.
The fourth type, called miscellaneous, was introduced in the CoNLL NER tasks in 2002 (Tjong Kim Sang, 2002) and 2003 (Tjong Kim Sang and De Meulder, 2003), and includes proper names falling outside the three classic types. $$$$$ More recently, there have been other system development competitions which dealt with different languages (IREX and CoNLL-2002).
