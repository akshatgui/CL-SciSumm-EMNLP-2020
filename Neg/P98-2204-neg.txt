 $$$$$ The phrase &quot;a judge&quot; is brand-new.
 $$$$$ Acknowledgments: This work has been funded by a post-doctoral grant from DFG (Str 545/1-1) and is supported by a post-doctoral fellowship award from IRCS.
 $$$$$ In contrast to the centering model, my model includes a treatment for intrasentential anaphora and is sufficiently well specified to be applied to real texts.
 $$$$$ In Section 4, I compare the results of my algorithm with the results of the centering algorithm (Brennan et al., 1987) with and without specifications for complex sentences (Kameyama, 1998).

According to Nissim et al, their definitions are built upon Prince? s (1981), and the categorization into old, new, and mediated entities resemble those of Strube (1998) and Eckert and Strube (2001). $$$$$ Also Lappin & Leass (1994), who give the subject of the current sentence the highest weight, have an implicit notion of evokedness.
According to Nissim et al, their definitions are built upon Prince? s (1981), and the categorization into old, new, and mediated entities resemble those of Strube (1998) and Eckert and Strube (2001). $$$$$ Future work will address whether the text position, which is the weakest grammatical concept, is sufficient for the order of the elements of the S-list at the second layer of my ranking constraints.
According to Nissim et al, their definitions are built upon Prince? s (1981), and the categorization into old, new, and mediated entities resemble those of Strube (1998) and Eckert and Strube (2001). $$$$$ Utterance (1d) contains one pronoun, utterance (id') two pronouns.

Our model of prominence is a simple local one similar to (Strube, 1998). $$$$$ The S-list ranking criteria define a preference for hearer-old over hearer-new discourse entities (Prince, 1981) generalizing Strube & Hahn's (1996) approach.
Our model of prominence is a simple local one similar to (Strube, 1998). $$$$$ The most highly ranked element of C f (Ui) that is realized in U2-F1 (i.e., is associated with an expression that has a valid interpretation in the underlying semantic representation) is the Cb(Ui+i).
Our model of prominence is a simple local one similar to (Strube, 1998). $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
Our model of prominence is a simple local one similar to (Strube, 1998). $$$$$ Future work will address whether the text position, which is the weakest grammatical concept, is sufficient for the order of the elements of the S-list at the second layer of my ranking constraints.

 $$$$$ I would like to thank Nobo Komagata, Rashmi Prasad, and Matthew Stone who commented on earlier drafts of this paper.
 $$$$$ But she uses the Cb and a ranking over simplified transitions preventing the incremental application of her model.
 $$$$$ Even models which use salience measures for determining the antecedents of pronoun use the concept of evoked discourse entities.
 $$$$$ I propose a model for determining the hearer's attentional state which depends solely on a list of salient discourse entities (S-list).

We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ Walker et al. (1994)) consists of three basic steps: To illustrate this algorithm, we consider example (1) (Brennan et al., 1987) which has two different final utterances (1d) and (1 d').
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ The difference between my algorithm and the BFP-algorithm becomes clearer when the unused discourse entity &quot;Friedman&quot; is replaced by a brandnew discourse entity, e.g., &quot;a professional driver&quot;7 (cf. example (2)).
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ Even models which use salience measures for determining the antecedents of pronoun use the concept of evoked discourse entities.
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ The BFP-algorithm (cf.

Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2) also deals with and even prefers intra sentential anaphora, which raises the upper limit to a more acceptable 80.2%. $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2) also deals with and even prefers intra sentential anaphora, which raises the upper limit to a more acceptable 80.2%. $$$$$ Also Lappin & Leass (1994), who give the subject of the current sentence the highest weight, have an implicit notion of evokedness.
Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2) also deals with and even prefers intra sentential anaphora, which raises the upper limit to a more acceptable 80.2%. $$$$$ I propose a model for determining the hearer's attentional state in understanding discourse.

Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ (2) Test elements of Ui left-to-right.
Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ Hajieova et al. (1992) assign the highest value to an evoked discourse entity.
Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ In (id'), the pronoun &quot;she&quot; is resolved to &quot;Friedman&quot; because SMOOTHSHIFT is preferred over ROUGH-SHIFT.
Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ I propose a model for determining the hearer's attentional state which depends solely on a list of salient discourse entities (S-list).

Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ But she uses the Cb and a ranking over simplified transitions preventing the incremental application of her model.
Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ Because of these ranking criteria, I can account for the difference in salience between definite NPs (mostly hearer-old) and indefinite NPs (mostly hearer-new).
Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ Hajieova et al. (1992) assign the highest value to an evoked discourse entity.
Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ Anaphora resolution is performed with a simple look-up in the S-list3.

Strube (1998)'s S-list algorithm is also restricted to the current and last sentence. $$$$$ For their centering algorithm, Brennan et al. (1987, henceforth BFP-algorithm) extend the notion of centering transition relations, which hold across adjacent utterances, to differentiate types of shift (cf.
Strube (1998)'s S-list algorithm is also restricted to the current and last sentence. $$$$$ Results.
Strube (1998)'s S-list algorithm is also restricted to the current and last sentence. $$$$$ In (2d), the pronoun &quot;she&quot; is resolved to BRENNAN because of the preference for CONTINUE over RETAIN.
Strube (1998)'s S-list algorithm is also restricted to the current and last sentence. $$$$$ Because of these ranking criteria, I can account for the difference in salience between definite NPs (mostly hearer-old) and indefinite NPs (mostly hearer-new).

 $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
 $$$$$ The model is the basis for an algorithm which operates incrementally, word by word.
 $$$$$ In Section 4, I compare the results of my algorithm with the results of the centering algorithm (Brennan et al., 1987) with and without specifications for complex sentences (Kameyama, 1998).
 $$$$$ The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse.

 $$$$$ Incremental processing is not a topic of these papers.
 $$$$$ I do not assume any difference between the elements of each set with respect to their information status.
 $$$$$ I propose a model for determining the hearer's attentional state which depends solely on a list of salient discourse entities (S-list).
 $$$$$ My proposal is inspired by the centering model (Grosz et al., 1983; 1995) and draws on the conclusions of Strube & Hahn's (1996) approach for the ranking of the forward-looking center list for German.

The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ We look at the interpretation of (1d) and (1 d').
The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ Acknowledgments: This work has been funded by a post-doctoral grant from DFG (Str 545/1-1) and is supported by a post-doctoral fellowship award from IRCS.
The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ Also Lappin & Leass (1994), who give the subject of the current sentence the highest weight, have an implicit notion of evokedness.
The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ My algorithm starts with an empty S-list at the beginning of a segment.

We now turn to our method of anaphora resolution, which extends the algorithm presented in Strube (1998), in order to be able to account for discourse deictic anaphora as well as individual anaphora. $$$$$ We look at the interpretation of (1d) and (1 d').
We now turn to our method of anaphora resolution, which extends the algorithm presented in Strube (1998), in order to be able to account for discourse deictic anaphora as well as individual anaphora. $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
We now turn to our method of anaphora resolution, which extends the algorithm presented in Strube (1998), in order to be able to account for discourse deictic anaphora as well as individual anaphora. $$$$$ Future work will address whether the text position, which is the weakest grammatical concept, is sufficient for the order of the elements of the S-list at the second layer of my ranking constraints.

In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ After step 2, the algorithm has produced two readings for each variant which are rated by the corresponding transitions in step 3.
In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ Anaphora resolution is performed with a simple look-up in the S-list3.
In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ In contrast to the centering model, my model includes a treatment for intrasentential anaphora and is sufficiently well specified to be applied to real texts.
In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ Incremental processing is not a topic of these papers.

We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ Grosz et al. (1995) and Brennan et al.
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ Its incremental character seems to be an answer to the question Kehler (1997) recently raised.
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ I showed that my model, though it omits the backward-looking center and the centering transitions, does not lose any of the predictive power of the centering model with respect to anaphora resolution.

Centering theory has also guided the development of pronoun resolution algorithms, such as the BFP algorithm (Brenan, Friedman and Pollard, 1987) and the S-list algorithm developed by Strube (Strube, 1998). $$$$$ Because of these ranking criteria, I can account for the difference in salience between definite NPs (mostly hearer-old) and indefinite NPs (mostly hearer-new).
Centering theory has also guided the development of pronoun resolution algorithms, such as the BFP algorithm (Brenan, Friedman and Pollard, 1987) and the S-list algorithm developed by Strube (Strube, 1998). $$$$$ The pronoun &quot;he&quot; and the possessive pronoun &quot;his&quot; are resolved to CURTIS.
Centering theory has also guided the development of pronoun resolution algorithms, such as the BFP algorithm (Brenan, Friedman and Pollard, 1987) and the S-list algorithm developed by Strube (Strube, 1998). $$$$$ If the analysis of utterance U5 is finished, remove all discourse entities from the S-list, which are not realized in U.
Centering theory has also guided the development of pronoun resolution algorithms, such as the BFP algorithm (Brenan, Friedman and Pollard, 1987) and the S-list algorithm developed by Strube (Strube, 1998). $$$$$ In (2d'), &quot;she&quot; is resolved to DRIVER because SMOOTH-SHIFT is preferred over ROUGH-SHIFT.
