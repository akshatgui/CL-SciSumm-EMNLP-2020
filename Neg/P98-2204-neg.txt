 $$$$$ Its incremental character seems to be an answer to the question Kehler (1997) recently raised.
 $$$$$ Hajieova et al. (1992) assign the highest value to an evoked discourse entity.

According to Nissim et al, their definitions are built upon Prince? s (1981), and the categorization into old, new, and mediated entities resemble those of Strube (1998) and Eckert and Strube (2001). $$$$$ In the BFP-algorithm, the ranking of the Cf-list depends on grammatical roles.
According to Nissim et al, their definitions are built upon Prince? s (1981), and the categorization into old, new, and mediated entities resemble those of Strube (1998) and Eckert and Strube (2001). $$$$$ However, &quot;Mr Curtis&quot; is the left-most evoked phrase in this sentence and therefore the most preferred antecedent for the pronoun &quot;him&quot;.
According to Nissim et al, their definitions are built upon Prince? s (1981), and the categorization into old, new, and mediated entities resemble those of Strube (1998) and Eckert and Strube (2001). $$$$$ The S-list ranking criteria define a preference for hearer-old over hearer-new discourse entities (Prince, 1981) generalizing Strube & Hahn's (1996) approach.

Our model of prominence is a simple local one similar to (Strube, 1998). $$$$$ The ordering among the elements of the S-list covers also the of the center the centering model.
Our model of prominence is a simple local one similar to (Strube, 1998). $$$$$ Its incremental character seems to be an answer to the question Kehler (1997) recently raised.
Our model of prominence is a simple local one similar to (Strube, 1998). $$$$$ I would like to thank Nobo Komagata, Rashmi Prasad, and Matthew Stone who commented on earlier drafts of this paper.

 $$$$$ Therefore, the S-list integrates in the simplest manner preferences for inter- and intrasentential anaphora, making further specifications for processing complex sentences unnecessary.
 $$$$$ The salience weight degrades from one sentence to another by a factor of two which implies that a repeatedly mentioned discourse entity gets a higher weight than a brand-new subject.
 $$$$$ I showed that my model, though it omits the backward-looking center and the centering transitions, does not lose any of the predictive power of the centering model with respect to anaphora resolution.
 $$$$$ The ordering among the elements of the S-list covers also the of the center the centering model.

We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ In contrast to the centering model, my model includes a treatment for intrasentential anaphora and is sufficiently well specified to be applied to real texts.
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ Its incremental character seems to be an answer to the question Kehler (1997) recently raised.
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ I propose a model for determining the hearer's attentional state which depends solely on a list of salient discourse entities (S-list).

Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2) also deals with and even prefers intra sentential anaphora, which raises the upper limit to a more acceptable 80.2%. $$$$$ Utterance (1d) contains one pronoun, utterance (id') two pronouns.
Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2) also deals with and even prefers intra sentential anaphora, which raises the upper limit to a more acceptable 80.2%. $$$$$ Kameyama distinguishes for tensed clauses further between sequential and hierarchical centering.
Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2) also deals with and even prefers intra sentential anaphora, which raises the upper limit to a more acceptable 80.2%. $$$$$ Their approach has been proven as the point of departure for a new model which is valid for English as well.
Strube (1998)'s centering approach (whose sentence ordering is designated as SR2 in Table 2) also deals with and even prefers intra sentential anaphora, which raises the upper limit to a more acceptable 80.2%. $$$$$ The BFP-algorithm (cf.

Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ Table 1 taken from Walker et al. (1994)).
Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ Therefore, the S-list integrates in the simplest manner preferences for inter- and intrasentential anaphora, making further specifications for processing complex sentences unnecessary.
Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ Utterance (1d) contains one pronoun, utterance (id') two pronouns.
Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs. $$$$$ Future work will address whether the text position, which is the weakest grammatical concept, is sufficient for the order of the elements of the S-list at the second layer of my ranking constraints.

Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ Hajieova et al. (1992) assign the highest value to an evoked discourse entity.
Like (Ge et al, 1998), Strube (1998) evaluates on ideal hand annotated data. $$$$$ Future work will address whether the text position, which is the weakest grammatical concept, is sufficient for the order of the elements of the S-list at the second layer of my ranking constraints.

Strube (1998)'s S-list algorithm is also restricted to the current and last sentence. $$$$$ Whenever these linguistic devices are missing, proper names are treated as unusedl .
Strube (1998)'s S-list algorithm is also restricted to the current and last sentence. $$$$$ I restrict inferrables to the particular subset defined by Hahn et al. (1996).
Strube (1998)'s S-list algorithm is also restricted to the current and last sentence. $$$$$ In Section 3, I introduce my model, its only data structure, the S-list, and the accompanying algorithm.

 $$$$$ Table 1 taken from Walker et al. (1994)).
 $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
 $$$$$ The ordering among the elements of the S-list covers also the of the center the centering model.
 $$$$$ In Section 4, I compare the results of my algorithm with the results of the centering algorithm (Brennan et al., 1987) with and without specifications for complex sentences (Kameyama, 1998).

 $$$$$ Because of binding restrictions, &quot;her&quot; cannot be resolved to FRIEDMAN but to the second element, BRENNAN.
 $$$$$ Walker et al. (1994)) consists of three basic steps: To illustrate this algorithm, we consider example (1) (Brennan et al., 1987) which has two different final utterances (1d) and (1 d').
 $$$$$ Therefore &quot;prosecutors&quot; in (3b) is not contained in the S-list.
 $$$$$ Hence, DRIVER is ranked higher than BRENNAN in the Cft2c).

The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ The model has been motivated with evidence from preferences for the antecedents of pronouns (Grosz et al., 1983; 1995) and has been applied to pronoun resolution (Brennan et al. (1987), inter alia, whose interpretation differs from the original model).
The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ With respect to any two discourse entities (x, uttx , pas x) and (y, utty, posy), uttx and utty specifying the current utterance Ui or the preceding utterance U2_1, I set up the following ordering constraints on elements in the S-list (Table 2)2.
The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ Furthermore, it neither has the problem of inconsistency Kehler mentioned with respect to the BFP-algorithm nor does it generate unnecessary ambiguities.
The POS properties could indicate whether a candidate refers to a hearer old entity that would have a higher preference to be selected as the antecedent (Strube, 1998). $$$$$ In both (1d) and (id') the pronoun &quot;she&quot; is resolved to FRIEDMAN.

We now turn to our method of anaphora resolution, which extends the algorithm presented in Strube (1998), in order to be able to account for discourse deictic anaphora as well as individual anaphora. $$$$$ The ordering among the elements of the S-list covers also the of the center the centering model.
We now turn to our method of anaphora resolution, which extends the algorithm presented in Strube (1998), in order to be able to account for discourse deictic anaphora as well as individual anaphora. $$$$$ But she uses the Cb and a ranking over simplified transitions preventing the incremental application of her model.
We now turn to our method of anaphora resolution, which extends the algorithm presented in Strube (1998), in order to be able to account for discourse deictic anaphora as well as individual anaphora. $$$$$ By making the distinction in (2) 'For examples of brand-new proper names and their introduction cf., e.g., the &quot;obituaries&quot; section of the New York Times.
We now turn to our method of anaphora resolution, which extends the algorithm presented in Strube (1998), in order to be able to account for discourse deictic anaphora as well as individual anaphora. $$$$$ The centering model describes the relation between the focus of attention, the choices of referring expressions, and the perceived coherence of discourse.

In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ The most highly ranked element of C f (Ui) that is realized in U2-F1 (i.e., is associated with an expression that has a valid interpretation in the underlying semantic representation) is the Cb(Ui+i).
In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ Future work will address whether the text position, which is the weakest grammatical concept, is sufficient for the order of the elements of the S-list at the second layer of my ranking constraints.
In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ preferred to RETAIN is preferred to SMOOTHSHIFT is preferred to ROUGH-SHIFT.
In addition to the S-List (Strube, 1998), which contains the referents of NPs available for anaphoric reference, our model includes an A-List for abstract objects. $$$$$ In Section 3, I introduce my model, its only data structure, the S-list, and the accompanying algorithm.

We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ Each utterance Ui is assigned a list of forward-looking centers, Cf (Ui), and a unique backward-looking center, Cb(Ui).
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ The ranking criteria for the S-list based on the distinction between entities and incorporate preferences for interand intra-sentential anaphora.
We have compared the obtained results with those obtained by testing bfp (Brennan et al, 1987) and str98 (Strube, 1998). $$$$$ Even models which use salience measures for determining the antecedents of pronoun use the concept of evoked discourse entities.

Centering theory has also guided the development of pronoun resolution algorithms, such as the BFP algorithm (Brenan, Friedman and Pollard, 1987) and the S-list algorithm developed by Strube (Strube, 1998). $$$$$ The salience weight degrades from one sentence to another by a factor of two which implies that a repeatedly mentioned discourse entity gets a higher weight than a brand-new subject.
Centering theory has also guided the development of pronoun resolution algorithms, such as the BFP algorithm (Brenan, Friedman and Pollard, 1987) and the S-list algorithm developed by Strube (Strube, 1998). $$$$$ We look at the interpretation of (1d) and (1 d').
Centering theory has also guided the development of pronoun resolution algorithms, such as the BFP algorithm (Brenan, Friedman and Pollard, 1987) and the S-list algorithm developed by Strube (Strube, 1998). $$$$$ Table 4).
