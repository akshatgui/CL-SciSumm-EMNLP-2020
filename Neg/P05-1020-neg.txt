(Ng, 2005) treats coreference resolution as a problem of ranking candidate partitions generated by a set of coreference systems. $$$$$ We employ as our baseline systems two existing coreference resolvers: our duplication of the Soon et al. (2001) system and the Ng and Cardie (2002b) system.
(Ng, 2005) treats coreference resolution as a problem of ranking candidate partitions generated by a set of coreference systems. $$$$$ Row 6 of Table 3 shows the results (averaged over five runs) when the random ranker is used in place of the supervised ranker.
(Ng, 2005) treats coreference resolution as a problem of ranking candidate partitions generated by a set of coreference systems. $$$$$ Our approach compares favorably to two state-of-the-art coreference systems when evaluated on three standard coreference data sets.
(Ng, 2005) treats coreference resolution as a problem of ranking candidate partitions generated by a set of coreference systems. $$$$$ Optimizing for clustering-level accuracy.

The main difference between this approach and ours is that (Ng, 2005)'s approach takes coreference resolution one step further, by comparing the results of multiple systems, while our system is a single resolver; furthermore, he emphasizes the global optimization of ranking clusters obtained locally, whereas our focus is on globally optimizing the clusterization method inside the resolver. $$$$$ In contrast to the MUC results, the B-CUBED results for the two baseline systems are mixed (see rows 1 and 2 of Table 4).
The main difference between this approach and ours is that (Ng, 2005)'s approach takes coreference resolution one step further, by comparing the results of multiple systems, while our system is a single resolver; furthermore, he emphasizes the global optimization of ranking clusters obtained locally, whereas our focus is on globally optimizing the clusterization method inside the resolver. $$$$$ A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.
The main difference between this approach and ours is that (Ng, 2005)'s approach takes coreference resolution one step further, by comparing the results of multiple systems, while our system is a single resolver; furthermore, he emphasizes the global optimization of ranking clusters obtained locally, whereas our focus is on globally optimizing the clusterization method inside the resolver. $$$$$ Our approach compares favorably to two state-of-the-art coreference systems when evaluated on three standard coreference data sets.

There are many different training example generation algorithms, e.g., McCarthy and Lehnert's method, Soon et als method, Ng and Cardies method (Ng, 2005). $$$$$ Nevertheless, our B-CUBED results suggest that 6The rank of a partition is computed in the same way as in Section 3.2, except that we now adopt the common convention of assigning rank to the -th highest scored partition.
There are many different training example generation algorithms, e.g., McCarthy and Lehnert's method, Soon et als method, Ng and Cardies method (Ng, 2005). $$$$$ If all of our candidate partitions are of very high quality, then ranking will not be particularly important because choosing any of these partitions may yield good results.

Similar to many previous works on co-reference (Ng, 2005), we cast the problem as a classification task and solve it in two steps: (1) train a classifier to determine whether two mentions are co-referent or not, and (2) use a clustering algorithm to partition the mentions into clusters, based on the pairwise predictions. $$$$$ Baseline systems.
Similar to many previous works on co-reference (Ng, 2005), we cast the problem as a classification task and solve it in two steps: (1) train a classifier to determine whether two mentions are co-referent or not, and (2) use a clustering algorithm to partition the mentions into clusters, based on the pairwise predictions. $$$$$ In comparison to the stronger baseline (i.e., N&C), F-measure increases by 7.4, 7.2, and 4.6 for the BNEWS, NPAPER, and NWIRE data sets, respectively.

To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005). $$$$$ Second, by employing a non-uniform penalty function B-CUBED effectively removes a bias inherent in the MUC scorer that leads to under-penalization of partitions in which entities are over-clustered.
To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005). $$$$$ First, while the MUC scorer only rewards correct identification of coreferent links, B-CUBED additionally rewards successful recognition of noncoreference relationships.
To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005). $$$$$ Instead of committing ourselves to a particular resolution method as in previous approaches, our framework makes it possible to leverage the strengths of different methods by allowing them to participate in the generation of candidate partitions.

Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method. $$$$$ For instance, if we 'We still need to determine the coreference systems to be employed in our framework, however.
Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method. $$$$$ At each step of this search process, candidate partitions are ranked based on their heuristically computed scores.

Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. $$$$$ Finally, Strube et al. (2002) and Iida et al.

This could be incorporated in a ranking scheme, as in Ng (2005). $$$$$ In an attempt to gain additional insight into the contribution of partition-based features and method-based features, we train our ranking model using each type of features in isolation.
This could be incorporated in a ranking scheme, as in Ng (2005). $$$$$ To address the first question, we take the 54 coreference systems that were trained on half of the available training texts (see Section 4) and apply them to the three ACE test data sets.
This could be incorporated in a ranking scheme, as in Ng (2005). $$$$$ We consider three previously-proposed methods of creating training instances.
This could be incorporated in a ranking scheme, as in Ng (2005). $$$$$ Our approach.

The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set. $$$$$ At each step of this search process, candidate partitions are ranked based on their heuristically computed scores.
The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set. $$$$$ Our approach compares favorably to two state-of-the-art coreference systems when evaluated on three standard coreference data sets.
The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set. $$$$$ Although we are not aware of any previous attempt on training a ranking model using global features of an NP partition, there is some related work on partition ranking where the score of a partition is computed via a heuristic function of the probabilities of its NP pairs being coreferent.2 For instance, Harabagiu et al. (2001) introduce a greedy algorithm for finding the highest-scored partition by performing a beam search in the space of possible partitions.
The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set. $$$$$ In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems.

 $$$$$ Our approach compares favorably to two state-of-the-art coreference systems when evaluated on three standard coreference data sets.
 $$$$$ To this end, we compute the rank of each candidate partition as follows.
 $$$$$ If this set is empty, then no antecedent is selected for NP✁ .

 $$$$$ Our approach compares favorably to two state-of-the-art coreference systems when evaluated on three standard coreference data sets.
 $$$$$ Instead of committing ourselves to a particular resolution method as in previous approaches, our framework makes it possible to leverage the strengths of different methods by allowing them to participate in the generation of candidate partitions.
 $$$$$ In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems.

MUC and B3 metrics (Ng, 2005a). $$$$$ A separate clustering mechanism then coordinates the possibly contradictory pairwise coreference classification decisions and constructs a partition on the given set of NPs, with one cluster for each set of coreferent NPs.
MUC and B3 metrics (Ng, 2005a). $$$$$ Two questions naturally arise after examining the above results.

Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using rerankers. $$$$$ The feature value is 1 if the corresponding coreference system generated the candidate partition and 0 otherwise.
Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using rerankers. $$$$$ (2002), Yang et al. (2003), Luo et al.
Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using rerankers. $$$$$ The central idea behind the majority of these learningbased approaches is to recast coreference resolution as a binary classification task.

A third global approach is offered by Ng (2005), who proposes a global reranking over partitions generated by different coreference systems. $$$$$ (2004)).
A third global approach is offered by Ng (2005), who proposes a global reranking over partitions generated by different coreference systems. $$$$$ In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems.
A third global approach is offered by Ng (2005), who proposes a global reranking over partitions generated by different coreference systems. $$$$$ Next, for each and , we create two partitionbased features, and would denote the probability that two NPs residing in the same cluster have incompatible gender values.

Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al (2006) who use a probabilistic first-order logic model. $$$$$ Previous attempts on bootstrapping coreference classifiers have only been mildly successful (e.g., M¨uller et al. (2002)), and this is also an area that deserves further research.
Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al (2006) who use a probabilistic first-order logic model. $$$$$ Our goal in this paper is to improve the robustness of the standard approach by addressing the above weaknesses.

Similarly, the method of (Ng, 2005) ranks base models according to their performance on separate tuning set, and then uses the highest-ranked base model for predicting on test documents. $$$$$ The results with respect to B-CUBED are mixed, however.
Similarly, the method of (Ng, 2005) ranks base models according to their performance on separate tuning set, and then uses the highest-ranked base model for predicting on test documents. $$$$$ Feature contribution.
Similarly, the method of (Ng, 2005) ranks base models according to their performance on separate tuning set, and then uses the highest-ranked base model for predicting on test documents. $$$$$ In the latter case we may have less data for training coreference classifiers, but at the same time we can employ weakly supervised techniques to bootstrap the classifiers.

The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure ranging in 50-60% for the same data set. $$$$$ We employ as our baseline systems two existing coreference resolvers: our duplication of the Soon et al. (2001) system and the Ng and Cardie (2002b) system.
The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure ranging in 50-60% for the same data set. $$$$$ Row 6 of Table 3 shows the results (averaged over five runs) when the random ranker is used in place of the supervised ranker.
The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure ranging in 50-60% for the same data set. $$$$$ Optimizing for clustering-level accuracy.

According to Ng (2005), most learning based coreference systems can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions. $$$$$ Feature sets.
According to Ng (2005), most learning based coreference systems can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions. $$$$$ Instead of committing ourselves to a particular resolution method as in previous approaches, our framework makes it possible to leverage the strengths of different methods by allowing them to participate in the generation of candidate partitions.

This strategy has been described as best-first clustering by Ng (2005). $$$$$ From row 3 of Table 4, we see that our approach achieves small but consistent improvements in F-measure over both baseline systems.
This strategy has been described as best-first clustering by Ng (2005). $$$$$ Second, by employing a non-uniform penalty function B-CUBED effectively removes a bias inherent in the MUC scorer that leads to under-penalization of partitions in which entities are over-clustered.
This strategy has been described as best-first clustering by Ng (2005). $$$$$ Feature contribution.

In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning. $$$$$ Perfect ranking.
In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning. $$$$$ Another potential weakness of this approach concerns its inability to directly optimize for clusteringlevel accuracy: the coreference classifier is trained and optimized independently of the clustering procedure to be used, and hence improvements in classification accuracy do not guarantee corresponding improvements in clustering-level accuracy.
In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning. $$$$$ Although we are not aware of any previous attempt on training a ranking model using global features of an NP partition, there is some related work on partition ranking where the score of a partition is computed via a heuristic function of the probabilities of its NP pairs being coreferent.2 For instance, Harabagiu et al. (2001) introduce a greedy algorithm for finding the highest-scored partition by performing a beam search in the space of possible partitions.
