In our experiments, we implement the feature-enriched tree kernel by extending the SVMlight (Joachims, 1998) with the proposed tree kernel function (Moschitti, 2004). $$$$$ F”give”,”IN”.
In our experiments, we implement the feature-enriched tree kernel by extending the SVMlight (Joachims, 1998) with the proposed tree kernel function (Moschitti, 2004). $$$$$ The simplest mapping that we can apply is O(Fz) = z� = (z1,..., zn) where zi = 1 if fi E Fz otherwise zi = 0, i.e. the characteristic vector of the set Fz with respect to F. If we choose as a kernel function the scalar product we obtain the linear kernel KL(Fx, Fz) = x�· z.
In our experiments, we implement the feature-enriched tree kernel by extending the SVMlight (Joachims, 1998) with the proposed tree kernel function (Moschitti, 2004). $$$$$ Finally, Section 5 summarizes the conclusions.
In our experiments, we implement the feature-enriched tree kernel by extending the SVMlight (Joachims, 1998) with the proposed tree kernel function (Moschitti, 2004). $$$$$ It is worth noting that the allowed sub-trees contain the entire (not partial) production rules.

The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ Support Vector Machines (SVMs), using a combination of such kernels and the flat feature kernel, classify Prop- Bank predicate arguments with accuracy higher the current argument classification state- Additionally, experiments on FrameNet data have shown that SVMs are appealing for the classification of semantic roles even if the proposed kernels do not produce any improvement.
The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ For example, the Parse Tree Path feature represents the path in the parse-tree between a predicate node and one of its argument nodes.
The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ Two pairs <p1, a1> and <p2, a2> have two different Path features even if the paths differ only for a node in the parse-tree.
The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ It is worth noting that in the experiments we used the gold standard parsing from Penn TreeBank, thus our kernel structures are derived with high precision.

 $$$$$ For instance, the sub-tree [NP [D a]] is excluded from the set of the Figure 4 since only a part of the production NP —* D N is used in its generation.
 $$$$$ As a consequence they would not be included in the parse-tree kernel of the sentence.
 $$$$$ The results have shown that: First, SVMs using the above kernels are appealing for semantically parsing both corpora.
 $$$$$ For example, SCF improves (a) the classification state-of-theart (i.e. the polynomial kernel) of about 3 percent points and (b) the best literature result of about 5 percent points.

We used support vector machines (Vapnik, 1995) with (a) polynomial kernels to learn the semantic role classification and (b) Tree Kernels (Moschitti, 2004) for learning both frame and ILC classification. $$$$$ Frame elements or semantic roles are arguments of predicates called target words.
We used support vector machines (Vapnik, 1995) with (a) polynomial kernels to learn the semantic role classification and (b) Tree Kernels (Moschitti, 2004) for learning both frame and ILC classification. $$$$$ The classification performances were evaluated using the f1 measure7 for single arguments and the accuracy for the final multi-class classifier.

 $$$$$ However, this constraint does not apply to the production VP —* V NP PP along with the fragment [VP [V NP]] as the subtree [VP [PP [...]]] is not considered part of the semantic structure.
 $$$$$ FrameNet also describes predicate/argument structures but for this purpose it uses richer semantic structures called frames.
 $$$$$ In particular, these problems affect the processing of predicate argument structures annotated in PropBank (Kingsbury and Palmer, 2002) or FrameNet (Fillmore, 1982).

The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ In order to evaluate K((Fx), (Fz)) without evaluating the feature vector x and z we define the indicator function Ii(n) = 1 if the substructure i is rooted at node n and 0 otherwise.
The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ In this paper we have designed and experimented novel convolution kernels for automatic classification of predicate arguments.
The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ To process PAF and SCF, we implemented our own kernels and we used them inside SVM-light.
The kernel that we employed in our experiments is based on the SCF structure devised in (Moschitti, 2004). $$$$$ This suggests that SCF should be used in conjunction with standard features to boost their classification performance.

 $$$$$ This suggests that SCF should be used in conjunction with standard features to boost their classification performance.
 $$$$$ It is worth noting that in the experiments we used the gold standard parsing from Penn TreeBank, thus our kernel structures are derived with high precision.
 $$$$$ Nevertheless, SCF may allow the learning algorithm to detect the active/passive form of verbs.

As shown in (Moschitti, 2004), we can label semantic roles by classifying the smallest subtree that includes the predicate with one of its arguments, i.e. the so called PAF structure. $$$$$ F”give”,”IN”.
As shown in (Moschitti, 2004), we can label semantic roles by classifying the smallest subtree that includes the predicate with one of its arguments, i.e. the so called PAF structure. $$$$$ In Section 3 we present our kernels whereas in Section 4 we show comparative results among SVMs using standard features and the proposed kernels.
As shown in (Moschitti, 2004), we can label semantic roles by classifying the smallest subtree that includes the predicate with one of its arguments, i.e. the so called PAF structure. $$$$$ In particular, our kernels aim to (a) represent the relation between predicate and one of its arguments and (b) to capture the overall argument structure of the target predicate.
As shown in (Moschitti, 2004), we can label semantic roles by classifying the smallest subtree that includes the predicate with one of its arguments, i.e. the so called PAF structure. $$$$$ Given a sentence in natural language and the target predicates, all arguments have to be recognized.

 $$$$$ Their common characteristic is the adoption of feature spaces that model predicate-argument structures in a flat representation.
 $$$$$ Other studies may relate to the use of SCF to generate verb clusters.
 $$$$$ Another function which is the current stateof-the-art of predicate argument classification is the polynomial kernel: Kp(Fx, Fz) = (c+x·z-)d, where c is a constant and d is the degree of the polynom.
 $$$$$ Note that each predicate/argument pair is associated with only one structure, i.e.

For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). $$$$$ On the contrary, convolution kernels aim to capture structural information in term of sub-structures, providing a viable alternative to flat features.
For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). $$$$$ The classical solution adopted for such tasks is to convert syntax structures into flat feature representations which are suitable for a given learning model.
For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). $$$$$ Finally, an analysis of SVMs using polynomial kernels over standard features has explained why they largely outperform linear classifiers based-on standard features.
For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). $$$$$ In particular, these problems affect the processing of predicate argument structures annotated in PropBank (Kingsbury and Palmer, 2002) or FrameNet (Fillmore, 1982).

In (Moschitti, 2004), an alternative to the SCF extraction was proposed, i.e. the SCF kernel (SK). $$$$$ Support Vector Machines (SVMs), using a combination of such kernels and the flat feature kernel, classify Prop- Bank predicate arguments with accuracy higher the current argument classification state- Additionally, experiments on FrameNet data have shown that SVMs are appealing for the classification of semantic roles even if the proposed kernels do not produce any improvement.
In (Moschitti, 2004), an alternative to the SCF extraction was proposed, i.e. the SCF kernel (SK). $$$$$ Figure 1 shows an example of a predicate annotation in PropBank for the sentence: &quot;Paul gives a lecture in Rome&quot;.
In (Moschitti, 2004), an alternative to the SCF extraction was proposed, i.e. the SCF kernel (SK). $$$$$ It is worth noting that the difference between linear and polynomial kernel is about 3-4 percent points for both PropBank and FrameNet.

A preliminary study on the benefit of such kernels was measured on the classification accuracy of semantic arguments in (Moschitti, 2004). $$$$$ In this vision the learning will be carried out on a set of structural features instead of a set of flat features.

The convolution kernel that we have experimented was devised in (Moschitti, 2004) and is characterized by two aspects $$$$$ This provides the classification algorithm with important clues about the possible set of arguments suited for the target syntactic structure.
The convolution kernel that we have experimented was devised in (Moschitti, 2004) and is characterized by two aspects $$$$$ FrameNet also describes predicate/argument structures but for this purpose it uses richer semantic structures called frames.

The evaluations were carried out with the SVMlight-TK software (Moschitti, 2004) available at http $$$$$ In this paper, we have experimented with SVMs using the two novel convolution kernels PAF and SCF which are designed for the semantic structures derived from PropBank and FrameNet corpora.
The evaluations were carried out with the SVMlight-TK software (Moschitti, 2004) available at http $$$$$ Frame elements or semantic roles are arguments of predicates called target words.
The evaluations were carried out with the SVMlight-TK software (Moschitti, 2004) available at http $$$$$ Their main property is the ability to process structured representations.
The evaluations were carried out with the SVMlight-TK software (Moschitti, 2004) available at http $$$$$ In this case, the kernel function aims to cluster together verbal predicates which have the same syntactic realizations.

Here we use the same convolution parse tree kernel as described in Collins and Duffy (2001) for syntactic parsing and Moschitti (2004) for semantic role labeling. $$$$$ A predicate may be a verb or a noun or an adjective and most of the time Arg 0 is the logical subject, Arg 1 is the logical object and ArgM may indicate locations, as in our example.
Here we use the same convolution parse tree kernel as described in Collins and Duffy (2001) for syntactic parsing and Moschitti (2004) for semantic role labeling. $$$$$ Given a vector space in Rn and a set of positive and negative points, SVMs classify vectors according to a separating hyperplane, H(x) = w�x x�+ b = 0, where w� E Rn and b E Rare learned by applying the Structural Risk Minimization principle (Vapnik, 1995).
Here we use the same convolution parse tree kernel as described in Collins and Duffy (2001) for syntactic parsing and Moschitti (2004) for semantic role labeling. $$$$$ On the contrary, SCF lacks important information, thus, alone it may be used only to classify verbs in syntactic categories.
Here we use the same convolution parse tree kernel as described in Collins and Duffy (2001) for syntactic parsing and Moschitti (2004) for semantic role labeling. $$$$$ It is expressed as a sequence of nonterminal labels linked by direction symbols (up or down), e.g. in Figure 1, VTVPINP is the path between the predicate to give and the argument 1, a lecture.

In our implementation, we use the binary SVMLight (Joachims, 1998) and Tree Kernel Tools (Moschitti, 2004). $$$$$ Finally, the FrameNet results are completely different.
In our implementation, we use the binary SVMLight (Joachims, 1998) and Tree Kernel Tools (Moschitti, 2004). $$$$$ In this way, an individual ONE-vs-ALL classifier for each argument i can be trained.

For all trees we first extract their Path Enclosed Tree, which is the smallest common subtree that contains the two target entities (Moschitti, 2004). $$$$$ In case the node a exactly covers Paul, a lecture or in Rome, it will be a positive instance otherwise it will be a negative one, e.g.
For all trees we first extract their Path Enclosed Tree, which is the smallest common subtree that contains the two target entities (Moschitti, 2004). $$$$$ Finally, the FrameNet results are completely different.
For all trees we first extract their Path Enclosed Tree, which is the smallest common subtree that contains the two target entities (Moschitti, 2004). $$$$$ For example, Cause and Agent semantic roles have identical syntactic realizations.
For all trees we first extract their Path Enclosed Tree, which is the smallest common subtree that contains the two target entities (Moschitti, 2004). $$$$$ Phrase Type, Predicate Word, Head Word, Governing Category, Position and Voice.

Moschitti (2004) and Che et al (2006) used a convolution tree kernel (Collins and Duffy, 2001) for semantic role classification. $$$$$ In this paper we have designed and experimented novel convolution kernels for automatic classification of predicate arguments.
Moschitti (2004) and Che et al (2006) used a convolution tree kernel (Collins and Duffy, 2001) for semantic role classification. $$$$$ Second, PAF and SCF can be used to improve automatic classification of PropBank arguments as they provide clues about the predicate argument structure of the target verb.
Moschitti (2004) and Che et al (2006) used a convolution tree kernel (Collins and Duffy, 2001) for semantic role classification. $$$$$ In (Collins and Duffy, 2002), it has been shown that i Ii(nx)Ii(nz) = A(nx, nz) can be computed in O(JNxJ x INzI) by the following recursive relation: guments, cannot be included one in the other.
Moschitti (2004) and Che et al (2006) used a convolution tree kernel (Collins and Duffy, 2001) for semantic role classification. $$$$$ The results have shown that: First, SVMs using the above kernels are appealing for semantically parsing both corpora.

Of special interest here, Moschitti (2004) proposed Predicate Argument Feature (PAF) kernel for SRL under the framework of convolution tree kernel. $$$$$ For example, Figure 4 shows that structures such as [VP [V] [NP]], [VP [V delivers ] [NP]] and [VP [V] [NP [DT] [N]]] are valid features, but these fragments (and many others) are not generated by a complete production, i.e.
Of special interest here, Moschitti (2004) proposed Predicate Argument Feature (PAF) kernel for SRL under the framework of convolution tree kernel. $$$$$ This problem can be divided into two subtasks: (a) the detection of the argument boundaries, i.e. all its compounding words and (b) the classification of the argument type, e.g.
Of special interest here, Moschitti (2004) proposed Predicate Argument Feature (PAF) kernel for SRL under the framework of convolution tree kernel. $$$$$ Without loss of generality we can assume: (a) Voice=1 if active and 0 if passive, and (b) Position=1 when the argument is after the predicate and 0 otherwise.
Of special interest here, Moschitti (2004) proposed Predicate Argument Feature (PAF) kernel for SRL under the framework of convolution tree kernel. $$$$$ Third, additional work is needed to design kernels suitable to learn the deep semantic contained in FrameNet as it seems not sensible to both PAF and SCF information.

In our implementation, we use the binary SVMLight (Joachims, 1998) and modify the Tree Kernel Tools (Moschitti, 2004) to a grammar driven one. $$$$$ In order to solve this problem we define the SubCategorization Feature (SCF).
In our implementation, we use the binary SVMLight (Joachims, 1998) and modify the Tree Kernel Tools (Moschitti, 2004) to a grammar driven one. $$$$$ In this way, an individual ONE-vs-ALL classifier for each argument i can be trained.
In our implementation, we use the binary SVMLight (Joachims, 1998) and modify the Tree Kernel Tools (Moschitti, 2004) to a grammar driven one. $$$$$ In this vision the learning will be carried out on a set of structural features instead of a set of flat features.
In our implementation, we use the binary SVMLight (Joachims, 1998) and modify the Tree Kernel Tools (Moschitti, 2004) to a grammar driven one. $$$$$ Finally, an analysis of SVMs using polynomial kernels over standard features has explained why they largely outperform linear classifiers based-on standard features.
