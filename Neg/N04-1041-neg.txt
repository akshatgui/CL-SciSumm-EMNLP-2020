We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004). $$$$$ 2003).
We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004). $$$$$ The current state of the art discovers many semantic classes but fails to label their concepts.
We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004). $$$$$ This research was partly supported by NSF grant #EIA-0205111.
We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004). $$$$$ This may lead to better answer selections.

Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ Moreover, once such knowledge is discovered, mechanisms must be in place to enrich current ontologies with this new knowledge.
Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ Out of the 1432 noun concepts, we were unable to name 21 (1.5%) of them.
Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ This may lead to better answer selections.
Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc.

Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC. $$$$$ Table 1 shows the first 10 randomly selected concepts (each concept is represented by three of its committee members).
Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC. $$$$$ Two judges annotated two random samples of 100 relationships: one from all 159,000 hyponyms and one from the subset of 65,000 proper nouns.
Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC. $$$$$ For each instance, the judges were asked to decide whether the hyponym relationship was correct, partially correct or incorrect.
Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC. $$$$$ Their classes consist of clustered instances like the three shown below: A limitation of these concepts is that CBC does not discover their actual names.

These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships. $$$$$ For each name, we asked the judges to assign a score of correct, partially correct, or incorrect.
These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships. $$$$$ Experimental results are presented in Section 4 and finally, we conclude with a discussion and future work.
These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships. $$$$$ That is, CBC discovers a semantic class of Canadian provinces such as Manitoba, Alberta, and Ontario, but stops short of labeling the concept as Canadian Provinces.
These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships. $$$$$ We counted how many of the 179 questions had a correct answer returned in the top-1 and top-100 passages.

The syntactical co-occurrence approach has worst-case time complexity O (n2k), where n is the number of words in the corpus and k is the feature space (Pantel and Ravichandran 2004). $$$$$ The highest scoring term is the name of the class.
The syntactical co-occurrence approach has worst-case time complexity O (n2k), where n is the number of words in the corpus and k is the feature space (Pantel and Ravichandran 2004). $$$$$ A committee is a set of representative elements that unambiguously describe the members of a possible class.
The syntactical co-occurrence approach has worst-case time complexity O (n2k), where n is the number of words in the corpus and k is the feature space (Pantel and Ravichandran 2004). $$$$$ First, they often contain rare senses.
The syntactical co-occurrence approach has worst-case time complexity O (n2k), where n is the number of words in the corpus and k is the feature space (Pantel and Ravichandran 2004). $$$$$ Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc.

Like Chambers and Jurafsky, we also used the discounting method suggested by Pantel and Ravichandran (2004) for low frequency observations. $$$$$ We selected the 179 questions from the QA track of TREC-2003 that had an explicit semantic answer type (e.g.
Like Chambers and Jurafsky, we also used the discounting method suggested by Pantel and Ravichandran (2004) for low frequency observations. $$$$$ Their classes consist of clustered instances like the three shown below: A limitation of these concepts is that CBC does not discover their actual names.
Like Chambers and Jurafsky, we also used the discounting method suggested by Pantel and Ravichandran (2004) for low frequency observations. $$$$$ In the top-1 category, the performance improved by 20%.
Like Chambers and Jurafsky, we also used the discounting method suggested by Pantel and Ravichandran (2004) for low frequency observations. $$$$$ The authors wish to thank the reviewers for their helpful comments.

Pantel and Ravichandran (2004) addressed the more specific task of labelling a semantic class by applying Hearst-style lexico-semantic patterns to each member of that class. $$$$$ We compared the passages returned by the passage retrieval module with and without the semantic indexing.
Pantel and Ravichandran (2004) addressed the more specific task of labelling a semantic class by applying Hearst-style lexico-semantic patterns to each member of that class. $$$$$ Of the 1432 noun concepts discovered by CBC, our system labelled 98.5% of them with an NRR score of 77.1% in a human evaluation.
Pantel and Ravichandran (2004) addressed the more specific task of labelling a semantic class by applying Hearst-style lexico-semantic patterns to each member of that class. $$$$$ Semantic extraction tasks are notoriously difficult to evaluate for recall.

Pantel and Ravichandran (2004) have used a method that is not related to query expansion, but yet very related to our work. $$$$$ Of course, it is a serious open question how many names each cluster (concept) should have, and how good each name is.
Pantel and Ravichandran (2004) have used a method that is not related to query expansion, but yet very related to our work. $$$$$ This research was partly supported by NSF grant #EIA-0205111.
Pantel and Ravichandran (2004) have used a method that is not related to query expansion, but yet very related to our work. $$$$$ Using sets of representative elements called committees, CBC discovers cluster centroids that unambiguously describe the members of a possible class.
Pantel and Ravichandran (2004) have used a method that is not related to query expansion, but yet very related to our work. $$$$$ We propose an algorithm labeling semantic and for leveraging them to extract relationships using a top-down approach.

 $$$$$ Without being able to automatically name a cluster and extract hyponym/hypernym relationships, the utility of automatically generated clusters or manually compiled lists of terms is limited.
 $$$$$ If the word wave occurred in this context, then the context is a feature of wave.
 $$$$$ The higher the performance of the passage retrieval module, the higher will be the performance of the answer pinpointing module.
 $$$$$ Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc.

Lin et al (2003) and Pantel and Ravichandran (2004) have proposed to classify the output of systems based on feature vectors using lexico-syntactic patterns, respectively in order to remove antonyms from a related words list and to name clusters of related terms. $$$$$ Phase II then uses these features to compute grammatical signatures of concepts using the CBC algorithm.
Lin et al (2003) and Pantel and Ravichandran (2004) have proposed to classify the output of systems based on feature vectors using lexico-syntactic patterns, respectively in order to remove antonyms from a related words list and to name clusters of related terms. $$$$$ We therefore multiply mief with the following discounting factor: n m where n is the number of words and N = cef Ã— By averaging the feature vectors of the committee members of a particular semantic class, we obtain a grammatical template, or signature, for that class.
Lin et al (2003) and Pantel and Ravichandran (2004) have proposed to classify the output of systems based on feature vectors using lexico-syntactic patterns, respectively in order to remove antonyms from a related words list and to name clusters of related terms. $$$$$ Phase II then uses these features to compute grammatical signatures of concepts using the CBC algorithm.
Lin et al (2003) and Pantel and Ravichandran (2004) have proposed to classify the output of systems based on feature vectors using lexico-syntactic patterns, respectively in order to remove antonyms from a related words list and to name clusters of related terms. $$$$$ In Section 4.1, we describe how we obtain these features.

We also adopt the 'discount score' to penalize low occuring words (Pantel and Ravichandran, 2004). $$$$$ Our method begins to address this thorny issue by quantifying the name assigned to a class and by simultaneously assigning a number that can be interpreted to reflect the strength of membership of each element to the class.
We also adopt the 'discount score' to penalize low occuring words (Pantel and Ravichandran, 2004). $$$$$ Passage retrieval is used in QA to supply relevant information to an answer pinpointing module.
We also adopt the 'discount score' to penalize low occuring words (Pantel and Ravichandran, 2004). $$$$$ WordNet also contains a very poor coverage of proper nouns.

Few recent attempts on related (though different) tasks were made to classify (Lin et al, 2003) and label (Pantel and Ravichandran, 2004) distributional similarity output using lexical-syntactic patterns, in a pipeline architecture. $$$$$ We propose an algorithm labeling semantic and for leveraging them to extract relationships using a top-down approach.
Few recent attempts on related (though different) tasks were made to classify (Lin et al, 2003) and label (Pantel and Ravichandran, 2004) distributional similarity output using lexical-syntactic patterns, in a pipeline architecture. $$$$$ Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc.
Few recent attempts on related (though different) tasks were made to classify (Lin et al, 2003) and label (Pantel and Ravichandran, 2004) distributional similarity output using lexical-syntactic patterns, in a pipeline architecture. $$$$$ For each concept, we added to the list of names a human generated name (obtained from an annotator looking at only the concept instances).
Few recent attempts on related (though different) tasks were made to classify (Lin et al, 2003) and label (Pantel and Ravichandran, 2004) distributional similarity output using lexical-syntactic patterns, in a pipeline architecture. $$$$$ Our system shows small gains in the performance of the IR output.

First, instead of separately addressing the tasks of collecting unlabeled sets of instances (Lin, 1998), assigning appropriate class labels to a given set of instances (Pantel and Ravichandran, 2004), and identifying relevant attributes for a given set of classes (Pasca, 2007), our integrated method from Section 2 enables the simultaneous extraction of class instances, associated labels and attributes. $$$$$ On a subset of 65,000 proper names, our performance was 81.5%.
First, instead of separately addressing the tasks of collecting unlabeled sets of instances (Lin, 1998), assigning appropriate class labels to a given set of instances (Pantel and Ravichandran, 2004), and identifying relevant attributes for a given set of classes (Pasca, 2007), our integrated method from Section 2 enables the simultaneous extraction of class instances, associated labels and attributes. $$$$$ Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc.
First, instead of separately addressing the tasks of collecting unlabeled sets of instances (Lin, 1998), assigning appropriate class labels to a given set of instances (Pantel and Ravichandran, 2004), and identifying relevant attributes for a given set of classes (Pasca, 2007), our integrated method from Section 2 enables the simultaneous extraction of class instances, associated labels and attributes. $$$$$ Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc.

Given pre-existing sets of instances, (Pantel and Ravichandran, 2004) investigates the task of acquiring appropriate class labels to the sets from unstructured text. $$$$$ The authors wish to thank the reviewers for their helpful comments.
Given pre-existing sets of instances, (Pantel and Ravichandran, 2004) investigates the task of acquiring appropriate class labels to the sets from unstructured text. $$$$$ This research was partly supported by NSF grant #EIA-0205111.
Given pre-existing sets of instances, (Pantel and Ravichandran, 2004) investigates the task of acquiring appropriate class labels to the sets from unstructured text. $$$$$ This is potentially a significant step away from traditional all-or-nothing semantic/ontology representations to a concept representation scheme that is more nuanced and admits multiple names and graded set memberships.

In (Pantel and Ravichandran, 2004), given a collection of news articles that is both cleaner and smaller than Web document collections, a syntactic parser is applied to document sentences in order to identify and exploit syntactic dependencies for the purpose of selecting candidate class labels. $$$$$ Some applications such as question answering would benefit from class labels.
In (Pantel and Ravichandran, 2004), given a collection of news articles that is both cleaner and smaller than Web document collections, a syntactic parser is applied to document sentences in order to identify and exploit syntactic dependencies for the purpose of selecting candidate class labels. $$$$$ They reported an accuracy of about 55% precision on a corpus of 100,000 words.

Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ The current state of the art discovers many semantic classes but fails to label their concepts.
Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ For example, if we labeled concept (A) from Section 1 with disease, then we could extract is-a relationships such as: diabetes is a disease, cancer is a disease, and lupus is a disease.
Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ The current state of the art discovers many semantic classes but fails to label their concepts.
Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun. $$$$$ Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc.

We thus multiply pmi (i, p) with the discounting factor suggested in (Pantel and Ravichandran 2004). $$$$$ We propose an algorithm labeling semantic and for leveraging them to extract relationships using a top-down approach.
We thus multiply pmi (i, p) with the discounting factor suggested in (Pantel and Ravichandran 2004). $$$$$ This occurs when a concept's committee members do not occur in any of the four syntactic relationships described in Section 0.
We thus multiply pmi (i, p) with the discounting factor suggested in (Pantel and Ravichandran 2004). $$$$$ Of the 1432 noun concepts discovered by CBC, our system labelled 98.5% of them with an NRR score of 77.1% in a human evaluation.
We thus multiply pmi (i, p) with the discounting factor suggested in (Pantel and Ravichandran 2004). $$$$$ On a subset of 65,000 proper names, our performance was 81.5%.

(Pantel and Ravichandran, 2004) have proposed an algorithm for labeling semantic classes, which can be viewed as a form of cluster. $$$$$ Class labels would serve useful in applications such as question answering to map a question concept into a semantic class and then search for answers within that class.
(Pantel and Ravichandran, 2004) have proposed an algorithm for labeling semantic classes, which can be viewed as a form of cluster. $$$$$ The authors wish to thank the reviewers for their helpful comments.
(Pantel and Ravichandran, 2004) have proposed an algorithm for labeling semantic classes, which can be viewed as a form of cluster. $$$$$ The current state of the art discovers many semantic classes but fails to label their concepts.
(Pantel and Ravichandran, 2004) have proposed an algorithm for labeling semantic classes, which can be viewed as a form of cluster. $$$$$ We first construct a frequency count vector C(e) = (ce1, ce2, ï¿½, cem), where m is the total number of features and cef is the frequency count of feature f occurring in word e. Here, cef is the number of times word e occurred in a grammatical context f. For example, if the word wave occurred 217 times as the object of the verb catch, then the feature vector for wave will have value 217 for its &quot;object-of catch&quot; feature.

Pantel and Ravichandran (2004) note that the nouns computer and company both have a WordNet sense that is a hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she. $$$$$ The authors wish to thank the reviewers for their helpful comments.
Pantel and Ravichandran (2004) note that the nouns computer and company both have a WordNet sense that is a hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she. $$$$$ We compared the passages returned by the passage retrieval module with and without the semantic indexing.
Pantel and Ravichandran (2004) note that the nouns computer and company both have a WordNet sense that is a hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she. $$$$$ For example, the wine cluster: Zinfandel, merlot, Pinot noir, Chardonnay, Cabernet Sauvignon, cabernet, riesling, Sauvignon blanc, Chenin blanc, sangiovese, syrah, Grape, Chianti ... contains some incorrect instances such as grape, appelation, and milk chocolate.
Pantel and Ravichandran (2004) note that the nouns computer and company both have a WordNet sense that is a hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she. $$$$$ This is potentially a significant step away from traditional all-or-nothing semantic/ontology representations to a concept representation scheme that is more nuanced and admits multiple names and graded set memberships.

We use PMI (point-wise mutual information) of hyponymy relation candidate (hyper, hypo) as a collocation feature (Pantel and Ravichandran, 2004), where we assume that hyper and hypo in candidates would frequently co-occur in the same sentence if they hold a hyponymy relation. $$$$$ Using concept signatures (templates describing the prototypical syntactic behavior of instances of a concept), we extract concept names by searching for simple syntactic patterns such as &quot;concept apposition-of instance&quot;.
We use PMI (point-wise mutual information) of hyponymy relation candidate (hyper, hypo) as a collocation feature (Pantel and Ravichandran, 2004), where we assume that hyper and hypo in candidates would frequently co-occur in the same sentence if they hold a hyponymy relation. $$$$$ Section 3 describes our algorithm for labeling concepts and for extracting hyponym relationships.
We use PMI (point-wise mutual information) of hyponymy relation candidate (hyper, hypo) as a collocation feature (Pantel and Ravichandran, 2004), where we assume that hyper and hypo in candidates would frequently co-occur in the same sentence if they hold a hyponymy relation. $$$$$ For example, the wine cluster: Zinfandel, merlot, Pinot noir, Chardonnay, Cabernet Sauvignon, cabernet, riesling, Sauvignon blanc, Chenin blanc, sangiovese, syrah, Grape, Chianti ... contains some incorrect instances such as grape, appelation, and milk chocolate.
