(Cherry and Foster, 2012), which is closer to the usual loss used for max-margin in machine learing. $$$$$ Among other results, we find that a simple and efficient batch version of MIRA performs at least as well as training online, and consistently outperforms other options.
(Cherry and Foster, 2012), which is closer to the usual loss used for max-margin in machine learing. $$$$$ In our implementation, we make a number of small, empirically verified deviations from Chiang et al. (2008).
(Cherry and Foster, 2012), which is closer to the usual loss used for max-margin in machine learing. $$$$$ This strategy has been adopted by Moses (Hasler et al., 2011), and it is the one we adopt in our MIRA implementation.

Cherry and Foster (2012) have concurrently performed a similar analysis. $$$$$ We evaluated the six tuning strategies described in this paper, along with two MERT baselines, on three language pairs (French-English (Fr-En), English-French (En-Fr) and Chinese-English (ZhEn)), across three different feature-set sizes.
Cherry and Foster (2012) have concurrently performed a similar analysis. $$$$$ For a given approximate �£i, PRO creates a sample Si of (eg, eb) pairs, such that BLEUi(eg) > BLEUi(eb).
Cherry and Foster (2012) have concurrently performed a similar analysis. $$$$$ Reported results use MegaM6 with a maximum of 30 iterations (as is done in Moses; the early stopping provides a form of regularization) for our six English/French tests, and MegaM with 100 iterations and a reduced initial uniform sample (50 pairs instead of 5000) for our three English/Chinese tests. gradient descent, with qo tuned to optimize the training loss achieved after one epoch (Bottou, 2010).

The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ The MERT algorithm optimizes linear weights relative to a collection of k-best lists or lattices, which provide an approximation to the true search space.
The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ The SVM requires a stable objective to optimize, meaning that it must forgo the pseudo-corpus used by MIRA to calculate Ai; instead, the SVM uses an interpolated sentence-level BLEU (Liang et al., 2006).4 Finally, MIRA’s oracle is selected with hope decoding.
The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ Our experiments show Batch Lattice MIRA to be the most consistent of the tested methods.
The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ For each example i, we select a fixed ez E �£i* that maximizes model score; that is, w~ is used to break ties in BLEU for oracle selection.

We are currently in the process of implementing and testing other parameter tuning methods (in addition to manual tuning and PRO), specifically lattice-based minimum error rate training (Macherey et al, 2008) and batch MIRA (Cherry and Foster, 2012). $$$$$ Our experiments show Batch Lattice MIRA to be the most consistent of the tested methods.
We are currently in the process of implementing and testing other parameter tuning methods (in addition to manual tuning and PRO), specifically lattice-based minimum error rate training (Macherey et al, 2008) and batch MIRA (Cherry and Foster, 2012). $$$$$ Our experiments show Batch Lattice MIRA to be the most consistent of the tested methods.
We are currently in the process of implementing and testing other parameter tuning methods (in addition to manual tuning and PRO), specifically lattice-based minimum error rate training (Macherey et al, 2008) and batch MIRA (Cherry and Foster, 2012). $$$$$ We review and organize the existing tuning literature, providing sentence-level loss functions for minimum risk, online and pairwise training.

As baselines we use MERT (Och, 2003), PRO, and the Moses (Koehn et al, 2007) implementation of k-best MIRA, which Cherry and Foster (2012) recently showed to work as well as online MIRA (Chiang, 2012) for feature-rich models. $$$$$ The results are shown in Figure 1.
As baselines we use MERT (Och, 2003), PRO, and the Moses (Koehn et al, 2007) implementation of k-best MIRA, which Cherry and Foster (2012) recently showed to work as well as online MIRA (Chiang, 2012) for feature-rich models. $$$$$ With the exception of MIRA, the tuning approaches discussed in this paper are direct optimizers.

Second, we ran the k-best batchMIRA (kbMIRA) (Cherry and Foster, 2012) implementation in Moses. $$$$$ However, their method of using different random seeds is not applicable in our context, since randomization does not play the same role for all tuning methods.
Second, we ran the k-best batchMIRA (kbMIRA) (Cherry and Foster, 2012) implementation in Moses. $$$$$ Our experiments show Batch Lattice MIRA to be the most consistent of the tested methods.
Second, we ran the k-best batchMIRA (kbMIRA) (Cherry and Foster, 2012) implementation in Moses. $$$$$ We perform empirical comparisons of eight different tuning strategies, including MERT, in a variety of settings.
Second, we ran the k-best batchMIRA (kbMIRA) (Cherry and Foster, 2012) implementation in Moses. $$$$$ For each example i, we select a fixed ez E �£i* that maximizes model score; that is, w~ is used to break ties in BLEU for oracle selection.

Cherry and Foster (2012) reported the same result, and their implementation is available in Moses. $$$$$ This is the first comparison to include all three categories of optimizer.
Cherry and Foster (2012) reported the same result, and their implementation is available in Moses. $$$$$ With the oracle fixed, the objective becomes a standard structured SVM objective, which can be minimized using a cutting-plane algorithm, as described by Tsochantaridis et al. (2004).
Cherry and Foster (2012) reported the same result, and their implementation is available in Moses. $$$$$ Systems for English/French were trained on Canadian Hansard data (years 2001–2009) summarized in table 1.7 The dev and test sets were chosen randomly from among the most recent 5 days of Hansard transcripts.

These works use radically different experimental setups, and to our knowledge only (Cherry and Foster, 2012) and this work compare to at least two high dimensional baselines. $$$$$ Parallelization is important for efficient SMT tuning, as decoding is still relatively expensive.
These works use radically different experimental setups, and to our knowledge only (Cherry and Foster, 2012) and this work compare to at least two high dimensional baselines. $$$$$ There has been a proliferation of recent work on SMT tuning algorithms capable of handling larger feature sets than the traditional MERT approach.

We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). $$$$$ This optimization is wrapped in an outer loop that iterates between optimizing weights and re-decoding with those weights to enhance the approximation.
We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). $$$$$ The MERT algorithm optimizes linear weights relative to a collection of k-best lists or lattices, which provide an approximation to the true search space.
We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). $$$$$ A linear model w~ scores derivations according to their features, meaning that the decoder solves: Assuming we wish to optimize our decoder’s BLEU score (Papineni et al., 2002), the natural objective of learning would be to find a w~ such that BLEU([e(~w), R]n1) is maximal.

See (Cherry and Foster, 2012) for details on objectives. $$$$$ It is the top scoring system in all Medium settings, and in two of three Big settings (in Big Zh-En, the SVM comes first, with batch lattice MIRA placing second).
See (Cherry and Foster, 2012) for details on objectives. $$$$$ We do not sharpen our distribution with a temperature or otherwise control for entropy; instead, we trust A = 50 to maintain a reasonable distribution.
See (Cherry and Foster, 2012) for details on objectives. $$$$$ Each update makes the smallest change to w~ (subject to a step-size cap C) that will separate the oracle from a number of negative hypotheses.
