(Cherry and Foster, 2012), which is closer to the usual loss used for max-margin in machine learing. $$$$$ We analyze a number of these algorithms in terms of their sentencelevel loss functions, which motivates several new approaches, including a Structured SVM.
(Cherry and Foster, 2012), which is closer to the usual loss used for max-margin in machine learing. $$$$$ The Structured SVM optimizes a sum of hinge losses directly, exposing an explicit regularization term.
(Cherry and Foster, 2012), which is closer to the usual loss used for max-margin in machine learing. $$$$$ Finally, since randomization plays a different role in each tuner, we also suggest a new method for testing an optimizer’s stability (Clark et al., 2011), which sub-samples the tuning set instead of varying a random seed.

Cherry and Foster (2012) have concurrently performed a similar analysis. $$$$$ The Big set adds sparse Boolean features to Medium, for a maximum of 6,848 features.
Cherry and Foster (2012) have concurrently performed a similar analysis. $$$$$ We begin by establishing some notation.
Cherry and Foster (2012) have concurrently performed a similar analysis. $$$$$ We perform empirical comparisons of eight different tuning strategies, including MERT, in a variety of settings.
Cherry and Foster (2012) have concurrently performed a similar analysis. $$$$$ We analyze a number of these algorithms in terms of their sentencelevel loss functions, which motivates several new approaches, including a Structured SVM.

The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ We perform empirical comparisons of eight different tuning strategies, including MERT, in a variety of settings.
The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ We develop two large-margin tuners that explore these trade-offs.
The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ To enable loading all of the lattices into memory at once, we prune to a density of 50 edges per reference word.
The system was tuned with batch lattice MIRA (Cherry and Foster, 2012). $$$$$ The results of our survey of tuning methods can be seen in Tables 4, 5 and 6.

We are currently in the process of implementing and testing other parameter tuning methods (in addition to manual tuning and PRO), specifically lattice-based minimum error rate training (Macherey et al, 2008) and batch MIRA (Cherry and Foster, 2012). $$$$$ However, their method of using different random seeds is not applicable in our context, since randomization does not play the same role for all tuning methods.
We are currently in the process of implementing and testing other parameter tuning methods (in addition to manual tuning and PRO), specifically lattice-based minimum error rate training (Macherey et al, 2008) and batch MIRA (Cherry and Foster, 2012). $$$$$ We begin by establishing some notation.
We are currently in the process of implementing and testing other parameter tuning methods (in addition to manual tuning and PRO), specifically lattice-based minimum error rate training (Macherey et al, 2008) and batch MIRA (Cherry and Foster, 2012). $$$$$ The availability of linear models and discriminative tuning algorithms has been a huge boon to statistical machine translation (SMT), allowing the field to move beyond the constraints of generative noisy channels (Och and Ney, 2002).

As baselines we use MERT (Och, 2003), PRO, and the Moses (Koehn et al, 2007) implementation of k-best MIRA, which Cherry and Foster (2012) recently showed to work as well as online MIRA (Chiang, 2012) for feature-rich models. $$$$$ The resulting standard deviations provide an indication of stability.

Second, we ran the k-best batchMIRA (kbMIRA) (Cherry and Foster, 2012) implementation in Moses. $$$$$ This is due to two main factors: The problems with MERT can be addressed through the use of surrogate loss functions.
Second, we ran the k-best batchMIRA (kbMIRA) (Cherry and Foster, 2012) implementation in Moses. $$$$$ The results are shown in Figure 1.
Second, we ran the k-best batchMIRA (kbMIRA) (Cherry and Foster, 2012) implementation in Moses. $$$$$ We follow Clark et al (2011), and perform multiple randomized replications of each experiment.

Cherry and Foster (2012) reported the same result, and their implementation is available in Moses. $$$$$ Minimum risk approaches (Och, 2003; Smith and Eisner, 2006) have been quietly capable of handling many features for some time, but have yet to see widespread adoption.
Cherry and Foster (2012) reported the same result, and their implementation is available in Moses. $$$$$ We do not sharpen our distribution with a temperature or otherwise control for entropy; instead, we trust A = 50 to maintain a reasonable distribution.
Cherry and Foster (2012) reported the same result, and their implementation is available in Moses. $$$$$ There has been a proliferation of recent work on SMT tuning algorithms capable of handling larger feature sets than the traditional MERT approach.

These works use radically different experimental setups, and to our knowledge only (Cherry and Foster, 2012) and this work compare to at least two high dimensional baselines. $$$$$ We have organized the literature on tuning, and carried out an extensive comparison of linear-loss SMT tuners.
These works use radically different experimental setups, and to our knowledge only (Cherry and Foster, 2012) and this work compare to at least two high dimensional baselines. $$$$$ Given [S]Z1, this convex objective can be optimized using any binary SVM.2 Unlike MIRA, the margin here is fixed to 1; cost enters into PRO through its sampling routine, which performs a large uniform sample and then selects a subset of pairs with large BLEU differentials.
These works use radically different experimental setups, and to our knowledge only (Cherry and Foster, 2012) and this work compare to at least two high dimensional baselines. $$$$$ That is, PRO employs a growing approximation of £i by aggregating the k-best hypotheses from a series of increasingly refined models.

We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). $$$$$ The results of our survey of tuning methods can be seen in Tables 4, 5 and 6.
We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). $$$$$ We attribute this to our parallelization strategy, Chiang et al.’s (2008) more complex solution may perform better.
We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). $$$$$ We have presented three new, large-margin tuning methods for SMT that can handle thousands of features.
We tune with the k-best batch MIRA algorithm (Cherry and Foster, 2012). $$$$$ The ability to optimize these models according to an error metric has become a standard assumption in SMT, due to the wide-spread adoption of Minimum Error Rate Training or MERT (Och, 2003).

See (Cherry and Foster, 2012) for details on objectives. $$$$$ In particular, we test variants of Chiang et al.’s (2008) hope-fear MIRA that use k-best or lattice-approximated search spaces, producing a Batch MIRA that outperforms a popular mechanism for parallelizing online learners.
See (Cherry and Foster, 2012) for details on objectives. $$$$$ MIRA is an instance of online learning, repeating the following steps: visit an example i, decode according to ~w, and update w~ to reduce `i(~w).
See (Cherry and Foster, 2012) for details on objectives. $$$$$ We analyze a number of these algorithms in terms of their sentencelevel loss functions, which motivates several new approaches, including a Structured SVM.
