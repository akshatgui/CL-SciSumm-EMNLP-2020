 $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
 $$$$$ For this goal, we put aside the anaphoricity classifier and focus on the pairwise classifier and transitivity constraints.
 $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
 $$$$$ Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al. (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al.

On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ Note that this model is degenerate, because it assigns probability mass to nonsensical clusterings.
On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ When describing our model, we build upon the notation used by Denis and Baldridge (2007).
On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).

One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion: Sharon Goldwater, Michel Galley, Anna Rafferty.
One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ If John Smith was labeled coreferent with Smith, and Smith with Jane Smith, then John Smith and Jane Smith were also coreferent regardless of the classifier’s evaluation of that pair.
One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).

Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ This is exactly the kind of constraint that integer linear programming (ILP) is ideal for, but, surprisingly, previous work applying ILP to coreference resolution has not encoded this type of constraint.
Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ Our feature set was simple, and included many features from (Soon et al., 2001), including the pronoun, string match, definite and demonstrative NP, number and gender agreement, proper name and appositive features.
Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).

As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ (2006) who use a probabilistic first-order logic model.
As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.
As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al. (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al.

Second, we compare our cut-based approach with the five aforementioned approaches to anaphoricity determination (namely, Ng and Cardie (2002a), Ng (2004), Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008)) in terms of their effectiveness in improving a learning-based coreference system. $$$$$ Note that this model is degenerate, because it assigns probability mass to nonsensical clusterings.
Second, we compare our cut-based approach with the five aforementioned approaches to anaphoricity determination (namely, Ng and Cardie (2002a), Ng (2004), Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008)) in terms of their effectiveness in improving a learning-based coreference system. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
Second, we compare our cut-based approach with the five aforementioned approaches to anaphoricity determination (namely, Ng and Cardie (2002a), Ng (2004), Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008)) in terms of their effectiveness in improving a learning-based coreference system. $$$$$ Much work that followed improved upon this strategy, by improving the features (Ng and Cardie, 2002b), the type of classifier (Denis and Baldridge, 2007), and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (Ng and Cardie, 2002b).

It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.
It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ For this goal, we put aside the anaphoricity classifier and focus on the pairwise classifier and transitivity constraints.
It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion: Sharon Goldwater, Michel Galley, Anna Rafferty.

 $$$$$ More recently, Denis and Baldridge (2007) utilized an integer linear programming (ILP) solver to better combine the decisions made by these two complementary classifiers, by finding the globally optimal solution according to both classifiers.
 $$$$$ As noted, these assignments may not be a legal clustering because there is no guarantee of transitivity.
 $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
 $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.

Duplicated Finkel and Manning (2008) baseline. $$$$$ If John Smith was labeled coreferent with Smith, and Smith with Jane Smith, then John Smith and Jane Smith were also coreferent regardless of the classifier’s evaluation of that pair.
Duplicated Finkel and Manning (2008) baseline. $$$$$ We used the MUC-6 formal training and test data, as well as the NWIRE and BNEWS portions of the ACE (Phase 2) corpus.
Duplicated Finkel and Manning (2008) baseline. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
Duplicated Finkel and Manning (2008) baseline. $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.

Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ We train a coreference classifier over pairs of mentions, and show how to encode this type of constraint on top of the probabilities output from our pairwise classifier to extract the most probable legal entity assignments.
Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ We train a coreference classifier over pairs of mentions, and show how to encode this type of constraint on top of the probabilities output from our pairwise classifier to extract the most probable legal entity assignments.
Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.

Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion: Sharon Goldwater, Michel Galley, Anna Rafferty.
Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.
Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.

 $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
 $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.
 $$$$$ The transitive closure happens in an ad-hoc manner after this assignment is found: any two mentions linked through other mentions are determined to be coreferent.
 $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.

 $$$$$ We had additional features for NE tags, head matching and head substring matching.
 $$$$$ We ran experiments on two datasets.
 $$$$$ We used lp solve3 to solve our ILP optimization problems.
 $$$$$ Create negative examples for all intermediate mentions, and a positive example for the mention and its correct antecedent.

Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs. $$$$$ The V scorer (Amit and Baldwin, 1998) was proposed to overcome several shortcomings of the MUC scorer.
Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs. $$$$$ This corpus had a third portion, NPAPER, but we found that several documents where too long for lp solve to find a solution.4 We added named entity (NE) tags to the data using the tagger of Finkel et al. (2005).

Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ For all three corpora, the ILP model beat both baselines for the cluster f-score, Rand index, and variation of information metrics.

Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ Using the V metric, the ILP system and the D&B-STYLE baseline performed about the same on the MUC-6 corpus, though for both ACE corpora, the ILP system was the clear winner.
Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ They use two classifiers, an anaphoricity classifier, which decides if a mention should have an antecedent and a pairwise classifier similar those just discussed, which are combined in a cascaded manner.

Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ Our D&B-STYLE baseline used the same test time method as Denis and Baldridge (2007), however at training time we created data for all mention pairs.
Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).

Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al, 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). $$$$$ This is exactly the kind of constraint that integer linear programming (ILP) is ideal for, but, surprisingly, previous work applying ILP to coreference resolution has not encoded this type of constraint.
Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al, 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al, 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.
Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al, 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). $$$$$ This line of work has largely ignored the implicit transitivity of the decisions made, and can result in unintuitive chains such as the Smith chain just described, where each pairwise decision is sensible, but the final result is not.

see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ This is exactly the kind of constraint that integer linear programming (ILP) is ideal for, but, surprisingly, previous work applying ILP to coreference resolution has not encoded this type of constraint.
see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ Because of the ad-hoc manner in which transitivity is enforced in our baseline systems, we do not necessarily find the most probable legal clustering.

The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al. (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al.
The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
