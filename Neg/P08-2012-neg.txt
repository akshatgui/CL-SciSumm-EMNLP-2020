 $$$$$ When using the MUC scorer, the ILP system always did worse than the D&B-STYLE baseline.
 $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
 $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
 $$$$$ We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.

On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ This corpus had a third portion, NPAPER, but we found that several documents where too long for lp solve to find a solution.4 We added named entity (NE) tags to the data using the tagger of Finkel et al. (2005).
On the MUC6-TEST dataset, our system outperforms both Poon and Domingos (2008) (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. $$$$$ The V scorer (Amit and Baldwin, 1998) was proposed to overcome several shortcomings of the MUC scorer.

One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ We had additional features for NE tags, head matching and head substring matching.
One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ Remember that going in the opposite direction and simply putting all mentions in one cluster produces a MUC score which is higher than any in the table, even though this clustering is clearly not useful in applications.
One could use ILP-based decoding in the style of Finkel and Manning (2008) and Song et al (2012) to attempt to explicitly find the optimal C with choice of a marginalized out, but we did not explore this option. $$$$$ For this task we are given a document which is annotated with a set of mentions, and the goal is to cluster the mentions which refer to the same entity.

Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ Using the V metric, the ILP system and the D&B-STYLE baseline performed about the same on the MUC-6 corpus, though for both ACE corpora, the ILP system was the clear winner.
Our formulation is equivalent to the one suggested by Finkel and Manning (2008) in a coreference resolution task. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).

As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ When describing our model, we build upon the notation used by Denis and Baldridge (2007).
As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ We train a coreference classifier over pairs of mentions, and show how to encode this type of constraint on top of the probabilities output from our pairwise classifier to extract the most probable legal entity assignments.
As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).

Second, we compare our cut-based approach with the five aforementioned approaches to anaphoricity determination (namely, Ng and Cardie (2002a), Ng (2004), Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008)) in terms of their effectiveness in improving a learning-based coreference system. $$$$$ This is exactly the kind of constraint that integer linear programming (ILP) is ideal for, but, surprisingly, previous work applying ILP to coreference resolution has not encoded this type of constraint.
Second, we compare our cut-based approach with the five aforementioned approaches to anaphoricity determination (namely, Ng and Cardie (2002a), Ng (2004), Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008)) in terms of their effectiveness in improving a learning-based coreference system. $$$$$ We ran experiments on two datasets.

It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion: Sharon Goldwater, Michel Galley, Anna Rafferty.
It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ For this task we are given a document which is annotated with a set of mentions, and the goal is to cluster the mentions which refer to the same entity.
It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ Our SOON-STYLE baseline used the same training and testing regimen as Soon et al. (2001).
It is worth noting, in particular, that Luo (2007), Denis and Baldridge (2007), and Finkel and Manning (2008) evaluate their approaches on true mentions extracted from the answer keys. $$$$$ A desirable quality of a coreference resolution system is the ability to handle transitivity constraints, such that even if it places high likelihood on a particular mention being coreferent with each of two other mentions, it will also consider the likelihood of those two mentions being coreferent when making a final assignment.

 $$$$$ The goal of the present work is simply to show that transitivity constraints are a useful source of information, which can and should be incorporated into an ILP-based coreference system.
 $$$$$ Note that this model is degenerate, because it assigns probability mass to nonsensical clusterings.

Duplicated Finkel and Manning (2008) baseline. $$$$$ We train a coreference classifier over pairs of mentions, and show how to encode this type of constraint on top of the probabilities output from our pairwise classifier to extract the most probable legal entity assignments.
Duplicated Finkel and Manning (2008) baseline. $$$$$ The improvements from the ILP system are most clearly shown on the ACE NWIRE corpus, where the V f-score improved 3.6%, and the cluster f-score improved 16.5%.
Duplicated Finkel and Manning (2008) baseline. $$$$$ Remember that going in the opposite direction and simply putting all mentions in one cluster produces a MUC score which is higher than any in the table, even though this clustering is clearly not useful in applications.

Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ Using their classifier, they would build up coreference chains, where each mention was linked up with the most recent previous mention that the classifier labeled as coreferent, if such a mention existed.
Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ We also added part of speech (POS) tags to the data using the tagger of Toutanova et al. (2003), and used the tags to decide if mentions were plural or singular.
Examples include (Finkel and Manning, 2008), using VI, Rand index and clustering F-score for evaluating coreference resolution. $$$$$ Using the V metric, the ILP system and the D&B-STYLE baseline performed about the same on the MUC-6 corpus, though for both ACE corpora, the ILP system was the clear winner.

Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ Much recent work on coreference resolution, which is the task of deciding which noun phrases, or mentions, in a document refer to the same real world entity, builds on Soon et al. (2001).
Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ A desirable quality of a coreference resolution system is the ability to handle transitivity constraints, such that even if it places high likelihood on a particular mention being coreferent with each of two other mentions, it will also consider the likelihood of those two mentions being coreferent when making a final assignment.
Recently Finkel and Manning (2008) show that the optimal ILP solution outperforms the first and best-link methods. $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.

 $$$$$ They built a decision tree classifier to label pairs of mentions as coreferent or not.
 $$$$$ The ACE data is labeled with mention type (pronominal, nominal, and name), but the MUC6 data is not, so the POS and NE tags were used to infer this information.
 $$$$$ Our D&B-STYLE baseline used the same test time method as Denis and Baldridge (2007), however at training time we created data for all mention pairs.

 $$$$$ As observed by Luo et al. (2004), if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score – significantly higher than any published system.
 $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.
 $$$$$ In addition to the MUC and V scorers, we also evaluate using cluster f-measure (Ghosh, 2003), which is the standard f-measure computed over true/false coreference decisions for pairs of mentions; the Rand index (Rand, 1971), which is pairwise accuracy of the clustering; and variation of information (Meila, 2003), which utilizes the entropy of the clusterings and their mutual information (and for which lower values are better).

Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs. $$$$$ The log likelihood of a document is the sum of the log likelihoods of all pairs of mentions: (2) where m is the set of mentions in the document, and x is the set of variables representing each pairwise coreference decision x(i,j).
Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).

Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ The MUC scorer (Vilain et al., 1995) is a popular coreference evaluation metric, but we found it to be fatally flawed.
Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ A desirable quality of a coreference resolution system is the ability to handle transitivity constraints, such that even if it places high likelihood on a particular mention being coreferent with each of two other mentions, it will also consider the likelihood of those two mentions being coreferent when making a final assignment.
Extending (Denis and Baldridge, 2007) and (Finkel and Manning,2008)'s work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.

Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ A desirable quality of a coreference resolution system is the ability to handle transitivity constraints, such that even if it places high likelihood on a particular mention being coreferent with each of two other mentions, it will also consider the likelihood of those two mentions being coreferent when making a final assignment.
Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ Our objective function is then the log probability of a particular (possibly illegal) variable assignment: We add binary constraints on each of the variables: x(i,j) E 10, 11.
Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ Thanks to the following members of the Stanford NLP reading group for helpful discussion: Sharon Goldwater, Michel Galley, Anna Rafferty.
Klenner (2007) and Finkel and Manning (2008)'s work extended the ILP framework to support transitivity constraints. $$$$$ We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance, including imof up to 3.6% using the and up to 16.5% using cluster f-measure.

Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ As observed by Luo et al. (2004), if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score – significantly higher than any published system.
Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ For each mention, work backwards through the preceding mentions in the document until you come to a true coreferent mention.
Last, we note that transitive relations have been explored in adjacent fields such as Temporal Information Extraction (Ling and Weld, 2010), Ontology Induction (Poon and Domingos, 2010), and Coreference Resolution (Finkel and Manning, 2008). $$$$$ A desirable quality of a coreference resolution system is the ability to handle transitivity constraints, such that even if it places high likelihood on a particular mention being coreferent with each of two other mentions, it will also consider the likelihood of those two mentions being coreferent when making a final assignment.

Transitivity was also used as an information source in other fields of NLP $$$$$ A desirable quality of a coreference resolution system is the ability to handle transitivity constraints, such that even if it places high likelihood on a particular mention being coreferent with each of two other mentions, it will also consider the likelihood of those two mentions being coreferent when making a final assignment.
Transitivity was also used as an information source in other fields of NLP $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
Transitivity was also used as an information source in other fields of NLP $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
Transitivity was also used as an information source in other fields of NLP $$$$$ Note that this model is degenerate, because it assigns probability mass to nonsensical clusterings.

see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ This line of work has largely ignored the implicit transitivity of the decisions made, and can result in unintuitive chains such as the Smith chain just described, where each pairwise decision is sensible, but the final result is not.
see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ This paper is based on work funded by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT).
see (Finkel and Manning, 2008) for an alternative but equivalent formalization. $$$$$ We train a coreference classifier over pairs of mentions, and show how to encode this type of constraint on top of the probabilities output from our pairwise classifier to extract the most probable legal entity assignments.

The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ We also include their JOINTILP numbers, however that system makes use of an additional anaphoricity classifier.
The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ A desirable quality of a coreference resolution system is the ability to handle transitivity constraints, such that even if it places high likelihood on a particular mention being coreferent with each of two other mentions, it will also consider the likelihood of those two mentions being coreferent when making a final assignment.
The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
The model from (Finkel and Manning, 2008) utilizes transitivity, but not exclusivity. $$$$$ We train a coreference classifier over pairs of mentions, and show how to encode this type of constraint on top of the probabilities output from our pairwise classifier to extract the most probable legal entity assignments.
