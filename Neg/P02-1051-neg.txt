Web counts are frequently used to automatically re-rank candidate lists for various NLP tasks (Al-Onaizan and Knight, 2002). $$$$$ As shown in Figure 1, the translation process in our system is carried out in two main steps.
Web counts are frequently used to automatically re-rank candidate lists for various NLP tasks (Al-Onaizan and Knight, 2002). $$$$$ Named entity phrases can be identified fairly accurately (e.g., Bikel et al. (1999) report an FMEASURE of 94.9%).
Web counts are frequently used to automatically re-rank candidate lists for various NLP tasks (Al-Onaizan and Knight, 2002). $$$$$ To illustrate this method, consider the name “ Coffee Annan, Coffee Engen, Coffee Anton, Coffee Anyone, and Covey Annan but not the correct translation Kofi Annan.

Specifically, (Al-Onaizan and Knight, 2002) uses transliteration to generate candidates and then web corpora to identify translations. $$$$$ The problem is that our news corpus is dated material, and it might not contain the information we are interested in.
Specifically, (Al-Onaizan and Knight, 2002) uses transliteration to generate candidates and then web corpora to identify translations. $$$$$ Another reason for doing poorly on organizations is that acronyms and abbreviations in the Arabic text (e.g., “ w¯as,” the Saudi Press Agency) are currently not handled by our system.
Specifically, (Al-Onaizan and Knight, 2002) uses transliteration to generate candidates and then web corpora to identify translations. $$$$$ We present a novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources.
Specifically, (Al-Onaizan and Knight, 2002) uses transliteration to generate candidates and then web corpora to identify translations. $$$$$ Therefore, we will not address them in this paper.

(Al-Onaizan and Knight 2002) showed that use of outside linguistic resources such as WWW counts of transliteration candidates can greatly boost transliteration accuracy. $$$$$ Let’s illustrate this idea with the following example: We would like to translate the named entities that appear in the following Arabic excerpt: The Arabic newspaper article from which we extracted this excerpt is about negotiations between the US and North Korean authorities regarding the search for the remains of US soldiers who died during the Korean war.
(Al-Onaizan and Knight 2002) showed that use of outside linguistic resources such as WWW counts of transliteration candidates can greatly boost transliteration accuracy. $$$$$ This means that there is a lot of room for improvement once we consider more effective re-scoring methods.

 $$$$$ Also, there is no oneto-one correspondence between Arabic sounds and English sounds.
 $$$$$ Named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere, and because many are domain specific, not to be found in bilingual dictionaries.
 $$$$$ They were then translated to English by a bilingual speaker (a native speaker of Arabic) given the text they appear in.

A spelling-based model is described in (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002c) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations. $$$$$ The candidate list is created by extracting the n-best transliterations for a given name.
A spelling-based model is described in (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002c) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations. $$$$$ In this paper, we describe a system for ArabicEnglish named entity translation, though the technique is applicable to any language pair and does not require especially difficult-to-obtain resources.
A spelling-based model is described in (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002c) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations. $$$$$ We would like to apply to other languages such as Chinese and Japanese and to investigate whether the current algorithm would perform as well or whether new algorithms might be needed.
A spelling-based model is described in (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002c) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations. $$$$$ We also compare our system with human translators and a commercial system.

The phonetics-based and spelling-based models have been linearly combined into a single transliteration model in (Al-Onaizan and Knight, 2002b) for transliteration of Arabic named entities into English. $$$$$ However, one serious limitation of this method is that only English words with known pronunciations can be produced.
The phonetics-based and spelling-based models have been linearly combined into a single transliteration model in (Al-Onaizan and Knight, 2002b) for transliteration of Arabic named entities into English. $$$$$ For example, the phrase “ alnw¯ab mˇgls” is translated as the House ofRepresentatives.
The phonetics-based and spelling-based models have been linearly combined into a single transliteration model in (Al-Onaizan and Knight, 2002b) for transliteration of Arabic named entities into English. $$$$$ The evaluation corpus consists of two different test sets, a development test set and a blind test set.

Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. $$$$$ The probability is a linear combination of the transliteration and translation score, where the translation score is a uniform probability over all dictionary entries for .
Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. $$$$$ In Section 3, we describe how translation candidates are generated.
Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. $$$$$ Instead of having to come up with translations for the named entities often with many unknown words in one document, sometimes it is easier for a human to find a document in the target language that is similar to, but not necessarily a translation of, the original document and then extract the translations.
Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. $$$$$ We present a novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources.

Al-Onaizan and Knight (2002) used Web statistics information to validate the translation candidates generated by language model, and obtained the accuracy of 72.6% in Arabic-English OOV word translation. $$$$$ This is enough to get the correct translation as the top candidate.
Al-Onaizan and Knight (2002) used Web statistics information to validate the translation candidates generated by language model, and obtained the accuracy of 72.6% in Arabic-English OOV word translation. $$$$$ First, an English word is generated according to its unigram probabilities .
Al-Onaizan and Knight (2002) used Web statistics information to validate the translation candidates generated by language model, and obtained the accuracy of 72.6% in Arabic-English OOV word translation. $$$$$ The score for a given candidate is given by a modified IBM Model 1 probability (Brown et al., 1993) as follows: where is the length of , is the length of , is a scaling factor based on the number of matches of found, and is the index of the English word aligned with according to alignment .

Al-Onaizan and Knight (2002) describe a system which combines a phonetic based model with a spelling model for transliteration. $$$$$ Also, human translators often transliterate words based on how they are spelled in the source language.
Al-Onaizan and Knight (2002) describe a system which combines a phonetic based model with a spelling model for transliteration. $$$$$ This is especially useful when translating named entities in news stories of international importance where the same event will most likely be reported in many languages including the target language.
Al-Onaizan and Knight (2002) describe a system which combines a phonetic based model with a spelling model for transliteration. $$$$$ The Chosin Reservoir campaign left approximately 750 Marines and soldiers missing in action from both the east and west sides of the reservoir in northeastern North Korea.
Al-Onaizan and Knight (2002) describe a system which combines a phonetic based model with a spelling model for transliteration. $$$$$ Named entity phrases can be identified fairly accurately (e.g., Bikel et al. (1999) report an FMEASURE of 94.9%).

For example, the work of (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation. $$$$$ Straight Web Counts re-score candidates based on their Web counts.
For example, the work of (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation. $$$$$ Stalls and Knight (1998) present an Arabic-toEnglish back-transliteration system based on the source-channel framework.
For example, the work of (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation. $$$$$ We would like to experiment with adding a small named entity translation dictionary for common names and see if this might improve the overall translation accuracy.
For example, the work of (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation. $$$$$ When it is not in the list, the re-scoring will fail.

Al-Onaizan and Knight (2002b) suggested that pronunciation can be skipped and the target language letters can be mapped directly to source language letters. $$$$$ Also, the re-scoring methods we used were initially developed and applied to person names.
Al-Onaizan and Knight (2002b) suggested that pronunciation can be skipped and the target language letters can be mapped directly to source language letters. $$$$$ The second document contained the following excerpt: Operations in 2001 will include areas of investigation near Kaechon, approximately 18 miles south of Unsan and Kujang.
Al-Onaizan and Knight (2002b) suggested that pronunciation can be skipped and the target language letters can be mapped directly to source language letters. $$$$$ To illustrate this method, consider the name “ Coffee Annan, Coffee Engen, Coffee Anton, Coffee Anyone, and Covey Annan but not the correct translation Kofi Annan.

Similarly, Al-Onaizan and Knight (2002a; 2002b) only made use of transliteration information alone and so was not directly comparable. $$$$$ Named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere, and because many are domain specific, not to be found in bilingual dictionaries.
Similarly, Al-Onaizan and Knight (2002a; 2002b) only made use of transliteration information alone and so was not directly comparable. $$$$$ It would be interesting to see how rearranging the order in which the modules are applied might affect the overall accuracy of the system.

For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ The challenge is to find the contextual information that provide the most accurate counts.
For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ We also compare our results with the results obtained from human translations and a commercial system for the same task.
For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ We next seek a more accurate counting method by counting phrases only if they appear within a certain context.
For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ We presented the Arabic document to a bilingual speaker and asked them to translate the locations “ tˇswzyn h˘ z¯an”, “ ¯awns¯an”, and “ kwˇg¯anˇg.” The translations they provided were Chozin Reserve, Onsan, and Kojanj.

Previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (Cao and Li, 2002) and named entity translation (Al-Onaizan and Knight, 2002). $$$$$ Transliteration between languages that use similar alphabets and sound systems is very simple.
Previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (Cao and Li, 2002) and named entity translation (Al-Onaizan and Knight, 2002). $$$$$ This human translation method gives us the correct translation for the names we are interested in.
Previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (Cao and Li, 2002) and named entity translation (Al-Onaizan and Knight, 2002). $$$$$ The translation candidates for typical person names are generated using the transliteration module described above.

Al-Onaizan and Knight (2002), Huang (2003) and Ji and Grishman (2007) investigated the general name entity translation problem, especially in the context of machine translation. $$$$$ The English translations in the two data sets were reviewed thoroughly to correct any wrong translations made by the original translators.
Al-Onaizan and Knight (2002), Huang (2003) and Ji and Grishman (2007) investigated the general name entity translation problem, especially in the context of machine translation. $$$$$ We do this by searching for the correct translation rather than generating it.
Al-Onaizan and Knight (2002), Huang (2003) and Ji and Grishman (2007) investigated the general name entity translation problem, especially in the context of machine translation. $$$$$ The top document returned by the search engines we used contained the following paragraph: The targeted area is near Unsan, which saw several battles between the U.S. Army’s 8th Cavalry regiment and Chinese troops who launched a surprise offensive in late 1950.
Al-Onaizan and Knight (2002), Huang (2003) and Ji and Grishman (2007) investigated the general name entity translation problem, especially in the context of machine translation. $$$$$ Named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere, and because many are domain specific, not to be found in bilingual dictionaries.
