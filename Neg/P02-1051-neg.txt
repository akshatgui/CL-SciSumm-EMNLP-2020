Web counts are frequently used to automatically re-rank candidate lists for various NLP tasks (Al-Onaizan and Knight, 2002). $$$$$ In Section 3, we describe how translation candidates are generated.
Web counts are frequently used to automatically re-rank candidate lists for various NLP tasks (Al-Onaizan and Knight, 2002). $$$$$ Named entity phrases are being introduced in news stories on a daily basis in the form of personal names, organizations, locations, temporal phrases, and monetary expressions.

Specifically, (Al-Onaizan and Knight, 2002) uses transliteration to generate candidates and then web corpora to identify translations. $$$$$ We would like to apply to other languages such as Chinese and Japanese and to investigate whether the current algorithm would perform as well or whether new algorithms might be needed.
Specifically, (Al-Onaizan and Knight, 2002) uses transliteration to generate candidates and then web corpora to identify translations. $$$$$ Alternatively, using a search engine, we retrieve the top matching documents for each of the names Coffee, Covey, Annan, Engen, Anton, and Anyone.
Specifically, (Al-Onaizan and Knight, 2002) uses transliteration to generate candidates and then web corpora to identify translations. $$$$$ We report on the application and evaluation of this algorithm in translating Arabic named entities to English.

(Al-Onaizan and Knight 2002) showed that use of outside linguistic resources such as WWW counts of transliteration candidates can greatly boost transliteration accuracy. $$$$$ We report on the application and evaluation of this algorithm in translating Arabic named entities to English.
(Al-Onaizan and Knight 2002) showed that use of outside linguistic resources such as WWW counts of transliteration candidates can greatly boost transliteration accuracy. $$$$$ This gives “ al-h˘ n¯azyr kyl ˇgwn.” The transliteration module proposes Jon and John as possible transliterations for the first name, and Keele and Kyl among others for the last name.
(Al-Onaizan and Knight 2002) showed that use of outside linguistic resources such as WWW counts of transliteration candidates can greatly boost transliteration accuracy. $$$$$ The articles have already been translated into English by professional translators.3 Named entity phrases in these articles were hand-tagged, extracted, and paired with their English translations to create the blind test set.

 $$$$$ In this paper, we describe a system for ArabicEnglish named entity translation, though the technique is applicable to any language pair and does not require especially difficult-to-obtain resources.
 $$$$$ For the previous example, we use Wall Street as the contextual information In this case we get the counts 15 and 113 for Donald Martin and Donald Marron, respectively.
 $$$$$ We would like to experiment with adding a small named entity translation dictionary for common names and see if this might improve the overall translation accuracy.
 $$$$$ We conclude this paper with the evaluation results of our translation algorithm on a test set.

A spelling-based model is described in (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002c) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations. $$$$$ Overall is a weighted average of the three named entity categories. tally.
A spelling-based model is described in (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002c) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations. $$$$$ Translating a common name incorrectly has a significant effect on the translation accuracy.
A spelling-based model is described in (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002c) that directly maps English letter sequences into Arabic letter sequences with associated probability that are trained on a small English/Arabic name list without the need for English pronunciations. $$$$$ For example, the top two translation candidates for “ m¯arwn dwn¯ald” are Donald Martin and Donald Marron.

The phonetics-based and spelling-based models have been linearly combined into a single transliteration model in (Al-Onaizan and Knight, 2002b) for transliteration of Arabic named entities into English. $$$$$ When it is not in the list, the re-scoring will fail.
The phonetics-based and spelling-based models have been linearly combined into a single transliteration model in (Al-Onaizan and Knight, 2002b) for transliteration of Arabic named entities into English. $$$$$ It is obvious that the human attempted to sound out names and despite coming close, they failed to get them correctly as we will see later.

Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. $$$$$ The spelling-based model we propose (described in detail in (Al-Onaizan and Knight, 2002)) directly According to this model, the transliteration probability is given by the following equation: maps English letter sequences into Arabic letter sequences with probability , which are trained on a small English/Arabic name list without the need for English pronunciations.
Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. $$$$$ This human translation method gives us the correct translation for the names we are interested in.
Yaser Al-Onaizan (Al-Onaizan and Knight, 2002) transliterated an NE in Arabic into several candidates in English and ranked the candidates by comparing their counts in several English corpora. $$$$$ We have presented a named entity translation algorithm that performs at near human translation accuracy when translating Arabic named entities to English.

Al-Onaizan and Knight (2002) used Web statistics information to validate the translation candidates generated by language model, and obtained the accuracy of 72.6% in Arabic-English OOV word translation. $$$$$ Let’s illustrate this idea with the following example: We would like to translate the named entities that appear in the following Arabic excerpt: The Arabic newspaper article from which we extracted this excerpt is about negotiations between the US and North Korean authorities regarding the search for the remains of US soldiers who died during the Korean war.
Al-Onaizan and Knight (2002) used Web statistics information to validate the translation candidates generated by language model, and obtained the accuracy of 72.6% in Arabic-English OOV word translation. $$$$$ This allowed us to create a more precise query by adding Unsan to the search terms: Search Query 2: soldiers remains, search, North Korea, US, and Unsan.

Al-Onaizan and Knight (2002) describe a system which combines a phonetic based model with a spelling model for transliteration. $$$$$ Then, the list of candidates is re-scored using different monolingual clues (Section 4).
Al-Onaizan and Knight (2002) describe a system which combines a phonetic based model with a spelling model for transliteration. $$$$$ We have presented a named entity translation algorithm that performs at near human translation accuracy when translating Arabic named entities to English.
Al-Onaizan and Knight (2002) describe a system which combines a phonetic based model with a spelling model for transliteration. $$$$$ This section presents our evaluation results on the named entity translation task.

For example, the work of (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation. $$$$$ Translating a common name incorrectly has a significant effect on the translation accuracy.
For example, the work of (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation. $$$$$ 2“ al-mˇgls” is the same word as “ mˇgls” but with the definite article a- attached.
For example, the work of (Al-Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation. $$$$$ The algorithm uses very limited amount of hard-to-obtain bilingual resources and should be easily adaptable to other languages.

Al-Onaizan and Knight (2002b) suggested that pronunciation can be skipped and the target language letters can be mapped directly to source language letters. $$$$$ (1999)), translation of named entities has not.
Al-Onaizan and Knight (2002b) suggested that pronunciation can be skipped and the target language letters can be mapped directly to source language letters. $$$$$ Stalls and Knight (1998) present an Arabic-toEnglish back-transliteration system based on the source-channel framework.
Al-Onaizan and Knight (2002b) suggested that pronunciation can be skipped and the target language letters can be mapped directly to source language letters. $$$$$ In this example, we add Kofi Annan to the candidate list, and it is subsequently ranked at the top.

Similarly, Al-Onaizan and Knight (2002a; 2002b) only made use of transliteration information alone and so was not directly comparable. $$$$$ We present a novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources.
Similarly, Al-Onaizan and Knight (2002a; 2002b) only made use of transliteration information alone and so was not directly comparable. $$$$$ This can be done by comparing the shortened phrase with the rest of the named entity phrases of the same type.
Similarly, Al-Onaizan and Knight (2002a; 2002b) only made use of transliteration information alone and so was not directly comparable. $$$$$ Then, the list of candidates is re-scored using different monolingual clues (Section 4).

For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ In Section 5, we describe how the candidates list can be extended using contextual information.
For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ But before we present further details, we will discuss how words can be transliterated (i.e., “sounded-out”), which is a crucial component of our named entity translation algorithm.
For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ We would like to apply to other languages such as Chinese and Japanese and to investigate whether the current algorithm would perform as well or whether new algorithms might be needed.
For example, the work of (Al Onaizan and Knight, 2002a; Al-Onaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation. $$$$$ Once a ranked list of translation candidates is generated for a given phrase, several monolingual English resources are used to help re-rank the list.

Previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (Cao and Li, 2002) and named entity translation (Al-Onaizan and Knight, 2002). $$$$$ Table 1 shows the distribution of the named entity phrases into the three categories PERSON, ORGANIZATION , and LOCATION in the two data sets.
Previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (Cao and Li, 2002) and named entity translation (Al-Onaizan and Knight, 2002). $$$$$ We report on the application and evaluation of this algorithm in translating Arabic named entities to English.
Previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (Cao and Li, 2002) and named entity translation (Al-Onaizan and Knight, 2002). $$$$$ We report on the application and evaluation of this algorithm in translating Arabic named entities to English.
Previous work on defining subtasks within statistical machine translation has been performed on, e.g., noun-noun pair (Cao and Li, 2002) and named entity translation (Al-Onaizan and Knight, 2002). $$$$$ We report on the application and evaluation of this algorithm in translating Arabic named entities to English.

Al-Onaizan and Knight (2002), Huang (2003) and Ji and Grishman (2007) investigated the general name entity translation problem, especially in the context of machine translation. $$$$$ Named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere, and because many are domain specific, not to be found in bilingual dictionaries.
Al-Onaizan and Knight (2002), Huang (2003) and Ji and Grishman (2007) investigated the general name entity translation problem, especially in the context of machine translation. $$$$$ The score for a given candidate is given by a modified IBM Model 1 probability (Brown et al., 1993) as follows: where is the length of , is the length of , is a scaling factor based on the number of matches of found, and is the index of the English word aligned with according to alignment .
Al-Onaizan and Knight (2002), Huang (2003) and Ji and Grishman (2007) investigated the general name entity translation problem, especially in the context of machine translation. $$$$$ To address this situation, we need to extrapolate from the candidate list.
