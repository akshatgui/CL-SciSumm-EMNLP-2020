Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ As of this writing, the STRAND Web site (http://umiacs.umd.edu/∼resnik/strand/), presenting URL pairs discovered via STRAND runs, contains collections only for English-French, English-Chinese, EnglishBasque, and now English-Arabic, and we are not aware of any other efforts to disseminate Web-based parallel data publicly.
Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ The p2 tool divides up tasks intelligently, invoking each parallel computation on the local machine where the data reside.
Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ We are currently adapting statistical text-based sentence alignment techniques to take advantage of the markup available in Web-based document pairs.

Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ We have demonstrated that the tsim score can be used to extract translationally equivalent English-Chinese sentence pairs from even a noisy space with high precision (Smith 2002).
Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ We are currently adapting statistical text-based sentence alignment techniques to take advantage of the markup available in Web-based document pairs.
Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ The first step in this process is to linearize the HTML structure and ignore the actual linguistic content of the documents.
Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new contentbased measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.

Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ Finally we present our thoughts on future work and conclusions.
Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ Keezer for permitting and facilitating our use of the Internet Archive.
Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ In our experience, neither of these has significantly hurt the performance of tsim-based classifiers (as compared to finding the maximum cardinality bipartite matching and/or using the full documents), and in some cases competitive linking seems to improve performance.
Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ After building a single classifier on all 149 test pairs (the set on which both human judges agreed), we reclassified the entire candidate set.

For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. $$$$$ Parallel corpora—bodies of text in parallel translation, also known as bitexts—have taken on an important role in machine translation and multilingual natural language processing.
For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. $$$$$ The first step in this process is to linearize the HTML structure and ignore the actual linguistic content of the documents.
For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. $$$$$ Note that the full corpus is available as a list of Wayback Machine URLs at (http://umiacs.umd.edu/∼resnik/strand).
For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. $$$$$ 29 A list of Wayback Machine URLs is available at (http://umiacs.umd.edu/∼resnik/strand/); a sample of the document pairs is included in Appendix A.

Most existing studies, such as Nie (1999), Resnik and Smith (2003) and Shi (2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment method. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.
Most existing studies, such as Nie (1999), Resnik and Smith (2003) and Shi (2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment method. $$$$$ Even for the top handful of majority languages, the available parallel corpora tend to be unbalanced, representing primarily governmental or newswire-style texts.
Most existing studies, such as Nie (1999), Resnik and Smith (2003) and Shi (2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment method. $$$$$ Finally we present our thoughts on future work and conclusions.

Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ Also shown is the performance of the tsim-only classifier, assuming an optimal threshold is chosen.
Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.
Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ These kinds of problems are expected to be overcome during sentence alignment processing.
Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ Unfortunately, they are not readily available in the necessary quantities.

Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ Ignoring again pages from the (maktoob.com) domain, 2,206 pairs were marked as translations.
Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ The second step is to align the linearized sequences using a standard dynamic programming technique (Hunt and McIlroy 1975).
Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ Section 5 puts all the pieces together, using structural and combined content-structure matching of pages on the Internet Archive in order to obtain a sizable corpus of English-Arabic Web document pairs.
Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.

At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ Smith (2002) suggested a bootstrapping paradigm for the construction of parallel corpora.
At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ (Qualitatively, one judge was rather more strict than the other; when the stricter judge identified a page pair as valid translations, the less strict judge virtually always agreed.)
At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ The text from the pages is shown in full.
At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ Keezer for permitting and facilitating our use of the Internet Archive.

Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ For each item, participants were instructed to provide three ratings.
Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ It presents, in revised and considerably extended form, our early work on mining the Web for bilingual text (STRAND) (Resnik 1998, 1999), incorporating new work on content-based detection of translations (Smith 2001, 2002), and efficient exploitation of the Internet Archive.
Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ For example, the Arabic page in the first pair includes an additional caption not present in the English side.
Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web,first reviewing the original algorithm and results and then presenting a set of significant enhancements.

These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ A baseline system in which no filtering is done at all achieves 89.93% precision on the full labeled set (with 100% recall).
These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ These pages show the generally high quality of the corpus and also illustrate some of the potential difficulties with parallel Web data.
These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ Generating candidate pairs on the Archive involves the following steps: Steps 1 and 2 are performed via a parallel search operation plus combination of results; for example, extracting all URLs in the Hong Kong, Taiwan, or China domains (and their associated bookkeeping data) using a pattern like /(.hk|.tw|.cn)/.16 Step 3 is potentially tricky owing to computational complexity issues.
These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ The combination of these approaches may be profitable, particularly for languages that are represented only very sparsely on the Web.

STRAND (Resnik and Smith, 2003) is a system that acquires document pairs in parallel translation automatically from the Web. $$$$$ With respect to classifying document pairs as translations, the reader will notice that our approach to content-based cross-lingual similarity essentially boils down to a greedy matching of some of the words in a document pair using a dictionary.
STRAND (Resnik and Smith, 2003) is a system that acquires document pairs in parallel translation automatically from the Web. $$$$$ These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new contentbased measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.
STRAND (Resnik and Smith, 2003) is a system that acquires document pairs in parallel translation automatically from the Web. $$$$$ The more such pairings are found, the more likely the candidate documents are to represent a valid translation pair.

Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ 28 There were 1,796 unique English URLs and 1,779 unique Arabic URLs, giving document duplication rates of 1.4% and 2.4%, respectively.
Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ The text from the pages is shown in full.
Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new contentbased measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.
Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.

Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ For these reasons, parallel corpora can be thought of as a critical resource.
Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ Parallel Text Miner (PTMiner) (Chen and Nie 2000) exploits already-existing Web search engines to locate pages by querying for pages in a given language that contain links to pages that are likely to be in the other language of interest.
Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ In Section 2 we lay out the STRAND architecture, which is based on the insight that translated Web pages tend quite strongly to exhibit parallel structure, permitting them to be identified even without looking at content; we also show how we have improved STRAND’s performance by training a supervised classifier using structural parameters rather than relying on manually tuned thresholds.
Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ For example, given the bucket containing the two URLs in Figure 6, this step would generate a single pair consisting of be more efficient to create buckets by doing a parallel sort of the entire URL set using the handle as the key, and then creating buckets based on identical handles’ being on adjacent lines. the URL for the English page and the URL for the Arabic page, assuming the language ID information associated with each URL confirmed it was in the proper language.19 At this point, the candidate generation process is complete.

This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ Quality of the English:
This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ The model consists of a bilingual dictionary that gives a probability distribution p over all possible link types.
This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ The following page pairs (Figures 7–8) are representative of English-Arabic parallel corpus extracted from the Internet Archive.
This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ We are no different: As computational linguists working on multilingual issues, we view the Web as a great big body of text waiting to be mined, a huge fabric of linguistic data often interwoven with parallel threads.

Resnik and Smith (2003) develop a method for gathering parallel corpora from the web. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.
Resnik and Smith (2003) develop a method for gathering parallel corpora from the web. $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
Resnik and Smith (2003) develop a method for gathering parallel corpora from the web. $$$$$ The approximations discussed in Section 3.2.2 were employed: Competitive linking on the first 500 words in each document was used to compute the score.

Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ Quality of the English:
Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.
Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ Matching is performed by manually creating a list of substitution rules (e.g., english → big5),1 and for each English URL, applying all possible rules to generate URLs that might appear on the list of pages for the other language.

(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ For each item, participants were instructed to provide three ratings.
(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ Finally, we are indebted to several Computational Linguistics reviewers, whose comments helped us to greatly improve this article.
(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ Keezer for permitting and facilitating our use of the Internet Archive.
(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ This was a threefold cross-validation experiment in which decision tree classifiers were tuned on the features extracted for each candidate pair by structure-based classification.23 In addition to the four structural scores, we included two language identification confidence scores (one for the English page, one for the Arabic page); these were available as part of the Internet Archive’s bookkeeping information for each URL and required no additional computation on our part.

Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ Quality of the English:
Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ In addition, a decision tree produced by C5.0 can be translated into a fast C program that is a rapid classifier of document pairs.
Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ This provides a researcher with the remarkable sensation of having the entire Web on his or her hard drive.
Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ For each item, participants were instructed to provide three ratings.

Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ The text from the pages is shown in full.
Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ For example, suppose an English-Chinese site contains a page with URL (http://mysite.com/english/home en.html), on which one combination of substitutions might produce the URL (http://mysite.com/big5/home ch.html).
Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.
Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ We observe that the distribution of scores for Web data peaks at the highest rating and that the data are in both cases modestly bimodally distributed.

Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ The following page pairs (Figures 7–8) are representative of English-Arabic parallel corpus extracted from the Internet Archive.
Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ Quality of the English:
Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web,first reviewing the original algorithm and results and then presenting a set of significant enhancements.
