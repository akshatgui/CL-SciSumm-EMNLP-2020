Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ Keezer for permitting and facilitating our use of the Internet Archive.
Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ This technique yielded a 63MB parallel corpus of English-German.
Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ In addition, we used a list of .com domains known to originate in Arabic-speaking countries.
Approaches such as harvesting parallel corpora from the web (Resnik and Smith, 2003) address the creation of data. $$$$$ They represent resources for automatic lexical acquisition (e.g., Gale and Church 1991; Melamed 1997), they provide indispensable training data for statistical translation models (e.g., Brown et al. 1990; Melamed 2000; Och and Ney 2002), and they can provide the connection between vocabularies in cross-language information retrieval (e.g., Davis and Dunning 1995; Landauer and Littman 1990; see also Oard 1997).

Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ All these considerations motivate an approach to matching translations that pays attention to similarity of content, whether or not similarities of structure exist.
Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.
Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ Ultimately, the utility of parallel data from the Web is a question that will need to be addressed in practice.
Besides, there are also some other types of methods for mining parallel corpora from the web such as the work in (Resnik, 1998), (Resnik and Smith, 2003) and (Zhang et al, 2006). $$$$$ In our experience, neither of these has significantly hurt the performance of tsim-based classifiers (as compared to finding the maximum cardinality bipartite matching and/or using the full documents), and in some cases competitive linking seems to improve performance.

Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ When all possible English-Arabic page pairs were generated from all 19 The Internet Archive tags its data for language using standard n-gram language identification techniques. buckets, the result was 8,294 candidate pairs.
Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ Note that all word pairs in the enhanced dictionary are included; we have merely added to that dictionary by bootstrapping additional entries from the Bible.
Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ These kinds of problems are expected to be overcome during sentence alignment processing.
Unfortunately, parallel corpora are not readily available in large quantities, except for a small subset of the world's languages (see Resnik and Smith (2003) for discussion), therefore limiting the potential use of current SMT systems. $$$$$ With respect to classifying document pairs as translations, the reader will notice that our approach to content-based cross-lingual similarity essentially boils down to a greedy matching of some of the words in a document pair using a dictionary.

For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. $$$$$ Second, we required the matching algorithm to be fast, and algorithms for aligning tree structures are more demanding than those for linear structures.
For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. $$$$$ These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new contentbased measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.

Most existing studies, such as Nie (1999), Resnik and Smith (2003) and Shi (2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment method. $$$$$ In Section 3 we present an approach to detecting translations that relies entirely on content rather than structure, demonstrating performance comparable to STRAND’s using this orthogonal source of information.
Most existing studies, such as Nie (1999), Resnik and Smith (2003) and Shi (2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment method. $$$$$ For each item, participants were instructed to provide three ratings.
Most existing studies, such as Nie (1999), Resnik and Smith (2003) and Shi (2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment method. $$$$$ In our experience, neither of these has significantly hurt the performance of tsim-based classifiers (as compared to finding the maximum cardinality bipartite matching and/or using the full documents), and in some cases competitive linking seems to improve performance.
Most existing studies, such as Nie (1999), Resnik and Smith (2003) and Shi (2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment method. $$$$$ The following page pairs (Figures 7–8) are representative of English-Arabic parallel corpus extracted from the Internet Archive.

Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ Even for the top handful of majority languages, the available parallel corpora tend to be unbalanced, representing primarily governmental or newswire-style texts.
Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ More recently, researchers at Johns Hopkins University and the University of Maryland have been exploring new ways to exploit parallel corpora in order to develop monolingual resources and tools, using a process of annotation, projection, and training: Given a parallel corpus in English and a less resource-rich language, we project English annotations across the parallel corpus to the second language, using word-level alignments as the bridge, and then use robust statistical techniques in learning from the resulting noisy annotations (Cabezas, Dorr, and Resnik 2001; Diab and Resnik 2002; Hwa et al. 2002; Lopez et al.
Resnik and Smith (2003) exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents. $$$$$ Finally, we are indebted to several Computational Linguistics reviewers, whose comments helped us to greatly improve this article.

Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ An example of two texts with links is illustrated in Figure 4.
Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ When all possible English-Arabic page pairs were generated from all 19 The Internet Archive tags its data for language using standard n-gram language identification techniques. buckets, the result was 8,294 candidate pairs.
Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ Keezer for permitting and facilitating our use of the Internet Archive.
Earlier work on corpus collection from the web (e.g. (Resnik and Smith, 2003)) gave some hope that reasonably large quantities of parallel text could be found on the web, so that a bitext collection could be built for interesting language pairs(with one member of the pair usually being English) relatively cheaply. $$$$$ Finally, we are indebted to several Computational Linguistics reviewers, whose comments helped us to greatly improve this article.

At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ Finally, we are indebted to several Computational Linguistics reviewers, whose comments helped us to greatly improve this article.
At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ For example, consider two documents that begin as follows: Using this alignment, we compute four scalar values that characterize the quality of the alignment: dp The difference percentage, indicating nonshared material (i.e., alignment tokens that are in one linearized file but not the other). n The number of aligned nonmarkup text chunks of unequal length. r The correlation of lengths of the aligned nonmarkup chunks. p The significance level of the correlation r. The difference percentage (dp) quantifies the extent to which there are mismatches in the alignment: sequence tokens on one side that have no corresponding token on the other side.
At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ For each item, participants were instructed to provide three ratings.
At the other end of the spectrum, Resnik and Smith (2003) search the Web to detect web pages that are translations of each other. $$$$$ Keezer for permitting and facilitating our use of the Internet Archive.

Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ For each item, participants were instructed to provide three ratings.
Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.
Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ Section 5 puts all the pieces together, using structural and combined content-structure matching of pages on the Internet Archive in order to obtain a sizable corpus of English-Arabic Web document pairs.
Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. $$$$$ Parallel corpora have become an essential resource for work in multilingual natural language processing.

These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ For each item, participants were instructed to provide three ratings.
These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ All these considerations motivate an approach to matching translations that pays attention to similarity of content, whether or not similarities of structure exist.
These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ Because Arabic is a highly inflected language with many surface forms, we found it necessary to use morphological preprocessing in order to make effective use of a dictionary.
These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al, 2000) or (Poesio et al, 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al, 2002). $$$$$ For each item, participants were instructed to provide three ratings.

STRAND (Resnik and Smith, 2003) is a system that acquires document pairs in parallel translation automatically from the Web. $$$$$ Finally, we are indebted to several Computational Linguistics reviewers, whose comments helped us to greatly improve this article.
STRAND (Resnik and Smith, 2003) is a system that acquires document pairs in parallel translation automatically from the Web. $$$$$ We might then iteratively select additional page pairs in which the current classifier has high confidence of translational equivalence, gradually increasing the pool of parallel data and at the same time expanding the bilingual lexicon.
STRAND (Resnik and Smith, 2003) is a system that acquires document pairs in parallel translation automatically from the Web. $$$$$ The following page pairs (Figures 7–8) are representative of English-Arabic parallel corpus extracted from the Internet Archive.
STRAND (Resnik and Smith, 2003) is a system that acquires document pairs in parallel translation automatically from the Web. $$$$$ With respect to the generation of candidate pairs, we have described a progression from index-based searches on AltaVista to exhaustive matching of URLs on the Internet Archive.

Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ We observe that the distribution of scores for Web data peaks at the highest rating and that the data are in both cases modestly bimodally distributed.
Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ The following page pairs (Figures 7–8) are representative of English-Arabic parallel corpus extracted from the Internet Archive.
Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ Parallel corpora—bodies of text in parallel translation, also known as bitexts—have taken on an important role in machine translation and multilingual natural language processing.
Due to its significant growth, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al, 2001), commonsense retrieval (Matuszek et al, 2005), and so forth. $$$$$ The first step in this process is to linearize the HTML structure and ignore the actual linguistic content of the documents.

Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ Because Arabic is a highly inflected language with many surface forms, we found it necessary to use morphological preprocessing in order to make effective use of a dictionary.
Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ To use MWBM to find the most probable link sequence, let the L1 words be V1 and the L2 words be V2.
Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ For example, a set of LSSs for English-Arabic might be as follows (those containing numerals correspond to character code sets): 1256, 437, 864, 8859-1, 8859-6, a, ar, ara, arab, arabic, cp1256, cp437, cp864, e, en, eng, english, gb, iso, iso-8859-1, iso-8859-6, latin, latin-1, latin1, uk, us, usa For each URL, we form a “handle” by subtracting any substrings that match (insensitive to case) any item on the LSS pattern list.
Another approach to retrieving relevant documents involves the collection of relevant document URLs from the WWW (Resnik and Smith, 2003). $$$$$ These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new contentbased measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.

This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ All of these word pairs were added to the dictionary, each with a count of one.
This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ For such languages, index-based searches on words from a language of interest might be used to identify sites potentially containing parallel text.
This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new contentbased measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.
This is for instance the case of PTMINER (Chen and Nie, 2000) and STRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. $$$$$ The following page pairs (Figures 7–8) are representative of English-Arabic parallel corpus extracted from the Internet Archive.

Resnik and Smith (2003) develop a method for gathering parallel corpora from the web. $$$$$ A baseline system in which no filtering is done at all achieves 89.93% precision on the full labeled set (with 100% recall).
Resnik and Smith (2003) develop a method for gathering parallel corpora from the web. $$$$$ Figure 6 illustrates handle generation on two real URLs.
Resnik and Smith (2003) develop a method for gathering parallel corpora from the web. $$$$$ For example, the Arabic page in the first pair includes an additional caption not present in the English side.
Resnik and Smith (2003) develop a method for gathering parallel corpora from the web. $$$$$ Finally, we are indebted to several Computational Linguistics reviewers, whose comments helped us to greatly improve this article.

Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ These results are further improved by adding content-based similarity as a feature.
Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ We also have not explored any filtering on the noisy translation lexicon; doing so might improve the quality of the tsim score.
Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ In Section 3 we present an approach to detecting translations that relies entirely on content rather than structure, demonstrating performance comparable to STRAND’s using this orthogonal source of information.
Resnik and Smith (2003) employ the Web as parallel corpora to provide bilingual sentences for translation models. $$$$$ For each item, participants were instructed to provide three ratings.

(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new contentbased measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.
(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ Note that the full corpus is available as a list of Wayback Machine URLs at (http://umiacs.umd.edu/∼resnik/strand).
(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
(Resnik and Smith, 2003) show that parallel corpora for a variety of languages can be harvested on the Internet. $$$$$ For example, given the bucket containing the two URLs in Figure 6, this step would generate a single pair consisting of be more efficient to create buckets by doing a parallel sort of the entire URL set using the handle as the key, and then creating buckets based on identical handles’ being on adjacent lines. the URL for the English page and the URL for the Arabic page, assuming the language ID information associated with each URL confirmed it was in the proper language.19 At this point, the candidate generation process is complete.

Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ The features we are using are the same for any language pair.
Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ An example of two texts with links is illustrated in Figure 4.
Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ For example, the Arabic page in the first pair includes an additional caption not present in the English side.
Resnik and Smith (2003) extract bilingual sentences from the Web to create parallel corpora for machine translation. $$$$$ For English, we tokenized the text and used the WordNet lemmatizer to strip suffixes.

Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ Also shown is the performance of the tsim-only classifier, assuming an optimal threshold is chosen.
Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.
Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ For each item, participants were instructed to provide three ratings.
Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (Resnik and Smith,2003) identifies potentially parallel documents using cues from URLs and document content. $$$$$ Until very recently, for example, statistical work in machine translation focused heavily on French-English translation because the Canadian parliamentary proceedings (Hansards) in English and French were the only large bitext available.

Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ Finally, we are indebted to several Computational Linguistics reviewers, whose comments helped us to greatly improve this article.
Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ By way of context, Chen and Nie (2000) reported that PTMiner found around 15,000 English-Chinese document pairs by crawling 185 sites in the .hk (Hong Kong) domain, with the run taking about a week.
Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ Note that the full corpus is available as a list of Wayback Machine URLs at (http://umiacs.umd.edu/∼resnik/strand).
Our system is based on the STRAND algorithm (Resnik and Smith, 2003). $$$$$ It remains to be seen whether weights in the dictionary can be exploited (Smith [2001] suggests that empirically estimated joint translation probabilities for word pairs are not useful).
