The BioScope corpus has been used to train and evaluate automatic classifiers (e.g. Ozgur and Radev (2009) and Morante and Daelemans (2009)) with promising results. $$$$$ The list and the scheme are validated by annotating 202 MEDLINE abstracts.
The BioScope corpus has been used to train and evaluate automatic classifiers (e.g. Ozgur and Radev (2009) and Morante and Daelemans (2009)) with promising results. $$$$$ As mentioned earlier, we are not aware of research that has focused on learning the scope of hedge signals inside or outside of the biomedical domain, which makes a direct comparison with the approaches described here impossible.
The BioScope corpus has been used to train and evaluate automatic classifiers (e.g. Ozgur and Radev (2009) and Morante and Daelemans (2009)) with promising results. $$$$$ In the hedge finding phase, the system achieves an F1 of 84.77% in the abstracts subcorpus.
The BioScope corpus has been used to train and evaluate automatic classifiers (e.g. Ozgur and Radev (2009) and Morante and Daelemans (2009)) with promising results. $$$$$ In the hedge finding phase, the system achieves an F1 of 84.77% in the abstracts subcorpus.

Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a supervised sequence labeling approach while Ozgur and Radev (2009) developed a rule-based system that exploits syntactic patterns. $$$$$ The second classification task consists of classifying the tokens of a sentence as being the first element of the scope, the last, or neither.
Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a supervised sequence labeling approach while Ozgur and Radev (2009) developed a rule-based system that exploits syntactic patterns. $$$$$ Our work was made possible through financial support from the University of Antwerp (GOA project BIOGRAPH).
Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a supervised sequence labeling approach while Ozgur and Radev (2009) developed a rule-based system that exploits syntactic patterns. $$$$$ They report experiments with SVMs on a dataset that they make publicly available1.
Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a supervised sequence labeling approach while Ozgur and Radev (2009) developed a rule-based system that exploits syntactic patterns. $$$$$ Szarvas (2008) follows Medlock and Briscoe (2007) in classifying sentences as being speculative or nonspeculative.

Most systems following Morante and Daelemans (2009) used three class labels (F) IRST, (L) AST and NONE. $$$$$ This observation is consistent with the observation that the portability of hedge classifiers is limited, made by Szarvas (Szarvas, 2008).
Most systems following Morante and Daelemans (2009) used three class labels (F) IRST, (L) AST and NONE. $$$$$ Some NLP applications incorporate modality information.
Most systems following Morante and Daelemans (2009) used three class labels (F) IRST, (L) AST and NONE. $$$$$ This allows the system to find multiword hedge cues.
Most systems following Morante and Daelemans (2009) used three class labels (F) IRST, (L) AST and NONE. $$$$$ We are thankful to three anonymous reviewers for their valuable comments.

The following summarizes the steps we took to achieve this goal. Similarly to previous work in hedge cue detection (Morante and Daelemans, 2009), we first convert the task into a sequential labeling task based on the BIO scheme, where each word in a hedge cue is labeled as B-CUE, I-CUE, or O, indicating respectively the labeled word is at the beginning of a cue, inside of a cue, or outside of a hedge cue; this is similar to the tagging scheme from the CoNLL-2001 shared task. $$$$$ The system combines several classifiers and works in two phases: in the first phase hedge cues (i.e., words indicating speculative language) are identified, and in the second phase the full scope of these hedge cues is found.
The following summarizes the steps we took to achieve this goal. Similarly to previous work in hedge cue detection (Morante and Daelemans, 2009), we first convert the task into a sequential labeling task based on the BIO scheme, where each word in a hedge cue is labeled as B-CUE, I-CUE, or O, indicating respectively the labeled word is at the beginning of a cue, inside of a cue, or outside of a hedge cue; this is similar to the tagging scheme from the CoNLL-2001 shared task. $$$$$ In this paper we present a machine learning system that finds the scope of hedge cues in biomedical texts.
The following summarizes the steps we took to achieve this goal. Similarly to previous work in hedge cue detection (Morante and Daelemans, 2009), we first convert the task into a sequential labeling task based on the BIO scheme, where each word in a hedge cue is labeled as B-CUE, I-CUE, or O, indicating respectively the labeled word is at the beginning of a cue, inside of a cue, or outside of a hedge cue; this is similar to the tagging scheme from the CoNLL-2001 shared task. $$$$$ We also experimented with IB1, but it produced lower results.
The following summarizes the steps we took to achieve this goal. Similarly to previous work in hedge cue detection (Morante and Daelemans, 2009), we first convert the task into a sequential labeling task based on the BIO scheme, where each word in a hedge cue is labeled as B-CUE, I-CUE, or O, indicating respectively the labeled word is at the beginning of a cue, inside of a cue, or outside of a hedge cue; this is similar to the tagging scheme from the CoNLL-2001 shared task. $$$$$ Identifying hedged information in biomedical literature is an important subtask in information extraction because it would be misleading to extract speculative information as factual information.

To tackle the hedge cue detection problem posed by the CoNLL-2010 shared task, we utilized a classifier for sequential labeling following previous work (Morante and Daelemans, 2009). $$$$$ Contrary to current practice to only detect modality, our system also determines the part of the sentence that is hedged.
To tackle the hedge cue detection problem posed by the CoNLL-2010 shared task, we utilized a classifier for sequential labeling following previous work (Morante and Daelemans, 2009). $$$$$ We are thankful to three anonymous reviewers for their valuable comments.
To tackle the hedge cue detection problem posed by the CoNLL-2010 shared task, we utilized a classifier for sequential labeling following previous work (Morante and Daelemans, 2009). $$$$$ (2) apparent, apparently, appear, assume, can, consider, consistent with, could, either, indicate, likely, may, no evidence, not, or, perhaps, possible, possibly, presumably, probable, probably, should, suggestion, support, think, unclear, whether, would 35 hedge cues that occur in the clinical reports subcorpus do not occur in the abstracts subcorpus, and 34 hedge cues that appear in the papers subcorpus do not appear in the abstracts subcorpus.
To tackle the hedge cue detection problem posed by the CoNLL-2010 shared task, we utilized a classifier for sequential labeling following previous work (Morante and Daelemans, 2009). $$$$$ Work on hedging in the machine learning field has as a goal to classify sentences into speculative or definite (non speculative).

In Morante and Daelemans (2009), the hedge detection task is solved as two consecutive classification tasks. $$$$$ Most work concentrates on finding relations between biological entities, like genes and proteins (Krauthammer et al., 2002; Mitsumori et al., 2006; Krallinger et al., 2008a; Krallinger et al., 2008b).
In Morante and Daelemans (2009), the hedge detection task is solved as two consecutive classification tasks. $$$$$ The second classification task consists of classifying the tokens of a sentence as being the first element of the scope, the last, or neither.
In Morante and Daelemans (2009), the hedge detection task is solved as two consecutive classification tasks. $$$$$ We are not aware of other systems that perform this task.
In Morante and Daelemans (2009), the hedge detection task is solved as two consecutive classification tasks. $$$$$ This allows the system to find multiword hedge cues.

As the baseline classifier, we use the Cue Dictionary proposed in Morante and Daelemans (2009), classifying each occurrence of those words as a cue. $$$$$ The results of the system based on gold standard hedge cues showed that the system can be applied to negation scope finding and hedge scope finding, but these results show that the results of the second phase of the system depend on the results of the first phase of the system, and that finding hedge cues is a domain dependent task.
As the baseline classifier, we use the Cue Dictionary proposed in Morante and Daelemans (2009), classifying each occurrence of those words as a cue. $$$$$ In this paper we have presented a metalearning approach to processing the scope of hedge cues, based on a system that finds the scope of negation cues.
As the baseline classifier, we use the Cue Dictionary proposed in Morante and Daelemans (2009), classifying each occurrence of those words as a cue. $$$$$ The second classification task consists of classifying the tokens of a sentence as being the first element of the scope, the last, or neither.
As the baseline classifier, we use the Cue Dictionary proposed in Morante and Daelemans (2009), classifying each occurrence of those words as a cue. $$$$$ This allows the system to find multiword hedge cues.

Also, the task of hedge detection (Morante and Daelemans, 2009) can be solved separately, in the original sentences, after the interacting pairs have been found. $$$$$ - If one token has been predicted as LAST and none as FIRST, the sequence will start at the hedge cue and it will finish at the token predicted as LAST.
Also, the task of hedge detection (Morante and Daelemans, 2009) can be solved separately, in the original sentences, after the interacting pairs have been found. $$$$$ The system is based on a similar system that finds the scope of negation cues.
Also, the task of hedge detection (Morante and Daelemans, 2009) can be solved separately, in the original sentences, after the interacting pairs have been found. $$$$$ Our work was made possible through financial support from the University of Antwerp (GOA project BIOGRAPH).
Also, the task of hedge detection (Morante and Daelemans, 2009) can be solved separately, in the original sentences, after the interacting pairs have been found. $$$$$ The second classification task consists of classifying the tokens of a sentence as being the first element of the scope, the last, or neither.

Parts of the system are similar to that of Morante and Daelemans (2009) both make use of machine learning to tag tokens as being in a cue or a scope. $$$$$ In Section 2, we summarise related work.
Parts of the system are similar to that of Morante and Daelemans (2009) both make use of machine learning to tag tokens as being in a cue or a scope. $$$$$ The experiments achieve a recall/precision break even point (BEP) of 0.76.
Parts of the system are similar to that of Morante and Daelemans (2009) both make use of machine learning to tag tokens as being in a cue or a scope. $$$$$ Although the tasks are different, we consider that the results of our system are competitive.
Parts of the system are similar to that of Morante and Daelemans (2009) both make use of machine learning to tag tokens as being in a cue or a scope. $$$$$ We are thankful to three anonymous reviewers for their valuable comments.

The presence of potential clause ending words, used by Morante and Daelemans (2009), is included as a feature type with values $$$$$ We are thankful to three anonymous reviewers for their valuable comments.
The presence of potential clause ending words, used by Morante and Daelemans (2009), is included as a feature type with values $$$$$ They report experiments with SVMs on a dataset that they make publicly available1.
The presence of potential clause ending words, used by Morante and Daelemans (2009), is included as a feature type with values $$$$$ This allows the system to find multiword hedge cues.
The presence of potential clause ending words, used by Morante and Daelemans (2009), is included as a feature type with values $$$$$ In the case of the negation scope finding system, the evaluation on the clinical subcorpus yielded a 4.23% PCS higher result, whereas in the case of the hedge scope finding system the results are almost 30.00% PCS lower, confirming the observation that the portability of hedge classifers is limited.

Vincze et al (2008) created a publicly available annotated corpus of biomedical papers, abstracts and clinical data called BioScope, parts of which were also used as training data for the CoNLL10 shared task, building on the dataset and annotation scheme used for evaluation by Medlock and Briscoe (2007). Morante and Daelemans (2009) use the BioScope corpus to approach the problem of identifying cues and scopes via supervised machine learning. $$$$$ We are thankful to three anonymous reviewers for their valuable comments.
Vincze et al (2008) created a publicly available annotated corpus of biomedical papers, abstracts and clinical data called BioScope, parts of which were also used as training data for the CoNLL10 shared task, building on the dataset and annotation scheme used for evaluation by Medlock and Briscoe (2007). Morante and Daelemans (2009) use the BioScope corpus to approach the problem of identifying cues and scopes via supervised machine learning. $$$$$ Contrary to current practice to only detect modality, our system also determines the part of the sentence that is hedged.
Vincze et al (2008) created a publicly available annotated corpus of biomedical papers, abstracts and clinical data called BioScope, parts of which were also used as training data for the CoNLL10 shared task, building on the dataset and annotation scheme used for evaluation by Medlock and Briscoe (2007). Morante and Daelemans (2009) use the BioScope corpus to approach the problem of identifying cues and scopes via supervised machine learning. $$$$$ A sentence consists of a sequence of tokens, each one starting on a new line.
Vincze et al (2008) created a publicly available annotated corpus of biomedical papers, abstracts and clinical data called BioScope, parts of which were also used as training data for the CoNLL10 shared task, building on the dataset and annotation scheme used for evaluation by Medlock and Briscoe (2007). Morante and Daelemans (2009) use the BioScope corpus to approach the problem of identifying cues and scopes via supervised machine learning. $$$$$ Our work was made possible through financial support from the University of Antwerp (GOA project BIOGRAPH).

Morante and Daelemans (2009) presented a meta-learning system that finds the scope of hedge cues in biomedical texts. $$$$$ We model this task in the same way that we modelled the task for finding the scope of negation (Morante and Daelemans, 2009), i.e., as two consecutive classification tasks: a first one that consists of classifying the tokens of a sentence as being at the beginning of a hedge signal, inside or outside.
Morante and Daelemans (2009) presented a meta-learning system that finds the scope of hedge cues in biomedical texts. $$$$$ In this phase, a classifier predicts for all tokens in a sentence whether a token is the first token of a hedge cue (B-cue), inside a hedge cue (I-cue), or outside of it (O-cue).
Morante and Daelemans (2009) presented a meta-learning system that finds the scope of hedge cues in biomedical texts. $$$$$ The system is based on a similar system that finds the scope of negation cues.
Morante and Daelemans (2009) presented a meta-learning system that finds the scope of hedge cues in biomedical texts. $$$$$ We model this task in the same way that we modelled the task for finding the scope of negation (Morante and Daelemans, 2009), i.e., as two consecutive classification tasks: a first one that consists of classifying the tokens of a sentence as being at the beginning of a hedge signal, inside or outside.

Shallow linguistic features are introduced in their experiments. Morante and Daelemans (2009) present their research on identifying hedge cues and their scopes. $$$$$ Results also show that the system based on predicted hedge cues performs lower for all corpora, which is also a trend observed for the negation scope finding system.
Shallow linguistic features are introduced in their experiments. Morante and Daelemans (2009) present their research on identifying hedge cues and their scopes. $$$$$ In the same corpora the number of negation cues is lower, 38.
Shallow linguistic features are introduced in their experiments. Morante and Daelemans (2009) present their research on identifying hedge cues and their scopes. $$$$$ Our work was made possible through financial support from the University of Antwerp (GOA project BIOGRAPH).
Shallow linguistic features are introduced in their experiments. Morante and Daelemans (2009) present their research on identifying hedge cues and their scopes. $$$$$ The fact that, despite a very low PCS, precision, recall and F1 are relatively high indicates that these measures are in themselves not reliable to evaluate the performance of the system.

More experiments could be found in their paper (Morante and Daelemans, 2009). $$$$$ Future research will focus on trying to improve the first phase of the system and anlysing errors in depth in order to get insights into how to get a better performance.
More experiments could be found in their paper (Morante and Daelemans, 2009). $$$$$ This suggests that when a scope is incorrectly predicted, main content tokens are also incorrectly left out of the scope or added.
More experiments could be found in their paper (Morante and Daelemans, 2009). $$$$$ In the scope finding phase, the system that uses predicted hedge cues achieves 65.55% PCS in the abstracts corpus, which is very similar to the result obtained by the negation scope finding system with predicted negation cues (66.07% PCS).

The main difference between the two systems is that Morante and Daelemans (2009) perform the second phase with a machine learner, whereas Ozgur and Radev (2009) perform the second phase witha rule-based system that exploits syntactic information. $$$$$ CRFs define a conditional probability distribution over label sequences given a particular observation sequence rather than a joint distribution over label and observation sequences, and are reported to avoid the label bias problem of HMMs and other learning approaches.
The main difference between the two systems is that Morante and Daelemans (2009) perform the second phase with a machine learner, whereas Ozgur and Radev (2009) perform the second phase witha rule-based system that exploits syntactic information. $$$$$ We show that the same scope finding approach can be applied to both negation and hedging.
The main difference between the two systems is that Morante and Daelemans (2009) perform the second phase with a machine learner, whereas Ozgur and Radev (2009) perform the second phase witha rule-based system that exploits syntactic information. $$$$$ We have shown that the same system can find both the scope of negation and hedge cues.
The main difference between the two systems is that Morante and Daelemans (2009) perform the second phase with a machine learner, whereas Ozgur and Radev (2009) perform the second phase witha rule-based system that exploits syntactic information. $$$$$ The classifier was parameterised by using gain ratio for feature weighting.

The approach to resolving the scopes of hedge cues that we present in this paper is similar to the approach followed in Morante and Daelemans (2009) in that the task is modelled in the same way. $$$$$ The system is based on a similar system that finds the scope of negation cues.
The approach to resolving the scopes of hedge cues that we present in this paper is similar to the approach followed in Morante and Daelemans (2009) in that the task is modelled in the same way. $$$$$ The system is based on a similar system that finds the scope of negation cues.
The approach to resolving the scopes of hedge cues that we present in this paper is similar to the approach followed in Morante and Daelemans (2009) in that the task is modelled in the same way. $$$$$ As with that system, we also observed that the papers subcorpus tends to get lower scores than the abstracts subcorpus.
The approach to resolving the scopes of hedge cues that we present in this paper is similar to the approach followed in Morante and Daelemans (2009) in that the task is modelled in the same way. $$$$$ They treat a wide spectrum of modal types and present the codification of modality information with the specification language TimeML, which allows to mark modality cues at a lexical level and at a syntactic level.

A difference between the two systems is that this system uses only one classifier to solve Task 2, whereas the system described in Morante and Daelemans (2009) used three classifiers and a metalearner. $$$$$ The method they use to derive a learning model from a seed corpus is based on iteratively predicting labels for unlabeled training samples.
A difference between the two systems is that this system uses only one classifier to solve Task 2, whereas the system described in Morante and Daelemans (2009) used three classifiers and a metalearner. $$$$$ We are thankful to three anonymous reviewers for their valuable comments.

Another difference is that the system in Morante and Daelemans (2009) used shallow syntactic features, whereas this system uses features from both shallow and dependency syntax. $$$$$ The second classification task consists of classifying the tokens of a sentence as being the first element of the scope, the last, or neither.
Another difference is that the system in Morante and Daelemans (2009) used shallow syntactic features, whereas this system uses features from both shallow and dependency syntax. $$$$$ The upper-bound results of the metalearner system assuming gold standard identification of hedge cues are shown in Table 6.
Another difference is that the system in Morante and Daelemans (2009) used shallow syntactic features, whereas this system uses features from both shallow and dependency syntax. $$$$$ Identifying hedged information in biomedical literature is an important subtask in information extraction because it would be misleading to extract speculative information as factual information.

It is not really possible to compare the scores obtained in this task to existing research previous to the CoNLL-2010 Shared Task, namely the results obtained by Ozgur and Radev (2009) on the BioScope corpus with a rule-based system and byMorante and Daelemans (2009) on the same corpus with a combination of classifiers. $$$$$ The BioScope corpus consists of three parts: clinical free-texts (radiology reports), biological full papers and biological paper abstracts from the GENIA corpus (Collier et al., 1999).
It is not really possible to compare the scores obtained in this task to existing research previous to the CoNLL-2010 Shared Task, namely the results obtained by Ozgur and Radev (2009) on the BioScope corpus with a rule-based system and byMorante and Daelemans (2009) on the same corpus with a combination of classifiers. $$$$$ Finding the scope of a hedge cue means determining at sentence level which words in the sentence are affected by the hedge cue.
It is not really possible to compare the scores obtained in this task to existing research previous to the CoNLL-2010 Shared Task, namely the results obtained by Ozgur and Radev (2009) on the BioScope corpus with a rule-based system and byMorante and Daelemans (2009) on the same corpus with a combination of classifiers. $$$$$ The evaluation is made using the precision and recall measures (Van Rijsbergen, 1979), and their harmonic mean, F-score.
It is not really possible to compare the scores obtained in this task to existing research previous to the CoNLL-2010 Shared Task, namely the results obtained by Ozgur and Radev (2009) on the BioScope corpus with a rule-based system and byMorante and Daelemans (2009) on the same corpus with a combination of classifiers. $$$$$ The system combines several classifiers and works in two phases: in the first phase hedge cues (i.e., words indicating speculative language) are identified, and in the second phase the full scope of these hedge cues is found.

Morante and Daelemans (2009) report percentage of correct scopes for the full text data set (42.37), obtained by training on the abstracts data set, whereas the results presented in Table 5 are reported in Fmeasures and obtained in by training and testing on other corpora. $$$$$ We model this task in the same way that we modelled the task for finding the scope of negation (Morante and Daelemans, 2009), i.e., as two consecutive classification tasks: a first one that consists of classifying the tokens of a sentence as being at the beginning of a hedge signal, inside or outside.
Morante and Daelemans (2009) report percentage of correct scopes for the full text data set (42.37), obtained by training on the abstracts data set, whereas the results presented in Table 5 are reported in Fmeasures and obtained in by training and testing on other corpora. $$$$$ Szarvas develops a MaxEnt system that incorporates bigrams and trigrams in the feature representation and performs a complex feature selection procedure in order to reduce the number of keyword candidates.
Morante and Daelemans (2009) report percentage of correct scopes for the full text data set (42.37), obtained by training on the abstracts data set, whereas the results presented in Table 5 are reported in Fmeasures and obtained in by training and testing on other corpora. $$$$$ According to the gain ratio scores, the most informative features are the lemma and word of the token in focus, followed by the word of the token to the right and of the token to the left.
