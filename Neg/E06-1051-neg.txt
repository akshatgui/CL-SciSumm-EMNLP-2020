We propose a hybrid kernel by combining the proposed feature based kernel (outlined above) with the Shallow Linguistic (SL) kernel (Giuliano et al., 2006) and the Path-enclosed Tree (PET) kernel (Moschitti, 2004). $$$$$ As mentioned in Section 1, another relevant approach is presented in (Roth and Yih, 2002).
We propose a hybrid kernel by combining the proposed feature based kernel (outlined above) with the Shallow Linguistic (SL) kernel (Giuliano et al., 2006) and the Path-enclosed Tree (PET) kernel (Moschitti, 2004). $$$$$ We would like to thank Razvan Bunescu for providing detailed information about the AImed data set and the settings of the experiments.
We propose a hybrid kernel by combining the proposed feature based kernel (outlined above) with the Shallow Linguistic (SL) kernel (Giuliano et al., 2006) and the Path-enclosed Tree (PET) kernel (Moschitti, 2004). $$$$$ It consists of 225 Medline abstracts: 200 are known to describe interactions between human proteins, while the other 25 do not refer to any interaction.

An interesting finding is that the Shallow Linguistic (SL) kernel (Giuliano et al 2006) (to be discussed in Section 4.2), despite its simplicity, is on par with the best kernels in most of the evaluation settings. $$$$$ Other relevant approaches include those that adopt kernel methods to perform relation extraction.
An interesting finding is that the Shallow Linguistic (SL) kernel (Giuliano et al 2006) (to be discussed in Section 4.2), despite its simplicity, is on par with the best kernels in most of the evaluation settings. $$$$$ A second reason concerns the fact that syntactic parsing is not always robust enough to deal with real-world sentences.
An interesting finding is that the Shallow Linguistic (SL) kernel (Giuliano et al 2006) (to be discussed in Section 4.2), despite its simplicity, is on par with the best kernels in most of the evaluation settings. $$$$$ Despite the positive results obtained exploiting syntactic information, we claim that there is still room for improvement relying exclusively on shallow linguistic information for two main reasons.
An interesting finding is that the Shallow Linguistic (SL) kernel (Giuliano et al 2006) (to be discussed in Section 4.2), despite its simplicity, is on par with the best kernels in most of the evaluation settings. $$$$$ The results show that our approach outperforms most of the previous methods based on syntactic and semantic information.

The Shallow Linguistic (SL) kernel was proposed by Giuliano et al (2006). $$$$$ Zelenko et al. (2003) describe a relation extraction algorithm that uses a tree kernel defined over a shallow parse tree representation of sentences.
The Shallow Linguistic (SL) kernel was proposed by Giuliano et al (2006). $$$$$ We use a combination of kernel functions to integrate two different information sources: (i) the whole sentence where the relation appears, and (ii) the local contexts around the interacting entities.
The Shallow Linguistic (SL) kernel was proposed by Giuliano et al (2006). $$$$$ The results show that our approach outperforms most of the previous methods based on syntactic and semantic information.
The Shallow Linguistic (SL) kernel was proposed by Giuliano et al (2006). $$$$$ Second, we plan to test the portability of our model on ACE and MUC data sets.

 $$$$$ A second reason concerns the fact that syntactic parsing is not always robust enough to deal with real-world sentences.
 $$$$$ It consists of 225 Medline abstracts: 200 are known to describe interactions between human proteins, while the other 25 do not refer to any interaction.
 $$$$$ NC2.

 $$$$$ Orthographic This feature maps each token into equivalence classes that encode attributes such as capitalization, punctuation, numerals and so on.
 $$$$$ It consists of 225 Medline abstracts: 200 are known to describe interactions between human proteins, while the other 25 do not refer to any interaction.
 $$$$$ As typically done in entity recognition, we represent each local context by using the following basic features: Token The token itself.
 $$$$$ Our long term goal is to populate databases and ontologies by extracting information from large text collections such as Medline.

A similar finding can be seen, for example, in the relatively flat learning curve of Giuliano et al (2006). $$$$$ The best results on the LLL challenge were obtained by the group from the University of Edinburgh (Reidel and Klein, 2005), which used Markov Logic, a framework that combines loglinear models and First Order Logic, to create a set of weighted clauses which can classify pairs of gene named entities as genic interactions.
A similar finding can be seen, for example, in the relatively flat learning curve of Giuliano et al (2006). $$$$$ We use a combination of kernel functions to integrate two different information sources: (i) the whole sentence where the relation appears, and (ii) the local contexts around the interacting entities.
A similar finding can be seen, for example, in the relatively flat learning curve of Giuliano et al (2006). $$$$$ Claudio Giuliano and Lorenza Romano have been supported by the ONTOTEXT project, funded by the Autonomous Province of Trento under the FUP2004 research program.

 $$$$$ With this aim, we will integrate the output of a parser (possibly trained on a domain-specific resource such the Genia Treebank).
 $$$$$ The approach is vulnerable to unrecoverable parsing errors.
 $$$$$ It consists of 225 Medline abstracts: 200 are known to describe interactions between human proteins, while the other 25 do not refer to any interaction.
 $$$$$ The two data sets used for the experiments concern the same domain (i.e. gene/protein interactions).

The former approach can produce higher performance $$$$$ Zelenko et al. (2003) describe a relation extraction algorithm that uses a tree kernel defined over a shallow parse tree representation of sentences.
The former approach can produce higher performance $$$$$ The good results obtained using only shallow linguistic features provide a higher baseline against which it is possible to measure improvements obtained using methods based on deep linguistic processing.
The former approach can produce higher performance $$$$$ Second, we plan to test the portability of our model on ACE and MUC data sets.

Our method outperforms most studies using similar evaluation methodology, with the exception being the approach of Giuliano et al (2006). $$$$$ For example, most of the participants at the Learning Language in Logic (LLL) challenge on Genic Interaction Extraction (see Section 4.2) were unable to successfully exploit linguistic information provided by parsers.
Our method outperforms most studies using similar evaluation methodology, with the exception being the approach of Giuliano et al (2006). $$$$$ We performed experiments on extracting gene and protein interactions from two different data sets.
Our method outperforms most studies using similar evaluation methodology, with the exception being the approach of Giuliano et al (2006). $$$$$ The first subset does not include coreferences, while the second one includes simple cases of coreference, mainly appositions.
Our method outperforms most studies using similar evaluation methodology, with the exception being the approach of Giuliano et al (2006). $$$$$ Third, we would like to use a named entity recognizer instead of assuming that entities are already extracted or given by a dictionary.

Airola et al. (2008) repeat the method published by Giuliano et al (2006) with a correctly preprocessed AIMed and reported an F1-score of 52.4%. $$$$$ First of all, we describe the complex case, namely the protein/gene interactions (LLL challenge).
Airola et al. (2008) repeat the method published by Giuliano et al (2006) with a correctly preprocessed AIMed and reported an F1-score of 52.4%. $$$$$ Despite the positive results obtained exploiting syntactic information, we claim that there is still room for improvement relying exclusively on shallow linguistic information for two main reasons.

 $$$$$ In our approach we cast relation extraction as a classification problem, in which examples are generated from sentences as follows.
 $$$$$ In this data set there is no distinction between genes and proteins and the relations are symmetric.
 $$$$$ The motivations for using these benchmarks derive from the increasing applicative interest in tools able to extract relations between relevant entities in biomedical texts and, consequently, from the growing availability of annotated data sets.
 $$$$$ We use a combination of kernel functions to integrate two different information sources: (i) the whole sentence where the relation appears, and (ii) the local contexts around the interacting entities.

In addition to word features, Giuliano et al (2006) extract shallow linguistic information such as POS tag, lemma, and orthographic features of tokens for PPI extraction. $$$$$ The results show that our approach outperforms most of the previous methods based on syntactic and semantic information.
In addition to word features, Giuliano et al (2006) extract shallow linguistic information such as POS tag, lemma, and orthographic features of tokens for PPI extraction. $$$$$ In order to implement the approach based on shallow linguistic information we employed a linear combination of kernels.
In addition to word features, Giuliano et al (2006) extract shallow linguistic information such as POS tag, lemma, and orthographic features of tokens for PPI extraction. $$$$$ Furthermore, under-sampling allows us to halve the data set size and reduce the data skewness.

On the LLL data set, the LA method using distributional similarity measures significantly outperforms both baselines and also yields better results than an approach based on shallow linguistic information (Giuliano et al, 2006). $$$$$ 9After the challenge deadline, Reidel and Klein (2005) achieved a significant improvement, Fl = 68.4% (without coreferences) and Fl = 64.7% (with and without coreferences). presence of the relation and roles of the interacting entities), they perform reasonably well even when considered separately.
On the LLL data set, the LA method using distributional similarity measures significantly outperforms both baselines and also yields better results than an approach based on shallow linguistic information (Giuliano et al, 2006). $$$$$ For instance: [P1] - [P2] association, [P1] and [P2] interact, [P1] has influence on [P2] binding.
On the LLL data set, the LA method using distributional similarity measures significantly outperforms both baselines and also yields better results than an approach based on shallow linguistic information (Giuliano et al, 2006). $$$$$ The results show that our approach outperforms most of the previous methods based on syntactic and semantic information.
On the LLL data set, the LA method using distributional similarity measures significantly outperforms both baselines and also yields better results than an approach based on shallow linguistic information (Giuliano et al, 2006). $$$$$ Recent evaluation campaigns on bio-entity recognition, such as BioCreAtIvE and JNLPBA 2004 shared task, have shown that several systems are able to achieve good performance (even if it is a bit worse than that reported on news articles).

Giuliano et al (2006) use no syntactic information. $$$$$ Claudio Giuliano and Lorenza Romano have been supported by the ONTOTEXT project, funded by the Autonomous Province of Trento under the FUP2004 research program.
Giuliano et al (2006) use no syntactic information. $$$$$ As a matter of fact, generating examples for each ordered pair of entities would produce two subsets of the same size containing similar examples (differing only for the attributes CANDIDATE and OTHER), but with different classification labels.
Giuliano et al (2006) use no syntactic information. $$$$$ In each example we assign the attribute CANDIDATE to each of the candidate interacting entities, while the other entities in the example are assigned the attribute OTHER, meaning that they do not participate in the relation.
Giuliano et al (2006) use no syntactic information. $$$$$ For example, as the sentence shown in Figure 1 contains three entities, the total number of examples generated is 3C2 = 3.

 $$$$$ As said at the beginning of this section, this task is simpler than the LLL challenge because there is no distinction between types (all entities are proteins) and roles (the relation is symmetric).
 $$$$$ The whole sentence where the entities appear (global context) is used to discover the presence of a relation between two entities, similarly to what was done by Bunescu and Mooney (2005b).
 $$$$$ As observed in (Ned´ellec, 2005), the scores obtained using the training set without coreferences and the whole training set are similar.

In contrast, work reported in (Giuliano et al, 2006) does not make use of syntactic information which on the data without coreferences yields higher recall. $$$$$ For instance: [P1] - [P2] association, [P1] and [P2] interact, [P1] has influence on [P2] binding.
In contrast, work reported in (Giuliano et al, 2006) does not make use of syntactic information which on the data without coreferences yields higher recall. $$$$$ The basic idea behind kernel methods is to embed the input data into a suitable feature space F via a mapping function 0 : X → F, and then use a linear algorithm for discovering nonlinear patterns.
In contrast, work reported in (Giuliano et al, 2006) does not make use of syntactic information which on the data without coreferences yields higher recall. $$$$$ At first glance, it may seem strange that KGC outperforms ERK on AImed, as the latter approach exploits a richer representation: sparse sub-sequences of words, PoS tags, entity and chunk types, or WordNet synsets.
In contrast, work reported in (Giuliano et al, 2006) does not make use of syntactic information which on the data without coreferences yields higher recall. $$$$$ With this aim, we will integrate the output of a parser (possibly trained on a domain-specific resource such the Genia Treebank).

For RE, we use AImed, previously used to train protein interaction extraction systems ((Giuliano et al, 2006)). $$$$$ Claudio Giuliano and Lorenza Romano have been supported by the ONTOTEXT project, funded by the Autonomous Province of Trento under the FUP2004 research program.
For RE, we use AImed, previously used to train protein interaction extraction systems ((Giuliano et al, 2006)). $$$$$ With this aim, we will integrate the output of a parser (possibly trained on a domain-specific resource such the Genia Treebank).
For RE, we use AImed, previously used to train protein interaction extraction systems ((Giuliano et al, 2006)). $$$$$ A dictionary of named entities (including typographical variants and synonyms) is associated to the data set.
For RE, we use AImed, previously used to train protein interaction extraction systems ((Giuliano et al, 2006)). $$$$$ In one case (AImed) interactions are considered symmetric, while in the other (LLL challenge) agents and targets of genic interactions have to be identified.

We use the KGC kernel from (Giuliano et al, 2006), one of the highest-performing systems on AImed to date and perform 10-fold cross validation. $$$$$ A second reason concerns the fact that syntactic parsing is not always robust enough to deal with real-world sentences.
We use the KGC kernel from (Giuliano et al, 2006), one of the highest-performing systems on AImed to date and perform 10-fold cross validation. $$$$$ Third, we would like to use a named entity recognizer instead of assuming that entities are already extracted or given by a dictionary.
We use the KGC kernel from (Giuliano et al, 2006), one of the highest-performing systems on AImed to date and perform 10-fold cross validation. $$$$$ The two data sets used for the experiments concern the same domain (i.e. gene/protein interactions).
We use the KGC kernel from (Giuliano et al, 2006), one of the highest-performing systems on AImed to date and perform 10-fold cross validation. $$$$$ With this aim, we will integrate the output of a parser (possibly trained on a domain-specific resource such the Genia Treebank).

The starting point of our research is an approach for identifying relations between named entities exploiting only shallow linguistic information, such as tokenization, sentence splitting, part-of-speech tagging and lemmatization (Giuliano et al, 2006). $$$$$ By substituting OP into Equation 1, we obtain the n-gram kernel Kn, which counts common uni-grams, bi-grams, ... , n-grams that two patterns have in common2.
The starting point of our research is an approach for identifying relations between named entities exploiting only shallow linguistic information, such as tokenization, sentence splitting, part-of-speech tagging and lemmatization (Giuliano et al, 2006). $$$$$ Claudio Giuliano and Lorenza Romano have been supported by the ONTOTEXT project, funded by the Autonomous Province of Trento under the FUP2004 research program.
The starting point of our research is an approach for identifying relations between named entities exploiting only shallow linguistic information, such as tokenization, sentence splitting, part-of-speech tagging and lemmatization (Giuliano et al, 2006). $$$$$ For example, in Figure 1 three entities are mentioned and two of the six ordered pairs of GENIA/topics/Corpus/GTB.html entities actually interact: (sigma(K), cwlH) and (gerE, cwlH).
The starting point of our research is an approach for identifying relations between named entities exploiting only shallow linguistic information, such as tokenization, sentence splitting, part-of-speech tagging and lemmatization (Giuliano et al, 2006). $$$$$ The objective of the challenge was to evaluate the performance of systems based on machine learning techniques to identify gene/protein interactions and their roles, agent or target.

Bunescu and Mooney (2005) and Giuliano et al (2006) successfully exploited the fact that relations between named entities are generally expressed using only words that appear simultaneously in one of the following three contexts. $$$$$ We would like to thank Razvan Bunescu for providing detailed information about the AImed data set and the settings of the experiments.
Bunescu and Mooney (2005) and Giuliano et al (2006) successfully exploited the fact that relations between named entities are generally expressed using only words that appear simultaneously in one of the following three contexts. $$$$$ We use a combination of kernel functions to integrate two different information sources: (i) the whole sentence where the relation appears, and (ii) the local contexts around the interacting entities.
Bunescu and Mooney (2005) and Giuliano et al (2006) successfully exploited the fact that relations between named entities are generally expressed using only words that appear simultaneously in one of the following three contexts. $$$$$ They use composite kernels to integrate information from different syntactic sources (tokenization, sentence parsing, and deep dependency analysis) so that processing errors occurring at one level may be overcome by information from other levels.
