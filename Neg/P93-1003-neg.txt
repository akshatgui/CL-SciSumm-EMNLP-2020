 $$$$$ To give an informal impression of overall performance, the hundred highest ranking correspondences were inspected and of these, ninety were completely correct.
 $$$$$ The algorithm is applicable for finding single or multiple word correspondences and can accommodate additional kinds of phrases.
 $$$$$ This resulted in a total of 34,000 correspondences.
 $$$$$ Improvements to the basic algorithm are described, which enable context to be accounted for when constructing the noun phrase mappings.

For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ An algorithm for producing collocational correspondences has also been described [Smadja, 1992].
For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ An arbitrarily large corpus can be accommodated by segmenting it appropriately.
For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ The algorithm is robust, and extensible in several ways.
For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ All correspondences are thus equally weighted, reflecting a state of ignorance.

There is a long tradition of research into bilingual terminology extraction (Kupiec, 1993), (Gaussier, 1998). $$$$$ Linguistic structure is used in the form of noun phrase recognizers to select phrases for a stochastic model which serves as a means of minimizing errors due to the approximations inherent in the correspondence model.

Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ Computation proceeds by evaluating Equation (1), Equation (2) and then iteratively applying Equations (3) and (2); r increasing with each successive iteration.
Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ This is important consideration because in large text corpora roughly a third of the word types only occur once.
Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ Linguistic structure is used in the form of noun phrase recognizers to select phrases for a stochastic model which serves as a means of minimizing errors due to the approximations inherent in the correspondence model.
Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ Computation proceeds by evaluating Equation (1), Equation (2) and then iteratively applying Equations (3) and (2); r increasing with each successive iteration.

Kupiec (1993) attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods. $$$$$ The highest ranking candidates are then extended by another word and the procedure is repeated until a corresponding French collocation having the highest mutual information is found.
Kupiec (1993) attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods. $$$$$ The taggers provide part-of-speech categories which are used by finite-state recognizers to extract simple noun phrases for both languages.
Kupiec (1993) attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods. $$$$$ The algorithm provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated.
Kupiec (1993) attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods. $$$$$ However, the model will assert that &quot;Christmas&quot; corresponds to &quot;projet de loi&quot; and to &quot;conge des Fetes&quot; with equal probability, no matter how likely the correspondence between &quot;Bill&quot; and &quot;projet de loi&quot;.

Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ For each sentence corresponding to an alignment, the index positions of all noun phrases in the sentence are recorded in a separate data structure, providing a compact representation of the corpus.
Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ English collocations are first extracted from the English side of the corpus.
Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ The algorithm is robust, and extensible in several ways.
Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ Possible interpretations of this are: 1.

For example, Kupiec (1993) presented a method for finding translations of whole noun phrases. $$$$$ 4,900 distinct English noun phrases and 5,100 distinct French noun phrases were extracted from the sample.
For example, Kupiec (1993) presented a method for finding translations of whole noun phrases. $$$$$ A word sequence in Ei is defined here as the correspondence of another sequence in Fi if the words of one sequence are considered to represent the words in the other.
For example, Kupiec (1993) presented a method for finding translations of whole noun phrases. $$$$$ The taggers are robust and operate with a low error rate [Kupiec, 19921.

Bound-length N-gram correspondences include (Kupiec, 1993) where NP recognizers are used to extract translation units and (Smadja et al, 1996) which uses the Extract system to extract collocations. $$$$$ Consider an English sentence Ei and a French sentence Fi which are assumed to be approximate translations of each other.
Bound-length N-gram correspondences include (Kupiec, 1993) where NP recognizers are used to extract translation units and (Smadja et al, 1996) which uses the Extract system to extract collocations. $$$$$ This results in a set of single word correspondences for the internal words in noun phrases.
Bound-length N-gram correspondences include (Kupiec, 1993) where NP recognizers are used to extract translation units and (Smadja et al, 1996) which uses the Extract system to extract collocations. $$$$$ Some terminology is necessary to describe the algorithm concisely.

We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ They can be used in bilingual concordances, for automatically constructing bilingual lexicons, and probabilistically quantified correspondences may be useful for statistical translation methods.
We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ Singular and plural forms of common nouns are thus distinct and assigned different positions in the index.
We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ The only embedding that is allowed is by prepositional phrases involving &quot;of' in English and &quot;de&quot; in French, as noun phrases involving them can be identified with relatively low error (revisions to this restriction are considered later).
We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ English collocations are first extracted from the English side of the corpus.

 $$$$$ To give an informal impression of overall performance, the hundred highest ranking correspondences were inspected and of these, ninety were completely correct.
 $$$$$ All correspondences are thus equally weighted, reflecting a state of ignorance.
 $$$$$ This is important consideration because in large text corpora roughly a third of the word types only occur once.
 $$$$$ Linguistic structure is used in the form of noun phrase recognizers to select phrases for a stochastic model which serves as a means of minimizing errors due to the approximations inherent in the correspondence model.

Kupiec proposes an Mgorithm for finding noun phrases in bilingual corpora (Kupiec, 1993). $$$$$ The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus.
Kupiec proposes an Mgorithm for finding noun phrases in bilingual corpora (Kupiec, 1993). $$$$$ So far it has been assumed (for the sake of simplicity) that there is always a one-to-one mapping between English and French sentences.
Kupiec proposes an Mgorithm for finding noun phrases in bilingual corpora (Kupiec, 1993). $$$$$ If all embedded prepositional phrases were permitted by the noun phrase recognizer, the algorithm could be used to reduce the degree of ambiguity between alternatives.
Kupiec proposes an Mgorithm for finding noun phrases in bilingual corpora (Kupiec, 1993). $$$$$ The algorithm described in this paper provides a practical means for obtaining correspondences between noun phrases in a bilingual corpus.

The plausible hypothesis that parallel sentences containing corresponding linguistic expressions is the major premise in Kupiec (1993). $$$$$ In discussing results, a selection of examples will be presented that demonstrates the strengths and weaknesses of the algorithm.
The plausible hypothesis that parallel sentences containing corresponding linguistic expressions is the major premise in Kupiec (1993). $$$$$ An algorithm for producing collocational correspondences has also been described [Smadja, 1992].
The plausible hypothesis that parallel sentences containing corresponding linguistic expressions is the major premise in Kupiec (1993). $$$$$ The algorithm described in this paper provides a practical means for obtaining correspondences between noun phrases in a bilingual corpus.

In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts. $$$$$ The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus.
In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts. $$$$$ Finding Word Correspondences: The algorithm finds corresponding noun phrases but provides no information about word-level correspondences within them.
In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts. $$$$$ In contrast to reservations that have been expressed [Gale and Church, 1991a] about using the EM algorithm to provide word correspondences, there have been no indications that prohibitive amounts of memory might be required, or that the approach lacks robustness.
In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts. $$$$$ The algorithm described in this paper provides a practical means for obtaining correspondences between noun phrases in a bilingual corpus.

Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (Kupiec, 1993), fixed/flexiblecollocations (Smadja et al, 1996), n-gram word sequences of arbitrary length (Kitamura and Matsumoto, 1996), non-compositional compounds (Melamed, 2001), captoids (Moore, 2001), and named entities. $$$$$ Even when a noun phrase only occurs once, a correct correspondence can be found if there are only single noun phrases in each sentence of the alignment.
Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (Kupiec, 1993), fixed/flexiblecollocations (Smadja et al, 1996), n-gram word sequences of arbitrary length (Kitamura and Matsumoto, 1996), non-compositional compounds (Melamed, 2001), captoids (Moore, 2001), and named entities. $$$$$ Single word correspondences have been investigated [Gale and Church, 1991a] using a statistic operating on contingency tables.
Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (Kupiec, 1993), fixed/flexiblecollocations (Smadja et al, 1996), n-gram word sequences of arbitrary length (Kitamura and Matsumoto, 1996), non-compositional compounds (Melamed, 2001), captoids (Moore, 2001), and named entities. $$$$$ The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus.
Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (Kupiec, 1993), fixed/flexiblecollocations (Smadja et al, 1996), n-gram word sequences of arbitrary length (Kitamura and Matsumoto, 1996), non-compositional compounds (Melamed, 2001), captoids (Moore, 2001), and named entities. $$$$$ Let the function 0(E2) be the number of noun phrases identified in the sentence.

Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ Simple noun phrases (excluding pronouns and digits) are then extracted from the sentences by finite-state recognizers that are specified by regular expressions defined in terms of part-ofspeech categories.
Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ Noun phrases are then mapped to each other using an iterative re-estimation algorithm that bears similarities to the Baum-Welch algorithm which is used for training the taggers.
Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ Several applications for bilingual correspondence information have been suggested.
Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ The table also illustrates an unembedded English noun phrase having multiple prepositional phrases in its French correspondent.

Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ Some terminology is necessary to describe the algorithm concisely.
Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ The taggers are robust and operate with a low error rate [Kupiec, 19921.
Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ The algorithm is robust, and extensible in several ways.
Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ They can be used in bilingual concordances, for automatically constructing bilingual lexicons, and probabilistically quantified correspondences may be useful for statistical translation methods.

Part-of-speech taggers are used in a few applications, such as speech synthesis (Sproat et al, 1992) and question answering (Kupiec, 1993b). $$$$$ The algorithm is reversible, by swapping E with F. The model for correspondence is that a source noun phrase in Ei is responsible for producing the various different target noun phrases in Fi with correspondingly different probabilities.
Part-of-speech taggers are used in a few applications, such as speech synthesis (Sproat et al, 1992) and question answering (Kupiec, 1993b). $$$$$ In such cases it was not necessary to form correspondences with all noun phrases in Fi for each noun phrase in E. Instead, the location of a phrase in Ei was mapped linearly to a position in Fi and correspondences were formed for noun phrases occurring in a window around that position.
Part-of-speech taggers are used in a few applications, such as speech synthesis (Sproat et al, 1992) and question answering (Kupiec, 1993b). $$$$$ This results in a set of single word correspondences for the internal words in noun phrases.

 $$$$$ Consider an English sentence Ei and a French sentence Fi which are assumed to be approximate translations of each other.
 $$$$$ In contrast to reservations that have been expressed [Gale and Church, 1991a] about using the EM algorithm to provide word correspondences, there have been no indications that prohibitive amounts of memory might be required, or that the approach lacks robustness.

 $$$$$ Noun phrases are then mapped to each other using an iterative re-estimation algorithm that bears similarities to the Baum-Welch algorithm which is used for training the taggers.
 $$$$$ The equations assume a directionality: finding French &quot;target&quot; correspondences for English &quot;source&quot; phrases.
 $$$$$ Equation (1) assumes that each English noun phrase in Ei is initially equally likely to correspond to each French noun phrase in Fi.
 $$$$$ English collocations are first extracted from the English side of the corpus.
