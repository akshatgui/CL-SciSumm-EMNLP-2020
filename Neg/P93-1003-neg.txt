 $$$$$ Some terminology is necessary to describe the algorithm concisely.
 $$$$$ Consider an English sentence Ei and a French sentence Fi which are assumed to be approximate translations of each other.
 $$$$$ The algorithm is robust, and extensible in several ways.
 $$$$$ So far it has been assumed (for the sake of simplicity) that there is always a one-to-one mapping between English and French sentences.

For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ Several applications for bilingual correspondence information have been suggested.
For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ In practice, if an alignment program produces blocks of several sentences in one or both languages, this can be accommodated by treating the block instead as a single bigger &quot;compound sentence&quot; in which noun phrases have a higher number of possible correspondences.
For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ An alternative approach is described here, which employs simple iterative re-estimation.
For instance, Kupiec (1993) uses statistical techniques and extracts bilingual noun phrases from parallel corpora tagged with terms. $$$$$ The algorithm provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated.

There is a long tradition of research into bilingual terminology extraction (Kupiec, 1993), (Gaussier, 1998). $$$$$ A noun phrase is defined by its word sequence, excluding any leading determiners.
There is a long tradition of research into bilingual terminology extraction (Kupiec, 1993), (Gaussier, 1998). $$$$$ If prepositional phrases involving &quot;for&quot; and &quot;a&quot; were also permitted, these phrases would be correctly identified; however many other adverbial prepositional phrases would also be incorrectly attached to noun phrases.
There is a long tradition of research into bilingual terminology extraction (Kupiec, 1993), (Gaussier, 1998). $$$$$ The algorithm involves several steps.
There is a long tradition of research into bilingual terminology extraction (Kupiec, 1993), (Gaussier, 1998). $$$$$ Areas of investigation using bilingual corpora have included the following: The work described here makes use of the aligned Canadian Hansards [Gale and Church, 1991b] to obtain noun phrase correspondences between the English and French text.

Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ When forming correspondences involving long sentences with many clauses, it was observed that the position at which a noun phrase occurred in Ei was very roughly proportional to the corresponding noun phrase in F. .
Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus.
Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus.
Kupiec (1993) applied finite state transducer in his noun phrases recogniser for both English and French. $$$$$ Linguistic structure is used in the form of noun phrase recognizers to select phrases for a stochastic model which serves as a means of minimizing errors due to the approximations inherent in the correspondence model.

Kupiec (1993) attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods. $$$$$ 4,900 distinct English noun phrases and 5,100 distinct French noun phrases were extracted from the sample.
Kupiec (1993) attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods. $$$$$ Singular and plural forms of common nouns are thus distinct and assigned different positions in the index.
Kupiec (1993) attempted to find noun phrase correspondences in parallel corpora using part-of-speech tagging and noun phrase recognition methods. $$$$$ The words in sentences are first tagged with their corresponding part-of-speech categories.

Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ Single word correspondences have been investigated [Gale and Church, 1991a] using a statistic operating on contingency tables.
Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ In practice, if an alignment program produces blocks of several sentences in one or both languages, this can be accommodated by treating the block instead as a single bigger &quot;compound sentence&quot; in which noun phrases have a higher number of possible correspondences.
Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ English collocations are first extracted from the English side of the corpus.
Kupiec (1993) also briefly mentions the use of finite state NP recognizers for both English and French to prepare the input for a program that identified the correspondences between NPs in bilingual corpora, but he does not directly discuss their performance. $$$$$ Linguistic structure is used in the form of noun phrase recognizers to select phrases for a stochastic model which serves as a means of minimizing errors due to the approximations inherent in the correspondence model.

For example, Kupiec (1993) presented a method for finding translations of whole noun phrases. $$$$$ The algorithm involves several steps.
For example, Kupiec (1993) presented a method for finding translations of whole noun phrases. $$$$$ An alternative approach is described here, which employs simple iterative re-estimation.

Bound-length N-gram correspondences include (Kupiec, 1993) where NP recognizers are used to extract translation units and (Smadja et al, 1996) which uses the Extract system to extract collocations. $$$$$ English collocations are first extracted from the English side of the corpus.
Bound-length N-gram correspondences include (Kupiec, 1993) where NP recognizers are used to extract translation units and (Smadja et al, 1996) which uses the Extract system to extract collocations. $$$$$ Linguistic structure is used in the form of noun phrase recognizers to select phrases for a stochastic model which serves as a means of minimizing errors due to the approximations inherent in the correspondence model.
Bound-length N-gram correspondences include (Kupiec, 1993) where NP recognizers are used to extract translation units and (Smadja et al, 1996) which uses the Extract system to extract collocations. $$$$$ Consider a sequence npePPe of an unembedded English noun phrase npe followed by a prepositional phrase ppe, and likewise a corresponding French sequence npf ppf.
Bound-length N-gram correspondences include (Kupiec, 1993) where NP recognizers are used to extract translation units and (Smadja et al, 1996) which uses the Extract system to extract collocations. $$$$$ They can be used in bilingual concordances, for automatically constructing bilingual lexicons, and probabilistically quantified correspondences may be useful for statistical translation methods.

We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ The only embedding that is allowed is by prepositional phrases involving &quot;of' in English and &quot;de&quot; in French, as noun phrases involving them can be identified with relatively low error (revisions to this restriction are considered later).
We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ They can be used in bilingual concordances, for automatically constructing bilingual lexicons, and probabilistically quantified correspondences may be useful for statistical translation methods.
We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ The correspondences in Table 4 are likewise flawed (in the table, &quot;souris&quot; means &quot;mouse&quot; and &quot;tigre de papier&quot; means &quot;paper tiger&quot;): These correspondences are the result of the following sentences: Ei: &quot;It is a roaring rabbit, a toothless tiger.&quot; Fi: &quot;C' est un tigre de papier, un souris qui rugit.&quot; In the case of the alliterative English phrase &quot;roaring rabbit&quot;, the (presumably) rhetorical aspect is preserved as a rhyme in &quot;souris qui rugit&quot;; the result being that &quot;rabbit&quot; corresponds to &quot;souris&quot; (mouse).
We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. $$$$$ Equation (1) assumes that each English noun phrase in Ei is initially equally likely to correspond to each French noun phrase in Fi.

 $$$$$ The algorithm is robust, and extensible in several ways.
 $$$$$ It is used to make correspondences between simple noun phrases that have been isolated in corresponding sentences of each language using finitestate recognizers.
 $$$$$ Given thresholds on the number of occurrences and the probability of the correspondence, the most likely correspondence can be predicted.
 $$$$$ Organizational acronyms (which may be not be available in general-purpose dictionaries) are also extracted, as the taggers are robust.

Kupiec proposes an Mgorithm for finding noun phrases in bilingual corpora (Kupiec, 1993). $$$$$ Instances of the English collocation are found and the mutual information is calculated between the instances and various single word candidates in aligned French sentences.
Kupiec proposes an Mgorithm for finding noun phrases in bilingual corpora (Kupiec, 1993). $$$$$ So far it has been assumed (for the sake of simplicity) that there is always a one-to-one mapping between English and French sentences.

The plausible hypothesis that parallel sentences containing corresponding linguistic expressions is the major premise in Kupiec (1993). $$$$$ The algorithm described in this paper provides a practical means for obtaining correspondences between noun phrases in a bilingual corpus.
The plausible hypothesis that parallel sentences containing corresponding linguistic expressions is the major premise in Kupiec (1993). $$$$$ Each tagger contains a hidden Markov model (HMM), which is trained using samples of raw text from the Hansards for each language.
The plausible hypothesis that parallel sentences containing corresponding linguistic expressions is the major premise in Kupiec (1993). $$$$$ It is used to make correspondences between simple noun phrases that have been isolated in corresponding sentences of each language using finitestate recognizers.

In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts. $$$$$ Several applications for bilingual correspondence information have been suggested.
In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts. $$$$$ Alternatively, the following strategy can be adopted, which involves fewer total correspondences.

Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (Kupiec, 1993), fixed/flexiblecollocations (Smadja et al, 1996), n-gram word sequences of arbitrary length (Kitamura and Matsumoto, 1996), non-compositional compounds (Melamed, 2001), captoids (Moore, 2001), and named entities. $$$$$ [Cutting et al., 1992]).
Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (Kupiec, 1993), fixed/flexiblecollocations (Smadja et al, 1996), n-gram word sequences of arbitrary length (Kitamura and Matsumoto, 1996), non-compositional compounds (Melamed, 2001), captoids (Moore, 2001), and named entities. $$$$$ The algorithm provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated.
Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (Kupiec, 1993), fixed/flexiblecollocations (Smadja et al, 1996), n-gram word sequences of arbitrary length (Kitamura and Matsumoto, 1996), non-compositional compounds (Melamed, 2001), captoids (Moore, 2001), and named entities. $$$$$ Noun phrases are then mapped to each other using an iterative re-estimation algorithm that bears similarities to the Baum-Welch algorithm which is used for training the taggers.

Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ The taggers provide part-of-speech categories which are used by finite-state recognizers to extract simple noun phrases for both languages.
Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ Consider an English sentence Ei and a French sentence Fi which are assumed to be approximate translations of each other.
Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ 2.
Kupiec (1993) focuses on noun-phrase translations only, Smadja et al (1996) limits to find French translation of English collocation identified by his Xtract system, and Kitamura and Matsumoto (1996) can exhaustively enumerate only rigid word sequences. $$$$$ The algorithm is robust, and extensible in several ways.

Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ The taggers provide part-of-speech categories which are used by finite-state recognizers to extract simple noun phrases for both languages.
Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ Simple noun phrases (excluding pronouns and digits) are then extracted from the sentences by finite-state recognizers that are specified by regular expressions defined in terms of part-ofspeech categories.
Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ Improvements to the basic algorithm are described, which enable context to be accounted for when constructing the noun phrase mappings.
Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). $$$$$ A word sequence in Ei is defined here as the correspondence of another sequence in Fi if the words of one sequence are considered to represent the words in the other.

Part-of-speech taggers are used in a few applications, such as speech synthesis (Sproat et al, 1992) and question answering (Kupiec, 1993b). $$$$$ The mappings are stable within a few (2-4) iterations.
Part-of-speech taggers are used in a few applications, such as speech synthesis (Sproat et al, 1992) and question answering (Kupiec, 1993b). $$$$$ For each sentence corresponding to an alignment, the index positions of all noun phrases in the sentence are recorded in a separate data structure, providing a compact representation of the corpus.
Part-of-speech taggers are used in a few applications, such as speech synthesis (Sproat et al, 1992) and question answering (Kupiec, 1993b). $$$$$ Areas of investigation using bilingual corpora have included the following: The work described here makes use of the aligned Canadian Hansards [Gale and Church, 1991b] to obtain noun phrase correspondences between the English and French text.
Part-of-speech taggers are used in a few applications, such as speech synthesis (Sproat et al, 1992) and question answering (Kupiec, 1993b). $$$$$ Noun phrases are then mapped to each other using an iterative re-estimation algorithm that bears similarities to the Baum-Welch algorithm which is used for training the taggers.

 $$$$$ The prepositional phrase attaches to the noun phrase in one language and does not in the other.
 $$$$$ This is demonstrated in the last row of Table 2, which is the result of the following alignment: Ei: &quot;The whole issue of free trade has been mentioned.&quot; &quot;On a mentionne la question du libreechange.&quot; Table 3 shows some incorrect correspondences produced by the algorithm (in the table, &quot;usine&quot; means &quot;factory&quot;).
 $$$$$ The algorithm described here is an instance of a general approach to statistical estimation, represented by the EM algorithm [Dempster et al., 1977].
 $$$$$ The taggers are robust and operate with a low error rate [Kupiec, 19921.

 $$$$$ Noun phrases are placed in an index to associate a unique identifier with each one.
 $$$$$ The weights Co(s, t) can be interpreted as the mean number of times that npF(t) corresponds to npE(s) given the corpus and the initial assumption of equiprobable correspondences.
 $$$$$ The procedure is then iterated using Equations (3), and (2) to obtain successively refined, convergent estimates of the probability that npF(t) corresponds to npE(s).
 $$$$$ The algorithm described in this paper provides a practical means for obtaining correspondences between noun phrases in a bilingual corpus.
