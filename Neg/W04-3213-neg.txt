Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ We also experimented with initial starting values of 2, 3, and 8 for the log likelihood ratio threshold.
Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ We present an unsupervised method for labelling the arguments of verbs with their semantic roles.
Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ Our combination of slot plus head word provides similar information (head of argument and its syntactic relation to the verb) to that captured by the features of Gildea and Jurafsky (2002) or Thompson et al. (2003).
Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ This yields a noun classification system that is very coarse and that does not distinguish between senses, but which is simple and computationally feasible. thus captures consistent relations between a verb and a class of nouns, regardless of the slot in which the noun occurs.

VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ The class of a verb in our model is its VerbNet class that is compatible with the current frame.
VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ For each slot in , assign the highest probability role.
VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ Semantic annotation of text corpora is needed to support tasks such as information extraction and question-answering (e.g., Riloff and Schmelzenbach, 1998; Niu and Hirst, 2004).
VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ Our bootstrapping algorithm makes initial unambiguous role assignments, and then iteratively updates the probability model on which future assignments are based.

Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ For any given slot, we use the most specific level that reaches the evidence threshold for any of the candidates.
Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ The evidence count for each of the conditional probabilities refers to the number of times we have observed the conjunction of its conditioning events.
Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ For the assigned slots, we report percent correct (of total, not of assigned) and percent incorrect.

There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ Our bootstrapping algorithm makes initial unambiguous role assignments, and then iteratively updates the probability model on which future assignments are based.
There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ The last backoff level simply uses the probability of the role given the slot class, .
There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ (Re)compute the probability model, using counts over the items in .

To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ We also hope to integrate some processing of adjunct roles, rather than limiting ourselves to the specified arguments.
To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ This frame matching step is very restrictive and greatly reduces potential role ambiguity.
To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ For example, for , this is the number of times the particular combination of verb, slot, and noun have been observed.
To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ We use maximum likelihood estimates (MLE) for each of the probability formulas.

There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ However, PP objects also have the lowest performance (of 78% correct on identified arguments, compared to 93% for subjects or objects).
There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ Although these results are promising, they are only a first step in demonstrating the potential of the approach.
There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ We focus on the analysis of test data; the pattern on the validation data was nearly identical in all respects.

For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ Here we use a linear interpolation of three probabilities, each of which: (1) drops one source of conditioning information from the most specific probability, and (2) generalizes a second source of conditioning information to a class-based conditioning event.
For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ Our results show a large improvement over an informed baseline.
For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ This corpus is processed by the chunker of Abney (1991), from whose output we can identify the probable head words of verb arguments with some degree of error.
For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ We first describe the lexicon that specifies the syntactic arguments and possible roles for the verbs, and then discuss our process of argument and role set identification.

Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ For each of 191 verb classes, including around 3000 verbs in total, VerbNet specifies the syntactic frames along with the semantic role assigned to each slot of a frame.
Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ Our bootstrapping algorithm makes initial unambiguous role assignments, and then iteratively updates the probability model on which future assignments are based.
Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ Using FrameNet would also have the advantage of providing large amounts of labelled test data for our evaluation.

Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ Our corpus consists of a random selection of 20% of the sentences in the British National Corpus (BNC Reference Guide, 2000).
Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ Agreement between the two annotators was high, yielding a kappa statistic of 0.83.
Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ At either of these steps it is possible for some slots to have been assigned and some to remain unassigned.
Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ Our ongoing work is investigating better class models to make the backoff process even more effective.

Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ We achieve 50–65% reduction in the error rate over an informed baseline, indicating the potential of our approach for a task that has heretofore relied on large amounts of manually generated training data.
Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ This gives us a set of 1159 verbs to observe in total, and increases the likelihood that some verb class information is available for each of the possible classes of the target verbs.
Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ When backing off from this probability, we use statistics over more general classes of information, such as conditioning over the semantic class of the verb instead of the verb itself—for this example, psychological state verbs.
Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ For the initial set of experiments, we chose 54 target verbs from three top-level VerbNet classes: preparing-26.3, transfer mesg-37.1, and contribute13.2.

Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ This corpus is processed by the chunker of Abney (1991), from whose output we can identify the probable head words of verb arguments with some degree of error.
Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ To our knowledge, this is the first unsupervised semantic role labelling system applied to general semantic roles in a domain-general corpus.
Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ To achieve this, we take a “bootstrapping” approach (e.g., Hindle and Rooth, 1993; Yarowsky, 1995; Jones et al., 1999), which initially makes only the role assignments that are unambiguous according to a verb lexicon.
Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ Observing the entire extended set also provides more data for our probability estimators that do not use verb class information.

Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ However, these have room for improvement—our noun classes are coarse, and prepositions clearly have the potential to be divided into more informative subclasses, such as spatial or time relations.
Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ This unambiguous data is leveraged by using those role assignments as the basis for the initial estimates for the probability model described in Section 3.
Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ First, when we broaden our range of verb classes, subjects and objects will have more possible roles.
Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ A novel aspect of our approach is the use of verb, slot, and noun class information as the basis for backing off in our probability model.

Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ We first describe the lexicon that specifies the syntactic arguments and possible roles for the verbs, and then discuss our process of argument and role set identification.
Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ In , the slot component is dropped, and the noun is generalized to the appropriate noun class.

Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ We extracted two sets of sentences: a validation set consisting of 5 random examples of each target verb, and a test set, consisting of 10 random examples of each target verb.
Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ We assume the probability of a role for a slot is independent of other slots; we do not ensure a consistent role assignment across an instance of a verb.
Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ The evidence count for each of the conditional probabilities refers to the number of times we have observed the conjunction of its conditioning events.

This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ We instead make use of VerbNet (Kipper et al., 2000), a manually developed hierarchical verb lexicon based on the verb classification of Levin (1993).
This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ We are using a very different verb lexicon, corpus, and human standard than in previous research.

For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ In Section 5, we describe details of the materials and methods used for the experiments presented in Section 6.
For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ Our combination of slot plus head word provides similar information (head of argument and its syntactic relation to the verb) to that captured by the features of Gildea and Jurafsky (2002) or Thompson et al. (2003).

For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ Also, the unsupervised nature of the approach highlights an intermediate step of determining the set of possible roles for each argument.
For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ The closest work is that of Gildea and Jurafsky (2002) which maps FrameNet roles to a set of 18 thematic roles very similar to our roles, and also operates on a subset of the BNC (albeit manually rather than randomly selected).
For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ We achieve 50–65% reduction in the error rate over an informed baseline, indicating the potential of our approach for a task that has heretofore relied on large amounts of manually generated training data.

As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ This unambiguous data is leveraged by using those role assignments as the basis for the initial estimates for the probability model described in Section 3.
As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ In future work, we plan to explore other possible methods of selecting roles from the frames, such as choosing candidates from all frames, or setting a threshold value on the matching score.

Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Here we use a linear interpolation of three probabilities, each of which: (1) drops one source of conditioning information from the most specific probability, and (2) generalizes a second source of conditioning information to a class-based conditioning event.
Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Observing the entire extended set also provides more data for our probability estimators that do not use verb class information.
