Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ Using FrameNet would also have the advantage of providing large amounts of labelled test data for our evaluation.
Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ Rather than performing a simple precision/recall analysis, we report a finer grained elaboration that gives a more precise picture of the results.
Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ We gratefully acknowledge the support of NSERC of Canada.
Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a boot strapping algorithm, and achieved 87% accuracy. $$$$$ This gives us a set of 1159 verbs to observe in total, and increases the likelihood that some verb class information is available for each of the possible classes of the target verbs.

VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ (For example, for , this is the mean or median count across all combinations of verb, slot, and noun.)
VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ Our bootstrapping algorithm makes initial unambiguous role assignments, and then iteratively updates the probability model on which future assignments are based.
VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ All these percent figures are out of all argument slots (for the first set of results), and out of all slots (for the second set); see Table 3.
VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al, 2008), verb classification (Joanis et al, 2008), and information extraction (Maynard et al, 2009). $$$$$ Our bootstrapping algorithm makes initial unambiguous role assignments, and then iteratively updates the probability model on which future assignments are based.

Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ This frame matching step is very restrictive and greatly reduces potential role ambiguity.
Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Our ongoing work is investigating better class models to make the backoff process even more effective.
Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ When backing off from this probability, we use statistics over more general classes of information, such as conditioning over the semantic class of the verb instead of the verb itself—for this example, psychological state verbs.
Early unsupervised approaches to the SRL problem include the work by Swier and Stevenson (2004), where the Verb Net verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ Thus, differs from by dropping the noun, and by treating all prepositional slots as the same slot.

There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ We first describe the lexicon that specifies the syntactic arguments and possible roles for the verbs, and then discuss our process of argument and role set identification.
There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ Given a noun argument, all of its ancestors that appear in this cut are used as the class(es) for the noun.
There has been little research on semi-supervised learning for SRL.We refer to He and Gildea (2006) who tested active learning and co-training methods, but found little or no gain from semi-supervised learning, and to Swier and Stevenson (2004), who achieved good results using semi-supervised methods, but tested their methods on a small number of Verb Net roles, which have not been used by other SRL systems. $$$$$ Our approach also differs from earlier work in its novel use of classes of information in backing off to less specific role probabilities (in contrast to using simple subsets of information, as in Gildea and Jurafsky, 2002).

To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ A novel aspect of our approach is the use of verb, slot, and noun class information as the basis for backing off in our probability model.
To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ However, these have room for improvement—our noun classes are coarse, and prepositions clearly have the potential to be divided into more informative subclasses, such as spatial or time relations.
To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.

There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ Currently, we use a cut through WordNet including all the top categories, except for the category “entity”; the latter, because of its generality, is replaced in the cut by its immediate children (Schulte im Walde, 2003).
There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ Our bootstrapping algorithm makes initial unambiguous role assignments, and then iteratively updates the probability model on which future assignments are based.
There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ Verb classes have been shown to be very important in capturing generalizations across verb behaviour in computational systems (e.g., Palmer, 2000; Merlo and Stevenson, 2001).
There are also some methods for unsupervised semantic role labeling (Swier and Stevenson, 2004), (Abend et al, 2009) that easily adapt across domains but their performances are not comparable to supervised systems. $$$$$ Our ongoing work is investigating better class models to make the backoff process even more effective.

For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ Because our evidence count and log ratio restrictions may not be met even when we have a very good candidate for a slot, we reduce the evidence count threshold to the minimum value of 1 when the log ratio threshold reaches 1.3 By this point, we assume competitor candidates have been given sufficient opportunity to amass the relevant counts.
For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ Indeed, when we examine each of the slot classes individually, we find that, for subjects and objects, the percent correct achieved by the algorithm is indistinguishable from the baseline (both are around 93%, for both subjects and objects).
For example, VerbNet (derived from Levin? s [1993] work, Kipper et al, 2008) is widely used for a number of semantic processing tasks, including semantic role labeling (Swier and Stevenson, 2004), the creation of semantic parse trees (Shi and Mihalcea, 2005), and implicit argument resolution (Gerber and Chai, 2010). $$$$$ In Section 2, we discuss the lexicon we use, and our initial steps of syntactic frame matching and “unambiguous” role assignment.

Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ We also hope to integrate some processing of adjunct roles, rather than limiting ourselves to the specified arguments.
Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ Including the adjunct slots, our percent correct goes from 90.1% to 88.7%.
Swier and Stevenson (2004) and Swier and Stevenson (2005) presented the first model that does not use an SRL annotated corpus. $$$$$ On PP objects, our conservative role assignment shows promise at leaving adjuncts unlabelled.

Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ Although these results are promising, they are only a first step in demonstrating the potential of the approach.
Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ The evidence count for each of the conditional probabilities refers to the number of times we have observed the conjunction of its conditioning events.
Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ Correctness is determined by the human judgements on the chunked slots, as reported above.
Swier and Stevenson (2004) present an unsupervised method for labeling the arguments of verbs with their semantic roles. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.

Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ Our corpus consists of a random selection of 20% of the sentences in the British National Corpus (BNC Reference Guide, 2000).
Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ The probability model predicts the role for a slot given certain conditioning information.
Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ A slot could also be labelled as an adjunct, or as “bad” (incorrectly chunked).
Swier and Stevenson (2004) were the first to introduce unsupervised SRL in an approach that used the VerbNet lexicon to guide unsupervised learning. $$$$$ Because of the importance of this task, a number of recent methods have been proposed for automatic semantic role labelling (e.g., Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Fleischman et al., 2003; Hacioglu et al., 2003; Thompson et al., 2003).

Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ We achieve 50–65% reduction in the error rate over an informed baseline, indicating the potential of our approach for a task that has heretofore relied on large amounts of manually generated training data.
Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ As we have seen with PPs, when more roles are available, the performance of a default role degrades.
Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ We present an unsupervised method for labelling the arguments of verbs with their semantic roles.
Finally, Swier and Stevenson (2004) per form unsupervised semantic role labeling by using hand-crafted verb lexicons to replace supervised semantic role training data. $$$$$ We align the slots of each frame with the chunked slots, and compute the portion %Frame of frame slots that can be mapped to a chunked slot, and the portion %Chunks of chunked slots that can be mapped to the frame.

Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ Table 1) that are the best syntactic matches with the chunker output.
Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ (For example, for , this is the mean or median count across all combinations of verb, slot, and noun.)
Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ The more lenient median setting worked slightly better on the validation set, and was retained for our test experiments.
Swier and Stevenson (2004, 2005), while addressing an unsupervised SRL task, greatly differ from us as their algorithm uses the VerbNet (Kipper et al, 2000) verb lexicon, in addition to supervised parses. $$$$$ Some subjects are assigned Theme, while some objects are assigned Recipient or Source.

Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ We achieve 50–65% reduction in the error rate over an informed baseline, indicating the potential of our approach for a task that has heretofore relied on large amounts of manually generated training data.
Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ The closest work is that of Gildea and Jurafsky (2002) which maps FrameNet roles to a set of 18 thematic roles very similar to our roles, and also operates on a subset of the BNC (albeit manually rather than randomly selected).
Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.

Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ Determining the appropriate level of generalization for a noun is an open problem (e.g., Clark and Weir, 2002).
Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ However, these have room for improvement—our noun classes are coarse, and prepositions clearly have the potential to be divided into more informative subclasses, such as spatial or time relations.
Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ In a similar vein of work, Riloff and colleagues (Riloff and Schmelzenbach, 1998; Jones et al., 1999) used bootstrapping to learn “case frames” for verbs, but their approach has been applied in very narrow topic domains with topic-specific roles.
Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system. $$$$$ This gives us a set of 1159 verbs to observe in total, and increases the likelihood that some verb class information is available for each of the possible classes of the target verbs.

This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ A unique aspect of our method is the probability model, which is novel in its generalizations over verb, slot, and noun classes for role labelling.
This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ Using FrameNet would also have the advantage of providing large amounts of labelled test data for our evaluation.
This is achieved by adopting the scoring method of Swier and Stevenson (2004), in which we compute the portion Frame of frame slots that can be mapped to an extracted argument, and the portion% Sent of extracted arguments from the sentence that can be mapped to the frame. $$$$$ Our ongoing work is investigating better class models to make the backoff process even more effective.

For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ We gratefully acknowledge the support of NSERC of Canada.
For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ Previous work has divided the semantic role labelling task into the identification of the arguments to be labelled, and the tagging of each argument with a role (Gildea and Jurafsky, 2002; Fleischman et al., 2003).
For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ We also thank Martha Palmer for providing us with the VerbNet data, Eric Joanis for help with the chunker, Vivian Tsang and Ryan North for helpful discussion, and two anonymous reviewers.
For comparison, we also apply the iterative algorithm developed by Swier and Stevenson (2004), using the same bootstrapping parameters. $$$$$ We mention the performance of their method where appropriate below.

For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ Many syntactic slots receive only a single candidate role, providing the initial unambiguous data for our bootstrapping algorithm.
For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ The score for each frame is computed by %Frame %Chunks, and only frames having the highest score contribute candidate roles to the chunked slots.
For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ In Section 2, we discuss the lexicon we use, and our initial steps of syntactic frame matching and “unambiguous” role assignment.
For ease of comparison, we use the same verbs as in Swier and Stevenson (2004), except that we measure performance over a much larger superset of verbs. $$$$$ We are left with a set of 16 roles: Agent, Amount, Attribute, Beneficiary, Cause, Destination, Experiencer, Instrument, Location, Material, Predicate, Recipient, Source, Stimulus, Theme, Time.

As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ To initialize the candidate roles precisely, we only choose roles from frames in the verb’s lexical entry (cf.
As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ Second, a few semantic distinctions that are made in VerbNet appeared to be too fine-grained to capture, so we map these to a more coarse-grained subset of the VerbNet roles.
As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ Semantic annotation of text corpora is needed to support tasks such as information extraction and question-answering (e.g., Riloff and Schmelzenbach, 1998; Niu and Hirst, 2004).
As a point of comparison, we apply the iterative back off model from Swier and Stevenson (2004), trained on 20% of the BNC, with our frame matcher and test data. $$$$$ In other work, Gildea (2002) has explored unsupervised methods to discover role-slot mappings for verbs, but not to apply this knowledge to label text with roles.

Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ However, PP objects also have the lowest performance (of 78% correct on identified arguments, compared to 93% for subjects or objects).
Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface. $$$$$ The closest work is that of Gildea and Jurafsky (2002) which maps FrameNet roles to a set of 18 thematic roles very similar to our roles, and also operates on a subset of the BNC (albeit manually rather than randomly selected).
