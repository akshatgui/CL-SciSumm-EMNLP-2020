Our approach to QC follows that of (Li and Roth, 2002). $$$$$ In future work we plan to investigate further the application of deeper semantic analysis (including better named entity and semantic categorization) to feature extraction, automate the generation of thesemantic features and develop a better understand ing to some of the learning issues involved in thedifference between a flat and a hierarchical classi fier.
Our approach to QC follows that of (Li and Roth, 2002). $$$$$ Wendy Lehnert?s conceptual taxonomy (Lehnert, 1986), for example, proposesabout 13 conceptual classes including causal antecedent, goal orientation, enablement, causal consequent, verification, disjunctive, and so on.

We will use the TREC dataset provided by Li and Roth (2002), which assigns 6000 questions with both a coarse and a fine-grained label. $$$$$ We construct a multi-class classifier only for fine classes.
We will use the TREC dataset provided by Li and Roth (2002), which assigns 6000 questions with both a coarse and a fine-grained label. $$$$$ In future work we plan to investigate further the application of deeper semantic analysis (including better named entity and semantic categorization) to feature extraction, automate the generation of thesemantic features and develop a better understand ing to some of the learning issues involved in thedifference between a flat and a hierarchical classi fier.
We will use the TREC dataset provided by Li and Roth (2002), which assigns 6000 questions with both a coarse and a fine-grained label. $$$$$ The approach we adoptedis a multi-level learning approach: some of our fea tures rely on finer analysis of the questions that are outcomes of learned classifiers; the QC module then applies learning with these as input features.
We will use the TREC dataset provided by Li and Roth (2002), which assigns 6000 questions with both a coarse and a fine-grained label. $$$$$ Comparison of the hierarchical and the flat classifier The flat classifier consists of one classifier which isalmost the same as the fine classifier in the hierar chical case, except that its initial confusion set is the whole set of fine classes.

This scheme is more suitable here than other common answer-typing schemata such as the one in Li and Roth (2002), which tend to focus on questions asking for factual knowledge. $$$$$ We show accurate results on a large col lection of free-form questions used in TREC 10.
This scheme is more suitable here than other common answer-typing schemata such as the one in Li and Roth (2002), which tend to focus on questions asking for factual knowledge. $$$$$ What is worth seeing in Reims?
This scheme is more suitable here than other common answer-typing schemata such as the one in Li and Roth (2002), which tend to focus on questions asking for factual knowledge. $$$$$ This work develops a machine learning approach to question classification (QC) (Harabagiu et al, 2001; Hermjakob, 2001).
This scheme is more suitable here than other common answer-typing schemata such as the one in Li and Roth (2002), which tend to focus on questions asking for factual knowledge. $$$$$ The motiva tion behind adding a level of coarse classes is that of compatibility with previous work?s definitions, andcomprehensibility.

This is important because while large sets of existing questions can be obtained (Li and Roth, 2002), there are many fewer questions with available answers. Our experiments demonstrate that how-question specific unit lists consistently achieve higher answer identification performance than fixed-type, general purpose answer typing (which propose all numerical entities as answer candidates). $$$$$ We show accurate results on a large col lection of free-form questions used in TREC 10.
This is important because while large sets of existing questions can be obtained (Li and Roth, 2002), there are many fewer questions with available answers. Our experiments demonstrate that how-question specific unit lists consistently achieve higher answer identification performance than fixed-type, general purpose answer typing (which propose all numerical entities as answer candidates). $$$$$ The hierarchy con tains 6 coarse classes (ABBREVIATION, ENTITY,DESCRIPTION, HUMAN, LOCATION and NU MERIC VALUE) and 50 fine classes, Table 1 showsthe distribution of these classes in the 500 ques tions of TREC 10.
This is important because while large sets of existing questions can be obtained (Li and Roth, 2002), there are many fewer questions with available answers. Our experiments demonstrate that how-question specific unit lists consistently achieve higher answer identification performance than fixed-type, general purpose answer typing (which propose all numerical entities as answer candidates). $$$$$ Class # Class # ABBREV.
This is important because while large sets of existing questions can be obtained (Li and Roth, 2002), there are many fewer questions with available answers. Our experiments demonstrate that how-question specific unit lists consistently achieve higher answer identification performance than fixed-type, general purpose answer typing (which propose all numerical entities as answer candidates). $$$$$ This paper presents a machine learning approach to question classification.

For example, Li and Roth (2002) assign one of fifty possible types to a question based on features present in the question. $$$$$ It is interesting to observe that this improvement is even more significant for fine classes.
For example, Li and Roth (2002) assign one of fifty possible types to a question based on features present in the question. $$$$$ The difficulty is more acute in tasks such as story comprehension in which the target text is less likely to overlap with the text in the questions.
For example, Li and Roth (2002) assign one of fifty possible types to a question based on features present in the question. $$$$$ Only ?active?
For example, Li and Roth (2002) assign one of fifty possible types to a question based on features present in the question. $$$$$ We developed a hierarchicalclassifier that is guided by a layered semantic hierarchy of answers types, and used it to classify questions into fine-grained classes.

(Li and Roth, 2002) propose a system based on SNoW. $$$$$ The intension is that this 1We do not address questions like ?Do you have a light??, which calls for an action, but rather only factual Wh-questions.
(Li and Roth, 2002) propose a system based on SNoW. $$$$$ One difficulty in the question classification task is that there is no completely clear boundary between classes.
(Li and Roth, 2002) propose a system based on SNoW. $$$$$ This work develops a machine learning approach to question classification (QC) (Harabagiu et al, 2001; Hermjakob, 2001).

The same dataset has been used in other investigations, such as in (Li and Roth, 2002). The distribution of these 5500 training questions, with respect to its interrogative pronoun or the initial word is showed in Table 1. $$$$$ The question classifier makes use of a sequence of two simple classifiers (Even-Zohar and Roth, 2001), each utilizing the Winnow algorithm within SNoW.
The same dataset has been used in other investigations, such as in (Li and Roth, 2002). The distribution of these 5500 training questions, with respect to its interrogative pronoun or the initial word is showed in Table 1. $$$$$ As the results below show, although questionclasses are still ambiguous, few mistakes are intro duced by our classifier in this step.
The same dataset has been used in other investigations, such as in (Li and Roth, 2002). The distribution of these 5500 training questions, with respect to its interrogative pronoun or the initial word is showed in Table 1. $$$$$ This paper presents a machine learning approach to question classification.
The same dataset has been used in other investigations, such as in (Li and Roth, 2002). The distribution of these 5500 training questions, with respect to its interrogative pronoun or the initial word is showed in Table 1. $$$$$ In this case, both classes are ac ceptable.

(Li and Roth, 2002) obtain a better performance for English, around a 92.5% in terms of accuracy. $$$$$ If we treat p i as the probability that a question belongs to Class i, the decision model yields a reasonable probabilistic interpretation.
(Li and Roth, 2002) obtain a better performance for English, around a 92.5% in terms of accuracy. $$$$$ This paper presents a machine learning approach to question classification.
(Li and Roth, 2002) obtain a better performance for English, around a 92.5% in terms of accuracy. $$$$$ 3 have been correctly classified.
(Li and Roth, 2002) obtain a better performance for English, around a 92.5% in terms of accuracy. $$$$$ 3.2 (we re peated the experiments on several different trainingand test sets).

It could be also interested to test the combination between a better QC system, the current one by Li and Roth's for instance (Li and Roth, 2002), and our machine translation method. $$$$$ larger D ij is, the darker the color is. The dotted lines separate the 6 coarse classes.
It could be also interested to test the combination between a better QC system, the current one by Li and Roth's for instance (Li and Roth, 2002), and our machine translation method. $$$$$ Therefore, the classification of a specific question can be quite ambiguous.
It could be also interested to test the combination between a better QC system, the current one by Li and Roth's for instance (Li and Roth, 2002), and our machine translation method. $$$$$ Re sults are evaluated using P 1 and P 5 . No.
It could be also interested to test the combination between a better QC system, the current one by Li and Roth's for instance (Li and Roth, 2002), and our machine translation method. $$$$$ In order to respond correctly to a free form factual question given a large collection of texts, one needs to un derstand the question to a level that allows determiningsome of the constraints the question imposes on a pos sible answer.

Li and Roth (2002) have developed a machine learning approach which uses the SNoW learning architecture. $$$$$ 3.1 A Hierarchical ClassifierQuestion classification is a multi-class classification.
Li and Roth (2002) have developed a machine learning approach which uses the SNoW learning architecture. $$$$$ We show accurate results on a large col lection of free-form questions used in TREC 10.
Li and Roth (2002) have developed a machine learning approach which uses the SNoW learning architecture. $$$$$ alized that locating an answer accurately hinges on first filtering out a wide range of candidates (Hovy et al, 2001; Ittycheriah et al, 2001) based on some categorization of answer types.
Li and Roth (2002) have developed a machine learning approach which uses the SNoW learning architecture. $$$$$ We show accurate results on a large col lection of free-form questions used in TREC 10.

Compared to the over feature size of 200000 in Li and Roth (2002), our feature space is much more compact, yet turned out to be more informative as suggested by the experiments. $$$$$ Our experimental re sults prove that the question classification problemcan be solved quite accurately using a learning ap proach, and exhibit the benefits of features based on semantic analysis.
Compared to the over feature size of 200000 in Li and Roth (2002), our feature space is much more compact, yet turned out to be more informative as suggested by the experiments. $$$$$ We developed a hierarchicalclassifier that is guided by a layered semantic hierarchy of answers types, and used it to classify questions into fine-grained classes.
Compared to the over feature size of 200000 in Li and Roth (2002), our feature space is much more compact, yet turned out to be more informative as suggested by the experiments. $$$$$ C 1 and C 3are the ul timate outputs from the whole classifier which are used in our evaluation.

With the increasing popularity of statistical NLP, Li and Roth (2002), Hacioglu and Ward (2003) and Zhang and Lee (2003) used supervised learning for question classification on a data set from UIUC that is now standard1. $$$$$ Figure 2 give some more intuition on the flat vs. hierarchical issue.
With the increasing popularity of statistical NLP, Li and Roth (2002), Hacioglu and Ward (2003) and Zhang and Lee (2003) used supervised learning for question classification on a data set from UIUC that is now standard1. $$$$$ We learn a hierarchical classifier that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into finegrained classes.
With the increasing popularity of statistical NLP, Li and Roth (2002), Hacioglu and Ward (2003) and Zhang and Lee (2003) used supervised learning for question classification on a data set from UIUC that is now standard1. $$$$$ Our goal is to categorize questions into different semantic classes that impose constraints on potential answers, so that they can be utilized in later stages of the question answeringprocess.
With the increasing popularity of statistical NLP, Li and Roth (2002), Hacioglu and Ward (2003) and Zhang and Lee (2003) used supervised learning for question classification on a data set from UIUC that is now standard1. $$$$$ Earlier works have suggested various standards of classifying questions.

Li and Roth (2002) used a Sparse Network of Winnows (SNoW) (Khardon et al, 1999). $$$$$ What is bipolar disorder?.
Li and Roth (2002) used a Sparse Network of Winnows (SNoW) (Khardon et al, 1999). $$$$$ 3 Learning a Question Classifier.

Our findings corroborate Li and Roth (2002), who report little benefit from adding head chunk features for the fine classification task. $$$$$ We can see that there is no good cluster ing of fine classes mistakes within a coarse class,which explains intuitively why the hierarchical clas sifier with an additional level coarse classes does not work much better.
Our findings corroborate Li and Roth (2002), who report little benefit from adding head chunk features for the fine classification task. $$$$$ Our learned classifier is based on the SNoW learning architecture (Carlson et al, 1999; Roth, 1998)2 where, in order to allow the classifier to output more than one class label, wemap the classifier?s output activation into a condi tional probability of the class labels and threshold it.
Our findings corroborate Li and Roth (2002), who report little benefit from adding head chunk features for the fine classification task. $$$$$ of features used, (e.g., conjunction of two consecutive words and their postags) is written and the features themselves are ex tracted in a data driven way.

in (Li and Roth, 2002) to our basic QA system, YourQA (Quarteroni and Manandhar, 2008) and by gathering the top 20 answer paragraphs. $$$$$ 2 presents the question classification problem; Sec.
in (Li and Roth, 2002) to our basic QA system, YourQA (Quarteroni and Manandhar, 2008) and by gathering the top 20 answer paragraphs. $$$$$ We show accurate results on a large col lection of free-form questions used in TREC 10.
in (Li and Roth, 2002) to our basic QA system, YourQA (Quarteroni and Manandhar, 2008) and by gathering the top 20 answer paragraphs. $$$$$ In future work we plan to investigate further the application of deeper semantic analysis (including better named entity and semantic categorization) to feature extraction, automate the generation of thesemantic features and develop a better understand ing to some of the learning issues involved in thedifference between a flat and a hierarchical classi fier.
in (Li and Roth, 2002) to our basic QA system, YourQA (Quarteroni and Manandhar, 2008) and by gathering the top 20 answer paragraphs. $$$$$ In future work we plan to investigate further the application of deeper semantic analysis (including better named entity and semantic categorization) to feature extraction, automate the generation of thesemantic features and develop a better understand ing to some of the learning issues involved in thedifference between a flat and a hierarchical classi fier.

 $$$$$ of the sought after answer.
 $$$$$ In future work we plan to investigate further the application of deeper semantic analysis (including better named entity and semantic categorization) to feature extraction, automate the generation of thesemantic features and develop a better understand ing to some of the learning issues involved in thedifference between a flat and a hierarchical classi fier.
 $$$$$ Features will be extracted for this class ifa word in a question belongs to the list.

Answer types are determined using classification rules similar to Li and Roth (2002). $$$$$ This methodology might cause slight problems in training, when the labels are ambiguous, since some questions are not treated as positive examples for possible classes as they should be.
Answer types are determined using classification rules similar to Li and Roth (2002). $$$$$ We developed a hierarchicalclassifier that is guided by a layered semantic hierarchy of answers types, and used it to classify questions into fine-grained classes.
Answer types are determined using classification rules similar to Li and Roth (2002). $$$$$ Most question classes have a semantically related word list.
Answer types are determined using classification rules similar to Li and Roth (2002). $$$$$ food,plant, ind,group?

The classification scheme we propose is based on one dynamic 1 and one static layer, contrasting with previous work that uses static taxonomies (Li and Roth, 2002). $$$$$ We learn a hierarchical classifier that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into finegrained classes.
The classification scheme we propose is based on one dynamic 1 and one static layer, contrasting with previous work that uses static taxonomies (Li and Roth, 2002). $$$$$ food,plant, ind,group?
The classification scheme we propose is based on one dynamic 1 and one static layer, contrasting with previous work that uses static taxonomies (Li and Roth, 2002). $$$$$ In future work we plan to investigate further the application of deeper semantic analysis (including better named entity and semantic categorization) to feature extraction, automate the generation of thesemantic features and develop a better understand ing to some of the learning issues involved in thedifference between a flat and a hierarchical classi fier.
The classification scheme we propose is based on one dynamic 1 and one static layer, contrasting with previous work that uses static taxonomies (Li and Roth, 2002). $$$$$ Our goal is to categorize questions into different semantic classes that impose constraints on potential answers, so that they can be utilized in later stages of the question answeringprocess.

1500 of those questions come from the Li and Roth corpus (Li and Roth, 2002), 500 questions were taken from the TREC-10 questions and 100 questions were asked over the Italian Opera topic map. $$$$$ This paper presents a machine learning approach toquestion classification.
1500 of those questions come from the Li and Roth corpus (Li and Roth, 2002), 500 questions were taken from the TREC-10 questions and 100 questions were asked over the Italian Opera topic map. $$$$$ This flat classifier takes all fine classes as its initial confusion set and classifies a questioninto fine classes directly.
1500 of those questions come from the Li and Roth corpus (Li and Roth, 2002), 500 questions were taken from the TREC-10 questions and 100 questions were asked over the Italian Opera topic map. $$$$$ In the TRECcompetition (Voorhees, 2000), participants are requested to build a system which, given a set of En glish questions, can automatically extract answers (a short phrase) of no more than 50 bytes from a5-gigabyte document library.

We followed Li and Roth (Li and Roth, 2002) to implement the features for the EAT classifier. $$$$$ We learn a hierarchical classifier that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into finegrained classes.
We followed Li and Roth (Li and Roth, 2002) to implement the features for the EAT classifier. $$$$$ Our goal is to categorize questions into different semantic classes that impose constraints on potential answers, so that they can be utilized in later stages of the question answeringprocess.
We followed Li and Roth (Li and Roth, 2002) to implement the features for the EAT classifier. $$$$$ 4 describes our experimen tal study.
We followed Li and Roth (Li and Roth, 2002) to implement the features for the EAT classifier. $$$$$ By comparing this flat classifier with our hi erarchical classifier in classifying fine classes, we hope to know whether the hierarchical classifier hasany advantage in performance, in addition to the ad vantages it might have in downstream processing and comprehensibility.
