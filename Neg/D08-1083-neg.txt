 $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.
 $$$$$ (2005), and Moilanen and Pulman (2007).2) In our experiments, we compare learning- and non-learning-based approaches to expression-level polarity classification — with and without compositional semantics — and find that (1) simple heuristics based on compositional semantics outperform (89.7% in accuracy) other reasonable heuristics that do not incorporate compositional semantics (87.7%); they can also perform better than simple learning-based methods that do not incorporate compositional semantics (89.1%), (2) combining learning with the heuristic rules based on compositional semantics further improves the performance (90.7%), (3) content-word negators play an important role in determining the expression-level polarity, and, somewhat surprisingly, we find that (4) expression-level classification accuracy uniformly decreases as additional, potentially disambiguating, context is considered.
 $$$$$ This shows that most of relevant context for judging the polarity is contained within the expression boundaries, and motivates the task of finding the boundaries of opinion expressions.
 $$$$$ But decisions at each sentence level does not consider structural inference within the sentence.

Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ We achieve 88.6% accuracy with COMPOPR, 90.1% with SCNEGEX, and 87.6% with CCICOMPOMC.9 There are a number of possible reasons for our lower performance vs. Moilanen and Pulman (2007) on this data set.
Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ For brevity, we refer to both variations collectively as CCI-COMPO.
Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ That is, we count the number of positive polarity words and negative polarity words in a given expression, and assign the majority polarity to the expression.

 $$$$$ Notice that in this simple binary classification setting, it is inherently difficult to capture the compositional structure among words in x, because f(x, y) is merely a flat bag of features, and the prediction is governed simply by the dot product of f(x, y) and the parameter vector w. Next, instead of determining y directly from x, we introduce hidden variables z = (zi,..., zn) as intermediate decision variables, where zi E {positive, negative, negator, none}, so that zi represents whether xi is a word with positive/negative polarity, or a negator, or none of the above.
 $$$$$ Determining the polarity of a sentimentbearing expression requires more than a simple bag-of-words approach.
 $$$$$ We presented a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.
 $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.

For the general-purpose polarity lexicon, we expand the polarity lexicon of Wilson et al (2005) with General Inquirer dictionary as suggested by Choi and Cardie (2008). $$$$$ Among the studies that examined content-word negators, Niu et al. (2005) manually collected a small set of such words (referred as “words that change phases”), but their lexicon was designed mainly for the medical domain and the type of negators was rather limited.
For the general-purpose polarity lexicon, we expand the polarity lexicon of Wilson et al (2005) with General Inquirer dictionary as suggested by Choi and Cardie (2008). $$$$$ In addition, the SemEval-07 data is very different from the MPQA data in that (1) the polarity annotation is given only at the sentence level, (2) the sentences are shorter, with simpler structure, and not as many negators as the MPQA sentences, and (3) there are many more instances with positive polarity than in the MPQA corpus.
For the general-purpose polarity lexicon, we expand the polarity lexicon of Wilson et al (2005) with General Inquirer dictionary as suggested by Choi and Cardie (2008). $$$$$ In this paper, we view such interactions in light of composiand present a novel learningbased approach that incorporates structural inference motivated by compositional semantics into the learning procedure.

According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ Our approach can be considered as a small step toward bridging the gap between computational semantics and machine learning methods.
According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ To this end, we present a novel learning-based approach that incorporates inference rules inspired by compositional semantics into the learning procedure (§3.2).
According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ One approach includes features based on contextual valence shifters1 (Polanyi and Zaenen, 2004), which are words that affect the polarity or intensity of sentiment over neighboring text spans (e.g., Kennedy and Inkpen (2005), Wilson et al. (2005), Shaikh et al.

Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ In this paper, we view such interactions in light of composiand present a novel learningbased approach that incorporates structural inference motivated by compositional semantics into the learning procedure.
Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ We presented a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.
Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ One approach includes features based on contextual valence shifters1 (Polanyi and Zaenen, 2004), which are words that affect the polarity or intensity of sentiment over neighboring text spans (e.g., Kennedy and Inkpen (2005), Wilson et al. (2005), Shaikh et al.
Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ The polarity lexicon is initialized with the lexicon of Wilson et al. (2005) and then expanded using the General Inquirer dictionary.6 In particular, a word contained in at least two of the following categories is considered as positive: POSITIV, PSTV, POSAFF, PLEASUR, VIRTUE, INCREAS, and a word contained in at least one of the following categories is considered as negative: NEGATIV, NGTV, NEGAFF, PAIN, VICE, HOSTILE, FAIL, ENLLOSS, WLBLOSS, TRANLOSS.

Choi and Cardie (2008) also focus on the expression-level polarity classification, but their evaluation setting is not as practical as ours in that they assume the inputs are guaranteed to be either strongly positive or negative. $$$$$ In particular, it refers to the degree of “commitment” of the author to the truth or falsity of a complement clause for a textual entailment task.
Choi and Cardie (2008) also focus on the expression-level polarity classification, but their evaluation setting is not as practical as ours in that they assume the inputs are guaranteed to be either strongly positive or negative. $$$$$ Determining the polarity of sentiment-bearing expressions at or below the sentence level requires more than a simple bag-of-words approach.
Choi and Cardie (2008) also focus on the expression-level polarity classification, but their evaluation setting is not as practical as ours in that they assume the inputs are guaranteed to be either strongly positive or negative. $$$$$ And a system that simply takes the majority vote of the polarity of individual words will not work well on the above examples.

Choi and Cardie (2008) proposed a learning-based framework. $$$$$ Determining the polarity of a sentimentbearing expression requires more than a simple bag-of-words approach.
Choi and Cardie (2008) proposed a learning-based framework. $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.
Choi and Cardie (2008) proposed a learning-based framework. $$$$$ Next we present experimental results in §4, followed by related work in §5.

Choi and Cardie (2008) present a more lightweight approach using compositional semantics towards classifying the polarity of expressions. $$$$$ Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).
Choi and Cardie (2008) present a more lightweight approach using compositional semantics towards classifying the polarity of expressions. $$$$$ For each x, we encode the following features: a feature that indicates the dominant polarity of words in the given expression, without considering the effect of negators.
Choi and Cardie (2008) present a more lightweight approach using compositional semantics towards classifying the polarity of expressions. $$$$$ Their approach can be viewed as a type of structural inference, but their hand-written rules have not been empirically compared to learning-based alternatives, which one might expect to be more effective in handling some aspects of the polarity classification task.

The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions. $$$$$ In this paper, we consider the task of determining the polarity of a sentiment-bearing expression, considering the effect of interactions among words or constituents in light of compositional semantics.
The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions. $$$$$ In short, the Principle of Compositionality states that the meaning of a compound expression is a function of the meaning of its parts and of the syntactic rules by which they are combined (e.g., Montague (1974), Dowty et al. (1981)).
The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions. $$$$$ Determining the polarity of a sentimentbearing expression requires more than a simple bag-of-words approach.

Unlike Choi and Cardie (2008), these rules require a proper parse and reflect grammatical relationships between different constituents. $$$$$ Finally, in contrast to conventional wisdom, we find that expression-level classification accuracy additional, potentially disambiguating, context is considered.
Unlike Choi and Cardie (2008), these rules require a proper parse and reflect grammatical relationships between different constituents. $$$$$ Because the structure of compositional inference C does not allow dynamic programming, finding such an assignment is again intractable.
Unlike Choi and Cardie (2008), these rules require a proper parse and reflect grammatical relationships between different constituents. $$$$$ Our approach can be considered as a small step toward bridging the gap between computational semantics and machine learning methods.

In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ In particular, it refers to the degree of “commitment” of the author to the truth or falsity of a complement clause for a textual entailment task.
In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ In the case of a tie, we default to the prevailing polarity of the data.
In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ Finally, in contrast to conventional wisdom, we find that expression-level classification accuracy additional, potentially disambiguating, context is considered.
In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ In this paper, we consider the task of determining the polarity of a sentiment-bearing expression, considering the effect of interactions among words or constituents in light of compositional semantics.

Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.
Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ (e.g., words such as “eliminated” in the example sentences).
Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ Because z* is not always correct, we allow the training procedure to replace z* with potentially better assignments as learning proceeds: in the event that the soft gold standard z* leads to an incorrect prediction, we search for an assignment that leads to a correct prediction to replace z*.
Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ In what follows, we first explore heuristic-based approaches in §2, then we present learning-based approaches in §3.

Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive. $$$$$ Therefore, a more ideal solution would be a learning-based method that can exploit ideas from compositional semantics while providing the flexibility to the rigid application of the heuristic rules.
Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive. $$$$$ Performance is reported in Table 3.
Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive. $$$$$ Their approach can be viewed as a type of structural inference, but their hand-written rules have not been empirically compared to learning-based alternatives, which one might expect to be more effective in handling some aspects of the polarity classification task.

Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ For brevity, we refer to COMPOPR and COMPOMC collectively as COMPO.
Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ Our experimental results suggest that this direction of research is promising.
Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ McDonald et al. (2007) use a structured model to determine the sentence-level polarity and the document-level polarity simultaneously.
Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ To assess the effect of compositional semantics in the learning-based methods, we also experiment with a simple classification approach that does not incorporate compositional semantics (§3.1).

Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase. $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase. $$$$$ Also, their approach was based on a flat bag of features, and only a few examples of what we call content-word negators were employed.
Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase. $$$$$ To address these questions, we gradually relax our previous assumption that the exact boundaries of expressions are given: for each annotation boundary, we expand the boundary by x words for each direction, up to sentence boundaries, where x E 11, 5, ocI.

We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ (e.g., words such as “eliminated” in the example sentences).
We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).
We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ Our experimental results suggest that this direction of research is promising.
We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ Because the structure of compositional inference C does not allow dynamic programming, it is intractable to perform exact expectationmaximization style training that requires enumerating all possible values of the hidden variables z.

An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ • Among the learning-based methods, those that involve compositional inference (CCI-COMPO) always perform better than those that do not (SC) for any boundaries.
An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ (Notable exceptions include e.g., Niu et al. (2005), Wilson et al.
An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ In particular, it refers to the degree of “commitment” of the author to the truth or falsity of a complement clause for a textual entailment task.
An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ Our approach can be considered as a small step toward bridging the gap between computational semantics and machine learning methods.

Choi and Cardie (2008) categorized polarity reversing words into two categories: function-word negators such as not and content-word negators such as eliminate. $$$$$ In addition, we explore the role of context by expanding the boundaries of the sentiment-bearing expressions (§ 4.2).
Choi and Cardie (2008) categorized polarity reversing words into two categories: function-word negators such as not and content-word negators such as eliminate. $$$$$ Features.
Choi and Cardie (2008) categorized polarity reversing words into two categories: function-word negators such as not and content-word negators such as eliminate. $$$$$ In addition to the novel learning approach, this paper presents new insights for content-word negators, which we define as content words that can negate the polarity of neighboring words or constituents.
Choi and Cardie (2008) categorized polarity reversing words into two categories: function-word negators such as not and content-word negators such as eliminate. $$$$$ In particular, it refers to the degree of “commitment” of the author to the truth or falsity of a complement clause for a textual entailment task.

Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics. $$$$$ One might wonder whether employing additional context outside the annotated expression boundaries could further improve the performance.
Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics. $$$$$ We also find that “contentword negators”, not widely employed in previous work, play an important role in determining expression-level polarity.
Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics. $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
