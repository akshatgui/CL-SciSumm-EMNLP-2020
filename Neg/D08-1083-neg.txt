 $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
 $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.
 $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.
 $$$$$ Our experimental results suggest that this direction of research is promising.

Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ One approach includes features based on contextual valence shifters1 (Polanyi and Zaenen, 2004), which are words that affect the polarity or intensity of sentiment over neighboring text spans (e.g., Kennedy and Inkpen (2005), Wilson et al. (2005), Shaikh et al.
Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ We add this feature for each xi that is not a stop word.
Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).
Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008). $$$$$ Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).

 $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
 $$$$$ Because the structure of compositional inference C does not allow dynamic programming, it is intractable to perform exact expectationmaximization style training that requires enumerating all possible values of the hidden variables z.
 $$$$$ Also, their approach was based on a flat bag of features, and only a few examples of what we call content-word negators were employed.
 $$$$$ Therefore, a more ideal solution would be a learning-based method that can exploit ideas from compositional semantics while providing the flexibility to the rigid application of the heuristic rules.

For the general-purpose polarity lexicon, we expand the polarity lexicon of Wilson et al (2005) with General Inquirer dictionary as suggested by Choi and Cardie (2008). $$$$$ We achieve 88.6% accuracy with COMPOPR, 90.1% with SCNEGEX, and 87.6% with CCICOMPOMC.9 There are a number of possible reasons for our lower performance vs. Moilanen and Pulman (2007) on this data set.
For the general-purpose polarity lexicon, we expand the polarity lexicon of Wilson et al (2005) with General Inquirer dictionary as suggested by Choi and Cardie (2008). $$$$$ However, their notion of polarity is quite different from that assumed here and in the literature on sentiment analysis.
For the general-purpose polarity lexicon, we expand the polarity lexicon of Wilson et al (2005) with General Inquirer dictionary as suggested by Choi and Cardie (2008). $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.

According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ Notice that in this simple binary classification setting, it is inherently difficult to capture the compositional structure among words in x, because f(x, y) is merely a flat bag of features, and the prediction is governed simply by the dot product of f(x, y) and the parameter vector w. Next, instead of determining y directly from x, we introduce hidden variables z = (zi,..., zn) as intermediate decision variables, where zi E {positive, negative, negator, none}, so that zi represents whether xi is a word with positive/negative polarity, or a negator, or none of the above.
According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ Also, their approach was based on a flat bag of features, and only a few examples of what we call content-word negators were employed.
According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ First, SemEval-07 does not include a training data set for this task, so we use 400 documents from the MPQA corpus instead.
According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity. $$$$$ In particular, we exploit the fact that in our task, we can automatically construct a reasonably accurate gold standard for z, denoted as z*: as shown in Figure 2, we simply rely on the negator and polarity lexicons.

Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ We also find that “contentword negators”, not widely employed in previous work, play an important role in determining expression-level polarity.
Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ And learning with compositional inference tend to perform better than the rigid application of heuristic rules (COMPO), although the relative performance gain decreases once the boundaries are relaxed.
Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).
Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2. $$$$$ The difference between COMPO and any other heuristic that is not based on computational semantics is also statistically significant.

Choi and Cardie (2008) also focus on the expression-level polarity classification, but their evaluation setting is not as practical as ours in that they assume the inputs are guaranteed to be either strongly positive or negative. $$$$$ McDonald et al. (2007) use a structured model to determine the sentence-level polarity and the document-level polarity simultaneously.
Choi and Cardie (2008) also focus on the expression-level polarity classification, but their evaluation setting is not as practical as ours in that they assume the inputs are guaranteed to be either strongly positive or negative. $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.
Choi and Cardie (2008) also focus on the expression-level polarity classification, but their evaluation setting is not as practical as ours in that they assume the inputs are guaranteed to be either strongly positive or negative. $$$$$ In this paper, we view such interactions in light of composiand present a novel learningbased approach that incorporates structural inference motivated by compositional semantics into the learning procedure.

Choi and Cardie (2008) proposed a learning-based framework. $$$$$ Finally, in contrast to conventional wisdom, we find that expression-level classification accuracy additional, potentially disambiguating, context is considered.
Choi and Cardie (2008) proposed a learning-based framework. $$$$$ Instead, we propose a simple and tractable training rule based on the creation of a soft gold standard for z.
Choi and Cardie (2008) proposed a learning-based framework. $$$$$ For NEG(1), we first determine the majority polarity vote as above, and then if the expression contains any function-word negator, flip the polarity of the majority vote once.

Choi and Cardie (2008) present a more lightweight approach using compositional semantics towards classifying the polarity of expressions. $$$$$ In particular, it refers to the degree of “commitment” of the author to the truth or falsity of a complement clause for a textual entailment task.
Choi and Cardie (2008) present a more lightweight approach using compositional semantics towards classifying the polarity of expressions. $$$$$ That is, y = C(x, z), where C is the function that applies the compositional inference, either COMPOPR or COMPOMC.

The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions. $$$$$ For each x, we encode the following features: a feature that indicates the dominant polarity of words in the given expression, without considering the effect of negators.
The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions. $$$$$ Our use of compositional semantics for the task of polarity classification is preceded by Moilanen and Pulman (2007), but our work differs in that we integrate the key idea of compositional semantics into learning-based methods, and that we perform empirical comparisons among reasonable alternative approaches.
The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions. $$$$$ Note that if the second argument is a negator, we do not flip the polarity of the first argument, because the first argument in general is not in the semantic scope of the negation.4 Instead, we treat the second argument as a constituent with negative polarity.
The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions. $$$$$ Future research includes an approach that learns the compositional inference rules from data.

Unlike Choi and Cardie (2008), these rules require a proper parse and reflect grammatical relationships between different constituents. $$$$$ (e.g., words such as “eliminated” in the example sentences).
Unlike Choi and Cardie (2008), these rules require a proper parse and reflect grammatical relationships between different constituents. $$$$$ First, SemEval-07 does not include a training data set for this task, so we use 400 documents from the MPQA corpus instead.
Unlike Choi and Cardie (2008), these rules require a proper parse and reflect grammatical relationships between different constituents. $$$$$ Our approach can be considered as a small step toward bridging the gap between computational semantics and machine learning methods.

In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ Results.
In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ (Liang et al., 2008) Moilanen and Pulman (2007), on the other hand, handle the structural nature of the interactions more directly using the ideas from compositional semantics (e.g., Montague (1974), Dowty et al. (1981)).
In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ Determining the polarity of a sentimentbearing expression requires more than a simple bag-of-words approach.
In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008). $$$$$ (Liang et al., 2008) Moilanen and Pulman (2007), on the other hand, handle the structural nature of the interactions more directly using the ideas from compositional semantics (e.g., Montague (1974), Dowty et al. (1981)).

Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ For each x, we encode the following features: a feature that indicates the dominant polarity of words in the given expression, without considering the effect of negators.
Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ Finally, in contrast to conventional wisdom, we find that expression-level classification accuracy additional, potentially disambiguating, context is considered.
Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis. $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.

Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive. $$$$$ We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.
Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive. $$$$$ In this paper, we consider the task of determining the polarity of a sentiment-bearing expression, considering the effect of interactions among words or constituents in light of compositional semantics.
Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive. $$$$$ Results.
Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive. $$$$$ Finally, in contrast to conventional wisdom, we find that expression-level classification accuracy additional, potentially disambiguating, context is considered.

Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ (Liang et al., 2008) Moilanen and Pulman (2007), on the other hand, handle the structural nature of the interactions more directly using the ideas from compositional semantics (e.g., Montague (1974), Dowty et al. (1981)).
Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ Their approach can be viewed as a type of structural inference, but their hand-written rules have not been empirically compared to learning-based alternatives, which one might expect to be more effective in handling some aspects of the polarity classification task.
Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ In any case, it is important to determine whether our results will apply to more real-world settings where human-annotated expression boundaries are not available.
Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity. $$$$$ Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).

Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase. $$$$$ When consulting the General Inquirer dictionary, senses with less than 5% frequency and senses specific to an idiom are dropped.
Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase. $$$$$ Based on pilot experiments on the development data, we set parameters for MIRA as follows: slack variable to 0.5, and the number of incorrect labels (constraints) for each parameter update to 1.
Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase. $$$$$ The details of these two approaches are elaborated in the following subsections.

We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ In this paper, we consider the task of determining the polarity of a sentiment-bearing expression, considering the effect of interactions among words or constituents in light of compositional semantics.
We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ In what follows, we first explore heuristic-based approaches in §2, then we present learning-based approaches in §3.
We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ Our approach can be considered as a small step toward bridging the gap between computational semantics and machine learning methods.
We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008). $$$$$ And Moilanen and Pulman (2007) develop a collection of composition rules to assign a sentiment value to individual expressions, clauses, or sentences.

An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ This work was supported in part by National Science Foundation Grants BCS-0624277 and IIS-0535099 and by Department of Homeland Security Grant N0014-07-1-0152.
An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ For brevity, we refer to COMPOPR and COMPOMC collectively as COMPO.
An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ We presented a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.
An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words). $$$$$ Each assesses the polarity of the words or constituents using a polarity lexicon that indicates whether a word has positive or negative polarity, and finds negators in the given expression using a negator lexicon.

Choi and Cardie (2008) categorized polarity reversing words into two categories $$$$$ In particular, words or constituents within the expression can interact with each other to yield a particular overall polarity.
Choi and Cardie (2008) categorized polarity reversing words into two categories $$$$$ One of the difficulties is that words or constituents within the expression can interact with each other to yield a particular overall polarity.

Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics. $$$$$ That is, we count the number of positive polarity words and negative polarity words in a given expression, and assign the majority polarity to the expression.
Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics. $$$$$ We conjecture this is because methods based on compositional semantics can handle the scope of negators more adequately.
Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics. $$$$$ We presented a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.
Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics. $$$$$ In particular, it refers to the degree of “commitment” of the author to the truth or falsity of a complement clause for a textual entailment task.
