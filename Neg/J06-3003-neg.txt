Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ Recall dropped from 56.1% to 55.3% and precision dropped from 56.8% to 55.9%.
Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ On the related problem of classifying semantic relations, LRA achieves similar gains over the VSM.
Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ The frequencies are usually transformed by various formulas and weights, tailored to improve the effectiveness of the search engine (Salton 1989).
Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ On the related problem of classifying semantic relations, LRA achieves similar gains over the VSM.

The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ This thesaurus is available through an on-line interactive demonstration or it can be downloaded.5 We used the on-line demonstration, since the downloadable version seems to contain fewer words.
The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ Rada et al. (1989) suggest that the assessment of similarity in semantic networks can in fact be thought of as involving just taxonomic (IS-A) links, to the exclusion of other link types; that view will also be taken here, although admittedly it excludes some potentially useful information.
The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ Elements in these vectors are based on the frequencies of words in the corresponding queries and documents.
The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ LRA extends the VSM approach in three ways: (1) The patterns are derived automatically from the corpus, (2) the Singular Value Decomposition (SVD) is used to smooth the frequency data, and (3) automatically generated synonyms are used to explore variations of the word pairs.

Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ LRA achieves 56% on the 374 analogy questions, statistically equivalent to the average human score of 57%.
Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ We could score each candidate analogy by the average of the attributional similarity, sima, between A and C and between B and D: This kind of approach was used in two of the thirteen modules in Turney et al. (2003) (see Section 3.1).
Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ Since the VSM module had the best performance of the 13 modules (Turney et al. 2003), the following experiments focus on comparing VSM and LRA.
Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ On the related problem of classifying semantic relations, LRA achieves similar gains over the VSM.

Turney (2006) used a corpus-based algorithm. $$$$$ The amount of relational similarity between two pairs of words, A:B and C:D, depends on the degree of correspondence between the relations between A and B and the relations between C and D. A measure of relational similarity is a function that maps two pairs, A:B and C:D, to a real number, simr(A:B,C:D) E R. The more correspondence there is between the relations of A:B and C:D, the greater their relational similarity.
Turney (2006) used a corpus-based algorithm. $$$$$ There are at least two kinds of similarity.
Turney (2006) used a corpus-based algorithm. $$$$$ Marx et al. (2002) developed an unsupervised algorithm for discovering analogies by clustering words from two different corpora.
Turney (2006) used a corpus-based algorithm. $$$$$ In other words, for a typical SAT analogy question, we need to examine the top 300 patterns to explain why LRA selected one choice instead of another.

The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ As a courtesy to other users of Lin’s on-line system, we insert a 20-second delay between each two queries.
The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ We may think of this matrix UkEkVTk as a “smoothed” or “compressed” version of the original matrix.
The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ There is a high degree of relational similarity between the word pair traffic:street and the word pair water:riverbed.

The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ Thanks to the anonymous reviewers of Computational Linguistics for their very helpful comments and suggestions.
The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ LRA achieves 56% on the 374 analogy questions, statistically equivalent to the average human score of 57%.
The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ Each cluster of words in one corpus is coupled one-to-one with a cluster in the other corpus.
The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ The experiments demonstrate that LRA performs better than the VSM approach, when evaluated with SAT word analogy questions and with the task of classifying noun-modifier expressions.

PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ Most of the other steps are parallelizable; with a bit of programming effort, they could also be executed on the Beowulf cluster.
PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ The results for VSM-AV are taken from Turney and Littman (2005).
PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ Pantel and Lin (2002) clustered words according to their attributional similarity, as measured by a VSM.
PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ The experiments demonstrate that LRA performs better than the VSM approach, when evaluated with SAT word analogy questions and with the task of classifying noun-modifier expressions.

The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ The hope is that we can find near analogies for the original pairs, such that the near analogies co-occur more frequently in the corpus.
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ Instead of semantic similarity (Resnik 1995) or semantically similar (Chiarello et al. 1990), we prefer the term taxonomical similarity, which we take to be a specific type of attributional similarity.
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ Here we prefer to use the term attributional similarity because it emphasizes the contrast with relational similarity.
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ Although LRA is able to surpass VSM-AV when the WMTS corpus is only about one tenth the size of the AV corpus, it seems likely that LRA would perform better with a larger corpus.

The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ On the related problem of classifying semantic relations, LRA achieves similar gains over the VSM.
The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ On the 5 class problem, the accuracy is 58.0% (348/600) and the macroaveraged F is 54.6%.
The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ Gentner et al. (2001) argue that relational similarity is essential to understanding novel metaphors (as opposed to conventional metaphors).
The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ Before applying SVD, the vectors are completely non-negative, which implies that the cosine can only range from 0 to +1, but SVD introduces negative values, so it is possible for the cosine to be negative, although we have never observed this in our experiments.

Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ As these examples show, semantic relatedness is the same as attributional similarity (e.g., hot and cold are both kinds of temperature, pencil and paper are both used for writing).
Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ Table 18 shows the performance as N varies from 1 to 3,000.
Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ However, the difference between the highest performance (Turney 2001) and the VSM approach (Turney and Littman 2005) is also statistically significant with 95% confidence.
Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ are at least two kinds of similarity. similarity correspondence between rein contrast with which is correspondence between attributes. two words have a high degree of attributional similarity, we call them When two pairs of words have a high degree of relational similarity, we say that their relations are For example, the word pair mason:stone is analogous to the pair carpenter:wood.

This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ For example, the word pair mason:stone is analogous to the pair carpenter:wood.
This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ Many researchers have argued that metaphor is the heart of human thinking (Lakoff and Johnson 1980; Hofstadter and the Fluid Analogies Research Group 1995; Gentner et al. 2001; French 2002).
This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ The phrases cannot have more than max phrase words (we use max phrase = 5).
This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ The original table listed several semantic relations for which there were no instances in the data set.

Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ We have presented several examples of the many potential applications for measures of relational similarity.
Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ Unfortunately, it is time consuming and expensive to acquire hand-labeled data.
Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ It is possible that the error rate of LRA is still too high for practical applications, but the fact that LRA matches average human performance on SAT analogy questions is encouraging.

On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). $$$$$ However, noun-modifier pairs are interesting due to their high frequency in English.
On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). $$$$$ The final output of the system was based on a weighted combination of the outputs of each individual module.
On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). $$$$$ A query to a search engine is represented by a very sparse vector, whereas a document is represented by a relatively dense vector.
On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). $$$$$ This article introduces Latent Relational Analysis (LRA), a method for measuring relational similarity.

We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ For some applications, 30 classes may not be necessary; the 5 class scheme may be sufficient.
We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ A street carries traffic; a riverbed carries water.
We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ For some applications, 30 classes may not be necessary; the 5 class scheme may be sufficient.
We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ 10.

We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ For example, in flu virus, the head noun (H) is virus and the modifier (M) is flu (*).
We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ In future work, we plan to investigate some potential applications for LRA.
We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ LRA extends this approach in three ways: (1) The patterns are generated dynamically from the corpus, (2) SVD is used to smooth the data, and (3) a thesaurus is used to explore variations of the word pairs.
We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ In step 4, we selected the top 8,000 patterns (instead of the top 4,000), distinguishing the pattern “word1 P word2” from the pattern “word2 P word1” (instead of considering them equivalent).

The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ In our experiments with LRA (Sections 6 and 7), we use a local copy of the Waterloo MultiText System (WMTS) (Clarke, Cormack, and Palmer 1998; Terra and Clarke 2003), running on a 16 CPU Beowulf Cluster, with a corpus of about 5 × 1010 English words.
The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ LRA extends the VSM approach in three ways: (1) The patterns are derived automatically from the corpus, (2) the Singular Value Decomposition (SVD) is used to smooth the frequency data, and (3) automatically generated synonyms are used to explore variations of the word pairs.
The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ LRA has potential applications in many areas, including information extraction, word sense disambiguation, and information retrieval.
The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ We believe that relational similarity plays a fundamental role in the mind and therefore relational similarity measures could be crucial for artificial intelligence.

In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ Thus the algorithm appears to have discovered an analogical mapping between Buddhist schools and traditions and Christian schools and traditions.
In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ A measure of attributional similarity is a function that maps two words, A and B, to a real number, sima(A,B) E R. The more correspondence there is between the properties of A and B, the greater their attributional similarity.
In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ are at least two kinds of similarity. similarity correspondence between rein contrast with which is correspondence between attributes. two words have a high degree of attributional similarity, we call them When two pairs of words have a high degree of relational similarity, we say that their relations are For example, the word pair mason:stone is analogous to the pair carpenter:wood.
In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ Thanks to Vivi Nastase and Stan Szpakowicz for sharing their 600 classified noun-modifier phrases.

Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ Other researchers have proposed different schemes (Vanderwende 1994; Barker and Szpakowicz 1998; Rosario and Hearst 2001; Rosario, Hearst, and Fillmore 2002).
Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ Given a word and its part of speech, Lin’s thesaurus provides a list of words, sorted in order of decreasing attributional similarity.
Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ The results for VSM-AV are taken from Turney and Littman (2005).
Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ This section examines past work on measuring attributional and relational similarity using the VSM.

The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ Turney et al. (2003) combine 13 independent modules to answer SAT questions.
The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ For some of the applications, such as information extraction, LRA might be suitable if it is adjusted for high precision, at the expense of low recall.
The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ Let’s suppose that we wish to calculate the relational similarity between the pair quart:volume and the pair mile:distance, taken from the SAT question in Table 6.
The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ However, with progress in computer hardware, speed will gradually become less of a concern.

Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ This article introduces Latent Relational Analysis (LRA), a method for measuring relational similarity.
Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ The term semantic relatedness may lead to confusion when the term relational similarity is also under discussion.
