Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ Let’s suppose that we wish to calculate the relational similarity between the pair quart:volume and the pair mile:distance, taken from the SAT question in Table 6.
Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ LRA achieves 56% on the 374 analogy questions, statistically equivalent to the average human score of 57%.
Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006). $$$$$ Several authors report that the logarithmic transformation of frequencies improves cosine-based similarity measures (Salton and Buckley 1988; Ruge 1992; Lin 1998b).

The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ In the VSM approach, the relation between a pair of words is characterized by a vector offrequencies of predefined patterns in a large corpus.
The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ The 30 classes of Nastase and Szpakowicz (2003) might not be the best scheme.
The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ The output similarity measure is based on cosines, so the degree of similarity can range from −1 (dissimilar; 0 = 180°) to +1 (similar; 0 = 0°).
The template we use here is similar to Turney (2006), but we have added extra context words before the X and after the Y. $$$$$ It may also be possible to precompute much of the information for LRA, although this would require substantial changes to the algorithm.

Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ The following experiments use single nearest neighbor classification with leave-one-out cross-validation.
Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ Section 4 presents the VSM approach to measuring similarity.
Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ Turney et al. (2003) combine 13 independent modules to answer SAT questions.
Turney (2006) also selects patterns based on the number of pairs that generate them, but the number of selected patterns is a constant (8000), independent of the number of input word pairs. $$$$$ For some of the applications, such as information extraction, LRA might be suitable if it is adjusted for high precision, at the expense of low recall.

Turney (2006) used a corpus-based algorithm. $$$$$ The best guess is the label for the training pair with the highest cosine.
Turney (2006) used a corpus-based algorithm. $$$$$ The experiments demonstrate that LRA performs better than the VSM approach, when evaluated with SAT word analogy questions and with the task of classifying noun-modifier expressions.
Turney (2006) used a corpus-based algorithm. $$$$$ The precision was 120/(120 + 224) and the recall was 120/(120 + 224 + 30).
Turney (2006) used a corpus-based algorithm. $$$$$ Both of these are types of attributional similarity, since they are based on correspondence between attributes (e.g., bees and honey are both found in hives; deer and ponies are both mammals).

The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ Attributes are used to state properties of objects; relations express relations between objects or propositions.
The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ The solar system is the source domain and Rutherford’s model of the atom is the target domain.
The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ Thanks to Joel Martin for comments on the article.
The best previous result is an accuracy of 56.1% (Turney, 2006). $$$$$ Past work suggests that a hybrid approach, combining multiple modules, some corpusbased, some lexicon-based, will surpass any purebred approach (Turney et al. 2003).

The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ Other researchers have proposed different schemes (Vanderwende 1994; Barker and Szpakowicz 1998; Rosario and Hearst 2001; Rosario, Hearst, and Fillmore 2002).
The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ SVD improves both document-query attributional similarity measures (Deerwester et al. 1990; Dumais 1993) and word–word attributional similarity measures (Landauer and Dumais 1997).
The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ In future work, we plan to investigate some potential applications for LRA.
The average senior high school student achieves 57% correct (Turney, 2006). $$$$$ Given a pair of words, A and B, the task is to return another pair of words, X and Y, such that there is high relational similarity between the pair A:X and the pair Y:B.

PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ Thanks to Joel Martin for comments on the article.
PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ The VSM approach represents the relation between a pair of words with a vector, in which the elements are based on the frequencies of 64 hand-built patterns in a large corpus.
PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ There are 600 word pairs in the input set for LRA.
PairClass generates probability estimates, whereas Turney (2006) uses a cosine measure of similarity. $$$$$ In the VSM approach, the relation between a pair of words is characterized by a vector offrequencies of predefined patterns in a large corpus.

The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ The correct choice is called the solution and the incorrect choices are distractors.
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ Thanks to Egidio Terra, Charlie Clarke, and the School of Computer Science of the University of Waterloo, for giving us a copy of the Waterloo MultiText System and their Terabyte Corpus.
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ Analogy is a high degree of relational similarity.
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006). $$$$$ Recently the Vector Space Model (VSM) of information retrieval has been adapted to measuring relational similarity, achieving a score of 47% on a collection of 374 college-level multiple-choice word analogy questions.

The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ LRA has potential applications in many areas, including information extraction, word sense disambiguation, and information retrieval.
The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ Past work suggests that a hybrid approach, combining multiple modules, some corpusbased, some lexicon-based, will surpass any purebred approach (Turney et al. 2003).
The morphological processing in PairClass (Minnen et al, 2001) is more sophisticated than in Turney (2006). $$$$$ The results in Section 6.8 show that a vector contains more information than any single pattern or small set of patterns; a vector is a distributed representation.

Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ Recently the Vector Space Model (VSM) of information retrieval has been adapted to measuring relational similarity, achieving a score of 47% on a collection of 374 college-level multiple-choice word analogy questions.
Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ This article introduces Latent Relational Analysis (LRA), a method for measuring relational similarity.
Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ The results in Section 6.8 show that a vector contains more information than any single pattern or small set of patterns; a vector is a distributed representation.
Whereas the above mentioned approaches rely on additional knowledge sources, Turney (2006) developed a corpus based approach to model relational similarity, addressing (among other tasks) the distinction between synonyms and antonyms. $$$$$ LRA has potential applications in many areas, including information extraction, word sense disambiguation, and information retrieval.

This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ It is possible that the error rate of LRA is still too high for practical applications, but the fact that LRA matches average human performance on SAT analogy questions is encouraging.
This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ We conclude that there are enough near analogies in the 374 SAT questions for attributional similarity to perform better than random guessing, but not enough near analogies for attributional similarity to perform as well as relational similarity.
This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ It is possible that the error rate of LRA is still too high for practical applications, but the fact that LRA matches average human performance on SAT analogy questions is encouraging.
This aspect is most striking for ukWaC where the coverage is low and by only utilizing the single-occurrence sub-vectors we obtain a performance of 38.2% correct answers (the comparable "attributional" models reported in Turney, 2006, have an average performance of 31%). $$$$$ Attributes are used to state properties of objects; relations express relations between objects or propositions.

Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ On the 30 class problem, LRA with the single nearest neighbor algorithm achieves an accuracy of 39.8% (239/600) and a macroaveraged F of 36.6%.
Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ The results for VSM-AV are taken from Turney and Littman (2005).
Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ The value k = 300 is recommended by Landauer and Dumais (1997) for measuring the attributional similarity between words.
Vector-based distributional similarity methods have proven to be a valuable tool for a number of tasks on automatic discovery of semantic relatedness between words, like synonymy tests (Rapp, 2003) or detection of analogical similarity (Turney, 2006). $$$$$ For example, suppose A:B is quart:volume and C:D is mile:distance.

On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter $$$$$ An example of one of the 80 TOEFL questions appears in Table 2.
On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter $$$$$ Calculate relational similarity: The relational similarity between A:B and C:D is the average of the cosines, among the (num filter + 1)2 cosines from step 11, that are greater than or equal to the cosine of the original pairs, A:B and C:D. The requirement that the cosine must be greater than or equal to the original cosine is a way of filtering out poor analogies, which may be introduced in step 1 and may have slipped through the filtering in step 2.
On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter $$$$$ The accuracy might not yet be adequate for practical applications, although past work has shown that it is possible to adjust the trade-off of precision versus recall (Turney and Littman 2005).
On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter $$$$$ Assume that the input to LRA is the 374 multiple-choice SAT word analogy questions of Turney and Littman (2005).

We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ The five capitalized terms in the Relation column of Table 19 are the names of five groups of semantic relations.
We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ We know a priori that, if A:B::C:D, then B:A::D:C. For example, mason is to stone as carpenter is to wood implies stone is to mason as wood is to carpenter.
We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ Likewise, the nucleus and the electrons have attributes, such as charge(electron) and charge(nucleus), and relations, such as revolve(electron, nucleus) and attracts(nucleus, electron).
We solve SAT analogies with a simplified version of the method of Turney (2006). $$$$$ To make the task easier, we can collapse the 30 classes to 5 classes, using the grouping that is given in Table 19.

We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ Each SAT question has five choices, so answering 374 SAT questions required calculating 374 x 5 x 16 = 29,920 cosines.
We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ We are currently working on an extension of LRA that will explain with a single pattern why one choice is better than another.
We use this space to measure "relational" similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools. $$$$$ LRA achieves 56% on the 374 analogy questions, statistically equivalent to the average human score of 57%.

The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ For example, “laser printer” is classified as instrument; the printer uses the laser as an instrument for printing.
The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ In the VSM approach to relational similarity (Turney and Littman 2005), we create vectors, r1 and r2, that represent features of R1 and R2, and then measure the similarity of R1 and R2 by the cosine of the angle 0 between r1 and r2: We create a vector, r, to characterize the relationship between two words, X and Y, by counting the frequencies of various short phrases containing X and Y. Turney and Littman (2005) use a list of 64 joining terms, such as of, for, and to, to form 128 phrases that contain X and Y, such as X of Y, Y of X, X for Y, Y for X, X to Y, and Y to X.
The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ The five capitalized terms in the Relation column of Table 19 are the names of five groups of semantic relations.
The Attr cells summarize the performance of the 6 models on the wiki table that are based on "attributional similarity" only (Turney, 2006). $$$$$ Thanks to Michael Littman for sharing the 374 SAT analogy questions and for inspiring me to tackle them.

In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ Thanks to Doug Rohde for SVDLIBC and Michael Berry for SVDPACK.
In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ Recently the Vector Space Model (VSM) of information retrieval has been adapted to measuring relational similarity, achieving a score of 47% on a collection of 374 college-level multiple-choice word analogy questions.
In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ The desktop computer had 2 GB of RAM and the cluster had a total of 16 GB of RAM. from Turney and Littman (2005).
In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space. $$$$$ The difference between the lowest performance (Jiang and Conrath 1997) and random guessing is statistically significant with 95% confidence, according to the Fisher Exact Test (Agresti 1990).

Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ The first column shows the original pair and the alternate pairs.
Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ For example, the word pair mason:stone is analogous to the pair carpenter:wood.
Some of the recent work on this problem includes that of Butnariu et al (2009), Girju (2007), Girju et al (2005), Kim and Baldwin (2005), Nakov (2008), Nastase et al (2006), Turney (2006), and Saghdha and Copestake (2009). $$$$$ In step 4 of LRA, we simply select the top num patterns most frequent patterns and discard the remaining patterns.

The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ On the related problem of classifying semantic relations, LRA achieves similar gains over the VSM.
The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ Thanks to Dekang Lin for making his Dependency-Based Word Similarity lexicon available online.
The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ (The original table had a sixth group, but there are no examples of this group in the data set.)
The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. $$$$$ This article introduces Latent Relational Analysis (LRA), a method for measuring relational similarity.

Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ VSM-WMTS processed the questions in only one day.
Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ Macroaveraging calculates the precision, recall, and F for each class separately, and then calculates the average across all classes.
Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ The first five algorithms in Table 4 are implemented in Pedersen’s WordNetSimilarity package.2 The sixth algorithm (Turney 2001) used the Waterloo MultiText System (WMTS), as described in Terra and Clarke (2003).
Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. $$$$$ The choice pair with the highest average cosine (the choice with the largest value in column 1), choice (b), is the solution for this question; LRA answers the question correctly.
