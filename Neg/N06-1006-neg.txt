Pado et al. (2009) uses Textual Entailment features extracted from the Standford Entailment Recognizer (MacCartney et al, 2006). $$$$$ This work was supported in part by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program.
Pado et al. (2009) uses Textual Entailment features extracted from the Standford Entailment Recognizer (MacCartney et al, 2006). $$$$$ We see the present work as a first step in a promising direction.
Pado et al. (2009) uses Textual Entailment features extracted from the Standford Entailment Recognizer (MacCartney et al, 2006). $$$$$ We thank Anna Rafferty, Josh Ainslie, and particularly Roger Grosse for contributions to the ideas and system reported here.

Some authors have already designed similar matching techniques, such as the ones described in (MacCartney et al, 2006) and (Snow et al, 2006). $$$$$ We argue that there are significant weaknesses in this approach, including flawed assumptions of monotonicity and locality.
Some authors have already designed similar matching techniques, such as the ones described in (MacCartney et al, 2006) and (Snow et al, 2006). $$$$$ We thank Anna Rafferty, Josh Ainslie, and particularly Roger Grosse for contributions to the ideas and system reported here.
Some authors have already designed similar matching techniques, such as the ones described in (MacCartney et al, 2006) and (Snow et al, 2006). $$$$$ The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms—as in Moldovan et al. (2003) but not Raina et al.
Some authors have already designed similar matching techniques, such as the ones described in (MacCartney et al, 2006) and (Snow et al, 2006). $$$$$ The goal is to say whether the hypothesis follows from the text and general background knowledge, according to the intuitions of an intelligent human reader.

Marsi and Krahmer (2005) and MacCartney et al (2006) first advocated pipelined system architectures containing a distinct alignment component, a strategy crucial to the top-performing systems of Hickl et al (2006) and Hickl and Bensley (2007). $$$$$ We argue that there are significant weaknesses in this approach, including flawed assumptions of monotonicity and locality.
Marsi and Krahmer (2005) and MacCartney et al (2006) first advocated pipelined system architectures containing a distinct alignment component, a strategy crucial to the top-performing systems of Hickl et al (2006) and Hickl and Bensley (2007). $$$$$ We report accuracy and CWS on each RTE data set.
Marsi and Krahmer (2005) and MacCartney et al (2006) first advocated pipelined system architectures containing a distinct alignment component, a strategy crucial to the top-performing systems of Hickl et al (2006) and Hickl and Bensley (2007). $$$$$ We define a measure of alignment quality, and a procedure for identifying high scoring alignments.
Marsi and Krahmer (2005) and MacCartney et al (2006) first advocated pipelined system architectures containing a distinct alignment component, a strategy crucial to the top-performing systems of Hickl et al (2006) and Hickl and Bensley (2007). $$$$$ We predict entailment just in case the alignment score exceeds a threshold which is optimized on development data.

We have previously emphasized (MacCartney et al, 2006) that there is more to inferential validity than close lexical or structural correspondence: negations, modals, non-factive and implicative verbs, and other linguistic constructs can affect validity in ways hard to capture in alignment. $$$$$ The two models become distinct when there is a good supply of additional linguistic and world knowledge axioms—as in Moldovan et al. (2003) but not Raina et al.
We have previously emphasized (MacCartney et al, 2006) that there is more to inferential validity than close lexical or structural correspondence: negations, modals, non-factive and implicative verbs, and other linguistic constructs can affect validity in ways hard to capture in alignment. $$$$$ Some have used simple measures of semantic overlap, but the more interesting work has largely converged on a graphalignment approach, operating on semantic graphs derived from syntactic dependency parses, and using a locally-decomposable alignment score as a proxy for strength of entailment.
We have previously emphasized (MacCartney et al, 2006) that there is more to inferential validity than close lexical or structural correspondence: negations, modals, non-factive and implicative verbs, and other linguistic constructs can affect validity in ways hard to capture in alignment. $$$$$ This work was supported in part by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program.

Our system is based on the stage architecture of the Stanford RTE system (MacCartney et al, 2006), but adds a stage for event coreference decision. $$$$$ The no category is set apart, while an ordering over the other four categories is defined.
Our system is based on the stage architecture of the Stanford RTE system (MacCartney et al, 2006), but adds a stage for event coreference decision. $$$$$ Even greater benefits would flow to richer and more semantically complex NLP tasks.
Our system is based on the stage architecture of the Stanford RTE system (MacCartney et al, 2006), but adds a stage for event coreference decision. $$$$$ We argue that there are significant weaknesses in this approach, including flawed assumptions of monotonicity and locality.

Based on this representation, we apply a two stage entailment process similar to MacCartney et al (2006) developed for textual entailment: an alignment stage followed by an entailment stage. $$$$$ Our system has three stages: linguistic analysis, alignment, and entailment determination.
Based on this representation, we apply a two stage entailment process similar to MacCartney et al (2006) developed for textual entailment: an alignment stage followed by an entailment stage. $$$$$ We report results on data from the 2005 Pascal RTE Challenge which surpass previously reported results for alignment-based systems.
Based on this representation, we apply a two stage entailment process similar to MacCartney et al (2006) developed for textual entailment: an alignment stage followed by an entailment stage. $$$$$ For the common case of restrictive adjuncts, dropping an adjunct preserves truth (Dogs barked loudly �= Dogs barked), while adding an adjunct does not (Dogs barked K Dogs barked today).

Given the clause representation, we follow the idea similar to MacCartney et al (2006), and predict the entailment decision in two stages of processing: (1) an alignment model aligns terms in the hypothesis to terms in the conversation segment; and (2) an inference model predicts the entailment based on the alignment between the hypothesis and the conversation segment. $$$$$ Entailment problems might involve antonymy, as in ID 971.
Given the clause representation, we follow the idea similar to MacCartney et al (2006), and predict the entailment decision in two stages of processing: (1) an alignment model aligns terms in the hypothesis to terms in the conversation segment; and (2) an inference model predicts the entailment based on the alignment between the hypothesis and the conversation segment. $$$$$ Because full, accurate, open-domain natural language understanding lies far beyond current capabilities, nearly all efforts in this area have sought to extract the maximum mileage from quite limited semantic representations.
Given the clause representation, we follow the idea similar to MacCartney et al (2006), and predict the entailment decision in two stages of processing: (1) an alignment model aligns terms in the hypothesis to terms in the conversation segment; and (2) an inference model predicts the entailment based on the alignment between the hypothesis and the conversation segment. $$$$$ We have argued that such models suffer from three crucial limitations: an assumption of monotonicity, an assumption of locality, and a confounding of alignment and entailment determination.
Given the clause representation, we follow the idea similar to MacCartney et al (2006), and predict the entailment decision in two stages of processing: (1) an alignment model aligns terms in the hypothesis to terms in the conversation segment; and (2) an inference model predicts the entailment based on the alignment between the hypothesis and the conversation segment. $$$$$ In future, we aim to combine more precise modeling of monotonicity effects with better modeling of paraphrase equivalence.

We base our experiments on the Stanford RTE system which uses a staged architecture (MacCartney et al, 2006). $$$$$ Participants in the first PASCAL RTE workshop reported accuracy from 49% to 59%, and CWS from 50.0% to 69.0% (Dagan et al., 2005).
We base our experiments on the Stanford RTE system which uses a staged architecture (MacCartney et al, 2006). $$$$$ Unfortunately, even with factored scores the problem of finding the best alignment of two graphs is NP-complete, so exact computation is intractable.
We base our experiments on the Stanford RTE system which uses a staged architecture (MacCartney et al, 2006). $$$$$ For example, the graph in figure 1 might generate the quasi-LF rose(e1), nsubj(e1, x1), sales(x1), nn(x1, x2), Mitsubishi(x2), dobj(e1, x3), percent(x3), num(x3, x4), 46(x4).
We base our experiments on the Stanford RTE system which uses a staged architecture (MacCartney et al, 2006). $$$$$ In this work, however, we ignore the task variable, and none of the results shown in table 2 reflect optimization by task. figures reported for development data performance therefore reflect overfitting; while such results are not a fair measure of overall performance, they can help us assess the adequacy of our feature set: if our features have failed to capture relevant aspects of the problem, we should expect poor performance even when overfitting.

Later systems that include more linguistic features extracted from resources such as WordNet have enjoyed more success (MacCartney et al, 2006). $$$$$ We argue that there are significant weaknesses in this approach, including flawed assumptions of monotonicity and locality.
Later systems that include more linguistic features extracted from resources such as WordNet have enjoyed more success (MacCartney et al, 2006). $$$$$ Modality features capture simple patterns of modal reasoning, as in ID 98, which illustrates the heuristic that possibility does not entail actuality.
Later systems that include more linguistic features extracted from resources such as WordNet have enjoyed more success (MacCartney et al, 2006). $$$$$ To take just one example, dropping a restrictive modifier preserves entailment in a positive context, but not in a negative one.

Many of these features are inspired by MacCartney et al (2006) and Snow et al (2006), but not as sophisticated. $$$$$ We then determine the polarity (negative context, positive context or restrictor of a universal quantifier) of the two root nodes to generate features accordingly.
Many of these features are inspired by MacCartney et al (2006) and Snow et al (2006), but not as sophisticated. $$$$$ In practice, however, the RTE task is exceedingly difficult for computers.
Many of these features are inspired by MacCartney et al (2006) and Snow et al (2006), but not as sophisticated. $$$$$ Such models have serious limitations: semantic overlap is typically a symmetric relation, whereas entailment is clearly not, and, because overlap models do not account for syntactic or semantic structure, they are easily fooled by examples like ID 2081.

The Stanford Entailment Recognizer (MacCartney et al, 2006) is a stochastic model that computes match and mismatch features for each premise hypothesis pair. $$$$$ The goal is to say whether the hypothesis follows from the text and general background knowledge, according to the intuitions of an intelligent human reader.
The Stanford Entailment Recognizer (MacCartney et al, 2006) is a stochastic model that computes match and mismatch features for each premise hypothesis pair. $$$$$ Instead we propose a pipelined approach where alignment is followed by a classification step, in which we extract features representing high-level characteristics of the entailment problem, and pass the resulting feature vector to a statistical classifier trained on development data.
The Stanford Entailment Recognizer (MacCartney et al, 2006) is a stochastic model that computes match and mismatch features for each premise hypothesis pair. $$$$$ If one could tell that Protestors chanted slogans opposing a free trade agreement was a match for people demonstrating against free trade, then one could offer a form of semantic search not available with current keywordbased search.

It has a three-stage architecture similar to the RTE system of MacCartney et al (2006). $$$$$ We see the present work as a first step in a promising direction.
It has a three-stage architecture similar to the RTE system of MacCartney et al (2006). $$$$$ Given a good alignment, the determination of entailment reduces to a simple classification decision.
It has a three-stage architecture similar to the RTE system of MacCartney et al (2006). $$$$$ For example, in ID 59, the hypothesis aligns well with the text, but the addition of in Iraq indicates non-entailment.
It has a three-stage architecture similar to the RTE system of MacCartney et al (2006). $$$$$ This work was supported in part by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program.

MacCartney et al (2006) describe a system for doing robust textual inference. $$$$$ We focus on the PASCAL RTE data, examples from which are shown in table 1.
MacCartney et al (2006) describe a system for doing robust textual inference. $$$$$ This paper advocates a new architecture for textual inference in which finding a good alignment is separated from evaluating entailment.
MacCartney et al (2006) describe a system for doing robust textual inference. $$$$$ Finding aligned content can be done by any search procedure.
MacCartney et al (2006) describe a system for doing robust textual inference. $$$$$ Such models have serious limitations: semantic overlap is typically a symmetric relation, whereas entailment is clearly not, and, because overlap models do not account for syntactic or semantic structure, they are easily fooled by examples like ID 2081.
