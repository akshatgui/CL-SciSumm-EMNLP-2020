We follow the recent work of (Klementiev and Roth 2006) who addressed the problem of discovery of transliterated named entities from comparable corpora and suggested that alignment may not be necessary for transliteration. $$$$$ Taliban and Afghanistan in recent news).
We follow the recent work of (Klementiev and Roth 2006) who addressed the problem of discovery of transliterated named entities from comparable corpora and suggested that alignment may not be necessary for transliteration. $$$$$ Unlike most of the previous work to transliteration, that consider generative transliteration models, we take a discriminative approach.
We follow the recent work of (Klementiev and Roth 2006) who addressed the problem of discovery of transliterated named entities from comparable corpora and suggested that alignment may not be necessary for transliteration. $$$$$ A large amount of previous work exists on transliteration models.

 $$$$$ Taliban and Afghanistan in recent news).
 $$$$$ A subject of future work is to extend the algorithm to the multi-word setting.
 $$$$$ For example, for Arabic, a small set of prefixes can be used to group most NE variants.
 $$$$$ (Shinyama and Sekine, 2004) used the idea to discover NEs, but in a single language, English, across two news sources.

 $$$$$ For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and English-Korean generative transliteration models, respectively.
 $$$$$ Named Entity recognition (NER) is an important part of many natural language processing tasks.
 $$$$$ The algorithm makes use of a new, frequency based, metric for time distributions and a resource free discriminative approach to transliteration.
 $$$$$ For example, we can disallow the coupling of substrings whose starting positions are too far apart: thus, we might not consider a pairing in the above example.

 $$$$$ A major challenge inherent in discovering transliterated NEs is the fact that a single entity may be represented by multiple transliteration strings.
 $$$$$ ).
 $$$$$ Unlike most of the previous work to transliteration, that consider generative transliteration models, we take a discriminative approach.
 $$$$$ On the other hand, time sequence similarity based approaches would incorrectly match words which happen to have similar time signatures (e.g.

 $$$$$ The algorithm can be naturally extended to comparable corpora of more than two languages.
 $$$$$ Most current approaches employ machine learning techniques and require supervised data.
 $$$$$ If a dictionary exists for the two languages, it can be consulted first, and, if a match is found, transliteration model can be bypassed.

 $$$$$ This paper presents an algorithm to automatically discover Named Entities (NEs) in a resource free language, given a bilingual corpora in which it is weakly temporally aligned with a resource rich language.
 $$$$$ The first observation is that NEs in one language in such corpora tend to co-occur with their counterparts in the other.
 $$$$$ If a dictionary exists for the two languages, it can be consulted first, and, if a match is found, transliteration model can be bypassed.
 $$$$$ Figure 4 shows parts of transliteration lists for NE forsyth for two iterations of the algorithm.

We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. $$$$$ Moreover, it is often difficult to find experts in these languages both for the expensive annotation effort and even for language specific clues.
We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. $$$$$ However, many languages lack such resources.
We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. $$$$$ For example, Mount in Mount Rainier will probably be translated, and Rainier - transliterated.
We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. $$$$$ This paper presents an algorithm to automatically discover Named Entities (NEs) in a resource free language, given a bilingual corpora in which it is weakly temporally aligned with a resource rich language.

This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.
This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ Positive examples used for iterative training are pairs of NEs and their best temporally aligned (thresholded) transliteration candidates.
This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). $$$$$ .

We adopt a methodology parallel to that of [Klementiev and Roth, 2006], but we focus instead on mining parallel named entity transliteration pairs, using a well-trained linear classifier to identify transliteration pairs. $$$$$ For time sequence matching, we used a scoring metric novel in this domain.
We adopt a methodology parallel to that of [Klementiev and Roth, 2006], but we focus instead on mining parallel named entity transliteration pairs, using a well-trained linear classifier to identify transliteration pairs. $$$$$ We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.
We adopt a methodology parallel to that of [Klementiev and Roth, 2006], but we focus instead on mining parallel named entity transliteration pairs, using a well-trained linear classifier to identify transliteration pairs. $$$$$ 1999.

Recently, [Klementiev and Roth, 2006] outlined an approach by leveraging the availability of article aligned news corpora between English and Russian, and tools in English, for discovering transliteration pairs between the two languages, and progressively refining the discovery process. $$$$$ However, many languages lack such resources.
Recently, [Klementiev and Roth, 2006] outlined an approach by leveraging the availability of article aligned news corpora between English and Russian, and tools in English, for discovering transliteration pairs between the two languages, and progressively refining the discovery process. $$$$$ One reason is language morphology.
Recently, [Klementiev and Roth, 2006] outlined an approach by leveraging the availability of article aligned news corpora between English and Russian, and tools in English, for discovering transliteration pairs between the two languages, and progressively refining the discovery process. $$$$$ In order to generate time sequence for a word, we divide the corpus into a sequence of temporal bins, and count the number of occurrences of the word in each bin.

As in [Klementiev and Roth, 2006] no language specific knowledge was used to refine our mining process, making the approach broadly applicable. $$$$$ In this work, we only consider single word Named Entities.
As in [Klementiev and Roth, 2006] no language specific knowledge was used to refine our mining process, making the approach broadly applicable. $$$$$ We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anonymous referees for their helpful comments.
As in [Klementiev and Roth, 2006] no language specific knowledge was used to refine our mining process, making the approach broadly applicable. $$$$$ Many of the multi-word NEs are translated as well as transliterated.

In this section, we outline briefly the methodology presented in [Klementiev and Roth, 2006], and refer interested readers to the source for details. $$$$$ However, they focus on the classification stage of already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language.
In this section, we outline briefly the methodology presented in [Klementiev and Roth, 2006], and refer interested readers to the source for details. $$$$$ If a dictionary exists for the two languages, it can be consulted first, and, if a match is found, transliteration model can be bypassed.
In this section, we outline briefly the methodology presented in [Klementiev and Roth, 2006], and refer interested readers to the source for details. $$$$$ We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anonymous referees for their helpful comments.
In this section, we outline briefly the methodology presented in [Klementiev and Roth, 2006], and refer interested readers to the source for details. $$$$$ The site provides loose translations of (and pointers to) the original English texts.

We start with comparable corpora in English and Tamil, similar in size to that used in [Klementiev and Roth, 2006], and using the English side of this corpora, first, we extract all the NEs that occur more than a given threshold parameter, FE, using a standard NER tool. $$$$$ Unsupervised models for named entity classification.
We start with comparable corpora in English and Tamil, similar in size to that used in [Klementiev and Roth, 2006], and using the English side of this corpora, first, we extract all the NEs that occur more than a given threshold parameter, FE, using a standard NER tool. $$$$$ We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language.
We start with comparable corpora in English and Tamil, similar in size to that used in [Klementiev and Roth, 2006], and using the English side of this corpora, first, we extract all the NEs that occur more than a given threshold parameter, FE, using a standard NER tool. $$$$$ In keeping with our objective to provide as little language knowledge as possible, we introduced a simplistic approach to identifying transliteration equivalence classes, which sometimes produced erroneous groupings (e.g. an equivalence class for NE lincoln in Russian included both lincoln and lincolnshire on Figure 6).
We start with comparable corpora in English and Tamil, similar in size to that used in [Klementiev and Roth, 2006], and using the English side of this corpora, first, we extract all the NEs that occur more than a given threshold parameter, FE, using a standard NER tool. $$$$$ However, they focus on the classification stage of already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language.

While we adopted a methodology similar to that in [Klementiev and Roth, 2006], our focus was on mining parallel NE transliteration pairs, leveraging the availability of comparable corpora and a well-trained linear classifier to identify transliteration pairs. $$$$$ Unsupervised models for named entity classification.
While we adopted a methodology similar to that in [Klementiev and Roth, 2006], our focus was on mining parallel NE transliteration pairs, leveraging the availability of comparable corpora and a well-trained linear classifier to identify transliteration pairs. $$$$$ This model is called the infinite attribute model (Blum, 1992) and it follows the perceptron version in SNoW (Roth, 1998).
While we adopted a methodology similar to that in [Klementiev and Roth, 2006], our focus was on mining parallel NE transliteration pairs, leveraging the availability of comparable corpora and a well-trained linear classifier to identify transliteration pairs. $$$$$ For example, for Arabic, a small set of prefixes can be used to group most NE variants.

However, several techniques for mining name transliterations from monolingual and comparable corpora have been studied (Pasternack and Roth, 2009), (Goldwasser and Roth, 2008), (Klementiev and Roth, 2006), (Sproat et al, 2006), (Udupa et al, 2009b). $$$$$ Most current approaches employ machine learning techniques and require supervised data.
However, several techniques for mining name transliterations from monolingual and comparable corpora have been studied (Pasternack and Roth, 2009), (Goldwasser and Roth, 2008), (Klementiev and Roth, 2006), (Sproat et al, 2006), (Udupa et al, 2009b). $$$$$ The intuition is the following: the few examples in the initial training set produce features corresponding to substring pairs characteristic for English-Russian transliterations.

Character unigrams and bigrams were used as features to learn a discriminative transliteration model and time series similarity was combined with the transliteration similarity model (Klementiev and Roth, 2006). $$$$$ However, starting at the 6th iteration, the three are with 3% of one another.
Character unigrams and bigrams were used as features to learn a discriminative transliteration model and time series similarity was combined with the transliteration similarity model (Klementiev and Roth, 2006). $$$$$ Our version of perceptron takes examples with a variable number of features; each example is a set of all features seen so far that are active in the input.
Character unigrams and bigrams were used as features to learn a discriminative transliteration model and time series similarity was combined with the transliteration similarity model (Klementiev and Roth, 2006). $$$$$ (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English.

Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al, 2008). $$$$$ However, for many languages, these resources do not exist.
Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al, 2008). $$$$$ Unless mentioned otherwise, the transliteration model was initialized with a subset of 254 pairs of NEs and their transliteration equivalence classes.
Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al, 2008). $$$$$ The ultimate goal of this work is to automatically tag NEs so that they can be used for training of an NER system for a new language.

The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ While generative models are often robust, they tend to make independence assumptions that do not hold in data.
The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ A subject of future work is to extend the algorithm to the multi-word setting.
The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ However, many languages lack such resources.
The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier. $$$$$ Named Entity recognition (NER) is an important part of many natural language processing tasks.

We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. $$$$$ This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.
We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. $$$$$ We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.
We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. $$$$$ A subject of future work is to extend the algorithm to the multi-word setting.

Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ The algorithm makes use of a new, frequency based, metric for time distributions and a resource free discriminative approach to transliteration.
Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ We developed a linear discriminative transliteration model, and presented a method to automatically generate features.
Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ The algorithm makes use of a new, frequency based, metric for time distributions and a resource free discriminative approach to transliteration.
Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. $$$$$ We use a Discrete Fourier Transform (Arfken, 1985) based metric for computing similarity of time distributions, and we score NEs similarity with a linear transliteration model.
