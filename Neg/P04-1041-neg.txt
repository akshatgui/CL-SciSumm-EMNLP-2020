 $$$$$ The only pre-processing of the trees that wedo is to remove empty nodes, and remove all PennII functional tags in the integrated model.
 $$$$$ We extract LFG subcategorisation frames and paths linking LDDreentrancies from f-structures generated automati cally for the Penn-II treebank trees and use them in an LDD resolution algorithm to parse new text.Unlike (Collins, 1999; Johnson, 2002), in our ap proach resolution of LDDs is done at f-structure (attribute-value structure representations of basicpredicate-argument or dependency structure) with out empty productions, traces and coindexation in CFG parse trees.
 $$$$$ grammars.
 $$$$$ grammars.

For this experiment, we choose the C&C parser (Clark and Curran, 2003) for CCG, Enju parser (Miyao and Tsujii, 2008) for HPSG and pipeline automatic annotator (Cahill et al, 2004) with Charniak parser for LFG. $$$$$ In our approach, LDDs are resolved in f-structure, not trees.
For this experiment, we choose the C&C parser (Clark and Curran, 2003) for CCG, Enju parser (Miyao and Tsujii, 2008) for HPSG and pipeline automatic annotator (Cahill et al, 2004) with Charniak parser for LFG. $$$$$ a source said []1.
For this experiment, we choose the C&C parser (Clark and Curran, 2003) for CCG, Enju parser (Miyao and Tsujii, 2008) for HPSG and pipeline automatic annotator (Cahill et al, 2004) with Charniak parser for LFG. $$$$$ Coverage is near complete with 99.82% of the 48K Penn-II sentences receiving a single, connected f-structure.
For this experiment, we choose the C&C parser (Clark and Curran, 2003) for CCG, Enju parser (Miyao and Tsujii, 2008) for HPSG and pipeline automatic annotator (Cahill et al, 2004) with Charniak parser for LFG. $$$$$ : GFn : GF, traverse f along GF1 : . . .

 $$$$$ We outline the automatic f-structure annotation algorithm, PCFG-based LFG grammar approximations and parsing architecturesof (Cahill et al, 2002).
 $$$$$ Lexical information is provided via macros for POS tag classes.
 $$$$$ : GFn : GF, traverse f along GF1 : . . .
 $$$$$ The algorithm achieves an F-score of 96.57% for full f-structures and 94.3% for preds-only f-structures.4 S S-TPC- 1 NP U.N. VP V signs NP treaty NP Det the N headline VP V said S T- 1 ? ?

The research presented in this paper forms part of an ongoing effort to develop methods to induce wide-coverage multilingual Lexical Functional Grammar (LFG) (Bresnan, 2001) resources from tree banks by means of automatically associating LFG f-structure information with constituency trees produced by probabilistic parsers (Cahill et al, 2004). $$$$$ ?TOPIC=?COMP*COMP and generates the LDD-resolved proper f-structurein Figure 3 for the traceless tree in Figure 4, as re quired.In addition to FU equations, subcategorisation in formation is a crucial ingredient in LFG?s accountof LDDs.
The research presented in this paper forms part of an ongoing effort to develop methods to induce wide-coverage multilingual Lexical Functional Grammar (LFG) (Bresnan, 2001) resources from tree banks by means of automatically associating LFG f-structure information with constituency trees produced by probabilistic parsers (Cahill et al, 2004). $$$$$ We present our subcategorisation frame extraction and introduce the treebank based acquisition of finite approximations of LFG functional uncertainty equations in terms of LDD paths.
The research presented in this paper forms part of an ongoing effort to develop methods to induce wide-coverage multilingual Lexical Functional Grammar (LFG) (Bresnan, 2001) resources from tree banks by means of automatically associating LFG f-structure information with constituency trees produced by probabilistic parsers (Cahill et al, 2004). $$$$$ Based on these resources (Cahill et al, 2002) de veloped two parsing architectures.
The research presented in this paper forms part of an ongoing effort to develop methods to induce wide-coverage multilingual Lexical Functional Grammar (LFG) (Bresnan, 2001) resources from tree banks by means of automatically associating LFG f-structure information with constituency trees produced by probabilistic parsers (Cahill et al, 2004). $$$$$ We extract LFG subcategorisation frames and paths linking LDD reentrancies fromf-structures generated automatically for the PennII treebank trees and use them in an LDD resolu tion algorithm to parse new text.

The f-structure annotation algorithm used for inducing LFG resources from the Penn-II treebank for English (Cahill et al, 2004) uses configurational, categorial, function tag and trace information. $$$$$ Unlike (Collins, 1999; Johnson, 2002), in our approach LDDs are resolved on the level of f-structure representation,rather than in terms of empty productions and coindexation on parse trees.
The f-structure annotation algorithm used for inducing LFG resources from the Penn-II treebank for English (Cahill et al, 2004) uses configurational, categorial, function tag and trace information. $$$$$ Given a set of semantic forms s with probabilities P(s|l) (where l is a lemma), a set of paths p withP(p|t) (where t is either TOPIC, TOPIC-REL or FO CUS) and an f-structure f , the core of the algorithm to resolve LDDs recursively traverses f to: find TOPIC|TOPIC-REL|FOCUS:g pair; retrieve TOPIC|TOPIC-REL|FOCUS paths; for each path p with GF1 : . . .
The f-structure annotation algorithm used for inducing LFG resources from the Penn-II treebank for English (Cahill et al, 2004) uses configurational, categorial, function tag and trace information. $$$$$ Table 8 shows the evaluation result brokendown by individual GF (preds-only) for the inte grated model PA-PCFG against the DCU 105.
The f-structure annotation algorithm used for inducing LFG resources from the Penn-II treebank for English (Cahill et al, 2004) uses configurational, categorial, function tag and trace information. $$$$$ Including prepositions associated with the subcategorised OBLs and particles, this number goes up to 14348.

A methodology for automatically obtaining LFG f-structures from trees output by probabilistic parsers trained on the Penn-II tree bank has been described by Cahill et al (2004). $$$$$ We presented and extensively evaluated a finiteapproximation of LDD resolution in automatically constructed, wide-coverage, robust, PCFG based LFG approximations, effectively turning the ?half?(or ?shallow?)-grammars presented in (Cahill et al, 2002) into ?full?
A methodology for automatically obtaining LFG f-structures from trees output by probabilistic parsers trained on the Penn-II tree bank has been described by Cahill et al (2004). $$$$$ V ? signs ?PRED=sign??
A methodology for automatically obtaining LFG f-structures from trees output by probabilistic parsers trained on the Penn-II tree bank has been described by Cahill et al (2004). $$$$$ ) as well as traces and coin dexation (to indicate LDDs) as basic data structures.
A methodology for automatically obtaining LFG f-structures from trees output by probabilistic parsers trained on the Penn-II tree bank has been described by Cahill et al (2004). $$$$$ We ran experiments with grammars in both the pipeline and the integrated parsing architectures.

Some properties of Spanish and the encoding of syntactic information in the Cast3LB treebank make it non-trivial to apply the method of automatically mapping c-structures to f-structures used by Cahill et al (2004), which assigns grammatical functions to tree nodes based on their phrasal category, the category of the mother node and their position relative to the local head. $$$$$ Our method of resolv ing LDDs at f-structure level results in a preds-only f-score of 80.97%.
Some properties of Spanish and the encoding of syntactic information in the Cast3LB treebank make it non-trivial to apply the method of automatically mapping c-structures to f-structures used by Cahill et al (2004), which assigns grammatical functions to tree nodes based on their phrasal category, the category of the mother node and their position relative to the local head. $$$$$ (O?Donovan et al, 2004) provide a more detailed description of the extraction and evaluation of semantic forms.
Some properties of Spanish and the encoding of syntactic information in the Cast3LB treebank make it non-trivial to apply the method of automatically mapping c-structures to f-structures used by Cahill et al (2004), which assigns grammatical functions to tree nodes based on their phrasal category, the category of the mother node and their position relative to the local head. $$$$$ We use P(s|l) ? P(p|t) to rank a solution, depending on how likely the PRED takes semantic frame s, and how likely the TOPIC, FOCUS or TOPIC-REL is resolved using path p. The algorithm also supports resolution of LDDs where no overt linguistic material introducesa source TOPIC-REL function (e.g. in reduced rela tive clause constructions).
Some properties of Spanish and the encoding of syntactic information in the Cast3LB treebank make it non-trivial to apply the method of automatically mapping c-structures to f-structures used by Cahill et al (2004), which assigns grammatical functions to tree nodes based on their phrasal category, the category of the mother node and their position relative to the local head. $$$$$ We use P(s|l) ? P(p|t) to rank a solution, depending on how likely the PRED takes semantic frame s, and how likely the TOPIC, FOCUS or TOPIC-REL is resolved using path p. The algorithm also supports resolution of LDDs where no overt linguistic material introducesa source TOPIC-REL function (e.g. in reduced rela tive clause constructions).

Cahill et al (2004), in their presentation of LFG parsing resources, distinguish 32 types of dependencies, divided into two major groups: a group of predicate-only dependencies and non predicate dependencies. $$$$$ Some of these involve extensive clean up of the underlying Penn-II treebank resource prior to grammar extraction.
Cahill et al (2004), in their presentation of LFG parsing resources, distinguish 32 types of dependencies, divided into two major groups: a group of predicate-only dependencies and non predicate dependencies. $$$$$ In all cases, there is a marked improvement (2.07-6.36%) in the f-structures after LDD res olution.
Cahill et al (2004), in their presentation of LFG parsing resources, distinguish 32 types of dependencies, divided into two major groups: a group of predicate-only dependencies and non predicate dependencies. $$$$$ (Collins, 1999)?s Model 3 is limited to wh-traces in relative clauses (it doesn?t treat topicalisation, focus etc.).

The translation and reference files are analyzed by a tree bank-based, probabilistic Lexical-Functional Grammar (LFG) parser (Cahill et al, 2004), which produces a set of dependency triples for each input. $$$$$ SUBJ, ? OBJ?
The translation and reference files are analyzed by a tree bank-based, probabilistic Lexical-Functional Grammar (LFG) parser (Cahill et al, 2004), which produces a set of dependency triples for each input. $$$$$ By the same measure,full parse coverage is around 99% for our automat ically acquired PCFG-based LFG approximations.Against the PARC 700, the hand-crafted LFG grammar reported in (Kaplan et al, 2004) achieves an f score of 79.6%.
The translation and reference files are analyzed by a tree bank-based, probabilistic Lexical-Functional Grammar (LFG) parser (Cahill et al, 2004), which produces a set of dependency triples for each input. $$$$$ Currently our best automaticallyinduced grammars achieve 80.97% f-score for f structures parsing section 23 of the WSJ part of the Penn-II treebank and evaluating against the DCU1051 and 80.24% against the PARC 700 Depen dency Bank (King et al, 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al, 2004).
The translation and reference files are analyzed by a tree bank-based, probabilistic Lexical-Functional Grammar (LFG) parser (Cahill et al, 2004), which produces a set of dependency triples for each input. $$$$$ DT[?SPEC=?]

Cahill et al (2004) presents Penn-II Treebank based LFG parsing resources. $$$$$ fstructures with LDDs unresolved resulting in in complete argument structures as in Figure 4.
Cahill et al (2004) presents Penn-II Treebank based LFG parsing resources. $$$$$ (Johnson, 2002) All GFs 80.86 86.65 85.16 Preds Only 74.63 80.97 79.75 Table 10: Comparison at f-structure level of LDD resolution to (Johnson, 2002) on the DCU 105 parser (Charniak, 1999) and, using the pipeline f-structure annotation model, evaluate against the DCU 105, both before and after LDD resolution.
Cahill et al (2004) presents Penn-II Treebank based LFG parsing resources. $$$$$ However, with few notable exceptions(e.g. Collins?
Cahill et al (2004) presents Penn-II Treebank based LFG parsing resources. $$$$$ Given that the total number of path tokens in section 23 is 949,the finite approximation extracted from 02-23 cov ers 99.69% of all LDD paths in section 23.

In this paper, we use the parser developed by Cahill et al (2004), which automatically annotates input text with c-structure trees and f-structure dependencies, reaching high precision and recall rates. $$$$$ S NP VP U.N. V NP signs treaty [ SUBJ [ PRED U.N. ] PRED sign OBJ [ PRED treaty ] ] S ? NP VP ?SUBJ=?
In this paper, we use the parser developed by Cahill et al (2004), which automatically annotates input text with c-structure trees and f-structure dependencies, reaching high precision and recall rates. $$$$$ : GFn to sub-f-structure h; retrieve local PRED:l; add GF:g to h iff ? GF is not present at h wh-less TOPIC-REL # wh-less TOPIC-REL # subj 5692 adjunct 1314 xcomp:adjunct 610 obj 364 xcomp:obj 291 xcomp:xcomp:adjunct 96 comp:subj 76 xcomp:subj 67 Table 5: Most frequent wh-less TOPIC-REL paths 02?21 23 23 /(02?21) TOPIC 26 7 2 FOCUS 13 4 0 TOPIC-REL 60 22 1 Table 6: Number of path types extracted?
In this paper, we use the parser developed by Cahill et al (2004), which automatically annotates input text with c-structure trees and f-structure dependencies, reaching high precision and recall rates. $$$$$ a source said []1.
In this paper, we use the parser developed by Cahill et al (2004), which automatically annotates input text with c-structure trees and f-structure dependencies, reaching high precision and recall rates. $$$$$ C-structurecaptures surface grammatical configurations, f structure encodes abstract syntactic information approximating to predicate-argument/dependency structure or simple logical form (van Genabithand Crouch, 1996).

We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al, 2004) automatically extracted from tree banks, maximising the probability of a tree given an f-structure. $$$$$ fstructures with LDDs unresolved resulting in in complete argument structures as in Figure 4.
We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al, 2004) automatically extracted from tree banks, maximising the probability of a tree given an f-structure. $$$$$ In the integrated architecture the treebank is first annotated with f-structure equations.
We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al, 2004) automatically extracted from tree banks, maximising the probability of a tree given an f-structure. $$$$$ S NP VP U.N. V NP signs treaty [ SUBJ [ PRED U.N. ] PRED sign OBJ [ PRED treaty ] ] S ? NP VP ?SUBJ=?
We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al, 2004) automatically extracted from tree banks, maximising the probability of a tree given an f-structure. $$$$$ In our approach, LDDs are resolved in f-structure, not trees.

In this paper we present a novel PCFG-based architecture for probabilistic generation based onwide-coverage, robust Lexical Functional Grammar (LFG) approximations automatically extracted from tree banks (Cahill et al, 2004). $$$$$ Here weshow how they can be acquired from f-structure an notated treebank resources.LFG distinguishes between governable (arguments) and nongovernable (adjuncts) grammati cal functions (GFs).
In this paper we present a novel PCFG-based architecture for probabilistic generation based onwide-coverage, robust Lexical Functional Grammar (LFG) approximations automatically extracted from tree banks (Cahill et al, 2004). $$$$$ Table 3 shows the most frequent seman tic forms for accept.
In this paper we present a novel PCFG-based architecture for probabilistic generation based onwide-coverage, robust Lexical Functional Grammar (LFG) approximations automatically extracted from tree banks (Cahill et al, 2004). $$$$$ by extracting paths between co-indexedmaterial occurring in the automatically generated fstructures from sections 02-21 of the Penn-II tree bank.
In this paper we present a novel PCFG-based architecture for probabilistic generation based onwide-coverage, robust Lexical Functional Grammar (LFG) approximations automatically extracted from tree banks (Cahill et al, 2004). $$$$$ : GFn to sub-f-structure h; retrieve local PRED:l; add GF:g to h iff ? GF is not present at h wh-less TOPIC-REL # wh-less TOPIC-REL # subj 5692 adjunct 1314 xcomp:adjunct 610 obj 364 xcomp:obj 291 xcomp:xcomp:adjunct 96 comp:subj 76 xcomp:subj 67 Table 5: Most frequent wh-less TOPIC-REL paths 02?21 23 23 /(02?21) TOPIC 26 7 2 FOCUS 13 4 0 TOPIC-REL 60 22 1 Table 6: Number of path types extracted?

Cahill et al (2004) present two parsing architectures: the pipeline and the integrated parsing architecture. $$$$$ S S NP U.N. VP V signs NP treaty NP Det the N headline VP V said ? ?
Cahill et al (2004) present two parsing architectures: the pipeline and the integrated parsing architecture. $$$$$ We present our subcategorisation frame extraction and introduce the treebank based acquisition of finite approximations of LFG functional uncertainty equations in terms of LDD paths.
Cahill et al (2004) present two parsing architectures: the pipeline and the integrated parsing architecture. $$$$$ By the same measure,full parse coverage is around 99% for our automat ically acquired PCFG-based LFG approximations.Against the PARC 700, the hand-crafted LFG grammar reported in (Kaplan et al, 2004) achieves an f score of 79.6%.
Cahill et al (2004) present two parsing architectures: the pipeline and the integrated parsing architecture. $$$$$ In our approach, LDDs are resolved in f-structure, not trees.

The generation architecture presented here builds on the integrated parsing architecture resources of Cahill et al (2004). $$$$$ (Riezler etal., 2002; Kaplan et al, 2004) describe how a care fully hand-crafted LFG is scaled to the full Penn-II treebank with log-linear based probability models.
The generation architecture presented here builds on the integrated parsing architecture resources of Cahill et al (2004). $$$$$ In order to model the LFG account of LDD resolu tion we require subcat frames (i.e. semantic forms)and LDD resolution paths through f-structure.
The generation architecture presented here builds on the integrated parsing architecture resources of Cahill et al (2004). $$$$$ To account for the fronted sentential con stituents in Figures 3 and 4, an FU equation of the form ? TOPIC = ? COMP* COMP would be required.The equation states that the value of the TOPIC at tribute is token identical with the value of the finalCOMP argument along a path through the immedi ately enclosing f-structure along zero or more COMPattributes.

 $$$$$ TOPIC [ SUBJ [ PRED U.N. ] PRED sign OBJ [ PRED treaty ] ] SUBJ [ SPEC the PRED headline ] PRED say ? ?
 $$$$$ Currently our best automaticallyinduced grammars achieve 80.97% f-score for f structures parsing section 23 of the WSJ part of the Penn-II treebank and evaluating against the DCU1051 and 80.24% against the PARC 700 Depen dency Bank (King et al, 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al, 2004).
 $$$$$ C(onstituent)-structure represents the grouping of words and phrases into largerconstituents and is realised in terms of a CF PSG grammar.
 $$$$$ C-structurecaptures surface grammatical configurations, f structure encodes abstract syntactic information approximating to predicate-argument/dependency structure or simple logical form (van Genabithand Crouch, 1996).

 $$$$$ F(unctional)-structure represents abstract syntactic functions such as SUBJ(ect), OBJ(ect), OBL(ique), closed and open clausal COMP/XCOMP(lement), ADJ(unct), APP(osition) etc. and is implemented in terms of recursive feature structures (attribute-value matrices).
 $$$$$ Given a set of semantic forms s with probabilities P(s|l) (where l is a lemma), a set of paths p withP(p|t) (where t is either TOPIC, TOPIC-REL or FO CUS) and an f-structure f , the core of the algorithm to resolve LDDs recursively traverses f to: find TOPIC|TOPIC-REL|FOCUS:g pair; retrieve TOPIC|TOPIC-REL|FOCUS paths; for each path p with GF1 : . . .
 $$$$$ : GFn : GF, traverse f along GF1 : . . .
 $$$$$ F-Score 78.28 82.70 81.49 83.28 DCU 105 F-Strs All GFs F-Score (before LDD resolution) 79.82 79.24 81.12 81.20 All GFs F-Score (after LDD resolution) 83.79 84.59 86.30 87.04 Preds only F-Score (before LDD resolution) 70.00 71.57 73.45 74.61 Preds only F-Score (after LDD resolution) 73.78 77.43 78.76 80.97 2416 F-Strs All GFs F-Score (before LDD resolution) 81.98 81.49 83.32 82.78 All GFs F-Score (after LDD resolution) 84.16 84.37 86.45 86.00 Preds only F-Score (before LDD resolution) 72.00 73.23 75.22 75.10 Preds only F-Score (after LDD resolution) 74.07 76.12 78.36 78.40 PARC 700 Dependency Bank Subset of GFs following (Kaplan et al, 2004) 77.86 80.24 77.68 78.60 Table 7: Parser Evaluation 3.

This conditioning effectively turns the f-structure annotated PCFGs of Cahill et al (2004) into probabilistic generation grammars. $$$$$ Given that the total number of path tokens in section 23 is 949,the finite approximation extracted from 02-23 cov ers 99.69% of all LDD paths in section 23.
This conditioning effectively turns the f-structure annotated PCFGs of Cahill et al (2004) into probabilistic generation grammars. $$$$$ by extracting paths between co-indexedmaterial occurring in the automatically generated fstructures from sections 02-21 of the Penn-II tree bank.
This conditioning effectively turns the f-structure annotated PCFGs of Cahill et al (2004) into probabilistic generation grammars. $$$$$ Table 3 shows the most frequent seman tic forms for accept.

Our back off uses the built-in lexical macros of the automatic f-structure annotation algorithm of Cahill et al (2004) to identify potential part-of-speech categories corresponding to a particular set of features. $$$$$ We evalu ate the parse trees using evalb.
Our back off uses the built-in lexical macros of the automatic f-structure annotation algorithm of Cahill et al (2004) to identify potential part-of-speech categories corresponding to a particular set of features. $$$$$ We use P(s|l) ? P(p|t) to rank a solution, depending on how likely the PRED takes semantic frame s, and how likely the TOPIC, FOCUS or TOPIC-REL is resolved using path p. The algorithm also supports resolution of LDDs where no overt linguistic material introducesa source TOPIC-REL function (e.g. in reduced rela tive clause constructions).
Our back off uses the built-in lexical macros of the automatic f-structure annotation algorithm of Cahill et al (2004) to identify potential part-of-speech categories corresponding to a particular set of features. $$$$$ We use P(s|l) ? P(p|t) to rank a solution, depending on how likely the PRED takes semantic frame s, and how likely the TOPIC, FOCUS or TOPIC-REL is resolved using path p. The algorithm also supports resolution of LDDs where no overt linguistic material introducesa source TOPIC-REL function (e.g. in reduced rela tive clause constructions).
Our back off uses the built-in lexical macros of the automatic f-structure annotation algorithm of Cahill et al (2004) to identify potential part-of-speech categories corresponding to a particular set of features. $$$$$ Annotation quality is measured in terms of precision and recall (P&R) against the DCU 105.

The feasibility of such post-parse deepening (for a statistical parser) is demonstrated by Cahill et al (2004). $$$$$ In contrast, we acquire our resources from treebanks and achieve sub stantially wider coverage.
The feasibility of such post-parse deepening (for a statistical parser) is demonstrated by Cahill et al (2004). $$$$$ An annotated PCFG is then extracted where each non-terminal symbol in the grammar has been augmented with LFG f-equations: NP[?OBJ=?]
The feasibility of such post-parse deepening (for a statistical parser) is demonstrated by Cahill et al (2004). $$$$$ Exploiting this in formation (Cahill et al, 2002) implement an automatic LFG f-structure annotation algorithmthat associates nodes in treebank trees with f structure annotations in the form of attribute-valuestructure equations representing abstract predicate argument structure/dependency relations.
The feasibility of such post-parse deepening (for a statistical parser) is demonstrated by Cahill et al (2004). $$$$$ C- and f-structures are re lated in terms of functional annotations (constraints, attribute-value equations) on c-structure rules (cf.
