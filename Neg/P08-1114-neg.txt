In Marton and Resnik (2008), hiero variables were disambiguated with additional binary feature functions, with their weights optimized in standard MER training. $$$$$ Section 4 demonstrates the the value of these constraints via substantial improvements in ChineseEnglish translation performance, and extends the approach to Arabic-English.
In Marton and Resnik (2008), hiero variables were disambiguated with additional binary feature functions, with their weights optimized in standard MER training. $$$$$ Our introduction has already briefly noted Cowan et al. (2006), who relax parse-tree-based alignment to permit alignment of non-constituent subphrases on the source side, and translate modifiers using a separate phrase-based model, and DeNeefe et al.
In Marton and Resnik (2008), hiero variables were disambiguated with additional binary feature functions, with their weights optimized in standard MER training. $$$$$ Zollman and Venugopal (2006) start with a target language parser and use it to provide constraints on the extraction of hierarchical phrase pairs.

Our stronger baseline employs, in addition, the fine-grained syntactic soft constraint features of Marton and Resnik (2008), here after MR08. $$$$$ (Chiang, 2005; Chiang, 2007; Wu, 1997)).
Our stronger baseline employs, in addition, the fine-grained syntactic soft constraint features of Marton and Resnik (2008), here after MR08. $$$$$ An approach to incorporating parser-based constituents in the model was explored briefly, treating syntactic constituency as a soft constraint, with negative results.
Our stronger baseline employs, in addition, the fine-grained syntactic soft constraint features of Marton and Resnik (2008), here after MR08. $$$$$ The authors would like to thank David Chiang and Adam Lopez for making their source code available; the Stanford Parser team and Mary Harper for making their parsers available; David Chiang, Amy Weinberg, and CLIP Laboratory colleagues, particularly Chris Dyer, Adam Lopez, and Smaranda Muresan, for discussion and invaluable assistance.
Our stronger baseline employs, in addition, the fine-grained syntactic soft constraint features of Marton and Resnik (2008), here after MR08. $$$$$ We present an approach that explores the tradeoff from the other direction, starting with a context-free translation model learned directly from aligned parallel text, and then adding soft constituent-level constraints based on parses of the source language.

Marton and Resnik (2008) employed soft syntactic constraints with weighted binary features and no MaxEnt model. $$$$$ Furthermore, our results provide some insight into why the original approach may have failed to yield a positive outcome.
Marton and Resnik (2008) employed soft syntactic constraints with weighted binary features and no MaxEnt model. $$$$$ By combining multiple finer-grained syntactic features, we obtain significant improvements of up to 1.65 BLEU points (NP_, VP2, IP2, all-labels_, and XP+).
Marton and Resnik (2008) employed soft syntactic constraints with weighted binary features and no MaxEnt model. $$$$$ In addition to this phrase translation probability feature, Hiero’s feature set includes the inverse phrase translation probability log p(�f|e), lexical weights lexwt(�f|e) and lexwt(e |�f), which are estimates of translation quality based on word-level correspondences (Koehn et al., 2003), and a rule penalty allowing the model to learn a preference for longer or shorter derivations; see (Chiang, 2007) for details.
Marton and Resnik (2008) employed soft syntactic constraints with weighted binary features and no MaxEnt model. $$$$$ An approach to incorporating parser-based constituents in the model was explored briefly, treating syntactic constituency as a soft constraint, with negative results.

Marton and Resnik (2008) utilize the language linguistic analysis that is derived from parse tree to constrain the translation in a soft way. $$$$$ On the face of it, there are any number of possible reasons Chiang’s (2005) soft constraint did not work – including, for example, practical issues like the quality of the Chinese parses.5 However, we focus here on two conceptual issues underlying his use of source language syntactic constituents.
Marton and Resnik (2008) utilize the language linguistic analysis that is derived from parse tree to constrain the translation in a soft way. $$$$$ This work was supported in part by DARPA prime agreement HR0011-06-2-0001.
Marton and Resnik (2008) utilize the language linguistic analysis that is derived from parse tree to constrain the translation in a soft way. $$$$$ Riezler and Maxwell (2006) do not achieve higher BLEU scores, but do score better according to human grammaticality judgments for in-coverage cases.
Marton and Resnik (2008) utilize the language linguistic analysis that is derived from parse tree to constrain the translation in a soft way. $$$$$ They use LFG dependency trees on both source and target sides, and relax syntactic constraints by adding a “fragment grammar” for unparsable chunks.

Chiang (2005), Marton and Resnik (2008) explored the constituent match/violation in hiero; Xiong (2009 a) added constituent parse tree based linguistic analysis into BTG model; Xiong (2009 b) added source dependency structure to BTG; Zhang (2009) added tree-kernel to BTG model. $$$$$ For example, seems to capture the use of jingtian/this year as a temporal modifier when building linguistic constituents such as noun phrases (the election this year) or verb phrases (voted in the primary this year).
Chiang (2005), Marton and Resnik (2008) explored the constituent match/violation in hiero; Xiong (2009 a) added constituent parse tree based linguistic analysis into BTG model; Xiong (2009 b) added source dependency structure to BTG; Zhang (2009) added tree-kernel to BTG model. $$$$$ Zollman and Venugopal (2006) start with a target language parser and use it to provide constraints on the extraction of hierarchical phrase pairs.
Chiang (2005), Marton and Resnik (2008) explored the constituent match/violation in hiero; Xiong (2009 a) added constituent parse tree based linguistic analysis into BTG model; Xiong (2009 b) added source dependency structure to BTG; Zhang (2009) added tree-kernel to BTG model. $$$$$ A number of previous efforts have tackled this tradeoff by starting with a commitment to linguistically motivated analyses and then finding appropriate ways to soften that commitment.

We believe a greater improvement can be expected if we apply our idea to finer-grained approaches that use constraints softly (Marton and Resnik (2008) and Cherry (2008)). $$$$$ The authors would like to thank David Chiang and Adam Lopez for making their source code available; the Stanford Parser team and Mary Harper for making their parsers available; David Chiang, Amy Weinberg, and CLIP Laboratory colleagues, particularly Chris Dyer, Adam Lopez, and Smaranda Muresan, for discussion and invaluable assistance.
We believe a greater improvement can be expected if we apply our idea to finer-grained approaches that use constraints softly (Marton and Resnik (2008) and Cherry (2008)). $$$$$ In adding syntax to statistical MT, there is a tradeoff between taking advantage of linguistic analysis, versus allowing the model to exploit linguistically unmotivated mappings learned from parallel training data.
We believe a greater improvement can be expected if we apply our idea to finer-grained approaches that use constraints softly (Marton and Resnik (2008) and Cherry (2008)). $$$$$ However, it is important to observe that nothing in the Hiero framework actually requires nonterminal symbols to cover linguistically sensible constituents, and in practice they frequently do not.3 Chiang (2005) conjectured that there might be value in allowing the Hiero model to favor hypotheses for which the synchronous derivation respects linguistically motivated source-language constituency boundaries, as identified using a parser.
We believe a greater improvement can be expected if we apply our idea to finer-grained approaches that use constraints softly (Marton and Resnik (2008) and Cherry (2008)). $$$$$ We map Chinese DP labels to NP.

By relaxing the distortion limit, we have left room for more sophisticated re-ordering models in conventional phrase-based decoders while maintaining a significant performance advantage over hierarchical systems (Marton and Resnik, 2008). $$$$$ NP, we define a feature NP_ that ties the weights of NP= and NP+.
By relaxing the distortion limit, we have left room for more sophisticated re-ordering models in conventional phrase-based decoders while maintaining a significant performance advantage over hierarchical systems (Marton and Resnik, 2008). $$$$$ Over the last several years, however, the pendulum has begun to swing back in the other direction, with researchers exploring a variety of statistical models that take advantage of source- and particularly target-language syntactic analysis (e.g.
By relaxing the distortion limit, we have left room for more sophisticated re-ordering models in conventional phrase-based decoders while maintaining a significant performance advantage over hierarchical systems (Marton and Resnik, 2008). $$$$$ Each Ai is a weight associated with feature Oi, and these weights are typically optimized using minimum error rate training (Och, 2003).
By relaxing the distortion limit, we have left room for more sophisticated re-ordering models in conventional phrase-based decoders while maintaining a significant performance advantage over hierarchical systems (Marton and Resnik, 2008). $$$$$ Similarly, oVP+ would denote a binary feature that matches whenever the span of f crosses a VP boundary in the parse tree, resulting in AVP+ being subtracted from the hypothesis score.7 For readability from this point forward, we will omit 0 from the notation and refer to features such as NP= (which one could read as “NP match”), VP+ (which one could read as “VP crossing”), etc.

Marton and Resnik (2008) revised this method by distinguishing different constituent syntactic types, and defined features for each type to count whether a phrase matches or crosses the syntactic boundary. $$$$$ The authors would like to thank David Chiang and Adam Lopez for making their source code available; the Stanford Parser team and Mary Harper for making their parsers available; David Chiang, Amy Weinberg, and CLIP Laboratory colleagues, particularly Chris Dyer, Adam Lopez, and Smaranda Muresan, for discussion and invaluable assistance.
Marton and Resnik (2008) revised this method by distinguishing different constituent syntactic types, and defined features for each type to count whether a phrase matches or crosses the syntactic boundary. $$$$$ The authors would like to thank David Chiang and Adam Lopez for making their source code available; the Stanford Parser team and Mary Harper for making their parsers available; David Chiang, Amy Weinberg, and CLIP Laboratory colleagues, particularly Chris Dyer, Adam Lopez, and Smaranda Muresan, for discussion and invaluable assistance.
Marton and Resnik (2008) revised this method by distinguishing different constituent syntactic types, and defined features for each type to count whether a phrase matches or crosses the syntactic boundary. $$$$$ This work was supported in part by DARPA prime agreement HR0011-06-2-0001.

Neither of our systems uses source-side syntactic information; hence, both could potentially benefit from soft syntactic constraints as described by Marton and Resnik (2008). $$$$$ In adding syntax to statistical MT, there is a tradeoff between taking advantage of linguistic analysis, versus allowing the model to exploit linguistically unmotivated mappings learned from parallel training data.
Neither of our systems uses source-side syntactic information; hence, both could potentially benefit from soft syntactic constraints as described by Marton and Resnik (2008). $$$$$ We limit ourselves here to several approaches that seem most closely related.
Neither of our systems uses source-side syntactic information; hence, both could potentially benefit from soft syntactic constraints as described by Marton and Resnik (2008). $$$$$ Although performance of XP=, XP2 and all-labels+ were similar to that of the undifferentiated constituency feature, XP+ achieved the highest gain.
Neither of our systems uses source-side syntactic information; hence, both could potentially benefit from soft syntactic constraints as described by Marton and Resnik (2008). $$$$$ The authors would like to thank David Chiang and Adam Lopez for making their source code available; the Stanford Parser team and Mary Harper for making their parsers available; David Chiang, Amy Weinberg, and CLIP Laboratory colleagues, particularly Chris Dyer, Adam Lopez, and Smaranda Muresan, for discussion and invaluable assistance.

Marton and Resnik (2008) add feature functions to penalize or reward non-terminals which cross constituent boundaries of the source sentence. $$$$$ He tested this conjecture by adding a soft constraint in the form of a “constituency feature”: if a synchronous rule X —* (e, f) is used in a derivation, and the span of f is a constituent in the sourcelanguage parse, then a term a, is added to the model score in expression (1).4 Unlike a hard constraint, which would simply prevent the application of rules violating syntactic boundaries, using the feature to introduce a soft constraint allows the model to boost the “goodness” for a rule if it is constitent with the source language constituency analysis, and to leave its score unchanged otherwise.
Marton and Resnik (2008) add feature functions to penalize or reward non-terminals which cross constituent boundaries of the source sentence. $$$$$ Hiero (Chiang, 2005; Chiang, 2007) is a hierarchical phrase-based statistical MT framework that generalizes phrase-based models by permitting phrases with gaps.

Marton and Resnik (2008) and Cherry (2008) imposed syntactic constraints on the PBMT system by making use of prior linguistic knowledge in the form of syntax analysis. $$$$$ This work was supported in part by DARPA prime agreement HR0011-06-2-0001.
Marton and Resnik (2008) and Cherry (2008) imposed syntactic constraints on the PBMT system by making use of prior linguistic knowledge in the form of syntax analysis. $$$$$ Our second observation argues for distinguishing the benefit of match6This accomplishes coverage of the logically complete set of possibilities, which include not only f matching a constituent exactly or crossing its boundaries, but also f being properly contained within the constituent span, properly containing it, or being outside it entirely.
Marton and Resnik (2008) and Cherry (2008) imposed syntactic constraints on the PBMT system by making use of prior linguistic knowledge in the form of syntax analysis. $$$$$ In this example, a, would be added to the hypothesis score for any rule used in the hypothesis whose source side spanned the minister, a speech, yesterday, gave a speech yesterday, or the minister gave a speech yesterday.
Marton and Resnik (2008) and Cherry (2008) imposed syntactic constraints on the PBMT system by making use of prior linguistic knowledge in the form of syntax analysis. $$$$$ Our first observation argues for distinguishing among constituent types (NP, VP, etc.).

Marton and Resnik (2008) exploit shallow correspondences of hierarchical rules with source syntactic constituents extracted from parallel text, an approach also investigated by Chiang (2005). $$$$$ This work was supported in part by DARPA prime agreement HR0011-06-2-0001.
Marton and Resnik (2008) exploit shallow correspondences of hierarchical rules with source syntactic constituents extracted from parallel text, an approach also investigated by Chiang (2005). $$$$$ A number of previous efforts have tackled this tradeoff by starting with a commitment to linguistically motivated analyses and then finding appropriate ways to soften that commitment.
Marton and Resnik (2008) exploit shallow correspondences of hierarchical rules with source syntactic constituents extracted from parallel text, an approach also investigated by Chiang (2005). $$$$$ An approach to incorporating parser-based constituents in the model was explored briefly, treating syntactic constituency as a soft constraint, with negative results.

We compare our method with the baseline and some typical approaches listed in Table 1 where XP+ denotes the approach in (Marton and Resnik, 2008) and TOFW (topological ordering of function words) stands for the method in (Setiawan et al., 2009). $$$$$ A rule translating, say, minister gave a as a unit would receive no such boost.
We compare our method with the baseline and some typical approaches listed in Table 1 where XP+ denotes the approach in (Marton and Resnik, 2008) and TOFW (topological ordering of function words) stands for the method in (Setiawan et al., 2009). $$$$$ In addition to this phrase translation probability feature, Hiero’s feature set includes the inverse phrase translation probability log p(�f|e), lexical weights lexwt(�f|e) and lexwt(e |�f), which are estimates of translation quality based on word-level correspondences (Koehn et al., 2003), and a rule penalty allowing the model to learn a preference for longer or shorter derivations; see (Chiang, 2007) for details.
We compare our method with the baseline and some typical approaches listed in Table 1 where XP+ denotes the approach in (Marton and Resnik, 2008) and TOFW (topological ordering of function words) stands for the method in (Setiawan et al., 2009). $$$$$ When looking at Hiero rules, which are acquired automatically by the model from parallel text, it is easy to find many cases that seem to respect linguistically motivated boundaries.

Early works reward/penalize spans that respect the syntactic parse constituents of an input sentence (Chiang, 2005), and (Marton and Resnik, 2008). $$$$$ • For each constituent type, e.g.
Early works reward/penalize spans that respect the syntactic parse constituents of an input sentence (Chiang, 2005), and (Marton and Resnik, 2008). $$$$$ An approach to incorporating parser-based constituents in the model was explored briefly, treating syntactic constituency as a soft constraint, with negative results.
Early works reward/penalize spans that respect the syntactic parse constituents of an input sentence (Chiang, 2005), and (Marton and Resnik, 2008). $$$$$ Intuitively, this seems plausible: the feature says, at least for Chinese, that a translation hypothesis should incur a penalty if it is translating a substring as a unit when that substring is not a canonical source constituent.
Early works reward/penalize spans that respect the syntactic parse constituents of an input sentence (Chiang, 2005), and (Marton and Resnik, 2008). $$$$$ Our introduction has already briefly noted Cowan et al. (2006), who relax parse-tree-based alignment to permit alignment of non-constituent subphrases on the source side, and translate modifiers using a separate phrase-based model, and DeNeefe et al.

On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. $$$$$ We map Chinese DP labels to NP.
On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. $$$$$ The 7Formally, AVP+ simply contributes to the sum in expression (1), as with all features in the model, but weight optimization using minimum error rate training should, and does, automatically assign this feature a negative weight.
On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. $$$$$ Finally, another soft-constraint approach that can also be viewed as coming from the data-driven side, adding syntax, is taken by Riezler and Maxwell (2006).

Marton and Resnik (2008) find that some constituency types favor matching the source parse while others encourage violations. $$$$$ On the face of it, there are any number of possible reasons Chiang’s (2005) soft constraint did not work – including, for example, practical issues like the quality of the Chinese parses.5 However, we focus here on two conceptual issues underlying his use of source language syntactic constituents.
Marton and Resnik (2008) find that some constituency types favor matching the source parse while others encourage violations. $$$$$ We demonstrated improvements for ChineseEnglish translation, and succeed in obtaining substantial gains for Arabic-English translation, as well.
Marton and Resnik (2008) find that some constituency types favor matching the source parse while others encourage violations. $$$$$ When hierarchical phrase-based translation was introduced by Chiang (2005), it represented a new and successful way to incorporate syntax into statistical MT, allowing the model to exploit non-local dependencies and lexically sensitive reordering without requiring linguistically motivated parsing of either the source or target language.
Marton and Resnik (2008) find that some constituency types favor matching the source parse while others encourage violations. $$$$$ For minimum error rate training and development we used the NIST MTeval MT03 set.

To compare with the CMVC, we also conduct experiments using (Marton and Resnik, 2008)'s XP+. $$$$$ We limit ourselves here to several approaches that seem most closely related.
To compare with the CMVC, we also conduct experiments using (Marton and Resnik, 2008)'s XP+. $$$$$ Two individual finer-grained features (PP+ and AdvP=) yielded statistically significant gains up to .42 BLEU points, and feature combinations AP2, XP2 and all-labels2 yielded significant gains up to 1.03 BLEU points.
To compare with the CMVC, we also conduct experiments using (Marton and Resnik, 2008)'s XP+. $$$$$ This work was supported in part by DARPA prime agreement HR0011-06-2-0001.
To compare with the CMVC, we also conduct experiments using (Marton and Resnik, 2008)'s XP+. $$$$$ On the face of it, there are any number of possible reasons Chiang’s (2005) soft constraint did not work – including, for example, practical issues like the quality of the Chinese parses.5 However, we focus here on two conceptual issues underlying his use of source language syntactic constituents.

Like (Marton and Resnik, 2008), we find that the XP+feature obtains a significant improvement of 1.08 BLEU over the baseline. $$$$$ The results in Section 4 demonstrate, to our knowledge for the first time, that significant and sometimes substantial gains over baseline can be obtained by incorporating soft syntactic constraints into Hiero’s translation model.
Like (Marton and Resnik, 2008), we find that the XP+feature obtains a significant improvement of 1.08 BLEU over the baseline. $$$$$ We obtain substantial improvements in performance for translation from Chinese and Arabic to English.
Like (Marton and Resnik, 2008), we find that the XP+feature obtains a significant improvement of 1.08 BLEU over the baseline. $$$$$ The 7Formally, AVP+ simply contributes to the sum in expression (1), as with all features in the model, but weight optimization using minimum error rate training should, and does, automatically assign this feature a negative weight.

Experiments show that our model achieves substantial improvements over baseline and significantly outperforms (Marton and Resnik, 2008)'s XP+. $$$$$ He tested this conjecture by adding a soft constraint in the form of a “constituency feature”: if a synchronous rule X —* (e, f) is used in a derivation, and the span of f is a constituent in the sourcelanguage parse, then a term a, is added to the model score in expression (1).4 Unlike a hard constraint, which would simply prevent the application of rules violating syntactic boundaries, using the feature to introduce a soft constraint allows the model to boost the “goodness” for a rule if it is constitent with the source language constituency analysis, and to leave its score unchanged otherwise.
Experiments show that our model achieves substantial improvements over baseline and significantly outperforms (Marton and Resnik, 2008)'s XP+. $$$$$ Our first observation argues for distinguishing among constituent types (NP, VP, etc.).
Experiments show that our model achieves substantial improvements over baseline and significantly outperforms (Marton and Resnik, 2008)'s XP+. $$$$$ For minimum error rate training and development we used the NIST MTeval MT03 set.

Marton and Resnik (2008) find that their constituent constraints are sensitive to language pairs. $$$$$ We present an approach that explores the tradeoff from the other direction, starting with a context-free translation model learned directly from aligned parallel text, and then adding soft constituent-level constraints based on parses of the source language.
Marton and Resnik (2008) find that their constituent constraints are sensitive to language pairs. $$$$$ This work was supported in part by DARPA prime agreement HR0011-06-2-0001.
Marton and Resnik (2008) find that their constituent constraints are sensitive to language pairs. $$$$$ He tested this conjecture by adding a soft constraint in the form of a “constituency feature”: if a synchronous rule X —* (e, f) is used in a derivation, and the span of f is a constituent in the sourcelanguage parse, then a term a, is added to the model score in expression (1).4 Unlike a hard constraint, which would simply prevent the application of rules violating syntactic boundaries, using the feature to introduce a soft constraint allows the model to boost the “goodness” for a rule if it is constitent with the source language constituency analysis, and to leave its score unchanged otherwise.
Marton and Resnik (2008) find that their constituent constraints are sensitive to language pairs. $$$$$ The weight a,, like all other aZ, is set via minimum error rate training, and that optimization process determines empirically the extent to which the constituency feature should be trusted.
