This paper describes our entry to the 2011 CoNLL closed task (Pradhan et al, 2011) on modeling unrestricted coreference in OntoNotes. $$$$$ Resources in this field have tended to be limited to noun phrase coreference, often on a set of entities, such as entities.
This paper describes our entry to the 2011 CoNLL closed task (Pradhan et al, 2011) on modeling unrestricted coreference in OntoNotes. $$$$$ • It is interesting to note that the developers of the lee system also did the experiment of running their system using gold standard information on the individual layers, rather than automatic model predictions.
This paper describes our entry to the 2011 CoNLL closed task (Pradhan et al, 2011) on modeling unrestricted coreference in OntoNotes. $$$$$ We hope that this corpus and task will provide a useful resource for continued experimentation to help resolve this issue.

We have updated the publicly available CoNLL coreference scorer 1 with the proposed BLANC, and used it to compute the proposed BLANC scores for all the CoNLL 2011 (Pradhan et al, 2011) and 2012 (Pradhan et al, 2012) participant sin the official track, where participants had to automatically predict the mentions. $$$$$ As one of its layers, it has created a corpus for general anaphoric coreference that covers entities and events not limited to noun phrases or a limited set of entity types.
We have updated the publicly available CoNLL coreference scorer 1 with the proposed BLANC, and used it to compute the proposed BLANC scores for all the CoNLL 2011 (Pradhan et al, 2011) and 2012 (Pradhan et al, 2012) participant sin the official track, where participants had to automatically predict the mentions. $$$$$ OntoNotes provides a large-scale corpus of general anaphoric coreference not restricted to noun phrases or to a specified set of entity types.
We have updated the publicly available CoNLL coreference scorer 1 with the proposed BLANC, and used it to compute the proposed BLANC scores for all the CoNLL 2011 (Pradhan et al, 2011) and 2012 (Pradhan et al, 2012) participant sin the official track, where participants had to automatically predict the mentions. $$$$$ In this paper we described the anaphoric coreference information and other layers of annotation in the Mention pairs with less than threshold (5) number of different attribute values are considered (22% out of 99% original are discarded) All mention pairs and longer of nested mentions with common head kept OntoNotes corpus, and presented the results from an evaluation on learning such unrestricted entities and events in text.
We have updated the publicly available CoNLL coreference scorer 1 with the proposed BLANC, and used it to compute the proposed BLANC scores for all the CoNLL 2011 (Pradhan et al, 2011) and 2012 (Pradhan et al, 2012) participant sin the official track, where participants had to automatically predict the mentions. $$$$$ Corpora to support supervised learning of this task date back to the Message Understanding Conferences (MUC).

The proposed BLANC is highly positively correlated with the 1http $$$$$ They are also less consistent, in terms of inter-annotator agreement (ITA) (Hirschman et al., 1998).
The proposed BLANC is highly positively correlated with the 1http $$$$$ A small portion of this corpus from the newswire and broadcast news genres (-120k) was recently used for a SEMEVAL task (Recasens et al., 2010).
The proposed BLANC is highly positively correlated with the 1http $$$$$ It is interesting to note that some of the systems, including the best-performing one, used a completely rule-based approach even for this component.
The proposed BLANC is highly positively correlated with the 1http $$$$$ The intent is to annotate the VP, but we mark the single-word head for convenience.

We follow the CoNLL2011 scheme to select TRAIN, DEV and TEST datasets (Pradhan et al,2011). $$$$$ Finally, it is interesting to note that the problem of coreference does not seem to be following the same kind of learning curve that we are used to with other problems of this sort.
We follow the CoNLL2011 scheme to select TRAIN, DEV and TEST datasets (Pradhan et al,2011). $$$$$ OntoNotes comprises the following layers of annotation:
We follow the CoNLL2011 scheme to select TRAIN, DEV and TEST datasets (Pradhan et al,2011). $$$$$ In spite of all the progress, current techniques still rely primarily on surface level features such as string match, proximity, and edit distance; syntactic features such as apposition; and shallow semantic features such as number, gender, named entities, semantic class, Hobbs’ distance, etc.
We follow the CoNLL2011 scheme to select TRAIN, DEV and TEST datasets (Pradhan et al,2011). $$$$$ Although OntoNotes does not count those as instances of IDENT coreference, using that information may have helped their system discover additional useful links.

(Pradhan et al, 2011) presents challenges that go beyond previous definitions of the task. $$$$$ Various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (Ponzetto and Strube, 2005; Ponzetto and Strube, 2006; Versley, 2007; Ng, 2007).
(Pradhan et al, 2011) presents challenges that go beyond previous definitions of the task. $$$$$ This paper briefly describes the OntoNotes annotation (coreference and other layers) and then describes the parameters of the shared task including the format, pre-processing information, and evaluation criteria, and presents and discusses the results achieved by the participating systems.
(Pradhan et al, 2011) presents challenges that go beyond previous definitions of the task. $$$$$ The OntoNotes project has created a corpus of largescale, accurate, and integrated annotation of multiple levels of the shallow semantic structure in text.

An overview of all systems participating in the CONLL-2011 shared task and their results is provided by Pradhan et al (2011). $$$$$ OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure.
An overview of all systems participating in the CONLL-2011 shared task and their results is provided by Pradhan et al (2011). $$$$$ • It is interesting to note that the developers of the lee system also did the experiment of running their system using gold standard information on the individual layers, rather than automatic model predictions.
An overview of all systems participating in the CONLL-2011 shared task and their results is provided by Pradhan et al (2011). $$$$$ OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure.
An overview of all systems participating in the CONLL-2011 shared task and their results is provided by Pradhan et al (2011). $$$$$ Automatic identification of coreferring entities and events in text has been an uphill battle for several decades, partly because it can require world knowledge which is not well-defined and partly owing to the lack of substantial annotated data.

In this paper we present SUCRE (Kobdani and Schutze, 2010) that is a modular coreference resolution system participating in theCoNLL-2011 Shared Task $$$$$ For the roughly 10% of mentions that the automatic parser did not correctly identify, while the systems knew the correct boundaries, they had no hierarchical parser or semantic role label information, and they also had to further approximate the already heuristic head word identification.
In this paper we present SUCRE (Kobdani and Schutze, 2010) that is a modular coreference resolution system participating in theCoNLL-2011 Shared Task $$$$$ OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure.
In this paper we present SUCRE (Kobdani and Schutze, 2010) that is a modular coreference resolution system participating in theCoNLL-2011 Shared Task $$$$$ System performance does not seem to vary as much across the different genres as is normally the case with language processing tasks, which could suggest that coreference is relatively genre insensitive, or it is possible that scores are two low for the difference to be apparent.

This paper describes our coreference resolution system participating in the close track of CoNLL 2011 shared task (Pradhan et al, 2011). $$$$$ Resources in this field have tended to be limited to noun phrase coreference, often on a set of entities, such as entities.
This paper describes our coreference resolution system participating in the close track of CoNLL 2011 shared task (Pradhan et al, 2011). $$$$$ OntoNotes comprises the following layers of annotation:
This paper describes our coreference resolution system participating in the close track of CoNLL 2011 shared task (Pradhan et al, 2011). $$$$$ In the systems that used trained models, many systems used the approach described in Soon et al. (2001) for selecting the positive and negative training examples, while others used some of the alternative approaches that have been introduced in the research literature more recently.
This paper describes our coreference resolution system participating in the close track of CoNLL 2011 shared task (Pradhan et al, 2011). $$$$$ In addition to coreference, this data is also tagged with syntactic trees, high coverage verb and some noun propositions, partial verb and noun word senses, and 18 named entity types.

The most frequent one is the constituent's head that solvers need then to extract using ad-hoc rules; see the CoNLL 2011 shared task (Pradhan et al, 2011), for instance. $$$$$ The de facto standard datasets for current coreference studies are the MUC (Hirschman and Chinchor, 1997; Chinchor, 2001; Chinchor and Sundheim, 2003) and the ACE1 (G. Doddington et al., 2000) corpora.
The most frequent one is the constituent's head that solvers need then to extract using ad-hoc rules; see the CoNLL 2011 shared task (Pradhan et al, 2011), for instance. $$$$$ We gratefully acknowledge the support of the Defense Advanced Research Projects Agency (DARPA/IPTO) under the GALE program, DARPA/CMO Contract No.
The most frequent one is the constituent's head that solvers need then to extract using ad-hoc rules; see the CoNLL 2011 shared task (Pradhan et al, 2011), for instance. $$$$$ OntoNotes provides a large-scale corpus of general anaphoric coreference not restricted to noun phrases or to a specified set of entity types.
The most frequent one is the constituent's head that solvers need then to extract using ad-hoc rules; see the CoNLL 2011 shared task (Pradhan et al, 2011), for instance. $$$$$ The uryupina system similarly scores very close to nugues’s 54.53 Given that our choice of the official metric was somewhat arbitrary, if is also useful to look at the individual metrics, including the mention-based CEAFm and BLANC metrics that were not part of the official metric.

Our system builds on an earlier system that we evaluated in the CoNLL 2011 shared task (Pradhan et al, 2011), where we optimized significantly the solver code, most notably the mention detection step and the feature design. $$$$$ Identification and encoding of richer knowledge – possibly linked to knowledge sources – and development of learning algorithms that would effectively incorporate them is a necessary next step towards improving the current state of the art.
Our system builds on an earlier system that we evaluated in the CoNLL 2011 shared task (Pradhan et al, 2011), where we optimized significantly the solver code, most notably the mention detection step and the feature design. $$$$$ • It is noteworthy that systems did not seem to attempt the kind of joint inference that could make use of the full potential of various layers available in OntoNotes, but this could well have been owing to the limited time available for the shared task.
Our system builds on an earlier system that we evaluated in the CoNLL 2011 shared task (Pradhan et al, 2011), where we optimized significantly the solver code, most notably the mention detection step and the feature design. $$$$$ Although OntoNotes does not count those as instances of IDENT coreference, using that information may have helped their system discover additional useful links.
Our system builds on an earlier system that we evaluated in the CoNLL 2011 shared task (Pradhan et al, 2011), where we optimized significantly the solver code, most notably the mention detection step and the feature design. $$$$$ While performance has improved somewhat, it is not clear how far we will be able to go given the strategies at hand, or whether new techniques will be needed to capture additional information from the texts or from world knowledge.

The CoNLL 2011 Shared Task (Pradhan et al,2011) is dedicated to modeling unrestricted coreference in OntoNotes. $$$$$ Having a standard test set and evaluation parameters, all based on a new resource that provides multiple integrated annotation layers (parses, semantic roles, word senses, named entities and coreference) that could support joint models, should help to energize ongoing research in the task of entity and event coreference.
The CoNLL 2011 Shared Task (Pradhan et al,2011) is dedicated to modeling unrestricted coreference in OntoNotes. $$$$$ Because they logically represent attributions, appositives are tagged separately from Identity coreference.
The CoNLL 2011 Shared Task (Pradhan et al,2011) is dedicated to modeling unrestricted coreference in OntoNotes. $$$$$ A systematic study was then conducted using decision trees by Soon et al. (2001).

Both the CoNLL-2011 (Pradhan et al, 2011) and CoNLL 2012 (Pradhan et al, 2012) shared tasks focus on resolving coreference on the OntoNotes corpus. $$$$$ Almost half of the trained systems used the feature selection strategy from Soon et al. (2001) and found it beneficial.
Both the CoNLL-2011 (Pradhan et al, 2011) and CoNLL 2012 (Pradhan et al, 2012) shared tasks focus on resolving coreference on the OntoNotes corpus. $$$$$ Finally, we offer our special thanks to Llufs M`arquez and Joakim Nivre for their wonderful support and guidance without which this task would not have been successful.
Both the CoNLL-2011 (Pradhan et al, 2011) and CoNLL 2012 (Pradhan et al, 2012) shared tasks focus on resolving coreference on the OntoNotes corpus. $$$$$ Most participants appear not to have focused much on eventive coreference, those coreference chains that build off verbs in the data.
Both the CoNLL-2011 (Pradhan et al, 2011) and CoNLL 2012 (Pradhan et al, 2012) shared tasks focus on resolving coreference on the OntoNotes corpus. $$$$$ It comprises —450k words from newswire, —150k from magazine articles, —200k from broadcast news, —200k from broadcast conversations and —200k web data.

a) Non-anaphoric detection modules b) Pronominal resolution module The data used for training as well as testing was provided CoNLL-2001 shared task (Pradhan et al, 2011), (Pradhan et al, 2007) organizers. $$$$$ This suggests that their rule-based approach was able to do a more effective job of combining the multiple sources of evidence than the trained systems.
a) Non-anaphoric detection modules b) Pronominal resolution module The data used for training as well as testing was provided CoNLL-2001 shared task (Pradhan et al, 2011), (Pradhan et al, 2007) organizers. $$$$$ They are also less consistent, in terms of inter-annotator agreement (ITA) (Hirschman et al., 1998).
a) Non-anaphoric detection modules b) Pronominal resolution module The data used for training as well as testing was provided CoNLL-2001 shared task (Pradhan et al, 2011), (Pradhan et al, 2007) organizers. $$$$$ Identification and encoding of richer knowledge – possibly linked to knowledge sources – and development of learning algorithms that would effectively incorporate them is a necessary next step towards improving the current state of the art.

Plenty of machine learning algorithms such as Decision tree (Ng and Cardie,2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. Meanwhile, the CoNLL-2011 shared task on English language show that a well-designed rule-based approach can achieve a comparable performance as a statistical one (Pradhan et al, 2011). $$$$$ To this effect, it uses a relational database representation that captures both the inter- and intra-layer dependencies and also provides an object-oriented API for efficient, multitiered access to this data (Pradhan et al., 2007a).
Plenty of machine learning algorithms such as Decision tree (Ng and Cardie,2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. Meanwhile, the CoNLL-2011 shared task on English language show that a well-designed rule-based approach can achieve a comparable performance as a statistical one (Pradhan et al, 2011). $$$$$ Thus the first element is the head in all of the following cases: In the specificity scale, specific names of diseases and technologies are classified as proper names, whether they are capitalized or not.
Plenty of machine learning algorithms such as Decision tree (Ng and Cardie,2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. Meanwhile, the CoNLL-2011 shared task on English language show that a well-designed rule-based approach can achieve a comparable performance as a statistical one (Pradhan et al, 2011). $$$$$ We would like to thank all the participants.

This paper describes the coreference resolution system used by Stanford at the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ Having a standard test set and evaluation parameters, all based on a new resource that provides multiple integrated annotation layers (parses, semantic roles, word senses, named entities and coreference) that could support joint models, should help to energize ongoing research in the task of entity and event coreference.
This paper describes the coreference resolution system used by Stanford at the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ OntoNotes provides a large-scale corpus of general anaphoric coreference not restricted to noun phrases or to a specified set of entity types.
This paper describes the coreference resolution system used by Stanford at the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ The sub-spans are not included separately in the IDENT chain.

This was the official metric in the CoNLL-2011 shared task (Pradhan et al2011). We followed the CoNLL-2011 evaluation methodology, that is, we removed all singleton clusters, and apposition/copular relations before scoring. We evaluated the systems on three different settings $$$$$ Many different algorithms have been tried in the past 15 years, but one thing that is still lacking is a corpus comprehensively tagged on a large scale with consistent, multiple layers of semantic information.
This was the official metric in the CoNLL-2011 shared task (Pradhan et al2011). We followed the CoNLL-2011 evaluation methodology, that is, we removed all singleton clusters, and apposition/copular relations before scoring. We evaluated the systems on three different settings $$$$$ The top-performing system (lee) had a score of 57.79 which is about 1.8 points higher than that of the second (sapena) and third (chang) ranking systems, which scored 55.99 and 55.96 respectively.
This was the official metric in the CoNLL-2011 shared task (Pradhan et al2011). We followed the CoNLL-2011 evaluation methodology, that is, we removed all singleton clusters, and apposition/copular relations before scoring. We evaluated the systems on three different settings $$$$$ OntoNotes also provides additional layers of integrated annotation, capturing additional shallow semantic structure.
This was the official metric in the CoNLL-2011 shared task (Pradhan et al2011). We followed the CoNLL-2011 evaluation methodology, that is, we removed all singleton clusters, and apposition/copular relations before scoring. We evaluated the systems on three different settings $$$$$ Annotators were allowed to use knowledge from outside the text in resolving these cases.

While models other than mention-pair have been proposed (Culotta et al, 2007), none performs clearly better as evidenced by recent shared evaluations such as SemEval 2010 (Recasens et al, 2010) and CoNLL 2011 (Pradhan et al, 2011). $$$$$ We would also like to thank the Linguistic Data Consortium for making the OntoNotes 4.0 corpus freely and timely available to the participants.
While models other than mention-pair have been proposed (Culotta et al, 2007), none performs clearly better as evidenced by recent shared evaluations such as SemEval 2010 (Recasens et al, 2010) and CoNLL 2011 (Pradhan et al, 2011). $$$$$ This should facilitate the creation of cross-layer features in integrated predictive models that will make use of these annotations.
While models other than mention-pair have been proposed (Culotta et al, 2007), none performs clearly better as evidenced by recent shared evaluations such as SemEval 2010 (Recasens et al, 2010) and CoNLL 2011 (Pradhan et al, 2011). $$$$$ The following represent our conclusions on reviewing the results: • Perhaps the most surprising finding was that the best-performing system (lee) was completely rule-based, rather than trained.
While models other than mention-pair have been proposed (Culotta et al, 2007), none performs clearly better as evidenced by recent shared evaluations such as SemEval 2010 (Recasens et al, 2010) and CoNLL 2011 (Pradhan et al, 2011). $$$$$ As one of its layers, it has created a corpus for general anaphoric coreference that covers entities and events not limited to noun phrases or a limited set of entity types.

We applied this solver to the closed track of the CoNLL 2011 shared task (Pradhan et al,2011). $$$$$ Corpora to support supervised learning of this task date back to the Message Understanding Conferences (MUC).
We applied this solver to the closed track of the CoNLL 2011 shared task (Pradhan et al,2011). $$$$$ These corpora were tagged with coreferring entities identified by noun phrases in the text.
We applied this solver to the closed track of the CoNLL 2011 shared task (Pradhan et al,2011). $$$$$ Thus in the examples below, FBI can be coreferenced to other mentions, but U.S. cannot.
We applied this solver to the closed track of the CoNLL 2011 shared task (Pradhan et al,2011). $$$$$ U.S.S.R. or U.S.). are also considered adjectival.

This task (Pradhan et al, 2011) has set a harder challenge by only considering exact matches to be correct. $$$$$ The OntoNotes project has created a corpus of largescale, accurate, and integrated annotation of multiple levels of the shallow semantic structure in text.
This task (Pradhan et al, 2011) has set a harder challenge by only considering exact matches to be correct. $$$$$ A systematic study was then conducted using decision trees by Soon et al. (2001).
This task (Pradhan et al, 2011) has set a harder challenge by only considering exact matches to be correct. $$$$$ The following represent our conclusions on reviewing the results: • Perhaps the most surprising finding was that the best-performing system (lee) was completely rule-based, rather than trained.
This task (Pradhan et al, 2011) has set a harder challenge by only considering exact matches to be correct. $$$$$ Most systems represented the markable mentions internally in terms of the parse tree NP constituent span, but some systems used shared attribute models, where the attributes of the merged entity are determined collectively by heuristically merging the attribute types and values of the different constituent mentions.

In this paper, we present a learning approach to coreference resolution of named entities (NE), pronouns (PRP), noun phrases (NP) in unrestricted text according to the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ However, such multi-layer annotations, with complex, cross-layer dependencies, demands a robust, efficient, scalable mechanism for storing them while providing efficient, convenient, integrated access to the the underlying structure.
In this paper, we present a learning approach to coreference resolution of named entities (NE), pronouns (PRP), noun phrases (NP) in unrestricted text according to the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ Emili Sapena, who graciously allowed the use of his scorer implementation, and made available enhancements and immediately fixed issues that were uncovered during the evaluation.
In this paper, we present a learning approach to coreference resolution of named entities (NE), pronouns (PRP), noun phrases (NP) in unrestricted text according to the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ The CoNLL-2011 shared task involved predicting coreference using OntoNotes data.
In this paper, we present a learning approach to coreference resolution of named entities (NE), pronouns (PRP), noun phrases (NP) in unrestricted text according to the CoNLL-2011 shared task (Pradhan et al, 2011). $$$$$ OntoNotes comprises the following layers of annotation:
