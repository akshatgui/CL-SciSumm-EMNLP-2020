Next, it looks promising to try to estimate the dictionary word frequencies using a search engine instead of text corpus, as proposed by Lapata and Keller (2004). $$$$$ The task is to infer which word in a confusion set is the correct one in a given context.
Next, it looks promising to try to estimate the dictionary word frequencies using a search engine instead of text corpus, as proposed by Lapata and Keller (2004). $$$$$ His results showed that a memory-based classifier that uses morphological information as well as positional probabilities as features outperforms all other methods (see Table 7).
Next, it looks promising to try to estimate the dictionary word frequencies using a search engine instead of text corpus, as proposed by Lapata and Keller (2004). $$$$$ We argue that web-based models should therefore be used as a baseline for, rather than an alternative to, standard models.

Lapata and Keller (2004) uses the number of page hits as the web-count of the queried n gram (which is problematic according to Kilgarriff (2007)). $$$$$ All queries (other than the ones using the NEAR operator) were performed as exact matches (using quotation marks in Altavista).
Lapata and Keller (2004) uses the number of page hits as the web-count of the queried n gram (which is problematic according to Kilgarriff (2007)). $$$$$ To compensate for this, Shaw and Hatzivassiloglou (1999) propose to compute the transitive closure of the ordering relation: if a � c and c � b, then a � b. Malouf (2000) further proposes a back-off bigram model of adjective pairs for choosing among alternative orders (P((a,b) {a,b}) vs. P((b,a) {a,b})).
Lapata and Keller (2004) uses the number of page hits as the web-count of the queried n gram (which is problematic according to Kilgarriff (2007)). $$$$$ The ordering of prenominal modifiers is important for natural language generation systems where the text must be both fluent and grammatical.
Lapata and Keller (2004) uses the number of page hits as the web-count of the queried n gram (which is problematic according to Kilgarriff (2007)). $$$$$ In English, nouns are typically either countable (e.g., one dog, two dogs) or uncountable (e.g., some peace, *one peace, *two peaces).

While it is possible to exploit search engine queries for various NLP tasks (Lapata and Keller, 2004), for applications which use corpora as unsupervised training material downloadable base data is essential. $$$$$ Sometimes the search engine fails to return a hit for a given n-gram (for any of its morphological variants).
While it is possible to exploit search engine queries for various NLP tasks (Lapata and Keller, 2004), for applications which use corpora as unsupervised training material downloadable base data is essential. $$$$$ We devised unsupervised models for the countability learning task and evaluated their performance on Baldwin and Bond’s (2003) test data.
While it is possible to exploit search engine queries for various NLP tasks (Lapata and Keller, 2004), for applications which use corpora as unsupervised training material downloadable base data is essential. $$$$$ We devised unsupervised models for the countability learning task and evaluated their performance on Baldwin and Bond’s (2003) test data.
While it is possible to exploit search engine queries for various NLP tasks (Lapata and Keller, 2004), for applications which use corpora as unsupervised training material downloadable base data is essential. $$$$$ However, they do not demonstrate that realistic NLP tasks can benefit from web counts.

This approach has been shown to be particularly effective over web data, where the sheer size of the data precludes the possibility of linguistic preprocessing but at the same time ameliorates the effects of data sparseness inherent in any lexicalised DLA approach (Lapata and Keller, 2004). $$$$$ The web baseline indicates how much can be achieved with a simple, unsupervised model based on n-grams with access to a huge data set.
This approach has been shown to be particularly effective over web data, where the sheer size of the data precludes the possibility of linguistic preprocessing but at the same time ameliorates the effects of data sparseness inherent in any lexicalised DLA approach (Lapata and Keller, 2004). $$$$$ This paper aims to address these questions.
This approach has been shown to be particularly effective over web data, where the sheer size of the data precludes the possibility of linguistic preprocessing but at the same time ameliorates the effects of data sparseness inherent in any lexicalised DLA approach (Lapata and Keller, 2004). $$$$$ However, in most cases, web-based models fail to outperform more sophisticated state-of-theart models trained on small corpora.
This approach has been shown to be particularly effective over web data, where the sheer size of the data precludes the possibility of linguistic preprocessing but at the same time ameliorates the effects of data sparseness inherent in any lexicalised DLA approach (Lapata and Keller, 2004). $$$$$ Then we investigate the generality of the web-based approach by applying it to a range of analysis and generations tasks, involving both syntactic and semantic knowledge: (c) ordering of prenominal adjectives, (d) compound noun bracketing, (e) compound noun interpretation, and (f) noun countability detection.

Lapata and Keller (2004) first used web-based co-occurrence counts for the bracketing of NCs. $$$$$ Three different types of queries were used for the NLP tasks in the present paper: Literal queries use the quoted n-gram directly as a search term for Altavista (e.g., the bigram history changes expands to the query &quot;history changes&quot;).
Lapata and Keller (2004) first used web-based co-occurrence counts for the bracketing of NCs. $$$$$ Co-occurrence frequencies were estimated from the web using inflected queries (see Section 2).
Lapata and Keller (2004) first used web-based co-occurrence counts for the bracketing of NCs. $$$$$ The comparison with the literature shows that both the Altavista and the BNC model perform significantly worse than the best model proposed by Baldwin and Bond (2003); this is a supervised model that uses many more features than just singular/plural frequency and det-noun frequency.
Lapata and Keller (2004) first used web-based co-occurrence counts for the bracketing of NCs. $$$$$ However, in most cases, web-based models fail to outperform more sophisticated state-of-theart models trained on small corpora.

Aside from counting bigrams, various tasks are attainable using web based models: spelling correction, adjective ordering, compound noun bracketing, countability detection, and so on (Lapata and Keller, 2004). $$$$$ Context-sensitive spelling correction is the task of correcting spelling errors that result in valid words.
Aside from counting bigrams, various tasks are attainable using web based models: spelling correction, adjective ordering, compound noun bracketing, countability detection, and so on (Lapata and Keller, 2004). $$$$$ Another important question is whether web-based methods, which are by definition unsupervised, can be competitive alternatives to supervised approaches used for most tasks in the literature.
Aside from counting bigrams, various tasks are attainable using web based models: spelling correction, adjective ordering, compound noun bracketing, countability detection, and so on (Lapata and Keller, 2004). $$$$$ He uses a probability ratio to compare the probability of the leftbranching analysis to that of the right-branching (see (4) for the dependency model and (5) for the adjacency model).

Therefore, it can be used easily as a baseline, as suggested by (Lapata and Keller, 2004). $$$$$ Previous work demonstrated that web counts can be used to approximate bigram frequencies, and thus should be useful for a wide variety of NLP tasks.
Therefore, it can be used easily as a baseline, as suggested by (Lapata and Keller, 2004). $$$$$ Sometimes the search engine fails to return a hit for a given n-gram (for any of its morphological variants).
Therefore, it can be used easily as a baseline, as suggested by (Lapata and Keller, 2004). $$$$$ However, in most cases, web-based models fail to outperform more sophisticated state-of-theart models trained on small corpora.
Therefore, it can be used easily as a baseline, as suggested by (Lapata and Keller, 2004). $$$$$ As shown in Table 10, the best performance was obtained using the web-based trigram model (f(n1, p,n2)); it significantly outperformed the best BNC model.

The results are compared against two state of the art approaches: a supervised machine learning model, Semantic Scattering (Moldovan and Badulescu, 2005), and a web based probabilistic model (Lapata and Keller, 2004). $$$$$ Instead, they focus on specific syntactic relations.
The results are compared against two state of the art approaches: a supervised machine learning model, Semantic Scattering (Moldovan and Badulescu, 2005), and a web based probabilistic model (Lapata and Keller, 2004). $$$$$ This result is consistent with Keller and Lapata’s (2003) findings that the web yields better counts than the BNC.

More recently, (Lapata and Keller, 2004) showed that simple unsupervised models perform significantly better when the frequencies are obtained from the web, rather than from a large standard corpus. $$$$$ If a query consists of a single, highly frequent word (such as the), Altavista will return an error message.
More recently, (Lapata and Keller, 2004) showed that simple unsupervised models perform significantly better when the frequencies are obtained from the web, rather than from a large standard corpus. $$$$$ Such a spelling error is illustrated in (4) where principal was typed when principle was intended.
More recently, (Lapata and Keller, 2004) showed that simple unsupervised models perform significantly better when the frequencies are obtained from the web, rather than from a large standard corpus. $$$$$ The majority of proposals are symbolic and therefore limited to a specific domain due to the large effort involved in hand-coding semantic information (see Lauer 1995 for an extensive overview).
More recently, (Lapata and Keller, 2004) showed that simple unsupervised models perform significantly better when the frequencies are obtained from the web, rather than from a large standard corpus. $$$$$ We compare this model both against a baseline (same model, but parameters estimated on the BNC) and against state-of-the-art models from the literature, which are either supervised (i.e., use annotated training data) or unsupervised but rely on taxonomies to recreate missing counts.

We have experimented with the support vector machines (SVM) model and compared the results against two state-of-the-art models: a supervised model, Semantic Scattering (SS), (Moldovan and Badulescu, 2005), and a web-based unsupervised model (Lapata and Keller, 2004). $$$$$ He observes that this approach suffers from an acute data sparseness problem and goes on to obtain counts for candidate compounds through web searches, thus achieving a translation accuracy of 86–87%.
We have experimented with the support vector machines (SVM) model and compared the results against two state-of-the-art models: a supervised model, Semantic Scattering (SS), (Moldovan and Badulescu, 2005), and a web-based unsupervised model (Lapata and Keller, 2004). $$$$$ We used the same 263,838 adjective pairs that Malouf extracted from the BNC.

(Lapata and Keller, 2004)'s web-based unsupervised model classifies noun noun instances based on Lauer's list of 8 prepositions and uses the web as training corpus. $$$$$ This holds for both the high and low ambiguity data sets.
(Lapata and Keller, 2004)'s web-based unsupervised model classifies noun noun instances based on Lauer's list of 8 prepositions and uses the web as training corpus. $$$$$ The simplest model of compound noun disambiguation compares the frequencies of the two competing analyses and opts for the most frequent one (Pustejovsky et al., 1993).
(Lapata and Keller, 2004)'s web-based unsupervised model classifies noun noun instances based on Lauer's list of 8 prepositions and uses the web as training corpus. $$$$$ Rather, in our opinion, web-based models should be used as a new baseline for NLP tasks.

Although (Lapata and Keller, 2004) used Altavista in their experiments, they showed there is almost no difference between the correlations achieved using Google and Altavista counts. $$$$$ Malouf (2000) extracted 263,838 individual pairs of adjectives from the BNC which he randomly partitioned into test (10%) and training data (90%) and evaluated all the above methods for ordering prenominal adjectives.
Although (Lapata and Keller, 2004) used Altavista in their experiments, they showed there is almost no difference between the correlations achieved using Google and Altavista counts. $$$$$ An average accuracy of 81.50% was obtained.
Although (Lapata and Keller, 2004) used Altavista in their experiments, they showed there is almost no difference between the correlations achieved using Google and Altavista counts. $$$$$ Another possibility that needs further investigation is the combination of web-based models with supervised methods.

They then later propose using Web counts as a baseline unsupervised method for many NLP tasks (Lapata and Keller, 2004). $$$$$ Four models were tested: (a) compare the frequency of the singular and plural forms of the noun; (b) compare the frequency of determiner-noun pairs that are characteristic of countable or uncountable nouns; the determiners used were many for countable and much for uncountable ones; (c) same as model (b), but the det-noun frequencies are normalized by the frequency of the noun; (d) backoff: try to make a decision using det-noun frequencies; if these are too sparse, back off to singular/plural frequencies.
They then later propose using Web counts as a baseline unsupervised method for many NLP tasks (Lapata and Keller, 2004). $$$$$ The estimation ofprobabilities over concepts (rather than words) reduces the number of model parameters and effectively decreases the amount of training data required.
They then later propose using Web counts as a baseline unsupervised method for many NLP tasks (Lapata and Keller, 2004). $$$$$ We used the same test set (2056 tokens from the Brown corpus) and confusion sets as Golding and Schabes (1996), Mangu and Brill (1997), and Cucerzan and Yarowsky (2002).

Lapata and Keller (2004) achieved their best accuracy (78.68%) with the dependency model and the simple symmetric score #(wi ,wj). $$$$$ The best Altavista model is the conditional det-noun model (f (det,n)/f (n)), which achieves 88.38% on countable and 91.22% on uncountable nouns.
Lapata and Keller (2004) achieved their best accuracy (78.68%) with the dependency model and the simple symmetric score #(wi ,wj). $$$$$ Web counts were retrieved for all possible verb-object translations; the most likely one was selected using either co-occurrence frequency (f(v,n)) or conditional probability (f (v,n)/f (n)).
Lapata and Keller (2004) achieved their best accuracy (78.68%) with the dependency model and the simple symmetric score #(wi ,wj). $$$$$ This was achieved by using the gold standard data set from the literature for a given task and randomly dividing it into a development set and a test set (of equal size).

This is confirmed by the adjacency model experiments in (Lapata and Keller, 2004) on Lauer's NC set. $$$$$ This was achieved by using the gold standard data set from the literature for a given task and randomly dividing it into a development set and a test set (of equal size).
This is confirmed by the adjacency model experiments in (Lapata and Keller, 2004) on Lauer's NC set. $$$$$ This paper aims to address these questions.
This is confirmed by the adjacency model experiments in (Lapata and Keller, 2004) on Lauer's NC set. $$$$$ The present paper investigates if these results generalize to tasks covering both syntax and semantics, both generation and analysis, and a larger of For the majority of tasks, we find that simple, unsupervised models perform when frequencies are obtained from the web rather than from a large corpus.

Lapata and Keller (2004) derived their statistics from the Web and achieved results close to Lauer's using simple lexical models. $$$$$ We argue that web-based models should therefore be used as a baseline for, rather than an alternative to, standard models.
Lapata and Keller (2004) derived their statistics from the Web and achieved results close to Lauer's using simple lexical models. $$$$$ The BNC-based models perform consistently worse than the web-based models with the exception of f(t,w1)/t; the best Altavista model performs significantly better than the best BNC model.
Lapata and Keller (2004) derived their statistics from the Web and achieved results close to Lauer's using simple lexical models. $$$$$ So far, only two generation tasks (candidate selection for machine translation and confusion-set disambiguation) have been tested using web-scale data sets.
Lapata and Keller (2004) derived their statistics from the Web and achieved results close to Lauer's using simple lexical models. $$$$$ Prescher et al. (2000) concentrate on verbs and their objects.

Table 3 compares our results to those of Lauer (1995) and of Lapata and Keller (2004). $$$$$ The task is to infer which word in a confusion set is the correct one in a given context.
Table 3 compares our results to those of Lauer (1995) and of Lapata and Keller (2004). $$$$$ Web counts were obtained by submitting literal queries to Altavista (see Section 2).
Table 3 compares our results to those of Lauer (1995) and of Lapata and Keller (2004). $$$$$ Such a spelling error is illustrated in (4) where principal was typed when principle was intended.
Table 3 compares our results to those of Lauer (1995) and of Lapata and Keller (2004). $$$$$ The ordering of prenominal adjectives has sparked a great deal of theoretical debate (see Shaw and Hatzivassiloglou 1999 for an overview) and efforts have concentrated on defining rules based on semantic criteria that account for different orders (e.g., age � color, value � dimension).

We have extended and improved upon the state-of-the-art approaches to NC bracketing using an unsupervised method that is more robust than Lauer (1995) and more accurate than Lapata and Keller (2004). $$$$$ The present paper investigates if these results generalize to tasks covering both syntax and semantics, both generation and analysis, and a larger of For the majority of tasks, we find that simple, unsupervised models perform when frequencies are obtained from the web rather than from a large corpus.
We have extended and improved upon the state-of-the-art approaches to NC bracketing using an unsupervised method that is more robust than Lauer (1995) and more accurate than Lapata and Keller (2004). $$$$$ Our results therefore indicate that large data sets such as those obtained from the web are not the panacea that they are claimed to be (at least implicitly) by authors such as Grefenstette (1998) and Keller and Lapata (2003).

 $$$$$ The reason for this seems to be that the web is much larger than the BNC (about 1000 times); the size seems to compensate for the fact that simple heuristics were used to obtain web counts, and for the noise inherent in web data.
 $$$$$ All queries (other than the ones using the NEAR operator) were performed as exact matches (using quotation marks in Altavista).
 $$$$$ As shown in Table 10, the best performance was obtained using the web-based trigram model (f(n1, p,n2)); it significantly outperformed the best BNC model.

The vast size of the Web has been demonstrated to combat the data sparseness problem, for example, in Lapata and Keller (2004). $$$$$ The semantic fit between a verb and its argument is modeled using a class-based lexicon that is derived from unlabeled data using the expectation maximization algorithm (verb-argument model).
The vast size of the Web has been demonstrated to combat the data sparseness problem, for example, in Lapata and Keller (2004). $$$$$ The reason for this seems to be that the web is much larger than the BNC (about 1000 times); the size seems to compensate for the fact that simple heuristics were used to obtain web counts, and for the noise inherent in web data.
The vast size of the Web has been demonstrated to combat the data sparseness problem, for example, in Lapata and Keller (2004). $$$$$ Another possibility that needs further investigation is the combination of web-based models with supervised methods.
The vast size of the Web has been demonstrated to combat the data sparseness problem, for example, in Lapata and Keller (2004). $$$$$ Table 13 shows that both the Altavista model and BNC model significantly outperform the baseline (relative frequency of the majority class on the gold-standard data).
