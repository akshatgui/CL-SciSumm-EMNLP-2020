Minipar outputs dependency trees (Lin, 1999) from the input sentences. $$$$$ Furthermore, such a threshold does not take into account the fact that with different frequency counts, we have different levels confidence in the mutual information values.
Minipar outputs dependency trees (Lin, 1999) from the input sentences. $$$$$ MIT Press.
Minipar outputs dependency trees (Lin, 1999) from the input sentences. $$$$$ In machine translation, word-for-word translation of non-compositional expressions can result in very misleading (sometimes laughable) translations.

Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSA to distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ However, many collocations resulted from systematic parser errors also tend to posses this property.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSA to distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ The method is based on the assumption that non-compositional phrases have a significantly different mutual information value than the phrases that are similar to their literal meanings.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSA to distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ Our experiment shows that this hypothesis is generally true.

Dekang Lin proposes a way to automatically identify the noncompositionality of MWEs (Lin, 1999). $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.
Dekang Lin proposes a way to automatically identify the noncompositionality of MWEs (Lin, 1999). $$$$$ In fact, the difference of mutual information values appear to be more important to the phrasal similarity than the similarity of individual words.
Dekang Lin proposes a way to automatically identify the noncompositionality of MWEs (Lin, 1999). $$$$$ For example, an underlying assumption in some word sense disambiguation systems, e.g., (Dagan and Itai, 1994; Li et al., 1995; Lin, 1997), is that if two words occurred in the same context, they are probably similar.

Least mutual information difference with similar collocations $$$$$ Our method is based on the hypothesis that when a phrase is non-composition, its mutual information differs significantly from the mutual informations of phrases obtained by substituting one of the word in the phrase with a similar word.
Least mutual information difference with similar collocations $$$$$ Our experiment shows that this hypothesis is generally true.
Least mutual information difference with similar collocations $$$$$ Non-compositional expressions present a special challenge to NLP applications.
Least mutual information difference with similar collocations $$$$$ For example, an underlying assumption in some word sense disambiguation systems, e.g., (Dagan and Itai, 1994; Li et al., 1995; Lin, 1997), is that if two words occurred in the same context, they are probably similar.

Lin (1999) gave a corpus-based method for finding various types of non-compositional phrases, including the sort discussed in this paper. $$$$$ Our method is based on the hypothesis that when a phrase is non-composition, its mutual information differs significantly from the mutual informations of phrases obtained by substituting one of the word in the phrase with a similar word.
Lin (1999) gave a corpus-based method for finding various types of non-compositional phrases, including the sort discussed in this paper. $$$$$ The top-10 most similar words are: economic: financial 0.305, political 0.243, social 0.219, fiscal 0.209, cultural 0.202, budgetary 0.2, technological 0.196, organizational 0.19, ecological 0.189, monetary 0.189; impact: effect 0.227, implication 0.163, consequence 0.156, significance 0.146, repercussion 0.141, fallout 0.141, potential 0.137, ramification 0.129, risk 0.126, influence 0.125; The frequency counts and mutual information values of &quot;economic impact&quot; and phrases obtained by replacing one of &quot;economic&quot; and &quot;impact&quot; with a similar word are in Table 4.

Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutual information measures identify such phrases, Bald win et al (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moiro and Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. $$$$$ More details about the construction of the collocation database and the thesaurus can be found in (Lin, 1998).
Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutual information measures identify such phrases, Bald win et al (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moiro and Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. $$$$$ Our experiment shows that this hypothesis is generally true.
Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutual information measures identify such phrases, Bald win et al (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moiro and Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. $$$$$ The `---' sign means that the verb-object pair is present in our dependency database, but it does not satisfy condition (3).
Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutual information measures identify such phrases, Bald win et al (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moiro and Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. $$$$$ For example, To compute the mutual information in a collocation, we treat a collocation (head type modifier) as the conjunction of three events: The mutual information of a collocation is the logarithm of the ratio between the probability of the collocation and the probability of events A, B, and C co-occur if we assume B and C are conditionally independent given A: d type modifierlxl* type * = l og( I \ pe *Ixl* type modifier')

Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ However, many collocations resulted from systematic parser errors also tend to posses this property.
Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ The confidence interval for the true probability gives rise to a confidence interval for the true mutual information (mutual information computed using the true probabilities instead of estimations).
Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ Non-compositional expressions present a special challenge to NLP applications.
Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ Not only many combinations are found in the corpus, many of them have very similar mutual information values to that of nomial distribution can be accurately approximated by a normal distribution (Dunning, 1993).

Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ Non-compositional expressions present a special challenge to NLP applications.
Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ Let 'head type modifierj = k and 1* * *1 = n. The maximum likelihood estimation of the true probability p of the collocation (head type modifier) is = k -n .
Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ We compared the collocations in Appendix A with the entries for the above 10 words in the NTC's English Idioms Dictionary (henceforth NTC-EID) (Spears and Kirkpatrick, 1993), which contains approximately 6000 definitions of idioms.
Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ We use is ft 14I to denote the frequency count of all the collocations that match the pattern (H R M), where H and M are either words or the wild card (*) and R is either a dependency type or the wild card.

Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants. $$$$$ Although one could simply use a predetermined threshold for this purpose, the threshold value will be totally arbitrary.
Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants. $$$$$ Although one could simply use a predetermined threshold for this purpose, the threshold value will be totally arbitrary.
Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants. $$$$$ We aggregated all word pairs that occurred within a 4-word window of each other.
Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants. $$$$$ We have presented a method to identify noncompositional phrases.

Lin (1999) and Wermter and Hahn (2005) go one step further and look into a linguistic property of non-compositional compounds their lexical fixedness to identify them. $$$$$ Automated discovery of wordnet relations.
Lin (1999) and Wermter and Hahn (2005) go one step further and look into a linguistic property of non-compositional compounds their lexical fixedness to identify them. $$$$$ Mutual information has often been used to separate systematic associations from accidental ones.

 $$$$$ When the frequency count is reasonably large (e.g., greater than 5), a biN% 50% 80% 90% 95% 98% 99% ZN 0.67 1.28 1.64 1.96 2.33 2.58 We further assume that the estimations of P(A), P(BIA) and P(CIA) in (2) are accurate.
 $$$$$ The author wishes to thank ACL reviewers for their helpful comments and suggestions.
 $$$$$ Furthermore, such a threshold does not take into account the fact that with different frequency counts, we have different levels confidence in the mutual information values.
 $$$$$ Ted Dunning.

Later work such as by Lin (1999) continued this tradition. $$$$$ This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338.
Later work such as by Lin (1999) continued this tradition. $$$$$ Non-compositional expressions present a special challenge to NLP applications.
Later work such as by Lin (1999) continued this tradition. $$$$$ Non-compositional expressions present a special challenge to NLP applications.

This is also the place where linguistic constraints can be applied, say to avoid non compositional phrases (Lin, 1999). $$$$$ For example, To compute the mutual information in a collocation, we treat a collocation (head type modifier) as the conjunction of three events: The mutual information of a collocation is the logarithm of the ratio between the probability of the collocation and the probability of events A, B, and C co-occur if we assume B and C are conditionally independent given A: d type modifierlxl* type * = l og( I \ pe *Ixl* type modifier')
This is also the place where linguistic constraints can be applied, say to avoid non compositional phrases (Lin, 1999). $$$$$ This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338.
This is also the place where linguistic constraints can be applied, say to avoid non compositional phrases (Lin, 1999). $$$$$ In machine translation, word-for-word translation of non-compositional expressions can result in very misleading (sometimes laughable) translations.

Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ For example, &quot;finish seventh&quot; is not found because &quot;seventh&quot; is normalized as &quot;..NUM&quot;, &quot;have a go&quot; is not found because &quot;a go&quot; is not an entry in our lexicon, and &quot;take advantage&quot; is not found because &quot;take advantage of&quot; is treated as a single lexical item by our parser.
Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ We parsed a 125-million word newspaper corpus with Minipar,1 a descendent of Principar (Lin, 1993; Lin, 1994), and extracted dependency relationships from the parsed corpus.
Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ Computational Linguistics, 19(1):61-74, March.
Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ The `---' sign means that the verb-object pair is present in our dependency database, but it does not satisfy condition (3).

To protect against that problem, we compute the 99.99999% confidence intervals around the PMI (Lin, 1999), and use the lower bound as a measure of association. $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.
To protect against that problem, we compute the 99.99999% confidence intervals around the PMI (Lin, 1999), and use the lower bound as a measure of association. $$$$$ For example, (la) is an example dependency tree and the set of dependency triples extracted from (la) are shown in (lb).

These properties can be used to identify potential idioms, for instance, by employing measures of association strength between the elements of an expression (Lin, 1999). $$$$$ However, many collocations resulted from systematic parser errors also tend to posses this property.
These properties can be used to identify potential idioms, for instance, by employing measures of association strength between the elements of an expression (Lin, 1999). $$$$$ Our method is based on the hypothesis that when a phrase is non-composition, its mutual information differs significantly from the mutual informations of phrases obtained by substituting one of the word in the phrase with a similar word.

Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ We define the probability space to consist of all possible collocation triples.
Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ We have presented a method to identify noncompositional phrases.
Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ The confidence interval for the true probability gives rise to a confidence interval for the true mutual information (mutual information computed using the true probabilities instead of estimations).
Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ However, this method fails when non-compositional expressions are involved.

 $$$$$ However, many collocations resulted from systematic parser errors also tend to posses this property.
 $$$$$ Our experiment shows that this hypothesis is generally true.
 $$$$$ For example, To compute the mutual information in a collocation, we treat a collocation (head type modifier) as the conjunction of three events: The mutual information of a collocation is the logarithm of the ratio between the probability of the collocation and the probability of events A, B, and C co-occur if we assume B and C are conditionally independent given A: d type modifierlxl* type * = l og( I \ pe *Ixl* type modifier')
 $$$$$ The ones marked with '+' sign are found in NTC-EID.

Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ The lexical analyzer in the parser analyzed &quot;trigger&quot; as the -er form of the adjective &quot;trig&quot; (meaning wellgroomed).
Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ For example, To compute the mutual information in a collocation, we treat a collocation (head type modifier) as the conjunction of three events: The mutual information of a collocation is the logarithm of the ratio between the probability of the collocation and the probability of events A, B, and C co-occur if we assume B and C are conditionally independent given A: d type modifierlxl* type * = l og( I \ pe *Ixl* type modifier')
Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ We parsed a 125-million word newspaper corpus with Minipar,1 a descendent of Principar (Lin, 1993; Lin, 1994), and extracted dependency relationships from the parsed corpus.
Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ We call a dependency relationship a collocation if its log-likelihood ratio is greater than a threshold (0.5).

We propose a new method that compares phrases with their alternative phrases, in the spirit of Lin (1999)'s substitution approach (see Section 4.3). $$$$$ Non-compositional expressions present a special challenge to NLP applications.
We propose a new method that compares phrases with their alternative phrases, in the spirit of Lin (1999)'s substitution approach (see Section 4.3). $$$$$ We use is ft 14I to denote the frequency count of all the collocations that match the pattern (H R M), where H and M are either words or the wild card (*) and R is either a dependency type or the wild card.
We propose a new method that compares phrases with their alternative phrases, in the spirit of Lin (1999)'s substitution approach (see Section 4.3). $$$$$ For example, To compute the mutual information in a collocation, we treat a collocation (head type modifier) as the conjunction of three events: The mutual information of a collocation is the logarithm of the ratio between the probability of the collocation and the probability of events A, B, and C co-occur if we assume B and C are conditionally independent given A: d type modifierlxl* type * = l og( I \ pe *Ixl* type modifier')
We propose a new method that compares phrases with their alternative phrases, in the spirit of Lin (1999)'s substitution approach (see Section 4.3). $$$$$ In order to implement the idea of separating noncompositional phrases from compositional ones with mutual information, we must use a criterion to determine whether or not the mutual information values of two collocations are significantly different.
