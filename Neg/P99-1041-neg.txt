Minipar outputs dependency trees (Lin, 1999) from the input sentences. $$$$$ Non-compositional expressions present a special challenge to NLP applications.
Minipar outputs dependency trees (Lin, 1999) from the input sentences. $$$$$ The frequency count of a collocation is a random variable with binomial distribution.
Minipar outputs dependency trees (Lin, 1999) from the input sentences. $$$$$ To find out the benefit of using the dependency relationships identified by a parser instead of simple co-occurrence relationships between words, we also created a database of the co-occurrence relationship between part-of-speech tagged words.
Minipar outputs dependency trees (Lin, 1999) from the input sentences. $$$$$ For example, &quot;take advantage of&quot; is treated as a transitive verb by the parser.

Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSA to distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ Our experiment shows that this hypothesis is generally true.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSA to distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ The input to our algorithm is a collocation database and a thesaurus.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSA to distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ For example, To compute the mutual information in a collocation, we treat a collocation (head type modifier) as the conjunction of three events: The mutual information of a collocation is the logarithm of the ratio between the probability of the collocation and the probability of events A, B, and C co-occur if we assume B and C are conditionally independent given A: d type modifierlxl* type * = l og( I \ pe *Ixl* type modifier')
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSA to distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ We propose a more principled approach.

Dekang Lin proposes a way to automatically identify the noncompositionality of MWEs (Lin, 1999). $$$$$ It is clear that Appendix B contains far fewer true non-compositional phrases than Appendix A.
Dekang Lin proposes a way to automatically identify the noncompositionality of MWEs (Lin, 1999). $$$$$ Mutual information has often been used to separate systematic associations from accidental ones.
Dekang Lin proposes a way to automatically identify the noncompositionality of MWEs (Lin, 1999). $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.

Least mutual information difference with similar collocations: this feature is based on Lin's work (Lin, 1999). $$$$$ There are about 80 million dependency relationships in the parsed corpus.
Least mutual information difference with similar collocations: this feature is based on Lin's work (Lin, 1999). $$$$$ For example, the following table shows the frequency count, mutual information (computed with the most likelihood estimation) and the lower and upper bounds of the 95% confidence interval of the true mutual information: verb-object freq. mutual lower upper count info bound bound make difference 1489 2.928 2.876 2.978 make change 1779 2.194 2.146 2.239 Since the intervals are disjoint, the two collocations are considered to have significantly different mutual information values.
Least mutual information difference with similar collocations: this feature is based on Lin's work (Lin, 1999). $$$$$ Non-compositional expressions present a special challenge to NLP applications.
Least mutual information difference with similar collocations: this feature is based on Lin's work (Lin, 1999). $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.

Lin (1999) gave a corpus-based method for finding various types of non-compositional phrases, including the sort discussed in this paper. $$$$$ We can find other words that are also modified by &quot;hot&quot; (e.g., &quot;hot car&quot;) and then choose the meaning of &quot;product&quot; that is most similar to meanings of these words.
Lin (1999) gave a corpus-based method for finding various types of non-compositional phrases, including the sort discussed in this paper. $$$$$ For example, To compute the mutual information in a collocation, we treat a collocation (head type modifier) as the conjunction of three events: The mutual information of a collocation is the logarithm of the ratio between the probability of the collocation and the probability of events A, B, and C co-occur if we assume B and C are conditionally independent given A: d type modifierlxl* type * = l og( I \ pe *Ixl* type modifier')
Lin (1999) gave a corpus-based method for finding various types of non-compositional phrases, including the sort discussed in this paper. $$$$$ In order to implement the idea of separating noncompositional phrases from compositional ones with mutual information, we must use a criterion to determine whether or not the mutual information values of two collocations are significantly different.

Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutual information measures identify such phrases, Bald win et al (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moiro and Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. $$$$$ For example, &quot;finish seventh&quot; is not found because &quot;seventh&quot; is normalized as &quot;..NUM&quot;, &quot;have a go&quot; is not found because &quot;a go&quot; is not an entry in our lexicon, and &quot;take advantage&quot; is not found because &quot;take advantage of&quot; is treated as a single lexical item by our parser.
Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutual information measures identify such phrases, Bald win et al (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moiro and Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. $$$$$ For each object noun o, (Tapanainen et al., 1998) computes the distributed frequency DF(o) and rank the non-compositionality of o according to this value.
Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutual information measures identify such phrases, Bald win et al (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moiro and Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. $$$$$ We use is ft 14I to denote the frequency count of all the collocations that match the pattern (H R M), where H and M are either words or the wild card (*) and R is either a dependency type or the wild card.

Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ MIT Press.
Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ In Proceedings of the RIAO Conference on User-Oriented Content-Based Text and Image Handling, Cambridge, MA, March 21-24.
Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ We have presented a method to identify noncompositional phrases.
Melamed (1997) and Lin (1999) have done some research on non compositional phrases discovery. $$$$$ Computational Linguistics, 19(1):61-74, March.

Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ For example, the phrases &quot;economic fallout&quot; and &quot;economic repercussion&quot; are intuitively more similar to &quot;economic impact&quot; than &quot;economic implication&quot; or &quot;economic significance&quot;, even though &quot;implication&quot; and &quot;significance&quot; have higher similarity values to &quot;impact&quot; than &quot;fallout&quot; and &quot;repercussion&quot; do.
Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ As a result, the extracted non-compositional phrases do not usually overlap with phrasal entries in the WordNet.
Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ The author wishes to thank ACL reviewers for their helpful comments and suggestions.
Inspired by Lin (1999), we examine the strength of association between the verb and noun constituents of the target combination and its variants, as an indirect cue to their idiomaticity. $$$$$ For example, the following disclaimer occurred 212 times in the corpus.

Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants. $$$$$ The top-10 most similar words to &quot;red&quot; and &quot;tape&quot; in our thesaurus are: red: yellow 0.164, purple 0.149, pink 0.146, green 0.136, blue 0.125, white 0.122, color 0.118, orange 0.111, brown 0.101, shade 0.094; tape: videotape 0.196, cassette 0.177, videocassette 0.168, video 0.151, disk 0.129, recording 0.117, disc 0.113, footage 0.111, recorder 0.106, audio 0.106; The following table shows the frequency and mutual information of &quot;red tape&quot; and word combinations in which one of &quot;red&quot; or &quot;tape&quot; is substituted by a similar word: Even though many other similar combinations exist in the collocation database, they have very different frequency counts and mutual information values than &quot;red tape&quot;.
Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants. $$$$$ The author wishes to thank ACL reviewers for their helpful comments and suggestions.
Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants. $$$$$ For example, &quot;finish seventh&quot; is not found because &quot;seventh&quot; is normalized as &quot;..NUM&quot;, &quot;have a go&quot; is not found because &quot;a go&quot; is not an entry in our lexicon, and &quot;take advantage&quot; is not found because &quot;take advantage of&quot; is treated as a single lexical item by our parser.

Lin (1999) and Wermter and Hahn (2005) go one step further and look into a linguistic property of non-compositional compounds their lexical fixedness to identify them. $$$$$ Non-compositional expressions present a special challenge to NLP applications.
Lin (1999) and Wermter and Hahn (2005) go one step further and look into a linguistic property of non-compositional compounds their lexical fixedness to identify them. $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.
Lin (1999) and Wermter and Hahn (2005) go one step further and look into a linguistic property of non-compositional compounds their lexical fixedness to identify them. $$$$$ Although one could simply use a predetermined threshold for this purpose, the threshold value will be totally arbitrary.
Lin (1999) and Wermter and Hahn (2005) go one step further and look into a linguistic property of non-compositional compounds their lexical fixedness to identify them. $$$$$ Our method is based on the hypothesis that when a phrase is non-composition, its mutual information differs significantly from the mutual informations of phrases obtained by substituting one of the word in the phrase with a similar word.

 $$$$$ For example, an underlying assumption in some word sense disambiguation systems, e.g., (Dagan and Itai, 1994; Li et al., 1995; Lin, 1997), is that if two words occurred in the same context, they are probably similar.
 $$$$$ Y. Chouelca.
 $$$$$ In information retrieval, expansion of words in a non-compositional expression can lead to dramatic decrease in precision without any gain in recall.
 $$$$$ Although one could simply use a predetermined threshold for this purpose, the threshold value will be totally arbitrary.

Later work such as by Lin (1999) continued this tradition. $$$$$ The &quot;mi&quot; column show the result of our mutual information filter.
Later work such as by Lin (1999) continued this tradition. $$$$$ We use the following condition to determine whether or not a collocation is compositional: (3) A collocation a is non-compositional if there does not exist another collocation /3 such that (a) 13 is obtained by substituting the head or the modifier in a with a similar word and (b) there is an overlap between the 95% confidence interval of the mutual information values of a and 0.
Later work such as by Lin (1999) continued this tradition. $$$$$ Although one could simply use a predetermined threshold for this purpose, the threshold value will be totally arbitrary.
Later work such as by Lin (1999) continued this tradition. $$$$$ 1993.

This is also the place where linguistic constraints can be applied, say to avoid non compositional phrases (Lin, 1999). $$$$$ The input to our algorithm is a collocation database and a thesaurus.
This is also the place where linguistic constraints can be applied, say to avoid non compositional phrases (Lin, 1999). $$$$$ Mutual information has often been used to separate systematic associations from accidental ones.
This is also the place where linguistic constraints can be applied, say to avoid non compositional phrases (Lin, 1999). $$$$$ However, many collocations resulted from systematic parser errors also tend to posses this property.
This is also the place where linguistic constraints can be applied, say to avoid non compositional phrases (Lin, 1999). $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.

Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ We call a dependency relationship a collocation if its log-likelihood ratio is greater than a threshold (0.5).
Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338.
Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ The author wishes to thank ACL reviewers for their helpful comments and suggestions.
Second, some n-grams themselves carry no linguistic meaning; their phrase translations can be misleading, for example non-compositional phrases (Lin, 1999). $$$$$ Since our confidence of p falling between/.1/--V-In. is N%, we can have N% confidence that the true mutual information is within the upper and lower bound.

To protect against that problem, we compute the 99.99999% confidence intervals around the PMI (Lin, 1999), and use the lower bound as a measure of association. $$$$$ However, many collocations resulted from systematic parser errors also tend to posses this property.
To protect against that problem, we compute the 99.99999% confidence intervals around the PMI (Lin, 1999), and use the lower bound as a measure of association. $$$$$ We briefly describe the process of obtaining this input.
To protect against that problem, we compute the 99.99999% confidence intervals around the PMI (Lin, 1999), and use the lower bound as a measure of association. $$$$$ Even though we do not know what p is, since p is (assumed to be) normally distributed, there is N% chance that it fails within the interval where zN is a constant related to the confidence level N and the last step in the above derivation is due to the fact that is very small.
To protect against that problem, we compute the 99.99999% confidence intervals around the PMI (Lin, 1999), and use the lower bound as a measure of association. $$$$$ For example, an underlying assumption in some word sense disambiguation systems, e.g., (Dagan and Itai, 1994; Li et al., 1995; Lin, 1997), is that if two words occurred in the same context, they are probably similar.

These properties can be used to identify potential idioms, for instance, by employing measures of association strength between the elements of an expression (Lin, 1999). $$$$$ For example, (la) is an example dependency tree and the set of dependency triples extracted from (la) are shown in (lb).
These properties can be used to identify potential idioms, for instance, by employing measures of association strength between the elements of an expression (Lin, 1999). $$$$$ This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338.
These properties can be used to identify potential idioms, for instance, by employing measures of association strength between the elements of an expression (Lin, 1999). $$$$$ Computational Linguistics, 20(4):563-596.

Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ The top-10 most similar words are: economic: financial 0.305, political 0.243, social 0.219, fiscal 0.209, cultural 0.202, budgetary 0.2, technological 0.196, organizational 0.19, ecological 0.189, monetary 0.189; impact: effect 0.227, implication 0.163, consequence 0.156, significance 0.146, repercussion 0.141, fallout 0.141, potential 0.137, ramification 0.129, risk 0.126, influence 0.125; The frequency counts and mutual information values of &quot;economic impact&quot; and phrases obtained by replacing one of &quot;economic&quot; and &quot;impact&quot; with a similar word are in Table 4.
Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ As a result, the extracted non-compositional phrases do not usually overlap with phrasal entries in the WordNet.
Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.
Lin (1999) argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based NLP methods. $$$$$ There are about 80 million dependency relationships in the parsed corpus.

 $$$$$ In this section, we use several examples to demonstrate the basic idea behind our algorithm.
 $$$$$ Mutual information has often been used to separate systematic associations from accidental ones.
 $$$$$ The top-10 most similar words to &quot;red&quot; and &quot;tape&quot; in our thesaurus are: red: yellow 0.164, purple 0.149, pink 0.146, green 0.136, blue 0.125, white 0.122, color 0.118, orange 0.111, brown 0.101, shade 0.094; tape: videotape 0.196, cassette 0.177, videocassette 0.168, video 0.151, disk 0.129, recording 0.117, disc 0.113, footage 0.111, recorder 0.106, audio 0.106; The following table shows the frequency and mutual information of &quot;red tape&quot; and word combinations in which one of &quot;red&quot; or &quot;tape&quot; is substituted by a similar word: Even though many other similar combinations exist in the collocation database, they have very different frequency counts and mutual information values than &quot;red tape&quot;.
 $$$$$ It was also used to compute the distributional similarity between words (Hindle, 1990; Lin, 1998).

Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ Our method is based on the hypothesis that when a phrase is non-composition, its mutual information differs significantly from the mutual informations of phrases obtained by substituting one of the word in the phrase with a similar word.
Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ We use is ft 14I to denote the frequency count of all the collocations that match the pattern (H R M), where H and M are either words or the wild card (*) and R is either a dependency type or the wild card.
Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ Ido Dagan and Alon Itai.
Lin (1999) defines a decision criterion for non compositional phrases based on the change in the mutual information of a phrase when substituting one word for a similar one based on an automatically constructed thesaurus. $$$$$ Non-compositional expressions present a special challenge to NLP applications.

We propose a new method that compares phrases with their alternative phrases, in the spirit of Lin (1999)'s substitution approach (see Section 4.3). $$$$$ Since our confidence of p falling between/.1/--V-In. is N%, we can have N% confidence that the true mutual information is within the upper and lower bound.
We propose a new method that compares phrases with their alternative phrases, in the spirit of Lin (1999)'s substitution approach (see Section 4.3). $$$$$ We present a method for automatic identification of non-compositional expressions using their statistical properties in a text corpus.
We propose a new method that compares phrases with their alternative phrases, in the spirit of Lin (1999)'s substitution approach (see Section 4.3). $$$$$ Non-compositional expressions present a special challenge to NLP applications.
