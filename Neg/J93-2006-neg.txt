We were already using a generative statistical model for part-of-speech tagging (Weischedel et al 1993). $$$$$ We expect to improve the model's performance by recording probabilities for other features in addition to just the set of rules involved in producing them.
We were already using a generative statistical model for part-of-speech tagging (Weischedel et al 1993). $$$$$ As a second result, we found that adding a context-free probability model improved the unification predictions of syntactic and semantic properties of an unknown word, reducing the error rate by a factor of two compared with no model.

Word features are introduced primarily to help with unknown words, as in (Weischedel et al 1993). $$$$$ This paper reports our experiments in predicting parts of speech of highly ambiguous words, predicting the intended interpretation of an utterance when more than one interpretation satisfies all known syntactic and semantic constraints, and learning case frame information for verbs from example uses.
Word features are introduced primarily to help with unknown words, as in (Weischedel et al 1993). $$$$$ One can similarly use probabilities for assigning semantic structure (Section 4).

Weischedel's group (Weischedel et al, 1993) examines unknown words in the context of part-of-speech tagging. $$$$$ Kupiec, J.
Weischedel's group (Weischedel et al, 1993) examines unknown words in the context of part-of-speech tagging. $$$$$ We could no longer assume a limited vocabulary.
Weischedel's group (Weischedel et al, 1993) examines unknown words in the context of part-of-speech tagging. $$$$$ &quot;Estimation of probabilities from sparse data for the language model component of a speech In Transactions on Acoustics, Speech, and Signal Processing, Vol.

in (Weischedel et al, 1993) where an unknown word was guessed given the probabilities for an unknown word to be of a particular pos, its capitalisation feature and its ending. $$$$$ (1989).
in (Weischedel et al, 1993) where an unknown word was guessed given the probabilities for an unknown word to be of a particular pos, its capitalisation feature and its ending. $$$$$ Assigning a semantic class to a core noun phrase can be handled via some structural rules.
in (Weischedel et al, 1993) where an unknown word was guessed given the probabilities for an unknown word to be of a particular pos, its capitalisation feature and its ending. $$$$$ &quot;A cache-based natural language model for recognition.&quot; In Transactions on Pattern Analysis and Machine Intelligence, 12,570-583.

For words that were unknown in our subtree set, we guessed their categories by means of the method described in Weischedel et al (1993) which uses statistics on word-endings, hyphenation and capitalization. $$$$$ The performance of today's natural language understanding systems is hindered by the following three complementary problems: Our results on problems (1) and (3) above are presented in this section.
For words that were unknown in our subtree set, we guessed their categories by means of the method described in Weischedel et al (1993) which uses statistics on word-endings, hyphenation and capitalization. $$$$$ Based on the results of those experiments, we have constructed a new natural language system (PLUM) for extracting data from text, e.g., newswire text.
For words that were unknown in our subtree set, we guessed their categories by means of the method described in Weischedel et al (1993) which uses statistics on word-endings, hyphenation and capitalization. $$$$$ These required much detailed, handcrafted knowledge from several sources (e.g., acoustic and phonetic).

More recently, the natural language processing community has effectively employed these models for part-of speech tagging, as in the seminal (Church, 1988) and other, more recent efforts (Weischedel et al, 1993). $$$$$ In our tests, the NLP system produces all interpretations satisfying all syntactic and semantic constraints.
More recently, the natural language processing community has effectively employed these models for part-of speech tagging, as in the seminal (Church, 1988) and other, more recent efforts (Weischedel et al, 1993). $$$$$ (1989).
More recently, the natural language processing community has effectively employed these models for part-of speech tagging, as in the seminal (Church, 1988) and other, more recent efforts (Weischedel et al, 1993). $$$$$ However, as we move from the application of understanding database queries in limited domains to applications of processing open-ended text, we found challenges that questioned our previous assumptions and suggested probabilistic models instead.

For words that were unknown in the training set, we guessed their categories by means of the method described in Weischedel et al (1993) which uses statistics on word-endings, hyphenation and capitalization. $$$$$ The first supervised test had an 81.4% improvement, the second a 50.8% improvement, and the third a 56% improvement.
For words that were unknown in the training set, we guessed their categories by means of the method described in Weischedel et al (1993) which uses statistics on word-endings, hyphenation and capitalization. $$$$$ (1989).
For words that were unknown in the training set, we guessed their categories by means of the method described in Weischedel et al (1993) which uses statistics on word-endings, hyphenation and capitalization. $$$$$ Two of our experiments have focused on the identification of core noun phrases, a primary way of expressing entities in text.

More advanced methods like those described by Weischedel et al (1993) incorporate the treatment of unknown words within the probability model. $$$$$ This independence assumption, of course, is not correct.
More advanced methods like those described by Weischedel et al (1993) incorporate the treatment of unknown words within the probability model. $$$$$ From spring 1990 through fall 1991, we performed a battery of small experiments to test the effectiveness of supplementing knowledge-based techniques with probabilistic models.
More advanced methods like those described by Weischedel et al (1993) incorporate the treatment of unknown words within the probability model. $$$$$ From these experiments, we are convinced that probabilistic models based on annotated corpora can effectively reduce the ambiguity in processing text and can be used to acquire lexical information from a corpus, by supplementing knowledge-based techniques.

The output produced is in the tradition of partial parsing (Hindle 1983, McDonald 1992, Weischedel et al 1993) and concentrates on the simple noun phrase. $$$$$ As a second result, we found that adding a context-free probability model improved the unification predictions of syntactic and semantic properties of an unknown word, reducing the error rate by a factor of two compared with no model.
The output produced is in the tradition of partial parsing (Hindle 1983, McDonald 1992, Weischedel et al 1993) and concentrates on the simple noun phrase. $$$$$ From spring 1990 through fall 1991, we performed a battery of small experiments to test the effectiveness of supplementing knowledge-based techniques with probabilistic models.
The output produced is in the tradition of partial parsing (Hindle 1983, McDonald 1992, Weischedel et al 1993) and concentrates on the simple noun phrase. $$$$$ From these experiments, we are convinced that probabilistic models based on annotated corpora can effectively reduce the ambiguity in processing text and can be used to acquire lexical information from a corpus, by supplementing knowledge-based techniques.
The output produced is in the tradition of partial parsing (Hindle 1983, McDonald 1992, Weischedel et al 1993) and concentrates on the simple noun phrase. $$$$$ The probabilistic algorithm is critical to selecting the appropriate generalizations to make from a set of examples.

Weischedel et al (1993) combine several heuristics in order to estimate the token generation prob ability according to various types of information. $$$$$ Katz, S. M. (1987).
Weischedel et al (1993) combine several heuristics in order to estimate the token generation prob ability according to various types of information. $$$$$ When a choice among alternative interpretations produced by a unification-based parser and semantic interpreter must be made, a simple context-free probability model reduced the error rate by a factor of two compared with using no model.
Weischedel et al (1993) combine several heuristics in order to estimate the token generation prob ability according to various types of information. $$$$$ We have developed a novel probabilistic model that takes into account features of the word in determining the likelihood of the word given a part of speech.
Weischedel et al (1993) combine several heuristics in order to estimate the token generation prob ability according to various types of information. $$$$$ Our work is an incremental improvement on these models in three ways: (1) Much less training data than theoretically required proved adequate; (2) we integrated a probabilistic model of word features to handle unknown words uniformly within the probabilistic model and measured its contribution; and (3) we have applied the forwardâ€”backward algorithm to accurately compute the most likely tag set.

In our framework, we employ a simple HMM-based tagger, where the most probable tag sequence, given the words, is out put (Weischedel et al, 1993). $$$$$ This paper reports our experiments in predicting parts of speech of highly ambiguous words, predicting the intended interpretation of an utterance when more than one interpretation satisfies all known syntactic and semantic constraints, and learning case frame information for verbs from example uses.
In our framework, we employ a simple HMM-based tagger, where the most probable tag sequence, given the words, is out put (Weischedel et al, 1993). $$$$$ &quot;Estimation of probabilities from sparse data for the language model component of a speech In Transactions on Acoustics, Speech, and Signal Processing, Vol.
In our framework, we employ a simple HMM-based tagger, where the most probable tag sequence, given the words, is out put (Weischedel et al, 1993). $$$$$ 3.

In addition to the ending, Weischedel et al (1993) exploit capitalisation. $$$$$ ASSP-35 No.
In addition to the ending, Weischedel et al (1993) exploit capitalisation. $$$$$ This paper reports our experiments in predicting parts of speech of highly ambiguous words, predicting the intended interpretation of an utterance when more than one interpretation satisfies all known syntactic and semantic constraints, and learning case frame information for verbs from example uses.
In addition to the ending, Weischedel et al (1993) exploit capitalisation. $$$$$ Using unification variables for all possible features of a noun, the parser produces multiple parses.

 $$$$$ However, the degree of reduction of error rate should not be taken as the final word, for the following reasons: import in the MUC-3 domain, their semantic type is vague, i.e., <unknown event>, <unknown entity>, etc.
 $$$$$ Based on the results of those experiments, we have constructed a new natural language system (PLUM) for extracting data from text, e.g., newswire text.

 $$$$$ Heights, NY.
 $$$$$ In this case, a significant new model synthesizing both semantic and syntactic knowledge is employed.
 $$$$$ Katz, S. M. (1987).

The practice of allowing only open-class tags for unknown words goes back a long way (Weischedel et al, 1993), and proved highly beneficial also in our case. $$$$$ This paper reports our experiments in predicting parts of speech of highly ambiguous words, predicting the intended interpretation of an utterance when more than one interpretation satisfies all known syntactic and semantic constraints, and learning case frame information for verbs from example uses.
The practice of allowing only open-class tags for unknown words goes back a long way (Weischedel et al, 1993), and proved highly beneficial also in our case. $$$$$ In Section 4, we report an experiment in learning case frame information of unknown verbs from examples.
The practice of allowing only open-class tags for unknown words goes back a long way (Weischedel et al, 1993), and proved highly beneficial also in our case. $$$$$ &quot;Augmenting a hidden Markov model for phrase-dependent tagging.&quot; In Speech and Language Workshop.
The practice of allowing only open-class tags for unknown words goes back a long way (Weischedel et al, 1993), and proved highly beneficial also in our case. $$$$$ At the level of syntax (Section 3), an event is the use of a particular structure; the model predicts what the most likely rule is given a particular situation.
