Of the several slightly different definitions of a base NP in the literature we use for the purposes of this work the definition presented in (Ramshaw and Marcus, 1995) and used also by (Argamon et al, 1998) and others. $$$$$ The authors wish to thank Yoram Singer for his collaboration in an earlier phase of this research project, and Giorgio Satta for helpful discussions.

SV phrases, following the definition suggested in (Argamon et al, 1998), are word phrases starting with the subject of the sentence and ending with the first verb, excluding modal verbs. $$$$$ In experimenting with the maximum context size parameter, we found that the difference between the values of Fo for context sizes of 2 and 3 is less than 0.5% for the optimal threshold.
SV phrases, following the definition suggested in (Argamon et al, 1998), are word phrases starting with the subject of the sentence and ending with the first verb, excluding modal verbs. $$$$$ This subsection describes how to compute the score of a situated candidate from the training corpus.
SV phrases, following the definition suggested in (Argamon et al, 1998), are word phrases starting with the subject of the sentence and ending with the first verb, excluding modal verbs. $$$$$ Generalization is performed on-line at recognition time by comparing subsequences of the new text to positive and negative evidence in the corpus.

As reported in (Argamon et al, 1998), most base NPs present in the data are less or equal than 4 words long. $$$$$ The set of matching tiles 2, 4, and 5 covers the candidate, as does the set of tiles 1 and 5.
As reported in (Argamon et al, 1998), most base NPs present in the data are less or equal than 4 words long. $$$$$ We aiso thank the anonymous reviewers for their instructive comments.
As reported in (Argamon et al, 1998), most base NPs present in the data are less or equal than 4 words long. $$$$$ Applying the method to three syntactic patterns in English yielded positive results, suggesting its applicability for recognizing local linguistic patterns.
As reported in (Argamon et al, 1998), most base NPs present in the data are less or equal than 4 words long. $$$$$ Similarly, we also consider the negative evidence for such sub-parts by noting where they occur in the corpus without being a corresponding part of a target instance.

Argamon et al (1998) segmented the POS sequence of a multi-word into small POS tiles, counted tile frequency in the new word and non-new-word on the training set respectively, and detected new words using these counts. $$$$$ Table 3 summarizes the optimal parameter settings and results for NP, VO, and SV on the test set.
Argamon et al (1998) segmented the POS sequence of a multi-word into small POS tiles, counted tile frequency in the new word and non-new-word on the training set respectively, and detected new words using these counts. $$$$$ The MBSL scoring algorithm searches the training corpus for each subsequence of the sentence in order to find matching tiles.
Argamon et al (1998) segmented the POS sequence of a multi-word into small POS tiles, counted tile frequency in the new word and non-new-word on the training set respectively, and detected new words using these counts. $$$$$ The MBSL approach may be viewed as a linear analogy to DOP in that it constructs a cover for a candidate based on subsequences of training instances.

(Argamon et al, 1998) use Memory-Based Sequence Learning for recognizing both NP chunks and VP chunks. $$$$$ Inspired by Satta (1997), we build two suffix trees for retrieving the positive and total counts for a tile.
(Argamon et al, 1998) use Memory-Based Sequence Learning for recognizing both NP chunks and VP chunks. $$$$$ The training data are stored as-is, in efficient suffix-tree data structures.
(Argamon et al, 1998) use Memory-Based Sequence Learning for recognizing both NP chunks and VP chunks. $$$$$ The common practice for approaching this task is by tedious manual definition of possible pattern structures, often in the form of regular expressions or finite automata.
(Argamon et al, 1998) use Memory-Based Sequence Learning for recognizing both NP chunks and VP chunks. $$$$$ For VO patterns, we have put the starting delimiter before the main verb and the ending delimiter after the object head, thus covering the whole noun phrase comprising the object; for example: ... investigators started to [ view the lower price levels 7 as attractive ... We used a similar policy for SV patterns, defining the start of the pattern at the start of the subject noun phrase and the end at the first verb encountered (not including auxiliaries and modals); for example: ... argue that [ the U.S. should regulate ] the class ...

Ramshaw and Marcus (1995), Munoz et al (1999), Argamon et al (1998), Daelemans et al (1999a) find NP chunks, using Wall Street Journal training material of about 9000 sentences. $$$$$ In future work we plan to investigate a datadriven approach for optimal selection and weighting of statistical features of candidate scores, as well as to apply the method to syntactic patterns of Hebrew and to domain-specific patterns for information extraction.
Ramshaw and Marcus (1995), Munoz et al (1999), Argamon et al (1998), Daelemans et al (1999a) find NP chunks, using Wall Street Journal training material of about 9000 sentences. $$$$$ The second suffix tree holds an unbracketed version of the entire training corpus.
Ramshaw and Marcus (1995), Munoz et al (1999), Argamon et al (1998), Daelemans et al (1999a) find NP chunks, using Wall Street Journal training material of about 9000 sentences. $$$$$ The training data are stored as-is in suffix-tree data structures, which enable linear time searching for subsequences in the corpus.
