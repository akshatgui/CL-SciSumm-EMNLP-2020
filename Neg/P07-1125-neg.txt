Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ Relay of hedge made in previous work.
Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ The m most probable features are then selected from each sentence to compute (5) and the rest are ignored.
Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ We can easily derive a classifier using the estimates from our learning model by: where a is an arbitrary threshold used to control the precision/recall balance.
Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ Various methods have been investigated to address this problem, such as ‘counter-training’ (Yangarber, 2003) and committee agreement (Zhang, 2004); how such ideas can be adapted for this task is one of many avenues for future research.

The authors are only aware of the following related corpora: the Hedge classification corpus (Medlock and Briscoe, 2007), which has been annotated for hedge cues (at the sentence level) and consists of five full biological research papers (1537 sentences). $$$$$ For comparison purposes, we also use Joachims’ SVMlight (Joachims, 1999).
The authors are only aware of the following related corpora: the Hedge classification corpus (Medlock and Briscoe, 2007), which has been annotated for hedge cues (at the sentence level) and consists of five full biological research papers (1537 sentences). $$$$$ Values for the original and negligence-corrected labelings are reported in Table 1.
The authors are only aware of the following related corpora: the Hedge classification corpus (Medlock and Briscoe, 2007), which has been annotated for hedge cues (at the sentence level) and consists of five full biological research papers (1537 sentences). $$$$$ The contributions of our work are as follows:
The authors are only aware of the following related corpora: the Hedge classification corpus (Medlock and Briscoe, 2007), which has been annotated for hedge cues (at the sentence level) and consists of five full biological research papers (1537 sentences). $$$$$ The work presented here has application in the wider academic community; in fact a key motivation in this study is to incorporate hedge classification into an interactive system for aiding curators in the construction and population of gene databases.

5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ Self-training is an alternative single-view algorithm in which a labelled pool is incrementally enlarged with unlabelled samples 993 2available from www.cl.cam.ac.uk/∼bwm23/ The following are not considered hedge instances: Here we show that the hemocytes are the main regulator of adenosine in the Drosophila larva, as was speculated previously for mammals.
5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ The papers were converted to XML and linguistically processed using the RASP toolkit3.
5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ To ensure selection of complete sentences rather than headings, captions etc., unlabelled samples were chosen under the constraints that they must be at least 10 words in length and contain a main verb.
5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ Statement of knowledge paucity. ture selection procedure.

Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ We used an archive of 5579 full-text papers from the functional genomics literature relating to Drosophila melanogaster (the fruit fly).
Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ These were developed been used for named entity recognition (NER) after initial annotation by the authors, and through (Collins and Singer, 1999), coreference resolution discussion with colleagues.
Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ Although the adgf-a mutation leads to larval or pupal death, we have shown that this is not due to the adenosine or deoxyadenosine simply blocking cellular proliferation or survival, as the experiments in vitro would suggest.
Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ The training and classification models we have presented require the setting of two parameters: the smoothing parameter α and the number of features per sample m. Analysis of the effect of varying α on feature ranking reveals that when α = 0, low frequency terms with spurious class correlation dominate and as α increases, high frequency terms become increasingly dominant, eventually smoothing away genuine low-to-mid frequency correlations.

A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007). $$$$$ As a baseline classifier we use the substring matching technique of (Light et al., 2004), which labels a sentence as spec if it contains one or more of the following: suggest, potential, likely, may, at least, in part, possibl, further investigation, unlikely, putative, insights, point toward, promise and propose.
A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007). $$$$$ We show that hedge classification is feasible using weakly supervised ML, and point toward avenues for future research.
A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007). $$$$$ Various methods have been investigated to address this problem, such as ‘counter-training’ (Yangarber, 2003) and committee agreement (Zhang, 2004); how such ideas can be adapted for this task is one of many avenues for future research.

Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification. $$$$$ The baseline classifier achieves a BEP of 0.60 while both classifiers using our learning model reach approximately 0.76 BEP with little to tell between them.
Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification. $$$$$ We will draw on this work lation classification and (Chen et al., 2006) where throughout our presentation of the task. a graph based algorithm called label propagation is Hedging is sometimes classed under the umbrella employed to perform weakly supervised relation exconcept of subjectivity, which covers a variety of lin- traction. guistic phenomena used to express differing forms 3 The Hedge Classification Task of authorial opinion (Wiebe et al., 2004).
Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification. $$$$$ To ensure selection of complete sentences rather than headings, captions etc., unlabelled samples were chosen under the constraints that they must be at least 10 words in length and contain a main verb.

Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ is expectation maximization (EM), used by Nigam Dl and Ser have been proposed to act redundantly in the et al. (2000) for text categorization and by Ng and sensory bristle lineage.
Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ We will now consider how to apply this learning model to the hedge classification task.
Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ Firstly, due to the relative sparsity of hedge cues, most samples contain large numbers of irrelevant features.
Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ This example also highlights the potential benefit of an enriched sample representation, in this case one which accounts for the negation of the phrase ‘clear evidence’ which otherwise might suggest a strongly non-speculative assertion.

In addition, by following the annotation guidelines of Medlock and Briscoe (2007), Szarvas (2008) made available the BMC Bioinformatics data set, by annotating four full text papers from the open access BMC Bioinformatics website. $$$$$ Our contributions include a precise description of the task with annotation guidelines, analysis and discussion, a probabilistic weakly supervised learning model, and experimental evaluation of the methods presented.
In addition, by following the annotation guidelines of Medlock and Briscoe (2007), Szarvas (2008) made available the BMC Bioinformatics data set, by annotating four full text papers from the open access BMC Bioinformatics website. $$$$$ We show that hedge classification is feasible using weakly supervised ML, and point toward avenues for future research.
In addition, by following the annotation guidelines of Medlock and Briscoe (2007), Szarvas (2008) made available the BMC Bioinformatics data set, by annotating four full text papers from the open access BMC Bioinformatics website. $$$$$ In the quest for a deeper machine-driven ‘understanding’ of the mass of scientific literature, a frequently occuring linguistic phenomenon that must be accounted for is the use of hedging to denote propositions of a speculative nature.

In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords. $$$$$ Hedging occurs across the entire spectrum of scientific literature, though it is particularly common in the experimental natural sciences.
In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords. $$$$$ prove annotation consistency, we have developed a 2.2 Weakly Supervised Learning new set of guidelines, building on the work of Light Recent years have witnessed a significant growth et al. (2004).
In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords. $$$$$ This work was partially supported by the FlySlip project, BBSRC Grant BBS/B/16291, and we thank Nikiforos Karamanis and Ruth Seal for thorough annotation and helpful discussion.

For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning. $$$$$ The work presented here has application in the wider academic community; in fact a key motivation in this study is to incorporate hedge classification into an interactive system for aiding curators in the construction and population of gene databases.
For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning. $$$$$ We have presented our initial results on the task using a simple probabilistic model in the hope that this will encourage others to investigate alternative learning models and pursue new techniques for improving accuracy.
For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning. $$$$$ In the quest for a deeper machine-driven ‘understanding’ of the mass of scientific literature, a frequently occuring linguistic phenomenon that must be accounted for is the use of hedging to denote propositions of a speculative nature.

Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ For similar work see (Banko and Brill, 2001; Zhang, 2004).
Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ Formally: An interesting observation is the importance of the sample prior P(xj) in the denominator, often ignored for classification purposes because of its invariance to class.
Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ In many cases hedge classification is challenging even for a human annotator.
Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ The training and classification models we have presented require the setting of two parameters: the smoothing parameter α and the number of features per sample m. Analysis of the effect of varying α on feature ranking reveals that when α = 0, low frequency terms with spurious class correlation dominate and as α increases, high frequency terms become increasingly dominant, eventually smoothing away genuine low-to-mid frequency correlations.

Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against. $$$$$ This has the dual benefit of removing irrelevant features and also reducing dependence between features, as the selected features will often be nonlocal and thus not too tightly correlated.
Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against. $$$$$ We investigate automatic classification of speculative language (‘hedging’), in biomedical text using weakly supervised machine learning.
Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against. $$$$$ These results suggest that performance may be enhanced when the learning and classification tasks are carried out by different models.
Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against. $$$$$ In many cases hedge classification is challenging even for a human annotator.

However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically. $$$$$ The papers were converted to XML and linguistically processed using the RASP toolkit3.
However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically. $$$$$ In the quest for a deeper machine-driven ‘understanding’ of the mass of scientific literature, a frequently occuring linguistic phenomenon that must be accounted for is the use of hedging to denote propositions of a speculative nature.
However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically. $$$$$ The baseline classifier achieves a BEP of 0.60 while both classifiers using our learning model reach approximately 0.76 BEP with little to tell between them.

Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated. $$$$$ Various methods have been investigated to address this problem, such as ‘counter-training’ (Yangarber, 2003) and committee agreement (Zhang, 2004); how such ideas can be adapted for this task is one of many avenues for future research.
Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated. $$$$$ As a baseline classifier we use the substring matching technique of (Light et al., 2004), which labels a sentence as spec if it contains one or more of the following: suggest, potential, likely, may, at least, in part, possibl, further investigation, unlikely, putative, insights, point toward, promise and propose.
Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated. $$$$$ The m most probable features are then selected from each sentence to compute (5) and the rest are ignored.

The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant. $$$$$ Further examples are (Ng and Cardie, 2003), text categorization (Nigam given in online Appendix A2. and Ghani, 2000) and improving gene name data The following are considered hedge instances: (Wellner, 2005).
The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant. $$$$$ The first author is supported by an University of Cambridge Millennium Scholarship.
The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant. $$$$$ It turned out that the large majority of cases of disagreement were due to negligence on behalf of one or other of the annotators (i.e. cases of clear hedging that were missed), and that the cases of genuine disagreement were actually quite rare.
The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant. $$$$$ The weakly supervised learner returns a labelled data set for each class, from which a classifier can be trained.

Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ (2006) use selflem, exploring annotation issues and outlining po- training for improving parse reranking. tential applications rather than on the specificities Other relevant recent work includes (Zhang, of the ML approach, though they do present some 2004), in which random feature projection and a results using a manually crafted substring match- committee of SVM classifiers is used in a hybrid ing classifier and a supervised SVM on a collection co/self-training strategy for weakly supervised reof Medline abstracts.
Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ Our contributions include a precise description of the task with annotation guidelines, analysis and discussion, a probabilistic weakly supervised learning model, and experimental evaluation of the methods presented.
Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ Some errors are due to the variety of hedge forms.
Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ This work was partially supported by the FlySlip project, BBSRC Grant BBS/B/16291, and we thank Nikiforos Karamanis and Ruth Seal for thorough annotation and helpful discussion.

We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ The baseline classifier achieves a BEP of 0.60 while both classifiers using our learning model reach approximately 0.76 BEP with little to tell between them.
We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ To provide a comparison for our learning model, we implement a more traditional self-training procedure in which at each iteration a committee of five SVMs is trained on randomly generated overlapping subsets of the training data and their cumulative confidence is used to select items for augmenting the labelled training data.
We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ Whether it is possible to learn such examples without additional seed information is an open question.
We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ For similar work see (Banko and Brill, 2001; Zhang, 2004).

Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ Our next aim is to explore possibilities of introducing linguistically-motivated knowledge into the sample representation to help the learner identify key hedge-related sentential components, and also to consider hedge classification at the granularity of assertions rather than text sentences.
Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ This characteristic is also problematic in terms of selecting a reliable set of nspec seed sentences, as by definition at the beginning of the learning cycle the learner has little knowledge about what a hedge looks like.
Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ Consider the following: The second example contains a hedge, signaled by the use of suggest and might, which renders the proposition inhibit(XfK89—*Felin-9) speculative.
Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ The first author is supported by an University of Cambridge Millennium Scholarship.

Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ The work presented here has application in the wider academic community; in fact a key motivation in this study is to incorporate hedge classification into an interactive system for aiding curators in the construction and population of gene databases.
Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ In many cases hedge classification is challenging even for a human annotator.
Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ The weakly supervised learner returns a labelled data set for each class, from which a classifier can be trained.
Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ Formally: An interesting observation is the importance of the sample prior P(xj) in the denominator, often ignored for classification purposes because of its invariance to class.

Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ Our next aim is to explore possibilities of introducing linguistically-motivated knowledge into the sample representation to help the learner identify key hedge-related sentential components, and also to consider hedge classification at the granularity of assertions rather than text sentences.
Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ The first author is supported by an University of Cambridge Millennium Scholarship.
Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ We can expand further by = arg max j marginalising over the classes in the denominator in expression 2, yielding: so we are left with the class priors and classconditional likelihoods, which can usually be estimated directly from the data, at least under limited dependence assumptions.
Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ The baseline classifier achieves a BEP of 0.60 while both classifiers using our learning model reach approximately 0.76 BEP with little to tell between them.
