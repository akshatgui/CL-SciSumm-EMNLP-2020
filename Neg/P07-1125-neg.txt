Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ Riloff et al. Given a collection of sentences, S, the task is to (2003) explore bootstrapping techniques to identify label each sentence as either speculative or nonsubjective nouns and subsequently classify subjec- speculative (spec or nspec henceforth).
Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ Thus, we used the following procedure to obtain a set of nspec seeds: We started with 8830 sentences and after a couple of hours work reduced this down to a (still potentially noisy) nspec seed set of 7541 sentences.
Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ We can easily derive a classifier using the estimates from our learning model by: where a is an arbitrary threshold used to control the precision/recall balance.
Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. $$$$$ Perhaps the most well known of such approaches 2.

The authors are only aware of the following related corpora $$$$$ The weakly supervised learner returns a labelled data set for each class, from which a classifier can be trained.
The authors are only aware of the following related corpora $$$$$ Figure 1 plots accuracy as a function of the training iteration.
The authors are only aware of the following related corpora $$$$$ For brevity we refer the reader to (Artstein and Poesio, 2005) and (Hripcsak and Rothschild, 2004) for formulation and discussion of n and Frel The two metrics are based on different assumptions about the nature of the annotation task.
The authors are only aware of the following related corpora $$$$$ The weakly supervised learner returns a labelled data set for each class, from which a classifier can be trained.

5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ We annotated six of the papers to form a test set with a total of 380 spec sentences and 1157 nspec sentences, and randomly selected 300,000 sentences from the remaining papers as training data for the weakly supervised learner.
5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ We investigate automatic classification of speculative language (‘hedging’), in biomedical text using weakly supervised machine learning.
5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ To ensure selection of complete sentences rather than headings, captions etc., unlabelled samples were chosen under the constraints that they must be at least 10 words in length and contain a main verb.
5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes. $$$$$ The contributions of our work are as follows:

Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ We investigate automatic classification of speculative language (‘hedging’), in biomedical text using weakly supervised machine learning.
Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ The m most probable features are then selected from each sentence to compute (5) and the rest are ignored.
Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ Generating seeds for nspec is much more difficult, as integrity requires the absence of hedge cues, and this cannot be done automatically.
Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative. $$$$$ This work was partially supported by the FlySlip project, BBSRC Grant BBS/B/16291, and we thank Nikiforos Karamanis and Ruth Seal for thorough annotation and helpful discussion.

A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007). $$$$$ As a baseline classifier we use the substring matching technique of (Light et al., 2004), which labels a sentence as spec if it contains one or more of the following: suggest, potential, likely, may, at least, in part, possibl, further investigation, unlikely, putative, insights, point toward, promise and propose.
A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007). $$$$$ To examine the practical efficacy of the learning and classification models we have presented, we use the following experimental method: The batch size for each iteration is set to 0.001 * |U|.
A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007). $$$$$ For similar work see (Banko and Brill, 2001; Zhang, 2004).
A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007). $$$$$ Formally: An interesting observation is the importance of the sample prior P(xj) in the denominator, often ignored for classification purposes because of its invariance to class.

Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification. $$$$$ In this study we develop a learning model based around the concept of iteratively predicting labels for unlabelled training samples, the basic paradigm for both co-training and self-training.
Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification. $$$$$ The work presented here has application in the wider academic community; in fact a key motivation in this study is to incorporate hedge classification into an interactive system for aiding curators in the construction and population of gene databases.
Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification. $$$$$ In this study we develop a learning model based around the concept of iteratively predicting labels for unlabelled training samples, the basic paradigm for both co-training and self-training.
Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification. $$$$$ Further examples are (Ng and Cardie, 2003), text categorization (Nigam given in online Appendix A2. and Ghani, 2000) and improving gene name data The following are considered hedge instances: (Wellner, 2005).

Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ This idea was for- Light et al. (item 1) and introduce a set of further malised by Blum and Mitchell (1998) in their guidelines to help elucidate various ‘grey areas’ and presentation of co-training.
Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ To provide a comparison for our learning model, we implement a more traditional self-training procedure in which at each iteration a committee of five SVMs is trained on randomly generated overlapping subsets of the training data and their cumulative confidence is used to select items for augmenting the labelled training data.
Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ For similar work see (Banko and Brill, 2001; Zhang, 2004).
Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams. $$$$$ For similar work see (Banko and Brill, 2001; Zhang, 2004).

In addition, by following the annotation guidelines of Medlock and Briscoe (2007), Szarvas (2008) made available the BMC Bioinformatics data set, by annotating four full text papers from the open access BMC Bioinformatics website. $$$$$ Thus, we used the following procedure to obtain a set of nspec seeds: We started with 8830 sentences and after a couple of hours work reduced this down to a (still potentially noisy) nspec seed set of 7541 sentences.
In addition, by following the annotation guidelines of Medlock and Briscoe (2007), Szarvas (2008) made available the BMC Bioinformatics data set, by annotating four full text papers from the open access BMC Bioinformatics website. $$$$$ Firstly, due to the relative sparsity of hedge cues, most samples contain large numbers of irrelevant features.
In addition, by following the annotation guidelines of Medlock and Briscoe (2007), Szarvas (2008) made available the BMC Bioinformatics data set, by annotating four full text papers from the open access BMC Bioinformatics website. $$$$$ Specifically, tive vs. objective sentences in newswire text.

In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords. $$$$$ Various methods have been investigated to address this problem, such as ‘counter-training’ (Yangarber, 2003) and committee agreement (Zhang, 2004); how such ideas can be adapted for this task is one of many avenues for future research.
In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords. $$$$$ The first author is supported by an University of Cambridge Millennium Scholarship.
In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords. $$$$$ For comparison purposes, we also use Joachims’ SVMlight (Joachims, 1999).
In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords. $$$$$ Formally: An interesting observation is the importance of the sample prior P(xj) in the denominator, often ignored for classification purposes because of its invariance to class.

For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning. $$$$$ We investigate automatic classification of speculative language (‘hedging’), in biomedical text using weakly supervised machine learning.
For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning. $$$$$ For comparison purposes, we also use Joachims’ SVMlight (Joachims, 1999).
For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning. $$$$$ 1.
For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning. $$$$$ For similar work see (Banko and Brill, 2001; Zhang, 2004).

Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ Formally: An interesting observation is the importance of the sample prior P(xj) in the denominator, often ignored for classification purposes because of its invariance to class.
Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ New labelings were then created with the negligent disagreements corrected, resulting in significantly higher agreement scores.
Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ The papers were converted to XML and linguistically processed using the RASP toolkit3.
Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative. $$$$$ The weakly supervised learner returns a labelled data set for each class, from which a classifier can be trained.

Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against. $$$$$ In many cases hedge classification is challenging even for a human annotator.
Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against. $$$$$ As discussed earlier, the speculative/non-speculative distinction hinges on the presence or absence of a few hedge cues within the sentence.
Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against. $$$$$ The baseline classifier achieves a BEP of 0.60 while both classifiers using our learning model reach approximately 0.76 BEP with little to tell between them.

However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically. $$$$$ We used an archive of 5579 full-text papers from the functional genomics literature relating to Drosophila melanogaster (the fruit fly).
However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically. $$$$$ The papers were converted to XML and linguistically processed using the RASP toolkit3.
However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically. $$$$$ To provide a comparison for our learning model, we implement a more traditional self-training procedure in which at each iteration a committee of five SVMs is trained on randomly generated overlapping subsets of the training data and their cumulative confidence is used to select items for augmenting the labelled training data.
However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically. $$$$$ We annotated six of the papers to form a test set with a total of 380 spec sentences and 1157 nspec sentences, and randomly selected 300,000 sentences from the remaining papers as training data for the weakly supervised learner.

Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated. $$$$$ Investigating more complex sample representation strategies is an avenue for future research.
Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated. $$$$$ Consider the following: The second example contains a hedge, signaled by the use of suggest and might, which renders the proposition inhibit(XfK89—*Felin-9) speculative.
Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated. $$$$$ We can expand further by = arg max j marginalising over the classes in the denominator in expression 2, yielding: so we are left with the class priors and classconditional likelihoods, which can usually be estimated directly from the data, at least under limited dependence assumptions.
Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated. $$$$$ This work was partially supported by the FlySlip project, BBSRC Grant BBS/B/16291, and we thank Nikiforos Karamanis and Ruth Seal for thorough annotation and helpful discussion.

The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant. $$$$$ This example also highlights the potential benefit of an enriched sample representation, in this case one which accounts for the negation of the phrase ‘clear evidence’ which otherwise might suggest a strongly non-speculative assertion.
The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant. $$$$$ An important issue in incremental learning scenarios is identification of the optimum stopping point.
The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant. $$$$$ We annotated six of the papers to form a test set with a total of 380 spec sentences and 1157 nspec sentences, and randomly selected 300,000 sentences from the remaining papers as training data for the weakly supervised learner.

Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ The first author is supported by an University of Cambridge Millennium Scholarship.
Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ After 150 iterations, all of the weakly supervised learning models are significantly more accurate than the baseline according to a binomial sign test (p < 0.01), though there is clearly still much room for improvement.
Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ We annotated six of the papers to form a test set with a total of 380 spec sentences and 1157 nspec sentences, and randomly selected 300,000 sentences from the remaining papers as training data for the weakly supervised learner.
Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007). $$$$$ We can easily derive a classifier using the estimates from our learning model by: where a is an arbitrary threshold used to control the precision/recall balance.

We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ We show that hedge classification is feasible using weakly supervised ML, and point toward avenues for future research.
We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ This highlights the similarity between many hedge and non-hedge instances, which makes such cases hard to learn in a weakly supervised manner.
We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ Our contributions include a precise description of the task with annotation guidelines, analysis and discussion, a probabilistic weakly supervised learning model, and experimental evaluation of the methods presented.
We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007). $$$$$ As a baseline classifier we use the substring matching technique of (Light et al., 2004), which labels a sentence as spec if it contains one or more of the following: suggest, potential, likely, may, at least, in part, possibl, further investigation, unlikely, putative, insights, point toward, promise and propose.

Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ In many cases hedge classification is challenging even for a human annotator.
Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ Self-training is an alternative single-view algorithm in which a labelled pool is incrementally enlarged with unlabelled samples 993 2available from www.cl.cam.ac.uk/∼bwm23/ The following are not considered hedge instances: Here we show that the hemocytes are the main regulator of adenosine in the Drosophila larva, as was speculated previously for mammals.
Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ The contributions of our work are as follows:
Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. $$$$$ The work presented here has application in the wider academic community; in fact a key motivation in this study is to incorporate hedge classification into an interactive system for aiding curators in the construction and population of gene databases.

Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ Given our definition of hedge classification and assessing the manner in which the annotation was carried out, we suggest that the founding assumption of Frel 1 fits the nature of the task better than that of n. Following initial agreement calculation, the instances of disagreement were examined.
Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ For comparison purposes, we also use Joachims’ SVMlight (Joachims, 1999).
Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ We show that hedge classification is feasible using weakly supervised ML, and point toward avenues for future research.
Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. $$$$$ For similar work see (Banko and Brill, 2001; Zhang, 2004).

Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ For comparison purposes, we also use Joachims’ SVMlight (Joachims, 1999).
Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ As a baseline classifier we use the substring matching technique of (Light et al., 2004), which labels a sentence as spec if it contains one or more of the following: suggest, potential, likely, may, at least, in part, possibl, further investigation, unlikely, putative, insights, point toward, promise and propose.
Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ After 150 iterations, all of the weakly supervised learning models are significantly more accurate than the baseline according to a binomial sign test (p < 0.01), though there is clearly still much room for improvement.
Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)). $$$$$ The learning model we have presented requires a set of seeds for each class.
