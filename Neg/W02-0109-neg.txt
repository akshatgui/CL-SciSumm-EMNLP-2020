If evaluated against the requirements for teaching environments discussed in (Loper and Bird, 2002), GATE covers them all quite well. $$$$$ We also plan to increase the number of algorithms implemented by some existing modules, such as the text classification module.
If evaluated against the requirements for teaching environments discussed in (Loper and Bird, 2002), GATE covers them all quite well. $$$$$ The interaction between different components of the toolkit should be kept to a minimum, using simple, well-defined interfaces.

However, other such modules, e.g., those from NLTK (Loper and Bird, 2002), can be used for such assignments. $$$$$ A widespread practice is to employ multiple programming languages, where each language provides native data structures and functions that are a good fit for the task at hand.
However, other such modules, e.g., those from NLTK (Loper and Bird, 2002), can be used for such assignments. $$$$$ Students were required to complete five assignments, two exams, and a final project.
However, other such modules, e.g., those from NLTK (Loper and Bird, 2002), can be used for such assignments. $$$$$ All class materials are available from the course website http://www.cis.upenn.edu/~cis530/.

We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk. $$$$$ The more time students must spend learning to use the toolkit, the less useful it is.
We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk. $$$$$ Although not originally motivated by pedagogical needs, all of these toolkits have pedagogical applications and many have already been used in teaching.
We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk. $$$$$ The toolkit is not intended to provide a comprehensive set of tools.
We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk. $$$$$ Typical projects involve the development of entirely new functionality for a previously unsupported NLP task, or the development of a complete system out of existing and new modules.

NLTK, the Natural Language Toolkit, is a suite of Python modules providing many NLP data types, processing tasks, corpus samples and readers, together with animated algorithms, tutorials, and problem sets (Loper and Bird, 2002). $$$$$ In particular, it should be possible to complete individual projects using small parts of the toolkit, without worrying about how they interact with the rest of the toolkit.
NLTK, the Natural Language Toolkit, is a suite of Python modules providing many NLP data types, processing tasks, corpus samples and readers, together with animated algorithms, tutorials, and problem sets (Loper and Bird, 2002). $$$$$ Grammar Developers.
NLTK, the Natural Language Toolkit, is a suite of Python modules providing many NLP data types, processing tasks, corpus samples and readers, together with animated algorithms, tutorials, and problem sets (Loper and Bird, 2002). $$$$$ Finding suitable corpora is a prerequisite for many student assignments and projects.
NLTK, the Natural Language Toolkit, is a suite of Python modules providing many NLP data types, processing tasks, corpus samples and readers, together with animated algorithms, tutorials, and problem sets (Loper and Bird, 2002). $$$$$ It was also important to decide what goals the toolkit would not attempt to accomplish; we therefore include an explicit set of nonrequirements, which the toolkit is not expected to satisfy.

For English and German documents in all experiments, we removed stop words (Loper and Bird, 2002), stemmed words (Porter and Boulton, 1970), and created a vocabulary of the most frequent 5000 words per language (this vocabulary limit was mostly done to ensure that the dictionary-based bridge was of manageable size). $$$$$ CIS-530 is a graduate level class, although some advanced undergraduates were also enrolled.
For English and German documents in all experiments, we removed stop words (Loper and Bird, 2002), stemmed words (Porter and Boulton, 1970), and created a vocabulary of the most frequent 5000 words per language (this vocabulary limit was mostly done to ensure that the dictionary-based bridge was of manageable size). $$$$$ The toolkit is accompanied by extensive documentation that explains the toolkit, and describes how to use and extend it.

We have not yet used the Natural Language Toolkit (Loper and Bird, 2002) (see Section 3.1) in this course. $$$$$ We are therefore putting together a collection of corpora containing data appropriate for every module defined by the toolkit.
We have not yet used the Natural Language Toolkit (Loper and Bird, 2002) (see Section 3.1) in this course. $$$$$ This work has found widespread pedagogical application.
We have not yet used the Natural Language Toolkit (Loper and Bird, 2002) (see Section 3.1) in this course. $$$$$ CIS-530 is a graduate level class, although some advanced undergraduates were also enrolled.
We have not yet used the Natural Language Toolkit (Loper and Bird, 2002) (see Section 3.1) in this course. $$$$$ NLTK covers symbolic and statistical natural language processing, and is interfaced to annotated corpora.

Finally, all texts were lemmatized using Porter's stemmer (1980) for English and Snowballstemmers for other languages using an implementation provided by the NLTK (Loper and Bird, 2002). $$$$$ They also liked being able to run everything on their computer at home.
Finally, all texts were lemmatized using Porter's stemmer (1980) for English and Snowballstemmers for other languages using an implementation provided by the NLTK (Loper and Bird, 2002). $$$$$ Each tutorial focuses on a single domain, such as tagging, probabilistic systems, or text classification.
Finally, all texts were lemmatized using Porter's stemmer (1980) for English and Snowballstemmers for other languages using an implementation provided by the NLTK (Loper and Bird, 2002). $$$$$ Technical Reports explain and justify the toolkit’s design and implementation.
Finally, all texts were lemmatized using Porter's stemmer (1980) for English and Snowballstemmers for other languages using an implementation provided by the NLTK (Loper and Bird, 2002). $$$$$ Modularity.

We strip unnecessary HTML tags and Wiki templates with mwlib5 and split sentences with NLTK (Loper and Bird, 2002). $$$$$ A more challenging task is to develop a new module.
We strip unnecessary HTML tags and Wiki templates with mwlib5 and split sentences with NLTK (Loper and Bird, 2002). $$$$$ Finally, the language must have an easy-to-use graphics library to support the development of graphical user interfaces.
We strip unnecessary HTML tags and Wiki templates with mwlib5 and split sentences with NLTK (Loper and Bird, 2002). $$$$$ NLTK covers symbolic and statistical natural language processing, and is interfaced to annotated corpora.

Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al, 2003) toolkits. $$$$$ We are therefore putting together a collection of corpora containing data appropriate for every module defined by the toolkit.
Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al, 2003) toolkits. $$$$$ The more time students must spend learning to use the toolkit, the less useful it is.
Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al, 2003) toolkits. $$$$$ Recent work includes (Copestake, 2000; Baldridge et al., 2002a).
Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al, 2003) toolkits. $$$$$ The Natural Language Toolkit is available under an open source license from http://nltk.sf.net/.

We use a simple path distance similarity measure, as implemented in NLTK (Loper and Bird, 2002). $$$$$ In particular, it should be possible to complete individual projects using small parts of the toolkit, without worrying about how they interact with the rest of the toolkit.
We use a simple path distance similarity measure, as implemented in NLTK (Loper and Bird, 2002). $$$$$ By relying on the built-in features of various languages, the teacher avoids having to develop a lot of software infrastructure.
We use a simple path distance similarity measure, as implemented in NLTK (Loper and Bird, 2002). $$$$$ The students encountered a couple of bugs in the toolkit, but none were serious, and all were quickly corrected.
We use a simple path distance similarity measure, as implemented in NLTK (Loper and Bird, 2002). $$$$$ CIS-530 is a graduate level class, although some advanced undergraduates were also enrolled.

Our word pairs are lemmatized using the Wordnet based lemmatizer of NLTK (Loper and Bird, 2002). $$$$$ The toolkit should structure the complexities of building NLP systems, not hide them.
Our word pairs are lemmatized using the Wordnet based lemmatizer of NLTK (Loper and Bird, 2002). $$$$$ These interactive tools can be used to display relevant data structures and to show the step-by-step execution of algorithms.
Our word pairs are lemmatized using the Wordnet based lemmatizer of NLTK (Loper and Bird, 2002). $$$$$ Infrastructure for grammar development has a long history in unification-based (or constraint-based) grammar frameworks, from DCG (Pereira and Warren, 1980) to HPSG (Pollard and Sag, 1994).
Our word pairs are lemmatized using the Wordnet based lemmatizer of NLTK (Loper and Bird, 2002). $$$$$ This allows students to learn how to use the toolkit incrementally throughout a course.

The Natural Language Toolkit, or NLTK, was developed to give a broad range of students access to the core knowledge and skills of NLP (Loper and Bird, 2002). $$$$$ However, when efficiency is an issue, type checking can be easily turned off; and with type checking is disabled, there is no performance penalty.
The Natural Language Toolkit, or NLTK, was developed to give a broad range of students access to the core knowledge and skills of NLP (Loper and Bird, 2002). $$$$$ Modularity.
The Natural Language Toolkit, or NLTK, was developed to give a broad range of students access to the core knowledge and skills of NLP (Loper and Bird, 2002). $$$$$ Second, its target audience consists of both linguists and computer scientists, and it is accessible and challenging at many levels of prior computational skill.
The Natural Language Toolkit, or NLTK, was developed to give a broad range of students access to the core knowledge and skills of NLP (Loper and Bird, 2002). $$$$$ At each step of the algorithm, the user can select which rule or strategy they wish to apply.

Tokenization ,lemmatization, and stop word removal was performed using the Natural Language Toolkit (Loper and Bird, 2002). $$$$$ We are grateful to Mitch Marcus and the Department of Computer and Information Science at the University of Pennsylvania for sponsoring the work reported here.
Tokenization ,lemmatization, and stop word removal was performed using the Natural Language Toolkit (Loper and Bird, 2002). $$$$$ NLTK covers symbolic and statistical natural language processing, and is interfaced to annotated corpora.
Tokenization ,lemmatization, and stop word removal was performed using the Natural Language Toolkit (Loper and Bird, 2002). $$$$$ A set of core modules defines basic data types and processing systems that are used throughout the toolkit.
Tokenization ,lemmatization, and stop word removal was performed using the Natural Language Toolkit (Loper and Bird, 2002). $$$$$ This work has found widespread pedagogical application.

Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. $$$$$ Each tutorial focuses on a single domain, such as tagging, probabilistic systems, or text classification.
Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. $$$$$ Once students become more familiar with the toolkit, they can be asked to make minor changes or extensions to an existing module.
Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. $$$$$ In this section we briefly review a selection of approaches, classified according to the (original) target audience.
Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. $$$$$ NLTK is an open source project, and we welcome any contributions.

To identify content words, we used the NLTK-Lite tagger to assign a part of speech to each word (Loper and Bird, 2002). $$$$$ To reduce the amount of time students must spend debugging their code, we provide a type checking module, which can be used to ensure that functions are given valid arguments.
To identify content words, we used the NLTK-Lite tagger to assign a part of speech to each word (Loper and Bird, 2002). $$$$$ In this section we briefly review a selection of approaches, classified according to the (original) target audience.
To identify content words, we used the NLTK-Lite tagger to assign a part of speech to each word (Loper and Bird, 2002). $$$$$ Readers who are interested in contributing to NLTK, or who have suggestions for improvements, are encouraged to contact the authors.
To identify content words, we used the NLTK-Lite tagger to assign a part of speech to each word (Loper and Bird, 2002). $$$$$ Students can also consult these reports if they would like further information about how the toolkit is designed, and why it is designed that way.

For the NL processing, the Natural Language Toolkit (NL Toolkit or NLTK), developed at the University of Pennsylvania by Loper and Bird (2002), and available for download from Source Forge at http $$$$$ Python offers a shallow learning curve; it was designed to be easily learnt by children (van Rossum, 1999).
For the NL processing, the Natural Language Toolkit (NL Toolkit or NLTK), developed at the University of Pennsylvania by Loper and Bird (2002), and available for download from Source Forge at http $$$$$ This documentation is divided into three primary categories: Tutorials teach students how to use the toolkit, in the context of performing specific tasks.
For the NL processing, the Natural Language Toolkit (NL Toolkit or NLTK), developed at the University of Pennsylvania by Loper and Bird (2002), and available for download from Source Forge at http $$$$$ NLTK provides a simple, extensible, uniform framework for assignments, projects, and class demonstrations.

 $$$$$ We are indebted to our students for feedback on the toolkit, and to anonymous reviewers, Jee Bang, and the workshop organizers for comments on an earlier version of this paper.
 $$$$$ The tutorials include a high-level discussion that explains and motivates the domain, followed by a detailed walk-through that uses examples to show how NLTK can be used to perform specific tasks.
 $$$$$ The remaining modules define data structures and interfaces for performing specific NLP tasks.
 $$$$$ Another issue was the fact that we were actively developing NLTK during the semester; some modules were only completed one or two weeks before the students used them.

In the end I decided to require the students to learn python because I wanted to use NLTK, the Natural Language Toolkit (Loper and Bird, 2002). $$$$$ This context calls for highly interactive graphical user interfaces, making it possible to view program state (e.g. the chart of a chart parser), observe program execution step-by-step (e.g. execution of a finite-state machine), and even make minor modifications to programs in response to “what if” questions from the class.
In the end I decided to require the students to learn python because I wanted to use NLTK, the Natural Language Toolkit (Loper and Bird, 2002). $$$$$ A widespread practice is to employ multiple programming languages, where each language provides native data structures and functions that are a good fit for the task at hand.
In the end I decided to require the students to learn python because I wanted to use NLTK, the Natural Language Toolkit (Loper and Bird, 2002). $$$$$ Technical Reports explain and justify the toolkit’s design and implementation.

 $$$$$ NLTK, the Natural Language Toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware.
 $$$$$ By relying on the built-in features of various languages, the teacher avoids having to develop a lot of software infrastructure.
 $$$$$ Technical Reports explain and justify the toolkit’s design and implementation.
 $$$$$ NLTK, the Natural Language Toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware.

The Natural Language Toolkit (NLTK) was developed in conjunction with a computational linguistics course at the University of Pennsylvania in 2001 (Loper and Bird, 2002). $$$$$ Infrastructure for grammar development has a long history in unification-based (or constraint-based) grammar frameworks, from DCG (Pereira and Warren, 1980) to HPSG (Pollard and Sag, 1994).
The Natural Language Toolkit (NLTK) was developed in conjunction with a computational linguistics course at the University of Pennsylvania in 2001 (Loper and Bird, 2002). $$$$$ Because of these difficulties it is common to avoid live demonstrations, and keep classes for theoretical presentations only.
The Natural Language Toolkit (NLTK) was developed in conjunction with a computational linguistics course at the University of Pennsylvania in 2001 (Loper and Bird, 2002). $$$$$ In surveying the available languages, we believe that Python offers an especially good fit to the above requirements.
