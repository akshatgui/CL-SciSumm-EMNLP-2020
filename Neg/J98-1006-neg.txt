Leacock et al (1998), Agirre and Lopezde Lacalle (2004), and Mihalcea and Moldovan (1999) propose a set of methods for automatic harvesting of web data for the purposes of creating sense annotated corpora. $$$$$ They collected contexts of sentence translated as peine to build a corpus for the judicial sense, and collected contexts of sentence translated as phrase to build a corpus for the grammatical sense.
Leacock et al (1998), Agirre and Lopezde Lacalle (2004), and Mihalcea and Moldovan (1999) propose a set of methods for automatic harvesting of web data for the purposes of creating sense annotated corpora. $$$$$ Testing consists of taking a new example of the polysemous word and computing the most probable sense, based on the cues present in the context of the new item.
Leacock et al (1998), Agirre and Lopezde Lacalle (2004), and Mihalcea and Moldovan (1999) propose a set of methods for automatic harvesting of web data for the purposes of creating sense annotated corpora. $$$$$ Corpus-based approaches to word sense identification have flexibility and generality but suffer from a knowledge acquisition bottleneck.
Leacock et al (1998), Agirre and Lopezde Lacalle (2004), and Mihalcea and Moldovan (1999) propose a set of methods for automatic harvesting of web data for the purposes of creating sense annotated corpora. $$$$$ No other cues, such as part-of-speech tags or word order, are used.

The following similarity measures were considered $$$$$ Corpus-based approaches to word sense identification have flexibility and generality but suffer from a knowledge acquisition bottleneck.
The following similarity measures were considered $$$$$ • • s,) is difficult to estimate because of the sparse data problem, but if we assume, as is often done, that the occurrence of each cue is independent of the others, then this term can be replaced with: In TLC, we have made this assumption and have estimated p(ci I si) from the training.
The following similarity measures were considered $$$$$ To open this bottleneck, we use WordNet's lexical relations to locate unsupervised training examples.
The following similarity measures were considered $$$$$ Our evidence indicates that local context is superior to topical context as an indicator of word sense when using a statistical classifier.

Many corpus based methods have been proposed to deal with the sense disambiguation problem when given definition for each possible sense of a target word or a tagged corpus with the instances of each possible sense, e.g., supervised sense disambiguation (Leacocketal., 1998), and semi-supervised sense disambiguation (Yarowsky, 1995). $$$$$ Results for the 12 pairs of homographs reported are almost perfect.
Many corpus based methods have been proposed to deal with the sense disambiguation problem when given definition for each possible sense of a target word or a tagged corpus with the instances of each possible sense, e.g., supervised sense disambiguation (Leacocketal., 1998), and semi-supervised sense disambiguation (Yarowsky, 1995). $$$$$ The two traditions complement each other.
Many corpus based methods have been proposed to deal with the sense disambiguation problem when given definition for each possible sense of a target word or a tagged corpus with the instances of each possible sense, e.g., supervised sense disambiguation (Leacocketal., 1998), and semi-supervised sense disambiguation (Yarowsky, 1995). $$$$$ This material is based upon work supported in part by the National Science Foundation under NSF Award No.

Many methods have been proposed to deal with this problem, including supervised learning algorithms (Leacock et al, 1998). $$$$$ The results of combining the two types of context to disambiguate a noun (line), a verb (serve), and an adjective (hard) are presented.
Many methods have been proposed to deal with this problem, including supervised learning algorithms (Leacock et al, 1998). $$$$$ The Cognitive Science Laboratory at Princeton University, with support from NSF-ARPA, is producing textual corpora that can be used in developing and evaluating automatic methods for disambiguation.
Many methods have been proposed to deal with this problem, including supervised learning algorithms (Leacock et al, 1998). $$$$$ Take a Roget's category—his examples were TOOL and ANIMAL—and collect sentences from a corpus (in this case, Grolier's Encyclopedia) using the words in each category.
Many methods have been proposed to deal with this problem, including supervised learning algorithms (Leacock et al, 1998). $$$$$ Manually tagged training materials were used in the development of TLC and the experiments in Section 2.

Inspired by the work of (Leacock et al, 1998), TSWEB was constructed using monosemous relatives from WN (synonyms ,hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the salient words with distinctive frequency using TFIDF. $$$$$ The results of this effort will be a useful resource for training statistical classifiers, but what about the next thousand polysemous words, and the next?
Inspired by the work of (Leacock et al, 1998), TSWEB was constructed using monosemous relatives from WN (synonyms ,hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the salient words with distinctive frequency using TFIDF. $$$$$ Test results are compared with those from manually tagged training examples.
Inspired by the work of (Leacock et al, 1998), TSWEB was constructed using monosemous relatives from WN (synonyms ,hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the salient words with distinctive frequency using TFIDF. $$$$$ Because the supply of manually tagged training data will always be limited, we propose a method to obtain training data automatically using commonly available materials: exploiting WordNet's lexical relations to harvest training examples from LDC corpora or even the World Wide Web.

It was first suggested by Leacock et al (1998). $$$$$ Finally we are grateful to the three anonymous CL reviewers for their comments and advice.
It was first suggested by Leacock et al (1998). $$$$$ A knowledge base in the form of WordNet's lexical relations is used to automatically locate training examples in a general text corpus.
It was first suggested by Leacock et al (1998). $$$$$ 1R19528983 and by the Defense Advanced Research Projects Agency, Grant No.

Leacock et al (1998) attempted to exclude irrelevant or spurious examples by using only monosemous relatives in WordNet. $$$$$ We are indebted to the other members of the WordNet group who have provided advice and technical support: Christiane Fellbaum, Shari Landes, and Randee Tengi.
Leacock et al (1998) attempted to exclude irrelevant or spurious examples by using only monosemous relatives in WordNet. $$$$$ Manually tagged training materials were used in the development of TLC and the experiments in Section 2.
Leacock et al (1998) attempted to exclude irrelevant or spurious examples by using only monosemous relatives in WordNet. $$$$$ When local context is combined with topical, TLC is superior to the topical classifiers compared in the Leacock, Towel!, and Voorhees (1993) study.

Our approach is somewhat similar to the WordNet based approach of Leacock et al (1998) in that it acquires relatives of a target word from WordNetand extracts co-occurrence frequencies of the relatives from a raw corpus, but our system uses poly semous as well as monosemous relatives. $$$$$ In the experiments of Section 3.2, these were estimated from the testing materials.
Our approach is somewhat similar to the WordNet based approach of Leacock et al (1998) in that it acquires relatives of a target word from WordNetand extracts co-occurrence frequencies of the relatives from a raw corpus, but our system uses poly semous as well as monosemous relatives. $$$$$ We describe a statistical classifier that combines topical context with local cues to identify a word sense.
Our approach is somewhat similar to the WordNet based approach of Leacock et al (1998) in that it acquires relatives of a target word from WordNetand extracts co-occurrence frequencies of the relatives from a raw corpus, but our system uses poly semous as well as monosemous relatives. $$$$$ Yarowsky points out that the resulting noise will be a problem only when one of the spurious senses is salient, dominating the training set, and he uses frequency-based weights to minimize these effects.

Other notable unsupervised and semi-supervised approaches are those of McCarthy et al (2004), who combine ontological relations and untagged corpora to automatically rank word senses in relation to a corpus, and Leacock et al (1998) who use untagged data to build sense-tagged data automatically based on monosemous words. $$$$$ They require only training corpora in which the sense distinctions have been marked, but therein lies their weakness.
Other notable unsupervised and semi-supervised approaches are those of McCarthy et al (2004), who combine ontological relations and untagged corpora to automatically rank word senses in relation to a corpus, and Leacock et al (1998) who use untagged data to build sense-tagged data automatically based on monosemous words. $$$$$ We are also grateful to Paul Bagyenda, Ben Johnson-Laird and Joshua Schecter.
Other notable unsupervised and semi-supervised approaches are those of McCarthy et al (2004), who combine ontological relations and untagged corpora to automatically rank word senses in relation to a corpus, and Leacock et al (1998) who use untagged data to build sense-tagged data automatically based on monosemous words. $$$$$ In order to compare our results with those reported in Yarowsky (1992), we trained and tested on the same two senses of the noun duty that Yarowsky had tested ('obligation' and 'tax').
Other notable unsupervised and semi-supervised approaches are those of McCarthy et al (2004), who combine ontological relations and untagged corpora to automatically rank word senses in relation to a corpus, and Leacock et al (1998) who use untagged data to build sense-tagged data automatically based on monosemous words. $$$$$ Senses whose contexts greatly overlap can be identified with a simple cosine correlation.

Inspired by the work of Leacock et al (1998), TSWEB was constructed using monosemous relatives from WN (synonyms ,hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the salient words with distinctive frequency using TFIDF. $$$$$ Following the approach of Dagan and Itai (1994), we use the log of the ratio of the probabilities In(pi/p2) for this purpose.
Inspired by the work of Leacock et al (1998), TSWEB was constructed using monosemous relatives from WN (synonyms ,hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the salient words with distinctive frequency using TFIDF. $$$$$ Leacock, Towell, and Voorhees (1993) report that the three topical classifiers tested averaged 74% accuracy on six senses of the noun line.

Others, such as Leacock et al (1998) and Agirre and Martnez (2004b), used information from WordNet to construct queries which were used to retrieve training examples. $$$$$ TLC used training examples based on monosemous WordNet relatives and correctly identified the senses with 93.5% precision at 100% recall.
Others, such as Leacock et al (1998) and Agirre and Martnez (2004b), used information from WordNet to construct queries which were used to retrieve training examples. $$$$$ A knowledge base in the form of WordNet's lexical relations is used to automatically locate training examples in a general text corpus.
Others, such as Leacock et al (1998) and Agirre and Martnez (2004b), used information from WordNet to construct queries which were used to retrieve training examples. $$$$$ N00014-91-1634.

In (Leacock et al, 1998), they used Bayesian approach for sense disambiguation of three ambiguous words. $$$$$ This material is based upon work supported in part by the National Science Foundation under NSF Award No.
In (Leacock et al, 1998), they used Bayesian approach for sense disambiguation of three ambiguous words. $$$$$ Operating in this mode, the classifier can gather new training materials, automatically, and with high precision.
In (Leacock et al, 1998), they used Bayesian approach for sense disambiguation of three ambiguous words. $$$$$ In the experiments of Section 3.2, these were estimated from the testing materials.
In (Leacock et al, 1998), they used Bayesian approach for sense disambiguation of three ambiguous words. $$$$$ Yarowsky's classifier is purely topical, but we also examine local context.

Another method, by (Leacock et al, 1998), normalizes path distance based on the depth of hierarchy. $$$$$ We are also grateful to Paul Bagyenda, Ben Johnson-Laird and Joshua Schecter.
Another method, by (Leacock et al, 1998), normalizes path distance based on the depth of hierarchy. $$$$$ We describe a statistical classifier that combines topical context with local cues to identify a word sense.
Another method, by (Leacock et al, 1998), normalizes path distance based on the depth of hierarchy. $$$$$ We are also grateful to Paul Bagyenda, Ben Johnson-Laird and Joshua Schecter.
Another method, by (Leacock et al, 1998), normalizes path distance based on the depth of hierarchy. $$$$$ Test results are compared with those from manually tagged training examples.

Various word-to-word similarity measures where applied, including distributional similarity (such as (Lin, 1998)), web-based co-occurrence statistics and WordNet based similarity measures (such as (Leacock et al, 1998)). $$$$$ We are indebted to the other members of the WordNet group who have provided advice and technical support: Christiane Fellbaum, Shari Landes, and Randee Tengi.
Various word-to-word similarity measures where applied, including distributional similarity (such as (Lin, 1998)), web-based co-occurrence statistics and WordNet based similarity measures (such as (Leacock et al, 1998)). $$$$$ In his paper, Yarowsky suggests WordNet as a source for the seed collocations—a suggestion that we pursue in the next section.
Various word-to-word similarity measures where applied, including distributional similarity (such as (Lin, 1998)), web-based co-occurrence statistics and WordNet based similarity measures (such as (Leacock et al, 1998)). $$$$$ Results for the 12 pairs of homographs reported are almost perfect.

Many supervised learning algorithms have been applied for WSD, ex. Bayesian learning (Leacock et al., 1998), exemplar based learning (Ng and Lee, 1996), decision list (Yarowsky, 2000), neural network (Towel and Voorheest, 1998), maximum entropy method (Dang et al., 2002), etc. $$$$$ Yarowsky (1994), building on his earlier work, designed a classifier that looks at words within ±k positions from the target; lemma forms are obtained through morphological analysis; and a coarse part-of-speech assignment is performed by dictionary lookup.
Many supervised learning algorithms have been applied for WSD, ex. Bayesian learning (Leacock et al., 1998), exemplar based learning (Ng and Lee, 1996), decision list (Yarowsky, 2000), neural network (Towel and Voorheest, 1998), maximum entropy method (Dang et al., 2002), etc. $$$$$ The classifiers were compared using different numbers of senses (two, three, or six manually tagged senses of line) and different amounts of training material (50, 100, and 200 examples).

The simple path measure computes the similarity between a pair of nodes in WordNet as the reciprocal of the number of edges in the shortest path between them, the LChmea sure (Leacock et al, 1998) also uses information about the length of the shortest path between a pair of nodes. $$$$$ Test results are compared with those from manually tagged training examples.
The simple path measure computes the similarity between a pair of nodes in WordNet as the reciprocal of the number of edges in the shortest path between them, the LChmea sure (Leacock et al, 1998) also uses information about the length of the shortest path between a pair of nodes. $$$$$ These ratios are then arranged in a sorted decision list with the largest values (strongest evidence) first.
The simple path measure computes the similarity between a pair of nodes in WordNet as the reciprocal of the number of edges in the shortest path between them, the LChmea sure (Leacock et al, 1998) also uses information about the length of the shortest path between a pair of nodes. $$$$$ The benefits of adding topical to local context alone depend on syntactic category as well as on the characteristics of the individual word.
The simple path measure computes the similarity between a pair of nodes in WordNet as the reciprocal of the number of edges in the shortest path between them, the LChmea sure (Leacock et al, 1998) also uses information about the length of the shortest path between a pair of nodes. $$$$$ We thank Scott Wayland, Tim Allison and Jill Hollifield for tagging the serve and hard corpora.

To our knowledge, the methods of auto-acquiring sense-labeled instances include using parallel corpora like Gale et al. (1992) and Ng et al. (2003), extracting by monosemous relative of WordNet like Leacock et al. (1998), Mihalcea and Moldovan (1999), Agirre and Martínez (2004), Martínez et al. (2006) and PengYuan et al. (2008). $$$$$ Corpus-based approaches have the advantage of being generally applicable to new texts, domains, and corpora without needing costly and perhaps error-prone parsing or semantic analysis.
To our knowledge, the methods of auto-acquiring sense-labeled instances include using parallel corpora like Gale et al. (1992) and Ng et al. (2003), extracting by monosemous relative of WordNet like Leacock et al. (1998), Mihalcea and Moldovan (1999), Agirre and Martínez (2004), Martínez et al. (2006) and PengYuan et al. (2008). $$$$$ They can also be estimated from a small manually tagged sample, such as the parts of the Brown corpus that have been tagged with senses in WordNet.
To our knowledge, the methods of auto-acquiring sense-labeled instances include using parallel corpora like Gale et al. (1992) and Ng et al. (2003), extracting by monosemous relative of WordNet like Leacock et al. (1998), Mihalcea and Moldovan (1999), Agirre and Martínez (2004), Martínez et al. (2006) and PengYuan et al. (2008). $$$$$ The classifier is used to disambiguate a noun, a verb, and an adjective.

The method we applied is based on the monosemous relatives of the target words (Leacock et al, 1998), and we studied some parameters that affect the quality of the acquired corpus, such as the distribution of the number of training instances per each word sense (bias), and the type of features used for disambiguation (local vs. topical). $$$$$ A final observation we can make is that when topical and local information is combined, what we have called &quot;nontopical senses&quot; can reduce overall accuracy.
The method we applied is based on the monosemous relatives of the target words (Leacock et al, 1998), and we studied some parameters that affect the quality of the acquired corpus, such as the distribution of the number of training instances per each word sense (bias), and the type of features used for disambiguation (local vs. topical). $$$$$ One approach to this problem is to look for a word that appears in many more topical domains than its total number of senses.

In (Leacock et al, 1998), the method to obtain sense-tagged examples using monosemous relatives is presented. $$$$$ The generality of these conclusions must, of course, be tested with additional words, which brings us to the problem of obtaining training and testing corpora.
In (Leacock et al, 1998), the method to obtain sense-tagged examples using monosemous relatives is presented. $$$$$ For four of the examples in Table 5, training with relatives produced results within 1% or 2% of manually tagged training.
In (Leacock et al, 1998), the method to obtain sense-tagged examples using monosemous relatives is presented. $$$$$ This material is based upon work supported in part by the National Science Foundation under NSF Award No.
In (Leacock et al, 1998), the method to obtain sense-tagged examples using monosemous relatives is presented. $$$$$ Corpus-based approaches have the advantage of being generally applicable to new texts, domains, and corpora without needing costly and perhaps error-prone parsing or semantic analysis.

This method is inspired in (Leacock et al, 1998). $$$$$ Do the answers to these questions depend on the size of the training?
This method is inspired in (Leacock et al, 1998). $$$$$ N00014-91-1634.
This method is inspired in (Leacock et al, 1998). $$$$$ Leacock, Towel!, and Voorhees (1993) compared this Bayesian classifier with a content vector classifier as used in information retrieval and a neural network with backpropagation.
