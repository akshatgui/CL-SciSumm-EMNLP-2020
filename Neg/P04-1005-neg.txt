These steps result in an improvement of 43.98% percent relative error reduction in F-score over an earlier best result in edited detection when punctuation is included in both training and testing data [Charniak and Johnson 2001], and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004]. $$$$$ We also provide results for our noisy channel model using a bigram language model and a second trigram model where the twenty most likely analyses are rescored.
These steps result in an improvement of 43.98% percent relative error reduction in F-score over an earlier best result in edited detection when punctuation is included in both training and testing data [Charniak and Johnson 2001], and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004]. $$$$$ A syntactic parser is used as the source model, and a novel type of TAG-based transducer is the channel model.

 $$$$$ The channel model defines a conditional probability distribution P(YIX) of surface sentences Y , which may contain repairs, given source sentences.
 $$$$$ The noisy channel model using a bigram language model does a slightly worse job at identifying reparandum and interregnum words than the classifier proposed in Charniak and Johnson (2001).
 $$$$$ That approach may do so well because many speech repairs are very short, involving only one or two words Shriberg and Stolcke (1998), so the reparandum, interregnum and repair are all contained in the surrounding word window used as features by the classifier.
 $$$$$ The channel model is designed so that exact copy reparandum words will have high probability.

These steps result in a significant improvement in F-score over the earlier best result reported in [Charniak and Johnson 2001], where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004], where punctuation is ignored in both the training and testing data of the Switchboard corpus. $$$$$ The use of TAG is motivated by the intuition that the reparandum is a “rough copy” of the repair.
These steps result in a significant improvement in F-score over the earlier best result reported in [Charniak and Johnson 2001], where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004], where punctuation is ignored in both the training and testing data of the Switchboard corpus. $$$$$ This paper describes a noisy channel model of speech repairs, which can identify and correct repairs in speech transcripts.
These steps result in a significant improvement in F-score over the earlier best result reported in [Charniak and Johnson 2001], where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004], where punctuation is ignored in both the training and testing data of the Switchboard corpus. $$$$$ Replacing the bigram language model with a trigram model helps slightly, and parserbased language model results in a significant performance improvement over all of the others.
These steps result in a significant improvement in F-score over the earlier best result reported in [Charniak and Johnson 2001], where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004], where punctuation is ignored in both the training and testing data of the Switchboard corpus. $$$$$ On the other hand, it seems desirable to use a language model that is sensitive to more global properties of the sentence, and we do this by reranking the initial analysis, replacing the bigram language model with a syntactic parser based model.

When compared with the latest results from [Johnson and Charniak 2004], where no punctuations are used for either training or testing data, we also observe the same trend of the improved results. $$$$$ This more local approach has a number of advantages over computing a global analysis.
When compared with the latest results from [Johnson and Charniak 2004], where no punctuations are used for either training or testing data, we also observe the same trend of the improved results. $$$$$ Most spontaneous speech contains disfluencies such as partial words, filled pauses (e.g., “uh”, “um”, “huh”), explicit editing terms (e.g., “I mean”), parenthetical asides and repairs.
When compared with the latest results from [Johnson and Charniak 2004], where no punctuations are used for either training or testing data, we also observe the same trend of the improved results. $$$$$ This more local approach has a number of advantages over computing a global analysis.

Noisy channel models have done well on the disfluency detection task in the past; the work of Johnson and Charniak (2004) first explores such an approach. $$$$$ However, there is one additional complication that makes a marked improvement to the model’s performance.
Noisy channel models have done well on the disfluency detection task in the past; the work of Johnson and Charniak (2004) first explores such an approach. $$$$$ Finally we show the results using the parser language model.
Noisy channel models have done well on the disfluency detection task in the past; the work of Johnson and Charniak (2004) first explores such an approach. $$$$$ There are other kinds of joint models of reparandum and repair that may produce a better reparandum detection system.
Noisy channel models have done well on the disfluency detection task in the past; the work of Johnson and Charniak (2004) first explores such an approach. $$$$$ Informally, the N,,,x nonterminals indicate that the preceding word w,, was analyzed as not being part of a repair, while the R,,,y:,,,x that the preceding words wy and w,, were part of a repair.

Following Johnson and Charniak (2004), we use a noisy channel model to propose a 25-best list of possible speech disfluency analyses. $$$$$ On the other hand, the probabilistic model of repairs explored here seems to be most successful in identifying long repairs in which the reparandum and repair are similar enough to be unlikely to have been generated independently.
Following Johnson and Charniak (2004), we use a noisy channel model to propose a 25-best list of possible speech disfluency analyses. $$$$$ The use of TAG is motivated by the intuition that the reparandum is a “rough copy” of the repair.
Following Johnson and Charniak (2004), we use a noisy channel model to propose a 25-best list of possible speech disfluency analyses. $$$$$ The corpus also includes punctuation and partial words, which are ignored in both training and evaluation here since we felt that in realistic applications these would not be available in speech recognizer output.

Further details of the noisy channel model can be found in Johnson and Charniak (2004). $$$$$ This paper describes a noisy channel model of speech repairs, which can identify and correct repairs in speech transcripts.
Further details of the noisy channel model can be found in Johnson and Charniak (2004). $$$$$ We have experimented with versions of the models described above based on POS bi-tag dependencies rather than word bigram dependencies, but with results very close to those presented here.
Further details of the noisy channel model can be found in Johnson and Charniak (2004). $$$$$ Even though our sentences are often long, it is extremely unlikely that any repair will be longer than, say, 12 words.
Further details of the noisy channel model can be found in Johnson and Charniak (2004). $$$$$ There are two innovations in this paper.

To improve performance over the standard noisy channel model we use a re-ranker, as previously suggest by Johnson and Charniak (2004). $$$$$ (We do insist that the reparandum and interregnum of a repair do not overlap with those of any other repairs in the same analysis).
To improve performance over the standard noisy channel model we use a re-ranker, as previously suggest by Johnson and Charniak (2004). $$$$$ Replacing the bigram language model with a trigram model helps slightly, and parserbased language model results in a significant performance improvement over all of the others.
To improve performance over the standard noisy channel model we use a re-ranker, as previously suggest by Johnson and Charniak (2004). $$$$$ This algorithm has n5 running time, where n is the length of the string.

As Johnson and Charniak (2004) noted, although this model performs well, a log linear re-ranker can be used to increase performance. $$$$$ As mentioned earlier, following Charniak and Johnson (2001) our test data consisted of all Penn III Switchboard tree-bank sw4[01]*.mrg files.
As Johnson and Charniak (2004) noted, although this model performs well, a log linear re-ranker can be used to increase performance. $$$$$ While we did not evaluate the quality of the alignments since they are not in themselves the object of this exercise, they seem to be fairly good.
As Johnson and Charniak (2004) noted, although this model performs well, a log linear re-ranker can be used to increase performance. $$$$$ That is, the model is used to classify each word in the sentence as belonging to a reparandum or not, and all other additional structure produced by the model is ignored.
As Johnson and Charniak (2004) noted, although this model performs well, a log linear re-ranker can be used to increase performance. $$$$$ Finally we show the results using the parser language model.

 $$$$$ For every such substring that can be analyzed as a repair we calculate the repair odds, i.e., the probability of generating this substring as a repair divided by the probability of generating this substring via the non-repair rules, or equivalently, the odds that this substring constitutes a repair.
 $$$$$ Heeman and Allen (1999) describe a noisy channel model of speech repairs, but leave “extending the model to incorporate higher level syntactic ... processing” to future work.
 $$$$$ Figure 2 shows the combined model’s dependency structure for the repair of Figure 1.

In this work, we use a total of 62 variables, which include 16 variables from Charniak and Johnson (2001) and Johnson and Charniak (2004), an additional 29 variables from Zhang and Weng (2005), 11 hierarchical POS tag variables, and 8 prosody variables (labels and their confidence scores). $$$$$ The noisy channel model using a bigram language model does a slightly worse job at identifying reparandum and interregnum words than the classifier proposed in Charniak and Johnson (2001).
In this work, we use a total of 62 variables, which include 16 variables from Charniak and Johnson (2001) and Johnson and Charniak (2004), an additional 29 variables from Zhang and Weng (2005), 11 hierarchical POS tag variables, and 8 prosody variables (labels and their confidence scores). $$$$$ There are other kinds of joint models of reparandum and repair that may produce a better reparandum detection system.

Because the edit region identification results on the original Switchboard are not directly comparable with the results on the newly segmented data, the state-of-art results reported by Charniak and Johnson (2001) and Johnson and Charniak (2004) are repeated on this new corpus by Kahn et al (2005). $$$$$ The rest of this paper is structured as follows.
Because the edit region identification results on the original Switchboard are not directly comparable with the results on the newly segmented data, the state-of-art results reported by Charniak and Johnson (2001) and Johnson and Charniak (2004) are repeated on this new corpus by Kahn et al (2005). $$$$$ This algorithm has n5 running time, where n is the length of the string.
Because the edit region identification results on the original Switchboard are not directly comparable with the results on the newly segmented data, the state-of-art results reported by Charniak and Johnson (2001) and Johnson and Charniak (2004) are repeated on this new corpus by Kahn et al (2005). $$$$$ Shriberg and Stolcke (1998) studied the location and distribution of repairs in the Switchboard corpus, but did not propose an actual model of repairs.
Because the edit region identification results on the original Switchboard are not directly comparable with the results on the newly segmented data, the state-of-art results reported by Charniak and Johnson (2001) and Johnson and Charniak (2004) are repeated on this new corpus by Kahn et al (2005). $$$$$ There are two innovations in this paper.

Speech is often disfluent, and speech repairs are known to repeat large portions of the preceding context (Johnson and Charniak, 2004). $$$$$ Shriberg and Stolcke (1998) studied the location and distribution of repairs in the Switchboard corpus, but did not propose an actual model of repairs.
Speech is often disfluent, and speech repairs are known to repeat large portions of the preceding context (Johnson and Charniak, 2004). $$$$$ This paper describes a noisy channel model of speech repairs, which can identify and correct repairs in speech transcripts.
Speech is often disfluent, and speech repairs are known to repeat large portions of the preceding context (Johnson and Charniak, 2004). $$$$$ For comparison we include the results of running the word-by-word classifier described in Charniak and Johnson (2001), but where partial words and punctuation have been removed from the training and test data.

The evaluation of this system was performed on the Switchboard corpus, using the mrg annotations in directories 2 and 3 for training, and the filessw4004.mrg to sw4153.mrg in directory 4 for evaluation, following Johnson and Charniak (2004). $$$$$ Languages with an unbounded number of crossed dependencies cannot be described by a context-free or finitestate grammar, and crossed dependencies like these have been used to argue natural languages ... a flight to Boston, uh, I mean, to Denver on Friday ... are not context-free Shieber (1985).
The evaluation of this system was performed on the Switchboard corpus, using the mrg annotations in directories 2 and 3 for training, and the filessw4004.mrg to sw4153.mrg in directory 4 for evaluation, following Johnson and Charniak (2004). $$$$$ Most spontaneous speech contains disfluencies such as partial words, filled pauses (e.g., “uh”, “um”, “huh”), explicit editing terms (e.g., “I mean”), parenthetical asides and repairs.
The evaluation of this system was performed on the Switchboard corpus, using the mrg annotations in directories 2 and 3 for training, and the filessw4004.mrg to sw4153.mrg in directory 4 for evaluation, following Johnson and Charniak (2004). $$$$$ That approach may do so well because many speech repairs are very short, involving only one or two words Shriberg and Stolcke (1998), so the reparandum, interregnum and repair are all contained in the surrounding word window used as features by the classifier.

The TAG system (Johnson and Charniak, 2004) achieves a higher EDIT-F score, largely as a result of its explicit tracking of overlapping words between reparanda and alterations. $$$$$ First, as just noted it is much more efficient to compute these partial analyses rather than to compute global analyses of the entire sentence.
The TAG system (Johnson and Charniak, 2004) achieves a higher EDIT-F score, largely as a result of its explicit tracking of overlapping words between reparanda and alterations. $$$$$ So to increase processing speed we only compute analyses for strings of length 12 or less.
The TAG system (Johnson and Charniak, 2004) achieves a higher EDIT-F score, largely as a result of its explicit tracking of overlapping words between reparanda and alterations. $$$$$ One way to guarantee this is to use a finite state language model; this motivates our use of a bigram language model.

The prior probability distributions over alignment operations is estimated from data in the Switchboard in a similar manner to Johnson and Charniak (2004). $$$$$ For comparison we include the results of running the word-by-word classifier described in Charniak and Johnson (2001), but where partial words and punctuation have been removed from the training and test data.
The prior probability distributions over alignment operations is estimated from data in the Switchboard in a similar manner to Johnson and Charniak (2004). $$$$$ The channel model is a stochastic TAG-based transducer; it is responsible for generating the repairs in the transcript Y , and it uses the ability of TAGs to straightforwardly model crossed dependencies.
The prior probability distributions over alignment operations is estimated from data in the Switchboard in a similar manner to Johnson and Charniak (2004). $$$$$ As mentioned earlier, following Charniak and Johnson (2001) our test data consisted of all Penn III Switchboard tree-bank sw4[01]*.mrg files.
The prior probability distributions over alignment operations is estimated from data in the Switchboard in a similar manner to Johnson and Charniak (2004). $$$$$ One of the advantages of probabilistic models is that they can be integrated with other probabilistic models in a principled way, and it would be interesting to investigate how to integrate this kind of model of speech repairs with probabilistic speech recognizers.

Given that state-of-the-art edit detection performs at about 80% f-measure (Johnson and Charniak, 2004), much of the benefit derived here from oracle repair detection should be realizable in practice. $$$$$ The resulting stochastic TAG is in fact exactly the intersection of the channel model TAG with a bigram language model.
Given that state-of-the-art edit detection performs at about 80% f-measure (Johnson and Charniak, 2004), much of the benefit derived here from oracle repair detection should be realizable in practice. $$$$$ On the other hand, the probabilistic model of repairs explored here seems to be most successful in identifying long repairs in which the reparandum and repair are similar enough to be unlikely to have been generated independently.
Given that state-of-the-art edit detection performs at about 80% f-measure (Johnson and Charniak, 2004), much of the benefit derived here from oracle repair detection should be realizable in practice. $$$$$ The model is trained and tested on the Switchboard disfluency-annotated corpus.

The Johnson and Charniak (2004) approach, referred to in this document as JC04, combines the noisy channel paradigm with a tree-adjoining grammar (TAG) to capture approximately repeated elements. $$$$$ Still, more sophisticated models may yield better performance.
The Johnson and Charniak (2004) approach, referred to in this document as JC04, combines the noisy channel paradigm with a tree-adjoining grammar (TAG) to capture approximately repeated elements. $$$$$ That approach may do so well because many speech repairs are very short, involving only one or two words Shriberg and Stolcke (1998), so the reparandum, interregnum and repair are all contained in the surrounding word window used as features by the classifier.
The Johnson and Charniak (2004) approach, referred to in this document as JC04, combines the noisy channel paradigm with a tree-adjoining grammar (TAG) to capture approximately repeated elements. $$$$$ Each different parse of the observed string Y with this grammar corresponds to a way of analyzing Y in terms of a hypothetical underlying sentence X and a number of different repairs.

The output of the JC04 model (Johnson and Charniak, 2004) is included as a feature and used as an approximate baseline in the following experiments. $$$$$ A string Z in this language can be interpreted as a pair of strings (Y, X), where Y is the concatenation of the projection of the first components of Z and X is the concatenation of the projection of the second components.
The output of the JC04 model (Johnson and Charniak, 2004) is included as a feature and used as an approximate baseline in the following experiments. $$$$$ This section describes how we evaluate our noisy model.
The output of the JC04 model (Johnson and Charniak, 2004) is included as a feature and used as an approximate baseline in the following experiments. $$$$$ However, there is one additional complication that makes a marked improvement to the model’s performance.

The training of the TAG model within this system requires a very specific data format, so this system is trained not with SSR but with Switchboard (SWBD) (Godfrey et al, 1992) data as described in (Johnson and Charniak, 2004). $$$$$ Most spontaneous speech contains disfluencies such as partial words, filled pauses (e.g., “uh”, “um”, “huh”), explicit editing terms (e.g., “I mean”), parenthetical asides and repairs.
The training of the TAG model within this system requires a very specific data format, so this system is trained not with SSR but with Switchboard (SWBD) (Godfrey et al, 1992) data as described in (Johnson and Charniak, 2004). $$$$$ The use of TAG is motivated by the intuition that the reparandum is a “rough copy” of the repair.
The training of the TAG model within this system requires a very specific data format, so this system is trained not with SSR but with Switchboard (SWBD) (Godfrey et al, 1992) data as described in (Johnson and Charniak, 2004). $$$$$ A single global analysis would not be able to capture this (since the TAG channel model does not permit the same substring to be both a reparandum and a repair), but we combine these overlapping repair substring analyses in a post-processing operation to yield an analysis of the whole sentence.
