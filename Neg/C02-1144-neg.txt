Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals). $$$$$ However, they often include many rare senses while missing domain-specific senses.
Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals). $$$$$ It discovers clusters using well scattered tight clusters called committees.
Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals). $$$$$ 3.
Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals). $$$$$ If the word handgun occurred in this context, the context is a feature of handgun.

NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ The parameters K and T are usually considered to be small numbers.
NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ The centroid of the members of a committee is used as the feature vector of the cluster.
NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ Evaluating cluster quality has always been a difficult task.
NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ The complexity of these algorithms is O(n2logn), where n is the number of elements to be clustered (Jain, Murty, Flynn 1999).

The labeled classes are acquired in three stages $$$$$ Using a single representative from a cluster may be problematic too because each individual element has its own idiosyncrasies that may not be shared by other members of the cluster.
The labeled classes are acquired in three stages $$$$$ Let C be a set of clusters and A be the answer key.
The labeled classes are acquired in three stages $$$$$ Phase III: Assign elements to clusters.
The labeled classes are acquired in three stages $$$$$ Since SemCor is a fairly small corpus, the frequency counts of the synsets in the lower part of the WordNet hierarchy are very sparse.

 $$$$$ For example, ?threaten with __?
 $$$$$ Here is the consumer class in WordNet 1.5: addict, alcoholic, big spender, buyer, client, concert-goer, consumer, customer, cutter, diner, drinker, drug addict, drug user, drunk, eater, feeder, fungi, head, heroin addict, home buyer, junkie, junky, lush, nonsmoker, patron, policy holder, purchaser, reader, regular, shopper, smoker, spender, subscriber, sucker, taker, user, vegetarian, wearer In our cluster, only the word client belongs to WordNet?s consumer class.
 $$$$$ Step 4 terminates the recursion if no committee is found in the previous step.
 $$$$$ We present a clustering algorithm called CBC (Cluster ing By Committee) that automatically discovers concepts from text.

For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002). $$$$$ Test Data.
For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002). $$$$$ In Phase I, we compute each element?s top-k similar elements.
For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002). $$$$$ One way to deal with these problems is to use a clustering algorithm to automatically induce semantic classes (Lin and Pantel 2001).
For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002). $$$$$ In Phase III, every element is assigned to the cluster containing the committee to which it is most similar.

(Schutze, 1998) and (Lin and Pantel, 2002a, b) show that clustering methods are helpful in this area. $$$$$ We proceed by assigning elements to their most similar cluster.
(Schutze, 1998) and (Lin and Pantel, 2002a, b) show that clustering methods are helpful in this area. $$$$$ It can handle a large number of elements, a large number of output clusters, and a large sparse feature space.
(Schutze, 1998) and (Lin and Pantel, 2002a, b) show that clustering methods are helpful in this area. $$$$$ We presented a clustering algorithm, CBC, for automatically discovering concepts from text.
(Schutze, 1998) and (Lin and Pantel, 2002a, b) show that clustering methods are helpful in this area. $$$$$ We therefore multiplied miw,c with a discounting factor: ( ) ( ) ( ) ( ) ( ) ( ) 11 +???

Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ We used a sample size of 2000 for Buckshot.
Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ is a context.
Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ We presented a clustering algorithm, CBC, for automatically discovering concepts from text.
Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ The centroid of the members of a committee is used as the feature vector of the cluster.

Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002). $$$$$ The residue elements are identified in Step 5 and if no residues are found, the algorithm terminates; otherwise, we recursively apply the algorithm to the residue elements.
Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002). $$$$$ However, this may cause undesirable mergers when there are a large number of pairs whose similarities barely exceed the threshold.
Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002). $$$$$ K-means has complexity O(K?T?n) and is efficient for many clustering tasks.

 $$$$$ This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338 and scholarship PGSB207797.
 $$$$$ However, in the newspaper corpus, the Person sense of dog is at best extremely rare.
 $$$$$ i j i jF is the total frequency counts of all words and their contexts.

 $$$$$ =, where N = ( )??
 $$$$$ They generally fall under two categories: ? comparing cluster outputs with manually generated answer keys (hereon referred to as classes); or ? embedding the clusters in an application and using its evaluation measure.
 $$$$$ By comparing the CBC clusters with WordNet classes, we not only find errors in CBC, but also oversights in WordNet.
 $$$$$ Some sets of initial centroids lead to poor convergence rates or poor cluster quality.

To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ A well known problem with mutual information is that it is biased towards infrequent words/features.
To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ Our experiments show that CBC outperforms several well-known clustering algorithms in cluster quality.
To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ Phase I: Find top-similar elements.
To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ We made the assumption that each element belongs to exactly one cluster.

To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents. $$$$$ We introduce a new evaluation methodol ogy that is based on the editing distance between output clusters and classes extracted from WordNet (the answer key).
To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents. $$$$$ Evaluating cluster quality has always been a difficult task.
To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents. $$$$$ Using a single representative from a cluster may be problematic too because each individual element has its own idiosyncrasies that may not be shared by other members of the cluster.
To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents. $$$$$ The words blend and mix as the event of mixing are present in WordNet but not as the result of mixing.

Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002). $$$$$ We made the assumption that each element belongs to exactly one cluster.
Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002). $$$$$ =, where N = ( )??
