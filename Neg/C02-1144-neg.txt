Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals). $$$$$ For example, in one experiment, CBC outperforms K-means by 4.25%.
Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals). $$$$$ Table 1 summa rizes the test sets.
Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals). $$$$$ There is no reason to expect a clustering algorithm to discover this sense of dog.

NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ We constructed two test sets: S13403 consisting of 13403 words (m = 250) and S3566 consisting of 3566 words (m = 3500).
NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ Chameleon is a hierarchical algorithm that employs dynamic modeling to improve clustering quality (Karypis, Han, Kumar 1999).
NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ Acknowledgements The authors wish to thank the reviewers for their helpful comments.
NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). $$$$$ We used Minipar 1 (Lin 1994), a broad coverage English parser, to parse about 1GB (144M words) of newspaper text from the TREC collection (1988 AP Newswire, 1989-90 LA Times, and 1991 San Jose Mercury) at a speed of about 500 words/second on a PIII-750 with 512MB memory.

The labeled classes are acquired in three stages: 1) extraction of a noisy pool of pairs of a class label and a potential class instance, by applying a few Is-A extraction patterns, selected from (Hearst, 1992), to Web documents: (fruits, apple), (fruits, corn), (fruits, mango), (fruits, orange), (foods, broccoli), (crops, lettuce), (flowers, rose); 2) extraction of unlabeled clusters of distributionally similar phrases, by clustering vectors of contextual features collected around the occurrences of the phrases within Web documents (Lin and Pantel, 2002). $$$$$ This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338 and scholarship PGSB207797.
The labeled classes are acquired in three stages: 1) extraction of a noisy pool of pairs of a class label and a potential class instance, by applying a few Is-A extraction patterns, selected from (Hearst, 1992), to Web documents: (fruits, apple), (fruits, corn), (fruits, mango), (fruits, orange), (foods, broccoli), (crops, lettuce), (flowers, rose); 2) extraction of unlabeled clusters of distributionally similar phrases, by clustering vectors of contextual features collected around the occurrences of the phrases within Web documents (Lin and Pantel, 2002). $$$$$ For example, in WordNet, the words dog, computer and company all have a sense that is a hyponym of person.
The labeled classes are acquired in three stages: 1) extraction of a noisy pool of pairs of a class label and a potential class instance, by applying a few Is-A extraction patterns, selected from (Hearst, 1992), to Web documents: (fruits, apple), (fruits, corn), (fruits, mango), (fruits, orange), (foods, broccoli), (crops, lettuce), (flowers, rose); 2) extraction of unlabeled clusters of distributionally similar phrases, by clustering vectors of contextual features collected around the occurrences of the phrases within Web documents (Lin and Pantel, 2002). $$$$$ We presented a clustering algorithm, CBC, for automatically discovering concepts from text.

 $$$$$ Using a single representative from a cluster may be problematic too because each individual element has its own idiosyncrasies that may not be shared by other members of the cluster.
 $$$$$ As a result, the centroid contains only features like those in List A. Evaluating clustering results is a very difficult task.
 $$$$$ As a result, the centroid contains only features like those in List A. Evaluating clustering results is a very difficult task.
 $$$$$ We say a committee covers an element if the element?s similarity to the centroid of the committee exceeds some high similarity threshold.

For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002). $$$$$ They generally fall under two categories: ? comparing cluster outputs with manually generated answer keys (hereon referred to as classes); or ? embedding the clusters in an application and using its evaluation measure.
For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002). $$$$$ Each feature corresponds to a context in which the word occurs.
For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002). $$$$$ If c?s similarity to the centroid of each committee previously added to C is be low a threshold ?1, add c to C. Step 4: If C is empty, we are done and return C. Step 5: For each element e ? E If e?s similarity to every committee in C is below threshold ?2, add e to a list of resi dues R. Step 6: If R is empty, we are done and return C. Otherwise, return the union of C and the output of a recursive call to Phase II us ing the same input except replacing E with R. Output: A list of committees.

(Schutze, 1998) and (Lin and Pantel, 2002a, b) show that clustering methods are helpful in this area. $$$$$ We presented a clustering algorithm, CBC, for automatically discovering concepts from text.
(Schutze, 1998) and (Lin and Pantel, 2002a, b) show that clustering methods are helpful in this area. $$$$$ Splitting a cluster consists of applying the basic K-means algorithm ? times with K=2 and keeping the split that has the highest average element centroid similarity.

Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ For example, when clustering words, we can use the contexts of the words as features and group together the words that tend to appear in similar contexts.
Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006). $$$$$ The parameters K and T are usually considered to be small numbers.

Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002). $$$$$ Unlike K-means, the number of clusters is not fixed and the centroids do not change (i.e. when an element is added to a cluster, it is not added to the committee of the cluster).
Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002). $$$$$ Hybrid clustering algorithms combine hierarchical and partitional algorithms in an attempt to have the high quality of hierarchical algorithms with the efficiency of partitional algorithms.
Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002). $$$$$ =, where N = ( )??
Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002). $$$$$ We present a clustering algorithm called CBC (Cluster ing By Committee) that automatically discovers concepts from text.

 $$$$$ is a context.
 $$$$$ A) The classes in the answer key; B) the clusters to be transformed; C) the sets used to reconstruct the classes (Rule 1); D) the sets after three merge operations (Step 2); E) the sets after one move operation (Step 3).
 $$$$$ We present a clustering algorithm called CBC (Cluster ing By Committee) that automatically discovers concepts from text.
 $$$$$ The words stopwatch and houseplant do not belong to the clusters but they have low similarity to their cluster centroid.

 $$$$$ 6.2.
 $$$$$ Acknowledgements The authors wish to thank the reviewers for their helpful comments.
 $$$$$ K-means has complexity O(K?T?n) and is efficient for many clustering tasks.
 $$$$$ However, they often include many rare senses while missing domain-specific senses.

To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338 and scholarship PGSB207797.
To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ In Phase I, we compute each element?s top-k similar elements.
To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ For example, in one experiment, CBC outperforms K-means by 4.25%.
To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990). $$$$$ In each recursive step, the algorithm finds a set of tight clusters, called committees, and identifies residue elements that are not covered by any committee.

To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents. $$$$$ It can handle a large number of elements, a large number of output clusters, and a large sparse feature space.
To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents. $$$$$ In this paper, we propose a clustering algo rithm, CBC (Clustering By Committee), in which the centroid of a cluster is constructed by averaging the feature vectors of a subset of the cluster members.
To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents. $$$$$ Our experiments show that CBC outperforms several well-known clustering algorithms in cluster quality.

Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002). $$$$$ 6.3.
Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002). $$$$$ Input: A list of elements E to be clustered, a similarity database S from Phase I, thresh olds ?1 and ?2.
Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002). $$$$$ However, in the newspaper corpus, the Person sense of dog is at best extremely rare.
Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002). $$$$$ Our experiments show that CBC outperforms several well-known clustering algorithms in cluster quality.
