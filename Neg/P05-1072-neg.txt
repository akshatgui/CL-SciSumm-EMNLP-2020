In Pradhan et al (2005), we reported on a first attempt to overcome this problem by combining semantic role labels produced from different syntactic parses. $$$$$ In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.
In Pradhan et al (2005), we reported on a first attempt to overcome this problem by combining semantic role labels produced from different syntactic parses. $$$$$ All of the reported techniques resulted in performance improvements.
In Pradhan et al (2005), we reported on a first attempt to overcome this problem by combining semantic role labels produced from different syntactic parses. $$$$$ For our experiments, we use Feb 2004 release of PropBank1 (Kingsbury and Palmer, 2002; Palmer et al., 2005), a corpus in which predicate argument relations are marked for verbs in the Wall Street Journal (WSJ) part of the Penn TreeBank (Marcus et al., 1994).

Pradhan et al (2005) combined systems that are based on phrase-structure parsing, dependency parsing, and shallow parsing. $$$$$ We show that these three views complement each other to improve performance.
Pradhan et al (2005) combined systems that are based on phrase-structure parsing, dependency parsing, and shallow parsing. $$$$$ Since the feature selection experiments were computationally intensive, we performed them using 10k training examples.
Pradhan et al (2005) combined systems that are based on phrase-structure parsing, dependency parsing, and shallow parsing. $$$$$ Error analysis of the baseline system showed that approximately half of the argument identification errors resulted from parse errors in which there was no syntactic constituent that aligned with the correct argument.
Pradhan et al (2005) combined systems that are based on phrase-structure parsing, dependency parsing, and shallow parsing. $$$$$ One using the correct CCG parses, and the other using parses obtained using StatCCG4 parser (Hockenmaier and Steedman, 2002).

 $$$$$ We analyze the performance on three tasks: Table 2 shows the performance of the system using the hand corrected, TreeBank parses (HAND) and using parses produced by a Charniak parser (AUTOMATIC).
 $$$$$ While the Path feature has been identified to be very important for the argument identification task, it is one of the most sparse features and may be difficult to train or generalize (Pradhan et al., 2004; Xue and Palmer, 2004).
 $$$$$ Relatively few predicates, 107 out of 4500, were affected by this combination.

 $$$$$ Using what is known as the ONE VS ALL classification strategy, n binary classifiers are trained, where n is number of semantic classes including a NULL class.
 $$$$$ This research was partially supported by the ARDA AQUAINT program via contract OCG4423B and by the NSF via grants IS-9978025 and ITR/HCI 0086132.

However, (Pradhan et al., 2005a) uses some additional information since it deals with incorrect parser output by using multiple parsers. $$$$$ We pruned this set by training classifiers after leaving out one feature at a time and checking its performance on a development set.
However, (Pradhan et al., 2005a) uses some additional information since it deals with incorrect parser output by using multiple parsers. $$$$$ We performed two sets of experiments.
However, (Pradhan et al., 2005a) uses some additional information since it deals with incorrect parser output by using multiple parsers. $$$$$ The probabilities resulting from either conversions may not be properly calibrated.
However, (Pradhan et al., 2005a) uses some additional information since it deals with incorrect parser output by using multiple parsers. $$$$$ The main contribution of combining both the Minipar based and the Charniak-based parsers was significantly improved performance on ARG1 in addition to slight improvements to some other arguments.

 $$$$$ For each argument, we started with the set of features introduced by (Gildea and Jurafsky, 2002).
 $$$$$ Minipar is a rule based dependency parser.
 $$$$$ In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.
 $$$$$ In the test set, about 37% of the arguments do not have corresponding constituents that match its boundaries.

 $$$$$ Gildea and Hockenmaier (2003) report that using features extracted from a Combinatory Categorial Grammar (CCG) representation improves semantic labeling performance on core arguments.
 $$$$$ The results for this system are shown in Table 9. on the PropBank training data.
 $$$$$ This system uses SVM classifiers to first chunk input text into flat chunks or base phrases, each labeled with a syntactic tag.
 $$$$$ The changes fell into three categories: i) new features, ii) feature selection and calibration, and iii) combining parses from different syntactic representations.

 $$$$$ We made a number of changes to the system which resulted in improved performance.
 $$$$$ A 5-token sliding window is used for the context.
 $$$$$ We combined the semantic parses as follows: i) scores for arguments were converted to calibrated probabilities, and arguments with scores below a threshold value were deleted.

In (Pradhan et al, 2005b), some experiments were conducted on SRL systems trained using different syntactic views. $$$$$ A simple combination of these representations did lead to improved performance.
In (Pradhan et al, 2005b), some experiments were conducted on SRL systems trained using different syntactic views. $$$$$ The architecture underlying all of these systems introduces two distinct sub-problems: the identification of syntactic constituents that are semantic roles for a given predicate, and the labeling of the those constituents with the correct semantic role.
In (Pradhan et al, 2005b), some experiments were conducted on SRL systems trained using different syntactic views. $$$$$ The architecture underlying all of these systems introduces two distinct sub-problems: the identification of syntactic constituents that are semantic roles for a given predicate, and the labeling of the those constituents with the correct semantic role.
In (Pradhan et al, 2005b), some experiments were conducted on SRL systems trained using different syntactic views. $$$$$ In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.

More details of this system can be found in Pradhan et al, (2005). $$$$$ The set of words under each node in Minipar’s dependency tree form a contiguous segment in the original sentence and correspond to the constituent in a constituent tree.
More details of this system can be found in Pradhan et al, (2005). $$$$$ The belief was that semantic parses based on different syntactic views would make different errors and that the combination would be complimentary.
More details of this system can be found in Pradhan et al, (2005). $$$$$ We investigate ways to combine hypotheses generated from semantic role taggers trained using different syntactic views – one trained using the Charniak parser (Charniak, 2000), another on a rule-based dependency parser – Minipar (Lin, 1998), and a third based on a flat, shallow syntactic chunk representation (Hacioglu, 2004a).
More details of this system can be found in Pradhan et al, (2005). $$$$$ The corresponding baseline performances are mentioned in parentheses.

To solve these errors, we need to explore more, such as using n-best parses and the use of several syntactic views (Pradhan et al, 2005b). $$$$$ On the other hand, the system’s performance on the identification task is quite a bit lower, achieving only 80% recall with 86% precision.
To solve these errors, we need to explore more, such as using n-best parses and the use of several syntactic views (Pradhan et al, 2005b). $$$$$ All of the reported techniques resulted in performance improvements.
To solve these errors, we need to explore more, such as using n-best parses and the use of several syntactic views (Pradhan et al, 2005b). $$$$$ Precision (P), Recall (R) and F1 scores are given for the identification and combined tasks, and Classification Accuracy (A) for the classification task.

Some other work paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ We would like to thank Ralph Weischedel and Scott Miller of BBN Inc. for letting us use their named entity tagger – IdentiFinder; Martha Palmer for providing us with the PropBank data; Dan Gildea and Julia Hockenmaier for providing the gold standard CCG parser information, and all the anonymous reviewers for their helpful comments.
Some other work paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ This research was partially supported by the ARDA AQUAINT program via contract OCG4423B and by the NSF via grants IS-9978025 and ITR/HCI 0086132.
Some other work paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ We combined semantic parses from a Minipar syntactic parse and from a chunked syntactic representation with our original baseline system which was based on Charniak parses.
Some other work paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ On the other hand, the system’s performance on the identification task is quite a bit lower, achieving only 80% recall with 86% precision.

Kernel Setup: We use the Constituent, Predicate, and Predicate-Constituent related features, which are reported to get the best-reported performance (Pradhan et al, 2005a), as the baseline features. $$$$$ We added several other features to the system.
Kernel Setup: We use the Constituent, Predicate, and Predicate-Constituent related features, which are reported to get the best-reported performance (Pradhan et al, 2005a), as the baseline features. $$$$$ This research was partially supported by the ARDA AQUAINT program via contract OCG4423B and by the NSF via grants IS-9978025 and ITR/HCI 0086132.
Kernel Setup: We use the Constituent, Predicate, and Predicate-Constituent related features, which are reported to get the best-reported performance (Pradhan et al, 2005a), as the baseline features. $$$$$ Computer time was provided by NSF ARI Grant #CDA-9601817, NSF MRI Grant #CNS0420873, NASA AIST grant #NAG2-1646, DOE SciDAC grant #DE-FG02-04ER63870, NSF sponsorship of the National Center for Atmospheric Research, and a grant from the IBM Shared University Research (SUR) program.
Kernel Setup: We use the Constituent, Predicate, and Predicate-Constituent related features, which are reported to get the best-reported performance (Pradhan et al, 2005a), as the baseline features. $$$$$ The probabilities resulting from either conversions may not be properly calibrated.

 $$$$$ We described a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.
 $$$$$ One using the correct CCG parses, and the other using parses obtained using StatCCG4 parser (Hockenmaier and Steedman, 2002).
 $$$$$ Table 1 lists the features used.
 $$$$$ Since the feature selection experiments were computationally intensive, we performed them using 10k training examples.

Some other works paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ The belief was that semantic parses based on different syntactic views would make different errors and that the combination would be complimentary.
Some other works paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.
Some other works paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ The system is trained SVMs were trained for begin (B) and inside (I) classes of all arguments and outside (O) class for a total of 78 one-vs-all classifiers.
Some other works paid much attention to the robust SRL (Pradhan et al, 2005b) and post inference (Punyakanok et al, 2004). $$$$$ We combined the semantic parses as follows: i) scores for arguments were converted to calibrated probabilities, and arguments with scores below a threshold value were deleted.

Pradhan et al (2005) combine the outputs of multiple parsers to extract reliable syntactic information, which is translated into features for a machine learning experiment in assigning semantic roles. $$$$$ The hope is that these parsers will produce different errors than the Charniak parser since they represent different syntactic views.
Pradhan et al (2005) combine the outputs of multiple parsers to extract reliable syntactic information, which is translated into features for a machine learning experiment in assigning semantic roles. $$$$$ In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.
Pradhan et al (2005) combine the outputs of multiple parsers to extract reliable syntactic information, which is translated into features for a machine learning experiment in assigning semantic roles. $$$$$ Semantic role labeling is the process of annotating the predicate-argument structure in text with semantic labels.
Pradhan et al (2005) combine the outputs of multiple parsers to extract reliable syntactic information, which is translated into features for a machine learning experiment in assigning semantic roles. $$$$$ In case of chunks, first word in prepositional base phrases was selected as the head word, and for all other chunks, the last word was selected to be the head word.

Most state-of-the-art methods for the latter two tasks use a cascaded architecture: they employ syntactic parsers and re-cast the corresponding tasks as pattern matching (Johnson, 2002) or classification (Pradhan et al, 2005) problems. $$$$$ The baseline feature set is a combination of features introduced by Gildea and Jurafsky (2002) and ones proposed in Pradhan et al., (2004), Surdeanu et al., (2003) and the syntactic-frame feature proposed in (Xue and Palmer, 2004).
Most state-of-the-art methods for the latter two tasks use a cascaded architecture: they employ syntactic parsers and re-cast the corresponding tasks as pattern matching (Johnson, 2002) or classification (Pradhan et al, 2005) problems. $$$$$ Error analysis showed that some features specifically suited for one argument class, for example, core arguments, tend to hurt performance on some adjunctive arguments.
Most state-of-the-art methods for the latter two tasks use a cascaded architecture: they employ syntactic parsers and re-cast the corresponding tasks as pattern matching (Johnson, 2002) or classification (Pradhan et al, 2005) problems. $$$$$ We used the x2 significance while making pruning decisions.
Most state-of-the-art methods for the latter two tasks use a cascaded architecture: they employ syntactic parsers and re-cast the corresponding tasks as pattern matching (Johnson, 2002) or classification (Pradhan et al, 2005) problems. $$$$$ The results for this are shown in Table 14.

 $$$$$ The architecture underlying all of these systems introduces two distinct sub-problems: the identification of syntactic constituents that are semantic roles for a given predicate, and the labeling of the those constituents with the correct semantic role.
 $$$$$ A second SVM is trained to assign semantic labels to the chunks.
 $$$$$ In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers.

In Table 4 we compare our system for semantic roles labeling with the output of Charniak's parser to the state-of-the-art system of (Pradhan et al, 2005). $$$$$ PropBank was constructed by assigning semantic arguments to constituents of handcorrected TreeBank parses.
In Table 4 we compare our system for semantic roles labeling with the output of Charniak's parser to the state-of-the-art system of (Pradhan et al, 2005). $$$$$ All the new features are shown in
In Table 4 we compare our system for semantic roles labeling with the output of Charniak's parser to the state-of-the-art system of (Pradhan et al, 2005). $$$$$ The probability assigned to the begin tag of an argument was used as the probability of the sequence of chunks forming an argument.
In Table 4 we compare our system for semantic roles labeling with the output of Charniak's parser to the state-of-the-art system of (Pradhan et al, 2005). $$$$$ This research was partially supported by the ARDA AQUAINT program via contract OCG4423B and by the NSF via grants IS-9978025 and ITR/HCI 0086132.

 $$$$$ We made a number of changes to the system which resulted in improved performance.
 $$$$$ To give an idea of what the potential improvements of the combinations could be, we performed an oracle experiment for a combined system that tags head words instead of exact constituents as we did in case of Minipar-based and Charniak-based semantic parser earlier.
 $$$$$ On the other hand, argument identification performance using Charniak parses is about 12.7% absolute worse.
