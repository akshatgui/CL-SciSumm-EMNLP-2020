 $$$$$ We call this system Single Malt, to emphasize the fact that it consists of a single instance of MaltParser.
 $$$$$ Section 4 gives a brief analysis of the experimental results, and section 5 concludes.
 $$$$$ Special thanks to Ryan McDonald, for fruitful discussions and assistance with the error analysis, and to Kenji Sagae, for showing us how to produce a good blend.
 $$$$$ The remaining 10% of the data was in both cases saved for a final dry run, where the parser was trained on 90% of the data for each language and tested on the remaining (fresh) 10%.

 $$$$$ We describe a two-stage optimization of the MaltParser system for the ten languages in the multilingual track of the CoNLL 2007 shared task on dependency parsing.
 $$$$$ The frequency of this error is more than twice as high for the Blended parser (180) as for the Single Malt parser (83).

One system (Hall et al, 2007b) extends this two-stage approach to a three-stage architecture where the parser and labeler generate an n-best list of parses which in turn is reranked. $$$$$ We describe a two-stage optimization of the MaltParser system for the ten languages in the multilingual track of the CoNLL 2007 shared task on dependency parsing.
One system (Hall et al, 2007b) extends this two-stage approach to a three-stage architecture where the parser and labeler generate an n-best list of parses which in turn is reranked. $$$$$ We consistently used the labeled attachment score (LAS) as the single optimization criterion.
One system (Hall et al, 2007b) extends this two-stage approach to a three-stage architecture where the parser and labeler generate an n-best list of parses which in turn is reranked. $$$$$ The parameters available in the MaltParser system can be divided into three groups: parsing algorithmparameters, feature model parameters, and learn ing algorithm parameters.2 Our overall optimization 2For a complete documentation of these parameters, see http://w3.msi.vxu.se/users/nivre/research/MaltParser.html.
One system (Hall et al, 2007b) extends this two-stage approach to a three-stage architecture where the parser and labeler generate an n-best list of parses which in turn is reranked. $$$$$ When evaluated on the official test sets, the ensemble system significantly outperforms the single-parser system and achieves the highest average labeled attachment score.

 $$$$$ et al, 2003), English (Marcus et al, 1993; Johansson and Nugues, 2007), Greek (Prokopidis et al, 2005), Hungarian (Csendes et al, 2005), Italian (Montemagni et al, 2003), and Turkish (Oflazer et al, 2003).1 Our contribution is a study in multilingual parser optimization using the freely available MaltParser system, which performs 1For more information about the task and the data sets, see Nivre et al (2007).deterministic, classifier-based parsing with history based feature models and discriminative learning, and which was one of the top performing systems in the CoNLL 2006 shared task (Nivre et al, 2006).In order to maximize parsing accuracy, optimiza tion has been carried out in two stages, leading to two different, but related parsers.
 $$$$$ Thesecond stage consists in building an ensemble system that combines six different parsing strategies, extrapolating from the opti mal parameters settings for each language.
 $$$$$ Acknowledgements We want to thank all treebank providers for making the data available for the shared task and the (other) organizers for their efforts in organizing it.
 $$$$$ When evaluated on the official test sets, the ensemble system significantly outperforms the single-parser system and achieves the highest average labeled attachment score.

This model is used by Marinov (2007) and in component parsers of the Nilsson ensemble system (Hall et al, 2007a). $$$$$ 10This conclusion is further supported by the observation that the single most frequent ?frame confusion?
This model is used by Marinov (2007) and in component parsers of the Nilsson ensemble system (Hall et al, 2007a). $$$$$ Arc-standard projective left-to-right.
This model is used by Marinov (2007) and in component parsers of the Nilsson ensemble system (Hall et al, 2007a). $$$$$ When evaluated on the official test sets, the ensemble system significantly outperforms the single-parser system and achieves the highest average labeled attachment score.
This model is used by Marinov (2007) and in component parsers of the Nilsson ensemble system (Hall et al, 2007a). $$$$$ the parser is initialized with an artificial root node (with token id 0) on the stack, so that arcsoriginating from the root can be added explicitly during parsing.

The most extreme case is the top performing Nilsson system (Hall et al, 2007a), which reached rank 1 for five languages and rank 2 for two more languages. $$$$$ The cumulative improvement after optimization of feature model and learning algorithm parameters was 1.71 percentage points on average over all ten languages, with a minimum of 0.69 (Turkish) and a maximum of 3.25 (Chinese) (cf.
The most extreme case is the top performing Nilsson system (Hall et al, 2007a), which reached rank 1 for five languages and rank 2 for two more languages. $$$$$ We describe a two-stage optimization of the MaltParser system for the ten languages in the multilingual track of the CoNLL 2007 shared task on dependency parsing.
The most extreme case is the top performing Nilsson system (Hall et al, 2007a), which reached rank 1 for five languages and rank 2 for two more languages. $$$$$ We describe a two-stage optimization of the MaltParser system for the ten languages in the multilingual track of the CoNLL 2007 shared task on dependency parsing.

However, Hall et al (2007a) point out that the official results for Chinese contained a bug, and the true performance of their system was actually much higher. $$$$$ We describe a two-stage optimization of the MaltParser system for the ten languages in the multilingual track of the CoNLL 2007 shared task on dependency parsing.
However, Hall et al (2007a) point out that the official results for Chinese contained a bug, and the true performance of their system was actually much higher. $$$$$ Thesecond stage consists in building an ensemble system that combines six different parsing strategies, extrapolating from the opti mal parameters settings for each language.
However, Hall et al (2007a) point out that the official results for Chinese contained a bug, and the true performance of their system was actually much higher. $$$$$ parameters in an interleaved fashion for each language.
However, Hall et al (2007a) point out that the official results for Chinese contained a bug, and the true performance of their system was actually much higher. $$$$$ Thesecond stage consists in building an ensemble system that combines six different parsing strategies, extrapolating from the opti mal parameters settings for each language.

 $$$$$ two non-projective parsers.
 $$$$$ When evaluated on the official test sets, the ensemble system significantly outperforms the single-parser system and achieves the highest average labeled attachment score.
 $$$$$ Below we describe the most important parameters in each group, define baseline settings, and report notable improvements for different languages during development.
 $$$$$ Arc order: The baseline algorithm is arc-.

The same technique was also used by the winning team of the CoNLL 2007 Shared Task (Hall et al, 2007), combining six transition-based parsers. $$$$$ Table 2 throwssome light on this by giving the precision and recall for dependencies of different length, treating de pendents of the artificial root node as a special case.As expected, the Single Malt parser has lower preci sion than recall for root dependents, but the Blendedparser has even lower precision (and somewhat bet ter recall), indicating that the fragmentation is even more severe in this case.10 By contrast, we see that precision and recall for other dependencies improve across the board, especially for longer dependencies,which probably means that the effect of error propa gation is mitigated by the use of an ensemble system,even if each of the component parsers is determinis tic in itself.
The same technique was also used by the winning team of the CoNLL 2007 Shared Task (Hall et al, 2007), combining six transition-based parsers. $$$$$ Italian), as well as the highest multilingual average score.
The same technique was also used by the winning team of the CoNLL 2007 Shared Task (Hall et al, 2007), combining six transition-based parsers. $$$$$ We have shown that deterministic, classifier-based dependency parsing, with careful optimization, can give highly accurate dependency parsing for a wide range of languages, as illustrated by the performanceof the Single Malt parser.

An existing method to combine multiple parsing algorithms is the ensemble approach (Sagae and Lavie, 2006a), which was reported to be useful in improving dependency parsing (Halletal., 2007). $$$$$ The second parser is an ensemble system, which combines the output of six deterministic parsers, each of which is a variation of the Single Malt parser with parameter settings extrapolated from the first stage of optimization.
An existing method to combine multiple parsing algorithms is the ensemble approach (Sagae and Lavie, 2006a), which was reported to be useful in improving dependency parsing (Halletal., 2007). $$$$$ 5This technique is similar to the one used by Yamada and Matsumoto (2003), but with only a single post-processing pass parsing complexity remains linear in string length.
An existing method to combine multiple parsing algorithms is the ensemble approach (Sagae and Lavie, 2006a), which was reported to be useful in improving dependency parsing (Halletal., 2007). $$$$$ Table 1 shows the labeled attachment score results from our internal dry run (training on 90% of the training data, testing on the remaining 10%) and the official test runs for both of our systems.
An existing method to combine multiple parsing algorithms is the ensemble approach (Sagae and Lavie, 2006a), which was reported to be useful in improving dependency parsing (Halletal., 2007). $$$$$ eager, in the sense that right dependents are attached to their head as soon as possible, but there is also an arc-standard version, where theattachment of right dependents has to be postponed until they have found all their own de pendents.

Both Hall et al (2007) and Nivre and McDonald (2008) can be seen as methods to combine separately defined models. $$$$$ The frequency of this error is more than twice as high for the Blended parser (180) as for the Single Malt parser (83).
Both Hall et al (2007) and Nivre and McDonald (2008) can be seen as methods to combine separately defined models. $$$$$ The final Blended parser was constructed by reusingthe tuned Single Malt parser for each language (arcstandard left-to-right for Chinese, arc-eager left-to right for the remaining languages) and training five additional parsers with the same parameter settings except for the following mechanical adjustments: 1.

We implement a left-to-right arc-eager parsing model in a way that the parser scan through an input sequence from left to right and the right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ of the Blended parser, over all languages, is to attach two dependents with the label ROOT to the root node, instead of only one.
We implement a left-to-right arc-eager parsing model in a way that the parser scan through an input sequence from left to right and the right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ et al, 2007), Chinese (Chen et al, 2003), Czech (Bo?hmova?
We implement a left-to-right arc-eager parsing model in a way that the parser scan through an input sequence from left to right and the right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ The first stage consists in tuning a single-parsersystem for each language by optimizing parameters of the parsing algorithm, the fea ture model, and the learning algorithm.
We implement a left-to-right arc-eager parsing model in a way that the parser scan through an input sequence from left to right and the right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ Arc-eager projective right-to-left.

Only one model was used for syntactic parsing in our system, in contrast to the existing work using an ensemble technique for further performance enhancement, e.g., (Hall et al, 2007). $$$$$ Pseudo-projective parsing was found to have a positive effect on over all parsing accuracy only for Basque, Czech, Greek and Turkish.
Only one model was used for syntactic parsing in our system, in contrast to the existing work using an ensemble technique for further performance enhancement, e.g., (Hall et al, 2007). $$$$$ et al, 2004), Basque (Aduriz et al, 2003), Catalan, (Mart??
Only one model was used for syntactic parsing in our system, in contrast to the existing work using an ensemble technique for further performance enhancement, e.g., (Hall et al, 2007). $$$$$ Below we describe the most important parameters in each group, define baseline settings, and report notable improvements for different languages during development.

 $$$$$ Section 2 summarizes the work done to optimize the Single Malt parser, while section 3 explains how the Blended parser was constructed from the Single Malt parser.
 $$$$$ We consistently used the labeled attachment score (LAS) as the single optimization criterion.
 $$$$$ Special thanks to Ryan McDonald, for fruitful discussions and assistance with the error analysis, and to Kenji Sagae, for showing us how to produce a good blend.

This model is simple and works very well in the shared-tasks of CoNLL2006 (Nivre et al, 2006) and CoNLL2007 (Hall et al, 2007). $$$$$ For Arabic, Basque, and Catalan, the baseline settings were used also in the dry run and final test.
This model is simple and works very well in the shared-tasks of CoNLL2006 (Nivre et al, 2006) and CoNLL2007 (Hall et al, 2007). $$$$$ 4 Results and Discussion.
This model is simple and works very well in the shared-tasks of CoNLL2006 (Nivre et al, 2006) and CoNLL2007 (Hall et al, 2007). $$$$$ 8We use CPOSTAG to determine the part of speech.

In this work, we adopt a left-to-right arc-eager parsing model, that means that the parser scans the input sequence from left to right and right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ figure is 10% or less.6 The cumulative improvement after optimization of parsing algorithm parameters was a modest 0.32 percentage points on average over all ten languages, with a minimum of 0.00 (Arabic, English) and a maximum of 0.83 (Czech) (cf.
In this work, we adopt a left-to-right arc-eager parsing model, that means that the parser scans the input sequence from left to right and right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ Section 2 summarizes the work done to optimize the Single Malt parser, while section 3 explains how the Blended parser was constructed from the Single Malt parser.
In this work, we adopt a left-to-right arc-eager parsing model, that means that the parser scans the input sequence from left to right and right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ We consistently used the labeled attachment score (LAS) as the single optimization criterion.
In this work, we adopt a left-to-right arc-eager parsing model, that means that the parser scans the input sequence from left to right and right dependents are attached to their heads as soon as possible (Hall et al, 2007). $$$$$ Thesecond stage consists in building an ensemble system that combines six different parsing strategies, extrapolating from the opti mal parameters settings for each language.

 $$$$$ This probably means that the per formance of the Blended system can be improved considerably by optimizing parameters for all six parsers separately.
 $$$$$ The Blended parser uses six component parsers, with three different parsing algorithms, each of which is used to construct one left-to-right parser and one right-to-left parser.
 $$$$$ The parsing algorithmsused are the arc-eager baseline algorithm, the arc standard variant of the baseline algorithm, and the incremental, non-projective parsing algorithm first described by Covington (2001) and recently used for deterministic classifier-based parsing by Nivre (2007), all of which are available in MaltParser.

For the final system, feature models and training parameters were adapted from Hall et al (2007). $$$$$ The final Blended parser was constructed by reusingthe tuned Single Malt parser for each language (arcstandard left-to-right for Chinese, arc-eager left-to right for the remaining languages) and training five additional parsers with the same parameter settings except for the following mechanical adjustments: 1.
For the final system, feature models and training parameters were adapted from Hall et al (2007). $$$$$ figure is 10% or less.6 The cumulative improvement after optimization of parsing algorithm parameters was a modest 0.32 percentage points on average over all ten languages, with a minimum of 0.00 (Arabic, English) and a maximum of 0.83 (Czech) (cf.
For the final system, feature models and training parameters were adapted from Hall et al (2007). $$$$$ In order to reduce training times during development, we also split the training data for each language intosmaller sets and trained separate multi-class classi fiers for each set, using the POSTAG of Next as the defining feature for the split.
For the final system, feature models and training parameters were adapted from Hall et al (2007). $$$$$ We describe a two-stage optimization of the MaltParser system for the ten languages in the multilingual track of the CoNLL 2007 shared task on dependency parsing.

The single parses were blended following the procedure of Hall et al (2007). $$$$$ Define a good baseline system with the same.
The single parses were blended following the procedure of Hall et al (2007). $$$$$ Hence, children of the root node in the final output may not have been predicted as such by the treebank-induced classifier.
The single parses were blended following the procedure of Hall et al (2007). $$$$$ et al, 2007), Chinese (Chen et al, 2003), Czech (Bo?hmova?
The single parses were blended following the procedure of Hall et al (2007). $$$$$ Stack initialization: In the baseline version.

system for English described in Hall et al (2007) was used as a baseline, and then optimized for this new task, focusing on feature selection. $$$$$ parameters in an interleaved fashion for each language.
