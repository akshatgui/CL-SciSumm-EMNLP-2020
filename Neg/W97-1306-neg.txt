We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin's CogNIAC (Baldwin 1997) approach which features. $$$$$ For example: The computer won the match.
We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin's CogNIAC (Baldwin 1997) approach which features. $$$$$ It was a great triumph.
We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin's CogNIAC (Baldwin 1997) approach which features. $$$$$ This class of coreference is quite challenging because the plural anaphor 'they' must be able to collect a set of antecedents from the prior discourse--but how far should it look back, and once it has found two antecedents, should it continue to look for more?

This result is comparable with the results described in (Baldwin 1997). $$$$$ The system does this by being very sensitive to ambiguity, and only resolving pronouns when very high confidence rules have been satisfied.
This result is comparable with the results described in (Baldwin 1997). $$$$$ The remaining instances of anaphora included common noun anaphora and coreferent instances of proper nouns.
This result is comparable with the results described in (Baldwin 1997). $$$$$ I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.
This result is comparable with the results described in (Baldwin 1997). $$$$$ It is also widely considered to be inherently an A.I. complete' task-meaning that resolution of pronouns requires full world knowledge and inference.

For the training data from the genre of technical manuals, it was rule 5 (see Baldwin 1997) which was most frequently used (39% of the cases, 100% success), followed by rule 8 (33% of the cases, 33% success), rule 7 (11%, 100%), rule I (9%, 100%) and rule 3 (7.4%, 100%). $$$$$ Earl was working with Ted the other day.
For the training data from the genre of technical manuals, it was rule 5 (see Baldwin 1997) which was most frequently used (39% of the cases, 100% success), followed by rule 8 (33% of the cases, 33% success), rule 7 (11%, 100%), rule I (9%, 100%) and rule 3 (7.4%, 100%). $$$$$ I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.
For the training data from the genre of technical manuals, it was rule 5 (see Baldwin 1997) which was most frequently used (39% of the cases, 100% success), followed by rule 8 (33% of the cases, 33% success), rule 7 (11%, 100%), rule I (9%, 100%) and rule 3 (7.4%, 100%). $$$$$ These rules are individually are high precision rules, and collectively they add up to reasonable recall.
For the training data from the genre of technical manuals, it was rule 5 (see Baldwin 1997) which was most frequently used (39% of the cases, 100% success), followed by rule 8 (33% of the cases, 33% success), rule 7 (11%, 100%), rule I (9%, 100%) and rule 3 (7.4%, 100%). $$$$$ 3.2.2 Experiment 2-- All pronouns in MUC-6 evaluation: CogNIAC was used as the pronoun component in the University Pennsylvania's coreference entry5 in the MUC-6 evaluation.

The approach for applying the rules is similar to the one proposed by Baldwin (1997). $$$$$ In lieu of full world knowledge, CogNIAC uses regularities of English usage in an attempt to mimic strategies used by humans when resolving pronouns.
The approach for applying the rules is similar to the one proposed by Baldwin (1997). $$$$$ A question raised by a reviewer asked whether there was any use for high precision coreference given that it is not resolving as much coreference as other methods.
The approach for applying the rules is similar to the one proposed by Baldwin (1997). $$$$$ Ambiguous pronoun use is a substantial problem for beginning writers and language learners.
The approach for applying the rules is similar to the one proposed by Baldwin (1997). $$$$$ The coreference would only help the scores of presumably relevant documents, but at the expense of missing some relevant documents.

The CogNIAC algorithm (Baldwin, 1997) was designed for high-precision AR. $$$$$ CogNIAC is currently the common noun and pronoun resolution component of the University of Pennsylvania's coreference resolution software and general NLP software (Camp).
The CogNIAC algorithm (Baldwin, 1997) was designed for high-precision AR. $$$$$ CogNIAC is currently the common noun and pronoun resolution component of the University of Pennsylvania's coreference resolution software and general NLP software (Camp).
The CogNIAC algorithm (Baldwin, 1997) was designed for high-precision AR. $$$$$ I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.
The CogNIAC algorithm (Baldwin, 1997) was designed for high-precision AR. $$$$$ These rules are individually are high precision rules, and collectively they add up to reasonable recall.

RAP (Kennedy and Boguraev, 1996), Baldwin's pronoun resolution method (Baldwin, 1997) and Mitkov's knowledge-poor pronoun resolution approach (Mitkov, 1998b). $$$$$ I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.
RAP (Kennedy and Boguraev, 1996), Baldwin's pronoun resolution method (Baldwin, 1997) and Mitkov's knowledge-poor pronoun resolution approach (Mitkov, 1998b). $$$$$ This control structure could control general inference techniques as well.
RAP (Kennedy and Boguraev, 1996), Baldwin's pronoun resolution method (Baldwin, 1997) and Mitkov's knowledge-poor pronoun resolution approach (Mitkov, 1998b). $$$$$ For a given rule, if an antecedent is found, then the appropriate annotations are made to the text and no more rules are tried for that pronoun, otherwise the next rule is tried.

Since the original version of CogNiac is non-robust and resolves only anaphors that obey certain rules, for fairer and comparable results we implemented the resolve-all version as described in (Baldwin, 1997). $$$$$ The precision is 97% (121/125) and the recall is 60% (121/201) for 198 pronouns of training data.
Since the original version of CogNiac is non-robust and resolves only anaphors that obey certain rules, for fairer and comparable results we implemented the resolve-all version as described in (Baldwin, 1997). $$$$$ The system has been evaluated in two distinct experiments which support the overall validity of the approach.
Since the original version of CogNiac is non-robust and resolves only anaphors that obey certain rules, for fairer and comparable results we implemented the resolve-all version as described in (Baldwin, 1997). $$$$$ CogNIAC has been used with a range of linguistic resources, ranging from scenarios where almost no linguistic processing of the text is done at all to partial parse trees being provided.
Since the original version of CogNiac is non-robust and resolves only anaphors that obey certain rules, for fairer and comparable results we implemented the resolve-all version as described in (Baldwin, 1997). $$$$$ Some examples follow.

Baldwin's CogNiac (Baldwin, 1997) is a knowledge poor approach to anaphora resolution based on a set of high confidence rules which are successively applied over the pronoun under consideration. $$$$$ For a given rule, if an antecedent is found, then the appropriate annotations are made to the text and no more rules are tried for that pronoun, otherwise the next rule is tried.
Baldwin's CogNiac (Baldwin, 1997) is a knowledge poor approach to anaphora resolution based on a set of high confidence rules which are successively applied over the pronoun under consideration. $$$$$ I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.
Baldwin's CogNiac (Baldwin, 1997) is a knowledge poor approach to anaphora resolution based on a set of high confidence rules which are successively applied over the pronoun under consideration. $$$$$ The system is capable of 'noticing' ambiguity because it requires that there be a unique antecedent within a salience ranking, and the salience rankings are not total orders, i.e. two or more antecedents can be equally salient.
Baldwin's CogNiac (Baldwin, 1997) is a knowledge poor approach to anaphora resolution based on a set of high confidence rules which are successively applied over the pronoun under consideration. $$$$$ As a result being part of a larger system, changes were made to CogNIAC to make it fit in better with the other components of the overall system in addition to adding rules that were specialized for the new kinds of pronominal anaphora.

This definition is slightly different from the one used in (Baldwin, 1997) and (Gaizauskas and Humphreys, 2000). $$$$$ I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.
This definition is slightly different from the one used in (Baldwin, 1997) and (Gaizauskas and Humphreys, 2000). $$$$$ For example: The computer won the match.
This definition is slightly different from the one used in (Baldwin, 1997) and (Gaizauskas and Humphreys, 2000). $$$$$ The problem is picking the correct one.
This definition is slightly different from the one used in (Baldwin, 1997) and (Gaizauskas and Humphreys, 2000). $$$$$ The high precision rules of CogNIAC performed very well, greater than 90% precision with good recall for the first experiment.

As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison. $$$$$ This pre-processing was subjected to hand correction in order to make comparison with Hobbs as fair as possible since that was an entirely hand executed algorithm, but CogNIAC was otherwise machine run and scored.
As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison. $$$$$ At the very least, there must be sufficient linguistic resources to recognize pronouns in the text and the space of candidate antecedents must be identified.

Evaluation results for both evaluation modes are 76 given in traditional precision, recall and f-score, which are similar to (Baldwin, 1997). $$$$$ What distinguishes CogNIAC from algorithms that use similar sorts of information is that it will not resolve a pronoun in circumstances of ambiguity.
Evaluation results for both evaluation modes are 76 given in traditional precision, recall and f-score, which are similar to (Baldwin, 1997). $$$$$ However, 25% of the errors were due directly to the rules of CogNIAC being plain wrong.
Evaluation results for both evaluation modes are 76 given in traditional precision, recall and f-score, which are similar to (Baldwin, 1997). $$$$$ Perhaps the most convincing reason to endorse partially ordered salience rankings is that salience distinctions fade as the discourse moves on.
Evaluation results for both evaluation modes are 76 given in traditional precision, recall and f-score, which are similar to (Baldwin, 1997). $$$$$ These rules are individually are high precision rules, and collectively they add up to reasonable recall.

Pronoun resolution is carried out using the Glencova Pronoun Resolution algorithm (Halpin et al, 2004), based on a series of rules similar to the CogNIAC engine (Baldwin, 1997), but without gender information based rules since this is not provided by the Penn Treebank tag set. $$$$$ CogNIAC as a set of seven or so high precision rules would act as an effective filter on what a more knowledge rich application would have to resolve.
Pronoun resolution is carried out using the Glencova Pronoun Resolution algorithm (Halpin et al, 2004), based on a series of rules similar to the CogNIAC engine (Baldwin, 1997), but without gender information based rules since this is not provided by the Penn Treebank tag set. $$$$$ It is suggested that the system is resolving a sub-set of anaphors that do not require general world knowledge or sophisticated linguistic processing for successful resolution.
Pronoun resolution is carried out using the Glencova Pronoun Resolution algorithm (Halpin et al, 2004), based on a series of rules similar to the CogNIAC engine (Baldwin, 1997), but without gender information based rules since this is not provided by the Penn Treebank tag set. $$$$$ This class of coreference is quite challenging because the plural anaphor 'they' must be able to collect a set of antecedents from the prior discourse--but how far should it look back, and once it has found two antecedents, should it continue to look for more?
Pronoun resolution is carried out using the Glencova Pronoun Resolution algorithm (Halpin et al, 2004), based on a series of rules similar to the CogNIAC engine (Baldwin, 1997), but without gender information based rules since this is not provided by the Penn Treebank tag set. $$$$$ I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.

As a consequence, current anaphor resolution implementations mainly rely on constraints and preference heuristics which employ information originated from morphosyntactic or shallow semantic analysis ,e.g. in Baldwin (1997). $$$$$ After he was dry, Joe carefully laid out the damp towel in front of his locker.
As a consequence, current anaphor resolution implementations mainly rely on constraints and preference heuristics which employ information originated from morphosyntactic or shallow semantic analysis ,e.g. in Baldwin (1997). $$$$$ Currently the system uses no verb semantics to try and constrain possible coreference.
As a consequence, current anaphor resolution implementations mainly rely on constraints and preference heuristics which employ information originated from morphosyntactic or shallow semantic analysis ,e.g. in Baldwin (1997). $$$$$ The space of ambiguity will certainly grow substantially when events are considered as candidate antecedents.
As a consequence, current anaphor resolution implementations mainly rely on constraints and preference heuristics which employ information originated from morphosyntactic or shallow semantic analysis ,e.g. in Baldwin (1997). $$$$$ If this is correct, then the introduction of better world knowledge sources will help in the recall of the system rather than the precision.
