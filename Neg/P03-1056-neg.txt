Because of these characteristics, Chinese has a rather different set of salient ambiguities from the perspective of statistical parsing (Levy and Manning, 2003). $$$$$ This is an encouraging result for the use of detailed error analysis followed by focused treestructure enhancements to improved parser performance.
Because of these characteristics, Chinese has a rather different set of salient ambiguities from the perspective of statistical parsing (Levy and Manning, 2003). $$$$$ We illustrate that each of these refinements can effectively be viewed as an amendment to the independence assumptions made by a simple PCFG.
Because of these characteristics, Chinese has a rather different set of salient ambiguities from the perspective of statistical parsing (Levy and Manning, 2003). $$$$$ We address this error by taking advantage of the CTB's principled VP annotation practices, marking adjunction, complementation, and coordination VP levels, which builds the flat adjunction constraint back into the structure of the head daughter.
Because of these characteristics, Chinese has a rather different set of salient ambiguities from the perspective of statistical parsing (Levy and Manning, 2003). $$$$$ There are two major sources of ambiguous attachment sites: (i) any VP can be parsed as an IP plus a unary IP—NP, so due to pro-drop any VP coordination is ambiguous with a higher IP coordination; (ii) VPs are multilevel, giving rise to ambiguities of scope over adjuncts.

We use the SVM-Light Toolkit version 6.02 (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser version 1.6 (Levy and Manning, 2003) as the constituent parser and the constituent-to-dependency converter. $$$$$ This type of parse ambiguity is grounded in the semantic ambiguity of compound noun interpretation.
We use the SVM-Light Toolkit version 6.02 (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser version 1.6 (Levy and Manning, 2003) as the constituent parser and the constituent-to-dependency converter. $$$$$ To begin development, we tested the interaction of complete parent and/or grandparent annotation with PCFG markovization (see (Collins, 1999; Charniak, 2000) for discussion).
We use the SVM-Light Toolkit version 6.02 (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser version 1.6 (Levy and Manning, 2003) as the constituent parser and the constituent-to-dependency converter. $$$$$ More recently, however, a wider variety of parsed corpora has become available in other languages.

To run the DE classifiers, we use the Stanford Chinese parser (Levy and Manning, 2003) to parse the Chinese side of the MT training data, the devset and test set. $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.
To run the DE classifiers, we use the Stanford Chinese parser (Levy and Manning, 2003) to parse the Chinese side of the MT training data, the devset and test set. $$$$$ In particular, linguistic generalizations corresponding to category refinements are easily implemented via category-splitting in the PCFG model, without concern for affecting the dependency model.
To run the DE classifiers, we use the Stanford Chinese parser (Levy and Manning, 2003) to parse the Chinese side of the MT training data, the devset and test set. $$$$$ We then ran the same model on the test set used in previous work (Bikel and Chiang, 2000; Chiang and Bikel, 2002).
To run the DE classifiers, we use the Stanford Chinese parser (Levy and Manning, 2003) to parse the Chinese side of the MT training data, the devset and test set. $$$$$ 4For unknown words we estimated P(wordltag) based on the first character of the word. foreign investment icalism (Sag and Wasow, 1999).

In this work, we use the Stanford Parser (Levy and Manning 2003). $$$$$ In particular, we found that coordination scoping ambiguity and N/V tag ambiguity are major sources of relatively catastrophic error for our parser.
In this work, we use the Stanford Parser (Levy and Manning 2003). $$$$$ CP NP I exports NP VP -** NP VP -** VV NP realized I gross exports CRDHN* NP PU NP NP problems CRDLN CP NP NP PU NP unmet • fig_ conditions ë problems VP NP ADVP VP nationwide most long NP VP ADVP VP nationwide -------most long Figure 4: Major parse ambiguities.
In this work, we use the Stanford Parser (Levy and Manning 2003). $$$$$ The trends we obtained are different enough from previous work to merit discussion.
In this work, we use the Stanford Parser (Levy and Manning 2003). $$$$$ Our PCFG enhancements were most effective at reducing NP-NP modification error, incorrect recursive bracketings, and IP/VP attachment errors.

Levy and Manning (2003) used a factored model that combines an unlexicalized PCFG model with a dependency model. $$$$$ This type of parse ambiguity is grounded in the semantic ambiguity of compound noun interpretation.
Levy and Manning (2003) used a factored model that combines an unlexicalized PCFG model with a dependency model. $$$$$ Of the simplest local-context enrichment strategies, the one that has proven effective on a systematic basis involves parent annotation; (Johnson, 1998) showed that when uniformly applied, it considerably improved WSJ Treebank parsing.
Levy and Manning (2003) used a factored model that combines an unlexicalized PCFG model with a dependency model. $$$$$ All natural languages possess derivational means by which roots can switch between nominal and verbal categories.
Levy and Manning (2003) used a factored model that combines an unlexicalized PCFG model with a dependency model. $$$$$ Second, some common error types are not the result of simple and easily fixable shortcomings in independence assumptions.

While it is uncommon to offer an error analysis for probabilistic parsing, Levy and Manning (2003) argue that a careful error classification can reveal possible improvements. $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.
While it is uncommon to offer an error analysis for probabilistic parsing, Levy and Manning (2003) argue that a careful error classification can reveal possible improvements. $$$$$ This yielded a 5.4% drop in Fl for the vanilla PCFG, and a much smaller drop of 1.7% for the refined model, suggesting at first glance that context plus correct independence assumptions can compensate for most of the distributional information gained from N/V tag priors.
While it is uncommon to offer an error analysis for probabilistic parsing, Levy and Manning (2003) argue that a careful error classification can reveal possible improvements. $$$$$ But the sparse morphology of English and Chinese means that frequently there is noun/verb ambiguity at the word level.
While it is uncommon to offer an error analysis for probabilistic parsing, Levy and Manning (2003) argue that a careful error classification can reveal possible improvements. $$$$$ In principle, any contextual information could be used, but in practice two types are most heavily relied on: (i) information highly local to the enhanced node; and (ii) a unique preterminal/terminal pair identified as the head of the node.

Verb mistagging is also a problem for other languages $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.
Verb mistagging is also a problem for other languages $$$$$ VP (-ADJ) ADVP ADVP VP (-COMP) NP AD AD VV NP 1 1 1 NP i• Itg 4k 4g* A A Fi' positively investigate profession NR NN NR I I I NN VP i4 A * 01 ADVP VP Shanghai customs Chorigm rig office AD ADVP VP I NR NN NR NN i• AD VV NP I I I I i4 A * 01 044' Itg 4k 4g* A A Fi' Shanghai customs Chorigming office positively investigate high-risk profession NP NNM±* Figure 5: Flat (corpus) versus multilevel (incorrect-parse) adjunction.
Verb mistagging is also a problem for other languages $$$$$ They were less effective at improving coordination attachment resolution and prenominal modification.
Verb mistagging is also a problem for other languages $$$$$ CTB rewrite rules are unary (Table 1).2 This is consonant with the behavior of simple PCFGs on training data, as shown in Table 2.

The closest previous work is the detailed manual analysis performed by Levy and Manning (2003). $$$$$ 4For unknown words we estimated P(wordltag) based on the first character of the word. foreign investment icalism (Sag and Wasow, 1999).
The closest previous work is the detailed manual analysis performed by Levy and Manning (2003). $$$$$ To capture this we mark those adverbs possessing an IP grandparent.
The closest previous work is the detailed manual analysis performed by Levy and Manning (2003). $$$$$ Since NP is right-headed while VP and IP are leftheaded, an improved dependency model may be the best place to address at least one of the key problems we have identified for CTB parsing.
The closest previous work is the detailed manual analysis performed by Levy and Manning (2003). $$$$$ Starred examples are correct in corpus; alternates are parse errors. string speculator Richard Denthese structures are typically bracketed flat in the ETB, underspecifying the semantic relations relative to the CTB.

 $$$$$ The strongest mistagging tendency was to tag verbs (VV) as common nouns (NN).
 $$$$$ Two major classes of ambiguity are involved in IP membership: (i) the presence or absence in IP of subjects and adjuncts; and (ii) coordinate attachment of verbal material.
 $$$$$ Of the simplest local-context enrichment strategies, the one that has proven effective on a systematic basis involves parent annotation; (Johnson, 1998) showed that when uniformly applied, it considerably improved WSJ Treebank parsing.

 $$$$$ The simplest systematic augmentations to basic PCFG models are the inclusion of various types of contextual information in the structure of individual node labels.
 $$$$$ First, some important and addressable error types are relatively rare in Treebank data.
 $$$$$ Our PCFG enhancements were most effective at reducing NP-NP modification error, incorrect recursive bracketings, and IP/VP attachment errors.

See Levy and Manning (2003) for a similar discussion of Chinese and the Penn Chinese Treebank. $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.
See Levy and Manning (2003) for a similar discussion of Chinese and the Penn Chinese Treebank. $$$$$ Interestingly, coordination scope ambiguity is recognized as perhaps the most recalcitrant problem in ETB parsing, while many cases of N/V ambiguity are particularly difficult points of linguistic analysis for Chinese, as discussed in Section 4.2.
See Levy and Manning (2003) for a similar discussion of Chinese and the Penn Chinese Treebank. $$$$$ We are grateful to Dan Klein for valuable input, and for the parser implementation used here.
See Levy and Manning (2003) for a similar discussion of Chinese and the Penn Chinese Treebank. $$$$$ With nominal coordination scope errors, the situation is different: we found no false low attachments.

We use the SVM-Light Toolkit (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser (Levy and Manning, 2003) as the parser and the constituent-to-dependency converter. $$$$$ The trends we obtained are different enough from previous work to merit discussion.
We use the SVM-Light Toolkit (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser (Levy and Manning, 2003) as the parser and the constituent-to-dependency converter. $$$$$ Chinese, on the other hand, has no morphological paradigms, so any test to determine the part of speech must be made with syntagmatic substitution: whether the word can take an adverbial modifier or a prenominal modifier, for example.
We use the SVM-Light Toolkit (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser (Levy and Manning, 2003) as the parser and the constituent-to-dependency converter. $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.
We use the SVM-Light Toolkit (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser (Levy and Manning, 2003) as the parser and the constituent-to-dependency converter. $$$$$ We are grateful to Dan Klein for valuable input, and for the parser implementation used here.

Noun/verb mis-taggings are a frequent error case for PCFG parsing on PCTB data, compounded in Chinese by the lack of function words and morphology (Levy and Manning, 2003). $$$$$ State-ofthe-art statistical parsing techniques now handle most ambiguity adequately; the best statistical parsers for the ETB are now at roughly 90% labeled bracketing accuracy (Charniak, 2000; Collins, 2000).
Noun/verb mis-taggings are a frequent error case for PCFG parsing on PCTB data, compounded in Chinese by the lack of function words and morphology (Levy and Manning, 2003). $$$$$ The CTB has far fewer rule types than an ETB of equivalent size, and has a considerably lower branching factor.
Noun/verb mis-taggings are a frequent error case for PCFG parsing on PCTB data, compounded in Chinese by the lack of function words and morphology (Levy and Manning, 2003). $$$$$ With nominal coordination scope errors, the situation is different: we found no false low attachments.
Noun/verb mis-taggings are a frequent error case for PCFG parsing on PCTB data, compounded in Chinese by the lack of function words and morphology (Levy and Manning, 2003). $$$$$ Starred examples are correct in corpus; alternates are parse errors. string speculator Richard Denthese structures are typically bracketed flat in the ETB, underspecifying the semantic relations relative to the CTB.

It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). $$$$$ We found that head-dependent distances in the CTB are larger than in the ETB, consistent with the greater degree of center-embedding resulting from the mixed headedness of Chinese, and suggesting that a dependency model developed for English may not be optimal for Chinese.
It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.
It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). $$$$$ We use the factored parsing model of (Klein and Manning, 2002).
It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). $$$$$ Of the simplest local-context enrichment strategies, the one that has proven effective on a systematic basis involves parent annotation; (Johnson, 1998) showed that when uniformly applied, it considerably improved WSJ Treebank parsing.

Levy and Manning (2003) established that properties of Chinese such as noun/verb ambiguity contribute to the difficulty of Chinese parsing. $$$$$ In addition to simplifying the parameterization of the parsing model and maintaining exactness, this 2WSJ-small is a randomly selected tenth of the full English Wall Street Journal corpus. model offers the prospect of increased flexibility in tuning the individual parse models.
Levy and Manning (2003) established that properties of Chinese such as noun/verb ambiguity contribute to the difficulty of Chinese parsing. $$$$$ We illustrate that each of these refinements can effectively be viewed as an amendment to the independence assumptions made by a simple PCFG.
Levy and Manning (2003) established that properties of Chinese such as noun/verb ambiguity contribute to the difficulty of Chinese parsing. $$$$$ It seems that (i) is a difficult problem; in some cases, certain &quot;discourse-level&quot; adverbs such as IP modification and are thus strong indicators of high attachment.
Levy and Manning (2003) established that properties of Chinese such as noun/verb ambiguity contribute to the difficulty of Chinese parsing. $$$$$ We found that first-order markovization was superior to zero-order, second-order, and unmarkovized PCFGs for all levels of ancestor annotation, and that within first-order markovization parent annotation was slightly superior to no annotation, with grandparent annotation decidedly worse.

greatly affects parsing accuracy (Levy and Manning, 2003). $$$$$ In particular a far higher proportion of 'Standard tree normalizations are: the removal of empty nodes and nodes dominating no non-empty terminals, and the subsequent removal of A over A unaries.
greatly affects parsing accuracy (Levy and Manning, 2003). $$$$$ The trends we obtained are different enough from previous work to merit discussion.
greatly affects parsing accuracy (Levy and Manning, 2003). $$$$$ Parsing in this model involves combining two independent parses: one of a non-lexicalized, maximum likelihoodestimated (MLE) PCFG model and another of a constituent-free dependency parse.
greatly affects parsing accuracy (Levy and Manning, 2003). $$$$$ This paper is based on research supported by the Advanced Research and Development Activity (ARDA)'s Advanced Question Answering for Intelligence (AQUAINT) Program.

We parsed the Chinese text using the Stanford parser (Levy and Manning, 2003) and the English text using TurboParser (Martins et al, 2009). $$$$$ We are grateful to Dan Klein for valuable input, and for the parser implementation used here.
We parsed the Chinese text using the Stanford parser (Levy and Manning, 2003) and the English text using TurboParser (Martins et al, 2009). $$$$$ In addition to simplifying the parameterization of the parsing model and maintaining exactness, this 2WSJ-small is a randomly selected tenth of the full English Wall Street Journal corpus. model offers the prospect of increased flexibility in tuning the individual parse models.
We parsed the Chinese text using the Stanford parser (Levy and Manning, 2003) and the English text using TurboParser (Martins et al, 2009). $$$$$ For example, the BA marker is descriptively used in Chinese to preverbalize objects.
We parsed the Chinese text using the Stanford parser (Levy and Manning, 2003) and the English text using TurboParser (Martins et al, 2009). $$$$$ In adapting this parsing model to Chinese, we have retained unchanged the dependency model developed for English; the model backs off to tags, and backoff parameters remain the same.3 In all cases, test input to the parser was segmented but untagged.4 Our focus in parser development has been to refine the PCFG model via stepwise refinements informed by major observed ambiguity classes.

Adapting unlexicalized parsers appears to be equally difficult $$$$$ For the future, we believe that there is still room for considerable improvement in CTB parsing under our model.
Adapting unlexicalized parsers appears to be equally difficult $$$$$ 4.1 Analysis by error type and PCFG-enrichment fixes Multilevel VP adjunction errors (Figure 5) are common in models without parent annotation, although even with parent annotation the presence of VP coordination would give multilevel VP adjunction nonzero probability.
Adapting unlexicalized parsers appears to be equally difficult $$$$$ We take advantage of the recently released Penn Chinese Treebank (version 2.0, abbreviated here as CTB; (Xue et al., 2002)) to address these questions for Chinese, a language with less morphology and more mixed headedness than English.

As pointed out in (Levyand Manning, 2003), there are many linguistic differences between Chinese and English, as well as structural differences between their corresponding tree banks, and some of these make it a harder task to parse Chinese. $$$$$ This is an encouraging result for the use of detailed error analysis followed by focused treestructure enhancements to improved parser performance.
As pointed out in (Levyand Manning, 2003), there are many linguistic differences between Chinese and English, as well as structural differences between their corresponding tree banks, and some of these make it a harder task to parse Chinese. $$$$$ We interpret these results as indicating that we have unlocked a heretofore undiscovered space of independence-assumption refinements for CTB parsing, suggesting that there is still considerable room for improvement in CTB parsing even with a small (90,000-word) training set; a parser-combining model such as that proposed in (Henderson and Brill, 1999), for example, might be effective here.
As pointed out in (Levyand Manning, 2003), there are many linguistic differences between Chinese and English, as well as structural differences between their corresponding tree banks, and some of these make it a harder task to parse Chinese. $$$$$ In addition to simplifying the parameterization of the parsing model and maintaining exactness, this 2WSJ-small is a randomly selected tenth of the full English Wall Street Journal corpus. model offers the prospect of increased flexibility in tuning the individual parse models.
As pointed out in (Levyand Manning, 2003), there are many linguistic differences between Chinese and English, as well as structural differences between their corresponding tree banks, and some of these make it a harder task to parse Chinese. $$$$$ Coordination scope errors occured in two major varieties: those where the misattached right conjunct is verbal (a VP or IP), and those where it is nominal the latter case is illustrated in and CRDLN in Figure The equivverbal coordination is generally marked with commas, whereas nominal coordination is marked with conjoiners or the mostly noun-conjoining punctuation mark &quot;, &quot; IP NP heretofore unmet conditions NP IP IP NP VP IP PU IP PU IP NP VP he I I president may VV him say president may he I meet him 120, say Figure 6: Ambiguity between communication verb subcategorization frame (left; corpus) and high coordination attachment (right; incorrect parse). ocal majority of low over high verbal attachment errors contrasts qualitatively with ETB parsing, where low attachment is more common and parsers tend to err toward high attachment.

First of all, we adopt the head finding rules for Chinese used in (Levy and Manning, 2003), and this affects sieve 4, 6 and 7 which are all take advantage of the head words. $$$$$ 4.1 Analysis by error type and PCFG-enrichment fixes Multilevel VP adjunction errors (Figure 5) are common in models without parent annotation, although even with parent annotation the presence of VP coordination would give multilevel VP adjunction nonzero probability.
First of all, we adopt the head finding rules for Chinese used in (Levy and Manning, 2003), and this affects sieve 4, 6 and 7 which are all take advantage of the head words. $$$$$ For the future, we believe that there is still room for considerable improvement in CTB parsing under our model.
First of all, we adopt the head finding rules for Chinese used in (Levy and Manning, 2003), and this affects sieve 4, 6 and 7 which are all take advantage of the head words. $$$$$ With nominal coordination scope errors, the situation is different: we found no false low attachments.
First of all, we adopt the head finding rules for Chinese used in (Levy and Manning, 2003), and this affects sieve 4, 6 and 7 which are all take advantage of the head words. $$$$$ In the CTB, BA heads a VP and always has a unique sister IP; but that IP essentially always rewrites as NP VP.
