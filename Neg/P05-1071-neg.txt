Both Diab et al (2004) and Habash and Rambow (2005) use support-vector machines with local features; the former for tokenization, POS tagging, and base phrase chunking; the latter for full morphological disambiguation. $$$$$ As a result of this process, we have the original text, with each word augmented with values for all the features in Figure 2.
Both Diab et al (2004) and Habash and Rambow (2005) use support-vector machines with local features; the former for tokenization, POS tagging, and base phrase chunking; the latter for full morphological disambiguation. $$$$$ For each of the ten classifiers, Yamcha then returns a confidence value for each possible value of the classifier, and in addition it marks the value that is chosen during subsequent Viterbi decoding (which need not be the value with the highest confidence value because of the inclusion of dynamic features).
Both Diab et al (2004) and Habash and Rambow (2005) use support-vector machines with local features; the former for tokenization, POS tagging, and base phrase chunking; the latter for full morphological disambiguation. $$$$$ In this paper, we show that the use of a morphological analyzer outperforms other tagging methods for Arabic; to our knowledge, we present the best-performing wide-coverage tokenizer on naturally occurring input and the bestperforming morphological tagger for Arabic.
Both Diab et al (2004) and Habash and Rambow (2005) use support-vector machines with local features; the former for tokenization, POS tagging, and base phrase chunking; the latter for full morphological disambiguation. $$$$$ However, there is a fair amount of descriptive work on dialectal morphology, so that dialectal morphological analyzers may be easier to come by than dialect corpora.

Habash and Sadat (2006) use the Arabic morphological analyzer MADA (Habash and Rambow, 2005) to segment the Arabic source; they propose various segmentation schemes. $$$$$ Third, we choose among the analyses returned by the morphological analyzer by using the output of the classifiers.
Habash and Sadat (2006) use the Arabic morphological analyzer MADA (Habash and Rambow, 2005) to segment the Arabic source; they propose various segmentation schemes. $$$$$ Second, we apply classifiers for ten morphological features to the words of the text.
Habash and Sadat (2006) use the Arabic morphological analyzer MADA (Habash and Rambow, 2005) to segment the Arabic source; they propose various segmentation schemes. $$$$$ However, the results for Rip show that retraining the Rip classifier on a new corpus can improve the results, without the need for retraining all ten Yamcha classifiers (which takes considerable time).
Habash and Sadat (2006) use the Arabic morphological analyzer MADA (Habash and Rambow, 2005) to segment the Arabic source; they propose various segmentation schemes. $$$$$ The only work on Arabic tagging that uses a corpus for training and evaluation (that we are aware of), (Diab et al., 2004), does not use a morphological analyzer.

Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al, 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). $$$$$ 8The ATB generates normalized forms of certain clitics and of the word stem, so that the resulting tokens are not simply the result of splitting the original words.
Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al, 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). $$$$$ We report in Figure 5 accuracy over all token fields for all words in the test corpus, as well as recall, precision, and f-measure for the non-null token fields.
Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al, 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). $$$$$ We present an approach to using a morphological analyzer for tokenizing and morphologically tagging (including partof-speech tagging) Arabic words in one process.

MADA is an SVM based system that disambiguates among different morphological analyses produced by BAMA (Habash and Rambow, 2005). $$$$$ Hajiˇc (2000) demonstrates convincingly that morphological disambiguation can be aided by a morphological analyzer, which, given a word without any context, gives us the set of all possible morphological tags.
MADA is an SVM based system that disambiguates among different morphological analyses produced by BAMA (Habash and Rambow, 2005). $$$$$ We specify a window of two words preceding and following the current word, using all 71 features for each word in this 5-word window.
MADA is an SVM based system that disambiguates among different morphological analyses produced by BAMA (Habash and Rambow, 2005). $$$$$ 2In this paper, we only discuss inflectional morphology.
MADA is an SVM based system that disambiguates among different morphological analyses produced by BAMA (Habash and Rambow, 2005). $$$$$ We report in Figure 5 accuracy over all token fields for all words in the test corpus, as well as recall, precision, and f-measure for the non-null token fields.

In a previous publication, we described the Morphological Analysis and Disambiguation of Arabic (MADA) system (Habash and Rambow, 2005). $$$$$ On our own reduced POS tagset, evaluating on TE1, we obtain an accuracy score of 98.1% on all tokens.
In a previous publication, we described the Morphological Analysis and Disambiguation of Arabic (MADA) system (Habash and Rambow, 2005). $$$$$ The baseline BL is the tokenization associated with the morphological analysis most frequently chosen for the input word in training.
In a previous publication, we described the Morphological Analysis and Disambiguation of Arabic (MADA) system (Habash and Rambow, 2005). $$$$$ The error rates on the baseline approximately double on TE2, reflecting the difference between TE2 and TR1, and the small size of TR1.
In a previous publication, we described the Morphological Analysis and Disambiguation of Arabic (MADA) system (Habash and Rambow, 2005). $$$$$ We learn classifiers for individual morphological features, as well as ways of using these classifiers to choose among entries from the output of the analyzer.

The algorithm we proposed in (Habash and Rambow, 2005) for choosing the best BAMA analysis simply counts the number of predicted values for the set of linguistic features in each candidate analysis. $$$$$ Thus, with the backoff analysis, unanalyzed words are distinguished for us only by the larger number of possible analyses (making it harder to choose the correct analysis).
The algorithm we proposed in (Habash and Rambow, 2005) for choosing the best BAMA analysis simply counts the number of predicted values for the set of linguistic features in each candidate analysis. $$$$$ Unfortunately, the full segmentation criteria are not given.
The algorithm we proposed in (Habash and Rambow, 2005) for choosing the best BAMA analysis simply counts the number of predicted values for the set of linguistic features in each candidate analysis. $$$$$ We intend to explore to what extent we can transfer models trained on Standard Arabic to dialectal morphological disambiguation.
The algorithm we proposed in (Habash and Rambow, 2005) for choosing the best BAMA analysis simply counts the number of predicted values for the set of linguistic features in each candidate analysis. $$$$$ The authors are listed in alphabetical order.

To create these schemes, we use MADA, an off-the-shelf resource for Arabic morphological disambiguation (Habash and Rambow, 2005), and TOKAN, a general Arabic tokenizer (Habash and Sadat, 2006). $$$$$ However, there is a fair amount of descriptive work on dialectal morphology, so that dialectal morphological analyzers may be easier to come by than dialect corpora.
To create these schemes, we use MADA, an off-the-shelf resource for Arabic morphological disambiguation (Habash and Rambow, 2005), and TOKAN, a general Arabic tokenizer (Habash and Sadat, 2006). $$$$$ We evaluate in this section how well our morphological disambiguation curacy measures for each input word whether it gets tokenized correctly, independently of the number of resulting tokens; the token-based measures refer to the four token fields into which the ATB splits each word determines the ATB tokenization.
To create these schemes, we use MADA, an off-the-shelf resource for Arabic morphological disambiguation (Habash and Rambow, 2005), and TOKAN, a general Arabic tokenizer (Habash and Sadat, 2006). $$$$$ The authors are listed in alphabetical order.

We tokenize using the MADA morphological disambiguation system (Habash and Rambow, 2005), and TOKAN, a general Arabic tokenizer (Sadat and Habash, 2006). $$$$$ In addition, a huge unannotated corpus (155 million words) is used to iteratively learn additional stems.
We tokenize using the MADA morphological disambiguation system (Habash and Rambow, 2005), and TOKAN, a general Arabic tokenizer (Sadat and Habash, 2006). $$$$$ We learn classifiers for individual morphological features, as well as ways of using these classifiers to choose among entries from the output of the analyzer.
We tokenize using the MADA morphological disambiguation system (Habash and Rambow, 2005), and TOKAN, a general Arabic tokenizer (Sadat and Habash, 2006). $$$$$ They use the same SVMbased learner we do, Yamcha, for three different tagging tasks: word tokenization (tagging on letters of a word), which we contrast with our work in Section 7; POS tagging, which we discuss in relation to our work in Section 8; and base phrase chunking, which we do not discuss in this paper.

MADA (Habash and Rambow, 2005) is used to pre-process the Arabic text for the translation model and 5-gram language model (LM). $$$$$ We learn classifiers for individual morphological features, as well as ways of using these classifiers to choose among entries from the output of the analyzer.
MADA (Habash and Rambow, 2005) is used to pre-process the Arabic text for the translation model and 5-gram language model (LM). $$$$$ Recall that the Yamcha classifiers are trained on TR1; in addition, Rip is trained on the output of these Yamcha classifiers on TR2.
MADA (Habash and Rambow, 2005) is used to pre-process the Arabic text for the translation model and 5-gram language model (LM). $$$$$ The morphological distinctions that the English tagset captures represent the complete morphological variation that can be found in English.
MADA (Habash and Rambow, 2005) is used to pre-process the Arabic text for the translation model and 5-gram language model (LM). $$$$$ There has been a fair amount of work on entirely unsupervised segmentation.

Our data is gold tokenized; however, all of the features we use are predicted using MADA (Habash and Rambow, 2005) following the work of Marton et al (2010). $$$$$ In addition, we define a second set of features which abstracts over the first set: for all features, we state whether any morphological analysis for that word has a value other than ‘NA’.
Our data is gold tokenized; however, all of the features we use are predicted using MADA (Habash and Rambow, 2005) following the work of Marton et al (2010). $$$$$ The matching included the use of some heuristics, since the representations and choices are not always consistent in the ATB.
Our data is gold tokenized; however, all of the features we use are predicted using MADA (Habash and Rambow, 2005) following the work of Marton et al (2010). $$$$$ The large set of Arabic tags has been mapped (by the Linguistic Data Consortium) to this smaller English set, and the meaning of the English tags has changed.
Our data is gold tokenized; however, all of the features we use are predicted using MADA (Habash and Rambow, 2005) following the work of Marton et al (2010). $$$$$ We have shown how to use a morphological analyzer for tokenization, part-of-speech tagging, and morphological disambiguation in Arabic.

For predicting morphological features, we use the MADA system (Habash and Rambow, 2005). $$$$$ We see that the best performing combination algorithm on TE1 is Maj, and on TE2 it is Rip.
For predicting morphological features, we use the MADA system (Habash and Rambow, 2005). $$$$$ Arabic words are often ambiguous in their morphological analysis.
For predicting morphological features, we use the MADA system (Habash and Rambow, 2005). $$$$$ Thus, with the backoff analysis, unanalyzed words are distinguished for us only by the larger number of possible analyses (making it harder to choose the correct analysis).
For predicting morphological features, we use the MADA system (Habash and Rambow, 2005). $$$$$ We present an approach to using a morphological analyzer for tokenizing and morphologically tagging (including partof-speech tagging) Arabic words in one process.

We compare our results with the form-based features from the state-of-the-art morphological analyzer MADA (Habash and Rambow, 2005). $$$$$ We have shown that the use of a morphological analyzer is beneficial in POS tagging, and we believe our results are the best published to date for tokenization of naturally occurring input (in undiacritized orthography) and POS tagging.
We compare our results with the form-based features from the state-of-the-art morphological analyzer MADA (Habash and Rambow, 2005). $$$$$ We consider this tagset unmotivated, as it makes morphological distinctions because they are marked in English, not Arabic.
We compare our results with the form-based features from the state-of-the-art morphological analyzer MADA (Habash and Rambow, 2005). $$$$$ We learn classifiers for individual morphological features, as well as ways of using these classifiers to choose among entries from the output of the analyzer.
We compare our results with the form-based features from the state-of-the-art morphological analyzer MADA (Habash and Rambow, 2005). $$$$$ These values represent a complete morphological disambiguation.

They use a trigram language model and the Arabic morphological analyzer MADA (Habash and Rambow, 2005) respectively, to segment the Arabic side of their corpora. $$$$$ We discuss the data and our lexicon in more detail in Section 4.
They use a trigram language model and the Arabic morphological analyzer MADA (Habash and Rambow, 2005) respectively, to segment the Arabic side of their corpora. $$$$$ Arabic is a morphologically complex language.1 The morphological analysis of a word consists of determining the values of a large number of (orthogonal) features, such as basic part-of-speech (i.e., noun, verb, and so on), voice, gender, number, information about the clitics, and so on.2 For Arabic, this gives us about 333,000 theoretically possible completely specified morphological analyses, i.e., morphological tags, of which about 2,200 are actually used in the first 280,000 words of the Penn Arabic Treebank (ATB).
They use a trigram language model and the Arabic morphological analyzer MADA (Habash and Rambow, 2005) respectively, to segment the Arabic side of their corpora. $$$$$ We obtain accuracy rates on all tasks in the high nineties.
They use a trigram language model and the Arabic morphological analyzer MADA (Habash and Rambow, 2005) respectively, to segment the Arabic side of their corpora. $$$$$ (The reason we use Ripper here is because it allows us to learn lower bounds for the confidence score features, which are real-valued.)

We use the Morphological Analyzer MADA (Habash and Rambow, 2005) to decompose the Arabic source. $$$$$ First, we obtain from our morphological analyzer a list of all possible analyses for the words of a given sentence.
We use the Morphological Analyzer MADA (Habash and Rambow, 2005) to decompose the Arabic source. $$$$$ Second, we use this approach to also perform tokenization.
We use the Morphological Analyzer MADA (Habash and Rambow, 2005) to decompose the Arabic source. $$$$$ The POS tag assigned to these words is then NO FUNC.
We use the Morphological Analyzer MADA (Habash and Rambow, 2005) to decompose the Arabic source. $$$$$ A backoff analysis mode in ALMORGEANA uses the morphological databases of prefixes, suffixes, and allowable combinations from the Buckwalter analyzer to hypothesize all possible stems along with feature sets.

The Arabic side is segmented according to the Arabic Treebank tokenization scheme (Maamouri et al, 2004) using the MADA + TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005). $$$$$ For example, verbal inflections for subject person, number, and gender are not marked; dual and plural are not distinguished on nouns; and gender is not marked on nouns at all.
The Arabic side is segmented according to the Arabic Treebank tokenization scheme (Maamouri et al, 2004) using the MADA + TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005). $$$$$ Arabic is a morphologically complex language.1 The morphological analysis of a word consists of determining the values of a large number of (orthogonal) features, such as basic part-of-speech (i.e., noun, verb, and so on), voice, gender, number, information about the clitics, and so on.2 For Arabic, this gives us about 333,000 theoretically possible completely specified morphological analyses, i.e., morphological tags, of which about 2,200 are actually used in the first 280,000 words of the Penn Arabic Treebank (ATB).
The Arabic side is segmented according to the Arabic Treebank tokenization scheme (Maamouri et al, 2004) using the MADA + TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005). $$$$$ The baseline BL is the tokenization associated with the morphological analysis most frequently chosen for the input word in training.
The Arabic side is segmented according to the Arabic Treebank tokenization scheme (Maamouri et al, 2004) using the MADA + TOKAN morphological analyzer and tokenizer (Habash and Rambow, 2005). $$$$$ In our approach, we determine all morphological properties of a word at once, so we can use this information to determine tokenization.

Past approaches include rule-based morphological analyzers (Buckwalter, 2004) and supervised learning (Habash and Rambow, 2005). $$$$$ The full list of features is shown in Figure 2, which also identifies possible values and which word classes (POS) can express these features.
Past approaches include rule-based morphological analyzers (Buckwalter, 2004) and supervised learning (Habash and Rambow, 2005). $$$$$ An important issue in using morphological analyzers for morphological disambiguation is what happens to unanalyzed words, i.e., words that receive no analysis from the morphological analyzer.
Past approaches include rule-based morphological analyzers (Buckwalter, 2004) and supervised learning (Habash and Rambow, 2005). $$$$$ In TR1, there are only 22 such words, presumably because the Buckwalter lexicon our morphological analyzer uses was developed onTR1.
Past approaches include rule-based morphological analyzers (Buckwalter, 2004) and supervised learning (Habash and Rambow, 2005). $$$$$ We consider this tagset unmotivated, as it makes morphological distinctions because they are marked in English, not Arabic.

The Morphological Analysis and Disambiguation of Arabic (MADA) system is described in (Habash and Rambow, 2005). $$$$$ However, in Arabic, much morphological variation goes untagged.
The Morphological Analysis and Disambiguation of Arabic (MADA) system is described in (Habash and Rambow, 2005). $$$$$ We specify a window of two words preceding and following the current word, using all 71 features for each word in this 5-word window.
The Morphological Analysis and Disambiguation of Arabic (MADA) system is described in (Habash and Rambow, 2005). $$$$$ We use the tagset here only to compare to previous work.

Habash and Rambow (2005) use SVM-classifiers for individual morphological features and a simple combining scheme for choosing among competing analyses proposed by the dictionary. $$$$$ In our approach, tokenizing and morphologically tagging (including part-of-speech tagging) are the same operation, which consists of three phases.
Habash and Rambow (2005) use SVM-classifiers for individual morphological features and a simple combining scheme for choosing among competing analyses proposed by the dictionary. $$$$$ This is a non-trivial task, as the classifiers may not fully disambiguate the options, or they may be contradictory, with none of them fully matching any one choice.
Habash and Rambow (2005) use SVM-classifiers for individual morphological features and a simple combining scheme for choosing among competing analyses proposed by the dictionary. $$$$$ We have shown that the use of a morphological analyzer is beneficial in POS tagging, and we believe our results are the best published to date for tokenization of naturally occurring input (in undiacritized orthography) and POS tagging.
Habash and Rambow (2005) use SVM-classifiers for individual morphological features and a simple combining scheme for choosing among competing analyses proposed by the dictionary. $$$$$ We investigate several options for how to do this combination.

To make our results more comparable to those by Habash and Rambow (2005), we converted the test set with the POS tags from the whole word tagger to their tokenization and to a reduced tag set of 15 tags. $$$$$ The large set of Arabic tags has been mapped (by the Linguistic Data Consortium) to this smaller English set, and the meaning of the English tags has changed.
To make our results more comparable to those by Habash and Rambow (2005), we converted the test set with the POS tags from the whole word tagger to their tokenization and to a reduced tag set of 15 tags. $$$$$ Diab et al. (2004) report a score of 95.5% for all tokens on a test corpus drawn from ATB1, thus their figure is comparable to our score of 97.6%.
To make our results more comparable to those by Habash and Rambow (2005), we converted the test set with the POS tags from the whole word tagger to their tokenization and to a reduced tag set of 15 tags. $$$$$ However, there is a fair amount of descriptive work on dialectal morphology, so that dialectal morphological analyzers may be easier to come by than dialect corpora.

Therefore, we repeated the experiments above with POS tags predicted by the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow, 2005). $$$$$ Furthermore, these features contain enough information about the presence of clitics and affixes to perform tokenization, for any reasonable tokenization scheme.
Therefore, we repeated the experiments above with POS tags predicted by the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow, 2005). $$$$$ Unsurprisingly, the results are much worse than in our resource-rich approach.
Therefore, we repeated the experiments above with POS tags predicted by the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow, 2005). $$$$$ We see that the baseline for TE1 is quite high, which we assume is due to the fact that when there is ambiguity, often one interpretation is much more prevelant than the others.
Therefore, we repeated the experiments above with POS tags predicted by the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow, 2005). $$$$$ The matching included the use of some heuristics, since the representations and choices are not always consistent in the ATB.
