Barzilay and Lapata (2008) presented early work in investigating the use of discourse to distinguish abridged from original encyclopedia articles. $$$$$ In contrast to existing systems which focus on intra-sentential features, we explore the contribution of discourse-level features to this task.
Barzilay and Lapata (2008) presented early work in investigating the use of discourse to distinguish abridged from original encyclopedia articles. $$$$$ The latter employs a large number of lexical and syntactic features which capture sentential differences among documents.
Barzilay and Lapata (2008) presented early work in investigating the use of discourse to distinguish abridged from original encyclopedia articles. $$$$$ This article proposes a novel framework for representing and measuring local coherence.
Barzilay and Lapata (2008) presented early work in investigating the use of discourse to distinguish abridged from original encyclopedia articles. $$$$$ We observe that the amount of data required depends on the domain at hand.

We adopt Barzilay and Lapata (2008)'s entity based local coherence model to represent a document by an entity grid, and extract local transitions among entities in continuous discourse constituents. $$$$$ We are grateful to Claire Cardie and Vincent Ng for providing us the results of their coreference system on our data.
We adopt Barzilay and Lapata (2008)'s entity based local coherence model to represent a document by an entity grid, and extract local transitions among entities in continuous discourse constituents. $$$$$ For instance, the probability of the transition [S –] in the grid from Table 1 is 0.08 (computed as a ratio of its frequency [i.e., six] divided by the total number of transitions of length two [i.e., 75]).
We adopt Barzilay and Lapata (2008)'s entity based local coherence model to represent a document by an entity grid, and extract local transitions among entities in continuous discourse constituents. $$$$$ Such information can be expressed in many ways (e.g., using constituent labels or thematic role information).
We adopt Barzilay and Lapata (2008)'s entity based local coherence model to represent a document by an entity grid, and extract local transitions among entities in continuous discourse constituents. $$$$$ In the discourse literature, entity-based theories are primarily applied at the level of local coherence, while relational models, such as Rhetorical Structure Theory (Mann and Thomson 1988; Marcu 2000), are used to model the global structure of discourse.

A prominent example is the entity-based model by Barzilay and Lapata (2008). $$$$$ Earthquakes 1,896 2,056 Accidents 2,095 2,087 Once the ranking function is learned, unseen renderings (xij,xik) of document di can be ranked simply by computing the values w*Φ(xij) and w*Φ(xik) and sorting them accordingly.
A prominent example is the entity-based model by Barzilay and Lapata (2008). $$$$$ Automatic, albeit noisy, feature extraction allows us to perform a large scale evaluation of differently instantiated coherence models across genres and applications.
A prominent example is the entity-based model by Barzilay and Lapata (2008). $$$$$ For instance, Miltsakaki and Kukich (2000) annotate a corpus of student essays with entity transition information, and show that the distribution of transitions correlates with human grades.
A prominent example is the entity-based model by Barzilay and Lapata (2008). $$$$$ This article proposes a novel framework for representing and measuring local coherence.

Adapted from the introduction to Barzilay and Lapata (2008). $$$$$ We also evaluated the training requirements for the readability system described herein.
Adapted from the introduction to Barzilay and Lapata (2008). $$$$$ In both experiments, our method yields improvements over state-of-the-art models.

We follow Barzilay and Lapata (2008) and use the Fisher Sign test. $$$$$ Any opinions, findings, and conclusions or recommendations expressed herein are those of the authors and do not necessarily reflect the views of the National Science Foundation or EPSRC.
We follow Barzilay and Lapata (2008) and use the Fisher Sign test. $$$$$ Using the proposed representation, we achieve good performance on text ordering, summary coherence evaluation, and readability assessment.
We follow Barzilay and Lapata (2008) and use the Fisher Sign test. $$$$$ This article focuses on local coherence, which captures text relatedness at the level of sentence-to-sentence transitions.
We follow Barzilay and Lapata (2008) and use the Fisher Sign test. $$$$$ Such a mechanism is particularly appropriate for generation and summarization systems as they can produce multiple text realizations of the same underlying content, either by varying parameter values, or by relaxing constraints that control the generation process.

The entity-based coherence model, proposed by Barzilay and Lapata (2008), is one of the most popular statistical models of inter-sentential coherence, and learns coherence properties similar to those employed by Centering Theory (Grosz et al, 1995). $$$$$ This article proposes a novel framework for representing and measuring local coherence.
The entity-based coherence model, proposed by Barzilay and Lapata (2008), is one of the most popular statistical models of inter-sentential coherence, and learns coherence properties similar to those employed by Centering Theory (Grosz et al, 1995). $$$$$ The authors acknowledge the support of the National Science Foundation (Barzilay; CAREER grant IIS-0448168 and grant IIS-0415865) and EPSRC (Lapata; grant GR/T04540/01).
The entity-based coherence model, proposed by Barzilay and Lapata (2008), is one of the most popular statistical models of inter-sentential coherence, and learns coherence properties similar to those employed by Centering Theory (Grosz et al, 1995). $$$$$ The salience status of an entity is often reflected in its grammatical function and the linguistic form of its subsequent mentions.
The entity-based coherence model, proposed by Barzilay and Lapata (2008), is one of the most popular statistical models of inter-sentential coherence, and learns coherence properties similar to those employed by Centering Theory (Grosz et al, 1995). $$$$$ In other words, entity transitions capture not only text coherence properties, but also reflect stylistic and genre-specific discourse properties.

Their local model of discourse coherence is based on the entity-grid (Barzilay and Lapata, 2008), as well as on the lexicalized IBM model (see Section 4.6 above); we have experimented with both, and showed that they have a minimal effect on grading performance with the FCE dataset. $$$$$ Both salience and syntactic information contribute to the accuracy of the ranking model.
Their local model of discourse coherence is based on the entity-grid (Barzilay and Lapata, 2008), as well as on the lexicalized IBM model (see Section 4.6 above); we have experimented with both, and showed that they have a minimal effect on grading performance with the FCE dataset. $$$$$ Thanks to Eli Barzilay, Eugene Webber, and three anonymous reviewers for helpful comments and suggestions.
Their local model of discourse coherence is based on the entity-grid (Barzilay and Lapata, 2008), as well as on the lexicalized IBM model (see Section 4.6 above); we have experimented with both, and showed that they have a minimal effect on grading performance with the FCE dataset. $$$$$ We would like to note that in this experiment we apply a coreference resolution tool to the original text and then generate permutations for the pairwise ranking task.
Their local model of discourse coherence is based on the entity-grid (Barzilay and Lapata, 2008), as well as on the lexicalized IBM model (see Section 4.6 above); we have experimented with both, and showed that they have a minimal effect on grading performance with the FCE dataset. $$$$$ The authors acknowledge the support of the National Science Foundation (Barzilay; CAREER grant IIS-0448168 and grant IIS-0415865) and EPSRC (Lapata; grant GR/T04540/01).

First, we show in a sentence ordering experiment that topological field information improves the entity grid model of Barzilay and Lapata (2008) more than grammatical role and simple clausal order information do, particularly when manual annotations of this information are not available. $$$$$ We re-conceptualize coherence assessment as a learning task and show that our entity-based representation is well-suited for ranking-based generation and text classification tasks.
First, we show in a sentence ordering experiment that topological field information improves the entity grid model of Barzilay and Lapata (2008) more than grammatical role and simple clausal order information do, particularly when manual annotations of this information are not available. $$$$$ We are grateful to Claire Cardie and Vincent Ng for providing us the results of their coreference system on our data.

Barzilay and Lapata (2008) introduce the entity grid as a method of representing the coherence of a document. $$$$$ The ability of these systems to generate high quality text, almost indistinguishable from human writing, makes the incorporation of coherence theories in robust large-scale systems particularly appealing.
Barzilay and Lapata (2008) introduce the entity grid as a method of representing the coherence of a document. $$$$$ Central to this approach is the entity-grid representation of discourse, which captures patterns of entity distribution in a text.
Barzilay and Lapata (2008) introduce the entity grid as a method of representing the coherence of a document. $$$$$ In order to learn a ranking, we require a set of summaries, each of which has been rated in terms of coherence.
Barzilay and Lapata (2008) introduce the entity grid as a method of representing the coherence of a document. $$$$$ Therefore, our exploration of the parameter space is guided by three considerations: the linguistic importance of a parameter, the accuracy of its automatic computation, and the size of the resulting feature space.

In Barzilay and Lapata (2008), an entity grid is constructed for each document, and is represented as a matrix in which each row represents a sentence, and each column represents an entity. $$$$$ To give a concrete example, the pronoun they is attested 173 times in the difficult corpus and only 73 in the easy corpus.
In Barzilay and Lapata (2008), an entity grid is constructed for each document, and is represented as a matrix in which each row represents a sentence, and each column represents an entity. $$$$$ In the summary evaluation task, we compare the rankings produced by the model against human coherence judgments elicited for automatically generated summaries.
In Barzilay and Lapata (2008), an entity grid is constructed for each document, and is represented as a matrix in which each row represents a sentence, and each column represents an entity. $$$$$ We also evaluated the training requirements for the readability system described herein.

We test a version of the entity grid representation augmented with topological fields in a sentence ordering experiment corresponding to Experiment 1 of Barzilay and Lapata (2008). $$$$$ Current approaches recast coreference resolution as a classification task.
We test a version of the entity grid representation augmented with topological fields in a sentence ordering experiment corresponding to Experiment 1 of Barzilay and Lapata (2008). $$$$$ We re-conceptualize coherence assessment as a learning task and show that our entity-based representation is well-suited for ranking-based generation and text classification tasks.
We test a version of the entity grid representation augmented with topological fields in a sentence ordering experiment corresponding to Experiment 1 of Barzilay and Lapata (2008). $$$$$ The algorithm introduced in the article automatically abstracts a text into a set of entity transition sequences and records distributional, syntactic, and referential information about discourse entities.

This set is larger than the set that was used in Experiment 1 of Barzilay and Lapata (2008), which consists of 400 documents in two English subcorpora on earthquakes and accidents respectively. $$$$$ We re-conceptualize coherence assessment as a learning task and show that our entity-based representation is well-suited for ranking-based generation and text classification tasks.
This set is larger than the set that was used in Experiment 1 of Barzilay and Lapata (2008), which consists of 400 documents in two English subcorpora on earthquakes and accidents respectively. $$$$$ Central to this approach is the entity-grid representation of discourse, which captures patterns of entity distribution in a text.
This set is larger than the set that was used in Experiment 1 of Barzilay and Lapata (2008), which consists of 400 documents in two English subcorpora on earthquakes and accidents respectively. $$$$$ We formulate the first two problems—text ordering and summary evaluation—as ranking problems, and present an efficiently learnable model that ranks alternative renderings of the same information based on their degree of local coherence.
This set is larger than the set that was used in Experiment 1 of Barzilay and Lapata (2008), which consists of 400 documents in two English subcorpora on earthquakes and accidents respectively. $$$$$ The algorithm introduced in the article automatically abstracts a text into a set of entity transition sequences and records distributional, syntactic, and referential information about discourse entities.

Barzilay and Lapata (2008) found that grammatical role improves performance in this task for an English corpus. $$$$$ Note that in both ranking experiments we assume that the algorithm is provided with a limited number of alternatives.
Barzilay and Lapata (2008) found that grammatical role improves performance in this task for an English corpus. $$$$$ The authors acknowledge the support of the National Science Foundation (Barzilay; CAREER grant IIS-0448168 and grant IIS-0415865) and EPSRC (Lapata; grant GR/T04540/01).
Barzilay and Lapata (2008) found that grammatical role improves performance in this task for an English corpus. $$$$$ The algorithm introduced in the article automatically abstracts a text into a set of entity transition sequences and records distributional, syntactic, and referential information about discourse entities.
Barzilay and Lapata (2008) found that grammatical role improves performance in this task for an English corpus. $$$$$ We are grateful to Claire Cardie and Vincent Ng for providing us the results of their coreference system on our data.

The results we obtain are higher than the results for the English corpora of Barzilay and Lapata (2008) (87.2% on the Earthquakes corpus and 90.4% on the Accidents corpus), but this is probably due to corpus differences as well as the availability of perfect coreference information in our experiments. $$$$$ The transitions are ranked, that is, texts demonstrating certain types of transitions are deemed more coherent than texts where such transitions are absent or infrequent.
The results we obtain are higher than the results for the English corpora of Barzilay and Lapata (2008) (87.2% on the Earthquakes corpus and 90.4% on the Accidents corpus), but this is probably due to corpus differences as well as the availability of perfect coreference information in our experiments. $$$$$ Any opinions, findings, and conclusions or recommendations expressed herein are those of the authors and do not necessarily reflect the views of the National Science Foundation or EPSRC.
The results we obtain are higher than the results for the English corpora of Barzilay and Lapata (2008) (87.2% on the Earthquakes corpus and 90.4% on the Accidents corpus), but this is probably due to corpus differences as well as the availability of perfect coreference information in our experiments. $$$$$ This is not uncommon in summaries with many proper names.
The results we obtain are higher than the results for the English corpora of Barzilay and Lapata (2008) (87.2% on the Earthquakes corpus and 90.4% on the Accidents corpus), but this is probably due to corpus differences as well as the availability of perfect coreference information in our experiments. $$$$$ We simply record whether an entity is mentioned in the discourse and in what grammatical role.

Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ Our results were compared to the LSA model introduced in Experiment 1 (see Section 4.2 for details).
Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ A unigram, bigram, and trigram model was estimated for each class, and perplexity scores were used to assess their performance on test data.
Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ As mentioned previously, our participants tend to rate human-authored summaries higher than machine-generated ones.
Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ Besides coreference, our feature representation captures important information about the presence and distribution of entities in discourse.

We extend the original entity-based coherence model (Barzilay and Lapata, 2008) by learning from more fine-grained coherence preferences in training data. $$$$$ Equipped with the feature vector representation introduced herein, we can view coherence assessment as a machine learning problem.
We extend the original entity-based coherence model (Barzilay and Lapata, 2008) by learning from more fine-grained coherence preferences in training data. $$$$$ Grammatical role information can be extracted from the output of a broad-coverage dependency parser (Lin 2001; Briscoe and Carroll 2002) or any state-of-the art statistical parser (Collins 1997; Charniak 2000).
We extend the original entity-based coherence model (Barzilay and Lapata, 2008) by learning from more fine-grained coherence preferences in training data. $$$$$ Given k original documents, each with n randomly generated permutations, we obtain k · n (trivially) annotated pairwise rankings for training and testing.
We extend the original entity-based coherence model (Barzilay and Lapata, 2008) by learning from more fine-grained coherence preferences in training data. $$$$$ Expanding our grammatical categories to modifiers and adjuncts may provide additional information, in particular when considering machine generated texts.

We show that our multiple-rank model outperforms B & L's basic model on two tasks, sentence ordering and summary coherence rating, evaluated on the same datasets as in Barzilay and Lapata (2008). $$$$$ We compared the performance of our algorithm against two state-of-the-art models proposed by Foltz, Kintsch, and Landauer (1998) and Barzilay and Lee (2004).
We show that our multiple-rank model outperforms B & L's basic model on two tasks, sentence ordering and summary coherence rating, evaluated on the same datasets as in Barzilay and Lapata (2008). $$$$$ In our experiments, we built two content models, one for the Accidents corpus and one for the Earthquake corpus.
We show that our multiple-rank model outperforms B & L's basic model on two tasks, sentence ordering and summary coherence rating, evaluated on the same datasets as in Barzilay and Lapata (2008). $$$$$ The algorithm introduced in the article automatically abstracts a text into a set of entity transition sequences and records distributional, syntactic, and referential information about discourse entities.

For entity extraction, Barzilay and Lapata (2008) had two conditions $$$$$ The algorithm introduced in the article automatically abstracts a text into a set of entity transition sequences and records distributional, syntactic, and referential information about discourse entities.
For entity extraction, Barzilay and Lapata (2008) had two conditions $$$$$ We are grateful to Claire Cardie and Vincent Ng for providing us the results of their coreference system on our data.
For entity extraction, Barzilay and Lapata (2008) had two conditions $$$$$ The algorithm introduced in the article automatically abstracts a text into a set of entity transition sequences and records distributional, syntactic, and referential information about discourse entities.
For entity extraction, Barzilay and Lapata (2008) had two conditions $$$$$ Each text can thus be viewed as a distribution defined over transition types.

Two evaluation tasks for Barzilay and Lapata (2008)'s entity-based model are sentence ordering and summary coherence rating. $$$$$ Centering Theory formalizes fluctuations in topic continuity in terms of transitions between adjacent utterances.
Two evaluation tasks for Barzilay and Lapata (2008)'s entity-based model are sentence ordering and summary coherence rating. $$$$$ Central to this approach is the entity-grid representation of discourse, which captures patterns of entity distribution in a text.
Two evaluation tasks for Barzilay and Lapata (2008)'s entity-based model are sentence ordering and summary coherence rating. $$$$$ The authors acknowledge the support of the National Science Foundation (Barzilay; CAREER grant IIS-0448168 and grant IIS-0415865) and EPSRC (Lapata; grant GR/T04540/01).

Barzilay and Lapata (2008) experimented on two datasets $$$$$ In the basic SVM framework, we try to separate the positive and negative instances by a hyperplane.
Barzilay and Lapata (2008) experimented on two datasets $$$$$ The corpora we used in our sentence ordering and readability assessment experiments are somewhat similar (i.e., human-authored narratives), whereas our summary coherence rating experiment employed machine generated texts.
Barzilay and Lapata (2008) experimented on two datasets $$$$$ We assumed that these summaries were maximally coherent.
Barzilay and Lapata (2008) experimented on two datasets $$$$$ In this article we proposed a novel framework for representing and measuring text coherence.
