The additional two systems were: PD-EDU: Same as EDU except using the perfect discourse trees, available from the RST corpus (Carlson et al, 2001). $$$$$ We anticipate that the RST Corpus will be multifunctional and support a wide range of language engineering applications.
The additional two systems were: PD-EDU: Same as EDU except using the perfect discourse trees, available from the RST corpus (Carlson et al, 2001). $$$$$ Re-tagging of a large number of documents after major enhancements to the annotation guidelines was also time consuming.
The additional two systems were: PD-EDU: Same as EDU except using the perfect discourse trees, available from the RST corpus (Carlson et al, 2001). $$$$$ In the end, all of the trees worked successfully with these programs.

We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RSTDTB) (Carlsonetal., 2001) distributed by the Linguistic Data Consortium (LDC). $$$$$ As Table 1 shows, all levels demonstrate a marked improvement from April to November (when the final corpus was completed), ranging from about 0.77 to 0.92 at the span level, from 0.70 to 0.88 at the nuclearity level, and from 0.60 to 0.79 at the relation level.
We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RSTDTB) (Carlsonetal., 2001) distributed by the Linguistic Data Consortium (LDC). $$$$$ We anticipate that the RST Corpus will be multifunctional and support a wide range of language engineering applications.
We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RSTDTB) (Carlsonetal., 2001) distributed by the Linguistic Data Consortium (LDC). $$$$$ The advent of large-scale collections of annotated data has marked a paradigm shift in the research community for natural language processing.
We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RSTDTB) (Carlsonetal., 2001) distributed by the Linguistic Data Consortium (LDC). $$$$$ 1998.

Two of the main corpora with discourse annotations are the RST Discourse Treebank (RSTDT) (Carlson et al., 2001) and the Penn Discourse Treebank (PDTB) (Prasad et al, 2008a), which are both based on the Wall Street Journal (WSJ) corpus. $$$$$ More extensive analysis of the final tagged corpus will demonstrate the extent to which individual relations that are similar in semantic content were distinguished consistently during the tagging process.
Two of the main corpora with discourse annotations are the RST Discourse Treebank (RSTDT) (Carlson et al., 2001) and the Penn Discourse Treebank (PDTB) (Prasad et al, 2008a), which are both based on the Wall Street Journal (WSJ) corpus. $$$$$ The tool enables an annotator to segment a text into units, and then build up a hierarchical structure of the discourse.
Two of the main corpora with discourse annotations are the RST Discourse Treebank (RSTDT) (Carlson et al., 2001) and the Penn Discourse Treebank (PDTB) (Prasad et al, 2008a), which are both based on the Wall Street Journal (WSJ) corpus. $$$$$ For example, the class Explanation includes the relations evidence, explanationargumentative, and reason, while TopicComment includes problem-solution, questionanswer, statement-response, topic-comment, and comment-topic.
Two of the main corpora with discourse annotations are the RST Discourse Treebank (RSTDT) (Carlson et al., 2001) and the Penn Discourse Treebank (PDTB) (Prasad et al, 2008a), which are both based on the Wall Street Journal (WSJ) corpus. $$$$$ In this paper, we recount our experience in developing a large resource with discourse-level annotation for NLP research.

Fortunately, RST Discourse Treebank (RSTDT) (Carlson et al, 2001) is an available resource to help with. $$$$$ This was followed by a one-month reassessment phase, during which we measured consistency across the group on a select set of documents, and refined the annotation rules.
Fortunately, RST Discourse Treebank (RSTDT) (Carlson et al, 2001) is an available resource to help with. $$$$$ In order to measure inter-annotator consistency, 53 of the documents (13.8%) were double-tagged.
Fortunately, RST Discourse Treebank (RSTDT) (Carlson et al, 2001) is an available resource to help with. $$$$$ During the initial phase of about four months, the team created a preliminary corpus of 100 tagged documents.
Fortunately, RST Discourse Treebank (RSTDT) (Carlson et al, 2001) is an available resource to help with. $$$$$ The advent of large-scale collections of annotated data has marked a paradigm shift in the research community for natural language processing.

In the Cause versus Contrast case, their reported performance exceeds ours significantly; however, in a subset of their experiments which test Cause versus Contrast on instances from the human annotated RSTBank corpus (Carlson et al., 2001) where no cue phrase is present, they report only 63% accuracy over a 56% baseline (the baseline is $$$$$ Thus, the RST Corpus provides an additional level of linguistic annotation to supplement existing annotated resources.
In the Cause versus Contrast case, their reported performance exceeds ours significantly; however, in a subset of their experiments which test Cause versus Contrast on instances from the human annotated RSTBank corpus (Carlson et al., 2001) where no cue phrase is present, they report only 63% accuracy over a 56% baseline (the baseline is $$$$$ Preliminary steps toward the creation of a discourse and text In of the First International Conference on Language
In the Cause versus Contrast case, their reported performance exceeds ours significantly; however, in a subset of their experiments which test Cause versus Contrast on instances from the human annotated RSTBank corpus (Carlson et al., 2001) where no cue phrase is present, they report only 63% accuracy over a 56% baseline (the baseline is $$$$$ A number of steps were taken to ensure the quality of the final discourse corpus.

 $$$$$ 1998.
 $$$$$ However, rich theoretical approaches to discourse/text analysis (Van Dijk and Kintsch, 1983; Meyer, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988) have yet to be applied on a large scale.
 $$$$$ Researchers in content analysis (Krippendorff, 1980) suggest that values of kappa > 0.8 reflect very high agreement, while values between 0.6 and 0.8 reflect good agreement.

For the first, the labelled/unlabelled relations f scores are 50.3% /73.0% and for the latter, they are 75.3% /84.0%: this is similar to the performance on other discourse annotation projects, e.g., Carlson et al (2001). $$$$$ We ourselves are eager to explore these aspects of the RST, and expect new insights to appear through analysis of the corpus.
For the first, the labelled/unlabelled relations f scores are 50.3% /73.0% and for the latter, they are 75.3% /84.0%: this is similar to the performance on other discourse annotation projects, e.g., Carlson et al (2001). $$$$$ We anticipate that the RST Corpus will be multifunctional and support a wide range of language engineering applications.
For the first, the labelled/unlabelled relations f scores are 50.3% /73.0% and for the latter, they are 75.3% /84.0%: this is similar to the performance on other discourse annotation projects, e.g., Carlson et al (2001). $$$$$ Because the goal of this effort was to build a high-quality, consistently annotated reference corpus, the task required that we employ people as annotators whose primary professional experience was in the area of language analysis and reporting, provide extensive annotator training, and specify a rigorous set of annotation guidelines.

The generator is informed by a corpus study of embedded discourse units on two discourse annotated corpora: the RST Discourse Treebank (Carlson et al., 2001) and the Penn Discourse Treebank. $$$$$ The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.
The generator is informed by a corpus study of embedded discourse units on two discourse annotated corpora: the RST Discourse Treebank (Carlson et al., 2001) and the Penn Discourse Treebank. $$$$$ Annotation of a single document could take anywhere from 30 minutes to several hours, depending on the length and topic.
The generator is informed by a corpus study of embedded discourse units on two discourse annotated corpora: the RST Discourse Treebank (Carlson et al., 2001) and the Penn Discourse Treebank. $$$$$ The first step in characterizing the discourse structure of a text in our protocol is to determine the elementary discourse units (EDUs), which are the minimal building blocks of a discourse tree.
The generator is informed by a corpus study of embedded discourse units on two discourse annotated corpora: the RST Discourse Treebank (Carlson et al., 2001) and the Penn Discourse Treebank. $$$$$ For example, the class Explanation includes the relations evidence, explanationargumentative, and reason, while TopicComment includes problem-solution, questionanswer, statement-response, topic-comment, and comment-topic.

We evaluate DPLP on the RST Discourse Tree bank (Carlson et al, 2001), comparing against state-of-the-art results. $$$$$ These exploratory sessions led to enhancements in the tagging guidelines.
We evaluate DPLP on the RST Discourse Tree bank (Carlson et al, 2001), comparing against state-of-the-art results. $$$$$ During this process, we regularly tracked interannotator agreement (see Section 4.2).
We evaluate DPLP on the RST Discourse Tree bank (Carlson et al, 2001), comparing against state-of-the-art results. $$$$$ As Table 1 shows, all levels demonstrate a marked improvement from April to November (when the final corpus was completed), ranging from about 0.77 to 0.92 at the span level, from 0.70 to 0.88 at the nuclearity level, and from 0.60 to 0.79 at the relation level.

To compare with previous works on RSTDT, we use the 18 coarse-grained relations defined in (Carlson et al, 2001). $$$$$ Annotators developed different strategies for analyzing a document and building up the corresponding discourse tree.
To compare with previous works on RSTDT, we use the 18 coarse-grained relations defined in (Carlson et al, 2001). $$$$$ Semantic checking involved reviewing nuclearity assignments, as well as choice of relation and level of attachment in the tree.
To compare with previous works on RSTDT, we use the 18 coarse-grained relations defined in (Carlson et al, 2001). $$$$$ These can be characterized both in terms of the kinds of features annotated as well as by the scope of the annotation.
To compare with previous works on RSTDT, we use the 18 coarse-grained relations defined in (Carlson et al, 2001). $$$$$ So far, the annotation of discourse structure of documents has been applied primarily to identifying topical segments (Hearst, 1997), inter-sentential relations (Nomoto and Matsumoto, 1999; Ts’ou et al., 2000), and hierarchical analyses of small corpora (Moser and Moore, 1995; Marcu et al., 1999).

(Carlson et al 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion. $$$$$ In combination with the tree structure, the concept of nuclearity also guided an annotator to capture one of a number of possible stylistic interpretations.
(Carlson et al 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion. $$$$$ The articles range over a variety of topics, including financial reports, general interest stories, business-related news, cultural reviews, editorials, and letters to the editor.
(Carlson et al 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion. $$$$$ In the final phase, the annotation team concentrated on ways to reduce differences by adopting some heuristics for handling higher levels of the discourse structure.
(Carlson et al 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion. $$$$$ The final tagged corpus contains 21,789 EDUs with an average of 56.59 EDUs per document.

To demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the RST parsed Wall Street Journal corpus as input (Carlson et al, 2001). $$$$$ Preliminary steps toward the creation of a discourse and text In of the First International Conference on Language
To demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the RST parsed Wall Street Journal corpus as input (Carlson et al, 2001). $$$$$ However, as examples 2-4 illustrate, separating rhetorical from syntactic analysis is not always easy.
To demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the RST parsed Wall Street Journal corpus as input (Carlson et al, 2001). $$$$$ The kappa coefficient (Siegel and Castellan, 1988) has been used extensively in previous empirical studies of discourse (Carletta et al., 1997; Flammia and Zue, 1995; Passonneau and Litman, 1997).
To demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the RST parsed Wall Street Journal corpus as input (Carlson et al, 2001). $$$$$ 1998.

In Discourse Tree Bank (Carlson et al, 2001) only 26% of Contrast relations were indicated by cue phrases while in NTC-7 about 70% of Contrast were indicated by cue phrases. $$$$$ Using Style 2, the annotator segments each sentence, and builds up corresponding sub-trees for spans [16], [17-18], [19-21] and [22-26].

They use the RST corpus (Carlson et al,2001), which contains 385 Wall Street Journal articles annotated following the Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ Giacomo Ferrari.
They use the RST corpus (Carlson et al,2001), which contains 385 Wall Street Journal articles annotated following the Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ The reliability of a dialogue structure coding Linguistics 13-32.

(Soricut and Marcu, 2003) parsed the discourse structures of sentences on RST Bank data set (Carlson et al, 2001) which is annotated based on Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ The statistics measure annotation reliability at four levels: elementary discourse units, hierarchical spans, hierarchical nuclearity and hierarchical relation assignments.
(Soricut and Marcu, 2003) parsed the discourse structures of sentences on RST Bank data set (Carlson et al, 2001) which is annotated based on Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ We believe this resource holds great promise as a rich new source of textlevel information to support multiple lines of research for language understanding applications.
(Soricut and Marcu, 2003) parsed the discourse structures of sentences on RST Bank data set (Carlson et al, 2001) which is annotated based on Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ The documents range in size from 31 to 2124 words, with an average of 458.14 words per document.
(Soricut and Marcu, 2003) parsed the discourse structures of sentences on RST Bank data set (Carlson et al, 2001) which is annotated based on Rhetorical Structure Theory (Mann and Thompson, 1988). $$$$$ Preliminary steps toward the creation of a discourse and text In of the First International Conference on Language

The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), is a corpus annotated in the framework of RST. $$$$$ In the final phase (about six months) all 100 documents were re-tagged with the new approach and guidelines.
The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), is a corpus annotated in the framework of RST. $$$$$ The articles range over a variety of topics, including financial reports, general interest stories, business-related news, cultural reviews, editorials, and letters to the editor.
The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), is a corpus annotated in the framework of RST. $$$$$ Different sets of documents were chosen for each stage, with no overlap in documents.
The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), is a corpus annotated in the framework of RST. $$$$$ and Anne Anderson.

In the corpus of Rhetorical Structure trees built by Carlson et al (2001), for example, we have observed that only 61 of 238 CONTRAST relation sand 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase. $$$$$ The added value of multiple layers of overt linguistic phenomena enhancing the Penn Treebank information can be exploited to advance the study of discourse, to enhance language technologies such as text summarization, machine translation or information retrieval, or to be a testbed for new and creative natural language processing techniques.
In the corpus of Rhetorical Structure trees built by Carlson et al (2001), for example, we have observed that only 61 of 238 CONTRAST relation sand 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase. $$$$$ The articles range over a variety of topics, including financial reports, general interest stories, business-related news, cultural reviews, editorials, and letters to the editor.
In the corpus of Rhetorical Structure trees built by Carlson et al (2001), for example, we have observed that only 61 of 238 CONTRAST relation sand 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase. $$$$$ The procedural knowledge available at the EDU level is likely to need further refinement for higher-level text spans along the lines of other work which posits a few macro-level relations for text segments, such as Ferrari (1998) or Meyer (1985).
In the corpus of Rhetorical Structure trees built by Carlson et al (2001), for example, we have observed that only 61 of 238 CONTRAST relation sand 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase. $$$$$ Thus, the RST Corpus provides an additional level of linguistic annotation to supplement existing annotated resources.

However, empirical work of Marcu (2000) and Carlson et al (2001) suggests that the majority of occurrences of but, for example, do signal CONTRAST relations. $$$$$ All trees were checked with a discourse parser and tree traversal program which often identified errors undetected by the manual validation process.
However, empirical work of Marcu (2000) and Carlson et al (2001) suggests that the majority of occurrences of but, for example, do signal CONTRAST relations. $$$$$ Thus, the RST Corpus provides an additional level of linguistic annotation to supplement existing annotated resources.
However, empirical work of Marcu (2000) and Carlson et al (2001) suggests that the majority of occurrences of but, for example, do signal CONTRAST relations. $$$$$ The initial focus was on resolving segmentation differences, but over time this shifted to addressing issues of relations and nuclearity.
However, empirical work of Marcu (2000) and Carlson et al (2001) suggests that the majority of occurrences of but, for example, do signal CONTRAST relations. $$$$$ Features may include specific discourse cues or markers, coreference links, identification of rhetorical relations, etc.

To test this, we used the corpus of discourse trees built in the style of RST by Carlson et al (2001). $$$$$ Below, we describe the protocol that we used to build consistent RST annotations.
To test this, we used the corpus of discourse trees built in the style of RST by Carlson et al (2001). $$$$$ We believe this resource holds great promise as a rich new source of textlevel information to support multiple lines of research for language understanding applications.
To test this, we used the corpus of discourse trees built in the style of RST by Carlson et al (2001). $$$$$ The final inventory of rhetorical relations is data driven, and is based on extensive analysis of the corpus.
To test this, we used the corpus of discourse trees built in the style of RST by Carlson et al (2001). $$$$$ The kappa coefficient (Siegel and Castellan, 1988) has been used extensively in previous empirical studies of discourse (Carletta et al., 1997; Flammia and Zue, 1995; Passonneau and Litman, 1997).

If no cue phrases are used to signal the relation between two elementary discourse units, an automatic discourse labeler can at best guess that an ELABORATION relation holds between the units, because ELABORATION relations are the most frequently used relations (Carlson et al, 2001). $$$$$ For details on obtaining the corpus, annotation software, tagging guidelines, and related documentation and resources, see: http://www.isi.edu/~marcu/discourse.
If no cue phrases are used to signal the relation between two elementary discourse units, an automatic discourse labeler can at best guess that an ELABORATION relation holds between the units, because ELABORATION relations are the most frequently used relations (Carlson et al, 2001). $$$$$ 1997.
If no cue phrases are used to signal the relation between two elementary discourse units, an automatic discourse labeler can at best guess that an ELABORATION relation holds between the units, because ELABORATION relations are the most frequently used relations (Carlson et al, 2001). $$$$$ Building the RST Corpus involved more than a dozen people on a full or part-time basis over a oneyear time frame (Jan. – Dec. 2000).
