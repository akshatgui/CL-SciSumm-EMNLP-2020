 $$$$$ If a clause dominates both a finite and infinitival verb, as well as a negative particle (i.e., a word tagged as PTKNEG), then the negative particle is moved to directly follow the finite verb.

 $$$$$ R: yet we would point out again that it is absolutely vital to guarantee independent financial control. however, we would like once again refer to the absolute need for the independence of the financial control. however, we would like to once again to the absolute need for the independence of the financial control out.
 $$$$$ As an example, the previous example now has the negative particle nicht moved, to give the following clause structure:
 $$$$$ A potential decoding decision at this point is to add the phrase “pass on” to the English hypothesis, at the same time absorbing “aushaendigen” from the German string.

This result was found to be significant (p= 0.021) under the paired bootstrap resampling method of Koehn (2004), and is close to significant (p= 0.058) under the sign test of Collins et al (2005). $$$$$ [6] Negation As a final step, we move negative particles.
This result was found to be significant (p= 0.021) under the paired bootstrap resampling method of Koehn (2004), and is close to significant (p= 0.058) under the sign test of Collins et al (2005). $$$$$ We define the subject to be the left-most child of the clause with label ...-SB or PPEREP, and the head to be the leftmost child with label ...-HD.
This result was found to be significant (p= 0.021) under the paired bootstrap resampling method of Koehn (2004), and is close to significant (p= 0.058) under the sign test of Collins et al (2005). $$$$$ We have demonstrated that adding knowledge about syntactic structure can significantly improve the performance of an existing state-of-the-art statistical machine translation system.

Our best performing method used unsupervised morphology with L-match (see Section 2.2) and the improvement is significant: bootstrap resampling provides a confidence margin of 0.77 and a t-test (Collins et al, 2005) showed significance with p= 0.001. $$$$$ For example, in the parse tree in Figure 1, aushaendigen would be moved to precede Ihnen in the first verb phrase (VPOC), and uebernehmen would be moved to precede das in the second VP-OC.
Our best performing method used unsupervised morphology with L-match (see Section 2.2) and the improvement is significant: bootstrap resampling provides a confidence margin of 0.77 and a t-test (Collins et al, 2005) showed significance with p= 0.001. $$$$$ We now describe the method we use for reordering German sentences.
Our best performing method used unsupervised morphology with L-match (see Section 2.2) and the improvement is significant: bootstrap resampling provides a confidence margin of 0.77 and a t-test (Collins et al, 2005) showed significance with p= 0.001. $$$$$ Define to be the probability that the reordered system improves on the baseline system, given that the two systems do not have equal performance.
Our best performing method used unsupervised morphology with L-match (see Section 2.2) and the improvement is significant: bootstrap resampling provides a confidence margin of 0.77 and a t-test (Collins et al, 2005) showed significance with p= 0.001. $$$$$ B: at that time was clear that we actually enlargement within the framework able to cope with the eu budget, the drawn.

 $$$$$ [6] Negation As a final step, we move negative particles.
 $$$$$ The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system.
 $$$$$ In the reordering phase, each of the following six restructuring steps were applied to a German parse tree, in sequence (see table 1 also, for examples of the reordering steps): [1] Verb initial In any verb phrase (i.e., phrase with label VP-...) find the head of the phrase (i.e., the child with label -HD) and move it into the initial position within the verb phrase.

We parse the input using the Collins parser (Collins, 1997) and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order (Collins et al, 2005). $$$$$ In the future we may investigate data-driven approaches, in an effort to learn reordering models automatically.
We parse the input using the Collins parser (Collins, 1997) and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order (Collins et al, 2005). $$$$$ We have demonstrated that adding knowledge about syntactic structure can significantly improve the performance of an existing state-of-the-art statistical machine translation system.
We parse the input using the Collins parser (Collins, 1997) and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order (Collins et al, 2005). $$$$$ Given this definition of , we found that , , and .
We parse the input using the Collins parser (Collins, 1997) and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order (Collins et al, 2005). $$$$$ The end result of the training process is a lexicon of phrase-to-phrase pairs, with associated costs or probabilities.

We are aware of two methods that have been proposed for significance testing with BLUE: bootstrap resampling (Koehn, 2004b; Zhang et al, 2004) and the sign test (Collins et al, 2005). $$$$$ Our current approach is based on hand-crafted rules, which are based on our linguistic knowledge of how German and English syntax differs.
We are aware of two methods that have been proposed for significance testing with BLUE: bootstrap resampling (Koehn, 2004b; Zhang et al, 2004) and the sign test (Collins et al, 2005). $$$$$ The second step is to apply a series of transformations to the parse tree, effectively reordering the surface string on the source language side of the translation system.
We are aware of two methods that have been proposed for significance testing with BLUE: bootstrap resampling (Koehn, 2004b; Zhang et al, 2004) and the sign test (Collins et al, 2005). $$$$$ In the future we may investigate data-driven approaches, in an effort to learn reordering models automatically.

But Collins et al (2005) note that it is not clear whether the conditions required by bootstrap resampling are met in the case of BLUE, and recommend the sign test instead. $$$$$ We have demonstrated that adding knowledge about syntactic structure can significantly improve the performance of an existing state-of-the-art statistical machine translation system.
But Collins et al (2005) note that it is not clear whether the conditions required by bootstrap resampling are met in the case of BLUE, and recommend the sign test instead. $$$$$ Annotator 1 judged 40 translations to be improved by the reordered model; 40 translations to be of equal quality; and 20 translations to be worse under the reordered model.
But Collins et al (2005) note that it is not clear whether the conditions required by bootstrap resampling are met in the case of BLUE, and recommend the sign test instead. $$$$$ In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems.

All results are statistically significant with p= 0.05 using the sign-test described in (Collins et al, 2005). $$$$$ If a clause dominates both a finite and infinitival verb, as well as a negative particle (i.e., a word tagged as PTKNEG), then the negative particle is moved to directly follow the finite verb.
All results are statistically significant with p= 0.05 using the sign-test described in (Collins et al, 2005). $$$$$ We describe a method for incorporating syntactic information in statistical machine translation systems.
All results are statistically significant with p= 0.05 using the sign-test described in (Collins et al, 2005). $$$$$ We could then define as follows: If If If Unfortunately Bleu scores do not give persentence measures and , and thus do not allow a definition of in this way.
All results are statistically significant with p= 0.05 using the sign-test described in (Collins et al, 2005). $$$$$ Source language sentences are reordered in test data, and also in training data that is used by the underlying phrasebased system.

Clause restructuring performed with hand-crafted reordering rules for German-to-English and Chinese-to-English tasks are presented in (Collins et al, 2005) and (Wang et al, 2007), respectively. $$$$$ For example, in the subordinate clause in Figure 1, the subject Sie would be moved to precede koennen, giving the following structure: [4] Particles In verb particle constructions, move the particle to immediately precede the verb.
Clause restructuring performed with hand-crafted reordering rules for German-to-English and Chinese-to-English tasks are presented in (Collins et al, 2005) and (Wang et al, 2007), respectively. $$$$$ As one example, the following clause contains both a verb (forden) as well as a particle (auf): [5] Infinitives In some cases, infinitival verbs are still not in the correct position after transformations [1]–[4].
Clause restructuring performed with hand-crafted reordering rules for German-to-English and Chinese-to-English tasks are presented in (Collins et al, 2005) and (Wang et al, 2007), respectively. $$$$$ We can define the following probabilities: where the probability is taken with respect to the distribution .

At the same time, many reorderings can be performed more efficiently based on fixed (hand-crafted) rules (as it is done in (Collins et al, 2005)). $$$$$ However, correctness of the bootstrap method relies on some technical properties of the statistic (e.g., Bleu scores) being used (e.g., see (Wasserman, 2004) theorem 8.3); (Koehn, 2004; Zhang and Vogel, 2004) do not discuss whether Bleu scores meet any such criteria, which makes us uncertain of their correctness when applied to Bleu scores.
At the same time, many reorderings can be performed more efficiently based on fixed (hand-crafted) rules (as it is done in (Collins et al, 2005)). $$$$$ As an example, the previous example now has the negative particle nicht moved, to give the following clause structure:
At the same time, many reorderings can be performed more efficiently based on fixed (hand-crafted) rules (as it is done in (Collins et al, 2005)). $$$$$ We define the subject to be the left-most child of the clause with label ...-SB or PPEREP, and the head to be the leftmost child with label ...-HD.
At the same time, many reorderings can be performed more efficiently based on fixed (hand-crafted) rules (as it is done in (Collins et al, 2005)). $$$$$ More specifically, if a finite verb (i.e., verb tagged as VVFIN) and a particle (i.e., word tagged as PTKVZ) are found in the same clause, move the particle to precede the verb.

We followed the approximation described in (Collins et al, 2005) to get around this problem. $$$$$ Thanks to Brooke Cowan and Luke Zettlemoyer for providing the human judgements of translation performance.

Collins et al (2005) approach the problem of properly translating negation in their general reordering setting. $$$$$ Our baseline is the phrase-based MT system of (Koehn et al., 2003).
Collins et al (2005) approach the problem of properly translating negation in their general reordering setting. $$$$$ Position of infinitival verbs.
Collins et al (2005) approach the problem of properly translating negation in their general reordering setting. $$$$$ In particular, at each point in decoding a “cost” is associated with skipping over 1 or more German words.

To make the word order of German input sentences more English-like a version of the rules of (Collins et al, 2005) were partially implemented using tagged output from the RFTagger. $$$$$ We define the subject to be the left-most child of the clause with label ...-SB or PPEREP, and the head to be the leftmost child with label ...-HD.
To make the word order of German input sentences more English-like a version of the rules of (Collins et al, 2005) were partially implemented using tagged output from the RFTagger. $$$$$ We now describe the method we use for reordering German sentences.
To make the word order of German input sentences more English-like a version of the rules of (Collins et al, 2005) were partially implemented using tagged output from the RFTagger. $$$$$ If a clause dominates both a finite and infinitival verb, as well as a negative particle (i.e., a word tagged as PTKNEG), then the negative particle is moved to directly follow the finite verb.
To make the word order of German input sentences more English-like a version of the rules of (Collins et al, 2005) were partially implemented using tagged output from the RFTagger. $$$$$ R: secondly, without these guarantees, the fall in consumption will impact negatively upon the entire industry. and, secondly, the collapse of consumption without these guarantees will have a negative impact on the whole sector. and secondly, the collapse of the consumption of these guarantees without a negative impact on the whole sector.

Bold numbers are not significantly different from the best result according to the sign test (p= 0.05) (Collins et al, 2005). $$$$$ In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems.
Bold numbers are not significantly different from the best result according to the sign test (p= 0.05) (Collins et al, 2005). $$$$$ As an example, the previous example now has the negative particle nicht moved, to give the following clause structure:
Bold numbers are not significantly different from the best result according to the sign test (p= 0.05) (Collins et al, 2005). $$$$$ The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system.
Bold numbers are not significantly different from the best result according to the sign test (p= 0.05) (Collins et al, 2005). $$$$$ Our approach makes use of syntactic knowledge to overcome a weakness of tradition SMT systems, namely long-distance reordering.

The test data for the experiments consisted of 2,000 sentences, and was the same test set as that used by Collins et al (2005). $$$$$ Our baseline is the phrase-based MT system of (Koehn et al., 2003).
The test data for the experiments consisted of 2,000 sentences, and was the same test set as that used by Collins et al (2005). $$$$$ Our approach involves a preprocessing step, where sentences in the language being translated are modified before being passed to an existing phrasebased translation system.
The test data for the experiments consisted of 2,000 sentences, and was the same test set as that used by Collins et al (2005). $$$$$ The goal of this step is to recover an underlying word order that is closer to the target language word-order than the original string.
The test data for the experiments consisted of 2,000 sentences, and was the same test set as that used by Collins et al (2005). $$$$$ For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)).

 $$$$$ The goal of this step is to recover an underlying word order that is closer to the target language word-order than the original string.
 $$$$$ Our baseline is the phrase-based MT system of (Koehn et al., 2003).
 $$$$$ The BLEU score for the new system was 26.8%, an improvement from 25.2% BLEU for the baseline system.

Collins et al (2005) address this problem by reordering German sentences to more closely parallel English word order, prior to translation by a PSMT system. $$$$$ (Koehn, 2004) gives empirical evidence that these give accurate estimates for Bleu statistics.
Collins et al (2005) address this problem by reordering German sentences to more closely parallel English word order, prior to translation by a PSMT system. $$$$$ 6/21/1998.
Collins et al (2005) address this problem by reordering German sentences to more closely parallel English word order, prior to translation by a PSMT system. $$$$$ More specifically, if a finite verb (i.e., verb tagged as VVFIN) and a particle (i.e., word tagged as PTKVZ) are found in the same clause, move the particle to precede the verb.
Collins et al (2005) address this problem by reordering German sentences to more closely parallel English word order, prior to translation by a PSMT system. $$$$$ Any remaining errors are of course our own.

Collins et al (2005) (German-to-English) use six hand-crafted reordering rules targeting the placement of verbs, subjects, particles and negation. $$$$$ In the future we may investigate data-driven approaches, in an effort to learn reordering models automatically.
Collins et al (2005) (German-to-English) use six hand-crafted reordering rules targeting the placement of verbs, subjects, particles and negation. $$$$$ The first step of the method is to parse the source language string that is being translated.

Zwarts and Dras (2007) implement six rules for Dutch-to-English translation, analogous to those of Collins et al (2005), as part of an exploration of dependency distance in syntax-augmented PSMT. $$$$$ While our experiments are on German, other languages have word orders that are very different from English, so we believe our methods will be generally applicable.
Zwarts and Dras (2007) implement six rules for Dutch-to-English translation, analogous to those of Collins et al (2005), as part of an exploration of dependency distance in syntax-augmented PSMT. $$$$$ Philipp Koehn was supported by a grant from NTT, Agmt. dtd.
Zwarts and Dras (2007) implement six rules for Dutch-to-English translation, analogous to those of Collins et al (2005), as part of an exploration of dependency distance in syntax-augmented PSMT. $$$$$ The BLEU score for the new system was 26.8%, an improvement from 25.2% BLEU for the baseline system.
Zwarts and Dras (2007) implement six rules for Dutch-to-English translation, analogous to those of Collins et al (2005), as part of an exploration of dependency distance in syntax-augmented PSMT. $$$$$ Note that if we only consider preferences where both annotators were in agree'We chose these shorter sentences for human evaluation because in general they include a single clause, which makes human judgements relatively straightforward. ment (and consider all disagreements to fall into the “equal” category), then 33 translations improved under the reordering system, and 13 translations became worse.
