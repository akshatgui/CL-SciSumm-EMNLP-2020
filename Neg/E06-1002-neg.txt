 $$$$$ John Williams (VC).
 $$$$$ A disambiguation SVM kernel is trained to exploit the high coverage and rich structure of the knowledge encoded in an online encyclopedia.
 $$$$$ Therefore, besides the non-ambiguous names that come from redirect pages, additionalaliases can be found by looking for all disambiguation pages that list a particular Wikipedia en tity.
 $$$$$ least two capital letters, then e is a named en tity.

With respect to the use of Wikipedia as a resource for natural language processing tasks, the work that is most closely related to ours is perhaps the name entity disambiguation algorithm proposed in (Bunescu and Pasca, 2006), where an SVM kernel is trained on the entries found in Wikipediafor ambiguous named entities. $$$$$ Otherwise, go to step 3.
With respect to the use of Wikipedia as a resource for natural language processing tasks, the work that is most closely related to ours is perhaps the name entity disambiguation algorithm proposed in (Bunescu and Pasca, 2006), where an SVM kernel is trained on the entries found in Wikipediafor ambiguous named entities. $$$$$ John Williams (composer) John Towner Williams John Williams Film score composers, 20th century classical composers John Williams (wrestler) Ian Rotten John Williams Professional wrestlers, People living in Baltimore John Williams (VC) none John Williams British Army soldiers, British Victoria Cross recipients Boston Pops Orchestra Boston Pops, Pops American orchestras, The Boston Pops Orchestra Massachusetts musicians United States US, USA, ...

 $$$$$ In his example, the planet Venus may be referred to using the phrases ?morning star?
 $$$$$ As an added benefit, userswould have easier access to a wider variety of re sults, whenever the top 10 or so results returned by the largest search engines happen to refer to only one particular (arguably the most popular) sense of the query (e.g., the programming language in the case of Python), thus submerging or ?hiding?
 $$$$$ 1.1 Motivation.
 $$$$$ goal of this paper is to design a disambiguationmethod that 1) learns the magnitude of these correlations, and 2) uses these correlations in a scor ing function, together with the cosine similarity.

The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. $$$$$ John Williams (VC).
The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. $$$$$ ?John Williams and the Boston Pops conducted a summer Star Wars concert at Tan glewood.?
The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. $$$$$ John Williams (VC) 1 won Victoria Cross ...

 $$$$$ ?John Williams lost a Taipei death match against his brother, Axl Rotten.?
 $$$$$ 1 lost Taipei match ...
 $$$$$ A disambiguation SVM kernel is trained to exploit the high coverage and rich structure of the knowledge encoded in an online encyclopedia.

 $$$$$ When submitting queries such as John Williamsor Python, search engine users could also be presented with a compilation of facts and specific at tributes about those named entities, rather than aset of best-matching web pages.
 $$$$$ When submitting queries such as John Williamsor Python, search engine users could also be presented with a compilation of facts and specific at tributes about those named entities, rather than aset of best-matching web pages.
 $$$$$ An exam ple entry with a considerably higher number of redirect pages is United States.

Based on the aforementioned resources of information, we follow the method presented in (Bunescu and Pasca, 2006) to build a dictionary called ViDic. $$$$$ The name is transformed (using underscores for spaces) into a title whose article contains aredirect link to the actual article for that en tity.
Based on the aforementioned resources of information, we follow the method presented in (Bunescu and Pasca, 2006) to build a dictionary called ViDic. $$$$$ The resultingmodel significantly outperforms a less in formed baseline.
Based on the aforementioned resources of information, we follow the method presented in (Bunescu and Pasca, 2006) to build a dictionary called ViDic. $$$$$ As an added benefit, userswould have easier access to a wider variety of re sults, whenever the top 10 or so results returned by the largest search engines happen to refer to only one particular (arguably the most popular) sense of the query (e.g., the programming language in the case of Python), thus submerging or ?hiding?

 $$$$$ One of the chal lenges in creating such an alternative search result page is the inherent ambiguity of the queries, as several instances of the same class (e.g., different people) or different classes (e.g., a type of snake, a programming language, or a movie) may share the same name in the query.
 $$$$$ Because every title inWikipedia must begin with a capital letter, the de cision whether a title is a proper name relies on the following sequence of heuristic steps: 11 1.

 $$$$$ Otherwise, go to step 3.
 $$$$$ Each article in Wikipedia is uniquely identified by its title ? a sequence of words separated byunderscores, with the first word always capital ized.

(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance. $$$$$ The effectiveness of the search could be greatly improved if the search results were grouped together according to the corresponding sense, rather than presented as a flat, sense-mixed list of items (whether links to full-length documents, or extracted facts).
(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance. $$$$$ As a departure from the methodology of previous approaches, the paper exploits a non-traditionalweb-based resource.
(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance. $$$$$ Consequently, a named entity e is included in d:E if and only if d = e:title, d 2 e:R, or d2e:D.
(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance. $$$$$ John Williams (wrestler).

After the task of EL was initiated with Wikipedia-based works on entity disambiguation, in particular by Cucerzan (2007) and Bunescu and Pasca (2006), numerous systems have been developed, encouraged by the TAC 2009 KB population task (McNamee and Dang, 2009). $$$$$ 1 lost Taipei match ...
After the task of EL was initiated with Wikipedia-based works on entity disambiguation, in particular by Cucerzan (2007) and Bunescu and Pasca (2006), numerous systems have been developed, encouraged by the TAC 2009 KB population task (McNamee and Dang, 2009). $$$$$ We organize all named entities from Wikipedia into a dictionary structure D, where each string entry d 2 D is mapped to the set of entities d:E that can be denoted by d in Wikipedia.
After the task of EL was initiated with Wikipedia-based works on entity disambiguation, in particular by Cucerzan (2007) and Bunescu and Pasca (2006), numerous systems have been developed, encouraged by the TAC 2009 KB population task (McNamee and Dang, 2009). $$$$$ This relationis captured in Wikipedia through redirect and dis ambiguation pages, as described in the next two sections.

This is addressed by various methods, such as setting a threshold of minimal similarity for an entity selection (Bunescu and Pasca, 2006), or training a separate binary classifier to judge whether the returned top candidate is the actual denotation (Zheng et al, 2010). $$$$$ The article may be too short or incomplete..
This is addressed by various methods, such as setting a threshold of minimal similarity for an entity selection (Bunescu and Pasca, 2006), or training a separate binary classifier to judge whether the returned top candidate is the actual denotation (Zheng et al, 2010). $$$$$ text of the article, in positions other than at the beginning of sentences.
This is addressed by various methods, such as setting a threshold of minimal similarity for an entity selection (Bunescu and Pasca, 2006), or training a separate binary classifier to judge whether the returned top candidate is the actual denotation (Zheng et al, 2010). $$$$$ If at least 75% of these occurrences are capitalized, then e is a named entity.

 $$$$$ least two capital letters, then e is a named en tity.
 $$$$$ The remainder of the pa per is organized as follows.
 $$$$$ If e:title is a one word title that contains at.
 $$$$$ A frequent case are queries about named entities,which constitute a significant fraction of popu lar web queries according to search engine logs.

 $$$$$ However, if one wants to combine evidence from multiple web pages, then one needs again to solve the name disambiguation problem.
 $$$$$ One of the chal lenges in creating such an alternative search result page is the inherent ambiguity of the queries, as several instances of the same class (e.g., different people) or different classes (e.g., a type of snake, a programming language, or a movie) may share the same name in the query.
 $$$$$ Otherwise, go to step 3.

 $$$$$ If e:title is a multiword title, check the cap-.
 $$$$$ As an example, the September 2005 version contains 751,666 articles, around 180,000 more articles than four months earlier.
 $$$$$ If at least 75% of these occurrences are capitalized, then e is a named entity.

We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pasca, 2006) to link the noun phrase subjects into Wikipedia. $$$$$ John Williams (composer) John Williams (wrestler) Figure 1: Word-Category correlations.
We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pasca, 2006) to link the noun phrase subjects into Wikipedia. $$$$$ We present a new method for detecting anddisambiguating named entities in open do main text.
We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pasca, 2006) to link the noun phrase subjects into Wikipedia. $$$$$ The combined heuristics extract close to half amillion named entities from Wikipedia.
We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pasca, 2006) to link the noun phrase subjects into Wikipedia. $$$$$ 2.

 $$$$$ It seems therefore natural to try to exploit the webin order to also improve the performance of relation extraction, i.e. the discovery of useful re lationships between named entities mentioned in text documents.
 $$$$$ We present a new method for detecting anddisambiguating named entities in open do main text.
 $$$$$ We present a new method for detecting anddisambiguating named entities in open do main text.
 $$$$$ We present a new method for detecting anddisambiguating named entities in open do main text.

Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia. $$$$$ 2.
Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia. $$$$$ Wikipedia is a free online encyclopedia writtencollaboratively by volunteers, using a wiki soft ware that allows almost anyone to add and change articles.
Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia. $$$$$ In his example, the planet Venus may be referred to using the phrases ?morning star?
Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia. $$$$$ low because the Wikipedia article for named entity e k does not contain all words that are relevant to e k , it is worth considering the correlation between context words and the categories to which e kbe longs.

 $$$$$ A disambiguation SVM kernel is trained to exploit the high coverage and rich structure of the knowledge encoded in an online encyclopedia.
 $$$$$ One of the chal lenges in creating such an alternative search result page is the inherent ambiguity of the queries, as several instances of the same class (e.g., different people) or different classes (e.g., a type of snake, a programming language, or a movie) may share the same name in the query.
 $$$$$ The de-facto web search paradigm defines the re sult to a user?s query as roughly a set of links to the best-matching documents selected out of billions of items available.
 $$$$$ The window size is set to 55, which is the value that was observed to give optimum performance in the related task of cross-document coreference (Gooi and Allan, 2004).

 $$$$$ The resultingmodel significantly outperforms a less in formed baseline.
 $$$$$ ?John Williams lost a Taipei death match against his brother, Axl Rotten.?
 $$$$$ Concretely, it takes advan tage of some of the human knowledge available in Wikipedia, a free online encyclopedia createdthrough decentralized, collective efforts of thou sands of users (Remy, 2002).
