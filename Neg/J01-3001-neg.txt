Stevenson and Wilks (2001) presented a classifier combination framework where disambiguation methods (simulated annealing, subject codes and selectional restrictions) were combined using the TiMBL memory-based approach (Daelemans et al, 1999). $$$$$ Stevenson (1998) describes an evaluation of this system in which the relations identified were compared with those derived from Penn TreeBank parses (Marcus, Santorini, and Marcinkiewicz 1993).
Stevenson and Wilks (2001) presented a classifier combination framework where disambiguation methods (simulated annealing, subject codes and selectional restrictions) were combined using the TiMBL memory-based approach (Daelemans et al, 1999). $$$$$ We are grateful for the feedback from many colleagues in Sheffield, especially Mark Hepple, and for the detailed comments from the anonymous reviewers of an earlier version of this paper.
Stevenson and Wilks (2001) presented a classifier combination framework where disambiguation methods (simulated annealing, subject codes and selectional restrictions) were combined using the TiMBL memory-based approach (Daelemans et al, 1999). $$$$$ In the remainder of this paper we go on to describe a sense tagger that assigns senses from LDOCE using a combination of classifiers.

Stevenson and Wilks (2001) propose a somewhat related technique to handle WSD, based on integrating LDOCE classes with simulated annealing. $$$$$ The main sources of divergence are the choice of computational paradigm, the proportion of text words disambiguated, the granularity of the meanings assigned to them, and the knowledge sources used.
Stevenson and Wilks (2001) propose a somewhat related technique to handle WSD, based on integrating LDOCE classes with simulated annealing. $$$$$ One type of module, a filter, can be used to remove senses from consideration when a knowledge source identifies them as unlikely in context.
Stevenson and Wilks (2001) propose a somewhat related technique to handle WSD, based on integrating LDOCE classes with simulated annealing. $$$$$ Some researchers have concentrated on producing WSD systems that base results on a limited number of words, for example Yarowsky (1995) and Schtitze (1992) who quoted results for 12 words, and a second group, including Leacock, Towell, and Voorhees (1993) and Bruce and Wiebe (1994), who gave results for just one, namely interest.
Stevenson and Wilks (2001) propose a somewhat related technique to handle WSD, based on integrating LDOCE classes with simulated annealing. $$$$$ The approach was based on the hypothesis that words exhibited &quot;one sense per collocation&quot; (Yarowsky 1993).

Stevenson and Wilks (2001) investigated the interaction of knowledge sources, such as part-of-speech, dictionary definition, subject codes, etc. on WSD. $$$$$ This level of semantic disambiguation is frequently sufficient for choosing the correct target word in an English-to-French Machine Translation system and is at a similar level of granularity to the sense distinctions explored by other researchers in WSD, for example Brown et al. (1991), Yarowsky (1996), and McRoy (1992) (see Section 2).
Stevenson and Wilks (2001) investigated the interaction of knowledge sources, such as part-of-speech, dictionary definition, subject codes, etc. on WSD. $$$$$ If more than one sense has been assigned the maximum value, the tie is again broken by choosing the first sense.
Stevenson and Wilks (2001) investigated the interaction of knowledge sources, such as part-of-speech, dictionary definition, subject codes, etc. on WSD. $$$$$ The work described here was supported by the European Union Language Engineering project ECRAN â€” Extraction of Content: Research at Near-market (LE-2110).

However, they are quite rare, even in monolingual contexts (Stevenson and Wilks, 2001, e.g.), and they are not able to integrate and use knowledge coming from corpus and other resources during the learning process. $$$$$ It is argued that this approach is more likely to assist the creation of practical systems.
However, they are quite rare, even in monolingual contexts (Stevenson and Wilks, 2001, e.g.), and they are not able to integrate and use knowledge coming from corpus and other resources during the learning process. $$$$$ We are grateful for the feedback from many colleagues in Sheffield, especially Mark Hepple, and for the detailed comments from the anonymous reviewers of an earlier version of this paper.
However, they are quite rare, even in monolingual contexts (Stevenson and Wilks, 2001, e.g.), and they are not able to integrate and use knowledge coming from corpus and other resources during the learning process. $$$$$ However, we believe we have shown that interesting combinations of WSD methods on a substantial training corpus are possible, and that this can show, among other things, the relative independence of the types of semantic information expressed by the various forms of lexical input.
However, they are quite rare, even in monolingual contexts (Stevenson and Wilks, 2001, e.g.), and they are not able to integrate and use knowledge coming from corpus and other resources during the learning process. $$$$$ Word sense disambiguation (WSD) is a computational linguistics task likely to benefit from the tradition of combining different knowledge sources in artificial intelligence research.

 $$$$$ Probabilities are estimated from frequency of occurrence in the training data.
 $$$$$ Syntactic, semantic, and pragmatic information are all potentially useful for WSD, as can be demonstrated by considering the following sentences: The first two sentences contain the ambiguous word well; as an adjective in (1) where it is used in its &quot;state of health&quot; sense, and as a noun in (2), meaning &quot;water supply&quot;.
 $$$$$ Therefore, up to 95% of word types in LDOCE can be disambiguated to the homograph level by part-of-speech information alone.
 $$$$$ Any errors are our own.

This is also shown by Stevenson and Wilks (2001), who used the Longman Dictionary of Contemporary English (LDOCE) as sense inventory. $$$$$ This paper reported a system which disambiguated all content words in a text, as defined by a standard machine readable dictionary, with a high degree of accuracy.
This is also shown by Stevenson and Wilks (2001), who used the Longman Dictionary of Contemporary English (LDOCE) as sense inventory. $$$$$ An important step in the exploration of this hypothesis is to determine which linguistic knowledge sources are most useful and whether their combination leads to improved results.
This is also shown by Stevenson and Wilks (2001), who used the Longman Dictionary of Contemporary English (LDOCE) as sense inventory. $$$$$ Previously reported WSD systems that enjoyed a high level of accuracy have often operated on restricted vocabularies and employed a single WSD methodology.
This is also shown by Stevenson and Wilks (2001), who used the Longman Dictionary of Contemporary English (LDOCE) as sense inventory. $$$$$ Although its overall result is slightly below the overall corpus baseline, it is very successful at disambiguating verbs.

 $$$$$ We are grateful for the feedback from many colleagues in Sheffield, especially Mark Hepple, and for the detailed comments from the anonymous reviewers of an earlier version of this paper.
 $$$$$ The semantic tagging was carried out by trained lexicographers under disciplined conditions that attempted to keep tagging inconsistencies to a minimum.
 $$$$$ Our system attempts to disambiguate all content words in running text rather than limiting itself to treating a restricted vocabulary of words.
 $$$$$ This approach is rather conservative in that it does not reject a sense unless it is impossible for it to fit into the preference pattern of the sentence.

However, there has been no direct comparison of which knowledge sources are the most useful or whether combining a variety of knowledge sources, a strategy which has been shown to be successful for WSD in the general domain (Stevenson and Wilks, 2001), improves results. $$$$$ SEMCOR contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper names, which we ignored, leaving 85,737 words which could potentially be translated.
However, there has been no direct comparison of which knowledge sources are the most useful or whether combining a variety of knowledge sources, a strategy which has been shown to be successful for WSD in the general domain (Stevenson and Wilks, 2001), improves results. $$$$$ This process is carried out by splitting the available data into ten roughly equal subsets.
However, there has been no direct comparison of which knowledge sources are the most useful or whether combining a variety of knowledge sources, a strategy which has been shown to be successful for WSD in the general domain (Stevenson and Wilks, 2001), improves results. $$$$$ These are excluded because they have already been analyzed semantically by means of the classification added by the named entity identifier (see Section 4.4).
However, there has been no direct comparison of which knowledge sources are the most useful or whether combining a variety of knowledge sources, a strategy which has been shown to be successful for WSD in the general domain (Stevenson and Wilks, 2001), improves results. $$$$$ The SENSEVAL evaluation framework (Kilgarriff 1998) was a DARPA-style competition designed to bring some conformity to the field of WSD, although it has yet to achieve that aim completely.

 $$$$$ There was a lexicon of 8,775 unique roots, a hierarchy of 1,000 concepts, and a set of 1,400 collocational patterns.
 $$$$$ Some verb senses will disallow all senses for a particular noun it dominates and these senses of the verb are immediately rejected.
 $$$$$ This paper reported a system which disambiguated all content words in a text, as defined by a standard machine readable dictionary, with a high degree of accuracy.
 $$$$$ At the homograph level, the number correctly disambiguated to the homograph is divided by the number which are polyhomographic.

In the hybrid approaches that have been explored so far, deep knowledge, like selectional preferences, is either pre-processed into a vector representation to accommodate machine learning algorithms, or used in previous steps to filter out possible senses e.g. (Stevenson and Wilks, 2001). $$$$$ Among the researchers mentioned above, one must distinguish between, on the one hand, supervised approaches that are inherently limited in performance to the words over which they evaluate because of limited training data and, on the other hand, approaches whose unsupervised learning methodology is applied to only small numbers of words for evaluation, but which could in principle have been used to tag all content words in a text.
In the hybrid approaches that have been explored so far, deep knowledge, like selectional preferences, is either pre-processed into a vector representation to accommodate machine learning algorithms, or used in previous steps to filter out possible senses e.g. (Stevenson and Wilks, 2001). $$$$$ However, there is no reason to believe that the method reported here is limited to lexicons with this structure.
In the hybrid approaches that have been explored so far, deep knowledge, like selectional preferences, is either pre-processed into a vector representation to accommodate machine learning algorithms, or used in previous steps to filter out possible senses e.g. (Stevenson and Wilks, 2001). $$$$$ We present a sense tagger which uses several knowledge sources.
In the hybrid approaches that have been explored so far, deep knowledge, like selectional preferences, is either pre-processed into a vector representation to accommodate machine learning algorithms, or used in previous steps to filter out possible senses e.g. (Stevenson and Wilks, 2001). $$$$$ Gillian Callaghan was extremely helpful in the preparation of the final version of this paper.

We refer to this method as stacking, and it has been previously used to integrate heterogeneous knowledge sources for WSD (Stevenson and Wilks, 2001). $$$$$ Although its overall result is slightly below the overall corpus baseline, it is very successful at disambiguating verbs.
We refer to this method as stacking, and it has been previously used to integrate heterogeneous knowledge sources for WSD (Stevenson and Wilks, 2001). $$$$$ It is argued that this approach is more likely to assist the creation of practical systems.
We refer to this method as stacking, and it has been previously used to integrate heterogeneous knowledge sources for WSD (Stevenson and Wilks, 2001). $$$$$ Word sense disambiguation (WSD) is a computational linguistics task likely to benefit from the tradition of combining different knowledge sources in artificial intelligence research.
We refer to this method as stacking, and it has been previously used to integrate heterogeneous knowledge sources for WSD (Stevenson and Wilks, 2001). $$$$$ We present a sense tagger which uses several knowledge sources.

POS tags of the focus word itself are also included, to aid sense disambiguations related to syntactic differences (Stevenson and Wilks, 2001). $$$$$ It could be reasonably argued that removing senses is a dangerous strategy since, if the part-of-speech tagger made an error, the correct sense could be removed from consideration.
POS tags of the focus word itself are also included, to aid sense disambiguations related to syntactic differences (Stevenson and Wilks, 2001). $$$$$ This method would tag all content words in a sentence with their senses from a dictionary that contains textual definitions.
POS tags of the focus word itself are also included, to aid sense disambiguations related to syntactic differences (Stevenson and Wilks, 2001). $$$$$ Our system attempts to disambiguate all content words in running text rather than limiting itself to treating a restricted vocabulary of words.

Prior research (e.g., (McRoy, 1992), (Ng and Lee, 1996), (Stevenson and Wilks, 2001), (Yarowsky and Florian, 2002)) suggests that use of both syntactic and lexical features will improve disambiguation accuracies. $$$$$ This review has been extremely brief and has not covered large areas of research into WSD.
Prior research (e.g., (McRoy, 1992), (Ng and Lee, 1996), (Stevenson and Wilks, 2001), (Yarowsky and Florian, 2002)) suggests that use of both syntactic and lexical features will improve disambiguation accuracies. $$$$$ Tested accuracy exceeds 94% on our evaluation corpus.
Prior research (e.g., (McRoy, 1992), (Ng and Lee, 1996), (Stevenson and Wilks, 2001), (Yarowsky and Florian, 2002)) suggests that use of both syntactic and lexical features will improve disambiguation accuracies. $$$$$ We did not employ these procedures and used simple corpus frequency counts when calculating the probabilities (see Section 4.5).
Prior research (e.g., (McRoy, 1992), (Ng and Lee, 1996), (Stevenson and Wilks, 2001), (Yarowsky and Florian, 2002)) suggests that use of both syntactic and lexical features will improve disambiguation accuracies. $$$$$ At the heart of this approach is the distance metric A(X, Y) which computes the similarity between instances X and Y.
