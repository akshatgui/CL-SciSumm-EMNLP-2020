Accuracy for XLE is not given, because the results reported by Kaplan et al (2004) compare labeled functional dependencies drawn from LFG f-structures with equivalents derived automatically from Collins outputs. $$$$$ We did not include the time for dependency conversion in our measures of performance.
Accuracy for XLE is not given, because the results reported by Kaplan et al (2004) compare labeled functional dependencies drawn from LFG f-structures with equivalents derived automatically from Collins outputs. $$$$$ In our system, tokenization and morphological analysis are performed by finite-state transductions arranged in a compositional cascade.
Accuracy for XLE is not given, because the results reported by Kaplan et al (2004) compare labeled functional dependencies drawn from LFG f-structures with equivalents derived automatically from Collins outputs. $$$$$ We found the deep-parsing system to be more accurate than the Collins parser with only a reduction in parsing
Accuracy for XLE is not given, because the results reported by Kaplan et al (2004) compare labeled functional dependencies drawn from LFG f-structures with equivalents derived automatically from Collins outputs. $$$$$ We investigated the accuracy of recovering semantically-relevant grammatical dependencies from the tree-structures produced by the Collins parser, comparing these dependencies to gold-standard dependencies which are available for a subset of 700 sentences randomly drawn from section 23 of the Wall Street Journal (see King et al. (2003)).

For estimation and best-parse searching, efficient dynamic programming techniques over features forests are employed (see Kaplan et al (2004)). $$$$$ Our experiment is comparable to recent work on reading off Propbank-style (Kingsbury and Palmer, 2002) predicate-argument relations from gold-standard treebank trees and automatic parses of the Collins parser.
For estimation and best-parse searching, efficient dynamic programming techniques over features forests are employed (see Kaplan et al (2004)). $$$$$ This paper reports on some experiments that put this conventional wisdom to an empirical test.
For estimation and best-parse searching, efficient dynamic programming techniques over features forests are employed (see Kaplan et al (2004)). $$$$$ The currently popular Collins parser is a shallow parser whose output contains more detailed semanticallyrelevant information than other such parsers.
For estimation and best-parse searching, efficient dynamic programming techniques over features forests are employed (see Kaplan et al (2004)). $$$$$ From this perspective, the nearly 75% F-score that is achieved for our deterministic rewriting of Collins’ trees into dependencies is remarkable, even if the results are not directly comparable.

Kaplan et al (2004) report high parsing speeds for a deep parsing system which uses an LFG grammar $$$$$ Clearly, both versions of the XLE system achieve a significant reduction in error rate over the Collins parser (12% for the core XLE system and 20% for the complete system) at an increase in parsing time of a factor of only 1.49 for the core XLE system.
Kaplan et al (2004) report high parsing speeds for a deep parsing system which uses an LFG grammar $$$$$ Finally, the trivial rewritings were used to, for example, change STMT-TYPE decl in the grammar to STMT-TYPE declarative in the dependency bank.
Kaplan et al (2004) report high parsing speeds for a deep parsing system which uses an LFG grammar $$$$$ Since feature-value computation proceeds incrementally over the feature forest, i.e. for each node that is visited all feature-functions that apply to it are evaluated, a complete feature annotation can be guaranteed for the part of the and/or-forest that is visited until discontinuation.

We have developed a parsing system that explores this space, in the vein of systems like (Kaplan et al, 2004). $$$$$ As part of our assessment, we also measured the parsing speed of the two systems, taking into account all stages of processing that each system requires to produce its output.
We have developed a parsing system that explores this space, in the vein of systems like (Kaplan et al, 2004). $$$$$ Since feature-value computation proceeds incrementally over the feature forest, i.e. for each node that is visited all feature-functions that apply to it are evaluated, a complete feature annotation can be guaranteed for the part of the and/or-forest that is visited until discontinuation.

We use the same 560 sentence subset from the DepBank utilised by Kaplan et al (2004) in their study of parser accuracy and efficiency. $$$$$ The stochastic component is also “ambiguity-enabled” in the sense that the computations for statistical estimation and selection of the most probable analyses are done efficiently by dynamic programming, avoiding the need to unpack the parse forests and enumerate individual analyses.
We use the same 560 sentence subset from the DepBank utilised by Kaplan et al (2004) in their study of parser accuracy and efficiency. $$$$$ Furthermore, extending the grammar base of the deep system results in much better accuracy at a cost of a factor of 5 in speed.
We use the same 560 sentence subset from the DepBank utilised by Kaplan et al (2004) in their study of parser accuracy and efficiency. $$$$$ The XLE parser is a deep-parsing system that couples a Lexical Functional Grammar to a loglinear disambiguation component and provides much richer representations theory.
We use the same 560 sentence subset from the DepBank utilised by Kaplan et al (2004) in their study of parser accuracy and efficiency. $$$$$ This multiword analysis was chosen because many applications do not require the internal structure of names, and the identification of named entities is now typically carried out by a separate non-syntactic pre-processing module.

Kaplan et al (2004) compare the Collins (2003) parser with the Parc LFG parser by mapping LFG F structures and Penn Treebank parses into DepBank dependencies, claiming that the LFG parser is considerably more accurate with only a slight reduction in speed. $$$$$ Our scores and Gildea and Palmer’s are both substantially lower than the 90% typically cited for evaluations based on labeled or unlabeled bracketing, suggesting that extracting semantically relevant dependencies is a more difficult, but we think more valuable, task.
Kaplan et al (2004) compare the Collins (2003) parser with the Parc LFG parser by mapping LFG F structures and Penn Treebank parses into DepBank dependencies, claiming that the LFG parser is considerably more accurate with only a slight reduction in speed. $$$$$ The stochastic component is also “ambiguity-enabled” in the sense that the computations for statistical estimation and selection of the most probable analyses are done efficiently by dynamic programming, avoiding the need to unpack the parse forests and enumerate individual analyses.
Kaplan et al (2004) compare the Collins (2003) parser with the Parc LFG parser by mapping LFG F structures and Penn Treebank parses into DepBank dependencies, claiming that the LFG parser is considerably more accurate with only a slight reduction in speed. $$$$$ This paper reports some experiments that compare the accuracy and performance of two stochastic parsing systems.
Kaplan et al (2004) compare the Collins (2003) parser with the Parc LFG parser by mapping LFG F structures and Penn Treebank parses into DepBank dependencies, claiming that the LFG parser is considerably more accurate with only a slight reduction in speed. $$$$$ We measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times.

Kaplan et al (2004) clearly invested considerable time and expertise in mapping the output of the Collins parser into the DepBank dependencies, but they also note that 'This conversion was relatively straightforward for LFG structures. $$$$$ An example is shown in (1).
Kaplan et al (2004) clearly invested considerable time and expertise in mapping the output of the Collins parser into the DepBank dependencies, but they also note that 'This conversion was relatively straightforward for LFG structures. $$$$$ Thus, S˜2 indicates that the head of the main clause is its second daughter, the VP, and its head is its first VP daughter.
Kaplan et al (2004) clearly invested considerable time and expertise in mapping the output of the Collins parser into the DepBank dependencies, but they also note that 'This conversion was relatively straightforward for LFG structures. $$$$$ A dynamic-programming solution to the problem of finding most probable parses is to compute the weight Od of each disjunctive node as the maximum weight of its conjunctive daugher nodes, i.e., and to recursively define the weight Oc of a conjunctive node as the product of the weights of all its descendant disjunctive nodes and of its own weight: Keeping a trace of the maximally weighted choices in a computaton of the weight Or of the root conjunctive node r allows us to efficiently recover the most probable parse of a sentence from the packed representation of its parses.
Kaplan et al (2004) clearly invested considerable time and expertise in mapping the output of the Collins parser into the DepBank dependencies, but they also note that 'This conversion was relatively straightforward for LFG structures. $$$$$ We compared the output of the XLE system, a deep-grammar-based parsing system using the English Lexical-Functional Grammar previously constructed as part of the Pargram project (Butt et al., 2002), to the same gold standard.

In the case of Kaplan et al (2004), the testing procedure would include running their con version process on Section 23 of the Penn Treebank and evaluating the output against DepBank. $$$$$ The currently popular Collins parser is a shallow parser whose output contains more detailed semanticallyrelevant information than other such parsers.
In the case of Kaplan et al (2004), the testing procedure would include running their con version process on Section 23 of the Penn Treebank and evaluating the output against DepBank. $$$$$ We measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times.
In the case of Kaplan et al (2004), the testing procedure would include running their con version process on Section 23 of the Penn Treebank and evaluating the output against DepBank. $$$$$ We presented some experiments that compare the accuracy and performance of two stochastic parsing systems, the shallow Collins parser and the deep-grammar-based XLE system.

Note that statistical parsers can equally suffer from this problem, see e.g. (Kaplan et al., 2004). $$$$$ After parsing, the underscores were converted to spaces to match the PARC 700 predicates.
Note that statistical parsers can equally suffer from this problem, see e.g. (Kaplan et al., 2004). $$$$$ The currently popular Collins parser is a shallow parser whose output contains more detailed semanticallyrelevant information than other such parsers.

they can be used to disprefer (actually ignore) rarely-applicable rules, in order to reduce parse time (Kaplan et al 2004). $$$$$ We measured the accuracy of both systems against a gold standard derived from the PARC 700 dependency bank, and also measured their processing times.
they can be used to disprefer (actually ignore) rarely-applicable rules, in order to reduce parse time (Kaplan et al 2004). $$$$$ We did not include the time for dependency extraction or stemming the Collins output.

The second extrapolation is to the LFG XLE parser (Kaplan et al 2004) for English, consisting of a highly developed symbolic parser and grammar, an OT-based preference component, and a stochastic back end to select among remaining alternative parser outputs. $$$$$ As described by (King et al., 2003), the annotations were boot-strapped by parsing the sentences with a LFG grammar and transforming the resulting f-structures to a collection of dependency triples in the DEPBANK format.
The second extrapolation is to the LFG XLE parser (Kaplan et al 2004) for English, consisting of a highly developed symbolic parser and grammar, an OT-based preference component, and a stochastic back end to select among remaining alternative parser outputs. $$$$$ This paper reports some experiments that compare the accuracy and performance of two stochastic parsing systems.
The second extrapolation is to the LFG XLE parser (Kaplan et al 2004) for English, consisting of a highly developed symbolic parser and grammar, an OT-based preference component, and a stochastic back end to select among remaining alternative parser outputs. $$$$$ So, for example, in the Core grammar there is no topicalization rule, and sentences with topics will receive a FRAGMENT parse.

The only other deep parser we are aware of to achieve such levels of robustness for the WSJ is Kaplan et al (2004). $$$$$ We measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times.
The only other deep parser we are aware of to achieve such levels of robustness for the WSJ is Kaplan et al (2004). $$$$$ We presented some experiments that compare the accuracy and performance of two stochastic parsing systems, the shallow Collins parser and the deep-grammar-based XLE system.
The only other deep parser we are aware of to achieve such levels of robustness for the WSJ is Kaplan et al (2004). $$$$$ The Collins parser is thought to be accurate and fast and thus to represent a reasonable trade-off between “good-enough” output, speed, and robustness.
The only other deep parser we are aware of to achieve such levels of robustness for the WSJ is Kaplan et al (2004). $$$$$ Gildea and Palmer (2002) report F-score results in the 55% range for argument and boundary recognition based on automatic parses.

The disadvantage of such parsers is that they are typically not very efficient, parsing a few sentences per second on commodity hardware (Kaplan et al, 2004). $$$$$ Gildea and Palmer (2002) report F-score results in the 55% range for argument and boundary recognition based on automatic parses.
The disadvantage of such parsers is that they are typically not very efficient, parsing a few sentences per second on commodity hardware (Kaplan et al, 2004). $$$$$ This system not only is frequently used for off-line data preprocessing, but also is included as a black-box component for applications such as document summarization (Daume and Marcu, 2002), information extraction (Miller et al., 2000), machine translation (Yamada and Knight, 2001), and question answering (Harabagiu et al., 2001).
The disadvantage of such parsers is that they are typically not very efficient, parsing a few sentences per second on commodity hardware (Kaplan et al, 2004). $$$$$ 2.

Currently our best automatically induced grammars achieve 80.97% f-score for f structures parsing section 23 of the WSJ part of the Penn-II tree bank and evaluating against the DCU1051 and 80.24% against the PARC 700 Dependency Bank (King et al, 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al, 2004). $$$$$ Average sentence length of sentences in DEPBANK is 19.8 words, and the average number of dependencies per sentence is 65.4.
Currently our best automatically induced grammars achieve 80.97% f-score for f structures parsing section 23 of the WSJ part of the Penn-II tree bank and evaluating against the DCU1051 and 80.24% against the PARC 700 Dependency Bank (King et al, 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al, 2004). $$$$$ Time spent for finite-state morphology and dictionary lookup for XLE is part of the measure of its timing performance.
Currently our best automatically induced grammars achieve 80.97% f-score for f structures parsing section 23 of the WSJ part of the Penn-II tree bank and evaluating against the DCU1051 and 80.24% against the PARC 700 Dependency Bank (King et al, 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al, 2004). $$$$$ These are parsed by the grammar as described in section 2.
Currently our best automatically induced grammars achieve 80.97% f-score for f structures parsing section 23 of the WSJ part of the Penn-II tree bank and evaluating against the DCU1051 and 80.24% against the PARC 700 Dependency Bank (King et al, 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al, 2004). $$$$$ We used a configuration of the XLE parser that expects sentences conforming to ordinary text conventions to appear in a file separated by double line-feeds.

 $$$$$ We also note that proper names appear in the DEPBANK as single multi-word expressions without any internal structure.
 $$$$$ The terminal nodes of this tree are inflected forms, and the first phase of our conversion replaces them with their citation forms (the verbs reiterate and express, and the decapitalized and standardized he for He and his).
 $$$$$ LFG Conversion We discarded the LFG tree structures and used a general rewriting system previously developed for machine translation to rewrite the relevant f-structure attributes as dependencies (see King et al. (2003)).
 $$$$$ Feature Meaning adegree degree of adjectives and adverbs (positive, comparative, superlative) coord form form of a coordinating conjunction (e.g., and, or) det form form of a determiner (e.g., the, a) num number of nouns (sg, pl) number type cardinals vs. ordinals passive passive verb (e.g., It was eaten.) perf perfective verb (e.g., have eaten) precoord form either, neither prog progressive verb (e.g., were eating) pron form form of a pronoun (he, she, etc.) prt form particle in a particle verb (e.g., They threw it out.) stmt type statement type (declarative, interrogative, etc.) subord form subordinating conjunction (e.g. that) tense tense of the verb (past, present, etc.)

We achieve between 77.68% and 80.24% against the PARC 700 following the experiments in (Kaplan et al, 2004). $$$$$ Similarly, NP-As under S are read off as subject.
We achieve between 77.68% and 80.24% against the PARC 700 following the experiments in (Kaplan et al, 2004). $$$$$ Our scores and Gildea and Palmer’s are both substantially lower than the 90% typically cited for evaluations based on labeled or unlabeled bracketing, suggesting that extracting semantically relevant dependencies is a more difficult, but we think more valuable, task.
We achieve between 77.68% and 80.24% against the PARC 700 following the experiments in (Kaplan et al, 2004). $$$$$ We found the deep-parsing system to be more accurate than the Collins parser with only a reduction in parsing

Against the PARC 700, the hand-crafted LFG grammar reported in (Kaplan et al, 2004) achieves an f score of 79.6%. $$$$$ Table 1 shows timing and accuracy results for the Reduced dependency set.
Against the PARC 700, the hand-crafted LFG grammar reported in (Kaplan et al, 2004) achieves an f score of 79.6%. $$$$$ In accordance with LFG theory, the output includes not only standard context-free phrase-structure trees but also attribute-value matrices (LFG’s f(unctional) structures) that explicitly encode predicate-argument relations and other meaningful properties.
Against the PARC 700, the hand-crafted LFG grammar reported in (Kaplan et al, 2004) achieves an f score of 79.6%. $$$$$ We measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times.
Against the PARC 700, the hand-crafted LFG grammar reported in (Kaplan et al, 2004) achieves an f score of 79.6%. $$$$$ For example, since the Collins parser depends on a prior part-of-speech tagger (Ratnaparkhi, 1996), we included the time for POS tagging in our Collins measurements.

Evaluating against the PARC 700 Dependency Bank, the P-PCFG achieves an f-score of 80.24%, an overall improvement of approximately 0.6% on the result reported for the best hand-crafted grammars in (Kaplan et al, 2004). $$$$$ 2), and a regularizer penalty of 10 was found optimal for the Bl prior used in stochastic disambiguation.
Evaluating against the PARC 700 Dependency Bank, the P-PCFG achieves an f-score of 80.24%, an overall improvement of approximately 0.6% on the result reported for the best hand-crafted grammars in (Kaplan et al, 2004). $$$$$ As part of our assessment, we also measured the parsing speed of the two systems, taking into account all stages of processing that each system requires to produce its output.
Evaluating against the PARC 700 Dependency Bank, the P-PCFG achieves an f-score of 80.24%, an overall improvement of approximately 0.6% on the result reported for the best hand-crafted grammars in (Kaplan et al, 2004). $$$$$ Model 3 trees also provide information about certain 4However, we did explore a few of these additional transformations and found only marginal F-score increases. long-distance dependencies, by marking with -g annotations the path between a filler and a gap and marking the gap by an explicit TRACE in the terminal string.
Evaluating against the PARC 700 Dependency Bank, the P-PCFG achieves an f-score of 80.24%, an overall improvement of approximately 0.6% on the result reported for the best hand-crafted grammars in (Kaplan et al, 2004). $$$$$ Table 1 shows timing and accuracy results for the Reduced dependency set.

Next, we applied parsing techniques developed for deep parsing, including quick check (Malouf et al., 2000), large constituent inhibition (Kaplan et al., 2004) and hybrid parsing with a CFG chunk parser (Daum et al., 2003; Frank et al., 2003; Frank, 2004). $$$$$ The currently popular Collins parser is a shallow parser whose output contains more detailed semanticallyrelevant information than other such parsers.
Next, we applied parsing techniques developed for deep parsing, including quick check (Malouf et al., 2000), large constituent inhibition (Kaplan et al., 2004) and hybrid parsing with a CFG chunk parser (Daum et al., 2003; Frank et al., 2003; Frank, 2004). $$$$$ The XLE system achieves 12% reduction in error rate over the Collins parser, that is 77.6% F-score for the XLE system versus 74.6% for the Collins parser, at a cost in parsing time of a factor of 1.49.
Next, we applied parsing techniques developed for deep parsing, including quick check (Malouf et al., 2000), large constituent inhibition (Kaplan et al., 2004) and hybrid parsing with a CFG chunk parser (Daum et al., 2003; Frank et al., 2003; Frank, 2004). $$$$$ We conducted our experiments by preparing versions of the test sentences in the form appropriate to each system.
Next, we applied parsing techniques developed for deep parsing, including quick check (Malouf et al., 2000), large constituent inhibition (Kaplan et al., 2004) and hybrid parsing with a CFG chunk parser (Daum et al., 2003; Frank et al., 2003; Frank, 2004). $$$$$ We used a configuration of the XLE parser that expects sentences conforming to ordinary text conventions to appear in a file separated by double line-feeds.

The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al, 2004). $$$$$ We measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times.
The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al, 2004). $$$$$ The corpus is freely available for research and evaluation, as are documentation and tools for displaying and pruning structures.3 In our experiments we used a Reduced version of the DEPBANK, including just the minimum set of dependencies necessary for reading out the central semantic relations and properties of a sentence.
The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al, 2004). $$$$$ The XLE parser is a deep-parsing system that couples a Lexical Functional Grammar to a loglinear disambiguation component and provides much richer representations theory.
The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al, 2004). $$$$$ Overall, feature extraction and weight calculation accounted for 5% of the computation time in combined parsing and stochastic selection.
