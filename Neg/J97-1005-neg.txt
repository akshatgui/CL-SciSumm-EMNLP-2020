Passonneau and Litman (1997) describe an experiment where seven untrained annotators were asked to find discourse segments in a corpus of transcribed narratives about a movie. $$$$$ Testing the new algorithms on a new data set shows that when multiple sources of linguistic knowledge are used concurrently, algorithm performance improves.
Passonneau and Litman (1997) describe an experiment where seven untrained annotators were asked to find discourse segments in a corpus of transcribed narratives about a movie. $$$$$ Finally, we quantify our results using a significance test, a reliability measure, and, for purposes of comparison with other work, percent agreement.
Passonneau and Litman (1997) describe an experiment where seven untrained annotators were asked to find discourse segments in a corpus of transcribed narratives about a movie. $$$$$ We evaluate each algorithm by examining its performance in segmenting an initial test set of 10 of our 20 narratives.
Passonneau and Litman (1997) describe an experiment where seven untrained annotators were asked to find discourse segments in a corpus of transcribed narratives about a movie. $$$$$ The need to model the relation between the structure of such units (referred to here as discourse segment structure) and linguistic features of utterances' is almost universally acknowledged in the literature on discourse.

We turned the segmentation task into a classification task by using boundaries between dialogue acts as one class and non-boundaries a the other (see Passonneau and Litman (1997) for a similar practice). $$$$$ On the first algorithm set, we evaluate and compare the correlation of discourse segmentation with three types of linguistic cues (referential noun phrases, cue words, and pauses).
We turned the segmentation task into a classification task by using boundaries between dialogue acts as one class and non-boundaries a the other (see Passonneau and Litman (1997) for a similar practice). $$$$$ Utterances were classified into four types, each of which was associated with a rule that assigned a controller; the discourse was then divided into segments, based on which speaker had control.
We turned the segmentation task into a classification task by using boundaries between dialogue acts as one class and non-boundaries a the other (see Passonneau and Litman (1997) for a similar practice). $$$$$ We wholeheartedly thank the anonymous reviewers for their very thorough commentary.
We turned the segmentation task into a classification task by using boundaries between dialogue acts as one class and non-boundaries a the other (see Passonneau and Litman (1997) for a similar practice). $$$$$ For the 20 narratives, the probabilities that the observed distributions could have arisen by chance range from p = .1 x 10-6 to p = .6 x 10-9.

By using multiple markers and machine learning methods, topic segmentation algorithms may be developed using this second approach that have a higher accuracy than methods using a single marker alone (Passonneau and Litman, 1997). $$$$$ We report highly significant results of segmentations performed by naive subjects, where a commonsense notion of speaker intention is the segmentation criterion.
By using multiple markers and machine learning methods, topic segmentation algorithms may be developed using this second approach that have a higher accuracy than methods using a single marker alone (Passonneau and Litman, 1997). $$$$$ We present quantitative results of a two-part study using a corpus of spontaneous, narrative monologues.
By using multiple markers and machine learning methods, topic segmentation algorithms may be developed using this second approach that have a higher accuracy than methods using a single marker alone (Passonneau and Litman, 1997). $$$$$ We wholeheartedly thank the anonymous reviewers for their very thorough commentary.
By using multiple markers and machine learning methods, topic segmentation algorithms may be developed using this second approach that have a higher accuracy than methods using a single marker alone (Passonneau and Litman, 1997). $$$$$ While none of the algorithms approached human performance, the fact that performance improved with the number of features coded, and by combining algorithms in a simple additive way, suggested directions for improvement.

Even annotating linear segmentation is challenging, particularly in the vicinity of segment boundaries (PassonneauandLitman, 1997). $$$$$ We present quantitative results of a two-part study using a corpus of spontaneous, narrative monologues.
Even annotating linear segmentation is challenging, particularly in the vicinity of segment boundaries (PassonneauandLitman, 1997). $$$$$ For the T = 4 boundaries, the superior recall of EA compared with conditions 1 and 2 of the automated algorithms is significant.
Even annotating linear segmentation is challenging, particularly in the vicinity of segment boundaries (PassonneauandLitman, 1997). $$$$$ We report highly significant results of segmentations performed by naive subjects, where a commonsense notion of speaker intention is the segmentation criterion.
Even annotating linear segmentation is challenging, particularly in the vicinity of segment boundaries (PassonneauandLitman, 1997). $$$$$ We show that human subjects can reliably perform discourse segmentation using speaker intention as a criterion.

These referential and lexical features build on the work of Passonneau and Litman (1997), who use them in discourse segmentation. $$$$$ A third person definite pronoun provides a referential link if its index occurs anywhere in the current segment.
These referential and lexical features build on the work of Passonneau and Litman (1997), who use them in discourse segmentation. $$$$$ However, there is only weak consensus on what the units of discourse structure are, or the criteria for recognizing and generating them.
These referential and lexical features build on the work of Passonneau and Litman (1997), who use them in discourse segmentation. $$$$$ The need to model the relation between discourse structure and linguistic features of utterances is almost universally acknowledged in the literature on discourse.
These referential and lexical features build on the work of Passonneau and Litman (1997), who use them in discourse segmentation. $$$$$ Each algorithm is designed to replicate the subjects' segmentation task (break up a narrative into contiguous segments, with segment breaks falling between prosodic phrases).

First, if non-canonicals are indicators of attentional stack pops, they should be more likely at segment boundaries; hence, we expect an increased presence of cue words (Passonneau and Litman, 1997) on non-canonicals compared to canonicals. $$$$$ In the second part of our study, data abstracted from the subjects' segmentations serve as a target for evaluating two sets of algorithms that use utterance features to perform segmentation.
First, if non-canonicals are indicators of attentional stack pops, they should be more likely at segment boundaries; hence, we expect an increased presence of cue words (Passonneau and Litman, 1997) on non-canonicals compared to canonicals. $$$$$ This is an important dimension of difference between the two sets of segments we use: segments identified by a minimum of four subjects are larger and fewer in number than those identified by a minimum of three.
First, if non-canonicals are indicators of attentional stack pops, they should be more likely at segment boundaries; hence, we expect an increased presence of cue words (Passonneau and Litman, 1997) on non-canonicals compared to canonicals. $$$$$ there are three little boys, up on the road a little bit, and they see this little accident.
First, if non-canonicals are indicators of attentional stack pops, they should be more likely at segment boundaries; hence, we expect an increased presence of cue words (Passonneau and Litman, 1997) on non-canonicals compared to canonicals. $$$$$ Swerts and Ostendorf (1995) also empirically derived discourse structure, using a spoken corpus of database query interactions.

In this sense, we are performing low-level discourse segmentation, as opposed to segmenting text into chunks or topics (e.g., Passonneau and Litman (1997)). $$$$$ We wholeheartedly thank the anonymous reviewers for their very thorough commentary.
In this sense, we are performing low-level discourse segmentation, as opposed to segmenting text into chunks or topics (e.g., Passonneau and Litman (1997)). $$$$$ A potential correlation between discourse signaling uses of cue words and adjacency patterns between cue words (cue2) was also suggested.
In this sense, we are performing low-level discourse segmentation, as opposed to segmenting text into chunks or topics (e.g., Passonneau and Litman (1997)). $$$$$ We wholeheartedly thank the anonymous reviewers for their very thorough commentary.
In this sense, we are performing low-level discourse segmentation, as opposed to segmenting text into chunks or topics (e.g., Passonneau and Litman (1997)). $$$$$ First, we must take into account the dimensions along which the three algorithms differ, apart from the different types of linguistic information used.

Passonneau and Litman (1997) found that pause length correlates with discourse segment boundaries. $$$$$ Each utterance of a discourse contributes to the communicative import of preceding utterances, or constitutes the onset of a new unit of meaning or action that subsequent utterances may add to.
Passonneau and Litman (1997) found that pause length correlates with discourse segment boundaries. $$$$$ Across the 20 narratives, statistical significance arises where at least three or four out of seven subjects agree on the same boundary location, depending on an arbitrary choice between probabilities of .02 versus .0001 as the significance threshold.
Passonneau and Litman (1997) found that pause length correlates with discourse segment boundaries. $$$$$ Each utterance of a discourse contributes to the communicative import of preceding utterances, or constitutes the onset of a new unit of meaning or action that subsequent utterances may add to.

This makes it different from others using surface features like (Passonneau and Litman, 1997). $$$$$ For the T = 4 boundary set, &quot;Learning 2&quot; recall was 53% as good as humans, precision was 95% as good, fallout was better than humans, and error (11%) was almost as low as that of humans (10%).
This makes it different from others using surface features like (Passonneau and Litman, 1997). $$$$$ Finally, the results of Litman (1996) show that there are many alternatives to the cue phrase algorithm used here, including some that use feature sets that can be fully coded automatically.
This makes it different from others using surface features like (Passonneau and Litman, 1997). $$$$$ The first part of our paper presents a method for empirically validating multiutterance units referred to as discourse segments.
This makes it different from others using surface features like (Passonneau and Litman, 1997). $$$$$ The first pertains to an abstract structure consisting of meaningful discourse segments and their interrelations.

Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al, 2004). $$$$$ Similar results are reported in Nakatani, Hirschberg, and Grosz (1995) and Hirschberg and Nakatani (1996) for spontaneous speech as well.
Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al, 2004). $$$$$ Both authors' work was partially supported by DARPA and ONR under contract N00014-89+1782; Passonneau was also partly supported by NSF grants IRI-91-13064 and IRI-95-28998.
Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al, 2004). $$$$$ Three types of inference relations linking successive clauses (Ci_i, C1) were added (originally there were five types [Passonneau 1994]).
Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al, 2004). $$$$$ Each utterance of a discourse contributes to the communicative import of preceding utterances, or constitutes the onset of a new unit of meaning or action that subsequent utterances may add to.

Human annotators demonstrate frequent disagreement about the number of segments and exactly where the transitions between segments occur, while still demonstrating statistically significant agreement (Passonneau and Litman, 1997). $$$$$ For N = 3 and above, the slope of the curve suddenly becomes linear, and much less steep, corresponding to a much more gradual decrease in frequency as values of N go to 7.
Human annotators demonstrate frequent disagreement about the number of segments and exactly where the transitions between segments occur, while still demonstrating statistically significant agreement (Passonneau and Litman, 1997). $$$$$ We present quantitative results of a two-part study using a corpus of spontaneous, narrative monologues.
