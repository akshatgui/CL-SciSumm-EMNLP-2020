(Note that the top participant of CTBc (Zhang et al, 2003) used additional named entity knowledge/data in their word segmenter). $$$$$ Evaluation on ICTCLAS shows that its performance is competitive.
(Note that the top participant of CTBc (Zhang et al, 2003) used additional named entity knowledge/data in their word segmenter). $$$$$ As illustrated in Figure 1, HHMM-based Chinese lexical analysis comprises five levels: atom segmentation, simple and recursive unknown words recognition, class-based segmentation and POS tagging.
(Note that the top participant of CTBc (Zhang et al, 2003) used additional named entity knowledge/data in their word segmenter). $$$$$ Then provide the evaluation results and give more analysis.
(Note that the top participant of CTBc (Zhang et al, 2003) used additional named entity knowledge/data in their word segmenter). $$$$$ And we acknowledge our debt to Gang Zou, Dr. Bin Wang, Dr. Jian Sun, Ji-Feng Li, Hao Zhang and other colleagues.

ICTCLAS Segmenter: this model, trained by Zhang et al (2003), is a hierarchicalHMM segmenter that incorporates parts-of speech (POS) information into the probability models and generates multiple HMM mod els for solving segmentation ambiguities. $$$$$ ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.
ICTCLAS Segmenter: this model, trained by Zhang et al (2003), is a hierarchicalHMM segmenter that incorporates parts-of speech (POS) information into the probability models and generates multiple HMM mod els for solving segmentation ambiguities. $$$$$ Huaping Zhang would especially express gratitude to his graceful girl friend Feifei and her family for their encouragement.
ICTCLAS Segmenter: this model, trained by Zhang et al (2003), is a hierarchicalHMM segmenter that incorporates parts-of speech (POS) information into the probability models and generates multiple HMM mod els for solving segmentation ambiguities. $$$$$ And we acknowledge our debt to Gang Zou, Dr. Bin Wang, Dr. Jian Sun, Ji-Feng Li, Hao Zhang and other colleagues.
ICTCLAS Segmenter: this model, trained by Zhang et al (2003), is a hierarchicalHMM segmenter that incorporates parts-of speech (POS) information into the probability models and generates multiple HMM mod els for solving segmentation ambiguities. $$$$$ Any word is made up of an atom or more.

ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. $$$$$ We have taken six tracks: Academia Sinica closed (ASc), U. Penn Chinese Tree Bank open and closed(CTBo,c), Hong Kong CityU closed (HKc), Peking University open and closed(PKo,c).
ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. $$$$$ We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.
ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. $$$$$ Except for the additional corpus, we have not employed any other special libraries or other resources.
ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. $$$$$ The next section presents the HHMM-based framework of ICTCLAS.

Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al, 2003) to extract named entities, noun phrases and events. $$$$$ This document presents the results from Inst. of Computing Tech., CAS in the ACL- SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff.
Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al, 2003) to extract named entities, noun phrases and events. $$$$$ Excepted for CTB, IV Recall is over 97%.
Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al, 2003) to extract named entities, noun phrases and events. $$$$$ Any word is made up of an atom or more.
Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al, 2003) to extract named entities, noun phrases and events. $$$$$ We skip the detail of operation in that it's a simple application on the basis of HMM.

HMMsegmenter (Zhang et al, 2003) that uses the specifications of PKU. $$$$$ And we acknowledge our debt to Gang Zou, Dr. Bin Wang, Dr. Jian Sun, Ji-Feng Li, Hao Zhang and other colleagues.
HMMsegmenter (Zhang et al, 2003) that uses the specifications of PKU. $$$$$ As demonstrated in Figure 3, we provide the process of class-based word segmentation on &quot;Et MT,, 1893' 01&quot; (Mao Ze-Dong was born in the year of 1893).
HMMsegmenter (Zhang et al, 2003) that uses the specifications of PKU. $$$$$ Next we detail the operation of six tracks.
HMMsegmenter (Zhang et al, 2003) that uses the specifications of PKU. $$$$$ The structure of this document is as follows.

Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al,2003). $$$$$ The authors would like to thank Prof. Shiwen Yu of Peking University for the Peking corpus.
Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al,2003). $$$$$ Through the first bakeoff, we have learn more about the development in Chinese word segmentation and become more confident on our HHMMbased approach.
Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al,2003). $$$$$ Moreover, unknown words, which are recognized in the following steps, can be added into the segmentation graph and proceeded as any other common words.

Its segmentation model is a 3The query set and relevance judgements are available at http: //www.cs.ualberta.ca/ ?yx2/research.html 59 class-based hidden Markov model (HMM) model (Zhang et al, 2003). $$$$$ As demonstrated in Figure 3, we provide the process of class-based word segmentation on &quot;Et MT,, 1893' 01&quot; (Mao Ze-Dong was born in the year of 1893).
Its segmentation model is a 3The query set and relevance judgements are available at http: //www.cs.ualberta.ca/ ?yx2/research.html 59 class-based hidden Markov model (HMM) model (Zhang et al, 2003). $$$$$ We look forward to participate forthcoming bakeoff.
Its segmentation model is a 3The query set and relevance judgements are available at http: //www.cs.ualberta.ca/ ?yx2/research.html 59 class-based hidden Markov model (HMM) model (Zhang et al, 2003). $$$$$ 2 HHMM-based Chinese lexical analysis
Its segmentation model is a 3The query set and relevance judgements are available at http: //www.cs.ualberta.ca/ ?yx2/research.html 59 class-based hidden Markov model (HMM) model (Zhang et al, 2003). $$$$$ We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.

Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine. $$$$$ Moreover, unknown words, which are recognized in the following steps, can be added into the segmentation graph and proceeded as any other common words.
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine. $$$$$ Huaping Zhang would especially express gratitude to his graceful girl friend Feifei and her family for their encouragement.
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine. $$$$$ We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine. $$$$$ At the same time, we really find our problems during the evaluation.

Decrease in H (XjX n) for Chinese characters when n is increased software such as (Zhang et al, 2003) whose performance is also high. $$$$$ Actually, open track is similar to closed one.
Decrease in H (XjX n) for Chinese characters when n is increased software such as (Zhang et al, 2003) whose performance is also high. $$$$$ The bakeoff is interesting and helpful.
Decrease in H (XjX n) for Chinese characters when n is increased software such as (Zhang et al, 2003) whose performance is also high. $$$$$ POS tagging and role tagging using Viterbi are also skipped because they are classic application of HMM.

Hence the need for automatic word segmentation systems (Zhang et al, 2003). $$$$$ The entire corpus is also from Peking University.
Hence the need for automatic word segmentation systems (Zhang et al, 2003). $$$$$ As demonstrated in Figure 3, we provide the process of class-based word segmentation on &quot;Et MT,, 1893' 01&quot; (Mao Ze-Dong was born in the year of 1893).
Hence the need for automatic word segmentation systems (Zhang et al, 2003). $$$$$ The bakeoff is interesting and helpful.

Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004). $$$$$ Huaping Zhang would especially express gratitude to his graceful girl friend Feifei and her family for their encouragement.
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004). $$$$$ This document presents the results from Inst. of Computing Tech., CAS in the ACL- SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff.
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004). $$$$$ As demonstrated in Figure 3, we provide the process of class-based word segmentation on &quot;Et MT,, 1893' 01&quot; (Mao Ze-Dong was born in the year of 1893).
Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004). $$$$$ We have taken six tracks: Academia Sinica closed (ASc), U. Penn Chinese Tree Bank open and closed(CTBo,c), Hong Kong CityU closed (HKc), Peking University open and closed(PKo,c).

Then for every path of the N+1paths4 (N best paths and the atom path), we perform a process of Roles Tagging with HMM model (Zhang et al 2003). $$$$$ At the same time, we really find our problems during the evaluation.
Then for every path of the N+1paths4 (N best paths and the atom path), we perform a process of Roles Tagging with HMM model (Zhang et al 2003). $$$$$ We participate all the closed tracks.
Then for every path of the N+1paths4 (N best paths and the atom path), we perform a process of Roles Tagging with HMM model (Zhang et al 2003). $$$$$ Through the first bakeoff, we have learn more about the development in Chinese word segmentation and become more confident on our HHMMbased approach.
Then for every path of the N+1paths4 (N best paths and the atom path), we perform a process of Roles Tagging with HMM model (Zhang et al 2003). $$$$$ Then, we could get: For a specific atom sequence A, P(A) is a constant and P(W,A)= P(W).

The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al, 2003). $$$$$ The next section presents the HHMM-based framework of ICTCLAS.
The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al, 2003). $$$$$ We look forward to participate forthcoming bakeoff.
The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al, 2003). $$$$$ We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.

Both ICTCLAS and Stanford segmenters utilise machine learning techniques, with Hidden Markov Models for ICT (Zhang et al, 2003) and conditional random fields for the Stanford segmenter (Tseng et al, 2005). $$$$$ Those named entity words are classified into different named entities: numeric and time expression, personal names, location names, and transliterated names.
Both ICTCLAS and Stanford segmenters utilise machine learning techniques, with Hidden Markov Models for ICT (Zhang et al, 2003) and conditional random fields for the Stanford segmenter (Tseng et al, 2005). $$$$$ Suppose ILEXI to be the lexicon size, then the total number of word classes is ILEXI+9.
Both ICTCLAS and Stanford segmenters utilise machine learning techniques, with Hidden Markov Models for ICT (Zhang et al, 2003) and conditional random fields for the Stanford segmenter (Tseng et al, 2005). $$$$$ After transformation through class-based HMM, word segmentation becomes single-source shortest paths problem.

In this work, we resort to ICTCLAS (Zhang et al, 2003), a widely used tool in the literature. $$$$$ And we acknowledge our debt to Gang Zou, Dr. Bin Wang, Dr. Jian Sun, Ji-Feng Li, Hao Zhang and other colleagues.
In this work, we resort to ICTCLAS (Zhang et al, 2003), a widely used tool in the literature. $$$$$ The authors would like to thank Prof. Shiwen Yu of Peking University for the Peking corpus.
In this work, we resort to ICTCLAS (Zhang et al, 2003), a widely used tool in the literature. $$$$$ The authors would like to thank Prof. Shiwen Yu of Peking University for the Peking corpus.

The posts were then part-of speech tagged using a Chinese word segmentation tool named ICTCLAS (Zhang et al, 2003). $$$$$ This document presents the results from Inst. of Computing Tech., CAS in the ACL- SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff.
The posts were then part-of speech tagged using a Chinese word segmentation tool named ICTCLAS (Zhang et al, 2003). $$$$$ Compared with other system, ICTCLAS has ranked top both in CTB and PK closed track.
The posts were then part-of speech tagged using a Chinese word segmentation tool named ICTCLAS (Zhang et al, 2003). $$$$$ The atom consists of Chinese character, punctuation, symbol string, numeric expression and other non-Chinese char string.
The posts were then part-of speech tagged using a Chinese word segmentation tool named ICTCLAS (Zhang et al, 2003). $$$$$ Moreover, unknown words, which are recognized in the following steps, can be added into the segmentation graph and proceeded as any other common words.

Their system only does IWR, using the CWS and POS tagging output of the ICTCLAS segmenter (Zhang et al, 2003) as in put. $$$$$ Hence the best choice W# of word segmentation is easy to find using Djikstra's algorithm.
Their system only does IWR, using the CWS and POS tagging output of the ICTCLAS segmenter (Zhang et al, 2003) as in put. $$$$$ We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.
Their system only does IWR, using the CWS and POS tagging output of the ICTCLAS segmenter (Zhang et al, 2003) as in put. $$$$$ The following section provides evaluation result and gives further analysis.

 $$$$$ The bakeoff is interesting and helpful.
 $$$$$ This document presents the results from Inst. of Computing Tech., CAS in the ACL- SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff.
 $$$$$ ICTCLAS BIG5 version was transformed from GB version only in two days; however, it achieved well in two BIG5 closed tracks.

ICTCLAS is developed by Chinese Academy of Science, the precision of which is 97.58% on tagging general words (Huaping Zhang et al, 2003). $$$$$ At the same time, we really find our problems during the evaluation.
ICTCLAS is developed by Chinese Academy of Science, the precision of which is 97.58% on tagging general words (Huaping Zhang et al, 2003). $$$$$ ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.
ICTCLAS is developed by Chinese Academy of Science, the precision of which is 97.58% on tagging general words (Huaping Zhang et al, 2003). $$$$$ Through the first bakeoff, we have learn more about the development in Chinese word segmentation and become more confident on our HHMMbased approach.

The Chinese word segmentation tool is ICTCLAS (Zhang et al 2003) and Google Translator is the MT for the source language. $$$$$ As demonstrated in Figure 3, we provide the process of class-based word segmentation on &quot;Et MT,, 1893' 01&quot; (Mao Ze-Dong was born in the year of 1893).
The Chinese word segmentation tool is ICTCLAS (Zhang et al 2003) and Google Translator is the MT for the source language. $$$$$ As demonstrated in Figure 3, we provide the process of class-based word segmentation on &quot;Et MT,, 1893' 01&quot; (Mao Ze-Dong was born in the year of 1893).
The Chinese word segmentation tool is ICTCLAS (Zhang et al 2003) and Google Translator is the MT for the source language. $$$$$ In this HMM, the original symbol is observation while the atom is state.
