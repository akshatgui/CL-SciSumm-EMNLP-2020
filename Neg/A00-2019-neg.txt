For instance, Chodorow and Leacock (2000) point out that the word concentrate is usually used as a noun in a general corpus whereas it is a verb 91% of the time in essays written by non-native learners of English. $$$$$ Misses can also be syntactic — when the target word is confused with another word but the syntactic environment fails to trigger an error.
For instance, Chodorow and Leacock (2000) point out that the word concentrate is usually used as a noun in a general corpus whereas it is a verb 91% of the time in essays written by non-native learners of English. $$$$$ All occurrences of the word in a collection of edited text could be automatically assigned to a single training set representing appropriate usage.
For instance, Chodorow and Leacock (2000) point out that the word concentrate is usually used as a noun in a general corpus whereas it is a verb 91% of the time in essays written by non-native learners of English. $$$$$ Although the system recognizes a wide range of error types, as Table 6 shows, it detects only about one-fifth as many errors as a human judge does.
For instance, Chodorow and Leacock (2000) point out that the word concentrate is usually used as a noun in a general corpus whereas it is a verb 91% of the time in essays written by non-native learners of English. $$$$$ Instead, we train ALEK on a general corpus of English and on edited text containing example uses of the target word.

Chodorow and Leacock (2000) try to identify errors on the basis of context, as we do here, and more specifically a 2 word window around the word of interest, from which they consider function words and POS tags. $$$$$ We have already seen in Table 1 that there is a negative correlation between essay score and two of ALEK's component measures, the general corpus n-grams.
Chodorow and Leacock (2000) try to identify errors on the basis of context, as we do here, and more specifically a 2 word window around the word of interest, from which they consider function words and POS tags. $$$$$ We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora.
Chodorow and Leacock (2000) try to identify errors on the basis of context, as we do here, and more specifically a 2 word window around the word of interest, from which they consider function words and POS tags. $$$$$ This system was tested on 79 sentences containing determiner and agreement errors, and 101 grammatical sentences.

N-gram-based approaches to the problem of error detection have been proposed and implemented in various forms by Atwell (1987), Bigert and Knutsson (2002), and Chodorow and Leacock (2000) amongst others. $$$$$ For example, a knowledge will not be treated as an error because it appears in the training corpus as part of the longer a knowledge of sequence (as in a knowledge of mathematics).
N-gram-based approaches to the problem of error detection have been proposed and implemented in various forms by Atwell (1987), Bigert and Knutsson (2002), and Chodorow and Leacock (2000) amongst others. $$$$$ We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora.

Chodorow and Leacock (2000) use a mutual information measure in addition to raw frequency of n grams. $$$$$ We have developed a statistical system, ALEK (Assessing Lexical Knowledge), that uses statistical analysis for this purpose.
Chodorow and Leacock (2000) use a mutual information measure in addition to raw frequency of n grams. $$$$$ The problem of error detection does not entail finding similarities to appropriate usage, rather it requires identifying one element among the contextual cues that simply does not fit.
Chodorow and Leacock (2000) use a mutual information measure in addition to raw frequency of n grams. $$$$$ In selecting the sentences for the word ALEK infers negative evidence from the contextual cues that do not co-occur with the target word — either in the word specific corpus or in the general English one.

Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. $$$$$ The errorrecognition system, ALEK, performs with about 80% precision and 20% recall.
Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. $$$$$ We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora.
Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. $$$$$ Golding (1995) showed how methods used for WSD (decision lists and Bayesian classifiers) could be adapted to detect errors resulting from common spelling confusions among sets such as there, their, and they're.

For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and part-of-speech (PoS) tags, while Sun et al (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. $$$$$ Instead, we train ALEK on a general corpus of English and on edited text containing example uses of the target word.
For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and part-of-speech (PoS) tags, while Sun et al (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. $$$$$ We need to supplement the word-specific corpora with material that more closely resembles the test corpus.
For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and part-of-speech (PoS) tags, while Sun et al (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. $$$$$ Since these errors are not indicative of one's ability to use the target word, they were not considered as errors unless they caused the judge to misanalyze the sentence.
For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and part-of-speech (PoS) tags, while Sun et al (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. $$$$$ A major objective of this research is to avoid the laborious and costly process of collecting errors (or negative evidence) for each word that we wish to evaluate.

For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al, 2008) and (Gamon and Leacock, 2010) use Web as a corpus. $$$$$ Since TEOFL graders are not supposed to take punctuation into account, punctuation errors were only marked when they caused the judge to &quot;garden path&quot; or initially misinterpret the sentence.
For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al, 2008) and (Gamon and Leacock, 2010) use Web as a corpus. $$$$$ TOEFL is taken by foreign students who are applying to US undergraduate and graduate-level programs.
For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al, 2008) and (Gamon and Leacock, 2010) use Web as a corpus. $$$$$ Since these errors are not indicative of one's ability to use the target word, they were not considered as errors unless they caused the judge to misanalyze the sentence.

Chodorow and Leacock (2000) and Chodorow et al (2007) argue that precision-oriented is better, but they do not give any concrete reason. $$$$$ Comparison of these results to those of other systems is difficult because there is no generally accepted test set or performance baseline.
Chodorow and Leacock (2000) and Chodorow et al (2007) argue that precision-oriented is better, but they do not give any concrete reason. $$$$$ However, most grammatical errors are not the result of simple word confusions.
Chodorow and Leacock (2000) and Chodorow et al (2007) argue that precision-oriented is better, but they do not give any concrete reason. $$$$$ Statistically-based computer programs have been able to do the same with a high level of accuracy (Kilgarriff and Palmer, 2000).

The grammar feature covers errors such as sentence fragments, verb form errors and pronoun errors (Chodorow and Leacock, 2000). $$$$$ False positives, when ALEK &quot;identifies&quot; an error where none exists, fall into six major categories.
The grammar feature covers errors such as sentence fragments, verb form errors and pronoun errors (Chodorow and Leacock, 2000). $$$$$ However, its techniques could be incorporated into a grammar checker for native speakers.
The grammar feature covers errors such as sentence fragments, verb form errors and pronoun errors (Chodorow and Leacock, 2000). $$$$$ This increases ALEK's precision at the price of reduced recall.

An example is the error detection method (Chodorow and Leacock, 2000), which identifies unnatural sequences of POSs as grammatical errors in the writing of learners. $$$$$ The problem of error detection does not entail finding similarities to appropriate usage, rather it requires identifying one element among the contextual cues that simply does not fit.
An example is the error detection method (Chodorow and Leacock, 2000), which identifies unnatural sequences of POSs as grammatical errors in the writing of learners. $$$$$ The system was developed and tested using essay-length responses to prompts on the Test of English as a Foreign Language (TOEFL).
An example is the error detection method (Chodorow and Leacock, 2000), which identifies unnatural sequences of POSs as grammatical errors in the writing of learners. $$$$$ The system identifies inappropriate usage based on differences between the word's local context cues in an essay and the models of context it has derived from the corpora of well-formed sentences.

Our method outperforms Microsoft Word03 and ALEK (Chodorow and Leacock, 2000) from Educational Testing Service (ETS) in some cases. $$$$$ A good indicator of whether a person knows the meaning of a word is the ability to use it appropriately in a sentence (Miller and Gildea, 1987).
Our method outperforms Microsoft Word03 and ALEK (Chodorow and Leacock, 2000) from Educational Testing Service (ETS) in some cases. $$$$$ The errorrecognition system, ALEK, performs with about 80% precision and 20% recall.
Our method outperforms Microsoft Word03 and ALEK (Chodorow and Leacock, 2000) from Educational Testing Service (ETS) in some cases. $$$$$ The system was developed and tested using essay-length responses to prompts on the Test of English as a Foreign Language (TOEFL).

An unsupervised method (Chodorow and Leacock, 2000) is employed to detect grammatical errors by inferring negative evidence from TOEFL administrated by ETS. $$$$$ We have already seen in Table 1 that there is a negative correlation between essay score and two of ALEK's component measures, the general corpus n-grams.
An unsupervised method (Chodorow and Leacock, 2000) is employed to detect grammatical errors by inferring negative evidence from TOEFL administrated by ETS. $$$$$ Another cause is that adjuncts, especially temporal and locative adverbials, distribute freely in the wordspecific corpora, as in &quot;Susan concentrated in her room.&quot; This second problem is more tractable than the polysemy problem — and would involve training the system to recognize certain types of adjuncts.
An unsupervised method (Chodorow and Leacock, 2000) is employed to detect grammatical errors by inferring negative evidence from TOEFL administrated by ETS. $$$$$ The errorrecognition system, ALEK, performs with about 80% precision and 20% recall.

In addition, we compared our technique with two other methods of checking errors, Microsoft Word03 and ALEK method (Chodorow and Leacock, 2000). $$$$$ The system identifies inappropriate usage based on differences between the word's local context cues in an essay and the models of context it has derived from the corpora of well-formed sentences.
In addition, we compared our technique with two other methods of checking errors, Microsoft Word03 and ALEK method (Chodorow and Leacock, 2000). $$$$$ It uses two kinds of contextual cues in a ±2 word window around the target word: function words (closed-class items) and part-of-speech tags (Brill, 1994).
In addition, we compared our technique with two other methods of checking errors, Microsoft Word03 and ALEK method (Chodorow and Leacock, 2000). $$$$$ The E-set contained 8.3% of the pollution sentences and the C-set had the remaining 91.7%.

In this paper, we compare our technique with the grammar checker of Microsoft Word03 and the ALEK (Chodorow and Leacock, 2000) method used by ETS. $$$$$ A requirement for ALEK has been that all steps in the process be automated, beyond choosing the words to be tested and assessing the results.
In this paper, we compare our technique with the grammar checker of Microsoft Word03 and the ALEK (Chodorow and Leacock, 2000) method used by ETS. $$$$$ The system was developed and tested using essay-length responses to prompts on the Test of English as a Foreign Language (TOEFL).
In this paper, we compare our technique with the grammar checker of Microsoft Word03 and the ALEK (Chodorow and Leacock, 2000) method used by ETS. $$$$$ Writers sometimes produce errors that violate basic principles of English syntax (e.g., a desks), while other mistakes show a lack of information about a specific vocabulary item (e.g., a knowledge).

Chodorow and Leacock (2000) utilized mutual information and chi-square statistics to identify typical contexts for a small set of targeted words from a large well-formed corpus. $$$$$ These have been developed by hand, based on small training and test sets.
Chodorow and Leacock (2000) utilized mutual information and chi-square statistics to identify typical contexts for a small set of targeted words from a large well-formed corpus. $$$$$ Much information about usage can be obtained from quite a limited context: Choueka and Lusignan (1985) found that people can typically recognize the intended sense of a polysemous word by looking at a narrow window of one or two words around it.
Chodorow and Leacock (2000) utilized mutual information and chi-square statistics to identify typical contexts for a small set of targeted words from a large well-formed corpus. $$$$$ We present an unsupervised method for detecting grammatical errors by inferring negative evidence from edited textual corpora.
Chodorow and Leacock (2000) utilized mutual information and chi-square statistics to identify typical contexts for a small set of targeted words from a large well-formed corpus. $$$$$ When concentrate is used spatially, it selects the preposition in, as &quot;the stores were concentrated in the downtown area&quot;.

The filter-based system combines unsupervised detection of a set of possible errors (Chodorow and Leacock, 2000) with hand-crafted filters designed to reduce this set to the largest subset of correctly flagged errors and the smallest possible number of false positives. $$$$$ Statistically-based computer programs have been able to do the same with a high level of accuracy (Kilgarriff and Palmer, 2000).
The filter-based system combines unsupervised detection of a set of possible errors (Chodorow and Leacock, 2000) with hand-crafted filters designed to reduce this set to the largest subset of correctly flagged errors and the smallest possible number of false positives. $$$$$ In summary, Word97's precision in error detection is impressive, but the lower recall values indicate that it is responding to fewer error types than does ALEK.

Chodorow and Leacock (2000) found that low-frequency bigrams (sequences of two lexical categories with a negative log-likelihood) are quite reliable predictors of grammatical errors. $$$$$ In summary, Word97's precision in error detection is impressive, but the lower recall values indicate that it is responding to fewer error types than does ALEK.
Chodorow and Leacock (2000) found that low-frequency bigrams (sequences of two lexical categories with a negative log-likelihood) are quite reliable predictors of grammatical errors. $$$$$ The system was developed and tested using essay-length responses to prompts on the Test of English as a Foreign Language (TOEFL).
Chodorow and Leacock (2000) found that low-frequency bigrams (sequences of two lexical categories with a negative log-likelihood) are quite reliable predictors of grammatical errors. $$$$$ Schneider and McCoy (1998) developed a system tailored to the error productions of American Sign Language signers.
Chodorow and Leacock (2000) found that low-frequency bigrams (sequences of two lexical categories with a negative log-likelihood) are quite reliable predictors of grammatical errors. $$$$$ From the wordspecific corpus, ALEK forms templates, sequences of words and tags that represent the local context of the target.
