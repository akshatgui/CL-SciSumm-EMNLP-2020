To evaluate the grammaticality of our generated summaries, following common practice (Barzilay and McKeown, 2005), we randomly selected 50 sentences from original conversations and system generated abstracts, for each dataset. $$$$$ However, these approaches operate in a limited domain (e.g., terrorist events), where information extraction systems can be used to interpret the source text.
To evaluate the grammaticality of our generated summaries, following common practice (Barzilay and McKeown, 2005), we randomly selected 50 sentences from original conversations and system generated abstracts, for each dataset. $$$$$ The main difference between the two methods is in the type of the alignment: Our algorithm performs local alignment, while the algorithm of Pang, Knight, and Marcu (2003) performs global alignment.
To evaluate the grammaticality of our generated summaries, following common practice (Barzilay and McKeown, 2005), we randomly selected 50 sentences from original conversations and system generated abstracts, for each dataset. $$$$$ In addition, some algorithms constrain the topology of the resulting alignment based on the domain-specific knowledge.
To evaluate the grammaticality of our generated summaries, following common practice (Barzilay and McKeown, 2005), we randomly selected 50 sentences from original conversations and system generated abstracts, for each dataset. $$$$$ Function: EdgeSim(edge1, edge2) Returns: The similarity score of two input edges based on their type begin if type of(edge1) = type of(edge2) = ‘subject-verb’ then return SUBJECT VERB SCORE; if is phrase (node1) or is phrase (node2) then All the comparison functions employ memoization, implemented by hash table wrappers.

Finally, recent research on analyzing online social media shown a growing interest in mining news stories and headlines because of its broad applications ranging from "meme" tracking and spike detection (Leskovec et al., 2009) to text summarization (Barzilay and McKeown, 2005). $$$$$ We are grateful to Eli Barzilay, Michael Collins, No`emie Elhadad, Julia Hirschberg, Mirella Lapata, Lillian Lee, Smaranda Muresan, and the anonymous reviewers for helpful comments and conversations.
Finally, recent research on analyzing online social media shown a growing interest in mining news stories and headlines because of its broad applications ranging from "meme" tracking and spike detection (Leskovec et al., 2009) to text summarization (Barzilay and McKeown, 2005). $$$$$ Function: MapChildren(tree1, tree2) memoized Returns: Given two dependency trees, MapChildren finds the optimal alignment of tree children.
Finally, recent research on analyzing online social media shown a growing interest in mining news stories and headlines because of its broad applications ranging from "meme" tracking and spike detection (Leskovec et al., 2009) to text summarization (Barzilay and McKeown, 2005). $$$$$ Portions of this work were completed while the first author was a graduate student at Columbia University.
Finally, recent research on analyzing online social media shown a growing interest in mining news stories and headlines because of its broad applications ranging from "meme" tracking and spike detection (Leskovec et al., 2009) to text summarization (Barzilay and McKeown, 2005). $$$$$ Sentence fusion moves the summarization field from the use of purely extractive methods to the generation of abstracts that contain sentences not found in any of the input documents and can synthesize information across sources.

The pioneering work on fusion is Barzilay and McKeown (2005), which introduces the frame work used by subsequent projects: they represent the inputs by dependency trees, align some words to merge the input trees into a lattice, and then extract a single, connected dependency tree as the output. $$$$$ The process so far produces a sentence that can be quite different from the extracted sentence; although the basis sentences provides guidance for the generation process, constituents may be removed, added in, or reordered.
The pioneering work on fusion is Barzilay and McKeown (2005), which introduces the frame work used by subsequent projects: they represent the inputs by dependency trees, align some words to merge the input trees into a lattice, and then extract a single, connected dependency tree as the output. $$$$$ An overview of related work and a discussion of future directions conclude the article.
The pioneering work on fusion is Barzilay and McKeown (2005), which introduces the frame work used by subsequent projects: they represent the inputs by dependency trees, align some words to merge the input trees into a lattice, and then extract a single, connected dependency tree as the output. $$$$$ 4.1.3 Baselines.

Barzilay and McKeown (2005) proposed an idea called sentence fusion that integrates information in overlapping sentences to produce a non-overlapping summary sentence. $$$$$ The function returns the score of the alignment and the mapping itself. begin /*Generate all legitimate mappings between the children on tree1 and tree2 */ all-maps <-- GenerateAllPermutations (tree1, tree2) ; best <-- (−1, void) ; /*Compute the score of each mapping, and select the one with the highest score */ + Sim (subtree (tree1, s1), (subtree (tree2, s2)); Function: NodeCompare(tree1, tree2) memoized Returns: Given two dependency trees, NodeCompare finds their optimal alignment that maps two top nodes of the tree one to another.
Barzilay and McKeown (2005) proposed an idea called sentence fusion that integrates information in overlapping sentences to produce a non-overlapping summary sentence. $$$$$ For example, a lexicon is used to identify which components of the sentence are obligatory to keep it grammatically correct.
Barzilay and McKeown (2005) proposed an idea called sentence fusion that integrates information in overlapping sentences to produce a non-overlapping summary sentence. $$$$$ Summary phrases are followed by parenthetical numbers indicating their source articles.

This is the other way around compared to the English dependency such as in Barzilay and McKeown (2005). $$$$$ The second baseline is produced by a simplification of our algorithm, where paraphrase information is omitted during the alignment process.
This is the other way around compared to the English dependency such as in Barzilay and McKeown (2005). $$$$$ We believe that the process of aligning theme sentences can be greatly improved by having the system learn the similarity function, instead of using manually assigned weights.
This is the other way around compared to the English dependency such as in Barzilay and McKeown (2005). $$$$$ In the next section, we provide an overview of MultiGen, focusing on components that produce input or operate over output of sentence fusion.
This is the other way around compared to the English dependency such as in Barzilay and McKeown (2005). $$$$$ As the set of sentences in the table illustrates, sentences within a theme are not exact repetitions of each other; they usually include phrases expressing information that is not common to all sentences in the theme.

Either a sentences from the cluster is selected (Aliguliyev, 2006) or a new sentence is regenerated from all/some sentences in a cluster (Barzilay and McKeown, 2005). $$$$$ Sentence fusion involves bottom-up local multisequence alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence.
Either a sentences from the cluster is selected (Aliguliyev, 2006) or a new sentence is regenerated from all/some sentences in a cluster (Barzilay and McKeown, 2005). $$$$$ Sentence fusion involves bottom-up local multisequence alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence.
Either a sentences from the cluster is selected (Aliguliyev, 2006) or a new sentence is regenerated from all/some sentences in a cluster (Barzilay and McKeown, 2005). $$$$$ Sentence fusion involves bottom-up local multisequence alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence.
Either a sentences from the cluster is selected (Aliguliyev, 2006) or a new sentence is regenerated from all/some sentences in a cluster (Barzilay and McKeown, 2005). $$$$$ A system that can produce informative summaries, highlighting common information found in many online documents, will help Web users to pinpoint information that they need without extensive reading.

Recent abstractive approaches, such as sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009) and sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009) have focused on rewriting techniques, without consideration for a complete model which would include a transition to an abstract representation for content selection. $$$$$ A system that can produce informative summaries, highlighting common information found in many online documents, will help Web users to pinpoint information that they need without extensive reading.
Recent abstractive approaches, such as sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009) and sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009) have focused on rewriting techniques, without consideration for a complete model which would include a transition to an abstract representation for content selection. $$$$$ Function: EdgeSim(edge1, edge2) Returns: The similarity score of two input edges based on their type begin if type of(edge1) = type of(edge2) = ‘subject-verb’ then return SUBJECT VERB SCORE; if is phrase (node1) or is phrase (node2) then All the comparison functions employ memoization, implemented by hash table wrappers.
Recent abstractive approaches, such as sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009) and sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009) have focused on rewriting techniques, without consideration for a complete model which would include a transition to an abstract representation for content selection. $$$$$ The function returns the score of the alignment and the mapping itself. begin /*Generate all legitimate mappings between the children on tree1 and tree2 */ all-maps <-- GenerateAllPermutations (tree1, tree2) ; best <-- (−1, void) ; /*Compute the score of each mapping, and select the one with the highest score */ + Sim (subtree (tree1, s1), (subtree (tree2, s2)); Function: NodeCompare(tree1, tree2) memoized Returns: Given two dependency trees, NodeCompare finds their optimal alignment that maps two top nodes of the tree one to another.
Recent abstractive approaches, such as sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009) and sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009) have focused on rewriting techniques, without consideration for a complete model which would include a transition to an abstract representation for content selection. $$$$$ An important goal for future work on sentence fusion is to increase the flexibility of content selection and realization.

The work of (Barzilay and McKeown, 2005) on sentence fusion shows an example of re-using the same syntactical structure of a source sentence to create a new one with a slightly different meaning. $$$$$ At least two mistakes resulted from noisy preprocessing (tokenization and parsing).
The work of (Barzilay and McKeown, 2005) on sentence fusion shows an example of re-using the same syntactical structure of a source sentence to create a new one with a slightly different meaning. $$$$$ Combining evidence from multiple trees is an essential step of our algorithm—pairwise comparison of nonparallel trees may not provide enough information regarding their underlying correspondences.
The work of (Barzilay and McKeown, 2005) on sentence fusion shows an example of re-using the same syntactical structure of a source sentence to create a new one with a slightly different meaning. $$$$$ In particular, generation for sentence fusion must be able to operate in a domainindependent fashion, scalable to handle a large variety of input documents with various degrees of overlap.
The work of (Barzilay and McKeown, 2005) on sentence fusion shows an example of re-using the same syntactical structure of a source sentence to create a new one with a slightly different meaning. $$$$$ In this article, we introduce sentence fusion, a novel text-to-text generation technique for synthesizing common information across documents.

The work of Barzilay and McKeown (2005) on Sentence Fusion introduced the problem of converting multiple sentences into a single summary sentence. $$$$$ In this article, we present a method for sentence fusion that exploits redundancy to achieve this task in the context of multidocument summarization.
The work of Barzilay and McKeown (2005) on Sentence Fusion introduced the problem of converting multiple sentences into a single summary sentence. $$$$$ An example of noisy Simfinder output.
The work of Barzilay and McKeown (2005) on Sentence Fusion introduced the problem of converting multiple sentences into a single summary sentence. $$$$$ In this article, we introduce sentence fusion, a novel text-to-text generation technique for synthesizing common information across documents.
The work of Barzilay and McKeown (2005) on Sentence Fusion introduced the problem of converting multiple sentences into a single summary sentence. $$$$$ Portions of this work were completed while the first author was a graduate student at Columbia University.

In our experiments, dependency parsing is accomplished with Minipar (Lin, 1998) and alignment is done using a bottom-up tree alignment algorithm (Barzilay and McKeown, 2005) modified to account for the shallow semantic role labels produced by the parser. $$$$$ The tree alignment is assembled by adding a pair of top nodes to the optimal alignment of their children.
In our experiments, dependency parsing is accomplished with Minipar (Lin, 1998) and alignment is done using a bottom-up tree alignment algorithm (Barzilay and McKeown, 2005) modified to account for the shallow semantic role labels produced by the parser. $$$$$ Sentence fusion involves bottom-up local multisequence alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence.
In our experiments, dependency parsing is accomplished with Minipar (Lin, 1998) and alignment is done using a bottom-up tree alignment algorithm (Barzilay and McKeown, 2005) modified to account for the shallow semantic role labels produced by the parser. $$$$$ We believe that the process of aligning theme sentences can be greatly improved by having the system learn the similarity function, instead of using manually assigned weights.
In our experiments, dependency parsing is accomplished with Minipar (Lin, 1998) and alignment is done using a bottom-up tree alignment algorithm (Barzilay and McKeown, 2005) modified to account for the shallow semantic role labels produced by the parser. $$$$$ The last sentence is extracted because it was repeated verbatim in several input articles.

Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009), and a generation based approach that could be called sentence splitting (Genest and Lapalme, 2011). $$$$$ Specifically, a theme that has many sentences ranked high by lexical chains as important for a single-document summary is, in turn, given a higher salience score for the multidocument summary.
Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009), and a generation based approach that could be called sentence splitting (Genest and Lapalme, 2011). $$$$$ Information that is common across sentences is shown in the table in boldface; other portions of the sentence are specific to individual articles.
Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009), and a generation based approach that could be called sentence splitting (Genest and Lapalme, 2011). $$$$$ In this article, we introduce sentence fusion, a novel text-to-text generation technique for synthesizing common information across documents.
Abstractive summarization has been explored to some extent in recent years: sentence compression (Knight and Marcu, 2000) (Cohn and Lapata, 2009), sentence fusion (Barzilay and McKeown, 2005) or revision (Tanaka et al, 2009), and a generation based approach that could be called sentence splitting (Genest and Lapalme, 2011). $$$$$ Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation.

Sentence fusion is a text-to-text generation application, which given two related sentences, outputs a single sentence expressing the information shared by the two input sentences (Barzilay and McKeown 2005). $$$$$ In this article, we introduce sentence fusion, a novel text-to-text generation technique for synthesizing common information across documents.
Sentence fusion is a text-to-text generation application, which given two related sentences, outputs a single sentence expressing the information shared by the two input sentences (Barzilay and McKeown 2005). $$$$$ */ return (node-sim + res.score, (tree1.top, tree2.top) U res.map) ;
Sentence fusion is a text-to-text generation application, which given two related sentences, outputs a single sentence expressing the information shared by the two input sentences (Barzilay and McKeown 2005). $$$$$ We found that in 27 cases the optimal verbalizations (in the authors’ view) were ranked below the top-10 sentences ranked by the language model.
Sentence fusion is a text-to-text generation application, which given two related sentences, outputs a single sentence expressing the information shared by the two input sentences (Barzilay and McKeown 2005). $$$$$ Sentence fusion involves bottom-up local multisequence alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence.

Barzilay and McKeown (2005) argue convincingly that employing such a fusion strategy in a multidocument summarization system can result in more informative and more coherent summaries. $$$$$ Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation.
Barzilay and McKeown (2005) argue convincingly that employing such a fusion strategy in a multidocument summarization system can result in more informative and more coherent summaries. $$$$$ (An example of a fusion sentence is shown in Table 1.)
Barzilay and McKeown (2005) argue convincingly that employing such a fusion strategy in a multidocument summarization system can result in more informative and more coherent summaries. $$$$$ The tree alignment is assembled by adding a pair of top nodes to the optimal alignment of their children.
Barzilay and McKeown (2005) argue convincingly that employing such a fusion strategy in a multidocument summarization system can result in more informative and more coherent summaries. $$$$$ Sentence fusion is the central technique used within the MultiGen summarization system.

In contrast to these approaches, sentence fusion was introduced to combine fragments of sentences with common information for multi-document summarization (Barzilay and McKeown, 2005). $$$$$ If language generation can be scaled to take fully formed text as input without semantic interpretation, selecting content and producing well-formed English sentences as output, then generation has a large potential payoff.
In contrast to these approaches, sentence fusion was introduced to combine fragments of sentences with common information for multi-document summarization (Barzilay and McKeown, 2005). $$$$$ Before giving the precise definition of Sim, we introduce some notation.
In contrast to these approaches, sentence fusion was introduced to combine fragments of sentences with common information for multi-document summarization (Barzilay and McKeown, 2005). $$$$$ Sentence fusion moves the summarization field from the use of purely extractive methods to the generation of abstracts that contain sentences not found in any of the input documents and can synthesize information across sources.
In contrast to these approaches, sentence fusion was introduced to combine fragments of sentences with common information for multi-document summarization (Barzilay and McKeown, 2005). $$$$$ Sentence fusion moves the summarization field from the use of purely extractive methods to the generation of abstracts that contain sentences not found in any of the input documents and can synthesize information across sources.
