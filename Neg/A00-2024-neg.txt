The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ We also investigated possible sentence combination operations and implemented the combination module.
The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ Based on the observation of cut and paste practice by humans, we produced a set of general heuristic rules.
The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ Table 1 shows the combination operations.

Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ The goal of the aggregation operation and the smoothing operation is similar to that of the sentence combination operation in our system.
Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ For instance, the summaries substituted point out with note, and fits squarely into with a more picturesque description hits the head on the nail in the previous examples.
Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ The automatic decomposition allows us to build large corpora for studying sentence reduction and sentence combination, which are two effective operations in cut and paste.
Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ Our sentence reduction model determines what to cut based on multiple sources of information, including syntactic knowledge, context, and statistics learned from corpus analysis.

Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ Human subjects were also asked to select the document sentences that are semantic-equivalent to the sentences in the abstracts.
Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ Our cut and paste based summarization is a computational model; we make no claim that humans use the same cut and paste operations.
Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ We will also extend the system to query-based summarization and investigate whether the system can be modified for multiple document summarization.

Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ The components in dotted lines are existing tools or resources; all the others were developed by ourselves.
Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ We will also extend the system to query-based summarization and investigate whether the system can be modified for multiple document summarization.
Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ Merge material from several sentences.
Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ IRI 96-19124 and MI 96-18797.

Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ We thank IBM for licensing us the ESG parser and the MITRE corporation for licensing us the coreference resolution system.
Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ There are also other cut and paste operations not listed here due to their infrequent occurrence.
Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ We used a Hidden Markov Model (Baum, 1972) solution to the decomposition problem.

We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ For instance, place an ending sentence in an article at the beginning of an abstract.
We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ (5) generalization or specification Replace phrases or clauses with more general or specific descriptions.
We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ Some studies are somewhere in between: &quot;summary language may or may not follow that of author's&quot; (Fidel, 1986).
We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ Examples include sentence reduction, sentence combination, syntactic transformation, and lexical paraphrasing.

The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ We thank IBM for licensing us the ESG parser and the MITRE corporation for licensing us the coreference resolution system.
The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ Our reduction module makes decisions based on multiple sources of knowledge: Original sentence : When it arrives sometime next year in new TV sets, the V-chip will give parents a new and potentially revolutionary device to block out programs they don't want their children to see. by adding up the scores of its children nodes in the parse tree.
The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ We also plan to evaluate the portability of the system by testing it on another corpus.
The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ (5) generalization or specification Replace phrases or clauses with more general or specific descriptions.

First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ Our evaluation includes separate evaluations of each module and the final evaluations of the overall system.
First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ They follow the author as closely as possible and reintegrate the most important points of a document in a shorter text&quot; (Endres-Niggemeyer et al., 1998).
First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ Its results have been used to train and test the sentence reduction and sentence combination module.
First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ We present a cut and paste based text summarizer, which uses operations derived from an analysis of human written abstracts.

Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ In both sentence reduction and combination, syntactic transformations may be involved.
Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ Examples include sentence reduction, sentence combination, syntactic transformation, and lexical paraphrasing.
Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ (2) Development of an automatic system to perform cut and paste operations.

Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ However, the combination operations and combination rules that we derived from corpus analysis are significantly different from those used in the above system, which mostly came from operations in traditional natural language generation.
Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ For instance, the summaries substituted point out with note, and fits squarely into with a more picturesque description hits the head on the nail in the previous examples.
Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ The goal of the aggregation operation and the smoothing operation is similar to that of the sentence combination operation in our system.

Existing work in abstractive summarization has been quite limited and can be categorized into two categories: (1) approaches using prior knowledge (Radev and McKeown, 1998) (Finley and Harabagiu, 2002) (DeJong, 1982) and (2) approaches using Natural Language Generation (NLG) systems (Saggion and Lapalme, 2002) (Jing and McKeown, 2000). $$$$$ Replace phrases with their paraphrases.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories: (1) approaches using prior knowledge (Radev and McKeown, 1998) (Finley and Harabagiu, 2002) (DeJong, 1982) and (2) approaches using Natural Language Generation (NLG) systems (Saggion and Lapalme, 2002) (Jing and McKeown, 2000). $$$$$ Our sentence reduction model determines what to cut based on multiple sources of information, including syntactic knowledge, context, and statistics learned from corpus analysis.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories: (1) approaches using prior knowledge (Radev and McKeown, 1998) (Finley and Harabagiu, 2002) (DeJong, 1982) and (2) approaches using Natural Language Generation (NLG) systems (Saggion and Lapalme, 2002) (Jing and McKeown, 2000). $$$$$ The deleted material can be at any granularity: a word, a phrase, or a clause.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories: (1) approaches using prior knowledge (Radev and McKeown, 1998) (Finley and Harabagiu, 2002) (DeJong, 1982) and (2) approaches using Natural Language Generation (NLG) systems (Saggion and Lapalme, 2002) (Jing and McKeown, 2000). $$$$$ (5) generalization or specification Replace phrases or clauses with more general or specific descriptions.

Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ Our work includes a statistically based sentence decomposition program that identifies where the phrases of a summary originate in the original document, producing an aligned corpus of summaries and articles which we used to develop the summarizer.
Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ One school of scholars is opposed; &quot;(use) your own words... Do not keep too close to the words before you&quot;, states an early book on abstracting for American high school students (Thurber, 1924).
Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ In human-written abstracts, there are, of course, sentences that are not based on cut and paste, but completely written from scratch.
Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ The decomposition program answers three questions about a sentence in a human-written abstract: (1) Is the sentence constructed by cutting and pasting phrases from the input article?

Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ It can be used together with sentence reduction, as illustrated in the following example, which also uses paraphrasing: Text Sentence 1: But it also raises serious questions about the privacy of such highly personal information wafting about the digital world.
Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ We used our decomposition program to automatically analyze 300 human-written abstracts, and found that 19% of sentences in the abstracts were written from scratch.
Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ Change the order of extracted sentences.
