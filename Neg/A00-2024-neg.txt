The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ We used our decomposition program to automatically analyze 300 human-written abstracts, and found that 19% of sentences in the abstracts were written from scratch.
The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ We also plan to evaluate the portability of the system by testing it on another corpus.
The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ Input to the system is a single document from any domain.
The recent approach for editing extracted text spans (Jing and McKeown,2000) may also produce improvement for our algorithm. $$$$$ Other resources and tools in the summarization system include a corpus of articles and their humanwritten abstracts, the automatic decomposition program, a syntactic parser, a co-reference resolution system, the WordNet lexical database, and a largescale lexicon we combined from multiple resources.

Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ (Mani et al., 1999) addressed the problem of revising summaries to improve their quality.
Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ ing operations.
Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ Table 1 shows the combination operations.
Jing and McKeown (2000) first extract sentences, then remove redundant phrases, and use (manual) recombination rules to produce coherent output. $$$$$ The key features of this work are:

Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ Examples include sentence reduction, sentence combination, syntactic transformation, and lexical paraphrasing.
Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ One school of scholars is opposed; &quot;(use) your own words... Do not keep too close to the words before you&quot;, states an early book on abstracting for American high school students (Thurber, 1924).
Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ We used our decomposition program to automatically analyze 300 human-written abstracts, and found that 19% of sentences in the abstracts were written from scratch.
Mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by Jing and McKeown (2000) which removed all prepositional phrases, clauses, to infinitives, and gerunds. $$$$$ They suggested three types of operations: elimination, aggregation, and smoothing.

Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ One school of scholars is opposed; &quot;(use) your own words... Do not keep too close to the words before you&quot;, states an early book on abstracting for American high school students (Thurber, 1924).
Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ We selected 20 documents; three different automatic summarizers were used to generate a summary for each document, producing 60 summaries in total.
Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ The components in dotted lines are existing tools or resources; all the others were developed by ourselves.
Like the work of Jing and McKeown (2000) and Mani et al (1999), our work was inspired by the summarization method used by human abstractors. $$$$$ Merge material from several sentences.

Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ This shortened text can be used directly as a summary, or it can be fed to the sentence combination module to be merged with other sentences.
Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ Such edits mainly involve cutting phrases and pasting them together in novel ways.
Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ Remove extraneous phrases from a selected sentence, as in the following example 1: 'All the examples in this section were produced by human professionals Document sentence: When it arrives sometime next year in new TV sets, the V-chip will give parents a new and potentially revolutionary device to block out programs they don't want their children to see.
Our two-step model essentially belongs to the same category as the works of (Mani et al, 1999) and (Jing and McKeown, 2000). $$$$$ This material is based upon work supported by the National Science Foundation under Grant No.

We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ The implementation of the combining actions involves joining two parse trees, substituting a subtree with another, or adding additional nodes.
We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ (Mani et al., 1999) addressed the problem of revising summaries to improve their quality.
We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ The components in dotted lines are existing tools or resources; all the others were developed by ourselves.
We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000). $$$$$ Our work includes a statistically based sentence decomposition program that identifies where the phrases of a summary originate in the original document, producing an aligned corpus of summaries and articles which we used to develop the summarizer.

The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ We present a cut and paste based text summarizer, which uses operations derived from an analysis of human written abstracts.
The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ We are currently exploring using machine learning techniques to learn the combination rules from our corpus.
The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ IRI 96-19124 and MI 96-18797.
The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000). $$$$$ We used our decomposition program to automatically analyze 300 human-written abstracts, and found that 19% of sentences in the abstracts were written from scratch.

First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ Recently, we have also tested the system on legal documents (the headnotes used by Westlaw company), and the program works well on those documents too.
First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ In human-written abstracts, there are, of course, sentences that are not based on cut and paste, but completely written from scratch.
First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation. $$$$$ The difference is that while elimination always removes parentheticals, sentenceinitial PPs and certain adverbial phrases for every extracted sentence, our sentence reduction module aims to make reduction decisions according to each case and removes a sentence component only if it considers it appropriate to do so.

Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ Input to the system is a single document from any domain.
Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ Our work includes a statistically based sentence decomposition program that identifies where the phrases of a summary originate in the original document, producing an aligned corpus of summaries and articles which we used to develop the summarizer.
Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ The architecture of our cut and paste based text summarization system is shown in Figure 1.
Rewrite operations other than deletion tend to be hand-crafted and domain specific (Jing and McKeown, 2000). $$$$$ The difference is that while elimination always removes parentheticals, sentenceinitial PPs and certain adverbial phrases for every extracted sentence, our sentence reduction module aims to make reduction decisions according to each case and removes a sentence component only if it considers it appropriate to do so.

Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ We present a cut and paste based text summarizer, which uses operations derived from an analysis of human written abstracts.
Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ The difference is that while elimination always removes parentheticals, sentenceinitial PPs and certain adverbial phrases for every extracted sentence, our sentence reduction module aims to make reduction decisions according to each case and removes a sentence component only if it considers it appropriate to do so.
Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ Input to the system is a single document from any domain.
Jing and McKeown (2000) studied what edits people use to create summaries from sentences in the source text. $$$$$ The components in dotted lines are existing tools or resources; all the others were developed by ourselves.

Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ (Mani et al., 1999) addressed the problem of revising summaries to improve their quality.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ Our cut and paste based summarization is a computational model; we make no claim that humans use the same cut and paste operations.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ We defined six operations that can be used alone, sequentially, or simultaneously to transform selected sentences from an article into the corresponding summary sentences in its human-written abstract:
Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ Other guidelines or books on abstracting (ANSI, 1997; Cremmins, 1982) do not discuss the issue.

Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ We present a cut and paste based text summarizer, which uses operations derived from an analysis of human written abstracts.
Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ We used our decomposition program to automatically analyze 300 human-written abstracts, and found that 19% of sentences in the abstracts were written from scratch.
Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ Examples of generalization and specification include: Generalization: &quot;a proposed new law that would require Web publishers to obtain parental consent before collecting personal information from children&quot; &quot;legislation to protect children's privacy on-line&quot; Specification: &quot;the White House's top drug official&quot; -4 &quot;Gen. Barry R. McCaffrey, the White House's top drug official&quot;
Close to the problem studied here is Jing and McKeown's (Jing and McKeown,2000) cut-and-paste method founded on Endres Niggemeyer's observations. $$$$$ (5) generalization or specification Replace phrases or clauses with more general or specific descriptions.

Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ IRI 96-19124 and MI 96-18797.
Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ (5) generalization or specification Replace phrases or clauses with more general or specific descriptions.
Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ The main idea of cut and paste summarization is to reuse the text in an article to generate the summary.
Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text. $$$$$ We will also extend the system to query-based summarization and investigate whether the system can be modified for multiple document summarization.
