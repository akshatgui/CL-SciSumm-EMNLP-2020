First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967) while more than 23% of the 73088 dependency structures in the Prague Dependency Treebank of Czech (Hajic et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006). $$$$$ In section 2, we provide a formal definition of dependency structures as a special kind of directed graphs, and characterize the notion of projectivity.
First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967) while more than 23% of the 73088 dependency structures in the Prague Dependency Treebank of Czech (Hajic et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006). $$$$$ The evaluation presented by Yli-Jyrä (2003) makes use of additional constraints that are sufficient to make the decomposition unique.
First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967) while more than 23% of the 73088 dependency structures in the Prague Dependency Treebank of Czech (Hajic et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006). $$$$$ In dependency-based parsing, several constraints have been proposed that restrict the class of permissible structures, such as projectivity, planarity, multi-planarity, well-nestedness, gap degree, and edge degree.
First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967) while more than 23% of the 73088 dependency structures in the Prague Dependency Treebank of Czech (Hajic et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006). $$$$$ In section 3, we define and compare five different constraints on mildly non-projective dependency structures that can be found in the literature: planarity, multiplanarity, well-nestedness, gap degree, and edge degree.

Mildly non-projective trees are of both theoretical and practical interest, as they correspond to derivations in Lexicalized Tree Adjoining Grammar (Bodirsky et al, 2005) and cover the overwhelming majority of sentences found in tree banks for Czech and Danish (Kuhlmann and Nivre, 2006). $$$$$ Both Graph 3b and 3c have edge degree 1: the edge (3, 6) in Graph 3b and the edges (2, 4), (3, 5) and (4, 6) in Graph 3c each span a single connected component that is not dominated by the respective head.
Mildly non-projective trees are of both theoretical and practical interest, as they correspond to derivations in Lexicalized Tree Adjoining Grammar (Bodirsky et al, 2005) and cover the overwhelming majority of sentences found in tree banks for Czech and Danish (Kuhlmann and Nivre, 2006). $$$$$ Syntactic parsing requires a fine balance between expressivity and complexity, so that naturally occurring structures can be accurately parsed without compromising efficiency.
Mildly non-projective trees are of both theoretical and practical interest, as they correspond to derivations in Lexicalized Tree Adjoining Grammar (Bodirsky et al, 2005) and cover the overwhelming majority of sentences found in tree banks for Czech and Danish (Kuhlmann and Nivre, 2006). $$$$$ Some authors extend dependency forests by a special root node with position 0, and add an edge (0, i) for every root node i of the remaining graph (McDonald et al., 2005).

In this paper, we consider all constraints and measures evaluated by Kuhlmann and Nivre (2006) with some minor variations. $$$$$ In the rightmost graph, the gap degree of i is 2, since 7ri = (2, 4, 6) contains two gaps ((2, 4) and (4, 6)).
In this paper, we consider all constraints and measures evaluated by Kuhlmann and Nivre (2006) with some minor variations. $$$$$ (As an example, only 7 or 0.17% of the analyses in DDT have gap 4A total number of 17 analyses in DDT were excluded because they either had more than one root node, or violated the indegree constraint.
In this paper, we consider all constraints and measures evaluated by Kuhlmann and Nivre (2006) with some minor variations. $$$$$ As an example, consider the node labelled i in the dependency graphs in Figure 3.
In this paper, we consider all constraints and measures evaluated by Kuhlmann and Nivre (2006) with some minor variations. $$$$$ This is especially relevant for languages with free or flexible word order.

None of the constraints and measures in Kuhlmann and Nivre (2006) take into account levels of nodes explicitly. $$$$$ The work of Joakim Nivre is partially supported by the Swedish Research Council.
None of the constraints and measures in Kuhlmann and Nivre (2006) take into account levels of nodes explicitly. $$$$$ Regarding the binary constraints, we find that planarity accounts for slightly more than the projective structures (86.41% of the data is planar), while almost all structures in DDT (99.89%) meet the well-nestedness constraint.
None of the constraints and measures in Kuhlmann and Nivre (2006) take into account levels of nodes explicitly. $$$$$ We write i --> j to mean that there is an edge from the node i to the node j (i.e., (i, j) E E), and i -->* j to mean that the node i dominates the node j, i.e., that there is a (possibly empty) path from i to j.
None of the constraints and measures in Kuhlmann and Nivre (2006) take into account levels of nodes explicitly. $$$$$ Another important line of research is the integration of these constraints into parsing algorithms for non-projective dependency structures, potentially leading to a better trade-off between accuracy and efficiency than that obtained with existing methods.

They confirm the findings of Kuhlmann and Nivre (2006): planarity seems to be almost as restrictive as projectivity; well-nestedness, on the other hand, covers large proportions of trees in all languages. $$$$$ In this paper, we review and compare the different constraints theoretically, and provide an experimental evaluation using data from two treebanks, investigating how large a proportion of the structures found in the treebanks are permitted under different constraints.
They confirm the findings of Kuhlmann and Nivre (2006): planarity seems to be almost as restrictive as projectivity; well-nestedness, on the other hand, covers large proportions of trees in all languages. $$$$$ We compare the proposals from a theoretical point of view, and evaluate a subset of them empirically by testing their representational adequacy with respect to two dependency treebanks: the Prague Dependency Treebank (PDT) (Hajiˇc et al., 2001), and the Danish Dependency Treebank (DDT) (Kromann, 2003).
They confirm the findings of Kuhlmann and Nivre (2006): planarity seems to be almost as restrictive as projectivity; well-nestedness, on the other hand, covers large proportions of trees in all languages. $$$$$ * i.
They confirm the findings of Kuhlmann and Nivre (2006): planarity seems to be almost as restrictive as projectivity; well-nestedness, on the other hand, covers large proportions of trees in all languages. $$$$$ The minimal degree of non-projectivity required to cover all of the data is 2 in the case of gap degree and 4 in the case of edge degree.

This supports our theoretical results and confirms that properties of non-projective edges provide a more accurate as well as expressive means for describing non projective structures in natural language than the constraints and measures considered by Kuhlmann and Nivre (2006). $$$$$ A gap is a discontinuity in the projection of a node in a dependency graph (Plátek et al., 2001).
This supports our theoretical results and confirms that properties of non-projective edges provide a more accurate as well as expressive means for describing non projective structures in natural language than the constraints and measures considered by Kuhlmann and Nivre (2006). $$$$$ This is especially relevant for languages with free or flexible word order.
This supports our theoretical results and confirms that properties of non-projective edges provide a more accurate as well as expressive means for describing non projective structures in natural language than the constraints and measures considered by Kuhlmann and Nivre (2006). $$$$$ In section 5, we present our conclusions and suggestions for further research.

Kuhlmann and Nivre (2006) compare several constraints on dependency structures and among the considered ones find well-nestedness to be in good accord with empirical data. $$$$$ Since projectivity requires each node to dominate a continuous substring of the sentence, it corresponds to a ban on discontinuous constituents in phrase structure representations.
Kuhlmann and Nivre (2006) compare several constraints on dependency structures and among the considered ones find well-nestedness to be in good accord with empirical data. $$$$$ The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003).
Kuhlmann and Nivre (2006) compare several constraints on dependency structures and among the considered ones find well-nestedness to be in good accord with empirical data. $$$$$ Definition 5 A dependency graph G = (V ; E) is m-planar, if it can be split into m planar graphs such that E = E1U- - -UEm.
Kuhlmann and Nivre (2006) compare several constraints on dependency structures and among the considered ones find well-nestedness to be in good accord with empirical data. $$$$$ Definition 9 Let G = (V I E) be a dependency forest, let e = (i, j) be an edge in E, and let Ge be the subgraph of G that is induced by the nodes contained in the span of e. • The degree of an edge e 2 E, ed(e), is the number of connected components c in Ge such that the root of c is not dominated by the head of e. • The edge degree of G, ed(G), is the maximum among the degrees of the edges in G. To illustrate the notion of edge degree, we return to Figure 3.

Kuhlmann and Nivre (2006) claim that the constraint of well-nestedness seems to approximate well dependency structures occurring in natural language. $$$$$ While projectivity is generally taken to be too restrictive for natural language syntax, it is not clear which of the other proposals strikes the best balance between expressivity and complexity.
Kuhlmann and Nivre (2006) claim that the constraint of well-nestedness seems to approximate well dependency structures occurring in natural language. $$$$$ Our experiments concern only the analytical layer, and are based on the dedicated training section of the treebank.
Kuhlmann and Nivre (2006) claim that the constraint of well-nestedness seems to approximate well dependency structures occurring in natural language. $$$$$ This raises the question of whether it is possible to characterize a class of mildly non-projective dependency structures that is rich enough to account for naturally occurring syntactic constructions, yet restricted enough to enable efficient parsing.
Kuhlmann and Nivre (2006) claim that the constraint of well-nestedness seems to approximate well dependency structures occurring in natural language. $$$$$ On the other hand, in PDT, a sentencefinal punctuation mark is annotated as a separate root node with no dependents.

Unlike acyclicity and the single head constraints, which impose restrictions on the dependency relation as such, projectivity constrains the interaction between the dependency relations and the order of the nodes in the sentence (Kuhlmann and Nivre, 2006). $$$$$ We compare the proposals from a theoretical point of view, and evaluate a subset of them empirically by testing their representational adequacy with respect to two dependency treebanks: the Prague Dependency Treebank (PDT) (Hajiˇc et al., 2001), and the Danish Dependency Treebank (DDT) (Kromann, 2003).
Unlike acyclicity and the single head constraints, which impose restrictions on the dependency relation as such, projectivity constrains the interaction between the dependency relations and the order of the nodes in the sentence (Kuhlmann and Nivre, 2006). $$$$$ Apart from proposals for structural constraints relaxing projectivity, there are dependency frameworks that in principle allow unrestricted graphs, but provide mechanisms to control the actually permitted forms of non-projectivity in the grammar.
Unlike acyclicity and the single head constraints, which impose restrictions on the dependency relation as such, projectivity constrains the interaction between the dependency relations and the order of the nodes in the sentence (Kuhlmann and Nivre, 2006). $$$$$ This is especially relevant for languages with free or flexible word order.
Unlike acyclicity and the single head constraints, which impose restrictions on the dependency relation as such, projectivity constrains the interaction between the dependency relations and the order of the nodes in the sentence (Kuhlmann and Nivre, 2006). $$$$$ Then a gap is a pair (jk, jk+1) of nodes adjacent in 7ri such that Definition 6 The gap degree of a node i in a dependency graph, gd(i), is the number of gaps in 7ri.

Following (Kuhlmann and Nivre, 2006), we call this edge degree to avoid confusion. $$$$$ Some authors extend dependency forests by a special root node with position 0, and add an edge (0, i) for every root node i of the remaining graph (McDonald et al., 2005).
Following (Kuhlmann and Nivre, 2006), we call this edge degree to avoid confusion. $$$$$ We use the notation 3r(i) to refer to the projection of i: the yield of i, arranged in ascending order.
Following (Kuhlmann and Nivre, 2006), we call this edge degree to avoid confusion. $$$$$ The work of Joakim Nivre is partially supported by the Swedish Research Council.

 $$$$$ The fundamental difference between gap degree and edge degree is that the gap degree measures the number of discontinuities within a subtree, while the edge degree measures the number of intervening constituents spanned by a single edge.
 $$$$$ We write i --> j to mean that there is an edge from the node i to the node j (i.e., (i, j) E E), and i -->* j to mean that the node i dominates the node j, i.e., that there is a (possibly empty) path from i to j.
 $$$$$ In this paper, we have reviewed a number of proposals for the characterization of mildly non-projective dependency structures, motivated by the need to find a better balance between expressivity and complexity than that offered by either strictly projective or unrestricted non-projective structures.
 $$$$$ Since projectivity requires each node to dominate a continuous substring of the sentence, it corresponds to a ban on discontinuous constituents in phrase structure representations.

This work further corroborates Kuhlmann's work on Czech (PDT) for Hindi (Kuhlmann and Nivre, 2006). $$$$$ The work of Marco Kuhlmann is funded by the Collaborative Research Centre 378 ‘Resource-Adaptive Cognitive Processes’ of the Deutsche Forschungsgemeinschaft.
This work further corroborates Kuhlmann's work on Czech (PDT) for Hindi (Kuhlmann and Nivre, 2006). $$$$$ In section 3, we define and compare five different constraints on mildly non-projective dependency structures that can be found in the literature: planarity, multiplanarity, well-nestedness, gap degree, and edge degree.
This work further corroborates Kuhlmann's work on Czech (PDT) for Hindi (Kuhlmann and Nivre, 2006). $$$$$ Syntactic parsing requires a fine balance between expressivity and complexity, so that naturally occurring structures can be accurately parsed without compromising efficiency.

Recent work identifies two properties that appear particularly relevant to the characterization of graph-based dependency models of syntactic structure: the absence of interleaving substructures (well-nestedness) and a bound on a type of discontinuity (gap-degree <= 1) successfully describe more than 99% of the structures in two dependency tree banks (Kuhlmann and Nivre 2006) . $$$$$ Many practical implementations of dependency parsing are restricted to projective structures, where the projection of a head word has to form a continuous substring of the sentence.
Recent work identifies two properties that appear particularly relevant to the characterization of graph-based dependency models of syntactic structure: the absence of interleaving substructures (well-nestedness) and a bound on a type of discontinuity (gap-degree <= 1) successfully describe more than 99% of the structures in two dependency tree banks (Kuhlmann and Nivre 2006) . $$$$$ Informally, a dependency graph is planar, if its edges can be drawn above the sentence without crossing.
Recent work identifies two properties that appear particularly relevant to the characterization of graph-based dependency models of syntactic structure: the absence of interleaving substructures (well-nestedness) and a bound on a type of discontinuity (gap-degree <= 1) successfully describe more than 99% of the structures in two dependency tree banks (Kuhlmann and Nivre 2006) . $$$$$ While this constraint guarantees good parsing complexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous.
Recent work identifies two properties that appear particularly relevant to the characterization of graph-based dependency models of syntactic structure: the absence of interleaving substructures (well-nestedness) and a bound on a type of discontinuity (gap-degree <= 1) successfully describe more than 99% of the structures in two dependency tree banks (Kuhlmann and Nivre 2006) . $$$$$ When we compare it with the notion of gaps, for example, we find that, in a planar dependency tree, every gap .i; j/ must contain the root node r, in the sense that i < r < j: if the gap would only contain non-root nodes k, then the two paths from r to k and from i to j would cross.

Relevant results from Kuhlmann and Nivre (2006). $$$$$ Syntactic parsing requires a fine balance between expressivity and complexity, so that naturally occurring structures can be accurately parsed without compromising efficiency.
Relevant results from Kuhlmann and Nivre (2006). $$$$$ But then, one not only needs to show that a dependency graph can be decomposed into m planar graphs, but also that this decomposition is the one with the smallest number of planes among all possible decompositions.
Relevant results from Kuhlmann and Nivre (2006). $$$$$ The results indicate that a combination of the well-nestedness constraint and a parametric constraint on discontinuity gives a very good fit with the linguistic data.
Relevant results from Kuhlmann and Nivre (2006). $$$$$ Syntactic parsing requires a fine balance between expressivity and complexity, so that naturally occurring structures can be accurately parsed without compromising efficiency.

See Kuhlmann and Nivre (2006) for the definition of edge degree. $$$$$ Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999), Bulgarian (Marinov and Nivre, 2005), and Turkish (Eryi˘git and Oflazer, 2006).
See Kuhlmann and Nivre (2006) for the definition of edge degree. $$$$$ In dependency-based parsing, several constraints have been proposed that restrict the class of permissible structures, such as projectivity, planarity, multi-planarity, well-nestedness, gap degree, and edge degree.
See Kuhlmann and Nivre (2006) for the definition of edge degree. $$$$$ Well-nestedness also brings computational benefits.
See Kuhlmann and Nivre (2006) for the definition of edge degree. $$$$$ Nivre (2006) shows experimentally that limiting the permissible edge degree to 1 or 2 can reduce the average parsing time for a deterministic algorithm from quadratic to linear, while omitting less than 1% of the structures found in DDT and PDT.

If we suppose that the characterization of dependency structures as reported by Kuhlmann and Nivre (2006) for Czech and Danish extends cross-linguistically, i.e. the dependency structures for natural language falls within the class of well-nested and gap degree <= 1 dependency structures, then MC-TAG appears to correspond to the wrong class of model-theoretic dependency structures. $$$$$ This particular property does not seem to be mirrored in any linguistic prediction.
If we suppose that the characterization of dependency structures as reported by Kuhlmann and Nivre (2006) for Czech and Danish extends cross-linguistically, i.e. the dependency structures for natural language falls within the class of well-nested and gap degree <= 1 dependency structures, then MC-TAG appears to correspond to the wrong class of model-theoretic dependency structures. $$$$$ The work of Joakim Nivre is partially supported by the Swedish Research Council.
If we suppose that the characterization of dependency structures as reported by Kuhlmann and Nivre (2006) for Czech and Danish extends cross-linguistically, i.e. the dependency structures for natural language falls within the class of well-nested and gap degree <= 1 dependency structures, then MC-TAG appears to correspond to the wrong class of model-theoretic dependency structures. $$$$$ These subtrees interleave, as T1 contains the nodes 2 and 4, and T2 contains the nodes 3 and 5.
If we suppose that the characterization of dependency structures as reported by Kuhlmann and Nivre (2006) for Czech and Danish extends cross-linguistically, i.e. the dependency structures for natural language falls within the class of well-nested and gap degree <= 1 dependency structures, then MC-TAG appears to correspond to the wrong class of model-theoretic dependency structures. $$$$$ We write i --> j to mean that there is an edge from the node i to the node j (i.e., (i, j) E E), and i -->* j to mean that the node i dominates the node j, i.e., that there is a (possibly empty) path from i to j.

This keeps the corresponding graph drawings within the class of structures identified by Bodirsky et al (2005) as a model of TAG derivations, and by Kuhlmann and Nivre (2006) as empirically relevant. $$$$$ Since projectivity requires each node to dominate a continuous substring of the sentence, it corresponds to a ban on discontinuous constituents in phrase structure representations.
This keeps the corresponding graph drawings within the class of structures identified by Bodirsky et al (2005) as a model of TAG derivations, and by Kuhlmann and Nivre (2006) as empirically relevant. $$$$$ This particular property does not seem to be mirrored in any linguistic prediction.
This keeps the corresponding graph drawings within the class of structures identified by Bodirsky et al (2005) as a model of TAG derivations, and by Kuhlmann and Nivre (2006) as empirically relevant. $$$$$ Well-nestedness also brings computational benefits.
This keeps the corresponding graph drawings within the class of structures identified by Bodirsky et al (2005) as a model of TAG derivations, and by Kuhlmann and Nivre (2006) as empirically relevant. $$$$$ The rest of the paper is structured as follows.

While the number of highly non-projective dependency structures is negligible for practical applications (Kuhlmann and Nivre, 2006), the rank can not easily be bounded. $$$$$ A dependency tree is acceptable, if it can be lifted to form a projective graph.3 A similar design is pursued in Topological Dependency Grammar (Duchier and Debusmann, 2001), where a dependency analysis consists of two, mutually constraining graphs: the ID graph represents information about immediate dominance, the LP graph models the topological structure of a sentence.
While the number of highly non-projective dependency structures is negligible for practical applications (Kuhlmann and Nivre, 2006), the rank can not easily be bounded. $$$$$ In dependency-based parsing, several constraints have been proposed that restrict the class of permissible structures, such as projectivity, planarity, multi-planarity, well-nestedness, gap degree, and edge degree.
While the number of highly non-projective dependency structures is negligible for practical applications (Kuhlmann and Nivre, 2006), the rank can not easily be bounded. $$$$$ But then, one not only needs to show that a dependency graph can be decomposed into m planar graphs, but also that this decomposition is the one with the smallest number of planes among all possible decompositions.
While the number of highly non-projective dependency structures is negligible for practical applications (Kuhlmann and Nivre, 2006), the rank can not easily be bounded. $$$$$ In DDT, sentence-final punctuation marks are annotated as dependents of the main verb of a dependency nexus.

It is interesting to compare our approach with techniques for well-nested dependency trees (Kuhlmann and Nivre, 2006). $$$$$ We write i --> j to mean that there is an edge from the node i to the node j (i.e., (i, j) E E), and i -->* j to mean that the node i dominates the node j, i.e., that there is a (possibly empty) path from i to j.
It is interesting to compare our approach with techniques for well-nested dependency trees (Kuhlmann and Nivre, 2006). $$$$$ Acknowledgements We thank three anonymous reviewers of this paper for their comments.
It is interesting to compare our approach with techniques for well-nested dependency trees (Kuhlmann and Nivre, 2006). $$$$$ Some authors extend dependency forests by a special root node with position 0, and add an edge (0, i) for every root node i of the remaining graph (McDonald et al., 2005).
It is interesting to compare our approach with techniques for well-nested dependency trees (Kuhlmann and Nivre, 2006). $$$$$ DDT comprises 100k words of text selected from the Danish PAROLE corpus, with annotation property all structures gap degree 0 gap degree 1 gap degree 2 gap degree 3 gap degree 4 edge degree 0 edge degree 1 edge degree 2 edge degree 3 edge degree 4 edge degree 5 edge degree 6 projective planar well-nested of primary and secondary dependencies based on Discontinuous Grammar (Kromann, 2003).

Alternative notions of mildly non-projective dependency structures are explored in Kuhlmann and Nivre (2006). $$$$$ Our experiments concern only the analytical layer, and are based on the dedicated training section of the treebank.
Alternative notions of mildly non-projective dependency structures are explored in Kuhlmann and Nivre (2006). $$$$$ The non-projective dependency grammar of Kahane et al. (1998) is based on an operation on dependency trees called lifting: a ‘lift’ of a tree T is the new tree that is obtained when one replaces one 2We use the term edge degree instead of the original simple term degree from Nivre (2006) to mark the distinction from the notion of gap degree. or more edges (i, k) in T by edges (j, k), where j !
Alternative notions of mildly non-projective dependency structures are explored in Kuhlmann and Nivre (2006). $$$$$ * i.
