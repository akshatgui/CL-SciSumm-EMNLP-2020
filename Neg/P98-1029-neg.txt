Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation. $$$$$ In this paper, we showed that the error distributions for three popular state of the art part of speech taggers are highly complementary.
Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation. $$$$$ In this paper we explore whether classifier combination can result in an overall improvement in lexical disambiguation accuracy.
Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation. $$$$$ We also plan to explore different methods for combining classifier outputs.
Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation. $$$$$ We also plan to explore different methods for combining classifier outputs.

Committee-based approaches to POS tagging have been in focus the last decade $$$$$ Next, we show how this complementary behavior can be used to our advantage.
Committee-based approaches to POS tagging have been in focus the last decade $$$$$ Next, we described experiments that demonstrated that we can exploit this complementarity to build a tagger that attains significantly higher accuracy than any of the individual taggers.
Committee-based approaches to POS tagging have been in focus the last decade $$$$$ One of the most exciting recent directions in machine learning is the discovery that the combination of multiple classifiers often results in significantly better performance than what can be achieved with a single classifier.

In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994). $$$$$ Another possibility could be that all of the different machine learning techniques are essentially doing the same thing.
In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994). $$$$$ We can also conclude that the improvements we expect are somewhat additive, meaning the more taggers we combine, the better results we should expect.
In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994). $$$$$ In the future, we plan to expand our repertoire of base taggers, to determine whether performance continues to improve as we add additional systems.

The complementarity between two learners was defined by Brill and Wu (1998) in order to quantify the percentage of time when one system is wrong, that another system is correct, and therefore providing an upper bound on combination accuracy. $$$$$ Whereas the transformation-based tagger enforces multiple constraints by having multiple rules fire, the maximum-entropy tagger can have all of these constraints play a role at setting the probability estimates for the model's parameters.
The complementarity between two learners was defined by Brill and Wu (1998) in order to quantify the percentage of time when one system is wrong, that another system is correct, and therefore providing an upper bound on combination accuracy. $$$$$ In this paper we explore whether classifier combination can result in an overall improvement in lexical disambiguation accuracy.
The complementarity between two learners was defined by Brill and Wu (1998) in order to quantify the percentage of time when one system is wrong, that another system is correct, and therefore providing an upper bound on combination accuracy. $$$$$ In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.

The data used in the experiment was selected from the Penn Treebank Wall Street Journal, and is the same used by Brill and Wu (1998). $$$$$ In the first case, given an instance in the test set, we find the most specific matching example in the training set, using the prespecified back-off ordering, and see what the most probable tag was in the training set for that environment.
The data used in the experiment was selected from the Penn Treebank Wall Street Journal, and is the same used by Brill and Wu (1998). $$$$$ In the field of machine learning, there have been many recent results demonstrating the efficacy of combining classifiers.'
The data used in the experiment was selected from the Penn Treebank Wall Street Journal, and is the same used by Brill and Wu (1998). $$$$$ Next, we described experiments that demonstrated that we can exploit this complementarity to build a tagger that attains significantly higher accuracy than any of the individual taggers.
The data used in the experiment was selected from the Penn Treebank Wall Street Journal, and is the same used by Brill and Wu (1998). $$$$$ The complementary rates are quite high, which is encouraging, since this sets the upper bound on how well we can do in combining the different classifiers.

The investigated MMVC model proves to be a very effective participant in classifier combination, with substantially different output to Naive Bayes (9.6% averaged complementary rate, as defined in Brill and Wu (1998)). $$$$$ By using contextual cues to guide tagger combination, we are able to derive a new tagger that achieves performance significantly greater than any of the individual taggers.
The investigated MMVC model proves to be a very effective participant in classifier combination, with substantially different output to Naive Bayes (9.6% averaged complementary rate, as defined in Brill and Wu (1998)). $$$$$ In the future, we plan to expand our repertoire of base taggers, to determine whether performance continues to improve as we add additional systems.
The investigated MMVC model proves to be a very effective participant in classifier combination, with substantially different output to Naive Bayes (9.6% averaged complementary rate, as defined in Brill and Wu (1998)). $$$$$ We know that the features used by the different algorithms are very similar, typically the words and tags within a small window from the word being tagged.
The investigated MMVC model proves to be a very effective participant in classifier combination, with substantially different output to Naive Bayes (9.6% averaged complementary rate, as defined in Brill and Wu (1998)). $$$$$ In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.

We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected. $$$$$ Next, we show how this complementary behavior can be used to our advantage.
We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected. $$$$$ Again the most specific context is found, but here we check which tagger has the highest probability of being correct in this particular context.
We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected. $$$$$ In our experiments, we use a standard trigram tagger using deleted interpolation (Jelinek (1980)) and used suffix information for handling unseen words (as was done in Weischedel (1993)).

One opossibility is the example-based combiner in Brill and Wu (1998, Sec. 3.2). $$$$$ The rule Change a tag from NOUN to VERB if the previous tag is a MODAL would be applied to the sentence, resulting in the correct tagging.
One opossibility is the example-based combiner in Brill and Wu (1998, Sec. 3.2). $$$$$ We tried simple voting, using the Maximum Entropy, Transformation-Based and Trigram taggers.
One opossibility is the example-based combiner in Brill and Wu (1998, Sec. 3.2). $$$$$ Therefore it could be possible that they all end up learning the same information, just in different forms.

Related work includes learning ensembles of POS taggers, as in the work of Brill and Wu (1998), where an ensemble consisting of a unigram model, an N-gram model, a transformation-based model, and an MEMM for POS tagging achieves substantial results beyond the individual taggers. $$$$$ It is possible that the 80/20 rule of engineering is applying: a certain number of tagging instances are relatively simple to disambiguate and are therefore being successfully tagged by all approaches, while another percentage is extremely difficult to disambiguate, requiring deep linguistic knowledge, thereby causing all taggers to err.
Related work includes learning ensembles of POS taggers, as in the work of Brill and Wu (1998), where an ensemble consisting of a unigram model, an N-gram model, a transformation-based model, and an MEMM for POS tagging achieves substantial results beyond the individual taggers. $$$$$ It is a nice framework for combining multiple constraints.
Related work includes learning ensembles of POS taggers, as in the work of Brill and Wu (1998), where an ensemble consisting of a unigram model, an N-gram model, a transformation-based model, and an MEMM for POS tagging achieves substantial results beyond the individual taggers. $$$$$ In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.
Related work includes learning ensembles of POS taggers, as in the work of Brill and Wu (1998), where an ensemble consisting of a unigram model, an N-gram model, a transformation-based model, and an MEMM for POS tagging achieves substantial results beyond the individual taggers. $$$$$ Next, we check whether tagger complementarity is additive.

(Van Halteren et al, 1998) and (Brill and Wu, 1998) describe a series of successful experiments for improving the performance of part-of-speech taggers. $$$$$ In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.
(Van Halteren et al, 1998) and (Brill and Wu, 1998) describe a series of successful experiments for improving the performance of part-of-speech taggers. $$$$$ One of the most exciting recent directions in machine learning is the discovery that the combination of multiple classifiers often results in significantly better performance than what can be achieved with a single classifier.
(Van Halteren et al, 1998) and (Brill and Wu, 1998) describe a series of successful experiments for improving the performance of part-of-speech taggers. $$$$$ In transformation-based tagging (Brill (1995)), every word is first assigned an initial tag, This tag is the most likely tag for a word if the word is known and is guessed based upon properties of the word if the word is not known.

This suggests that the final accuracy number presented here could be slightly improved upon by classifier combination, it is worth noting that not only is this tagger better than any previous single tagger, but it also appears to outperform Brill and Wu (1998), the best-known combination tagger (they report an accuracy of 97.16% over the same WSJ data, but using a larger training set, which should favor them). $$$$$ As a simple example, if race appears in the corpus most frequently as a noun, it will initially be mistagged as a noun in the sentence: We can race all day long.
This suggests that the final accuracy number presented here could be slightly improved upon by classifier combination, it is worth noting that not only is this tagger better than any previous single tagger, but it also appears to outperform Brill and Wu (1998), the best-known combination tagger (they report an accuracy of 97.16% over the same WSJ data, but using a larger training set, which should favor them). $$$$$ Note that this method is capable of learning to assign a tag that none of the taggers assigned.
This suggests that the final accuracy number presented here could be slightly improved upon by classifier combination, it is worth noting that not only is this tagger better than any previous single tagger, but it also appears to outperform Brill and Wu (1998), the best-known combination tagger (they report an accuracy of 97.16% over the same WSJ data, but using a larger training set, which should favor them). $$$$$ This is then chosen as the tag for the word.
This suggests that the final accuracy number presented here could be slightly improved upon by classifier combination, it is worth noting that not only is this tagger better than any previous single tagger, but it also appears to outperform Brill and Wu (1998), the best-known combination tagger (they report an accuracy of 97.16% over the same WSJ data, but using a larger training set, which should favor them). $$$$$ In this paper, we showed that the error distributions for three popular state of the art part of speech taggers are highly complementary.

Brill and Wu (1998) call this complementary disagreement complementarity. $$$$$ In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.
Brill and Wu (1998) call this complementary disagreement complementarity. $$$$$ In this paper, we showed that the error distributions for three popular state of the art part of speech taggers are highly complementary.
Brill and Wu (1998) call this complementary disagreement complementarity. $$$$$ From these results, we can conclude that there is at least hope that improvments can be gained by combining the output of different taggers.
Brill and Wu (1998) call this complementary disagreement complementarity. $$$$$ All of these methods seem to achieve roughly comparable accuracy.

Numerous methods for combining classifiers have been proposed and utlized to improve the performance of different NLP tasks such as part of speech tagging (Brill and Wu, 1998), identifying base noun phrases (Tjong Kim Sang et al, 2000), named entity extraction (Florian et al, 2003), etc. $$$$$ For example, when the oracle can examine the output of the Maximum Entropy, Transformation-Based and Trigram taggers, it could achieve an error rate of 1.62%.
Numerous methods for combining classifiers have been proposed and utlized to improve the performance of different NLP tasks such as part of speech tagging (Brill and Wu, 1998), identifying base noun phrases (Tjong Kim Sang et al, 2000), named entity extraction (Florian et al, 2003), etc. $$$$$ In this paper, we showed that the error distributions for three popular state of the art part of speech taggers are highly complementary.

Comparison of different taggers on the WSJ corpus TBL and ME (Brill and Wu, 1998). $$$$$ The results are shown in Figure 5.
Comparison of different taggers on the WSJ corpus TBL and ME (Brill and Wu, 1998). $$$$$ This can be done using the Viterbi algorithm to find the T that maximizes: P(T)*P(WIT).
Comparison of different taggers on the WSJ corpus TBL and ME (Brill and Wu, 1998). $$$$$ All of these methods seem to achieve roughly comparable accuracy.
Comparison of different taggers on the WSJ corpus TBL and ME (Brill and Wu, 1998). $$$$$ In the future, we plan to expand our repertoire of base taggers, to determine whether performance continues to improve as we add additional systems.

Combination techniques have earlier been applied to various applications including machine translation (Jayaraman and Lavie, 2005), part-of-speech tagging (Brill and Wu, 1998) and base noun phrase identification (Sang et al., 2000). $$$$$ In addition, a tagger is much more likely to have misclassified the tag for a word in instances where there is disagreement with at least one of the other classifiers than in the case where all classifiers agree.
Combination techniques have earlier been applied to various applications including machine translation (Jayaraman and Lavie, 2005), part-of-speech tagging (Brill and Wu, 1998) and base noun phrase identification (Sang et al., 2000). $$$$$ By using contextual cues to guide tagger combination, we are able to derive a new tagger that achieves performance significantly greater than any of the individual taggers.
Combination techniques have earlier been applied to various applications including machine translation (Jayaraman and Lavie, 2005), part-of-speech tagging (Brill and Wu, 1998) and base noun phrase identification (Sang et al., 2000). $$$$$ In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.
Combination techniques have earlier been applied to various applications including machine translation (Jayaraman and Lavie, 2005), part-of-speech tagging (Brill and Wu, 1998) and base noun phrase identification (Sang et al., 2000). $$$$$ In Figure 3 we see, for instance that while the overall error rate for the Maximum Entropy tagger is 3.17%, in cases where there is disagreement between the four taggers the Maximum Entropy tagger error rate jumps to 27.1%.
