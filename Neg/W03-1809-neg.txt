Bannard et al (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not. $$$$$ In (1), the meaning seems to be that Peter put the picture somewhere and that as a consequence the picture was up.
Bannard et al (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not. $$$$$ Baldwin et al. used LSA to calculate the distributional similarity between an MWE and its head word, and demonstrate a correlation between similarity and compositionality (modelled in terms of endocentricity) by way of items with higher similarity being more compositional.
Bannard et al (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not. $$$$$ In order to test the effects of polysemy in the example sentences on inter-annotator agreement, we analysed the agreement obtained over those VPCs which have only one meaning according to WordNet (Miller et al., 1990).
Bannard et al (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not. $$$$$ The following sections describe four methods for modelling VPC compositionality, each of which is tested over the 4 individual compositionality classification tasks.

Semantically, the compositionality of MWEs is gradual, ranging from fully compositional to idiomatic (Bannard et al, 2003). $$$$$ On TASK 3, Method 2 achieved the highest classification accuracy at .600, and on TASK 4, Method 4 achieved a classification accuracy of .675.
Semantically, the compositionality of MWEs is gradual, ranging from fully compositional to idiomatic (Bannard et al, 2003). $$$$$ While there has been some work on statistical approaches to the semantics of compositional compound nominals (e.g.
Semantically, the compositionality of MWEs is gradual, ranging from fully compositional to idiomatic (Bannard et al, 2003). $$$$$ This paper describes a distributional approach to the semantics of verb-particle (e.g.
Semantically, the compositionality of MWEs is gradual, ranging from fully compositional to idiomatic (Bannard et al, 2003). $$$$$ The results for each method are given in Table 4, in which the baseline for each task is the score obtained when we assign the most frequent label to all items.

They are also extremely diverse: for example ,onthe semantic dimension alone, MWEs cover an en tire spectrum, ranging from frozen, fixed idioms to free combinations of words (Bannard et al, 2003). $$$$$ We report first on a framework for implementing and evaluating such models.
They are also extremely diverse: for example ,onthe semantic dimension alone, MWEs cover an en tire spectrum, ranging from frozen, fixed idioms to free combinations of words (Bannard et al, 2003). $$$$$ On TASK 2, the highest-performing classifier (Method 4), achieved a classification accuracy of .725.

Note that although Lin characterizes his work as detecting non-compositionality, we agree with Bannard et al (2003) that it is better thought of as tapping into productivity.plore whether the light verbs themselves show different patterns in terms of how they are used semi productively in these constructions. $$$$$ There are swings in the relative scores obtained over the majority as compared to centroid annotator data for a given task.
Note that although Lin characterizes his work as detecting non-compositionality, we agree with Bannard et al (2003) that it is better thought of as tapping into productivity.plore whether the light verbs themselves show different patterns in terms of how they are used semi productively in these constructions. $$$$$ However, corpus-based or empirical NLP has shown limited interest in the problem.
Note that although Lin characterizes his work as detecting non-compositionality, we agree with Bannard et al (2003) that it is better thought of as tapping into productivity.plore whether the light verbs themselves show different patterns in terms of how they are used semi productively in these constructions. $$$$$ This paper has described the implementation and evaluation of four corpus-based approaches to the semantics of verb-particle constructions.
Note that although Lin characterizes his work as detecting non-compositionality, we agree with Bannard et al (2003) that it is better thought of as tapping into productivity.plore whether the light verbs themselves show different patterns in terms of how they are used semi productively in these constructions. $$$$$ In order to get a reliable sense for how good these scores are, we compare them with the level of agreement across human judges.

Bannard (2005), extending work by Bannard et al (2003), instead considers the extent to which the verb and particle each contribute semantically to the VPC. $$$$$ On TASK 3, Method 2 achieved the highest classification accuracy at .600, and on TASK 4, Method 4 achieved a classification accuracy of .675.
Bannard (2005), extending work by Bannard et al (2003), instead considers the extent to which the verb and particle each contribute semantically to the VPC. $$$$$ This paper has described the implementation and evaluation of four corpus-based approaches to the semantics of verb-particle constructions.
Bannard (2005), extending work by Bannard et al (2003), instead considers the extent to which the verb and particle each contribute semantically to the VPC. $$$$$ In our implementation we replaced Lin’s collocations with our VPCs, treating the relationship between a verb and a particle as a kind of grammatical relation.
Bannard (2005), extending work by Bannard et al (2003), instead considers the extent to which the verb and particle each contribute semantically to the VPC. $$$$$ We created a set of gold-standard data, based on non-expert judgements acquired via a web-based experiment.

Semantically, the compositionality of MWEs is gradual, ranging from fully com positional to idiomatic (Bannard et al, 2003). $$$$$ We then implemented four different techniques and showed that they offer a significant improvement over a naive approach.
Semantically, the compositionality of MWEs is gradual, ranging from fully com positional to idiomatic (Bannard et al, 2003). $$$$$ In terms of relative performance, the semantic similarity based approach of Methods 3 and 4 outperform the distribution based approach of Methods 1 and 2 in terms of F-score, on 6 of the 8 sets of results reported.
Semantically, the compositionality of MWEs is gradual, ranging from fully com positional to idiomatic (Bannard et al, 2003). $$$$$ They were all native speakers of English, recruited by advertisements posted to newsgroups and mailing lists.

Bannard et al (2003), on the other hand, look at the separate contribution of the verb and particle, but assume that a binary decision on the compositionality of each is sufficient. $$$$$ This is similar to the assumption made in Schone and Jurafsky (2001), except that we make a distinction between the contribution of the different component parts.
Bannard et al (2003), on the other hand, look at the separate contribution of the verb and particle, but assume that a binary decision on the compositionality of each is sufficient. $$$$$ Semantically, they often cannot be understood through the simple composition of their independent parts.
Bannard et al (2003), on the other hand, look at the separate contribution of the verb and particle, but assume that a binary decision on the compositionality of each is sufficient. $$$$$ The unique challenge posed by MWEs for empirical NLP is precisely that they do not fall cleanly into the binary classes of compositional and non-compositional expressions, but populate a continuum between the two extremes.

 $$$$$ We therefore replicated the approach described in Lin (1998a) to build the thesaurus, using BNC data and including prepositions.
 $$$$$ The assumption that non-compositionality is requisite for the presence of a MWE in a dictionary, while interesting, is not well-founded, and hence it does not seem to us that the poor results reflect a failure of the LSA approach in measuring compositionality.
 $$$$$ We consider that simply partitioning VPC items into intransitive and transitive usages would reduce polysemy significantly. get down get 19 5 2 down 14 10 2 move off move 14 12 0 off 19 7 0 throw out throw 20 6 0 out 15 10 1 pay off pay 11 12 3 off 16 8 2 lift out lift 25 1 0 out 26 0 0 roll back roll 13 9 4 back 14 12 0 dig up dig 21 5 0 up 18 7 1 lie down lie 24 2 0 down 25 1 0 wear on wear 6 19 1 on 3 22 1 fall off fall 23 3 0 off 25 1 0 move out move 22 4 0 out 26 0 0 hand out hand 15 9 2 out 19 7 0 seek out seek 13 13 0 out 15 11 0 sell off sell 14 12 0 off 16 9 1 trail off trail 8 18 0 off 10 16 0 stay up stay 20 5 1 up 21 5 0 go down go 18 7 1 down 22 3 1 hang out hang 22 4 0 out 25 1 0 get back get 20 6 0 back 19 6 1 throw in throw 15 9 2 in 13 12 1 put off put 8 17 1 off 5 19 2 shake off shake 12 14 0 off 15 11 0 step off step 25 1 0 off 26 0 0 give off give 12 12 2 off 21 5 0 carry away carry 7 17 2 away 6 18 2 throw back throw 18 7 1 back 21 4 1 pull off pull 13 10 3 off 13 6 7 carry out carry 0 25 1 out 0 25 1 brighten up brighten 9 16 1 up 16 10 0 map out map 9 17 0 out 10 16 0 slow down slow 11 14 1 down 19 7 0 sort out sort 6 19 1 out 11 15 0 bite off bite 15 10 1 off 16 8 2 add up add 12 14 0 The experiment was conducted remotely over the Web, using the experimental software package WebExp (Corley et al., 2000).
 $$$$$ On TASK 1, three of the four classifiers achieved a classification accuracy of .575.

They do not fall cleanly into mutually exclusive classes, but populate the continuum between the two extremes (Bannard et al, 2003). $$$$$ We created a set of gold-standard data, based on non-expert judgements acquired via a web-based experiment.
They do not fall cleanly into mutually exclusive classes, but populate the continuum between the two extremes (Bannard et al, 2003). $$$$$ The order in which the forty sets of sentences were presented was randomised by the software.
They do not fall cleanly into mutually exclusive classes, but populate the continuum between the two extremes (Bannard et al, 2003). $$$$$ The underlying intuition is that identifying the degree of semantic similarity between a VPC and its component verb and/or particle will indicate whether that component part contributes independent semantics.

Possible alternatives for dealing with this issue are discussed by both Bannard et al (2003) and McCarthy et al (2003). $$$$$ We calculated the similarity between two terms by finding the cosine of the angle between their vectors.
Possible alternatives for dealing with this issue are discussed by both Bannard et al (2003) and McCarthy et al (2003). $$$$$ Participants were advised that if they felt more that one meaning was present in the set of five sentences, they should base their decision on the sense that had the greatest number of occurrences in the set.
Possible alternatives for dealing with this issue are discussed by both Bannard et al (2003) and McCarthy et al (2003). $$$$$ A (partial) Parsons-style semantic analysis of this might be as follows: Sentence (4), on the other hand requires a rather different analysis.
Possible alternatives for dealing with this issue are discussed by both Bannard et al (2003) and McCarthy et al (2003). $$$$$ In order to get a reliable sense for how good these scores are, we compare them with the level of agreement across human judges.

Bannard et al (2003) tested techniques using statistical models to infer the meaning of verb-particle constructions (VPCs), focus 2 In this lexicon, many MWEs are encoded as templates,. $$$$$ Method 3 attempts to adapt substitution to more accurately reflect non-compositionality by removing the assumption that an item formed by substitution should have the same distributional characteristics as the original item.
Bannard et al (2003) tested techniques using statistical models to infer the meaning of verb-particle constructions (VPCs), focus 2 In this lexicon, many MWEs are encoded as templates,. $$$$$ The underlying intuition is that identifying the degree of semantic similarity between a VPC and its component verb and/or particle will indicate whether that component part contributes independent semantics.
Bannard et al (2003) tested techniques using statistical models to infer the meaning of verb-particle constructions (VPCs), focus 2 In this lexicon, many MWEs are encoded as templates,. $$$$$ In order to get a reliable sense for how good these scores are, we compare them with the level of agreement across human judges.
Bannard et al (2003) tested techniques using statistical models to infer the meaning of verb-particle constructions (VPCs), focus 2 In this lexicon, many MWEs are encoded as templates,. $$$$$ We used this technique to reduce the feature space for our target words from 1000 to 100, allowing relations to be discovered between target words even if there is not direct match between their context words.

 $$$$$ We then go on to report on the implementation of some techniques for using statistical models acquired from corpus data to infer the meaning of verb-particle constructions.
 $$$$$ We observed significant correlations for a number of the regressions (notably all items vs. the centroid annotator, and monosemous items vs. 60% agreement).
 $$$$$ As a consequence of Philip’s action the intruder is down, but since there is no simplex verb to gun, we would not say that anyone gunned or was gunned The semantic analysis is consequently as follows: gun down(e1, x, y) n philip(x) n intruder(y) n down(e1, y) In the linguistic literature, the semantics of VPCs is frequently viewed in rather more complicated terms than we are suggesting here, with particles often seen as making significant construction-specific contributions in terms of aspect (e.g.
 $$$$$ On TASK 1, three of the four classifiers achieved a classification accuracy of .575.
