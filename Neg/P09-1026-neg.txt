Following (Somasundaran and Wiebe, 2009), stance, as used in this work, refers to an overall position held by a person toward an object, idea or proposition. $$$$$ In order to handle the complexities of this genre, we mine the web to learn associations that are indicative of opinion stances in debates.
Following (Somasundaran and Wiebe, 2009), stance, as used in this work, refers to an overall position held by a person toward an object, idea or proposition. $$$$$ This knowledge is exploited in an unsupervised method for classifying the side taken by a post, which also accounts for concessionary opinions.
Following (Somasundaran and Wiebe, 2009), stance, as used in this work, refers to an overall position held by a person toward an object, idea or proposition. $$$$$ However, the opinion-target pairing system only tells us that the opinion is tied to the “it.” A co-reference system would be needed to tie the “it” to “iPhone” in the first sentence.
Following (Somasundaran and Wiebe, 2009), stance, as used in this work, refers to an overall position held by a person toward an object, idea or proposition. $$$$$ This knowledge is exploited in an unsupervised method for classifying the side taken by a post, which also accounts for concessionary opinions.

Our work is also different from related work in the domain of product debates (Somasundaran and Wiebe, 2009) in terms of the methodology. $$$$$ This result suggests that not all terms that are relevant to a topic are useful for determining the debate side.
Our work is also different from related work in the domain of product debates (Somasundaran and Wiebe, 2009) in terms of the methodology. $$$$$ More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)).
Our work is also different from related work in the domain of product debates (Somasundaran and Wiebe, 2009) in terms of the methodology. $$$$$ Opinion-target pairing.
Our work is also different from related work in the domain of product debates (Somasundaran and Wiebe, 2009) in terms of the methodology. $$$$$ However, they do not endorse this rival opinion.

Some previous research looked at the related field of opinion mining, also on political discussion, as in (AbuJbara et al, 2012), (Anand et al., 2011) or (Somasundaran and Wiebe, 2009). $$$$$ We would also like to thank Vladislav D. Veksler for help with the MSR engine, and the anonymous reviewers for their helpful comments.
Some previous research looked at the related field of opinion mining, also on political discussion, as in (AbuJbara et al, 2012), (Anand et al., 2011) or (Somasundaran and Wiebe, 2009). $$$$$ Thus, for this system, the step of opinion-target pairing only finds all topic+1 , topic= , topic+2 , topic2 instances in the post (where, for example, an instance of topic+1 is a positive opinion whose target is explicitly topic1).
Some previous research looked at the related field of opinion mining, also on political discussion, as in (AbuJbara et al, 2012), (Anand et al., 2011) or (Somasundaran and Wiebe, 2009). $$$$$ Our results show that our method is substantially better than challenging baseline methods.

As we aim at performing a finegrained analysis, approaches merely classifying pro or contra (like those of (Walker et al, 2012) or (Somasundaran and Wiebe, 2009) are not applicable in our case. $$$$$ We do not model inter-personal exchanges; instead, we model factors that influence stance taking.
As we aim at performing a finegrained analysis, approaches merely classifying pro or contra (like those of (Walker et al, 2012) or (Somasundaran and Wiebe, 2009) are not applicable in our case. $$$$$ We combine this knowledge with discourse information, and formulate the debate side classification task as an Integer Linear Programming problem.
As we aim at performing a finegrained analysis, approaches merely classifying pro or contra (like those of (Walker et al, 2012) or (Somasundaran and Wiebe, 2009) are not applicable in our case. $$$$$ However, they do not find distinguishing factors associated with a preference for a stance.
As we aim at performing a finegrained analysis, approaches merely classifying pro or contra (like those of (Walker et al, 2012) or (Somasundaran and Wiebe, 2009) are not applicable in our case. $$$$$ On http://www.convinceme.net, the html page for each debate contains side information for each post (side1 is blue in color and side2 is green).

Somasundaran and Wiebe (2009) propose an unsupervised method for classifying the stance of each contribution to an on line debate concerning the merits of competing products. $$$$$ A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products.
Somasundaran and Wiebe (2009) propose an unsupervised method for classifying the stance of each contribution to an on line debate concerning the merits of competing products. $$$$$ This knowledge is exploited in an unsupervised method for classifying the side taken by a post, which also accounts for concessionary opinions.
Somasundaran and Wiebe (2009) propose an unsupervised method for classifying the stance of each contribution to an on line debate concerning the merits of competing products. $$$$$ But even an aspect the topics share may distinguish between them, because people who are positive toward one topic may value that aspect more.

Somasundaran and Wiebe (2009) presents an unsupervised opinion analysis method for debate-side classification. $$$$$ We would also like to thank Vladislav D. Veksler for help with the MSR engine, and the anonymous reviewers for their helpful comments.
Somasundaran and Wiebe (2009) presents an unsupervised opinion analysis method for debate-side classification. $$$$$ We would also like to thank Vladislav D. Veksler for help with the MSR engine, and the anonymous reviewers for their helpful comments.
Somasundaran and Wiebe (2009) presents an unsupervised opinion analysis method for debate-side classification. $$$$$ In this example, the participant mentions the difference in the prices in the first sentence.
Somasundaran and Wiebe (2009) presents an unsupervised opinion analysis method for debate-side classification. $$$$$ Some aspects are unique to one side/topic or the other, e.g., “3g” in Example 1 and “inline spell check” in Example 2.

There have been some related works that focus on discovering the general topics and ideological perspectives in online discussions (Ahmed and Xing, 2010), placing users in support/oppose camps (Agarwal et al, 2003), and classifying user stances (Somasundaran and Wiebe, 2009). $$$$$ Some aspects are unique to one side/topic or the other, e.g., “3g” in Example 1 and “inline spell check” in Example 2.
There have been some related works that focus on discovering the general topics and ideological perspectives in online discussions (Ahmed and Xing, 2010), placing users in support/oppose camps (Agarwal et al, 2003), and classifying user stances (Somasundaran and Wiebe, 2009). $$$$$ However, the opinion-target pairing system only tells us that the opinion is tied to the “it.” A co-reference system would be needed to tie the “it” to “iPhone” in the first sentence.
There have been some related works that focus on discovering the general topics and ideological perspectives in online discussions (Ahmed and Xing, 2010), placing users in support/oppose camps (Agarwal et al, 2003), and classifying user stances (Somasundaran and Wiebe, 2009). $$$$$ The OpTopic has low recall.
There have been some related works that focus on discovering the general topics and ideological perspectives in online discussions (Ahmed and Xing, 2010), placing users in support/oppose camps (Agarwal et al, 2003), and classifying user stances (Somasundaran and Wiebe, 2009). $$$$$ When the two topics do share an aspect (e.g., a keyboard in the iPhone vs. Blackberry debate), the writer may perceive it to be more positive for one than the other.

 $$$$$ As reported in the previous section, the OpPr system outperforms both the OpTopic and the OpPMI systems.
 $$$$$ A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products.
 $$$$$ In order to handle the complexities of this genre, we mine the web to learn associations that are indicative of opinion stances in debates.
 $$$$$ Participants directly express their opinions, such as “The iPhone is cool,” but, more often, they mention associated aspects.

 $$$$$ Note that in 3 out of 4 of the debates, the full system is able to make a guess for all of the posts (hence, the metrics all have the same values).
 $$$$$ Complicating the picture further, participants may concede positive aspects of the opposing issue or topic, without coming out in favor of it, and they may concede negative aspects of the issue or topic they support.
 $$$$$ This paper addresses challenges faced by opinion analysis in the debate genre.
 $$$$$ We use the API provided by the Measures of Semantic Relatedness (MSR)4 engine for this purpose.

Sentence 14 is a negative pragmatic opinion (Somasundaran and Wiebe, 2009) which can only be detected with the help of external world knowledge. $$$$$ Note that in 3 out of 4 of the debates, the full system is able to make a guess for all of the posts (hence, the metrics all have the same values).
Sentence 14 is a negative pragmatic opinion (Somasundaran and Wiebe, 2009) which can only be detected with the help of external world knowledge. $$$$$ We would also like to thank Vladislav D. Veksler for help with the MSR engine, and the anonymous reviewers for their helpful comments.
Sentence 14 is a negative pragmatic opinion (Somasundaran and Wiebe, 2009) which can only be detected with the help of external world knowledge. $$$$$ This research was supported in part by the Department of Homeland Security under grant N000140710152.
Sentence 14 is a negative pragmatic opinion (Somasundaran and Wiebe, 2009) which can only be detected with the help of external world knowledge. $$$$$ The OpPr system, on the other hand, is able to map it to a debate side.

Somasundaran and Wiebe (2009) used unsupervised methods to identify stances in online debates. $$$$$ In our method, factors that influence the choice of a debate side are learned by mining a web corpus for opinions.
Somasundaran and Wiebe (2009) used unsupervised methods to identify stances in online debates. $$$$$ The participant concedes that the iPhone appeals to young consumers, but this positive opinion is opposite to his overall stance.
Somasundaran and Wiebe (2009) used unsupervised methods to identify stances in online debates. $$$$$ However, they do not endorse this rival opinion.
Somasundaran and Wiebe (2009) used unsupervised methods to identify stances in online debates. $$$$$ This knowledge is exploited in an unsupervised method for classifying the side taken by a post, which also accounts for concessionary opinions.
