They used a combination of a minimum word frequency threshold and Categorical Proportional Difference as a feature selection method and achieved the highest accuracy of 83.33% on a hand labeled test dataset. (Agarwal et al, 2011) performed three class (positive, negative and neutral) classification of tweets. $$$$$ Table 5 compares the performance of three models: unigram model, feature based model using only 100 Senti-features, and the tree kernel model.
They used a combination of a minimum word frequency threshold and Categorical Proportional Difference as a feature selection method and achieved the highest accuracy of 83.33% on a hand labeled test dataset. (Agarwal et al, 2011) performed three class (positive, negative and neutral) classification of tweets. $$$$$ In Table 7 we present a list of unigrams that consistently appear as top 15 unigram features across all folds.
They used a combination of a minimum word frequency threshold and Categorical Proportional Difference as a feature selection method and achieved the highest accuracy of 83.33% on a hand labeled test dataset. (Agarwal et al, 2011) performed three class (positive, negative and neutral) classification of tweets. $$$$$ Target: Users of Twitter use the “@” symbol to refer to other users on the microblog.

We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ Features that combine prior polarity of words with their parts-of-speech tags are most important for both the classification tasks.
We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ We investigated two kinds of models: tree kernel and feature based models and demonstrate that both these models outperform the unigram baseline.
We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ We calculate these features for the whole tweet and for the last one-third of the tweet.
We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ For example, we add the subtree (EW (JJ great POS)) for the word great.

We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ Our feature based model that uses only 100 features achieves similar accuracy as the unigram model that uses over 10,000 features.
We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ For example, given the tree (EW (JJ) (great) (POS)), the PT kernel will use (EW (JJ) (great) (POS)), (EW (great) (POS)), (EW (JJ) (POS)), (EW (JJ) (great)), (EW (JJ)), (EW (great)), (EW (POS)), (EW), (JJ), (great), and (POS).
We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ Vovsha is funded by NSF grant IIS-0916200.
We use the emoticons list provided by (Agarwal et al, 2011) in their research. $$$$$ We presented a comprehensive set of experiments for both these tasks on manually annotated data that is a random sample of stream of tweets.

Other resources for sentiment detection include the Dictionary of Affect in Language (DAL) to score the prior polarity of words, as in Agarwal et al (2011) on social media data. $$$$$ For our feature-based approach, we do feature analysis which reveals that the most important features are those that combine the prior polarity of words and their parts-of-speech tags.
Other resources for sentiment detection include the Dictionary of Affect in Language (DAL) to score the prior polarity of words, as in Agarwal et al (2011) on social media data. $$$$$ For our feature-based approach, we do feature analysis which reveals that the most important features are those that combine the prior polarity of words and their parts-of-speech tags.
Other resources for sentiment detection include the Dictionary of Affect in Language (DAL) to score the prior polarity of words, as in Agarwal et al (2011) on social media data. $$$$$ This is a binary classification task with two classes of sentiment polarity: positive and negative.
Other resources for sentiment detection include the Dictionary of Affect in Language (DAL) to score the prior polarity of words, as in Agarwal et al (2011) on social media data. $$$$$ In Table 3 we see that 38.3% of the tokens are stop words, 30.1% of the tokens are found in WordNet and 1.2% tokens are negation words.

Johansson and Moschitti (2010) and Agarwal et al (2011) process sentences and tweets respectively. $$$$$ We examine sentiment analysis on Twitter data.
Johansson and Moschitti (2010) and Agarwal et al (2011) process sentences and tweets respectively. $$$$$ POS refers to features that capture statistics about parts-of-speech of words and Other refers to all other types of features.
Johansson and Moschitti (2010) and Agarwal et al (2011) process sentences and tweets respectively. $$$$$ In future work, we will explore even richer linguistic analysis, for example, parsing, semantic analysis and topic modeling.
Johansson and Moschitti (2010) and Agarwal et al (2011) process sentences and tweets respectively. $$$$$ We use previously proposed state-of-the-art unigram model as our baseline and report an overall gain of over 4% for two classification tasks: a binary, positive versus negative and a 3-way positive versus negative versus neutral.

In (Agarwal et al, 2011) a study was conducted on a reduced corpus of tweets labelled manually. $$$$$ We record the occurrence of three standard twitter tags: emoticons, URLs and targets.
In (Agarwal et al, 2011) a study was conducted on a reduced corpus of tweets labelled manually. $$$$$ We use stratified sampling to get a balanced data-set of 5127 tweets (1709 tweets each from classes positive, negative and neutral).
In (Agarwal et al, 2011) a study was conducted on a reduced corpus of tweets labelled manually. $$$$$ In total we get 100 additional features.
In (Agarwal et al, 2011) a study was conducted on a reduced corpus of tweets labelled manually. $$$$$ Table 9 presents classifier accuracy and F1measure when features are added incrementally.
