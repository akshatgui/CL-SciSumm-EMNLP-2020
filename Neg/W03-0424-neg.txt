We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ Mixedcase applies to words with mixed lower- and uppercase (e.g.
We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.
We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ Some studies found that gazetteers did not improve performance (e.g.
We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ The classes are used to define unigram, bigram and trigram contextual predicates over the window.

Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ This feature enables us to know something about the likely NE tag of the next word before reaching it.
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ Maximum entropy models are an effective way of incorporating diverse and overlapping features.
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.

As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ We have experimented with removing the other contextual predicates but each time performance was reduced, except for the next-next unigram tag feature which was switched off for all final experiments.
As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ Our maximum entropy tagger employs Gaussian smoothing which allows a large number of sparse, but informative, features to be used without overfitting.

The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ For the German NER we removed the lowercase more frequent than uppercase feature.
The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ Our system incorporates only English and Dutch first name and last name gazetteers as shown in Table 6.

These are based on those found in (Curran and Clark, 2003). $$$$$ The results for the Dutch test data are given in Table 5.
These are based on those found in (Curran and Clark, 2003). $$$$$ Malouf (2002), Burger et al. (2002)) reported results significantly lower than the best system (Carreras et al., 2002).
These are based on those found in (Curran and Clark, 2003). $$$$$ Maximum entropy models are an effective way of incorporating diverse and overlapping features.
These are based on those found in (Curran and Clark, 2003). $$$$$ The tag O indicates words outside of a named entity.

The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ Incorporating a diverse set of overlapping features in a HMM-based tagger is difficult and complicates the smoothing typically used for such taggers.
The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ Entity Recognition systems need to integrate a wide variety of information for optimal performance.
The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ The next set of contextual predicates encode extra information about NE tags in the current context.

The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain. $$$$$ Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes.
The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain. $$$$$ Incorporating a diverse set of overlapping features in a HMM-based tagger is difficult and complicates the smoothing typically used for such taggers.

Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ The papers from the CoNLL-2002 shared task which used such methods (e.g.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ This paper demonstrates that a maximum entropy tagger can effectively encode such information and identify named entities with very high accuracy.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ The tag O indicates words outside of a named entity.

A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ The next set of contextual predicates encode extra information about NE tags in the current context.
A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ The probability of a tag sequence y1 ... yn given a sentence w1 ... wn is approximated as follows: where xi is the context for word wi.
A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ We report reasonable precision and recall (84.9 F-score) for the CoNLL-2003 English test data, and an F-score of 68.4 for the CoNLL-2003 German test data.

 $$$$$ The length predicates encode the number of characters in the word from 1 to 15, with a single predicate for lengths greater than 15.
 $$$$$ The tagger uses beam search to find the most probable sequence given the sentence.
 $$$$$ Clearly the additional features have a significant impact on both precision and recall scores across all entities.
 $$$$$ Using a wider context window than 2 words may improve performance; a reranking phase using global features may also improve performance (Collins, 2002).

Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ We used three data sets: the English and German data for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003) and the Dutch data for the CoNLL2002 shared task (Tjong Kim Sang, 2002).
Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ We used three data sets: the English and German data for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003) and the Dutch data for the CoNLL2002 shared task (Tjong Kim Sang, 2002).
Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ The performance of the final system drops by 1.97% if these features are removed.

Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ We demonstrate this to be the case by improving on the best Dutch results from CoNLL-2002 using a maximum entropy (ME) tagger.
Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ The performance of the final system drops by 1.97% if these features are removed.
Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ Our system does not currently exploit the chunk tags.
Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ These features have been shown to be useful in other NER systems.

We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ This memory is cleared at the beginning of each document.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ Our maximum entropy tagger employs Gaussian smoothing which allows a large number of sparse, but informative, features to be used without overfitting.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ Entity Recognition systems need to integrate a wide variety of information for optimal performance.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ There are 4 types of entities to be recognised: persons, locations, organisations, and miscellaneous entities not belonging to the other three classes.

We use different strategies for the identification of the two classes of entities $$$$$ The tagger uses models of the form: where y is the tag, x is the context and the fi(x, y) are the features with associated weights λi.
We use different strategies for the identification of the two classes of entities $$$$$ Clearly the additional features have a significant impact on both precision and recall scores across all entities.
We use different strategies for the identification of the two classes of entities $$$$$ Some studies found that gazetteers did not improve performance (e.g.
We use different strategies for the identification of the two classes of entities $$$$$ The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.

The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.
The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ Malouf (2002), Burger et al. (2002)) reported results significantly lower than the best system (Carreras et al., 2002).
The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ The baseline development results for English using the supertagger features only are given in Table 3.
The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.

We use different strategies for the identification of the two classes of entities $$$$$ Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.
We use different strategies for the identification of the two classes of entities $$$$$ The baseline development results for English using the supertagger features only are given in Table 3.
We use different strategies for the identification of the two classes of entities $$$$$ The probability of a tag sequence y1 ... yn given a sentence w1 ... wn is approximated as follows: where xi is the context for word wi.

For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.
For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ The tagger uses a Gaussian prior over the weights (Chen et al., 1999) which allows a large number of rare, but informative, features to be used without overfitting.

Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ Each word in the data sets is annotated with a named entity tag plus POS tag, and the words in the German and English data also have a chunk tag.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ In contrast, a ME tagger can easily deal with diverse, overlapping features.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ Our NER system demonstrates that using a large variety of features produces good performance.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ Some studies found that gazetteers did not improve performance (e.g.

By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.
By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ The features are binary valued functions which pair a tag with various elements of the context; for example: � Generalised Iterative Scaling (GIS) is used to estimate the values of the weights.
By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ We report reasonable precision and recall (84.9 F-score) for the CoNLL-2003 English test data, and an F-score of 68.4 for the CoNLL-2003 German test data.
By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ Maximum entropy models are an effective way of incorporating diverse and overlapping features.

We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.
We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ The 2002 data uses the IOB-2 format in which a B-XXX tag indicates the first word of an entity of type XXX and I-XXX is used for subsequent words in an entity of type XXX.
We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ This paper demonstrates that a maximum entropy tagger can effectively encode such information and identify named entities with very high accuracy.
