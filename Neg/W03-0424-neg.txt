We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ Incorporating a diverse set of overlapping features in a HMM-based tagger is difficult and complicates the smoothing typically used for such taggers.
We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.
We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters. $$$$$ The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.

Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ The sizes of our gazetteers are given in Table 6.
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ The classes are used to define unigram, bigram and trigram contextual predicates over the window.
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ Apart from this change, the system was identical.
Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004). $$$$$ Maximum entropy models are an effective way of incorporating diverse and overlapping features.

As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ However, Zhou and Su (2002) have reported state of the art results on the MUC-6 and MUC-7 data using a HMM-based tagger.
As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ The features are binary valued functions which pair a tag with various elements of the context; for example: ï¿½ Generalised Iterative Scaling (GIS) is used to estimate the values of the weights.
As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER. $$$$$ The 2003 data uses a variant of IOB-2, IOB-1, in which I-XXX is used for all words in an entity, including the first word, unless the first word separates contiguous entities of the same type, in which case B-XXX is used.

The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ The 2003 data uses a variant of IOB-2, IOB-1, in which I-XXX is used for all words in an entity, including the first word, unless the first word separates contiguous entities of the same type, in which case B-XXX is used.
The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ Our system does not currently exploit the chunk tags.
The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. $$$$$ Our NER system demonstrates that using a large variety of features produces good performance.

These are based on those found in (Curran and Clark, 2003). $$$$$ Our system does not currently exploit the chunk tags.
These are based on those found in (Curran and Clark, 2003). $$$$$ The 2003 data uses a variant of IOB-2, IOB-1, in which I-XXX is used for all words in an entity, including the first word, unless the first word separates contiguous entities of the same type, in which case B-XXX is used.
These are based on those found in (Curran and Clark, 2003). $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.

The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ We used three data sets: the English and German data for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003) and the Dutch data for the CoNLL2002 shared task (Tjong Kim Sang, 2002).
The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ One feature we have adapted encodes whether the current word is more frequently seen lowercase than uppercase in a large external corpus.
The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based. $$$$$ Entity Recognition systems need to integrate a wide variety of information for optimal performance.

The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain. $$$$$ Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes.
The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain. $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.
The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain. $$$$$ Each word in the data sets is annotated with a named entity tag plus POS tag, and the words in the German and English data also have a chunk tag.

Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ Our maximum entropy tagger employs Gaussian smoothing which allows a large number of sparse, but informative, features to be used without overfitting.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document. $$$$$ The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.

A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ These features can be defined and extracted in a language independent manner, as our results for German, Dutch and English show.
A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ Our NER system demonstrates that using a large variety of features produces good performance.
A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)). $$$$$ The full system results for the English development data are given in Table 7.

 $$$$$ Entity Recognition systems need to integrate a wide variety of information for optimal performance.
 $$$$$ Each word in the data sets is annotated with a named entity tag plus POS tag, and the words in the German and English data also have a chunk tag.
 $$$$$ The tagger uses beam search to find the most probable sequence given the sentence.
 $$$$$ Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes.

Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.
Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ The tag O indicates words outside of a named entity.
Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7. $$$$$ The final results for the English test data are given in Table 7.

Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ We have found that the word type features are particularly useful, as is the memory feature.
Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.

We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ Entity Recognition systems need to integrate a wide variety of information for optimal performance.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ Our NER system demonstrates that using a large variety of features produces good performance.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ Clearly the additional features have a significant impact on both precision and recall scores across all entities.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.

We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non domain-specific ones we use the C&C named entity tagger (Curran and Clark, 2003) trained on the MUC-7 data set. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non domain-specific ones we use the C&C named entity tagger (Curran and Clark, 2003) trained on the MUC-7 data set. $$$$$ Tsukamoto et al. (2002)) encode the most probable tag for the next words in the window.
We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non domain-specific ones we use the C&C named entity tagger (Curran and Clark, 2003) trained on the MUC-7 data set. $$$$$ This paper demonstrates that a maximum entropy tagger can effectively encode such information and identify named entities with very high accuracy.
We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non domain-specific ones we use the C&C named entity tagger (Curran and Clark, 2003) trained on the MUC-7 data set. $$$$$ The additional orthographic features have proved useful in other systems, for example Carreras et al. (2002), Borthwick (1999) and Zhou and Su (2002).

The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ One feature we have adapted encodes whether the current word is more frequently seen lowercase than uppercase in a large external corpus.
The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ We would like to thank Jochen Leidner for help collecting the Gazetteers.
The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ Table 2 lists the extra features used in our final system.
The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based. $$$$$ These features are important for tagging unknown and rare words.

We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non-domain-specific ones we use the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the MUC7 data set. $$$$$ This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non-domain-specific ones we use the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the MUC7 data set. $$$$$ Titlecase applies to words with an initial uppercase letter followed by all lowercase (e.g.
We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non-domain-specific ones we use the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the MUC7 data set. $$$$$ The performance of the final system drops by 1.97% if these features are removed.

For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ The tagger uses beam search to find the most probable sequence given the sentence.
For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ The full system results for the English development data are given in Table 7.
For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ However, Zhou and Su (2002) have reported state of the art results on the MUC-6 and MUC-7 data using a HMM-based tagger.
For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics. $$$$$ Entity Recognition systems need to integrate a wide variety of information for optimal performance.

Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ The full system results for the English development data are given in Table 7.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ The tagger uses features which can be obtained for a variety of languages and works effectively not only for English, but also for other languages such as German and Dutch.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ We have also defined additional composite features which are a combination of atomic features; for example, a feature which is active for mid-sentence titlecase words seen more frequently as lowercase than uppercase in a large external corpus.
Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document. $$$$$ Each word in the data sets is annotated with a named entity tag plus POS tag, and the words in the German and English data also have a chunk tag.

By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ These features can be defined and extracted in a language independent manner, as our results for German, Dutch and English show.
By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ The full system results for the English development data are given in Table 7.
By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ The performance of the system if the gazetteer features are removed is given in Table 4.
By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER. $$$$$ This involves mapping characters to classes and merging adjacent characters of the same type.

We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ Entity Recognition systems need to integrate a wide variety of information for optimal performance.
We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ Zhou and Su (2002) used a wide variety of features, which suggests that the relatively poor performance of the taggers used in CoNLL-2002 was largely due to the feature sets used rather than the machine learning method.
We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.
We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus. $$$$$ Most systems use gazetteers to encode information about personal and organisation names, locations and trigger words.
