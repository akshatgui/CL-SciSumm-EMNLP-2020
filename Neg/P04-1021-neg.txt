(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ Most foreign names are transliterated into Chinese, Japanese or Korean with approximate phonetic equivalents.
(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ In Table 7, the word error rates for both E2C and C2E are reported which imply potential error reduction by secondary knowledge source.
(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ The transliteration is usually achieved through intermediate phonemic mapping.
(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ This contributes to the success of E2C but presents a great challenge to C2E backtransliteration.

 $$$$$ The transliteration is usually achieved through intermediate phonemic mapping.
 $$$$$ In the case of E2C transliteration, we form a learning vector of 6 attributes by combining 2 left and 2 right letters around the letter of focus ek and 1 previous Chinese unit ck−1 .
 $$$$$ For instance, French has different phonic rules from those of English.

Li et al (2004) presented a framework allowing direct orthographical mapping of transliteration units be tween English and Chinese, and an extended model is presented in Ekbal et al (2006). $$$$$ Three factors could have contributed: 1) English transliteration unit size ranges from 1 letter to 7 letters.
Li et al (2004) presented a framework allowing direct orthographical mapping of transliteration units be tween English and Chinese, and an extended model is presented in Ekbal et al (2006). $$$$$ The TM under the DOM framework greatly reduces system development effort and provides a quantum leap in improvement in transliteration accuracy over that of other state-of-the-art machine learning algorithms.

One Chinese Pinyin string can correspond to several Chinese characters (Li et al, 2004). $$$$$ Transliterating English names into Chinese is not straightforward.
One Chinese Pinyin string can correspond to several Chinese characters (Li et al, 2004). $$$$$ Furthermore, /s-/ and /-th/ correspond to overlapping characters as well, as shown next.
One Chinese Pinyin string can correspond to several Chinese characters (Li et al, 2004). $$$$$ The database includes a collection of 37,694 unique English entries and their official Chinese transliteration.

For this reason, it has been reported that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al, 2004). $$$$$ In the close test, all data entries are used for training and testing.
For this reason, it has been reported that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al, 2004). $$$$$ This contributes to the success of E2C but presents a great challenge to C2E backtransliteration.
For this reason, it has been reported that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al, 2004). $$$$$ It generates probabilistic orthographic transformation rules using a data driven approach.

We performed alignment between E G and E P and between E P and C P in a similar manner presented in Li et al (2004). $$$$$ Here we implement ID3 (Quinlan, 1993) algorithm to construct the decision tree which contains questions and return values at terminal nodes.
We performed alignment between E G and E P and between E P and C P in a similar manner presented in Li et al (2004). $$$$$ Under the DOM framework, here is the first attempt to apply decision tree in E2C and C2E transliteration.
We performed alignment between E G and E P and between E P and C P in a similar manner presented in Li et al (2004). $$$$$ For writing foreign names in Chinese, transliteration always follows the original romanization.

 $$$$$ The transliteration is usually achieved through intermediate phonemic mapping.
 $$$$$ In this paper, the n-gram TM model serves as the sole knowledge source for transliteration.
 $$$$$ This paper is organized as follows: In section 2, we present the transliteration problems.

We used the same test set used in Li et al (2004) for our testing. $$$$$ Although we can arrive at an obvious segmentation /s-mi-th/, there are three Chinese characters for each of /s-/, /-mi-/ and /-th/.
We used the same test set used in Li et al (2004) for our testing. $$$$$ In this experiment, we conduct both open and closed tests for TM and NCM models under DOM paradigm.
We used the same test set used in Li et al (2004) for our testing. $$$$$ As the proposed framework allows direct orthographical mapping, it can also be easily extended to handle such name translation.
We used the same test set used in Li et al (2004) for our testing. $$$$$ It is shown that TM consistently gives lower perplexity than NCM in open and closed tests.

(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ This paper presents a new framework that allows direct orthographical mapping (DOM) between two different languages, through a joint source-channel model, also transliteration model (TM). the TM model, we automate the orthographic alignment process to derive the aligned transliteration units from bilingual dictionary.
(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ Furthermore, the bilingual aligning process is integrated into the decoding process in n-gram TM, which allows us to achieve a joint optimization of alignment and transliteration automatically.
(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ In order words, on average, for each English unit, we have 1.53 = 5,640/3,683 Chinese correspondences.
(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ The problems of English-Chinese transliteration have been studied extensively in the paradigm of noisy channel model (NCM).

Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ As the proposed framework allows direct orthographical mapping, it can also be easily extended to handle such name translation.
Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ The problems of English-Chinese transliteration have been studied extensively in the paradigm of noisy channel model (NCM).
Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ In this paper we discuss the limitations of such an approach and address its problems by firstly proposing a paradigm that allows direct orthographic mapping (DOM), secondly further proposing a joint source-channel model as a realization of DOM.
Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ Furthermore, /s-/ and /-th/ correspond to overlapping characters as well, as shown next.

To compare Li et al (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al (2004). $$$$$ Similar to n-gram TM, for unseen names in open test, ID3 has backoff smoothing, which lies on the default case which returns the most probable value as its best guess for a partial tree path according to the learning set.
To compare Li et al (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al (2004). $$$$$ Therefore, any foreign name will have only one Pinyin (romanization of Chinese) and thus in Chinese characters.
To compare Li et al (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al (2004). $$$$$ Unlike the noisy-channel model, the joint source-channel model does not try to capture how source names can be mapped to target names, but rather how source and target names can be generated simultaneously.
To compare Li et al (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al (2004). $$$$$ Two other machine learning techniques, NCM and ID3 (Quinlan, 1993) decision tree, also are implemented under DOM as reference to compare with the proposed n-gram TM.

Since the training data used in Li et al (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. $$$$$ To address the issues in transliteration, we propose a direct orthographic mapping (DOM) framework through a joint source-channel model by fully exploring orthographic contextual information, aiming at alleviating the imprecision introduced by the multiple-step phoneme-based approach.
Since the training data used in Li et al (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. $$$$$ For example, /Lafontant/ is transliterated into 拉丰唐(La-FengTang) while /Constant/ becomes 康斯坦特(KangSi-Tan-Te) , where syllable /-tant/ in the two names are transliterated differently depending on the names’ language of origin.
Since the training data used in Li et al (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. $$$$$ One may need to prepare multiple language-dependent grapheme-to-phoneme (G2P) conversion systems accordingly, and that is not easy to achieve (The Onomastica Consortium, 1995).
Since the training data used in Li et al (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. $$$$$ As a result, n-gram TM and ID3 do not generate Chinese Pinyin as intermediate results.

The grapheme-based approach, also known as direct orthographical mapping (Li et al, 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. $$$$$ Most foreign names are transliterated into Chinese, Japanese or Korean with approximate phonetic equivalents.
The grapheme-based approach, also known as direct orthographical mapping (Li et al, 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. $$$$$ The transliteration is usually achieved through intermediate phonemic mapping.
The grapheme-based approach, also known as direct orthographical mapping (Li et al, 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. $$$$$ However, the phoneme-based approaches are limited by two major constraints, which could compromise transliterating precision, especially in English-Chinese transliteration: 1) Latin-alphabet foreign names are of different origins.

Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ For a given English name E as the observed channel output, one seeks a posteriori the most likely Chinese transliteration C that maximizes P(C|E).
Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ For instance, French has different phonic rules from those of English.
Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ The modeling framework is validated through several experiments for English-Chinese language pair.
Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ It would be interesting to relate n-gram TM to other related framework.

The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions. $$$$$ In other words, we estimate a joint probability model that can be easily marginalized in order to yield conditional probability models for both transliteration and back-transliteration.
The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions. $$$$$ In machine transliteration, the noisy channel model (NCM), based on a phoneme-based approach, has recently received considerable attention (Meng et al. 2001; Jung et al, 2000; Virga & Khudanpur, 2003; Knight & Graehl, 1998).
The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions. $$$$$ This paper presents a new framework that allows direct orthographical mapping (DOM) between two different languages, through a joint source-channel model, also transliteration model (TM). the TM model, we automate the orthographic alignment process to derive the aligned transliteration units from bilingual dictionary.

Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ surprise, Chinese names have much lower perplexity than English names thanks to fewer Chinese units.
Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ Unlike other related work where pre-alignment is needed, the new framework greatly reduces the development efforts of machine transliteration systems.
Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ It is noted that place and company names are sometimes translated in combination of transliteration and meanings, for example, /Victoria-Fall/ becomes ff � f1 R 4 �ti (Pinyin:Wei Duo Li Ya Pu Bu).
Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ In machine transliteration, the noisy channel model (NCM), based on a phoneme-based approach, has recently received considerable attention (Meng et al. 2001; Jung et al, 2000; Virga & Khudanpur, 2003; Knight & Graehl, 1998).

Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ The n-gram TM and ID3 under direct orthographic mapping (DOM) paradigm simplify the process and reduce the chances of conversion errors.
Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ Oftentimes, the number of letters is different from the number of Chinese A bilingual dictionary contains entries mapping English names to their respective Chinese transliterations.
Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ Furthermore, /s-/ and /-th/ correspond to overlapping characters as well, as shown next.
Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ A human translator will use transliteration rules between English syllable sequence and Chinese character sequence to obtain the best mapping 史密-斯, as indicated in italic in the table above.

Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin (Li et al, 2004). $$$$$ To better understand the task, let’s compare the complexity of the two languages presented in the bilingual dictionary.
Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin (Li et al, 2004). $$$$$ In section 3, a joint source-channel model is formulated.
Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin (Li et al, 2004). $$$$$ By skipping the intermediate phonemic interpretation, the transliteration error rate is reduced significantly.
Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin (Li et al, 2004). $$$$$ Based on the transliteration formulation above, a transliteration model can be built with transliteration unit’s ngram statistics.

So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ The TM under the DOM framework greatly reduces system development effort and provides a quantum leap in improvement in transliteration accuracy over that of other state-of-the-art machine learning algorithms.
So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ Two other machine learning techniques, NCM and ID3 (Quinlan, 1993) decision tree, also are implemented under DOM as reference to compare with the proposed n-gram TM.
So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ For E2C conversion, re-writing eqn (1) and eqn (6) , we have The formulation of eqn.
So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ The modeling framework is validated through several experiments for English-Chinese language pair.

Direct orthographic mapping (e.g. Li et al, 2004), making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly. $$$$$ The cross-entropy Hp (W) of a model on data W is defined as number of aligned transliteration pair tokens in the data W. The perplexity PPp (W) of a model is the reciprocal of the average probability assigned by the model to each aligned pair in the test set W We have the perplexity reported in Table 2 on the aligned bilingual dictionary, a database of 119,364 aligned tokens.
Direct orthographic mapping (e.g. Li et al, 2004), making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly. $$$$$ For writing foreign names in Chinese, transliteration always follows the original romanization.
Direct orthographic mapping (e.g. Li et al, 2004), making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly. $$$$$ The phoneme-based approach requires derivation of proper phonemic representation for names of different origins.
Direct orthographic mapping (e.g. Li et al, 2004), making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly. $$$$$ This contributes to the success of E2C but presents a great challenge to C2E backtransliteration.
