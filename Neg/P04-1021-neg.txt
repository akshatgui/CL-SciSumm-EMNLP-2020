(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ For a given English name E as the observed channel output, one seeks a posteriori the most likely Chinese transliteration C that maximizes P(C|E).
(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ By skipping the intermediate phonemic interpretation, the transliteration error rate is reduced significantly.
(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ The modeling framework is validated through several experiments for English-Chinese language pair.
(Li et al 2004) introduced the joint transliteration model whose variant augmented with adaptive re-ranking we used in our experiments. $$$$$ It generates probabilistic orthographic transformation rules using a data driven approach.

 $$$$$ In the open test, one subset is withheld for testing while the remaining 12 subsets are used as the training materials.
 $$$$$ The transliteration is usually achieved through intermediate phonemic mapping.
 $$$$$ Then, the E2C transliteration can be formulated as and similarly the C2E back-transliteration as An n-gram transliteration model is defined as the conditional probability, or transliteration probability, of a transliteration pair < e, c >k depending on its immediate n predecessor pairs: which provides an alternative to the phonemebased approach for resolving eqn.
 $$$$$ This contributes to the success of E2C but presents a great challenge to C2E backtransliteration.

Li et al (2004) presented a framework allowing direct orthographical mapping of transliteration units be tween English and Chinese, and an extended model is presented in Ekbal et al (2006). $$$$$ As the proposed framework allows direct orthographical mapping, it can also be easily extended to handle such name translation.
Li et al (2004) presented a framework allowing direct orthographical mapping of transliteration units be tween English and Chinese, and an extended model is presented in Ekbal et al (2006). $$$$$ The modeling framework is validated through several experiments for English-Chinese language pair.
Li et al (2004) presented a framework allowing direct orthographical mapping of transliteration units be tween English and Chinese, and an extended model is presented in Ekbal et al (2006). $$$$$ Unlike Japanese katakana or Korean alphabet, Chinese characters are more ideographic than phonetic.
Li et al (2004) presented a framework allowing direct orthographical mapping of transliteration units be tween English and Chinese, and an extended model is presented in Ekbal et al (2006). $$$$$ Although we can arrive at an obvious segmentation /s-mi-th/, there are three Chinese characters for each of /s-/, /-mi-/ and /-th/.

One Chinese Pinyin string can correspond to several Chinese characters (Li et al, 2004). $$$$$ The TM under the DOM framework greatly reduces system development effort and provides a quantum leap in improvement in transliteration accuracy over that of other state-of-the-art machine learning algorithms.
One Chinese Pinyin string can correspond to several Chinese characters (Li et al, 2004). $$$$$ As expected, C2E error rate is much higher than that of E2C.
One Chinese Pinyin string can correspond to several Chinese characters (Li et al, 2004). $$$$$ The transliteration is usually achieved through intermediate phonemic mapping.

For this reason, it has been reported that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al, 2004). $$$$$ In Table 1, we see only 28,632 unique Chinese transliterations exist for 37,694 English entries, meaning that some phonemic evidence is lost in the process of transliteration.
For this reason, it has been reported that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al, 2004). $$$$$ Most foreign names are transliterated into Chinese, Japanese or Korean with approximate phonetic equivalents.
For this reason, it has been reported that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al, 2004). $$$$$ This paper presents a new framework that allows direct orthographical mapping (DOM) between two different languages, through a joint source-channel model, also transliteration model (TM). the TM model, we automate the orthographic alignment process to derive the aligned transliteration units from bilingual dictionary.
For this reason, it has been reported that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al, 2004). $$$$$ Most foreign names are transliterated into Chinese, Japanese or Korean with approximate phonetic equivalents.

We performed alignment between E G and E P and between E P and C P in a similar manner presented in Li et al (2004). $$$$$ A back-transliteration is considered correct if it falls within the multiple valid orthographically correct options.
We performed alignment between E G and E P and between E P and C P in a similar manner presented in Li et al (2004). $$$$$ It is noted that in the 374 legitimate Chinese characters for transliteration, character to Pinyin mapping is unique while Pinyin to character mapping could be one to many.
We performed alignment between E G and E P and between E P and C P in a similar manner presented in Li et al (2004). $$$$$ The first 4 setups by Virga et al all adopted the phoneme-based approach in the following steps: It is obvious that the n-gram TM compares favorably to other techniques. n-gram TM presents an error reduction of 74.6%=(42.5-10.8)/42.5% for Pinyin over the best reported result, Huge MT (Big MT) test case, which is noteworthy.

 $$$$$ Therefore, any foreign name will have only one Pinyin (romanization of Chinese) and thus in Chinese characters.
 $$$$$ However, if secondary knowledge, such as a lookup table of valid target transliterations, is available, it can help reduce error rate by discarding invalid transliterations top-down the N choices.
 $$$$$ It generates probabilistic orthographic transformation rules using a data driven approach.

We used the same test set used in Li et al (2004) for our testing. $$$$$ For a test set W composed of V names, where each name has been aligned into a sequence of transliteration pair tokens, we can calculate the probability of test set models to the token sequence.
We used the same test set used in Li et al (2004) for our testing. $$$$$ It generates probabilistic orthographic transformation rules using a data driven approach.
We used the same test set used in Li et al (2004) for our testing. $$$$$ The TM under the DOM framework greatly reduces system development effort and provides a quantum leap in improvement in transliteration accuracy over that of other state-of-the-art machine learning algorithms.
We used the same test set used in Li et al (2004) for our testing. $$$$$ In eqn (1) and (2), P(C) and P(E) are usually estimated using n-gram language models (Jelinek, 1991).

(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ As expected, C2E error rate is much higher than that of E2C.
(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ Unlike the noisy-channel model, the joint source-channel model does not try to capture how source names can be mapped to target names, but rather how source and target names can be generated simultaneously.
(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ Only the top choice in N-best results is used for error rate reporting.
(Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). $$$$$ Results are reported in Table 3 and In word error report, a word is considered correct only if an exact match happens between transliteration and the reference.

Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ We have good reason to expect TM to provide better transliteration results which we expect to be confirmed later in the experiments.
Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ Transliterating English names into Chinese is not straightforward.
Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ To minimize the effects from alignment variation, we use the same alignment results from section 4.
Table 6 represents the overall performance of one system in a previous work (Li et al, 2004) and eighteen systems based on the transliteration models defined in this paper. $$$$$ A transliteration unit correspondence < e, c > is called a transliteration pair.

To compare Li et al (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al (2004). $$$$$ (8), it depends only on the previous Chinese unit.
To compare Li et al (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al (2004). $$$$$ Like many other solutions in computational linguistics, it is possible to automatically analyze the bilingual dictionary to acquire knowledge in order to map new English names to Chinese and vice versa.
To compare Li et al (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al (2004). $$$$$ The N-best error rates are reduced significantly at 10-best level as reported in Table 7.

Since the training data used in Li et al (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. $$$$$ Therefore, for simplicity, we randomly select one of the 13 subsets, which consists of 2896 entries, as the standard open test set to report results.
Since the training data used in Li et al (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. $$$$$ Furthermore, /s-/ and /-th/ correspond to overlapping characters as well, as shown next.
Since the training data used in Li et al (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. $$$$$ surprise, Chinese names have much lower perplexity than English names thanks to fewer Chinese units.

The grapheme-based approach, also known as direct orthographical mapping (Li et al, 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. $$$$$ In contrast, for each Chinese unit, we have 15.1 = 5,640/374 English back-transliteration units!
The grapheme-based approach, also known as direct orthographical mapping (Li et al, 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. $$$$$ The resulting alignment may not be optimal for tree construction.
The grapheme-based approach, also known as direct orthographical mapping (Li et al, 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. $$$$$ In section 5, we relate our algorithms to other reported work.
The grapheme-based approach, also known as direct orthographical mapping (Li et al, 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. $$$$$ (9), the current transliteration depends on both Chinese and English transliteration history while in eqn.

Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ Furthermore, /s-/ and /-th/ correspond to overlapping characters as well, as shown next.
Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ As T2 >>T+ C2, an n-gram TM gives a finer description than that of NCM.
Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ This paper presents a new framework that allows direct orthographical mapping (DOM) between two different languages, through a joint source-channel model, also transliteration model (TM). the TM model, we automate the orthographic alignment process to derive the aligned transliteration units from bilingual dictionary.
Other transliteration systems focus on alignment for transliteration, for example the joint source channel model suggested by Li et al (2004). $$$$$ A perplexity study in section 4.1 will look at the model from another perspective.

The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions. $$$$$ Suppose that we have an English name α = x1x2 ...xm and a Chinese transliteration β = y1y2 .
The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions. $$$$$ A back-transliteration is considered correct if it falls within the multiple valid orthographically correct options.
The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions. $$$$$ In this paper, we adopted an N-best stack decoder (Schwartz and Chow, 1990) in both TM and NCM experiments to search for N-best results.
The grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions. $$$$$ Let’s take another name /Smith/ as an example.

Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ The database includes a collection of 37,694 unique English entries and their official Chinese transliteration.
Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ It would be interesting to relate n-gram TM to other related framework.
Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ For a given English name E as the observed channel output, one seeks a posteriori the most likely Chinese transliteration C that maximizes P(C|E).
Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations (Li et al, 2004). $$$$$ Proper names of English, French, German, Russian, Spanish and Arabic origins constitute a good portion of out-of-vocabulary words.

Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ In this paper, we focus on automatic Chinese transliteration of foreign alphabet names.
Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ Although the framework is implemented on an English-Chinese personal name data set, without loss of generality, it well applies to transliteration of other language pairs such as English/Korean and English/Japanese.
Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ It generates probabilistic orthographic transformation rules using a data driven approach.
Li et al (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. $$$$$ In CLIR or multilingual corpus alignment (Virga and Khudanpur, 2003), N-best results will be very helpful to increase chances of correct hits.

Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin (Li et al, 2004). $$$$$ For a test set W composed of V names, where each name has been aligned into a sequence of transliteration pair tokens, we can calculate the probability of test set models to the token sequence.
Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin (Li et al, 2004). $$$$$ It is noted that place and company names are sometimes translated in combination of transliteration and meanings, for example, /Victoria-Fall/ becomes ff � f1 R 4 �ti (Pinyin:Wei Duo Li Ya Pu Bu).
Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin (Li et al, 2004). $$$$$ In other words, we estimate a joint probability model that can be easily marginalized in order to yield conditional probability models for both transliteration and back-transliteration.

So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ We expect to see the proposed model to be further explored in other related areas.
So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ This process is repeated 13 times to yield an average result, which is called the 13-fold open test.
So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ In section 4, one observes that contextual information in both source and target languages is essential.
So grapheme-based (Li et al, 2004) approach has gained lots of attention recently. $$$$$ Nevertheless, ID3 presents another successful implementation of DOM framework.

Direct orthographic mapping (e.g. Li et al, 2004), making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly. $$$$$ One may need to prepare multiple language-dependent grapheme-to-phoneme (G2P) conversion systems accordingly, and that is not easy to achieve (The Onomastica Consortium, 1995).
Direct orthographic mapping (e.g. Li et al, 2004), making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly. $$$$$ The modeling framework is validated through several experiments for English-Chinese language pair.
Direct orthographic mapping (e.g. Li et al, 2004), making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly. $$$$$ For reference purpose, we list some reported studies on other databases of E2C transliteration tasks in Table 10.
