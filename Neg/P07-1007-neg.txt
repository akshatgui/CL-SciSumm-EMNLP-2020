Chan and Ng (2007) performed supervised domain adaptation on a manually selected subset of 21 nouns from the DSO corpus. $$$$$ The results show that a-estPred performs consistently better than a, and a-c-estPred in turn performs better than aestPred.
Chan and Ng (2007) performed supervised domain adaptation on a manually selected subset of 21 nouns from the DSO corpus. $$$$$ This highlights the importance of domain adaptation for word sense disambiguation.
Chan and Ng (2007) performed supervised domain adaptation on a manually selected subset of 21 nouns from the DSO corpus. $$$$$ Also, we have successfully used an EM-based algorithm to detect a change in predominant sense between the training and new domain.

 $$$$$ SMF-20041076).
 $$$$$ Note that the probabilities bpL(ωi|xk) and bpL(ωi) in Equation (4) will stay the same throughout the iterations for each particular instance xk and class ωi.
 $$$$$ We let c denote the counts from out-of-domain training data, c� denote the counts from in-domain adaptation data, and p� denote the probability estimate by count-merging.
 $$$$$ In this paper, we perform domain adaptation for WSD of a set of its BC and WSJ parts to investigate the domain denouns using fine-grained evaluation.

In building training dataset by active learning, we use uncertainty sampling like (Chan and Ng, 2007) (Figure 1 line 30-31). $$$$$ When a word sense disambiguation (WSD) system is trained on one domain but applied to a different domain, a drop in accuracy is frequently observed.
In building training dataset by active learning, we use uncertainty sampling like (Chan and Ng, 2007) (Figure 1 line 30-31). $$$$$ However, their work only investigated the use of active learning to reduce the annotation effort necessary for WSD, but did not deal with the porting of a WSD system to a different domain.
In building training dataset by active learning, we use uncertainty sampling like (Chan and Ng, 2007) (Figure 1 line 30-31). $$$$$ In this paper, we have shown that active learning is effective in reducing the annotation effort required in porting a WSD system to a new domain.
In building training dataset by active learning, we use uncertainty sampling like (Chan and Ng, 2007) (Figure 1 line 30-31). $$$$$ We can scale the out-of-domain and in-domain counts with different factors, or just use a single weight parameter β: Obtaining an optimum value for β is not the focus of this work.

Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. $$$$$ These results highlight the importance of striking a balance between these two goals.
Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. $$$$$ This highlights the importance of domain adaptation for word sense disambiguation.
Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. $$$$$ Count-merging can be regarded as scaling of counts obtained from different data sets.
Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. $$$$$ SEMCOR is a subset of BC which is senseIn particular, we explore the issue of different sense annotated.

AL seems to improve results in a WSD task with coarse-grained sense distinctions (Chan and Ng, 2007), but the results of (Dang, 2004) raise doubts as to whether AL can successfully be applied to a fine-grained annotation scheme, where Inter Annotator Agreement (IAA) is low and thus the consistency of the human annotations decreases. $$$$$ Yee Seng Chan is supported by a Singapore Millennium Foundation Scholarship (ref no.
AL seems to improve results in a WSD task with coarse-grained sense distinctions (Chan and Ng, 2007), but the results of (Dang, 2004) raise doubts as to whether AL can successfully be applied to a fine-grained annotation scheme, where Inter Annotator Agreement (IAA) is low and thus the consistency of the human annotations decreases. $$$$$ A possible reason might be that by strictly adhering to the sense priors in the WSJ data, we have removed too many BC training examples, from an average of 310 examples per noun as shown in Table 1, to an average of 195 examples.
AL seems to improve results in a WSD task with coarse-grained sense distinctions (Chan and Ng, 2007), but the results of (Dang, 2004) raise doubts as to whether AL can successfully be applied to a fine-grained annotation scheme, where Inter Annotator Agreement (IAA) is low and thus the consistency of the human annotations decreases. $$$$$ Yee Seng Chan is supported by a Singapore Millennium Foundation Scholarship (ref no.
AL seems to improve results in a WSD task with coarse-grained sense distinctions (Chan and Ng, 2007), but the results of (Dang, 2004) raise doubts as to whether AL can successfully be applied to a fine-grained annotation scheme, where Inter Annotator Agreement (IAA) is low and thus the consistency of the human annotations decreases. $$$$$ We can similarly choose BC examples such that the sense priors in the BC training data adhere to the sense priors in the WSJ evaluation data.

Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al, 2007), parsing (Tang et al, 2002) and word sense disambiguation (Chan and Ng, 2007). $$$$$ We can scale the out-of-domain and in-domain counts with different factors, or just use a single weight parameter β: Obtaining an optimum value for β is not the focus of this work.
Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al, 2007), parsing (Tang et al, 2002) and word sense disambiguation (Chan and Ng, 2007). $$$$$ SMF-20041076).
Active learning has been widely used for NLP tasks such as part of speech tagging (Ringger et al, 2007), parsing (Tang et al, 2002) and word sense disambiguation (Chan and Ng, 2007). $$$$$ Also, we have successfully used an EM-based algorithm to detect a change in predominant sense between the training and new domain.

Here, we take inspiration from the target-word specific results reported by Chan and Ng (2007) where by using just 30% of the target data they obtained the same performance as that obtained by using the entire target data. $$$$$ With this information on the predominant sense of the new domain and incorporating count-merging, we have shown that we are able to improve the effectiveness of the original adaptation process achieved by the basic active learning approach.
Here, we take inspiration from the target-word specific results reported by Chan and Ng (2007) where by using just 30% of the target data they obtained the same performance as that obtained by using the entire target data. $$$$$ (2006) used active learning for 5 verbs using coarse-grained evaluation, and H. T. Dang (2004) employed active learning for another set of 5 verbs.
Here, we take inspiration from the target-word specific results reported by Chan and Ng (2007) where by using just 30% of the target data they obtained the same performance as that obtained by using the entire target data. $$$$$ The a posteriori bp(s)(ωi|xk) and a priori probabilities bp(s)(ωi) are re-estimated sequentially during each iterations for each new instance xk and each class ωi, until the convergence of the estimated probabilities bp(s)(ωi), which will be our estimated sense priors.
Here, we take inspiration from the target-word specific results reported by Chan and Ng (2007) where by using just 30% of the target data they obtained the same performance as that obtained by using the entire target data. $$$$$ In applying active learning for domain adaptation, Zhang et al. (2003) presented work on sentence boundary detection using generalized Winnow, while Tur et al.

 $$$$$ The denominator in Equation (4) is simply a normalizing factor.
 $$$$$ We also define bp(s)(ωi) and bp(s)(ωi|xk) as estimates of the new a priori and a posteriori probabilities at step s of the iterative EM procedure.
 $$$$$ In this paper, we have shown that active learning is effective in reducing the annotation effort required in porting a WSD system to a new domain.

Domain specific WSD for selected target words has been attempted by Ng and Lee (1996), Agirre and de Lacalle (2009), Chan and Ng (2007), Koeling et al (2005) and Agirre et al (2009b). $$$$$ Instead, we are interested to see if assigning a higher weight to the in-domain WSJ adaptation examples, as compared to the out-of-domain BC examples, will improve the adaptation process.
Domain specific WSD for selected target words has been attempted by Ng and Lee (1996), Agirre and de Lacalle (2009), Chan and Ng (2007), Koeling et al (2005) and Agirre et al (2009b). $$$$$ We have recently shown that this algorithm is effective in estimating the sense priors of a set of nouns (Chan and Ng, 2005).
Domain specific WSD for selected target words has been attempted by Ng and Lee (1996), Agirre and de Lacalle (2009), Chan and Ng (2007), Koeling et al (2005) and Agirre et al (2009b). $$$$$ Most of this section is based on (Saerens et al., 2002).
Domain specific WSD for selected target words has been attempted by Ng and Lee (1996), Agirre and de Lacalle (2009), Chan and Ng (2007), Koeling et al (2005) and Agirre et al (2009b). $$$$$ Figure 4 plots the curve a-estPred, which is similar to a-truePred, except that the predominant sense is now estimated by the EM-based algorithm.

Our main inspiration comes from the target word specific results reported by Chan and Ng (2007) and Agirre and de Lacalle (2009). $$$$$ Domain adaptation is important to ensure the general applicability of WSD systems across different domains.
Our main inspiration comes from the target word specific results reported by Chan and Ng (2007) and Agirre and de Lacalle (2009). $$$$$ Hence, we just use a β value of 3 in our experiments involving count-merging.
Our main inspiration comes from the target word specific results reported by Chan and Ng (2007) and Agirre and de Lacalle (2009). $$$$$ The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.

With the exception of (Chan and Ng, 2007) which tried to adapt a WSD system trained on the BC part of the DSO corpus to the WSJ part of the DSO corpus, the other researchers simply applied active learning to reduce the annotation effort required and did not deal with the issue of adapting a WSD system to a new domain. $$$$$ Finally, we note that we have an average of 310 BC training examples and 406 WSJ adaptation examples per noun.
With the exception of (Chan and Ng, 2007) which tried to adapt a WSD system trained on the BC part of the DSO corpus to the WSJ part of the DSO corpus, the other researchers simply applied active learning to reduce the annotation effort required and did not deal with the issue of adapting a WSD system to a new domain. $$$$$ With this information on the predominant sense of the new domain and incorporating count-merging, we have shown that we are able to improve the effectiveness of the original adaptation process achieved by the basic active learning approach.
With the exception of (Chan and Ng, 2007) which tried to adapt a WSD system trained on the BC part of the DSO corpus to the WSJ part of the DSO corpus, the other researchers simply applied active learning to reduce the annotation effort required and did not deal with the issue of adapting a WSD system to a new domain. $$$$$ For instance, to reach the final accuracy of 78.4%, r, a, a-estPred, and ac-estPred require the addition of 100%, 51%, 38%, and 29% adaptation examples respectively.

It has also been applied to the problem of domain adaptation for word sense disambiguation in (Chan and Ng, 2007). $$$$$ SMF-20041076).
It has also been applied to the problem of domain adaptation for word sense disambiguation in (Chan and Ng, 2007). $$$$$ SMF-20041076).
It has also been applied to the problem of domain adaptation for word sense disambiguation in (Chan and Ng, 2007). $$$$$ Also, we have successfully used an EM-based algorithm to detect a change in predominant sense between the training and new domain.
It has also been applied to the problem of domain adaptation for word sense disambiguation in (Chan and Ng, 2007). $$$$$ To date, the best performing systems in WSD use a corpus-based, supervised learning approach.

Chan and Ng (2007) notably show that detecting changes in predominant sense as modeled by domain sense priors can improve sense disambiguation, even after performing adaptation using active learning. $$$$$ The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.
Chan and Ng (2007) notably show that detecting changes in predominant sense as modeled by domain sense priors can improve sense disambiguation, even after performing adaptation using active learning. $$$$$ Then, by using the predominant sense predicted by expectation-maximization (EM) and adopting a count-merging technique, we improve the effectiveness of the original adaptation process achieved by the basic active learning approach.
Chan and Ng (2007) notably show that detecting changes in predominant sense as modeled by domain sense priors can improve sense disambiguation, even after performing adaptation using active learning. $$$$$ When a word sense disambiguation (WSD) system is trained on one domain but applied to a different domain, a drop in accuracy is frequently observed.
