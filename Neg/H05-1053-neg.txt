Recent results on the SPORTS and FINANCE gold standard dataset (Koeling et al 2005) show that domain WSD can achieve accuracy in the 50 60% ballpark when a state-of-the-art algorithm such as Personalized PageRank is paired with a distributional approach (Agirre et al 2009) or with semantic model vectors acquired for many domains (Navigli et al 2011). $$$$$ and the UK Royal Society.
Recent results on the SPORTS and FINANCE gold standard dataset (Koeling et al 2005) show that domain WSD can achieve accuracy in the 50 60% ballpark when a state-of-the-art algorithm such as Personalized PageRank is paired with a distributional approach (Agirre et al 2009) or with semantic model vectors acquired for many domains (Navigli et al 2011). $$$$$ This weight is normalised by the sum of such WN similarity scores between all senses of  and and the senses of the neighbour that maximises this score.
Recent results on the SPORTS and FINANCE gold standard dataset (Koeling et al 2005) show that domain WSD can achieve accuracy in the 50 60% ballpark when a state-of-the-art algorithm such as Personalized PageRank is paired with a distributional approach (Agirre et al 2009) or with semantic model vectors acquired for many domains (Navigli et al 2011). $$$$$ We use WordNet (WN) as our sense inventory.
Recent results on the SPORTS and FINANCE gold standard dataset (Koeling et al 2005) show that domain WSD can achieve accuracy in the 50 60% ballpark when a state-of-the-art algorithm such as Personalized PageRank is paired with a distributional approach (Agirre et al 2009) or with semantic model vectors acquired for many domains (Navigli et al 2011). $$$$$ The work was funded by EU-2001-34460 project MEANING, UK EPSRC project ?Ranking Word Sense for Word Sense Disambiguation?

We also experimented with the gold standard produced by Koeling et al (2005). $$$$$ The domain of a doc ument has a strong influence on the sensedistribution of words, but it is not feasi ble to produce large manually annotated corpora for every domain of interest.
We also experimented with the gold standard produced by Koeling et al (2005). $$$$$ We demonstrate that for a set of words which meet this condition,the performance of the automatic method is far bet ter than when using data from SemCor.
We also experimented with the gold standard produced by Koeling et al (2005). $$$$$ For the annotation task we recruited linguistics stu dents from two universities.

We first test the proposed method over the tasks of predominant sense learning and sense distribution induction, using the WordNet-tagged dataset of Koeling et al (2005), which is made up of 3 collections of documents $$$$$ We show that in our domains and for these words, first sense information automatically acquired from a general corpus is more accurate than first senses derived from SemCor.
We first test the proposed method over the tasks of predominant sense learning and sense distribution induction, using the WordNet-tagged dataset of Koeling et al (2005), which is made up of 3 collections of documents $$$$$ In some other cases, e.g. F sal tested on SPORTS, it is better to use SemCor data.
We first test the proposed method over the tasks of predominant sense learning and sense distribution induction, using the WordNet-tagged dataset of Koeling et al (2005), which is made up of 3 collections of documents $$$$$ documents, amounting to 3209 documents (around 89.7M words), and covering a wide range of topic domains.
We first test the proposed method over the tasks of predominant sense learning and sense distribution induction, using the WordNet-tagged dataset of Koeling et al (2005), which is made up of 3 collections of documents $$$$$ We use the method described in McCarthy et al (2004) for finding predominant senses from raw text.

We first notice that, despite the coarser-grained senses of Macmillan as compared to WordNet, the upper bound WSD accuracy using Macmillan is comparable to that of the WordNet-based datasets over the balanced BNC, and quite a bit lower than that of the two domain corpora of Koeling et al (2005). $$$$$ The au tomatic method seems to lead to better performance for words that are salient to a domain.
We first notice that, despite the coarser-grained senses of Macmillan as compared to WordNet, the upper bound WSD accuracy using Macmillan is comparable to that of the WordNet-based datasets over the balanced BNC, and quite a bit lower than that of the two domain corpora of Koeling et al (2005). $$$$$ We plan to combine this with local context, using collocates of neighbours in the thesaurus, for contextual WSD.
We first notice that, despite the coarser-grained senses of Macmillan as compared to WordNet, the upper bound WSD accuracy using Macmillan is comparable to that of the WordNet-based datasets over the balanced BNC, and quite a bit lower than that of the two domain corpora of Koeling et al (2005). $$$$$ et al (2004) we use   and obtain our thesaurus using the distributional similarity metric described by Lin (1998).
We first notice that, despite the coarser-grained senses of Macmillan as compared to WordNet, the upper bound WSD accuracy using Macmillan is comparable to that of the WordNet-based datasets over the balanced BNC, and quite a bit lower than that of the two domain corpora of Koeling et al (2005). $$$$$ box.

The relative occurrence of unlisted/unclear senses in the datasets of Koeling et al (2005) is comparable to UKWAC. $$$$$ We also intend to exploit the automatic rankingto obtain information on sense frequency distribu tions (rather than just predominant senses) given the genre as well as the domain of the text.
The relative occurrence of unlisted/unclear senses in the datasets of Koeling et al (2005) is comparable to UKWAC. $$$$$ 8We see that for words which are pertinent to the do main of the test text, it pays to use domain specific training data.
The relative occurrence of unlisted/unclear senses in the datasets of Koeling et al (2005) is comparable to UKWAC. $$$$$ The best results are obtained when training on a domain relevant corpus.
