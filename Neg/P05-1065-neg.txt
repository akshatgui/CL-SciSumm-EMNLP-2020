For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.
For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ We believe that higher order n-gram models or class n-gram models can achieve better performance by capturing both semantic and syntactic information.
For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ In addition to the traditional reading level metrics, researchers at Carnegie Mellon University have applied probabilistic language modeling techniques to this task.
For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ These methods are quick and easy to calculate but have drawbacks: sentence length is not an accurate measure of syntactic complexity, and syllable count does not necessarily indicate the difficulty of a word.

Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. $$$$$ Measures of reading level based on word lists do not capture this information.
Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. $$$$$ Other measures of readability focus on semantics, which is usually approximated by word frequency with respect to a reference list or corpus.
Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. $$$$$ Finding reading materials that fulfill these requirements is difficult and time-consuming, and teachers are often forced to rewrite texts themselves to suit the varied needs of their students.
Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. $$$$$ The traditional measures performed better on some commercial corpora, but these corpora were calibrated using similar measures, so this is not a fair comparison.

 $$$$$ Further experiments are planned on the generalizability of our classifier to text from other sources (e.g. newspaper articles, web pages); to accomplish this we will add higher level text as negative training data.
 $$$$$ The minimum cost operating point depends on the relative costs of misses and false alarms; it is conceivable that one type of error might be more serious than the other.

 $$$$$ Section 3 describes the corpora used in our work.
 $$$$$ In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.
 $$$$$ This is particularly important for the tasks we are interested in, when the vocabulary (i.e. topic) and grade level are not necessarily well-matched.

Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.
Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ Combining information from statistical LMs with other features using support vector machines provided the best results.
Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ This task can be addressed with natural language processing technology to assess reading level.
Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ The minimum cost operating point depends on the relative costs of misses and false alarms; it is conceivable that one type of error might be more serious than the other.

Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005). $$$$$ The Dale-Chall formula uses a combination of average sentence length and percentage of words not on a list of 3000 “easy” words (Chall and Dale, 1995).
Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005). $$$$$ In the same year, one quarter of all public school students in California and one in seven students in Texas were classified as LEP (U.S. Dept. of Education, 2004).
Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005). $$$$$ This section highlights examples and features of some commonly used measures of reading level and discusses current research on the topic of reading level assessment using NLP techniques.

A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005). $$$$$ In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.
A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005). $$$$$ In this work, the minimum cost operating point is selected by averaging the percentages of misses and false alarms at each point and choosing the point with the lowest average.
A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005). $$$$$ Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.

Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences). $$$$$ We divide the Weekly Reader corpus described in Section 3 into separate training, development, and test sets.
Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences). $$$$$ In this work, the minimum cost operating point is selected by averaging the percentages of misses and false alarms at each point and choosing the point with the lowest average.

For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005). $$$$$ Reading proficiency is a fundamental component of language competency.
For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005). $$$$$ The traditional measures performed better on some commercial corpora, but these corpora were calibrated using similar measures, so this is not a fair comparison.
For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005). $$$$$ Information gain measures the difference in entropy when w is and is not included as a feature.

We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.
We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ Section 3 describes the corpora used in our work.
We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ Many traditional methods of reading level assessment focus on simple approximations of syntactic complexity such as sentence length.
We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ For example, for the common trigram model where n = 3, the probability of sequence w is: The parameters of the model are estimated using a maximum likelihood estimate based on the observed frequency in a training corpus and smoothed using modified Kneser-Ney smoothing (Chen and Goodman, 1999).

Table 8 compares a classifier trained on the four parse features of Schwarm and Ostendorf (2005) to a classifier trained on our expanded set of parse features. $$$$$ This section highlights examples and features of some commonly used measures of reading level and discusses current research on the topic of reading level assessment using NLP techniques.
Table 8 compares a classifier trained on the four parse features of Schwarm and Ostendorf (2005) to a classifier trained on our expanded set of parse features. $$$$$ Teachers need to find material at a variety of levels, since students need different texts to read independently and with help from the teacher.
Table 8 compares a classifier trained on the four parse features of Schwarm and Ostendorf (2005) to a classifier trained on our expanded set of parse features. $$$$$ Future work includes testing additional classifier features, e.g. parser likelihood scores and features obtained using a syntax-based language model such as Chelba and Jelinek (2000) or Roark (2001).

The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ Many traditional methods of reading level assessment focus on simple approximations of syntactic complexity such as sentence length.
The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ Further experiments are planned on the generalizability of our classifier to text from other sources (e.g. newspaper articles, web pages); to accomplish this we will add higher level text as negative training data.
The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ The likelihood ratio described above could also be used as a feature, but we achieved better results using perplexity.
The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ Information gain measures the difference in entropy when w is and is not included as a feature.

Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5. $$$$$ We design classifiers to distinguish each of these four categories.
Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5. $$$$$ Combining information from statistical LMs with other features using support vector machines provided the best results.
Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5. $$$$$ Further experiments are planned on the generalizability of our classifier to text from other sources (e.g. newspaper articles, web pages); to accomplish this we will add higher level text as negative training data.

A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features. $$$$$ Existing reading level measures are inadequate due to their reliance on vocabulary lists and/or a superficial representation of syntax.
A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features. $$$$$ By combining language model scores with other features in an SVM framework, we achieve our best results.
A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features. $$$$$ We also plan to test these techniques on languages other than English, and incorporate them with an information retrieval system to create a tool that may be used by teachers to help select reading material for their students.

 $$$$$ Figures 2 and 3 show DET curves for this set of classifiers on the development set and test set, respectively.
 $$$$$ Although these corpora do not provide an explicit grade-level ranking for each article, broad categories are distinguished.
 $$$$$ Statistical LMs were used to classify texts based on reading level, with trigram models being noticeably more accurate than bigrams and unigrams.

 $$$$$ In addition to students in bilingual education, these tools will also be useful for those with reading-related learning disabilities and adult literacy students.
 $$$$$ However, feature selection proves to be important in other text classification work, e.g.
 $$$$$ We also plan to test these techniques on languages other than English, and incorporate them with an information retrieval system to create a tool that may be used by teachers to help select reading material for their students.
 $$$$$ We also plan to test these techniques on languages other than English, and incorporate them with an information retrieval system to create a tool that may be used by teachers to help select reading material for their students.

Schwarm and Ostendorf (2005) implemented four parse tree features (average parse tree height, aver age number of SBARs, NPs per sentence and VPs per sentence) in their work. $$$$$ Section 6 provides a summary and description of future work.
Schwarm and Ostendorf (2005) implemented four parse tree features (average parse tree height, aver age number of SBARs, NPs per sentence and VPs per sentence) in their work. $$$$$ Table 2 shows the size of the supplemental corpora.

In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one published (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used. $$$$$ Using threshold values selected based on minimum cost on the development set, indicated by large dots on the plot, we calculated precision and recall on the test set.
In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one published (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used. $$$$$ Combining information from statistical LMs with other features using support vector machines provided the best results.
In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one published (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used. $$$$$ Reading proficiency is a fundamental component of language competency.

 $$$$$ However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.
 $$$$$ The parse features are generated using the Charniak parser (Charniak, 2000) trained on the standard Wall Street Journal Treebank corpus.
 $$$$$ Although these corpora do not provide an explicit grade-level ranking for each article, broad categories are distinguished.
 $$$$$ This task can be addressed with natural language processing technology to assess reading level.

Syntactic complexity is an obvious factor $$$$$ Statistical LMs were used to classify texts based on reading level, with trigram models being noticeably more accurate than bigrams and unigrams.
Syntactic complexity is an obvious factor $$$$$ For each of these three classifiers, Table 5 shows the percentage of articles which are misclassified by more than one grade level.
Syntactic complexity is an obvious factor $$$$$ Additionally, we have two corpora consisting of articles for adults and corresponding simplified versions for children or other language learners.
Syntactic complexity is an obvious factor $$$$$ Additionally, we have two corpora consisting of articles for adults and corresponding simplified versions for children or other language learners.
