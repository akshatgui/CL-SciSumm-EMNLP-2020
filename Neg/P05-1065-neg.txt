For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ Future work includes testing additional classifier features, e.g. parser likelihood scores and features obtained using a syntax-based language model such as Chelba and Jelinek (2000) or Roark (2001).
For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ Table 2 shows the size of the supplemental corpora.
For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ In practice, a teacher is likely to be looking for texts at a particular level rather than classifying a group of texts into a variety of categories.
For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005). $$$$$ More importantly, the smoothed unigram measure worked better on the web corpus, especially on short passages.

Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. $$$$$ Table 2 shows the size of the supplemental corpora.
Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. $$$$$ This task can be addressed with natural language processing technology to assess reading level.
Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases. $$$$$ The Western/Pacific Literacy Network’s (2004) web site has an archive of CNN news stories and abridged versions which we have also received permission to use.

 $$$$$ Further experiments are planned on the generalizability of our classifier to text from other sources (e.g. newspaper articles, web pages); to accomplish this we will add higher level text as negative training data.
 $$$$$ Statistical LMs were used to classify texts based on reading level, with trigram models being noticeably more accurate than bigrams and unigrams.
 $$$$$ Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.
 $$$$$ To meet the needs of their students, bilingual education instructors seek out “high interest level” texts at low reading levels, e.g. texts at a first or second grade reading level that support the fifth grade science curriculum.

 $$$$$ Statistical LMs were used to classify texts based on reading level, with trigram models being noticeably more accurate than bigrams and unigrams.
 $$$$$ Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.
 $$$$$ Statistical LMs were used to classify texts based on reading level, with trigram models being noticeably more accurate than bigrams and unigrams.
 $$$$$ This resulted in 12 LM perplexity features per article based on trigram, bigram and unigram LMs trained on Britannica (adult), Britannica Elementary, CNN (adult) and CNN abridged text.

Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ Combining information from statistical LMs with other features using support vector machines provided the best results.
Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ SVMs are based on the principle of structural risk minimization.
Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ Si and Callan (2001) conducted preliminary work to classify science web pages using unigram models.
Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability. $$$$$ Future work includes testing additional classifier features, e.g. parser likelihood scores and features obtained using a syntax-based language model such as Chelba and Jelinek (2000) or Roark (2001).

Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005). $$$$$ Reading proficiency is a fundamental component of language competency.
Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005). $$$$$ Section 6 provides a summary and description of future work.
Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005). $$$$$ Additionally, we have two corpora consisting of articles for adults and corresponding simplified versions for children or other language learners.
Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005). $$$$$ Future work includes testing additional classifier features, e.g. parser likelihood scores and features obtained using a syntax-based language model such as Chelba and Jelinek (2000) or Roark (2001).

A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005). $$$$$ Information retrieval systems successfully find topical materials and even answer complex queries in text databases and on the World Wide Web.
A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005). $$$$$ We also plan to test these techniques on languages other than English, and incorporate them with an information retrieval system to create a tool that may be used by teachers to help select reading material for their students.
A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005). $$$$$ Many traditional methods of reading level assessment focus on simple approximations of syntactic complexity such as sentence length.
A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005). $$$$$ However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.

Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences). $$$$$ However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.
Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences). $$$$$ To test our classifier on data outside the Weekly Reader corpus, we downloaded 10 randomly selected newspaper articles from the “Kidspost” edition of The Washington Post (2005).
Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences). $$$$$ Reading is a critical part of language and educational development, but finding appropriate reading material for LEP students is often difficult.
Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences). $$$$$ Our corpus consists of articles from the second, third, fourth, and fifth grade editions of the newspaper.

For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005). $$$$$ We also compared error rates for the best performing SVM classifier with two traditional reading level measures, Flesch-Kincaid and Lexile.
For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005). $$$$$ The widelyused Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al., 1975) (as cited in (Collins-Thompson and Callan, 2004)).
For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005). $$$$$ Barzilay and Elhadad (2003) have allowed us to use their corpus from Encyclopedia Britannica, which contains articles from the full version of the encyclopedia and corresponding articles from Britannica Elementary, a new version targeted at children.
For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005). $$$$$ In Section 4 we present our approach to the task, and Section 5 contains experimental results.

We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ Similarly, the Gunning Fog index is based on the average number of words per sentence and the percentage of words with three or more syllables (Gunning, 1952).
We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ This task can be addressed with natural language processing technology to assess reading level.
We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.
We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2). $$$$$ The grade 2 and 5 classifiers have the best performance, probably because grade 3 and 4 must be distinguished from other classes at both higher and lower levels.

Table 8 compares a classifier trained on the four parse features of Schwarm and Ostendorf (2005) to a classifier trained on our expanded set of parse features. $$$$$ Our corpus consists of articles from the second, third, fourth, and fifth grade editions of the newspaper.
Table 8 compares a classifier trained on the four parse features of Schwarm and Ostendorf (2005) to a classifier trained on our expanded set of parse features. $$$$$ Combining information from statistical LMs with other features using support vector machines provided the best results.

The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ Lexile is a more general measure while our classifier is trained on this particular domain, so the better performance of our model is not entirely surprising.
The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ For our LM classifiers, we followed Boulis and Ostendorf’s (2005) approach for feature selection and ranked words by their ability to discriminate between classes.
The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ More recently, Collins-Thompson and Callan manually collected a corpus of web pages ranked by grade level and observed that vocabulary words are not distributed evenly across grade levels.
The most closely related previous study is the work of Schwarm and Ostendorf (2005). $$$$$ Finding reading materials that fulfill these requirements is difficult and time-consuming, and teachers are often forced to rewrite texts themselves to suit the varied needs of their students.

Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5. $$$$$ Although the smoothed unigram classifier outperforms other vocabulary-based semantic measures, it does not capture syntactic information.
Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5. $$$$$ However, an effective automated way to assess the reading level of the retrieved text is still needed.
Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5. $$$$$ Si and Callan (2001) conducted preliminary work to classify science web pages using unigram models.
Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5. $$$$$ We also plan to test these techniques on languages other than English, and incorporate them with an information retrieval system to create a tool that may be used by teachers to help select reading material for their students.

A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features. $$$$$ Section 2 describes related work on reading level assessment.
A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features. $$$$$ Statistical language models (LMs) are used successfully in this way in other areas of NLP such as speech recognition and machine translation.
A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features. $$$$$ The results presented here on reading level assessment are part of a larger project to develop teacher-support tools for bilingual education instructors.
A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features. $$$$$ Traditional measures such as Dale-Chall and Lexile are based on static word lists.

 $$$$$ Finding reading materials that fulfill these requirements is difficult and time-consuming, and teachers are often forced to rewrite texts themselves to suit the varied needs of their students.
 $$$$$ We chose the Lexile measure as an example of a reading level classifier based on word lists.3 Lexile scores do not correlate directly to numeric grade levels, however a mapping of ranges of Lexile scores to their corresponding grade levels is available on the Lexile web site (Lexile, 2005).
 $$$$$ More recently, Collins-Thompson and Callan manually collected a corpus of web pages ranked by grade level and observed that vocabulary words are not distributed evenly across grade levels.

 $$$$$ Si and Callan (2001) conducted preliminary work to classify science web pages using unigram models.
 $$$$$ Further experiments are planned on the generalizability of our classifier to text from other sources (e.g. newspaper articles, web pages); to accomplish this we will add higher level text as negative training data.
 $$$$$ The widelyused Flesch-Kincaid Grade Level index is based on the average number of syllables per word and the average sentence length in a passage of text (Kincaid et al., 1975) (as cited in (Collins-Thompson and Callan, 2004)).
 $$$$$ For training SVMs, we used the SVMUght toolkit developed by Joachims (1998b).

Schwarm and Ostendorf (2005) implemented four parse tree features (average parse tree height, aver age number of SBARs, NPs per sentence and VPs per sentence) in their work. $$$$$ These measures are inadequate for our task; in many cases, teachers want materials with more difficult, topic-specific words but simple structure.
Schwarm and Ostendorf (2005) implemented four parse tree features (average parse tree height, aver age number of SBARs, NPs per sentence and VPs per sentence) in their work. $$$$$ Additionally, we have two corpora consisting of articles for adults and corresponding simplified versions for children or other language learners.
Schwarm and Ostendorf (2005) implemented four parse tree features (average parse tree height, aver age number of SBARs, NPs per sentence and VPs per sentence) in their work. $$$$$ Similarly, the Gunning Fog index is based on the average number of words per sentence and the percentage of words with three or more syllables (Gunning, 1952).

In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one published (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used. $$$$$ Reading proficiency is a fundamental component of language competency.
In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one published (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used. $$$$$ Our work is currently focused on a corpus obtained from Weekly Reader, an educational newspaper with versions targeted at different grade levels (Weekly Reader, 2004).
In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one published (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used. $$$$$ We also compared error rates for the best performing SVM classifier with two traditional reading level measures, Flesch-Kincaid and Lexile.

 $$$$$ Other measures of readability focus on semantics, which is usually approximated by word frequency with respect to a reference list or corpus.
 $$$$$ In this work, the minimum cost operating point is selected by averaging the percentages of misses and false alarms at each point and choosing the point with the lowest average.
 $$$$$ We chose the Lexile measure as an example of a reading level classifier based on word lists.3 Lexile scores do not correlate directly to numeric grade levels, however a mapping of ranges of Lexile scores to their corresponding grade levels is available on the Lexile web site (Lexile, 2005).
 $$$$$ Since there was no training data corresponding to higher reading levels, the best performance we can expect for adult-level newspaper articles is for our classifiers to mark them as the highest grade level, which is indeed what happened for 10 randomly chosen articles from standard edition of The Washington Post.

Syntactic complexity is an obvious factor: indeed (Heilman et al, 2007) and (Schwarm and Ostendorf, 2005) also used syntactic features, such as parse tree height or the number of passive sentences, to predict reading grade levels. $$$$$ Coupled with an information retrieval system, these tools will be used to select and simplify reading material in multiple languages for use by language learners.
Syntactic complexity is an obvious factor: indeed (Heilman et al, 2007) and (Schwarm and Ostendorf, 2005) also used syntactic features, such as parse tree height or the number of passive sentences, to predict reading grade levels. $$$$$ We also plan to test these techniques on languages other than English, and incorporate them with an information retrieval system to create a tool that may be used by teachers to help select reading material for their students.
Syntactic complexity is an obvious factor: indeed (Heilman et al, 2007) and (Schwarm and Ostendorf, 2005) also used syntactic features, such as parse tree height or the number of passive sentences, to predict reading grade levels. $$$$$ The number of articles in each set is shown in Table 3.
Syntactic complexity is an obvious factor: indeed (Heilman et al, 2007) and (Schwarm and Ostendorf, 2005) also used syntactic features, such as parse tree height or the number of passive sentences, to predict reading grade levels. $$$$$ Future work includes testing additional classifier features, e.g. parser likelihood scores and features obtained using a syntax-based language model such as Chelba and Jelinek (2000) or Roark (2001).
