Similarly, in a case study on co-training for natural language tasks, Pierce and Cardie (2001) find that the degradation in data quality from automatic labelling prevents these systems from performing comparably to their fully-supervised counterparts. $$$$$ On one hand, the goal of weakly supervised learning is to bootstrap a classifier from small amounts of labeled data and large amounts of unlabeled data, often by automatically labeling some of the unlabeled data.
Similarly, in a case study on co-training for natural language tasks, Pierce and Cardie (2001) find that the degradation in data quality from automatic labelling prevents these systems from performing comparably to their fully-supervised counterparts. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.
Similarly, in a case study on co-training for natural language tasks, Pierce and Cardie (2001) find that the degradation in data quality from automatic labelling prevents these systems from performing comparably to their fully-supervised counterparts. $$$$$ Finally, as an approach to resolving the tension in weakly supervised learning between accumulating accurate training data and covering the desired task, we suggest combining weakly supervised methods such as co-training or selftraining with active learning.

Pierce and Cardie (2001) have shown, however, that for tasks which require large numbers of labeled examples such as most NLP tasks co training might be inadequate because it tends to generate noisy data. $$$$$ The most natural views are perhaps {—k, , Of and {0, , k}, indicating that one classifier looks at the focus tag and the tags to its left, while the other looks at the focus tag and the tags to its right.
Pierce and Cardie (2001) have shown, however, that for tasks which require large numbers of labeled examples such as most NLP tasks co training might be inadequate because it tends to generate noisy data. $$$$$ Other views, such as left/right views omitting the focus tag, for example, may be more theoretically attractive, but we found that the left/right views including focus proved most effectual in practice.
Pierce and Cardie (2001) have shown, however, that for tasks which require large numbers of labeled examples such as most NLP tasks co training might be inadequate because it tends to generate noisy data. $$$$$ Since it is impractical to add, say, 27 I, 22 0, and 1 B, to the labeled data at each step of co-training, instead, instances are selected by first choosing a label 1 at random according to the label distribution, then adding the instance 3This standard modification was introduced by Blum and Mitchell (1998) in an effort to cover the underlying distribution of unlabeled instances; however, Nigam and Ghani (2000) found it to be unnecessary in their experiments. train classifier h1 on view V1 of L train classifier h2 on view V2 of L transfer randomly selected examples from U to U' until = u for he h2} allow h to posit labels for all examples in U' repeat g times select label 1 at random according to DL most confidently labeled 1 to the labeled data.

We observed the same pattern in co-training; its accuracy peaked after two iterations (85.1%) and then performance degraded drastically (68% after five iterations) due in part to an increase in mislabeled data in the training set (as previously observed in (Pierce and Cardie, 2001)) and in part because the data skew is not controlled for. $$$$$ We hypothesize that this decline is due to degradation in the quality of the labeled data.
We observed the same pattern in co-training; its accuracy peaked after two iterations (85.1%) and then performance degraded drastically (68% after five iterations) due in part to an increase in mislabeled data in the training set (as previously observed in (Pierce and Cardie, 2001)) and in part because the data skew is not controlled for. $$$$$ Thanks to three anonymous reviewers for their comments and suggestions.
We observed the same pattern in co-training; its accuracy peaked after two iterations (85.1%) and then performance degraded drastically (68% after five iterations) due in part to an increase in mislabeled data in the training set (as previously observed in (Pierce and Cardie, 2001)) and in part because the data skew is not controlled for. $$$$$ We seek to apply the co-training paradigm to problems in natural language learning, with the goal of reducing the amount of humanannotated data required for developing natural language processing components.
We observed the same pattern in co-training; its accuracy peaked after two iterations (85.1%) and then performance degraded drastically (68% after five iterations) due in part to an increase in mislabeled data in the training set (as previously observed in (Pierce and Cardie, 2001)) and in part because the data skew is not controlled for. $$$$$ While previous research (summarized in Section 2) has investigated the theoretical basis of co-training, this study is motivated by practical concerns.

For naive co-training, new samples will always be added, and so there is a possibility that the noise accumulated at later stages will start to degrade performance (see Pierce and Cardie (2001)). $$$$$ Thanks to three anonymous reviewers for their comments and suggestions.
For naive co-training, new samples will always be added, and so there is a possibility that the noise accumulated at later stages will start to degrade performance (see Pierce and Cardie (2001)). $$$$$ Base noun phrases (base NPs) are traditionally defined as nonrecursive noun phrases, i.e.
For naive co-training, new samples will always be added, and so there is a possibility that the noise accumulated at later stages will start to degrade performance (see Pierce and Cardie (2001)). $$$$$ This case study of co-training for natural language learning addresses the scalability question using the task of base noun phrase identification.
For naive co-training, new samples will always be added, and so there is a possibility that the noise accumulated at later stages will start to degrade performance (see Pierce and Cardie (2001)). $$$$$ Usefulness is commonly quantified as the learner's uncertainty about the class of an example (Lewis and Catlett, 1994).

The opposite behaviour has been observed in other applications of co-training (Pierce and Cardie, 2001). $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.
The opposite behaviour has been observed in other applications of co-training (Pierce and Cardie, 2001). $$$$$ Furthermore, co-training for base NP identification seems to be quite sensitive to the CT parameter settings.
The opposite behaviour has been observed in other applications of co-training (Pierce and Cardie, 2001). $$$$$ This study examines the learning behavior of co-training on natural language processing tasks that typically require large numbers of training instances to achieve usable performance levels.
The opposite behaviour has been observed in other applications of co-training (Pierce and Cardie, 2001). $$$$$ Other views, such as left/right views omitting the focus tag, for example, may be more theoretically attractive, but we found that the left/right views including focus proved most effectual in practice.

 $$$$$ Collins and Singer (1999) were concerned that the CT algorithm does not strongly enforce the requirement that hypothesis functions should be compatible with the unlabeled data.
 $$$$$ This estimate smoothes the training probability by including virtual (unseen) samples for each part-of-speech tag (of which there are 45).
 $$$$$ This procedure preserves the distribution of labels in the labeled data as instances are labeled and added.
 $$$$$ This procedure preserves the distribution of labels in the labeled data as instances are labeled and added.

The drop in F-measure is potentially due to the pollution of the labeled data by mislabeled instances (Pierce and Cardie, 2001). $$$$$ Finally, as an approach to resolving the tension in weakly supervised learning between accumulating accurate training data and covering the desired task, we suggest combining weakly supervised methods such as co-training or selftraining with active learning.
The drop in F-measure is potentially due to the pollution of the labeled data by mislabeled instances (Pierce and Cardie, 2001). $$$$$ NPs that do not contain NPs.
The drop in F-measure is potentially due to the pollution of the labeled data by mislabeled instances (Pierce and Cardie, 2001). $$$$$ Thanks to three anonymous reviewers for their comments and suggestions.

However, it has been shown (Pierce and Cardie, 2001) that semi-supervised learning is brittle for NLP tasks where typically large amounts of high quality annotations are needed to train appropriate classifiers. $$$$$ Thanks to three anonymous reviewers for their comments and suggestions.
However, it has been shown (Pierce and Cardie, 2001) that semi-supervised learning is brittle for NLP tasks where typically large amounts of high quality annotations are needed to train appropriate classifiers. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.
However, it has been shown (Pierce and Cardie, 2001) that semi-supervised learning is brittle for NLP tasks where typically large amounts of high quality annotations are needed to train appropriate classifiers. $$$$$ For the JOB instances (vectors of part-of-speech tags indexed from —k to k) a view corresponds to a subset of the set of indices {—k, , k} .

The use of the disagreement between taggers for selecting candidates for manual correction is reminiscent of corrected co-training (PierceandCardie, 2001). $$$$$ Naturally, the resulting classifier does not perform as well as a fully supervised classifier trained on hundreds of times as much labeled data, but if the difference in accuracy is less important than the effort required to produce the labeled training data, co-training is especially attractive.
The use of the disagreement between taggers for selecting candidates for manual correction is reminiscent of corrected co-training (PierceandCardie, 2001). $$$$$ We chose naive bayes classifiers for the study, first, because they are convenient to use and, indeed, have been used in previous co-training studies; and second, because they are particularly well-suited to co-training by virtue of calculating probabilities for each prediction.
The use of the disagreement between taggers for selecting candidates for manual correction is reminiscent of corrected co-training (PierceandCardie, 2001). $$$$$ While this result is satisfying, further investigation reveals that deterioration in the quality of the labeled data accumulated by co-training hinders further improvement.
The use of the disagreement between taggers for selecting candidates for manual correction is reminiscent of corrected co-training (PierceandCardie, 2001). $$$$$ These values are used throughout the evaluation unless noted otherwise.

For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). $$$$$ The modified CT algorithm is presented in Figure 3.
For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). $$$$$ However, degradation in the quality of the bootstrapped data arises as an obstacle to further improvement.
For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.

The fact that no improvement was obtained agrees with previous observations that classifiers that are too accurate can not be improved with bootstrapping (Pierce and Cardie,2001). $$$$$ This neatly dovetails with the criterion for selecting instances to label in CT. We envision a learner that would alternate between selecting its most certain unlabeled examples to label and present to the human for acknowledgment, and selecting its most uncertain examples to present to the human for annotation.
The fact that no improvement was obtained agrees with previous observations that classifiers that are too accurate can not be improved with bootstrapping (Pierce and Cardie,2001). $$$$$ We seek to apply the co-training paradigm to problems in natural language learning, with the goal of reducing the amount of humanannotated data required for developing natural language processing components.
The fact that no improvement was obtained agrees with previous observations that classifiers that are too accurate can not be improved with bootstrapping (Pierce and Cardie,2001). $$$$$ In particular, many natural language learning tasks contrast sharply with the classification tasks previously studied in conjunction with co-training in that they require hundreds of thousands, rather than hundreds, of training examples.
The fact that no improvement was obtained agrees with previous observations that classifiers that are too accurate can not be improved with bootstrapping (Pierce and Cardie,2001). $$$$$ While previous research (summarized in Section 2) has investigated the theoretical basis of co-training, this study is motivated by practical concerns.

A comparative analysis of words that benefit from basic/smoothed co-training with global parameter settings, versus words with little or no improvement obtained through bootstrapping reveals several observations $$$$$ Yarowsky (1995), Riloff and Jones (1999)), suggesting that the rewards of understanding and dealing with this issue may be significant.
A comparative analysis of words that benefit from basic/smoothed co-training with global parameter settings, versus words with little or no improvement obtained through bootstrapping reveals several observations $$$$$ Our experiments indicate that co-training is an effective method for learning bracketers from small amounts of labeled data.
A comparative analysis of words that benefit from basic/smoothed co-training with global parameter settings, versus words with little or no improvement obtained through bootstrapping reveals several observations $$$$$ For this task, co-training reduces by 36% the difference in error between classifiers trained on 500 labeled examples and classifiers trained on 211,000 labeled examples.

Algorithms such as co-training (Blum and Mitchell, 1998) (Collins and Singer, 1999) (Pierce and Cardie, 2001) and the Yarowsky algorithm (Yarowsky, 1995) make assumptions about the data that permit such an approach. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.
Algorithms such as co-training (Blum and Mitchell, 1998) (Collins and Singer, 1999) (Pierce and Cardie, 2001) and the Yarowsky algorithm (Yarowsky, 1995) make assumptions about the data that permit such an approach. $$$$$ While previous research (summarized in Section 2) has investigated the theoretical basis of co-training, this study is motivated by practical concerns.
Algorithms such as co-training (Blum and Mitchell, 1998) (Collins and Singer, 1999) (Pierce and Cardie, 2001) and the Yarowsky algorithm (Yarowsky, 1995) make assumptions about the data that permit such an approach. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.

The table further indicates that co-training for machine translation suffers the same problem reported in Pierce and Cardie (2001) $$$$$ Corrected Co-Training.
The table further indicates that co-training for machine translation suffers the same problem reported in Pierce and Cardie (2001) $$$$$ To address this, we propose a moderately supervised variant of cotraining in which a human corrects the mistakes made during automatic labeling.
The table further indicates that co-training for machine translation suffers the same problem reported in Pierce and Cardie (2001) $$$$$ As shown above, the degradation of the labeled data introduces a scalability problem for co-training because successive view classifiers use successively poorer quality data for training.
The table further indicates that co-training for machine translation suffers the same problem reported in Pierce and Cardie (2001) $$$$$ We address this problem with a moderately supervised variant, corrected co-training, that employs a human annotator to correct the errors made during bootstrapping.

Pierce and Cardie (2001) showed that the quality of the automatically labeled training data is crucial for co-training to perform well because too many tagging errors prevent a high performing model from being learned. $$$$$ Furthermore, our experiments support the hypothesis that labeled data quality is a crucial issue for co-training.
Pierce and Cardie (2001) showed that the quality of the automatically labeled training data is crucial for co-training to perform well because too many tagging errors prevent a high performing model from being learned. $$$$$ Note that the accuracy of the classifier stabilizes at a point a bit lower than the stable accuracy of the labeled data, as would be expected if labeled data quality hinders further improvement from cotraining.
Pierce and Cardie (2001) showed that the quality of the automatically labeled training data is crucial for co-training to perform well because too many tagging errors prevent a high performing model from being learned. $$$$$ Co-Training (Blum and Mitchell, 1998) is a weakly supervised paradigm for learning a classification task from a small set of labeled data and a large set of unlabeled data, using separate, but redundant, views of the data.
Pierce and Cardie (2001) showed that the quality of the automatically labeled training data is crucial for co-training to perform well because too many tagging errors prevent a high performing model from being learned. $$$$$ Co-Training is a weakly supervised learning paradigm in which the redundancy of the learning task is captured by training two classifiers using separate views of the same data.

To address the problem of data pollution by tagging errors, Pierce and Cardie (2001) propose corrected co-training. $$$$$ Collins and Singer (1999) were concerned that the CT algorithm does not strongly enforce the requirement that hypothesis functions should be compatible with the unlabeled data.
To address the problem of data pollution by tagging errors, Pierce and Cardie (2001) propose corrected co-training. $$$$$ They proved that under these assumptions, a task that is learnable with random classification noise is learnable with co-training.
To address the problem of data pollution by tagging errors, Pierce and Cardie (2001) propose corrected co-training. $$$$$ The next section of this paper introduces issues and concerns surrounding co-training.
To address the problem of data pollution by tagging errors, Pierce and Cardie (2001) propose corrected co-training. $$$$$ Naturally, the resulting classifier does not perform as well as a fully supervised classifier trained on hundreds of times as much labeled data, but if the difference in accuracy is less important than the effort required to produce the labeled training data, co-training is especially attractive.

Thus, these bootstrapping methods will presumably not find the most useful unlabeled examples but require a human to review data points of limited training utility (Pierce and Cardie, 2001). $$$$$ Co-Training.
Thus, these bootstrapping methods will presumably not find the most useful unlabeled examples but require a human to review data points of limited training utility (Pierce and Cardie, 2001). $$$$$ This case study explored issues involved with applying co-training to the natural language processing task of identifying base noun phrases, particularly, the scalability of cotraining for large-scale problems.
Thus, these bootstrapping methods will presumably not find the most useful unlabeled examples but require a human to review data points of limited training utility (Pierce and Cardie, 2001). $$$$$ Second, many NLL problems require hundreds of thousands of training examples, while the web page task can be learned using hundreds of examples.
Thus, these bootstrapping methods will presumably not find the most useful unlabeled examples but require a human to review data points of limited training utility (Pierce and Cardie, 2001). $$$$$ Since it is impractical to add, say, 27 I, 22 0, and 1 B, to the labeled data at each step of co-training, instead, instances are selected by first choosing a label 1 at random according to the label distribution, then adding the instance 3This standard modification was introduced by Blum and Mitchell (1998) in an effort to cover the underlying distribution of unlabeled instances; however, Nigam and Ghani (2000) found it to be unnecessary in their experiments. train classifier h1 on view V1 of L train classifier h2 on view V2 of L transfer randomly selected examples from U to U' until = u for he h2} allow h to posit labels for all examples in U' repeat g times select label 1 at random according to DL most confidently labeled 1 to the labeled data.

 $$$$$ Sang and Veenstra (1999)), among others.
 $$$$$ Thanks to three anonymous reviewers for their comments and suggestions.
 $$$$$ Consequently, our focus on natural language learning raises the question of how co-training scales when a large number of training examples are required to achieve usable performance levels.
 $$$$$ (Figure 2a illustrates base NPs with a short example.)

In their experiments on NP identifiers, Pierce and Cardie (2001) observed a similar effect. $$$$$ It is plausible to expect that the CT algorithm will not scale well, due to mistakes made by the view classifiers.
In their experiments on NP identifiers, Pierce and Cardie (2001) observed a similar effect. $$$$$ Furthermore, the distribution of labels in the training data is more unbalanced than the distribution of positive and negative examples in the web page task: namely, 53.9% of examples are labeled I, 44.0% 0, and 2.1% B.
In their experiments on NP identifiers, Pierce and Cardie (2001) observed a similar effect. $$$$$ Thanks to three anonymous reviewers for their comments and suggestions.
In their experiments on NP identifiers, Pierce and Cardie (2001) observed a similar effect. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.

Co-training has been applied to a number of NLP applications ,including POS-tagging (Clark et al, 2003), parsing (Sarkar, 2001), word sense disambiguation (Mihalcea, 2004), and base noun phrase detection (Pierce and Cardie, 2001). $$$$$ Co-Training is a weakly supervised learning paradigm in which the redundancy of the learning task is captured by training two classifiers using separate views of the same data.
Co-training has been applied to a number of NLP applications ,including POS-tagging (Clark et al, 2003), parsing (Sarkar, 2001), word sense disambiguation (Mihalcea, 2004), and base noun phrase detection (Pierce and Cardie, 2001). $$$$$ Second, how does co-training scale when a large number of training examples are required to achieve usable performance levels?
Co-training has been applied to a number of NLP applications ,including POS-tagging (Clark et al, 2003), parsing (Sarkar, 2001), word sense disambiguation (Mihalcea, 2004), and base noun phrase detection (Pierce and Cardie, 2001). $$$$$ Many corpus-based methods have been applied to the task, including statistical methods (e.g.
Co-training has been applied to a number of NLP applications ,including POS-tagging (Clark et al, 2003), parsing (Sarkar, 2001), word sense disambiguation (Mihalcea, 2004), and base noun phrase detection (Pierce and Cardie, 2001). $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 9454149, 0081334, and 0074896.
