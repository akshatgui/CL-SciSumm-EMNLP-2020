Koehn and Knight (2002) combine a vector-space approach with other clues such as orthographic similarity and frequency. $$$$$ Since there are O(n!) possible mappings, a brute force approach to this is practically impossible.
Koehn and Knight (2002) combine a vector-space approach with other clues such as orthographic similarity and frequency. $$$$$ Again, as in Section 2.2, we have to compute all possible word – or context vector – matches.
Koehn and Knight (2002) combine a vector-space approach with other clues such as orthographic similarity and frequency. $$$$$ Furthermore, texts derived from parliament speeches may not be appropriate for a particular targeted domain.
Koehn and Knight (2002) combine a vector-space approach with other clues such as orthographic similarity and frequency. $$$$$ However, they span different time periods and have a different orientation: the World Street Journal covers mostly business news, the German news wire mostly German politics.

Unlike the noun-only test sets used in other studies, (e.g., Koehn and Knight (2002), Haghighi et al (2008)), TS1000 also contains adjectives and verbs. $$$$$ We collect then the best word matches in a greedy fashion.
Unlike the noun-only test sets used in other studies, (e.g., Koehn and Knight (2002), Haghighi et al (2008)), TS1000 also contains adjectives and verbs. $$$$$ In our case, this is additionally hampered by the different orientation of the news sources.
Unlike the noun-only test sets used in other studies, (e.g., Koehn and Knight (2002), Haghighi et al (2008)), TS1000 also contains adjectives and verbs. $$$$$ Experimental results for the construction of a German-English noun lexicon are reported.
Unlike the noun-only test sets used in other studies, (e.g., Koehn and Knight (2002), Haghighi et al (2008)), TS1000 also contains adjectives and verbs. $$$$$ We combine various clues such as cognates, similar context, preservation of word similarity, and word frequency.

Koehn and Knight (2002) automatically induce the initial seed bilingual dictionary by using identical spelling features such as cognates and similar contexts. $$$$$ Still, for most language pairs, parallel texts are hard to come by.
Koehn and Knight (2002) automatically induce the initial seed bilingual dictionary by using identical spelling features such as cognates and similar contexts. $$$$$ The counts are then normalized by a using the tf/idf method which is often used in information retrieval [Jones, 1979].
Koehn and Knight (2002) automatically induce the initial seed bilingual dictionary by using identical spelling features such as cognates and similar contexts. $$$$$ Experimental results for the construction of a German-English noun lexicon are reported.
Koehn and Knight (2002) automatically induce the initial seed bilingual dictionary by using identical spelling features such as cognates and similar contexts. $$$$$ In the Hansard, each of these words occurs only once.

This setting has been considered before, most notably in Koehn and Knight (2002) and Fung (1995), but the current paper is the first to use a probabilistic model and present results across a variety of language pairs and data conditions. $$$$$ This results in a 600-dimensional vector.
This setting has been considered before, most notably in Koehn and Knight (2002) and Fung (1995), but the current paper is the first to use a probabilistic model and present results across a variety of language pairs and data conditions. $$$$$ Our experiments have been restricted to nouns.
This setting has been considered before, most notably in Koehn and Knight (2002) and Fung (1995), but the current paper is the first to use a probabilistic model and present results across a variety of language pairs and data conditions. $$$$$ We add this word pair to the lexicon, and drop word pairs that include either the German and English word from further search.
This setting has been considered before, most notably in Koehn and Knight (2002) and Fung (1995), but the current paper is the first to use a probabilistic model and present results across a variety of language pairs and data conditions. $$$$$ Using identically spelled words proved to be a good starting point.

Following Koehn and Knight (2002), we consider lexicons over only noun word types, although this is not a fundamental limitation of our model. $$$$$ The seminal work by Brown et al. [1990] at IBM on the Candide system laid the foundation for much of the current work in Statistical Machine Translation (SMT).
Following Koehn and Knight (2002), we consider lexicons over only noun word types, although this is not a fundamental limitation of our model. $$$$$ Still, for most language pairs, parallel texts are hard to come by.
Following Koehn and Knight (2002), we consider lexicons over only noun word types, although this is not a fundamental limitation of our model. $$$$$ This paper presents work on the task of constructing a word-level translation lexicon purely from unrelated monolingual corpora.

Also, as in Koehn and Knight (2002), we make use of a seed lexicon, which consists of a small, and perhaps incorrect, set of initial translation pairs. $$$$$ Therefore we counted all spelling scores below 0.3 as 0.3.
Also, as in Koehn and Knight (2002), we make use of a seed lexicon, which consists of a small, and perhaps incorrect, set of initial translation pairs. $$$$$ Beyond this, we examined four different clues.
Also, as in Koehn and Knight (2002), we make use of a seed lexicon, which consists of a small, and perhaps incorrect, set of initial translation pairs. $$$$$ Some of this work has been re-implemented and is freely available for research purposes [AlOnaizan et al., 1999].
Also, as in Koehn and Knight (2002), we make use of a seed lexicon, which consists of a small, and perhaps incorrect, set of initial translation pairs. $$$$$ In our case, this is additionally hampered by the different orientation of the news sources.

The second method is to heuristically induce, where applicable, a seed lexicon using edit distance, as is done in Koehn and Knight (2002). $$$$$ Noun translation accuracy of 39% scored against a parallel test corpus could be achieved.
The second method is to heuristically induce, where applicable, a seed lexicon using edit distance, as is done in Koehn and Knight (2002). $$$$$ When using the spelling clue in combination with others, we found it useful to define a cutoff.
The second method is to heuristically induce, where applicable, a seed lexicon using edit distance, as is done in Koehn and Knight (2002). $$$$$ In our experiments, however, we included all the words pairs.

In order to explore system robustness to heuristically chosen seed lexicons, we automatically extracted a seed lexicon similarly to Koehn and Knight (2002) $$$$$ We combine various clues such as cognates, similar context, preservation of word similarity, and word frequency.
In order to explore system robustness to heuristically chosen seed lexicons, we automatically extracted a seed lexicon similarly to Koehn and Knight (2002) $$$$$ We are testing our mappings against a bilingual lexicon of 9,206 German and 10,645 English nouns.
In order to explore system robustness to heuristically chosen seed lexicons, we automatically extracted a seed lexicon similarly to Koehn and Knight (2002) $$$$$ This paper presents work on the task of constructing a word-level translation lexicon purely from unrelated monolingual corpora.
In order to explore system robustness to heuristically chosen seed lexicons, we automatically extracted a seed lexicon similarly to Koehn and Knight (2002) $$$$$ Again, we search for the highest score and add the corresponding word pair, drop these words from further search, and so on.

However, we attempted to run an experiment as similar as possible in setup to Koehn and Knight (2002), using English Gigaword and German Europarl. $$$$$ Even if the most frequent word in the German corpus is not necessarily the translation of the most frequent English word, it should also be very frequent.
However, we attempted to run an experiment as similar as possible in setup to Koehn and Knight (2002), using English Gigaword and German Europarl. $$$$$ We combine various clues such as cognates, similar context, preservation of word similarity, and word frequency.

In this setting, our MCCA system yielded 61.7% accuracy on the 186 most confident predictions compared to 39% reported in Koehn and Knight (2002). $$$$$ The similarity and frequency clues, however, seem to be too imprecise to pinpoint the search to the correct translations.
In this setting, our MCCA system yielded 61.7% accuracy on the 186 most confident predictions compared to 39% reported in Koehn and Knight (2002). $$$$$ Adding in the other scores, however, does not seem to be beneficial: only adding the frequency clue to the spelling clue provides some improvement.
In this setting, our MCCA system yielded 61.7% accuracy on the 186 most confident predictions compared to 39% reported in Koehn and Knight (2002). $$$$$ These methods may be also useful given a different starting point: For efforts in building machine translation systems, some small parallel text should be available.

Koehn and Knight (2002) describe few potential clues that may help in extracting bilingual lexicon from two monolingual corpora such as identical words, similar spelling, and similar context features. $$$$$ Using identically spelled words proved to be a good starting point.
Koehn and Knight (2002) describe few potential clues that may help in extracting bilingual lexicon from two monolingual corpora such as identical words, similar spelling, and similar context features. $$$$$ We have attempted to learn a one-to-one translation lexicon purely from unrelated monolingual corpora.
Koehn and Knight (2002) describe few potential clues that may help in extracting bilingual lexicon from two monolingual corpora such as identical words, similar spelling, and similar context features. $$$$$ It consists of 1339 entries, of which are (88.9%) correct according to the existing bilingual lexicon.
Koehn and Knight (2002) describe few potential clues that may help in extracting bilingual lexicon from two monolingual corpora such as identical words, similar spelling, and similar context features. $$$$$ From these, some high-quality lexical entries can be learned, but there will always be many words that are missing.

Koehn and Knight (2002) map 976 identical word pairs that are found in their two monolingual German-English corpora and report that 88.0 percent of them are correct. $$$$$ Using identically spelled words proved to be a good starting point.
Koehn and Knight (2002) map 976 identical word pairs that are found in their two monolingual German-English corpora and report that 88.0 percent of them are correct. $$$$$ Noun translation accuracy of 39% scored against a parallel test corpus could be achieved.
Koehn and Knight (2002) map 976 identical word pairs that are found in their two monolingual German-English corpora and report that 88.0 percent of them are correct. $$$$$ We then changed the weights to see, if we can obtain better results.

Koehn and Knight (2002) mention few related works that use different measurement to compute the similarity, such as longest common subsequence ratio (Melamed, 1995) and string edit distance (Mann 10 and Yarowski, 2001). $$$$$ Besides this linear combination of scores from the different clues, more sophisticated methods may be possible [Koehn, 2002].
Koehn and Knight (2002) mention few related works that use different measurement to compute the similarity, such as longest common subsequence ratio (Melamed, 1995) and string edit distance (Mann 10 and Yarowski, 2001). $$$$$ Beyond this, we examined four different clues.
Koehn and Knight (2002) mention few related works that use different measurement to compute the similarity, such as longest common subsequence ratio (Melamed, 1995) and string edit distance (Mann 10 and Yarowski, 2001). $$$$$ Specific parallel texts can be constructed by hand for the purpose of training an SMT system, but this is a very costly endeavor.

However, Koehn and Knight (2002) point out that majority of their word pairs do not show much resemblance at all since they use German-English language pair. $$$$$ The important point here is that we have generated a similarity matrix, which we will use now to find new translation word pairs.

Koehn and Knight (2002) present one interesting idea of using extracted cognate pairs from corpus as the seed words in order to alleviate the need of huge, initial bilingual lexicon. $$$$$ On the other hand, the digital revolution and the wide-spread use of the World Wide Web have proliferated vast amounts of monolingual corpora.
Koehn and Knight (2002) present one interesting idea of using extracted cognate pairs from corpus as the seed words in order to alleviate the need of huge, initial bilingual lexicon. $$$$$ Specific parallel texts can be constructed by hand for the purpose of training an SMT system, but this is a very costly endeavor.
Koehn and Knight (2002) present one interesting idea of using extracted cognate pairs from corpus as the seed words in order to alleviate the need of huge, initial bilingual lexicon. $$$$$ For all experiments the starting point was the seed lexicon of 1339 identical spelled words described in Section 2.1. which achieve 15.8% Corpus score.
Koehn and Knight (2002) present one interesting idea of using extracted cognate pairs from corpus as the seed words in order to alleviate the need of huge, initial bilingual lexicon. $$$$$ These may be learned using the described methods.

 $$$$$ This paper presents work on the task of constructing a word-level translation lexicon purely from unrelated monolingual corpora.
 $$$$$ We combine various clues such as cognates, similar context, preservation of word similarity, and word frequency.
 $$$$$ These may be learned using the described methods.

Koehn and Knight (2002) derived such a seed lexicon from German-English cognates which were selected by using string similarity criteria. $$$$$ Thus, our second evaluation measurement tests the word translations proposed by the acquired lexicon against the actual word-level translations in a 5,000 sentence aligned parallel corpus.5 The starting point to extending the lexicon is the seed lexicon of identically spelled words, as described in Section 2.1.
Koehn and Knight (2002) derived such a seed lexicon from German-English cognates which were selected by using string similarity criteria. $$$$$ It consists of 1339 entries, of which are (88.9%) correct according to the existing bilingual lexicon.

Other methods such as (Koehn and Knight, 2002) try to design a bootstrapping algorithm based on an initial seed lexicon of translations and various lexical evidences. $$$$$ The two monolingual corpora should be in a fairly comparable domain.
Other methods such as (Koehn and Knight, 2002) try to design a bootstrapping algorithm based on an initial seed lexicon of translations and various lexical evidences. $$$$$ Our experiments have been restricted to nouns.

Following Koehn and Knight (2002), we have also employed simple transformation rules for the adoption of words from one language to another. $$$$$ Combining the context and the spelling clues yields a significantly better result than using each clue by itself.
Following Koehn and Knight (2002), we have also employed simple transformation rules for the adoption of words from one language to another. $$$$$ We combine various clues such as cognates, similar context, preservation of word similarity, and word frequency.
Following Koehn and Knight (2002), we have also employed simple transformation rules for the adoption of words from one language to another. $$$$$ We have attempted to learn a one-to-one translation lexicon purely from unrelated monolingual corpora.
Following Koehn and Knight (2002), we have also employed simple transformation rules for the adoption of words from one language to another. $$$$$ Verbs, adjectives, adverbs and other part of speech may be tackled in a similar way.

The previous approach relying on work from Koehn and Knight (2002) has been outperformed in terms of precision and coverage. $$$$$ We have attempted to learn a one-to-one translation lexicon purely from unrelated monolingual corpora.
The previous approach relying on work from Koehn and Knight (2002) has been outperformed in terms of precision and coverage. $$$$$ Noun translation accuracy of 39% scored against a parallel test corpus could be achieved.
