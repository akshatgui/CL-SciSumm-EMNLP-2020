We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM (Haghighi and Klein, 2006) and HMMs trained with soft constraints (Chang et al, 2007). $$$$$ Our experiments demonstrate that the proposed approach is robust to inaccurate approximation of the prior knowledge (assigning the same penalty to all the pi ).
We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM (Haghighi and Klein, 2006) and HMMs trained with soft constraints (Chang et al, 2007). $$$$$ We use two constraints to illustrate the ideas.
We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM (Haghighi and Klein, 2006) and HMMs trained with soft constraints (Chang et al, 2007). $$$$$ Figure 3 compares two protocols on the advertisements domain: H&W+I, where we first run the H&W protocol and then apply the constraints during testing stage, and H&W&C+I, which uses constraints to guide the model during learning and uses it also in testing.

Another recent method that has been proposed for training sequence models with constraints is Chang et al (2007). $$$$$ In the third baseline, denoted H&W, we balanced the weight of the supervised and unsupervised models as described in line 9 of Figure 2.
Another recent method that has been proposed for training sequence models with constraints is Chang et al (2007). $$$$$ Over the last few years, two of the main research directions in machine learning of natural language processing have been the study of semi-supervised learning algorithms as a way to train classifiers when the labeled data is scarce, and the study of ways to exploit knowledge and global information in structured learning tasks.
Another recent method that has been proposed for training sequence models with constraints is Chang et al (2007). $$$$$ Our novel framework unifies can exploit several kinds of specific The experimental results presented in the information extraction domain demonstrate that applying constraints helps the model to generate better feedback during learning, and hence the framework allows for high performance learning with significantly less training data than was possible before on these tasks.

 $$$$$ In this paper, we suggest a method for incorporating domain knowledge in semi-supervised learning algorithms.
 $$$$$ This paper proposes a novel constraints-based learning protocol for guiding semi-supervised learning.

Most constraints that prove useful for SRL (Chang et al., 2007) also require customization when applied to a new language, and some rely on language specific resources, such as a valency lexicon. $$$$$ Therefore, an increasing attention has been recently given to semi-supervised learning, where large amounts of unlabeled data are used to improve the models learned from a small training set (Collins and Singer, 1999; Thelen and Riloff, 2002).
Most constraints that prove useful for SRL (Chang et al., 2007) also require customization when applied to a new language, and some rely on language specific resources, such as a valency lexicon. $$$$$ This may hurt the performance in both the inference and the learning stage.
Most constraints that prove useful for SRL (Chang et al., 2007) also require customization when applied to a new language, and some rely on language specific resources, such as a valency lexicon. $$$$$ Natural Language Processing (NLP) systems typically require large amounts of knowledge to achieve good performance.
Most constraints that prove useful for SRL (Chang et al., 2007) also require customization when applied to a new language, and some rely on language specific resources, such as a valency lexicon. $$$$$ Acknowledgments: This work is supported by NSF SoDHCER-0613885 and by a grant from Boeing.

Constraint driven learning (CoDL) was first introduced in Chang et al [2007], and has been used also in Chang et al [2008]. $$$$$ One possible way to implement this distance function is as the minimal Hamming distance to a sequence that respects the constraint Ci, that is: d(y, 1Ci(x)) = min(y'E1C(.))
Constraint driven learning (CoDL) was first introduced in Chang et al [2007], and has been used also in Chang et al [2008]. $$$$$ In this paper, we suggest a method for incorporating domain knowledge in semi-supervised learning algorithms.

 $$$$$ Given a small amount of labeled data and a large unlabeled pool, our framework initializes the model with the labeled data and then repeatedly: This way, we can generate better “training” examples during the semi-supervised learning process.
 $$$$$ The I results are consistently better.
 $$$$$ Part of this work was done while Dan Roth visited the Technion, Israel, supported by a Lady Davis Fellowship.
 $$$$$ This labeling violates C1, the minimal hamming distance is 2, and our approximation gives 1, (since there is only one transition that violates the constraint.)

Likewise, Chang et al (2007) use constraints at multiple levels, such as sentence-level constraints to specify field boundaries and global constraints to ensure relation-level consistency. $$$$$ Therefore, we implemented a generic approximation for the hamming distance assuming only that we are given a boolean function OC(yN) that returns whether labeling the token xN with state yN violates constraint with respect to an already labeled consider the prefix x1, x2, x3, x4, which contains no punctuation or newlines and was labeled AUTH, AUTH, DATE, DATE.
Likewise, Chang et al (2007) use constraints at multiple levels, such as sentence-level constraints to specify field boundaries and global constraints to ensure relation-level consistency. $$$$$ The second difference is that each unlabeled example generates K labeled instances.
Likewise, Chang et al (2007) use constraints at multiple levels, such as sentence-level constraints to specify field boundaries and global constraints to ensure relation-level consistency. $$$$$ We used maximum likelihood estimation of A but, in general, perceptron or quasiNewton can also be used.

Chang et al (2007) use a set of domain specific rules as automatic implicit feedback for training information extraction system. $$$$$ Note that some of the constraints are non-local and are very intuitive for people, yet it is very difficult to inject this knowledge into most models.
Chang et al (2007) use a set of domain specific rules as automatic implicit feedback for training information extraction system. $$$$$ We carefully examined the contribution of using constraints to the learning stage and the testing stage, and two separate results are presented: testing with constraints (denoted I for inference) and without constraints (no I).
Chang et al (2007) use a set of domain specific rules as automatic implicit feedback for training information extraction system. $$$$$ Our formalism is most related to this last work.
Chang et al (2007) use a set of domain specific rules as automatic implicit feedback for training information extraction system. $$$$$ We implement some global constraints and include unary constraints which were largely imported from the list of seed words used in (Haghighi and Klein, 2006).

We compare our CRF model integrated with VE with two state-of-the-art models, i.e., constraint driven learning (Chang et al, 2007) and generalized expectation criteria (Mann and McCallum, 2008). $$$$$ Part of this work was done while Dan Roth visited the Technion, Israel, supported by a Lady Davis Fellowship.
We compare our CRF model integrated with VE with two state-of-the-art models, i.e., constraint driven learning (Chang et al, 2007) and generalized expectation criteria (Mann and McCallum, 2008). $$$$$ Our novel framework unifies can exploit several kinds of specific The experimental results presented in the information extraction domain demonstrate that applying constraints helps the model to generate better feedback during learning, and hence the framework allows for high performance learning with significantly less training data than was possible before on these tasks.
We compare our CRF model integrated with VE with two state-of-the-art models, i.e., constraint driven learning (Chang et al, 2007) and generalized expectation criteria (Mann and McCallum, 2008). $$$$$ Since the fields are typically related and interdependent, these kinds of applications provide a good test case for an approach like ours.1 The first task is to identify fields from citations (McCallum et al., 2000) .

Constraint-driven learning (Chang et al, 2007) expresses several kinds of constraints in a unified form. $$$$$ Our novel framework unifies can exploit several kinds of specific The experimental results presented in the information extraction domain demonstrate that applying constraints helps the model to generate better feedback during learning, and hence the framework allows for high performance learning with significantly less training data than was possible before on these tasks.
Constraint-driven learning (Chang et al, 2007) expresses several kinds of constraints in a unified form. $$$$$ Note that some of the constraints are non-local and are very intuitive for people, yet it is very difficult to inject this knowledge into most models.
Constraint-driven learning (Chang et al, 2007) expresses several kinds of constraints in a unified form. $$$$$ Therefore, we implemented a generic approximation for the hamming distance assuming only that we are given a boolean function OC(yN) that returns whether labeling the token xN with state yN violates constraint with respect to an already labeled consider the prefix x1, x2, x3, x4, which contains no punctuation or newlines and was labeled AUTH, AUTH, DATE, DATE.

 $$$$$ To the best of our knowledge, we are the first to suggest a general semi-supervised protocol that is driven by soft constraints.
 $$$$$ Conceptually, although not technically, the most related work to ours is (Shen et al., 2005) that, in a somewhat ad-hoc manner uses soft constraints to guide an unsupervised model that was crafted for mention tracking.
 $$$$$ The dataset consists of 8,767 advertisements for apartment rentals in the San Francisco Bay Area downloaded in June 2004 from the Craigslist website.

(Chang et al 2007) incorporates domain specific constraints in semi-supervised learning. $$$$$ In the top-K version, the algorithm uses K-best predictions (K=50) for each instance in order to update the model as described in Figure 2.
(Chang et al 2007) incorporates domain specific constraints in semi-supervised learning. $$$$$ In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology (Cohen and Sarawagi, 2004; Collins and Singer, 1999; Haghighi and Klein, 2006; Thelen and Riloff, 2002).
(Chang et al 2007) incorporates domain specific constraints in semi-supervised learning. $$$$$ Moreover, our framework is a useful tool when the domain knowledge cannot be expressed by the model.
(Chang et al 2007) incorporates domain specific constraints in semi-supervised learning. $$$$$ The results show that constraints improve not only the performance of the final inference stage but also propagate useful information during the semisupervised learning process and that training with the constraints is especially significant when the number of labeled training data is small.

The learning algorithm in Figure 2 is an instance of augmented-loss training (Hall et al, 2011) which is closely related to the constraint driven learning algorithms of Chang et al (2007). $$$$$ In the experimental part of this paper we use HMMs as the underlying model, and exhibit significant reduction in the number of training examples required in two information extraction problems.
The learning algorithm in Figure 2 is an instance of augmented-loss training (Hall et al, 2011) which is closely related to the constraint driven learning algorithms of Chang et al (2007). $$$$$ Our experiments demonstrate that the proposed approach is robust to inaccurate approximation of the prior knowledge (assigning the same penalty to all the pi ).
The learning algorithm in Figure 2 is an instance of augmented-loss training (Hall et al, 2011) which is closely related to the constraint driven learning algorithms of Chang et al (2007). $$$$$ We also make use of soft constraints and, furthermore, extend the notion of soft constraints to account for multiple levels of constraints’ violation.
The learning algorithm in Figure 2 is an instance of augmented-loss training (Hall et al, 2011) which is closely related to the constraint driven learning algorithms of Chang et al (2007). $$$$$ The intuition behind (1) is as follows.

Note that the objective function in Equation 5, if written in the additive form, leads to a cost function reminiscent of the one used in constraint-driven learning algorithm (CoDL) (Chang et al, 2007) (and similarly, posterior regularization (Ganchev et al, 2010), which we will discuss later at Section 6). $$$$$ Acknowledgments: This work is supported by NSF SoDHCER-0613885 and by a grant from Boeing.
Note that the objective function in Equation 5, if written in the additive form, leads to a cost function reminiscent of the one used in constraint-driven learning algorithm (CoDL) (Chang et al, 2007) (and similarly, posterior regularization (Ganchev et al, 2010), which we will discuss later at Section 6). $$$$$ But, we develop a semi-supervised learning protocol based on this formalism.
Note that the objective function in Equation 5, if written in the additive form, leads to a cost function reminiscent of the one used in constraint-driven learning algorithm (CoDL) (Chang et al, 2007) (and similarly, posterior regularization (Ganchev et al, 2010), which we will discuss later at Section 6). $$$$$ The framework developed is general both in terms of the representation and expressiveness of the constraints, and in terms of the underlying model being learned – HMM in the current implementation.
Note that the objective function in Equation 5, if written in the additive form, leads to a cost function reminiscent of the one used in constraint-driven learning algorithm (CoDL) (Chang et al, 2007) (and similarly, posterior regularization (Ganchev et al, 2010), which we will discuss later at Section 6). $$$$$ We propose learning with constraints - a framework that combines the approaches described above in a unified and intuitive way.

Constraint-driven learning (CoDL) (Chang et al, 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. $$$$$ On the other hand, in the supervised setting, it has been shown that incorporating domain and problem specific structured information can result in substantial improvements (Toutanova et al., 2005; Roth and Yih, 2005).
Constraint-driven learning (CoDL) (Chang et al, 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. $$$$$ As is often the case in semi-supervised learning, the algorithm can be viewed as a process that improves the model by generating feedback through labeling unlabeled examples.
Constraint-driven learning (CoDL) (Chang et al, 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. $$$$$ For instance, the constraint C2 cannot be implemented with prefix information when the assignment is not complete.

Most semi-supervised learning algorithms rely on marginals (GE, Mann and McCallum, 2008) or MAP assignments (CODL, Chang et al, 2007). $$$$$ The core of our approach, (1), is described in Section 5.
Most semi-supervised learning algorithms rely on marginals (GE, Mann and McCallum, 2008) or MAP assignments (CODL, Chang et al, 2007). $$$$$ But, we develop a semi-supervised learning protocol based on this formalism.
Most semi-supervised learning algorithms rely on marginals (GE, Mann and McCallum, 2008) or MAP assignments (CODL, Chang et al, 2007). $$$$$ When they use their final model, along with a mechanism for extending the prototypes to other tokens, they get results that are comparable to our model with 10 labeled examples.
Most semi-supervised learning algorithms rely on marginals (GE, Mann and McCallum, 2008) or MAP assignments (CODL, Chang et al, 2007). $$$$$ (Nigam et al., 2000) has suggested to balance the contribution of labeled and unlabeled data to the parameters.

corresponds to constraint satisfaction weights used in (Chang et al, 2007). $$$$$ In the semi-supervised domain there are two main approaches for injecting domain specific knowledge.
corresponds to constraint satisfaction weights used in (Chang et al, 2007). $$$$$ The framework developed is general both in terms of the representation and expressiveness of the constraints, and in terms of the underlying model being learned – HMM in the current implementation.
corresponds to constraint satisfaction weights used in (Chang et al, 2007). $$$$$ However, as shown, our proposed algorithm H&W&C for training with constraints is critical when the amount labeled data is small.
corresponds to constraint satisfaction weights used in (Chang et al, 2007). $$$$$ However, in the general case, semi-supervised approaches give mixed results, and sometimes even degrade the model performance (Nigam et al., 2000).

Chang et al propose constraint-driven learning (CODL, Chang et al, 2007) which can be interpreted as a variation of self-training: Instances are selected for supervision based not only on the model's prediction, but also on their consistency with a set of user-defined constraints. $$$$$ The case of one iteration of top-1 hard EM is equivalent to self training, where all the unlabeled samples are added to the labeled pool.
Chang et al propose constraint-driven learning (CODL, Chang et al, 2007) which can be interpreted as a variation of self-training: Instances are selected for supervision based not only on the model's prediction, but also on their consistency with a set of user-defined constraints. $$$$$ In this paper, we suggest a method for incorporating domain knowledge in semi-supervised learning algorithms.
Chang et al propose constraint-driven learning (CODL, Chang et al, 2007) which can be interpreted as a variation of self-training: Instances are selected for supervision based not only on the model's prediction, but also on their consistency with a set of user-defined constraints. $$$$$ In our framework, dictionary lookup approaches are viewed as unary constraints on the output states.
Chang et al propose constraint-driven learning (CODL, Chang et al, 2007) which can be interpreted as a variation of self-training: Instances are selected for supervision based not only on the model's prediction, but also on their consistency with a set of user-defined constraints. $$$$$ We propose learning with constraints - a framework that combines the approaches described above in a unified and intuitive way.

We use the same token label constraints as Chang et al (2007). $$$$$ When the constraint violation penalty p was infinity (equivalent to hard constraint), the accuracy improved to 78.7%, but when the penalty was set to −log(0.1), the accuracy of the model jumped to 80.6%.
We use the same token label constraints as Chang et al (2007). $$$$$ In the semi-supervised domain there are two main approaches for injecting domain specific knowledge.
We use the same token label constraints as Chang et al (2007). $$$$$ We experimented with two flavors of the algorithm: the top-1 and the top-K version.
We use the same token label constraints as Chang et al (2007). $$$$$ We develop a formalism for constraints-based learning that unifies several kinds of constraints: unary, dictionary based and n-ary constraints, which encode structural information and interdependencies among possible labels.

We also report supervised results from (Chang et al, 2007) and SampleRank. $$$$$ The set of constraints we used in our experiments appears in Table 1.
We also report supervised results from (Chang et al, 2007) and SampleRank. $$$$$ In the citations domain, H&W&C+I achieves with 20 labeled samples similar performance to the supervised version without constraints with 300 labeled samples.
We also report supervised results from (Chang et al, 2007) and SampleRank. $$$$$ In our case we used the topK elements in the beam, but this could be applied to any other inference procedure.
We also report supervised results from (Chang et al, 2007) and SampleRank. $$$$$ A second approach has been to use a small highaccuracy set of labeled tokens as a way to seed and bootstrap the semi-supervised learning.
