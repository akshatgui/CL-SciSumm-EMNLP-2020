(Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for Information Retrieval purposes, in particular the lack of domain information and the fact that sense distinctions are excessively fine-grained for the task. $$$$$ In of 17th International Conference on Research and Development in Information Retrieval.
(Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for Information Retrieval purposes, in particular the lack of domain information and the fact that sense distinctions are excessively fine-grained for the task. $$$$$ We produced different versions of the synset indexed collection. introducing fixed percentages of erroneous synsets.
(Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for Information Retrieval purposes, in particular the lack of domain information and the fact that sense distinctions are excessively fine-grained for the task. $$$$$ In this case, it is a noun belonging to the noun.communication file.

Then, following previous studies (e.g., (Gonzaloet al, 1998)), we use the synsets relations in Word Net for query expansion. $$$$$ While his results are very interesting, it remains unclear, in our opinion, whether they would be corroborated with real occurrences of ambiguous words.
Then, following previous studies (e.g., (Gonzaloet al, 1998)), we use the synsets relations in Word Net for query expansion. $$$$$ We also generated a list of &quot;stop-senses&quot; and a list of &quot;stop-synsets&quot;, automatically translating a standard list of stop words for English.
Then, following previous studies (e.g., (Gonzaloet al, 1998)), we use the synsets relations in Word Net for query expansion. $$$$$ Moreover, what he understands as disambiguating is selecting -in the example- bank or spring which remain to be ambiguous words themselves.
Then, following previous studies (e.g., (Gonzaloet al, 1998)), we use the synsets relations in Word Net for query expansion. $$$$$ We are indebted to Renee Pohlmann for giving us good pointers at an early stage of this work, and to AnseImo Peilas and David Fernandez for their help finishing up the test collection.

The LKB can be used, among others, for monolingual and cross-lingual information retrieval, which has been demonstrated in other projects (Gonzalo et al, 1998). $$$$$ &quot;{argument, debatel}&quot; (a discussion in which reasons are advanced for and against some proposition or proposal; &quot;the argument over foreign aid goes on and on&quot;) This collection represents conceptual indexing, as equivalent word senses are represented with a unique identifier.
The LKB can be used, among others, for monolingual and cross-lingual information retrieval, which has been demonstrated in other projects (Gonzalo et al, 1998). $$$$$ With this set of experiments we can measure the sensitivity of the retrieval process to disambiguation errors.
The LKB can be used, among others, for monolingual and cross-lingual information retrieval, which has been demonstrated in other projects (Gonzalo et al, 1998). $$$$$ Thus we only report here on the results for nnn weighting scheme.
The LKB can be used, among others, for monolingual and cross-lingual information retrieval, which has been demonstrated in other projects (Gonzalo et al, 1998). $$$$$ Query relations.

Gonzalo et al (1998) cite this failure to model related senses in order to explain why their study into the effects of ambiguity showed radically different results to Sanderson (1994). $$$$$ Proceedings of the International Conference on Research and Development in IR.
Gonzalo et al (1998) cite this failure to model related senses in order to explain why their study into the effects of ambiguity showed radically different results to Sanderson (1994). $$$$$ For instance, it could be used to evaluate automatic summarization systems (measuring the semantic relation between the manually written and hand-tagged summaries of IRSEMCOR and the output of text summarization systems) and other related tasks.
Gonzalo et al (1998) cite this failure to model related senses in order to explain why their study into the effects of ambiguity showed radically different results to Sanderson (1994). $$$$$ In Proceedings of TREC-4.
Gonzalo et al (1998) cite this failure to model related senses in order to explain why their study into the effects of ambiguity showed radically different results to Sanderson (1994). $$$$$ The answer to the first question is that indexing by synsets can be very helpful for text retrieval; our experiments give up to a 29% improvement over a standard SMART run indexing with words.

Gonzalo et al (1998) showed in an experiment, where words were manually disambiguated, that a substantial increase in performance is obtained when query words are disambiguated, before they are expanded. $$$$$ This research is being supported by the European Community, project LE #4003 and also partially by the Spanish government, project TIC-96-1243-0O3-01.
Gonzalo et al (1998) showed in an experiment, where words were manually disambiguated, that a substantial increase in performance is obtained when query words are disambiguated, before they are expanded. $$$$$ 1994.
Gonzalo et al (1998) showed in an experiment, where words were manually disambiguated, that a substantial increase in performance is obtained when query words are disambiguated, before they are expanded. $$$$$ It is too soon to say if state-of-the-art WSD techniques can perform with less than 30% errors, because each technique is evaluated in fairly different settings.
Gonzalo et al (1998) showed in an experiment, where words were manually disambiguated, that a substantial increase in performance is obtained when query words are disambiguated, before they are expanded. $$$$$ TREC-4 experiments at dublin city university: Thresolding posting lists, query expansion with and POS tagging of spanish.

(Gonzalo et al, 1998) demonstrates an increment in performance over an IR test collection using the sense data contained in SemCor over a purely term based model. $$$$$ The next point represents the documents retrieved as the first or the second most relevant to its summary/query, and so on.
(Gonzalo et al, 1998) demonstrates an increment in performance over an IR test collection using the sense data contained in SemCor over a purely term based model. $$$$$ Thus, indexing by synsets gets maximum matching and minimum spurious matching, seeming a good starting point to study text retrieval with WordNet.
(Gonzalo et al, 1998) demonstrates an increment in performance over an IR test collection using the sense data contained in SemCor over a purely term based model. $$$$$ These summaries serve as queries on the text collection, and then there is exactly one relevant document per query.

The KB can be used, among others, for monolingual and cross-lingual information retrieval, which was demonstrated by (Gonzalo et al, 1998). $$$$$ Nevertheless, it shows that WordNet can greatly enhance text retrieval: the problem resides in achieving accurate automatic Word Sense Disambiguation.
The KB can be used, among others, for monolingual and cross-lingual information retrieval, which was demonstrated by (Gonzalo et al, 1998). $$$$$ We are indebted to Renee Pohlmann for giving us good pointers at an early stage of this work, and to AnseImo Peilas and David Fernandez for their help finishing up the test collection.
The KB can be used, among others, for monolingual and cross-lingual information retrieval, which was demonstrated by (Gonzalo et al, 1998). $$$$$ We believe that these results have to be further contrasted, but they strongly suggest that WordNet can be more useful to Text Retrieval than it was previously thought.

In another work, Gonzalo et al (1998) used a manually sense annotated corpus, SemCor, to study the effects of incorrect disambiguation. $$$$$ They reach a 58.7% accuracy on a Brown Corpus subset and a 75.2% on a subset of the Wall Street Journal Corpus.
In another work, Gonzalo et al (1998) used a manually sense annotated corpus, SemCor, to study the effects of incorrect disambiguation. $$$$$ This is not a major problem in an interactive system that may help the user to disambiguate his query, but it must be taken into account if the process is not interactive and the query is too short to do reliable disambiguation.
In another work, Gonzalo et al (1998) used a manually sense annotated corpus, SemCor, to study the effects of incorrect disambiguation. $$$$$ We are indebted to Renee Pohlmann for giving us good pointers at an early stage of this work, and to AnseImo Peilas and David Fernandez for their help finishing up the test collection.
In another work, Gonzalo et al (1998) used a manually sense annotated corpus, SemCor, to study the effects of incorrect disambiguation. $$$$$ This research is being supported by the European Community, project LE #4003 and also partially by the Spanish government, project TIC-96-1243-0O3-01.
