Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ We present a method that makes local analogies between each specific unobserved cooccurrence and other cooccurrences that contain similar words, as determined by an appropriate word similarity metric.
Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ The search is based on the property that when computing sim(wi w2), words that have high mutual information values 'The nominator in our metric resembles the similarity metric in (Hindle, 1990).
Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ We are grateful to Alon Itai for his help in initiating this research.
Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ This is because the individual frequencies of all participating words are within the same range of values.

As to the research on computing word sense relatedness, Dagan et al (1993) did some pilot work and Lee (1997) and Resnik (1999) contributed to the research on semantic similarity. $$$$$ This raises the question whether generalizations over word classes, which follow long traditions in semantic classification, indeed provide the best means for inferencing about properties of words.
As to the research on computing word sense relatedness, Dagan et al (1993) did some pilot work and Lee (1997) and Resnik (1999) contributed to the research on semantic similarity. $$$$$ The mathematical formulations, though, are presented in terms of the general case.
As to the research on computing word sense relatedness, Dagan et al (1993) did some pilot work and Lee (1997) and Resnik (1999) contributed to the research on semantic similarity. $$$$$ Our evaluation suggests that this method performs better than existing smoothing methods, and may provide an alternative to class based models.

In (Dagan et al., 1993) and (Pereira et al, 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time. $$$$$ We present a method that makes local analogies between each specific unobserved cooccurrence and other cooccurrences that contain similar words, as determined by an appropriate word similarity metric.
In (Dagan et al., 1993) and (Pereira et al, 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time. $$$$$ Comparing with class based models, our approach suggests the advantage of making the most specific analogies for each word, instead of making analogies with all members of a class, via general class parameters.
In (Dagan et al., 1993) and (Pereira et al, 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time. $$$$$ The mutual information of a cooccurrence pair, which measures the degree of association between the two words (Church and Hanks, 1990), is defined as (Fano, 1961): where P(z) and P(y) are the probabilities of the events x and y (occurrences of words, in our case) and P (x , y) is the probability of the joint event (a cooccurrence pair).
