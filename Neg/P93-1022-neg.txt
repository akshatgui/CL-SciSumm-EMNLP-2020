Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ We also set i (x , y) to 0 if f (x y) = 0.
Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ We are grateful to Alon Itai for his help in initiating this research.
Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ Using these weights, we get the weighted average in Figure 2 as the general definition of 41n the case of cooccurrence pairs, a word may be involved in two types of relations, being the left or right argument of the pair.
Dagan et al (1993) argue that using a relatively small number of classes to model the similarity between words may lead to substantial loss of information. $$$$$ Frequency based estimation, on the other hand, makes a much poorer distinction between the two sets.

As to the research on computing word sense relatedness, Dagan et al (1993) did some pilot work and Lee (1997) and Resnik (1999) contributed to the research on semantic similarity. $$$$$ This represents the assumption that the word 'describes' is associated with the word 'chapter' to a similar extent as it is associated with the words 'introduction', 'book' and 'section'.
As to the research on computing word sense relatedness, Dagan et al (1993) did some pilot work and Lee (1997) and Resnik (1999) contributed to the research on semantic similarity. $$$$$ The purpose of the first evaluation was to test whether the similarity based estimation method can enhance the performance of a disambiguation technique.
As to the research on computing word sense relatedness, Dagan et al (1993) did some pilot work and Lee (1997) and Resnik (1999) contributed to the research on semantic similarity. $$$$$ This indicates that when trying to estimate cooccurrence probabilities, it is useful to consider the cooccurrence patterns of the specific words and not just their frequencies, as smoothing methods do.

In (Dagan et al., 1993) and (Pereira et al, 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time. $$$$$ This special case is less susceptible to noise than unrestricted similarity, as we replace only one of the words in the pair.
In (Dagan et al., 1993) and (Pereira et al, 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time. $$$$$ We estimate mutual information values using the Maximum Likelihood Estimator (MLE): d 4 (Y) (2) where f denotes the frequency of an event and N is the length of the corpus.
In (Dagan et al., 1993) and (Pereira et al, 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time. $$$$$ Our evaluation suggests that this method performs better than existing smoothing methods, and may provide an alternative to class based models.
In (Dagan et al., 1993) and (Pereira et al, 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time. $$$$$ This paper discusses how to estimate the probability of cooccurrences that do not occur in the training data.
