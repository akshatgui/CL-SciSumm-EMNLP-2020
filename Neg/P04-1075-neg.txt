It is only recently employed in NER (Shen et al, 2004). $$$$$ The results of the named entity recognition in both MUC-6 and GENIA show that the labeling cost can be reduced by at least 80% without degrading the performance.
It is only recently employed in NER (Shen et al, 2004). $$$$$ We build two strategies to combine the measures proposed above.
It is only recently employed in NER (Shen et al, 2004). $$$$$ (26K words) 8004 sent.
It is only recently employed in NER (Shen et al, 2004). $$$$$ However, he didn’t further explore how to avoid selecting outliers to a batch.

This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ Diversity criterion is to maximize the training utility of a batch.
This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ The goal of DTW is to find a path, m = map(n), which map n onto the corresponding m such that the accumulated similarity Sim* along the path is maximized. map n n= A dynamic programming method is used to determine the optimum path map(n).
This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ Active learning targets to minimize the human annotation efforts by selecting examples for labeling.
This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ So far, we haven’t found any previous work integrating the informativeness, representativeness and diversity all together.

In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ Our informativeness-based measure is similar to these works.
In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ First, we propose three scoring functions to quantify the informativeness of an example, which can be used to select the most uncertain examples.
In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ Since there is no study on active learning for NER task previously, we only introduce general active learning methods here.
In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ In order to evaluate the effectiveness of our selection strategies, we apply them to recognize protein (PRT) names in biomedical domain using GENIA corpus V1.1 (Ohta et al. 2002) and person (PER), location (LOC), organization (ORG) names in newswire domain using MUC-6 corpus.

 $$$$$ So, the algorithm is time-consuming.
 $$$$$ It is more efficient than clustering algorithm described in Section 2.3.1.
 $$$$$ The accumulated similarity SimA to any grid point (n, m) can be recursively calculated as Certainly, the overall similarity measure Sim* has to be normalized as longer sequences normally give higher similarity value.

Given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (Morgan et al, 2004) or semi-automatically (active learning approaches like Shen et al (2004) or systems using seed rules such as Mikheev et al. $$$$$ For example, given the batch size 5, we try not to select five repetitious examples at a time.
Given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (Morgan et al, 2004) or semi-automatically (active learning approaches like Shen et al (2004) or systems using seed rules such as Mikheev et al. $$$$$ In Figure 5, the horizontal line is the performance level (63.3 F-measure) achieved by supervised learning (223K words).
Given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (Morgan et al, 2004) or semi-automatically (active learning approaches like Shen et al (2004) or systems using seed rules such as Mikheev et al. $$$$$ The experiment shows that our active learning methods achieve a promising result in this NER task.

Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ In this paper, we propose a multi-criteriabased active learning approach and effectively apply it to named entity recognition.
Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ In this paper, we propose a multi-criteriabased active learning approach and effectively apply it to named entity recognition.
Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ .., NEN} BatchSet with the maximal size K. INTERSet with the maximal size M Steps: which the Info and Density value of NEi are normalized first.
Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ (277 words) 900 sent.

Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ Domain Class Corpus Initial Training Set Test Set Unlabeled Set Biomedical PRT GENIA1.1 10 sent.
Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ These strategies are based on the varying priorities of the criteria and the varying degrees to satisfy the criteria. most informativeness score from NESet to an intermediate set called INTERSet.
Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ SVM training is to get these support vectors and their weights from training set by solving quadratic programming problem.
Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ Many existing work in the area focus on two approaches: certainty-based methods (Thompson et al. 1999; Tang et al.

It has been applied to various NLP/IE tasks, including named entity recognition (Shen et al, 2004) and parse selection (Baldridge and Osborne, 2004) with rather impressive results in reducing the amount of annotated training data. $$$$$ Practically, a batch of examples are selected at a time, called batchedbased sample selection (Lewis and Catlett 1994) since it is time consuming to retrain the model if only one new example is added to the training set.
It has been applied to various NLP/IE tasks, including named entity recognition (Shen et al, 2004) and parse selection (Baldridge and Osborne, 2004) with rather impressive results in reducing the amount of annotated training data. $$$$$ In practical application, the optimal value of these parameters should be decided automatically based on the training process.
It has been applied to various NLP/IE tasks, including named entity recognition (Shen et al, 2004) and parse selection (Baldridge and Osborne, 2004) with rather impressive results in reducing the amount of annotated training data. $$$$$ However these works just follow a single criterion.

In order to circumvent this obstacle several approaches have been presented, among them active learning (Shen et al, 2004) and rule-based systems encoding domain specific knowledge (Gaizauskas et al, 2003). $$$$$ However, annotating such corpus is expensive and timeconsuming, which makes it difficult to adapt an existing model to a new domain.
In order to circumvent this obstacle several approaches have been presented, among them active learning (Shen et al, 2004) and rule-based systems encoding domain specific knowledge (Gaizauskas et al, 2003). $$$$$ To maximize the contribution of the selected examples, we the multiple criteria: informativepropose measures to quantify them.
In order to circumvent this obstacle several approaches have been presented, among them active learning (Shen et al, 2004) and rule-based systems encoding domain specific knowledge (Gaizauskas et al, 2003). $$$$$ We make the comparisons in GENIA corpus.

Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ Many existing active learning methods are to select the most uncertain examples using various measures (Thompson et al. 1999; Schohn and Cohn 2000; Tong and Koller 2000; Engelson and Dagan 1999; Ngai and Yarowsky 2000).
Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ We build two strategies to combine the measures proposed above.
Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ By this means, we consider representativeness and diversity criteria at the same time.
Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ The results of the named entity recognition in both MUC-6 and GENIA show that the labeling cost can be reduced by at least 80% without degrading the performance.

Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ One limitation of this strategy is that clustering result may not reflect the distribution of whole sample space since we only cluster on INTERSet for efficiency.
Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ Another interesting work is to study when to stop active learning.
Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ We propose a multi-criteria-based approach to select examples based on their informativeness, representativeness and diversity, which are incorporated all together by two strategies (local and global).
Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ So far, we haven’t found any previous work integrating the informativeness, representativeness and diversity all together.

(Collins and Singer, 1999) classified NEs through co-training, (Kozareva et al, 2005a) used self-training and co-training to detect and classify named entities in news domain, (Shen et al, 2004) conducted experiments with multi-criteria-based active learning for biomedical NER. $$$$$ NE1 and NE2 consist of M and N words respectively.
(Collins and Singer, 1999) classified NEs through co-training, (Kozareva et al, 2005a) used self-training and co-training to detect and classify named entities in news domain, (Shen et al, 2004) conducted experiments with multi-criteria-based active learning for biomedical NER. $$$$$ Then we cluster the examples in INTERSet and choose the centroid of each cluster into a batch called BatchSet.
(Collins and Singer, 1999) classified NEs through co-training, (Kozareva et al, 2005a) used self-training and co-training to detect and classify named entities in news domain, (Shen et al, 2004) conducted experiments with multi-criteria-based active learning for biomedical NER. $$$$$ To our best knowledge, this is not only the first work to report the empirical results of active learning for NER, but also the first work to incorporate the three criteria all together for selecting examples.
(Collins and Singer, 1999) classified NEs through co-training, (Kozareva et al, 2005a) used self-training and co-training to detect and classify named entities in news domain, (Shen et al, 2004) conducted experiments with multi-criteria-based active learning for biomedical NER. $$$$$ Active learning targets to minimize the human annotation efforts by selecting examples for labeling.

 $$$$$ Many existing active learning methods are to select the most uncertain examples using various measures (Thompson et al. 1999; Schohn and Cohn 2000; Tong and Koller 2000; Engelson and Dagan 1999; Ngai and Yarowsky 2000).
 $$$$$ More comprehensively, we incorporate all the criteria using two selection strategies, both of which result in less labeling cost than single-criterion-based method.
 $$$$$ .., NEN} BatchSet with the maximal size K. INTERSet with the maximal size M Steps: which the Info and Density value of NEi are normalized first.
 $$$$$ Our informativeness-based measure is similar to these works.

Shen et al (2004) proposed an approach to selecting examples based on informativeness, representativeness and diversity criteria. $$$$$ In this paper, we propose a multi-criteriabased active learning approach and effectively apply it to named entity recognition.
Shen et al (2004) proposed an approach to selecting examples based on informativeness, representativeness and diversity criteria. $$$$$ In this paper, we propose a multi-criteriabased active learning approach and effectively apply it to named entity recognition.
Shen et al (2004) proposed an approach to selecting examples based on informativeness, representativeness and diversity criteria. $$$$$ By this means, we consider representativeness and diversity criteria at the same time.
Shen et al (2004) proposed an approach to selecting examples based on informativeness, representativeness and diversity criteria. $$$$$ In practical application, the optimal value of these parameters should be decided automatically based on the training process.
