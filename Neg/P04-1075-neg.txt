It is only recently employed in NER (Shen et al, 2004). $$$$$ The results of the named entity recognition in both MUC-6 and GENIA show that the labeling cost can be reduced by at least 80% without degrading the performance.
It is only recently employed in NER (Shen et al, 2004). $$$$$ The experiment shows that our active learning methods achieve a promising result in this NER task.
It is only recently employed in NER (Shen et al, 2004). $$$$$ Then we cluster the examples in INTERSet and choose the centroid of each cluster into a batch called BatchSet.

This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ The density of NEi is defined as the average similarity between NEi and all the other entities NEj in NESet as follows.
This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ Different from supervised learning in which the entire corpus are labeled manually, active learning is to select the most useful example for labeling and add the labeled example to training set to retrain model.
This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ Finally, two combination strategies with the above three criteria are proposed to reach the maximum effectiveness on active learning for NER.
This issue was previously addressed in Shen et al (2004) in the context of named-entity recognition, where they used a two-step procedure to first select the most informative and representative samples, followed by a diversity filter. $$$$$ In addition to the informativeness criterion, we further incorporate representativeness and diversity criteria into active learning using two strategies described in Section 3.

In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ In the machine learning approaches of natural language processing (NLP), models are generally trained on large annotated corpus.
In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ Domain Class Corpus Initial Training Set Test Set Unlabeled Set Biomedical PRT GENIA1.1 10 sent.
In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ To maximize the contribution of the selected examples, we the multiple criteria: informativepropose measures to quantify them.
In a more recent study, Shen et al (2004) consider AL for entity recognition based on Support Vector Machines. $$$$$ (26K words) 8004 sent.

 $$$$$ (277 words) 900 sent.
 $$$$$ .., NEN}, the representativeness of a named entity NEi in NESet is quantified by its density.
 $$$$$ Third, we propose two diversity considerations (global and local) to avoid repetition among the examples of a batch.
 $$$$$ In Figure 5, the horizontal line is the performance level (63.3 F-measure) achieved by supervised learning (223K words).

Given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (Morgan et al, 2004) or semi-automatically (active learning approaches like Shen et al (2004) or systems using seed rules such as Mikheev et al. $$$$$ So far, we havenâ€™t found any previous work integrating the informativeness, representativeness and diversity all together.
Given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (Morgan et al, 2004) or semi-automatically (active learning approaches like Shen et al (2004) or systems using seed rules such as Mikheev et al. $$$$$ Many existing active learning methods are to select the most uncertain examples using various measures (Thompson et al. 1999; Schohn and Cohn 2000; Tong and Koller 2000; Engelson and Dagan 1999; Ngai and Yarowsky 2000).
Given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (Morgan et al, 2004) or semi-automatically (active learning approaches like Shen et al (2004) or systems using seed rules such as Mikheev et al. $$$$$ The basic idea of informativeness criterion is similar to certainty-based sample selection methods, which have been used in many previous works.
Given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (Morgan et al, 2004) or semi-automatically (active learning approaches like Shen et al (2004) or systems using seed rules such as Mikheev et al. $$$$$ Each example is defined as a machine-recognized named entity and its context words (previous 3 words and next 3 words).

Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ In this paper, we propose a multi-criteriabased active learning approach and effectively apply it to named entity recognition.
Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ Adding them to the training set will have effect on a large number of unlabeled examples.
Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ Based on the assumption that N examples are uniformly distributed between the K clusters, the time complexity of the algorithm is about O(N2/K+NK) (Tang et al. 2002).
Active learning, which has been applied to the problem of NER in (Shen et al, 2004), is used in situations where a large amount of unlabeled data exists and data labeling is expensive. $$$$$ Active learning targets to minimize the human annotation efforts by selecting examples for labeling.

Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ To maximize the contribution of the selected examples, we the multiple criteria: informativepropose measures to quantify them.
Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ (McCallum and Nigam 1998; Tang et al. 2002) are the only two works considering the representativeness criterion in active learning.
Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ The representativeness of an example can be evaluated based on how many examples there are similar or near to it.
Diversity measures as proposed by (Shen et al, 2004) might help in mitigating this effect, but our experiments show that there are fundamental differences between text classification and NER. $$$$$ Furthermore, the examples in different clusters may be considered diverse to each other.

It has been applied to various NLP/IE tasks, including named entity recognition (Shen et al, 2004) and parse selection (Baldridge and Osborne, 2004) with rather impressive results in reducing the amount of annotated training data. $$$$$ 2003), noun phrase chunking (Ngai and Yarowsky 2000), etc.
It has been applied to various NLP/IE tasks, including named entity recognition (Shen et al, 2004) and parse selection (Baldridge and Osborne, 2004) with rather impressive results in reducing the amount of annotated training data. $$$$$ In the next part, we will introduce informativeness, representativeness and diversity measures for the SVM-based NER.
It has been applied to various NLP/IE tasks, including named entity recognition (Shen et al, 2004) and parse selection (Baldridge and Osborne, 2004) with rather impressive results in reducing the amount of annotated training data. $$$$$ Second, the representativeness measure is further proposed to choose the examples representing the majority.

In order to circumvent this obstacle several approaches have been presented, among them active learning (Shen et al, 2004) and rule-based systems encoding domain specific knowledge (Gaizauskas et al, 2003). $$$$$ The smaller the angle is, the more similar between the vectors are.
In order to circumvent this obstacle several approaches have been presented, among them active learning (Shen et al, 2004) and rule-based systems encoding domain specific knowledge (Gaizauskas et al, 2003). $$$$$ The centroid of a cluster is the most representative example in that cluster since it has the largest density.
In order to circumvent this obstacle several approaches have been presented, among them active learning (Shen et al, 2004) and rule-based systems encoding domain specific knowledge (Gaizauskas et al, 2003). $$$$$ We add the candidate example NEi to a batch only if NEi is different enough from any previously selected example in the batch.
In order to circumvent this obstacle several approaches have been presented, among them active learning (Shen et al, 2004) and rule-based systems encoding domain specific knowledge (Gaizauskas et al, 2003). $$$$$ The margin is defined by the distance of the hyperplane to the nearest of the positive and negative examples.

Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ The individual importance of each criterion in this function is adjusted by the tradeoff parameter l ( 0 â‰¤ l â‰¤1 ) (set to 0.6 in our experiment).
Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ In this section, we will study how to combine and strike a proper balance between these criteria, viz. informativeness, representativeness and diversity, to reach the maximum effectiveness on NER active learning.
Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ However these works just follow a single criterion.
Shen et al (2004) combine multiple criteria to measure the informativeness, representativeness, and diversity of examples in active learning for named entity recognition. $$$$$ Therefore, all of the measures we propose for active learning should be applied to the machineannotated named entities and we have to further study how to extend the measures for words to named entities.

Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ In the beginning iterations (F-measure < 60), the three methods performed similarly.
Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ The results of the named entity recognition in both MUC-6 and GENIA show that the labeling cost can be reduced by at least 80% without degrading the performance.
Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ Another interesting work is to study when to stop active learning.
Therefore, in order to avoid recursion and over-complexity, we employ a diversity-motivated intra-stratum sampling scheme (Shen et al, 2004), called KDN (K-diverse neighbors), which aims to maximize the training utility of all seeds from a stratum. $$$$$ However these works just follow a single criterion.

(Collins and Singer, 1999) classified NEs through co-training, (Kozareva et al, 2005a) used self-training and co-training to detect and classify named entities in news domain, (Shen et al, 2004) conducted experiments with multi-criteria-based active learning for biomedical NER. $$$$$ This procedure is repeated until the model achieves a certain level of performance.
(Collins and Singer, 1999) classified NEs through co-training, (Kozareva et al, 2005a) used self-training and co-training to detect and classify named entities in news domain, (Shen et al, 2004) conducted experiments with multi-criteria-based active learning for biomedical NER. $$$$$ Comparing the two strategies with the best result of the single-criterionbased selection methods Info_Min, we are to justify that representativeness and diversity are also important factors for active learning.
(Collins and Singer, 1999) classified NEs through co-training, (Kozareva et al, 2005a) used self-training and co-training to detect and classify named entities in news domain, (Shen et al, 2004) conducted experiments with multi-criteria-based active learning for biomedical NER. $$$$$ This assumption is valid in most NLP tasks.

 $$$$$ Different from supervised learning in which the entire corpus are labeled manually, active learning is to select the most useful example for labeling and add the labeled example to training set to retrain model.
 $$$$$ The margin is defined by the distance of the hyperplane to the nearest of the positive and negative examples.
 $$$$$ In this section, we evaluate our selection strategies by comparing them with a random selection method, in which a batch of examples is randomly selected iteratively, on GENIA and MUC-6 corpus.
 $$$$$ The contributions not only come from the above measures, but also the two sample selection strategies which effectively incorporate informativeness, representativeness and diversity criteria.

Shen et al (2004) proposed an approach to selecting examples based on informativeness, representativeness and diversity criteria. $$$$$ More comprehensively, we incorporate all the criteria using two selection strategies, both of which result in less labeling cost than single-criterion-based method.
Shen et al (2004) proposed an approach to selecting examples based on informativeness, representativeness and diversity criteria. $$$$$ By this means, we consider representativeness and diversity criteria at the same time.
Shen et al (2004) proposed an approach to selecting examples based on informativeness, representativeness and diversity criteria. $$$$$ In this paper, we propose a multi-criteriabased active learning approach and effectively apply it to named entity recognition.
