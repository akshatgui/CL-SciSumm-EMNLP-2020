The OVIS annotations are in contrast with other corpora and systems (e.g. Miller et al. 1996), in that our annotation convention exploits the Principle of Compositionality of Meaning. $$$$$ Second, ATIS provides an existing evaluation methodology, complete with independent training and test corpora, and scoring programs.
The OVIS annotations are in contrast with other corpora and systems (e.g. Miller et al. 1996), in that our annotation convention exploits the Principle of Compositionality of Meaning. $$$$$ We have presented a fully trained statistical natural language interface system, with separate models corresponding to the classical processing steps of parsing, semantic interpretation and discourse.
The OVIS annotations are in contrast with other corpora and systems (e.g. Miller et al. 1996), in that our annotation convention exploits the Principle of Compositionality of Meaning. $$$$$ We have evaluated our system on the same blind test sets used in the ARPA evaluations (Pallett et al. 1995), and present a preliminary result at the conclusion of this paper.
The OVIS annotations are in contrast with other corpora and systems (e.g. Miller et al. 1996), in that our annotation convention exploits the Principle of Compositionality of Meaning. $$$$$ Each of these stages is modeled as a statistical process.

This use of model-theoretic interpretation represents an important extension to thesemantic grammars used in existing statistical spoken language interfaces, which rely on co-occurrences among lexically-determined semantic classes and slot fillers (Miller et al, 1996), in that the probability of an analysis is now also conditioned on the existence of denoted entities and relations in the world model. $$$$$ The models are fully integrated, resulting in an end-to-end system that maps input utterances into meaning representation frames.
This use of model-theoretic interpretation represents an important extension to thesemantic grammars used in existing statistical spoken language interfaces, which rely on co-occurrences among lexically-determined semantic classes and slot fillers (Miller et al, 1996), in that the probability of an analysis is now also conditioned on the existence of denoted entities and relations in the world model. $$$$$ P(location/pp I arrivaL/vp-head, arrival/vp) is the probability of a location/pp following an arrivaMvphead within an arrivallvp constituent. probability along the path corresponding to T. Transition probabilities are estimated directly by observing occurrence and transition frequencies in a training corpus of annotated parse trees.
This use of model-theoretic interpretation represents an important extension to thesemantic grammars used in existing statistical spoken language interfaces, which rely on co-occurrences among lexically-determined semantic classes and slot fillers (Miller et al, 1996), in that the probability of an analysis is now also conditioned on the existence of denoted entities and relations in the world model. $$$$$ The implementation and integration of these elements is far less conventional.
This use of model-theoretic interpretation represents an important extension to thesemantic grammars used in existing statistical spoken language interfaces, which rely on co-occurrences among lexically-determined semantic classes and slot fillers (Miller et al, 1996), in that the probability of an analysis is now also conditioned on the existence of denoted entities and relations in the world model. $$$$$ We have presented a fully trained statistical natural language interface system, with separate models corresponding to the classical processing steps of parsing, semantic interpretation and discourse.

Examples include an early statistical method for learning to fill slot-value representations (Miller et al, 1996) and a more recent approach for recovering semantic parse trees (Ge & Mooney, 2006). $$$$$ In this test, the system was trained on approximately 4000 ATIS 2 and ATIS 3 sentences, and then evaluated on the December 1994 test material (which was held aside as a blind test set).
Examples include an early statistical method for learning to fill slot-value representations (Miller et al, 1996) and a more recent approach for recovering semantic parse trees (Ge & Mooney, 2006). $$$$$ Much work remains to be done in order to refine the statistical modeling techniques, and to extend the
Examples include an early statistical method for learning to fill slot-value representations (Miller et al, 1996) and a more recent approach for recovering semantic parse trees (Ge & Mooney, 2006). $$$$$ Each of these stages is modeled as a statistical process.
Examples include an early statistical method for learning to fill slot-value representations (Miller et al, 1996) and a more recent approach for recovering semantic parse trees (Ge & Mooney, 2006). $$$$$ The discourse history H simply consists of the list of all postdiscourse frame representations for all previous utterances in the current session with the system.

An influential precursor to this integration is the system described in (Miller et al, 1996). $$$$$ Work on the system is ongoing, however, and interested parties are encouraged to contact the authors for more recent results.
An influential precursor to this integration is the system described in (Miller et al, 1996). $$$$$ Much work remains to be done in order to refine the statistical modeling techniques, and to extend the

We are only aware of one system that learns to construct context-dependent interpretations (Miller et al, 1996). $$$$$ Much work remains to be done in order to refine the statistical modeling techniques, and to extend the
We are only aware of one system that learns to construct context-dependent interpretations (Miller et al, 1996). $$$$$ NO0014-91-C-0115, and by Ft. Huachuca under Contract Nos.

The Miller et al (1996) approach is fully supervised and produces a final meaning representation in SQL. $$$$$ We present a natural language interface system which is based entirely on trained statistical models.
The Miller et al (1996) approach is fully supervised and produces a final meaning representation in SQL. $$$$$ Given a string of input words W and a discourse history H, the task of a statistical language understanding system is to search among the many possible discourse-dependent meanings MD for the most likely meaning Mo: Mo = arg max P(MD I W, H).
The Miller et al (1996) approach is fully supervised and produces a final meaning representation in SQL. $$$$$ A common approach in non-statistical natural language systems is to bridge this gap by introducing intermediate representations such as parse structure and pre-discourse sentence meaning.
The Miller et al (1996) approach is fully supervised and produces a final meaning representation in SQL. $$$$$ This assumption is justified because the word tags in our parse representation specify both semantic and syntactic class information.

Evaluation Metrics Miller et al (1996) report accuracy rates for recovering correct SQL annotations on the test set. $$$$$ Much work remains to be done in order to refine the statistical modeling techniques, and to extend the
Evaluation Metrics Miller et al (1996) report accuracy rates for recovering correct SQL annotations on the test set. $$$$$ DABT63-94-C-0061 and DABT63-94C-0063 .
Evaluation Metrics Miller et al (1996) report accuracy rates for recovering correct SQL annotations on the test set. $$$$$ Second, ATIS provides an existing evaluation methodology, complete with independent training and test corpora, and scoring programs.
Evaluation Metrics Miller et al (1996) report accuracy rates for recovering correct SQL annotations on the test set. $$$$$ In order to explore the space of possible parses efficiently, the parsing model is searched using a decoder based on an adaptation of the Earley parsing algorithm (Earley 1970).

In the domain of the Air Traveler Information System (Miller et al, 1996) the authors apply statistical methods to compute the probability that a constituent can fill in a semantic slot within a semantic frame. $$$$$ 3.
In the domain of the Air Traveler Information System (Miller et al, 1996) the authors apply statistical methods to compute the probability that a constituent can fill in a semantic slot within a semantic frame. $$$$$ This work was supported by the Advanced Research Projects Agency and monitored by the Office of Naval Research under Contract No.
In the domain of the Air Traveler Information System (Miller et al, 1996) the authors apply statistical methods to compute the probability that a constituent can fill in a semantic slot within a semantic frame. $$$$$ We have presented a fully trained statistical natural language interface system, with separate models corresponding to the classical processing steps of parsing, semantic interpretation and discourse.
In the domain of the Air Traveler Information System (Miller et al, 1996) the authors apply statistical methods to compute the probability that a constituent can fill in a semantic slot within a semantic frame. $$$$$ We now proceed to a detailed discussion of each of these three stages, beginning with parsing.

For example, in the context of the Air Traveler Information System (ATIS) for spoken dialogue, Miller et al (1996) computed the probability that a constituent such as Atlanta filled a semantic slot such as Destination in a semantic frame for air travel. $$$$$ This work was supported by the Advanced Research Projects Agency and monitored by the Office of Naval Research under Contract No.
For example, in the context of the Air Traveler Information System (ATIS) for spoken dialogue, Miller et al (1996) computed the probability that a constituent such as Atlanta filled a semantic slot such as Destination in a semantic frame for air travel. $$$$$ The system consists of three stages of processing: parsing, semantic interpretation, and discourse.
For example, in the context of the Air Traveler Information System (ATIS) for spoken dialogue, Miller et al (1996) computed the probability that a constituent such as Atlanta filled a semantic slot such as Destination in a semantic frame for air travel. $$$$$ The semantic,/syntactic character of this representation offers several advantages: /topÂ° /wh-question process: semantic labels identify the basic units of meaning, while syntactic structures help identify relationships between those units.
For example, in the context of the Air Traveler Information System (ATIS) for spoken dialogue, Miller et al (1996) computed the probability that a constituent such as Atlanta filled a semantic slot such as Destination in a semantic frame for air travel. $$$$$ These estimates are then smoothed to overcome sparse data limitations.
