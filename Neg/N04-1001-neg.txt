Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ In addition, the mention detection model crucially uses feature streams derived from different named entity classifiers.
Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ Pragmatically, we found segmenting Arabic text to be a necessary and beneficial process due mainly to two facts: Given these observations, we decided to “condition” the output of the system on the segmented data: the text is first segmented into tokens, and the classification is then performed on tokens.

However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ N66001-99-2-8916.
However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ The models for all three languages are built as joint models, simultaneously predicting the type, level and genericity of a mention – basically each mention is labeled with a 3-pronged tag.
However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ Let be the map from mention index to entity index.

We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ Each example has associated a vector of binary features .
We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ This statistical framework is general and can incorporate heterogeneous feature types — the models were built using a wide array of lexical, syntactic and semantic features extracted from texts, and further enhanced by adding the output of pre-existing semantic classifiers as feature streams; additional feature types help improve the performance significantly, especially in terms of ACE value.

In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ Entity detection and tracking is a relatively new addition to the repertoire of natural language tasks.
In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ Unlike the English case, the systems had access to only a small amount of training data (60k words for Arabic and 90k characters for Chinese, in contrast with 340k words for English), which made it difficult to train statistical models with large number of feature types.
In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ Second, the largest single improvement in ACE value is obtained by adding dictionary features, at least in this order of adding features.
In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ In this paper, we present a general statistical framework for entity detection and tracking in unrestricted text.

In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ In the comparative experiments for the mention detection and entity tracking tasks, the training data for the English system consists of the training data from both the 2002 evaluation and the 2003 evaluation, while for Arabic and Chinese, new additions to the ACE task in 2003, consists of 80% of the provided training data.
In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ Therefore, the problem of coreference resolution is equivalent to ranking the action sequences.
In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ The process works from left to right: it starts with an initial entity consisting of the first mention of a document, and the next mention is processed by either linking it with one of the existing entities, or starting a new entity.

In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ Both the mention detection model and the novel entity tracking model can use arbitrary feature types, being able to integrate a wide array of lexical, syntactic and semantic features.
In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ N66001-99-2-8916.
In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ For this system, the gazetteer features are computed on words, not on tokens; the gazetteers consist of 12000 person names and 3000 location and country names, all of which have been collected by few man-hours web browsing.
In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ In this paper, we present a general statistical framework for entity detection and tracking in unrestricted text.

Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ For a mention index , let us define the set of indices of the partially-established entities to the left of (note that ), and the set of the partially-established entities.
Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ We will instead adopt the nomenclature of the Automatic Content Extraction program' (NIST, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g.
Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ For English, we investigated in more detail the way features interact.
Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract No.

This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ We would like to thank Dr. Tong Zhang for providing us with the RRM toolkit.
This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ In addition to the language-general features described in Section 2.3, the Arabic system implements a feature specifying for each token its original stem.
This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ Both the mention detection model and the novel entity tracking model can use arbitrary feature types, being able to integrate a wide array of lexical, syntactic and semantic features.

Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ This statistical framework is general and can incorporate heterogeneous feature types — the models were built using a wide array of lexical, syntactic and semantic features extracted from texts, and further enhanced by adding the output of pre-existing semantic classifiers as feature streams; additional feature types help improve the performance significantly, especially in terms of ACE value.
Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ The data is annotated with five types of entities: person, organization, geo-political entity, location, facility; each mention can be either named, nominal or pronominal, and can be either generic (not referring to a clearly described entity) or specific.
Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ The views and findings contained in this material are those of the authors and do not necessarily reflect the position of policy of the U.S. government and no official endorsement should be inferred.

In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text.
In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ We will instead adopt the nomenclature of the Automatic Content Extraction program' (NIST, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g.

The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ The task is separated into two sub-tasks: a mention detection part, which is modeled through a named entity-like approach, and an entity tracking part, for a which a novel modeling approach is proposed.
The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ In addition, the mention detection model crucially uses feature streams derived from different named entity classifiers.

Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004). $$$$$ errors can lead to irrecoverable mention detection errors; Jing et al. (2003) also observe that character-based models are better performing than word-based ones for Chinese named entity recognition.
Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004). $$$$$ The task is separated into two sub-tasks: a mention detection part, which is modeled through a named entity-like approach, and an entity tracking part, for a which a novel modeling approach is proposed.
Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004). $$$$$ This paper presents a language-independent framework for the entity detection and tracking task, which is shown to obtain top-tier performance on three radically different languages: Arabic, Chinese and English.

These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ In this paper, we present a general statistical framework for entity detection and tracking in unrestricted text.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ This statistical framework is general and can incorporate heterogeneous feature types — the models were built using a wide array of lexical, syntactic and semantic features extracted from texts, and further enhanced by adding the output of pre-existing semantic classifiers as feature streams; additional feature types help improve the performance significantly, especially in terms of ACE value.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ The task is separated into two sub-tasks: a mention detection part, which is modeled through a named entity-like approach, and an entity tracking part, for a which a novel modeling approach is proposed.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ The task is transformed into a sequence classification problem.

We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text.
We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ The experimental results show that the systems perform remarkably well, for both well investigated languages, such as English, and for the relatively new additions Arabic and Chinese.
We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ The experimental results show that the systems perform remarkably well, for both well investigated languages, such as English, and for the relatively new additions Arabic and Chinese.
We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ N66001-99-2-8916.

Finally we note that while Blitzer et al (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al (2004). $$$$$ We investigate a wide array of lexical, syntactic and semantic features to perform the mention detection and classification task including, for all three languages, features based on pre-existing statistical semantic taggers, even though these taggers have been trained on different corpora and use different semantic categories.
Finally we note that while Blitzer et al (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al (2004). $$$$$ Entity detection and tracking is a relatively new addition to the repertoire of natural language tasks.
Finally we note that while Blitzer et al (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al (2004). $$$$$ We would like to thank Dr. Tong Zhang for providing us with the RRM toolkit.

Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ This statistical framework is general and can incorporate heterogeneous feature types — the models were built using a wide array of lexical, syntactic and semantic features extracted from texts, and further enhanced by adding the output of pre-existing semantic classifiers as feature streams; additional feature types help improve the performance significantly, especially in terms of ACE value.
Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract No.
Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ Algorithm 1 The RRM Decoding Algorithm Somewhat similarly, the MaxEnt algorithm has an associated set of weights , which are estimated during the training phase so as to maximize the likelihood of the data (Berger et al., 1996).
Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ Our submission in the evaluation performed well relative to the other participating systems (contractual obligations prevent us from elaborating further).

Each instance represents w i, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al (1999) and Florian et al (2004), as described below. $$$$$ The ACE value computes a weighted cost by applying different weights to each error, depending on the error type and target entity type (e.g.
Each instance represents w i, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al (1999) and Florian et al (2004), as described below. $$$$$ That is not to say, ultimately, that rule-based systems are in some way inferior to statistical models – they are built using valuable insight which is hard to obtain from a statistical-modelonly approach.

For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ The system performance is very close to human performance on this task; this small difference in performance highlights the difficulty of the entity tracking task.
For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ As it is the case with with mention detection approach presented in Section 2, most features used here are language-independent and are instantiated from the training data, while some are language-specific, but mostly because the resources were not available for the specific language.
For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ The task is separated into two sub-tasks: a mention detection part, which is modeled through a named entity-like approach, and an entity tracking part, for a which a novel modeling approach is proposed.
For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract No.

Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ The English mention detection model is similar to the system described in (Ittycheriah et al., 2003)7.The following is a list of additional features (again, is the current token): Shallow parsing information associated with the tokens in window of 3; Prefixes/suffixes of length up to 4; A capitalization/word-type flag (similar to the ones described by Bikel et al. (1997)); Gazetteer information: a handful of location (55k entries) person names (30k) and organizations (5k) dictionaries; A combination of gazetteer, POS and capitalization information, obtained as follows: if the word is a closed-class word — select its class, else if it’s in a dictionary — select that class, otherwise back-off to its capitalization information; we call this feature gap; WordNet information (the synsets and hypernyms of the two most frequent senses of the word); The outputs of three systems (HMM, RRM and MaxEnt) trained on a 32-category named entity data, the output of an RRM system trained on the MUC-6 data, and the output of RRM model identifying 49 categories.
Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ This statistical framework is general and can incorporate heterogeneous feature types — the models were built using a wide array of lexical, syntactic and semantic features extracted from texts, and further enhanced by adding the output of pre-existing semantic classifiers as feature streams; additional feature types help improve the performance significantly, especially in terms of ACE value.
Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ The entity tracking system uses even fewer languagespecific features than the mention detection systems.
Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ Both the mention detection model and the novel entity tracking model can use arbitrary feature types, being able to integrate a wide array of lexical, syntactic and semantic features.

These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ We propose a novel MaxEnt-based model for predicting whether a mention should or should not be linked to an existing entity, and show how this model can be used to build entity chains.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ Moreover, the presented approach implicitly learns the correlation between these different semantic types and the desired output types.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ The experimental results show that the systems perform remarkably well, for both well investigated languages, such as English, and for the relatively new additions Arabic and Chinese.
