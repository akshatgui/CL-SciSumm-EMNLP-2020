Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ Entity detection and tracking is a relatively new addition to the repertoire of natural language tasks.
Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ Although we also use a mention-pair model, our tracking algorithm differs from Soon et al. (2001), Ng and Cardie (2002) in several aspects.
Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ This paper presents a language-independent framework for the entity detection and tracking task, which is shown to obtain top-tier performance on three radically different languages: Arabic, Chinese and English.
Details of the mention detection and coreference system can be found in (Florian et al, 2004). $$$$$ Training directly the model is difficult since it depends on all partial entities .

However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ The experimental results show that the systems perform remarkably well, for both well investigated languages, such as English, and for the relatively new additions Arabic and Chinese.
However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ The experimental results show that the systems perform remarkably well, for both well investigated languages, such as English, and for the relatively new additions Arabic and Chinese.
However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ Figure 1 presents a hierarchical direct comparison between the performance of the RRM model and the MaxEnt model.
However, Florian et al (2006) used some gazetteers and the output of other Information Extraction (IE) models as additional features, which provided significant gains ((Florian et al, 2004)). $$$$$ In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text.

We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ One limitation apparent in our mention detection system is that it does not model explicitly the genericity of a mention.
We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ Each example has associated a vector of binary features .
We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ It is interesting to compare the entity tracking results with inter-annotator agreements.
We use an information extraction toolkit (Florian et al, 2004) to analyze each event argument. $$$$$ Deciding whether a mention refers to a specific entity or a generic entity requires knowledge of substantially wider context than the window of 5 tokens we currently use in our mention detection systems.

In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ The views and findings contained in this material are those of the authors and do not necessarily reflect the position of policy of the U.S. government and no official endorsement should be inferred.
In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ In addition, the mention detection model crucially uses feature streams derived from different named entity classifiers.
In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ N66001-99-2-8916.
In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al (2004) to achieve even greater performance. $$$$$ The task is transformed into a sequence classification problem.

In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ We would like to thank Dr. Tong Zhang for providing us with the RRM toolkit.
In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ N66001-99-2-8916.
In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ A gauge of the performance of an EDT system is the ACE value, a measure developed especially for this purpose.
In this case, we use classifiers as features as described in Florian et al (2004). $$$$$ The following is a list of the features that are shared across languages ( is considered by default the current token): tokens4 in a window of : ; the part-of-speech associated with token dictionary information (whether the current token is part of a large collection of dictionaries - one boolean value for each dictionary) the output of named mention detectors trained on different style of entities. the previously assigned classification tags5.

In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ errors can lead to irrecoverable mention detection errors; Jing et al. (2003) also observe that character-based models are better performing than word-based ones for Chinese named entity recognition.
In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ Both the mention detection model and the novel entity tracking model can use arbitrary feature types, being able to integrate a wide array of lexical, syntactic and semantic features.
In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ Instead, we are just suggesting that the output of such a system can be easily integrated into the previously described framework, as one of the input features, most likely leading to improved performance.
In this case, we make use of the out-of-domain data by using features of the source domain tagger's predictions in training and testing the target domain tagger (Florian et al, 2004). $$$$$ The EDT task is arguably harder than traditional named entity recognition, because of the additional complexity involved in extracting non-named mentions (nominals and pronouns) and the requirement of grouping mentions into entities.

Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ For mention detection we use approaches based on Maximum Entropy (MaxEnt henceforth) (Berger et al., 1996) and Robust Risk Minimization (RRM henceforth) 'For a description of the ACE program see http://www.nist.gov/speech/tests/ace/.
Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ For example, the word “trwmAn” (translation: “Truman”) could be segmented in 3 tokens (for instance, if the word was not seen in the training data): trwmAn t rwm An which introduces ambiguity, as the three tokens form really just one mention, and, in the case of the word “tmnEh”, which has the segmentation tmnEh t mnE h the first and third tokens should both be labeled as pronominal mentions – but, to do this, they need to be separated from the stem mnE.
Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ The framework presented in this paper is languageuniversal – the classification method does not make any assumption about the type of input.
Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains. $$$$$ This paper presents a language-independent framework for the entity detection and tracking task, which is shown to obtain top-tier performance on three radically different languages: Arabic, Chinese and English.

This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ We would like to thank Dr. Tong Zhang for providing us with the RRM toolkit.
This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ In contrast, in a rule based system, the system designer would have to consider how, for instance, a WordNet (Miller, 1995) derived information for a particular example interacts with a part-of-speech-based information and chunking information.
This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ Let be the map from mention index to entity index.
This is because, similar to many NLP tasks, good performance has been shown to depend heavily on integrating many sources of information (Florian et al, 2004). $$$$$ One way we plan to improve performance for such cases is to separate the task into two parts: one in which the mention type and level are predicted, followed by a genericitypredicting model which uses long-range features, such as sentence or document level features.

Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ The views and findings contained in this material are those of the authors and do not necessarily reflect the position of policy of the U.S. government and no official endorsement should be inferred.
Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ The task is separated into two sub-tasks: a mention detection part, which is modeled through a named entity-like approach, and an entity tracking part, for a which a novel modeling approach is proposed.
Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ This paper presents a language-independent framework for the entity detection and tracking task, which is shown to obtain top-tier performance on three radically different languages: Arabic, Chinese and English.
Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al, 2004) for NE detection. $$$$$ LDC reported (NIST, 2003b) that the interannotator agreement (computed as ACE-values) between annotators are %, % and % for Arabic, Chinese and English, respectively.

In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract No.
In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ The EDT task is arguably harder than traditional named entity recognition, because of the additional complexity involved in extracting non-named mentions (nominals and pronouns) and the requirement of grouping mentions into entities.
In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ The task is separated into two sub-tasks: a mention detection part, which is modeled through a named entity-like approach, and an entity tracking part, for a which a novel modeling approach is proposed.
In addition, feature-based integration has been used by Taskar et al (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al (2004), who trained classifiers on auxiliary data to guide named entity classifiers. $$$$$ We would like to thank Dr. Tong Zhang for providing us with the RRM toolkit.

The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ It is an open research question whether a system can be directly optimized for the ACE value.
The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ The task is separated into two sub-tasks: a mention detection part, which is modeled through a named entity-like approach, and an entity tracking part, for a which a novel modeling approach is proposed.
The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ N66001-99-2-8916.
The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information. $$$$$ We separate the EDT task into a mention detection part – the task of finding all mentions in the text – and an entity tracking part – the task of combining the detected mentions into groups of references to the same object.

Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004). $$$$$ Notice that a sequence of such actions corresponds uniquely to an entity outcome (or a partition of mentions).
Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004). $$$$$ At test time, for each example , the model computes a score and labels the example with either the class corresponding to the classifier with the highest score, if above 0, or outside, otherwise.

These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ Entity detection and tracking is a relatively new addition to the repertoire of natural language tasks.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ Formally, let be mentions in a document.

We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ We selected two methods which satisfy these criteria: a linear classifier – the Robust Risk Minimization classifier – and a log-linear classifier – the Maximum Entropy classifier.
We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ As will be shown in Section 4, the relatively knowledge-lean feature sets work fairly well in our tasks.
We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ It is also a necessary step for identifying the relations present in the text and populating a knowledge database.
We also note that while Florian et al (2004) and Blitzer et al (2006) observe that including the label of a source classifier as a feature on small amounts of target data tends to improve over using either the source alone or the target alone, we did not observe that for our data. $$$$$ The lower part of each box describes the particular combination of feature types; the arrows show a inclusion relationship between the feature sets. the fundamental classification algorithm can be applied to every language and the only changes involve finding appropriate and available feature streams for each language.

Finally we note that while Blitzer et al (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al (2004). $$$$$ Both the mention detection model and the novel entity tracking model can use arbitrary feature types, being able to integrate a wide array of lexical, syntactic and semantic features.
Finally we note that while Blitzer et al (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al (2004). $$$$$ This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract No.

Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ Second, instead of doing a pick-first (Soon et al., 2001) or best-first (Ng and Cardie, 2002) selection, the mention-pair linking model is used to compute a starting probability.
Florian et al (2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain. $$$$$ The experimental results show that the systems perform remarkably well, for both well investigated languages, such as English, and for the relatively new additions Arabic and Chinese.

Each instance represents w i, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al (1999) and Florian et al (2004), as described below. $$$$$ The views and findings contained in this material are those of the authors and do not necessarily reflect the position of policy of the U.S. government and no official endorsement should be inferred.
Each instance represents w i, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al (1999) and Florian et al (2004), as described below. $$$$$ This paper presents a language-independent framework for the entity detection and tracking task, which is shown to obtain top-tier performance on three radically different languages: Arabic, Chinese and English.
Each instance represents w i, the token under consideration, and consists of 29 linguistic features, many of which are modeled after the systems of Bikel et al (1999) and Florian et al (2004), as described below. $$$$$ This statistical framework is general and can incorporate heterogeneous feature types — the models were built using a wide array of lexical, syntactic and semantic features extracted from texts, and further enhanced by adding the output of pre-existing semantic classifiers as feature streams; additional feature types help improve the performance significantly, especially in terms of ACE value.

For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ Similarly to the RRM model, we use the model to perform sequence classification, through dynamic programing.
For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ We would like to thank Dr. Tong Zhang for providing us with the RRM toolkit.
For event coreference, we follow the approach to entity coreference detailed in (Florian et al,2004). $$$$$ The segmentation model is similar to the one presented by Lee et al. (2003), and obtains an accuracy of about 98%.

Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ N66001-99-2-8916.
Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text.
Florian et al (2004) reports good results on the 2003 ACE task. $$$$$ The models for all three languages are built as joint models, simultaneously predicting the type, level and genericity of a mention – basically each mention is labeled with a 3-pronged tag.

These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ Given that has been formed to the left of the active mention ,can take two possible actions: if , then the active mention is said to link with the entity ; Otherwise it starts a new entity .
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ In Chinese text, unlike in Indo-European languages, words neither are white-space delimited nor do they have capitalization markers.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ Every such classifier has an associated feature weight vector, , which is learned during the training phase so as to minimize the classification error rate3.
These features were described in (Florian et al, 2004), and are not discussed here. $$$$$ One way we plan to improve performance for such cases is to separate the task into two parts: one in which the mention type and level are predicted, followed by a genericitypredicting model which uses long-range features, such as sentence or document level features.
