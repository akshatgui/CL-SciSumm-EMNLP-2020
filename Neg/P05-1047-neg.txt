It has also been shown that these techniques prove useful for tasks such as word sense disambiguation (Patwardhan et al, 2003), real-word spelling correction (Budanitsky and Hirst, 2001) and information extraction (Stevenson and Greenwood, 2005), among others. $$$$$ The approach makes the assumption that useful patterns will have similar meanings to those already identified as relevant.
It has also been shown that these techniques prove useful for tasks such as word sense disambiguation (Patwardhan et al, 2003), real-word spelling correction (Budanitsky and Hirst, 2001) and information extraction (Stevenson and Greenwood, 2005), among others. $$$$$ Firstly, items belonging to semantic categories are identified by running the text through the named entity identifier in the GATE system (Cunningham et al., 2002).
It has also been shown that these techniques prove useful for tasks such as word sense disambiguation (Patwardhan et al, 2003), real-word spelling correction (Budanitsky and Hirst, 2001) and information extraction (Stevenson and Greenwood, 2005), among others. $$$$$ The clear difference between these results shows that the semantic similarity approach can indeed identify relevant sentences while the documentcentric method identifies patterns which match relevant documents, although not necessarily relevant sentences.

 $$$$$ Results from the document filtering experiment are shown on the left hand side of the table and continuous F-measure scores for the same experiment are also presented in graphical format in Figure 2.
 $$$$$ Yangarber et al. (2000) proposed an algorithm for learning extraction patterns for a small number of examples which greatly reduced the burden on the application developer and reduced the knowledge acquisition bottleneck.

Stevenson and Greenwood (2005) evaluated their method through document and sentence filtering at the scenario level. $$$$$ We then introduce a new algorithm which makes use of WordNet to generalise extraction patterns (Section 3) and describe an implementation (Section 4).
Stevenson and Greenwood (2005) evaluated their method through document and sentence filtering at the scenario level. $$$$$ The set of seed patterns listed in Table 1 are indicative of the management succession extraction task and were used for these experiments.
Stevenson and Greenwood (2005) evaluated their method through document and sentence filtering at the scenario level. $$$$$ Rather than focusing on the documents matched by a pattern, an alternative approach is to rank patterns according to how similar their meanings are to those which are known to be relevant.

Many of the adaptive IE systems rely on the existing part-of-speech (POS) taggers (Debnath and Giles, 2005) and/or syntactic parsers (Stevenson and Greenwood, 2005) for analysing and annotating text corpora. $$$$$ We begin by describing the general process of pattern induction and an existing approach, based on the distribution of patterns in a corpus (Section 2).
Many of the adaptive IE systems rely on the existing part-of-speech (POS) taggers (Debnath and Giles, 2005) and/or syntactic parsers (Stevenson and Greenwood, 2005) for analysing and annotating text corpora. $$$$$ Patterns are compared using a variation of the standard vector space model in which information from an ontology is used to capture semantic similarity.
Many of the adaptive IE systems rely on the existing part-of-speech (POS) taggers (Debnath and Giles, 2005) and/or syntactic parsers (Stevenson and Greenwood, 2005) for analysing and annotating text corpora. $$$$$ A number of pre-processing stages have to be applied to documents in order for the set of patterns to be extracted before learning can take place.
Many of the adaptive IE systems rely on the existing part-of-speech (POS) taggers (Debnath and Giles, 2005) and/or syntactic parsers (Stevenson and Greenwood, 2005) for analysing and annotating text corpora. $$$$$ We are also grateful for the detailed comments provided by the anonymous reviewers of this paper.

Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. $$$$$ While the document-centric approach achieves the highest F-measure of either system (0.83 on the 33rd iteration compared against 0.81 after 48 iterations of the semantic similarity approach) it only outperforms the proposed approach for a few iterations.
Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. $$$$$ Overall the semantic similarity approach was found to be significantly better than the document-centric approach (p < 0.001, Wilcoxon Signed Ranks Test).
Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. $$$$$ Yangarber et al. (2000) chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns.

Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. $$$$$ The similarity of two pattern vectors can be compared using the measure shown in Equation 1.
Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. $$$$$ Firstly, items belonging to semantic categories are identified by running the text through the named entity identifier in the GATE system (Cunningham et al., 2002).
Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. $$$$$ Our algorithm disregards any patterns whose corpus occurrences are below a set threshold, α, since these may be due to noise.

Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ However, this also means that there are fewer examples of the patterns to be learned, making the learning task more challenging.
Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ This paper presents a novel algorithm for the acquisition of Information Extraction patterns.
Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ The approach makes the assumption that useful patterns will have similar meanings to those already identified as relevant.
Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ The clear difference between these results shows that the semantic similarity approach can indeed identify relevant sentences while the documentcentric method identifies patterns which match relevant documents, although not necessarily relevant sentences.

This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ Riloff (1996) judged the precision of patterns learned by reviewing them manually.
This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ This paper presents a novel algorithm for the acquisition of Information Extraction patterns.
This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ Roman Yangarber provided advice on the reimplementation of the document-centric algorithm.
This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ The approach makes the assumption that useful patterns will have similar meanings to those already identified as relevant.

 $$$$$ In addition, a second threshold, Q, is used to determine the maximum number of documents in which a pattern can occur since these very frequent patterns are often too general to be useful for IE.
 $$$$$ Two evaluation regimes are described; one based on the identification of relevant documents and another which aims to identify sentences in a corpus which are relevant for a particular IE task (Section 5).
 $$$$$ However, there is no difference between the expressiveness of the patterns learned by either approach and we do not believe this difference has any effect on the results of our experiments.
 $$$$$ Consequently, we believe the sentence filtering evaluation to be more useful for this problem.

 $$$$$ The evaluation corpus used for the experiments was compiled from the training and testing corpus used in MUC-6, where the task was to extract information about the movements of executives from newswire texts.
 $$$$$ Here d andb are pattern vectors, bT � the transpose ofb and The semantic similarity matrix W contains information about the similarity of each pattern elementfiller pair stored as non-negative real numbers and is crucial for this measure.
 $$$$$ This “sentence filtering” task is a more fine-grained evaluation and is likely to provide more information about how well a given set of patterns is likely to perform as part of an IE system.
 $$$$$ This evaluation indicates whether the set of patterns being learned can identify documents containing descriptions of events but does not provide any information about whether it can find those events within the documents.

 $$$$$ WordNet is also a generic resource not associated with a particular domain which means the learning algorithm can make use of that knowledge to acquire patterns for a diverse range of IE tasks.
 $$$$$ However, there is no difference between the expressiveness of the patterns learned by either approach and we do not believe this difference has any effect on the results of our experiments.
 $$$$$ Candidate patterns are ranked according to the proportion of relevant and irrelevant documents in which they occur, those found in relevant documents far more than in irrelevant ones are ranked highly.
 $$$$$ Roman Yangarber provided advice on the reimplementation of the document-centric algorithm.

Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns. $$$$$ The semantic similarity algorithm can be seen to outperform the document-centric approach.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns. $$$$$ However, it relies on an assumption about the way in which relevant patterns are distributed in a document collection and may learn patterns which tend to occur in the same documents as relevant ones whether or not they are actually relevant.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns. $$$$$ The best score recorded by the proposed algorithm on the sentence filtering task is an F-measure of 0.58 (22nd iteration).

 $$$$$ Weakly supervised algorithms, which bootstrap from a small number of examples, have the advantage of requiring only small amounts of annotated data, which is often difficult and time-consuming to produce.
 $$$$$ This work was carried out as part of the RESuLT project funded by the EPSRC (GR/T06391).
 $$$$$ This paper presents a novel algorithm for the acquisition of Information Extraction patterns.
 $$$$$ Roman Yangarber provided advice on the reimplementation of the document-centric algorithm.

 $$$$$ In addition, the set of seed patterns used for these experiments have a high precision and low recall (Table 2).
 $$$$$ This work was carried out as part of the RESuLT project funded by the EPSRC (GR/T06391).
 $$$$$ Such approaches are often hampered by a lack of information but the additional knowledge in WordNet helps to compensate.

Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns by lexical similarities. $$$$$ Riloff (1996) judged the precision of patterns learned by reviewing them manually.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns by lexical similarities. $$$$$ The clear difference between these results shows that the semantic similarity approach can indeed identify relevant sentences while the documentcentric method identifies patterns which match relevant documents, although not necessarily relevant sentences.

To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ It is important to mention that this implementation is not identical to the one described by Yangarber et al. (2000).
To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ Assuming the subset of documents relevant to a particular IE scenario is known, it is possible to use these relevance judgements to determine how accurately a given set of patterns can discriminate the relevant documents from the irrelevant.
To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ The indirect object of ditransitive verbs is not extracted; these verbs are treated like transitive verbs for the purposes of this analysis.
To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ We begin by outlining the general process of learning extraction patterns, similar to one presented by (Yangarber, 2003). are currently in Sacc.

We adapted the method of matrix similarity given by Stevenson and Greenwood (2005). $$$$$ Initially seed patterns are given a maximum confidence score of 1 and all others a 0 score.
We adapted the method of matrix similarity given by Stevenson and Greenwood (2005). $$$$$ We are also grateful for the detailed comments provided by the anonymous reviewers of this paper.
We adapted the method of matrix similarity given by Stevenson and Greenwood (2005). $$$$$ An implementation of the algorithm described in Section 3 was completed in addition to an implementation of the document-centric algorithm described in Section 2.1.
