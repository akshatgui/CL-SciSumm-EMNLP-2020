It has also been shown that these techniques prove useful for tasks such as word sense disambiguation (Patwardhan et al, 2003), real-word spelling correction (Budanitsky and Hirst, 2001) and information extraction (Stevenson and Greenwood, 2005), among others. $$$$$ Firstly, items belonging to semantic categories are identified by running the text through the named entity identifier in the GATE system (Cunningham et al., 2002).
It has also been shown that these techniques prove useful for tasks such as word sense disambiguation (Patwardhan et al, 2003), real-word spelling correction (Budanitsky and Hirst, 2001) and information extraction (Stevenson and Greenwood, 2005), among others. $$$$$ At the same time it learns patterns with high recall much faster than the document-centric approach, by the 120th iteration the pattern set covers almost 95% of relevant sentences while the document-centric approach covers only 75%.
It has also been shown that these techniques prove useful for tasks such as word sense disambiguation (Patwardhan et al, 2003), real-word spelling correction (Budanitsky and Hirst, 2001) and information extraction (Stevenson and Greenwood, 2005), among others. $$$$$ Assume that the set of patterns, P, consists of n element-filler pairs denoted by p1, p2, ...pn.
It has also been shown that these techniques prove useful for tasks such as word sense disambiguation (Patwardhan et al, 2003), real-word spelling correction (Budanitsky and Hirst, 2001) and information extraction (Stevenson and Greenwood, 2005), among others. $$$$$ It is important to choose appropriate values for the elements of W. We chose to make use of the research that has concentrated on computing similarity between pairs of lexical items using the WordNet hierarchy (Resnik, 1995; Jiang and Conrath, 1997; Patwardhan et al., 2003).

 $$$$$ We are also grateful for the detailed comments provided by the anonymous reviewers of this paper.
 $$$$$ Roman Yangarber provided advice on the reimplementation of the document-centric algorithm.
 $$$$$ This work was carried out as part of the RESuLT project funded by the EPSRC (GR/T06391).
 $$$$$ The learning algorithm presented in Section 3 includes a mechanism for comparing two extraction patterns using information about lexical similarity derived from WordNet.

Stevenson and Greenwood (2005) evaluated their method through document and sentence filtering at the scenario level. $$$$$ This paper presents a novel algorithm for the acquisition of Information Extraction patterns.
Stevenson and Greenwood (2005) evaluated their method through document and sentence filtering at the scenario level. $$$$$ This approach, which can be viewed as being document-centric, operates by associating confidence scores with patterns and relevance scores with documents.
Stevenson and Greenwood (2005) evaluated their method through document and sentence filtering at the scenario level. $$$$$ Active and passive voice is taken into account in MINIPAR’s output so the sentences “COMPANY fired their C.E.O.” and “The C.E.O. was fired by COMPANY” would yield the same triple, COMPANY+fire+ceo.

Many of the adaptive IE systems rely on the existing part-of-speech (POS) taggers (Debnath and Giles, 2005) and/or syntactic parsers (Stevenson and Greenwood, 2005) for analysing and annotating text corpora. $$$$$ The second element is the verb in the clause and the third the object (patient) or predicate.

Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. $$$$$ The best score recorded by the proposed algorithm on the sentence filtering task is an F-measure of 0.58 (22nd iteration).
Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. $$$$$ As mentioned above, the second part of a pattern element-filler pair can be either a lexical item or a semantic category, such as company.
Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. $$$$$ We are also grateful for the detailed comments provided by the anonymous reviewers of this paper.
Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. $$$$$ To avoid this problem these tokens are manually mapped onto the most appropriate node in the WordNet hierarchy which is then used for similarity calculations.

Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. $$$$$ The algorithm described here relies on identifying patterns with similar meanings.
Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. $$$$$ We are also grateful for the detailed comments provided by the anonymous reviewers of this paper.
Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. $$$$$ The corpus is then parsed, using a version of MINIPAR (Lin, 1999) adapted to process text marked with named entities, to produce dependency trees from which SVO-patterns are extracted.
Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. $$$$$ In addition, IE patterns encode the different ways in which a piece of information can be expressed in text.

Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ The approach makes the assumption that useful patterns will have similar meanings to those already identified as relevant.
Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ The approach makes the assumption that useful patterns will have similar meanings to those already identified as relevant.
Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ For these experiments extraction patterns consist of predicate-argument structures, as proposed by Yangarber (2003).
Stevenson and Greenwood (2005) use subject-verb-object triples for their features. $$$$$ This paper presents a novel weakly supervised algorithm for IE pattern induction which makes use of the WordNet ontology (Fellbaum, 1998).

This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ While the document-centric approach achieves the highest F-measure of either system (0.83 on the 33rd iteration compared against 0.81 after 48 iterations of the semantic similarity approach) it only outperforms the proposed approach for a few iterations.
This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ The best score recorded by the proposed algorithm on the sentence filtering task is an F-measure of 0.58 (22nd iteration).
This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ This paper presents a novel algorithm for the acquisition of Information Extraction patterns.
This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. $$$$$ In addition, Sudo et al. (2003) proposed representations for IE patterns which extends the SVO representation used here and, while they did not appear to significantly improve IE, it is expected that it will be straightforward to extend the vector space model to those pattern representations.

 $$$$$ We are also grateful for the detailed comments provided by the anonymous reviewers of this paper.
 $$$$$ Here d andb are pattern vectors, bT � the transpose ofb and The semantic similarity matrix W contains information about the similarity of each pattern elementfiller pair stored as non-negative real numbers and is crucial for this measure.
 $$$$$ This corpus is unannotated, and so may not be difficult to obtain, but is nevertheless an additional requirement.
 $$$$$ This supplementary corpus yielded 126,942 pattern tokens and 79,473 types with 14,576 of these appearing more than once.

 $$$$$ We now go on to describe a new algorithm which implements this approach.
 $$$$$ Patterns are compared using a variation of the standard vector space model in which information from an ontology is used to capture semantic similarity.
 $$$$$ For example, Lehnert et al. (1992) reported that their system required around 1,500 person-hours of expert labour to modify for a new extraction task.
 $$$$$ Two evaluation regimes are described; one based on the identification of relevant documents and another which aims to identify sentences in a corpus which are relevant for a particular IE task (Section 5).

 $$$$$ Yangarber et al. (2000) chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns.
 $$$$$ The indirect object of ditransitive verbs is not extracted; these verbs are treated like transitive verbs for the purposes of this analysis.
 $$$$$ Roman Yangarber provided advice on the reimplementation of the document-centric algorithm.
 $$$$$ The precision scores for the sentence filtering task in Table 2 show that the semantic similarity algorithm consistently learns more accurate patterns than the existing approach.

Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns. $$$$$ Note that taking the dot product of a pair of vectors is equivalent to multiplying by the identity matrix, i.e. a.b = aICT.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns. $$$$$ An implementation of the algorithm described in Section 3 was completed in addition to an implementation of the document-centric algorithm described in Section 2.1.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns. $$$$$ For example, Lehnert et al. (1992) reported that their system required around 1,500 person-hours of expert labour to modify for a new extraction task.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns. $$$$$ In addition, a second threshold, Q, is used to determine the maximum number of documents in which a pattern can occur since these very frequent patterns are often too general to be useful for IE.

 $$$$$ In addition the semantic similarity approach learns more quickly and does not exhibit as much of a drop in performance after it has reached its best value.
 $$$$$ We are also grateful for the detailed comments provided by the anonymous reviewers of this paper.
 $$$$$ We begin by describing the general process of pattern induction and an existing approach, based on the distribution of patterns in a corpus (Section 2).
 $$$$$ These form the set Slearn.

 $$$$$ Firstly, items belonging to semantic categories are identified by running the text through the named entity identifier in the GATE system (Cunningham et al., 2002).
 $$$$$ Differences between the two approaches are most obvious when the results of the sentence filtering task are considered and it seems that this is a more informative evaluation for this problem.
 $$$$$ Weakly supervised algorithms, which bootstrap from a small number of examples, have the advantage of requiring only small amounts of annotated data, which is often difficult and time-consuming to produce.

Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns by lexical similarities. $$$$$ Although it is an informative evaluation, the document filtering task is limited for evaluating IE pattern learning.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns by lexical similarities. $$$$$ The evaluation corpus used for the experiments was compiled from the training and testing corpus used in MUC-6, where the task was to extract information about the movements of executives from newswire texts.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns by lexical similarities. $$$$$ Pairs with different pattern elements (i.e. grammatical roles) are automatically given a similarity score of 0.
Stevenson and Greenwood (2005) suggested an alternative method for ranking the candidate patterns by lexical similarities. $$$$$ The evaluation corpus used for the experiments was compiled from the training and testing corpus used in MUC-6, where the task was to extract information about the movements of executives from newswire texts.

To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ This function assigns a real number to candidate patterns so V c E Scand, f(c, Sacc) H R. A set of high scoring patterns (based on absolute scores or ranks after the set of patterns has been ordered by scores) are chosen as being suitable for inclusion in the set of accepted patterns.
To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ The semantic similarity algorithm can be seen to outperform the document-centric approach.
To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ This evaluation indicates whether the set of patterns being learned can identify documents containing descriptions of events but does not provide any information about whether it can find those events within the documents.
To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005). $$$$$ Differences between the two approaches are most obvious when the results of the sentence filtering task are considered and it seems that this is a more informative evaluation for this problem.

We adapted the method of matrix similarity given by Stevenson and Greenwood (2005). $$$$$ These form the set Slearn.
We adapted the method of matrix similarity given by Stevenson and Greenwood (2005). $$$$$ The corpus is then parsed, using a version of MINIPAR (Lin, 1999) adapted to process text marked with named entities, to produce dependency trees from which SVO-patterns are extracted.
We adapted the method of matrix similarity given by Stevenson and Greenwood (2005). $$$$$ This approach has been shown to successfully acquire useful extraction patterns which, when added to an IE system, improved its performance (Yangarber et al., 2000).
We adapted the method of matrix similarity given by Stevenson and Greenwood (2005). $$$$$ It was not used for the semantic similarity algorithm since there was no benefit.
