Implementations of GIS typically use a correction feature, but following Curran and Clark (2003) we do not use such a feature, which simplifies the algorithm. $$$$$ The Syntactic Process.
Implementations of GIS typically use a correction feature, but following Curran and Clark (2003) we do not use such a feature, which simplifies the algorithm. $$$$$ The contextual predicates used by the two taggers are given in Table 2, where w, is the ith word and ti is the ith tag.
Implementations of GIS typically use a correction feature, but following Curran and Clark (2003) we do not use such a feature, which simplifies the algorithm. $$$$$ This resulted in a minor improvement, and gave the best performance on the development data: 96.83%.
Implementations of GIS typically use a correction feature, but following Curran and Clark (2003) we do not use such a feature, which simplifies the algorithm. $$$$$ Note that the unseen word-tag pairs do not include the previously unseen words.

Table 3 also gives the results if automatically assigned POS tags are used in the training and testing phases, using the C & C POS tagger (Curran and Clark, 2003). $$$$$ The supertagger assigns CCG lexical categories (Steedman, 2000) which encode subcategorisation information.
Table 3 also gives the results if automatically assigned POS tags are used in the training and testing phases, using the C & C POS tagger (Curran and Clark, 2003). $$$$$ This research is supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
Table 3 also gives the results if automatically assigned POS tags are used in the training and testing phases, using the C & C POS tagger (Curran and Clark, 2003). $$$$$ Finding the maximum entropy model that satisfies these constraints is a constrained optimisation problem, which can be solved using the method of Lagrange multipliers, and leads to the form in (1) where the Ai are the Lagrange multipliers.
Table 3 also gives the results if automatically assigned POS tags are used in the training and testing phases, using the C & C POS tagger (Curran and Clark, 2003). $$$$$ Adwait Ratnaparkhi.

 $$$$$ The features used by each tagger are binary valued, and pair a tag with various elements of the context; for example: fi(x ) = { 1 if word(x)= the & y = DT ,y
 $$$$$ This may further boost supertagger performance.
 $$$$$ The features used by each tagger are binary valued, and pair a tag with various elements of the context; for example: fi(x ) = { 1 if word(x)= the & y = DT ,y
 $$$$$ We would like to thank Joshua Goodman, Miles Osborne, Andrew Smith, Hanna Wallach, Tara Murphy and the anonymous reviewers for their comments on drafts of this paper.

When compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). $$$$$ This paper has demonstrated, both analytically and empirically, that GIS does not require a correction feature Eliminating the correction feature simplifies further the already very simple estimation algorithm.
When compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). $$$$$ In doing so, we discovered a number of minor variations from Ratnaparkhi (1998): MXPOST uses a cutoff of 1 for the current word feature and 5 for other features.
When compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). $$$$$ We insert a special end of sentence symbol at sentence boundaries so that the features looking forwards and backwards are always defined.
When compared with other supertag sets of automatically extracted lexicalized grammars, the (effective) size of our supertag set, 1,361 lexical entries, is between the CCG supertag set (398 categories) used by Curran and Clark (2003) and the LTAG supertag set (2920 elementary trees) used by Shen and Joshi (2003). $$$$$ This led us to reduce the cutoffs for all features simultaneously.

Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al, 1994). $$$$$ We would like to thank Joshua Goodman, Miles Osborne, Andrew Smith, Hanna Wallach, Tara Murphy and the anonymous reviewers for their comments on drafts of this paper.
Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al, 1994). $$$$$ The results on section 00 and section 23 are given in Tables 11 and 12.4 c&c outperforms Clark's supertagger by 0.43% on the test set, a reduction in error rate of 4.9%.
Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al, 1994). $$$$$ The supertagger uses POS tags as additional features, which Clark (2002) found improved performance significantly, and does not use the morphological features, since the POS tags provide equivalent information.
Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al, 1994). $$$$$ The lexical categories for the supertagging experiments were extracted from CCGbank, a CCG version of the Penn Treebank (Hockenmaier and Steedman, 2002).

Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger. $$$$$ This research is supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger. $$$$$ This may further boost supertagger performance.
Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger. $$$$$ A simple technique used to avoid overfitting is a frequency cutoff, in which only frequently occurring features are included in the model (Ratnaparkhi, 1998).
Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger. $$$$$ Note that the unseen word-tag pairs do not include the previously unseen words.

The tagger is very similar to the Maximum Entropy POS tagger described in Curran and Clark (2003). $$$$$ The contextual predicates used by the two taggers are given in Table 2, where w, is the ith word and ti is the ith tag.
The tagger is very similar to the Maximum Entropy POS tagger described in Curran and Clark (2003). $$$$$ This form can be derived by choosing the model with maximum entropy (i.e. the most uniform model) from a set of models that satisfy a certain set of constraints.
The tagger is very similar to the Maximum Entropy POS tagger described in Curran and Clark (2003). $$$$$ Studies of infrequent features in other domains suggest this assumption may be incorrect (Daelemans et al., 1999).
The tagger is very similar to the Maximum Entropy POS tagger described in Curran and Clark (2003). $$$$$ 2000.

Here we use the Maximum Entropy models described in Curran and Clark (2003). $$$$$ For the supertagger, t, is the lexical category of the ith word.
Here we use the Maximum Entropy models described in Curran and Clark (2003). $$$$$ The supertagger uses POS tags as additional features, which Clark (2002) found improved performance significantly, and does not use the morphological features, since the POS tags provide equivalent information.
Here we use the Maximum Entropy models described in Curran and Clark (2003). $$$$$ The features used by each tagger are binary valued, and pair a tag with various elements of the context; for example: fi(x ) = { 1 if word(x)= the & y = DT ,y
Here we use the Maximum Entropy models described in Curran and Clark (2003). $$$$$ Achieving optimal performance with Gaussian smoothing and without cutoffs demonstrates that low frequency features can contribute to good performance.

Curran and Clark (2003) describes the model and explains how Generalised Iterative Scaling, together with a Gaussian prior for smoothing, can be used to set the weights. $$$$$ The original formulation of GIS (Darroch and Ratcliff, 1972) required the sum of the feature values for each event to be constant.
Curran and Clark (2003) describes the model and explains how Generalised Iterative Scaling, together with a Gaussian prior for smoothing, can be used to set the weights. $$$$$ CCG supertagging is more difficult than POS tagging because the set of &quot;tags&quot; assigned by the supertagger is much larger (398 in this implementation, compared with 45 POS tags).
Curran and Clark (2003) describes the model and explains how Generalised Iterative Scaling, together with a Gaussian prior for smoothing, can be used to set the weights. $$$$$ The new update rule for GIS with a Gaussian prior is found by solving the following equation for the Ai update values (denoted by S), which can easily be derived from (10) by analogy with the proof in the Appendix: This equation does not have an analytic solution for Si and can be solved using a numerical solver such as Newton-Raphson.
Curran and Clark (2003) describes the model and explains how Generalised Iterative Scaling, together with a Gaussian prior for smoothing, can be used to set the weights. $$$$$ We reimplemented Ratnaparkhi's publicly available POS tagger MXPOST (Ratnaparkhi, 1996; Ratnaparkhi, 1998) and Clark's CCG supertagger (Clark, 2002) as a starting point for our experiments.

The supertagger in Curran and Clark (2003) finds the single most probable category sequence given the sentence, and uses additional features defined in terms of the previously assigned categories. $$$$$ The features used by each tagger are binary valued, and pair a tag with various elements of the context; for example: fi(x ) = { 1 if word(x)= the & y = DT ,y
The supertagger in Curran and Clark (2003) finds the single most probable category sequence given the sentence, and uses additional features defined in terms of the previously assigned categories. $$$$$ We also explore the use of a Gaussian prior and a simple cutoff for smoothing.
The supertagger in Curran and Clark (2003) finds the single most probable category sequence given the sentence, and uses additional features defined in terms of the previously assigned categories. $$$$$ Computational Linguistics, 27(2): 199-229.

The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran and Clark (2003) tagger. $$$$$ The remainder of Table 5 shows a minimal change in performance when the current word (w) and previous word (pw) cutoffs are varied.
The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran and Clark (2003) tagger. $$$$$ In doing so, we discovered a number of minor variations from Ratnaparkhi (1998): MXPOST uses a cutoff of 1 for the current word feature and 5 for other features.
The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran and Clark (2003) tagger. $$$$$ To get more information into the model, more features must be extracted, and so we investigated the addition of the current word feature for all words, including the rare ones.
The table gives results for gold standard POS tags and, in the final 2 columns, for POS tags automatically assigned by the Curran and Clark (2003) tagger. $$$$$ In doing so, we discovered a number of minor variations from Ratnaparkhi (1998): MXPOST uses a cutoff of 1 for the current word feature and 5 for other features.

The CCG parser results are based on automatically assigned POS tags, using the Curran and Clark (2003) tagger. $$$$$ We also investigate how the use of a correction feature affects the performance of ME taggers.
The CCG parser results are based on automatically assigned POS tags, using the Curran and Clark (2003) tagger. $$$$$ A simple technique used to avoid overfitting is a frequency cutoff, in which only frequently occurring features are included in the model (Ratnaparkhi, 1998).
The CCG parser results are based on automatically assigned POS tags, using the Curran and Clark (2003) tagger. $$$$$ Ph.D. thesis, University of Pennsylvania.
The CCG parser results are based on automatically assigned POS tags, using the Curran and Clark (2003) tagger. $$$$$ We explore the combination of Gaussian smoothing and a simple cutoff for two tagging tasks.

We investigate whether co-training based upon directly maximising agreement can be successfully applied to a pair of part-of-speech (POS) taggers: the Markov model TNT tagger (Brants, 2000) and the maximum entropy C & C tagger (Curran and Clark, 2003). $$$$$ The difference between MXPOST and c&c represents a reduction in error rate of 4.3%, and the difference between TNT and C&C a reduction in error rate of 10.8%.
We investigate whether co-training based upon directly maximising agreement can be successfully applied to a pair of part-of-speech (POS) taggers: the Markov model TNT tagger (Brants, 2000) and the maximum entropy C & C tagger (Curran and Clark, 2003). $$$$$ The obvious cost associated with retaining all the features is the significant increase in model size, which slows down both the training and tagging and requires more memory.
We investigate whether co-training based upon directly maximising agreement can be successfully applied to a pair of part-of-speech (POS) taggers: the Markov model TNT tagger (Brants, 2000) and the maximum entropy C & C tagger (Curran and Clark, 2003). $$$$$ This can be thought of as relaxing the constraints in (5), so that the model fits the data less exactly.

The modern Bible is tagged using the C & C maximum entropy tagger (Curran and Clark, 2003), and these tags are transferred from source to target through high-confidence alignments aquired from two alignment approaches. $$$$$ A natural choice for Ki is the empirical expected value of the feature fi: xo, An alternative motivation for this model is that, starting with the log-linear form in (1) and deriving (conditional) MLES, we arrive at the same solution as the ME model which satisfies the constraints in (5).
The modern Bible is tagged using the C & C maximum entropy tagger (Curran and Clark, 2003), and these tags are transferred from source to target through high-confidence alignments aquired from two alignment approaches. $$$$$ A conditional ME model, also known as a loglinear model, has the following form: where the functions fi are the features of the model, the A, are the parameters, or weights, and Z(x) is a normalisation constant.
The modern Bible is tagged using the C & C maximum entropy tagger (Curran and Clark, 2003), and these tags are transferred from source to target through high-confidence alignments aquired from two alignment approaches. $$$$$ This feature does not contribute to the model and can be ignored during weight update.
The modern Bible is tagged using the C & C maximum entropy tagger (Curran and Clark, 2003), and these tags are transferred from source to target through high-confidence alignments aquired from two alignment approaches. $$$$$ The parameters o-, are usually collapsed into one parameter which can be set using heldout data.

The C & C tagger (Curran and Clark, 2003) was trained on the Wall Street Journal texts in the Penn Treebank and then used to tag the NET Bible (the source text). $$$$$ CCG supertagging is more difficult than POS tagging because the set of &quot;tags&quot; assigned by the supertagger is much larger (398 in this implementation, compared with 45 POS tags).
The C & C tagger (Curran and Clark, 2003) was trained on the Wall Street Journal texts in the Penn Treebank and then used to tag the NET Bible (the source text). $$$$$ The conditional probability of a tag sequence y ...y, given a sentence w wn is approximated as follows: where x; is the context of the ith word.
The C & C tagger (Curran and Clark, 2003) was trained on the Wall Street Journal texts in the Penn Treebank and then used to tag the NET Bible (the source text). $$$$$ Adwait Ratnaparkhi.

However, it is unclear whether multi-POS tagging will be useful in this context, since our single-tagger POS tagger is highly accurate: over 97% for WSJ text (Curran and Clark,2003). $$$$$ Sections 02-21, section 00, and section 23 were used for training, development and testing, as before.
However, it is unclear whether multi-POS tagging will be useful in this context, since our single-tagger POS tagger is highly accurate: over 97% for WSJ text (Curran and Clark,2003). $$$$$ We explore the combination of Gaussian smoothing and a simple cutoff for two tagging tasks.
However, it is unclear whether multi-POS tagging will be useful in this context, since our single-tagger POS tagger is highly accurate: over 97% for WSJ text (Curran and Clark,2003). $$$$$ This may further boost supertagger performance.

Part-of-speech (POS) tagging is done using the C & C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ Achieving optimal performance with Gaussian smoothing and without cutoffs demonstrates that low frequency features can contribute to good performance.
Part-of-speech (POS) tagging is done using the C & C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ The Gaussian prior effectively relaxes the constraints on the ME model, which allows the model to use low frequency features without overfitting.
Part-of-speech (POS) tagging is done using the C & C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000). $$$$$ As well as evaluating the overall accuracy of the taggers (Acc), we also calculate the accuracy on previously unseen words (UwoRD), previously unseen word-tag pairs (UTAG) and ambiguous words (AMB), that is, those with more than one tag over the testing, training and development datasets.

We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C & C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ For the remainder of the experiments we use neither the correction nor the default features.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C & C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ ).
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C & C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ For the supertagger, t, is the lexical category of the ith word.
We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C & C maximum entropy NER tagger (Curran and Clark, 2003b). $$$$$ A simple technique used to avoid overfitting is a frequency cutoff, in which only frequently occurring features are included in the model (Ratnaparkhi, 1998).

We determine weights for the features with a modified version of the Generative Iterative Scaling algorithm (Curran and Clark, 2003). $$$$$ The two taggers used for the experiments are a POS tagger, trained on the WSJ Penn Treebank, and a &quot;supertagger&quot;, which assigns tags from the much larger set of lexical types from Combinatory Categorial Grammar (ccG) (Clark, 2002).
We determine weights for the features with a modified version of the Generative Iterative Scaling algorithm (Curran and Clark, 2003). $$$$$ We first replicated the results of the MXPOST tagger.
We determine weights for the features with a modified version of the Generative Iterative Scaling algorithm (Curran and Clark, 2003). $$$$$ We found that using a 2 gave the most benefit to our basic tagger, improving performance by about 0.15% on the development set.
We determine weights for the features with a modified version of the Generative Iterative Scaling algorithm (Curran and Clark, 2003). $$$$$ This may further boost supertagger performance.

It is straightforward to apply this in tasks with token-based evaluation, such as part-of-speech tagging (Curran and Clark, 2003). $$$$$ ).
It is straightforward to apply this in tasks with token-based evaluation, such as part-of-speech tagging (Curran and Clark, 2003). $$$$$ We would like to thank Joshua Goodman, Miles Osborne, Andrew Smith, Hanna Wallach, Tara Murphy and the anonymous reviewers for their comments on drafts of this paper.
It is straightforward to apply this in tasks with token-based evaluation, such as part-of-speech tagging (Curran and Clark, 2003). $$$$$ This paper investigates two elements of Maximum Entropy tagging: the use of a correction feature in the Generalised Iterative Scaling (Gis) estimation algorithm, and techniques for model smoothing.
