As new applications appear, that cannot start generation from a semantic input because such an input is not available (for example re-generation of sentences from syntactic fragments to produce summaries (Barzilay et al, 1999) or generation of complex NPs in a hybrid template system for business letters (Gedalia, 1996)), this motivation has lost some of its strength. $$$$$ A time marker will be added to the output summary for each gap, for example &quot;According to a Reuters report on the 10/21&quot;.
As new applications appear, that cannot start generation from a semantic input because such an input is not available (for example re-generation of sentences from syntactic fragments to produce summaries (Barzilay et al, 1999) or generation of complex NPs in a hybrid template system for business letters (Gedalia, 1996)), this motivation has lost some of its strength. $$$$$ Our intersection algorithm identified 29 (74%) predicate-argument structures and was able to identify correctly 69% of the subjects, 74% of the main verbs, and 65% of the other constituents in our list of model predicate-argument structures.
As new applications appear, that cannot start generation from a semantic input because such an input is not available (for example re-generation of sentences from syntactic fragments to produce summaries (Barzilay et al, 1999) or generation of complex NPs in a hybrid template system for business letters (Gedalia, 1996)), this motivation has lost some of its strength. $$$$$ One interesting problem for future work is the question of how much context to include from a sentence from which an intersected phrase is drawn.

Barzilay et al (1999) were one of the first to use time for multi-document summarization. $$$$$ FUF/SURGE, our language generator, requires that the input contain a semantic role, circumstantial which in turn contains a temporal feature.
Barzilay et al (1999) were one of the first to use time for multi-document summarization. $$$$$ Assuming a set of similar sentences as input extracted from multiple documents on the same event (McKeown et al., 1999; Eskin et al., 1999), our system identifies common phrases across sentences and uses language generation to reformulate them as a coherent summary.
Barzilay et al (1999) were one of the first to use time for multi-document summarization. $$$$$ Thus, we label circumstantials with the features front-i (i-th circumstantial at the front of the sentence) and end-i (i-th circumstantial at the end), where i indicates the relative ordering of the circumstantial within the clause.
Barzilay et al (1999) were one of the first to use time for multi-document summarization. $$$$$ While we used circumstantials to illustrate the issues, we also handled revision for a variety of other categories in the same manner.

Extractive summarization is a simple but robust method for text summarization and it involves assigning saliency scores to some units (e.g. sentences, paragraphs) of the documents and extracting those with highest scores, while abstraction summarization usually needs information fusion (Barzilay et al, 1999), sentence compression (Knight and Marcu, 2002) and reformulation (McKeown et al, 1999). $$$$$ In order to construct a DSYNT we first run our sentences through Collin's robust, statistical parser (Collins, 1996).
Extractive summarization is a simple but robust method for text summarization and it involves assigning saliency scores to some units (e.g. sentences, paragraphs) of the documents and extracting those with highest scores, while abstraction summarization usually needs information fusion (Barzilay et al, 1999), sentence compression (Knight and Marcu, 2002) and reformulation (McKeown et al, 1999). $$$$$ The mission was carried out by CH-53 helicopters with an escort of missile- and rocket-armed Cobra helicopters. information needed for clarification (entity descriptions, temporal references, and newswire source references).
Extractive summarization is a simple but robust method for text summarization and it involves assigning saliency scores to some units (e.g. sentences, paragraphs) of the documents and extracting those with highest scores, while abstraction summarization usually needs information fusion (Barzilay et al, 1999), sentence compression (Knight and Marcu, 2002) and reformulation (McKeown et al, 1999). $$$$$ One interesting problem for future work is the question of how much context to include from a sentence from which an intersected phrase is drawn.

Then one can apply the method inspired by (Barzilay et al, 1999) to identify common phrases across sentences and use language generation to form a more coherent summary. $$$$$ Information overload has created an acute need for summarization.
Then one can apply the method inspired by (Barzilay et al, 1999) to identify common phrases across sentences and use language generation to form a more coherent summary. $$$$$ For example, information extraction systems can be used to interpret the source text.
Then one can apply the method inspired by (Barzilay et al, 1999) to identify common phrases across sentences and use language generation to form a more coherent summary. $$$$$ In this paper, we presented an implemented algorithm for multi-document summarization which moves beyond the sentence extraction paradigm.

Paraphrase here includes sentences generated in an Information Fusion task (Barzilay et al, 1999). $$$$$ This initial set might allow us to automatically identify more rules and increase the performance of our comparison algorithm.
Paraphrase here includes sentences generated in an Information Fusion task (Barzilay et al, 1999). $$$$$ On the eve of the meeting, a U.S. F-16 fighter was shot down while on a routine patrol over northern Bosnia.
Paraphrase here includes sentences generated in an Information Fusion task (Barzilay et al, 1999). $$$$$ We have modified SURGE to accept this type of input: in all places SURGE checks the semantic type of the circumstantial before making choices, we verified that the absence of the corresponding input feature would not lead to an inappropriate default being selected.
Paraphrase here includes sentences generated in an Information Fusion task (Barzilay et al, 1999). $$$$$ The mission was carried out by CH-53 helicopters with an escort of missile- and rocket-armed Cobra helicopters. information needed for clarification (entity descriptions, temporal references, and newswire source references).

Barzilay et al (1999) introduce a combination of extracted similar phrases and a reformulation through sentence generation. $$$$$ An example summary automatically generated by the system from our corpus of themes is shown in Figure 1.
Barzilay et al (1999) introduce a combination of extracted similar phrases and a reformulation through sentence generation. $$$$$ Our approach is unique in its usage of language generation to reformulate the wording of the summary.
Barzilay et al (1999) introduce a combination of extracted similar phrases and a reformulation through sentence generation. $$$$$ In summary, this new application for syntactic realization highlights the need for supporting hybrid inputs of variable abstraction levels.

In this work, we use the clusters of event related sentences from the Information Fusion work by Barzilay et al [1999]. $$$$$ If nodes are not identical, the algorithm tries to apply an appropriate paraphrasing rule from a set of rules described in the next section.
In this work, we use the clusters of event related sentences from the Information Fusion work by Barzilay et al [1999]. $$$$$ As an example, consider the case of temporal modifiers.
In this work, we use the clusters of event related sentences from the Information Fusion work by Barzilay et al [1999]. $$$$$ The use of generation to merge similar information is a new approach that significantly improves the quality of the resulting summaries, reducing repetition and increasing fluency.
In this work, we use the clusters of event related sentences from the Information Fusion work by Barzilay et al [1999]. $$$$$ Recent work (Mani and Bloedorn, 1997) exploits semantic relations between text units for content representation, such as synonymy and co-reference.

For our evaluation cases, we use the Information Fusion data collected by [Barzilay et al, 1999]. $$$$$ Our algorithm was compared against intersections extracted by human judges from each theme, producing 39 sentence-level predicateargument structures.
For our evaluation cases, we use the Information Fusion data collected by [Barzilay et al, 1999]. $$$$$ After six days, O'Grady, downed pilot, was rescued by Marine force.
For our evaluation cases, we use the Information Fusion data collected by [Barzilay et al, 1999]. $$$$$ Some approaches directly exploit word distribution in the text (Salton et al., 1991; Carbonell and Goldstein, 1998).
For our evaluation cases, we use the Information Fusion data collected by [Barzilay et al, 1999]. $$$$$ While we have tuned the system to perform with minor errors on the manual set of themes we have created (the missing article in the fourth sentence of the summary in Figure 1 is an example), we need more robust input data from the theme construction component, which is still under development, to train the generator before beginning large scale testing.

). $$$$$ Our approach is unique in its usage of language generation to reformulate the wording of the summary.
). $$$$$ In the following sections, we provide an overview of existing multi-document summarization systems, then we will detail our sentence comparison technique, and describe the sentence generation component.
). $$$$$ We would like to thank Ya.el Dahan-Netzer for her help with SURGE.

Semantic Role Labeling (SRL) has been implemented or suggested as a means to aid several Natural Language Processing (NLP) tasks such as information extraction (Kogan et al, 2005), multi document summarization (Barzilay et al, 1999) and machine translation (Quantz and Schmitz, 1994. $$$$$ Thus, for each phrase, we must find the earliest publication date in the theme, create a &quot;time stamp&quot;, and order phrases in the summary according to this time stamp.
Semantic Role Labeling (SRL) has been implemented or suggested as a means to aid several Natural Language Processing (NLP) tasks such as information extraction (Kogan et al, 2005), multi document summarization (Barzilay et al, 1999) and machine translation (Quantz and Schmitz, 1994. $$$$$ We present system accuracy separately for each category, since identifying a verb or a subject is, in most cases, more important than identifying other sentence constituents.
Semantic Role Labeling (SRL) has been implemented or suggested as a means to aid several Natural Language Processing (NLP) tasks such as information extraction (Kogan et al, 2005), multi document summarization (Barzilay et al, 1999) and machine translation (Quantz and Schmitz, 1994. $$$$$ The labelling of the circumstantial as time allows SURGE to make the following decisions given a sentence such as: &quot;After they made an emergency landing, the pilots were reported missing.&quot; The semantic input also provides a solid basis to authorize sophisticated revisions to a base input.
Semantic Role Labeling (SRL) has been implemented or suggested as a means to aid several Natural Language Processing (NLP) tasks such as information extraction (Kogan et al, 2005), multi document summarization (Barzilay et al, 1999) and machine translation (Quantz and Schmitz, 1994. $$$$$ First is the need to use learning techniques to identify paraphrasing patterns in corpus data.

As a text-to-text approach, our work is more similar to work on Information Fusion (Barzilay et al., 1999), a sub-problem in multi-document summarisation. $$$$$ Another time-related issue that we address is normalization of temporal references in the summary.
As a text-to-text approach, our work is more similar to work on Information Fusion (Barzilay et al., 1999), a sub-problem in multi-document summarisation. $$$$$ We would like to thank Ya.el Dahan-Netzer for her help with SURGE.
As a text-to-text approach, our work is more similar to work on Information Fusion (Barzilay et al., 1999), a sub-problem in multi-document summarisation. $$$$$ We present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents.
As a text-to-text approach, our work is more similar to work on Information Fusion (Barzilay et al., 1999), a sub-problem in multi-document summarisation. $$$$$ This occurs just once in our test cases, but it is a serious error.

 $$$$$ For the theme in Figure 2, the intersection result is &quot;On Friday, a U.S. F-16 fighter jet was shot down by Bosnian Serb missile.&quot;1 Identification of theme intersection requires collecting paraphrasing patterns which occur in our corpus.
 $$$$$ O'Grady's F-16 fighter jet, based in Aviano, Italy, was shot down by a Bosnian Serb SA-6 anti-aircraft missile last Friday and hopes had diminished for finding him alive despite intermittent electronic signals from the area which later turned out to be a navigational beacon.
 $$$$$ However, in cases where the preposition is ambiguous (e.g., &quot;in&quot; can indicate &quot;time&quot; or &quot;location&quot;) the generator must rely solely on ordering circumstantials based on ordering found in the input.

Several well-known models have been proposed, i.e., MMR (Carbonell and Goldstein, 1998), multi Gen (Barzilay et al, 1999), and MEAD (Radev et al, 2004). $$$$$ When the semantic information is not available, it is more difficult to predict that the decisions are compatible with the input provided in syntactic form.
Several well-known models have been proposed, i.e., MMR (Carbonell and Goldstein, 1998), multi Gen (Barzilay et al, 1999), and MEAD (Radev et al, 2004). $$$$$ To avoid redundant statements in a summary, we could select one sentence from the set of similar sentences that meets some criteria (e.g., a threshold number of common content words).
Several well-known models have been proposed, i.e., MMR (Carbonell and Goldstein, 1998), multi Gen (Barzilay et al, 1999), and MEAD (Radev et al, 2004). $$$$$ Far more training data is needed to tune the generation portion.

A famous effort in this direction is the information fusion approach proposed in Barzilay et al (1999). $$$$$ We present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents.
A famous effort in this direction is the information fusion approach proposed in Barzilay et al (1999). $$$$$ Evaluation of multi-document summarization is difficult.
A famous effort in this direction is the information fusion approach proposed in Barzilay et al (1999). $$$$$ We added features that indicate the ordering of circumstantials in the output.
A famous effort in this direction is the information fusion approach proposed in Barzilay et al (1999). $$$$$ Our work is part of a full summarization system (McKeown et al., 1999), which extracts sets of similar sentences, themes (Eskin et al., 1999), in the first stage for input to the components described here.

Barzilay et al (1999) does not explicitly extract facts, but instead picks out relevant repeated elements and combines them to obtain a summary which retains the semantics of the original. $$$$$ We present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents.
Barzilay et al (1999) does not explicitly extract facts, but instead picks out relevant repeated elements and combines them to obtain a summary which retains the semantics of the original. $$$$$ Second, methods used for evaluation of extraction-based systems are not applicable for a system which involves text regeneration.
Barzilay et al (1999) does not explicitly extract facts, but instead picks out relevant repeated elements and combines them to obtain a summary which retains the semantics of the original. $$$$$ We present system accuracy separately for each category, since identifying a verb or a subject is, in most cases, more important than identifying other sentence constituents.
Barzilay et al (1999) does not explicitly extract facts, but instead picks out relevant repeated elements and combines them to obtain a summary which retains the semantics of the original. $$$$$ As an example, consider the case of temporal modifiers.

Nevertheless, one might imagine that such output forms the basis for generating coherent query-focused summaries with sentence rewrite techniques, e.g., (Barzilay et al, 1999). $$$$$ As an example, consider the case of temporal modifiers.
Nevertheless, one might imagine that such output forms the basis for generating coherent query-focused summaries with sentence rewrite techniques, e.g., (Barzilay et al, 1999). $$$$$ We present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents.

Since paraphrases capture the variations of linguistic expressions while preserving the meaning, they are very useful in many applications, such as machine translation (Marton et al, 2009), document summarization (Barzilay et al, 1999), and recognizing textual entailment (RTE) (Dagan et al, 2005). $$$$$ We present system accuracy separately for each category, since identifying a verb or a subject is, in most cases, more important than identifying other sentence constituents.
Since paraphrases capture the variations of linguistic expressions while preserving the meaning, they are very useful in many applications, such as machine translation (Marton et al, 2009), document summarization (Barzilay et al, 1999), and recognizing textual entailment (RTE) (Dagan et al, 2005). $$$$$ Consequently, the evaluation that we performed to date is limited.
Since paraphrases capture the variations of linguistic expressions while preserving the meaning, they are very useful in many applications, such as machine translation (Marton et al, 2009), document summarization (Barzilay et al, 1999), and recognizing textual entailment (RTE) (Dagan et al, 2005). $$$$$ We would like to thank Ya.el Dahan-Netzer for her help with SURGE.

Lexical chains have been used in text summarization (Barzilay et al, 1999), and our linear time algorithm (Silber and McCoy, 2002) makes their computation feasible even for large texts. $$$$$ While some researchers address this problem by selecting a subset of the repetitions (Carbonell and Goldstein, 1998), this approach is not always satisfactory.
Lexical chains have been used in text summarization (Barzilay et al, 1999), and our linear time algorithm (Silber and McCoy, 2002) makes their computation feasible even for large texts. $$$$$ We developed techniques to map predicateargument structure produced by the content-planner to the functional representation expected by FUF/SURGE(Elhaklad, 1993; Robin, 1994) and to integrate new constraints on realization choice, using surface features in place of semantic or pragmatic ones typically used in sentence generation.
Lexical chains have been used in text summarization (Barzilay et al, 1999), and our linear time algorithm (Silber and McCoy, 2002) makes their computation feasible even for large texts. $$$$$ IRI-96-1879.
Lexical chains have been used in text summarization (Barzilay et al, 1999), and our linear time algorithm (Silber and McCoy, 2002) makes their computation feasible even for large texts. $$$$$ We present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents.

It has been observed that in the context of multi-document summarization of news articles, extraction may be inappropriate because it may produce summaries which are overly verbose or biased towards some sources (Barzilay et al, 1999). $$$$$ A content planner selects and orders propositions from an underlying knowledge base to form text content.
It has been observed that in the context of multi-document summarization of news articles, extraction may be inappropriate because it may produce summaries which are overly verbose or biased towards some sources (Barzilay et al, 1999). $$$$$ While we have tuned the system to perform with minor errors on the manual set of themes we have created (the missing article in the fourth sentence of the summary in Figure 1 is an example), we need more robust input data from the theme construction component, which is still under development, to train the generator before beginning large scale testing.
It has been observed that in the context of multi-document summarization of news articles, extraction may be inappropriate because it may produce summaries which are overly verbose or biased towards some sources (Barzilay et al, 1999). $$$$$ In such cases, the resulting summary is actually false.
It has been observed that in the context of multi-document summarization of news articles, extraction may be inappropriate because it may produce summaries which are overly verbose or biased towards some sources (Barzilay et al, 1999). $$$$$ FUF/SURGE, our language generator, requires that the input contain a semantic role, circumstantial which in turn contains a temporal feature.

The merging task is a more logic-based approach than similar techniques like information fusion used in multi-document summarization (Barzilay et al, 1999). $$$$$ IRI-96-1879.
The merging task is a more logic-based approach than similar techniques like information fusion used in multi-document summarization (Barzilay et al, 1999). $$$$$ If paraphrasing rules are known, we can compare the predicate-argument structure of the sentences and find common parts.
The merging task is a more logic-based approach than similar techniques like information fusion used in multi-document summarization (Barzilay et al, 1999). $$$$$ In order to prevent noisy input from the theme construction component from skewing the evaluation, we manually constructed 26 themes, each containing 4 sentences on average.
