See Ng and Cardie (2002) for a detailed description of the features. $$$$$ Manual feature selection, with an eye toward eliminating low-precision rules for common noun resolution, is shown to reliably improve performance over the full feature set and produces the best results to date on the MUC-6 and MUC-7 coreference data sets — F-measures of 70.4 and 63.4, respectively.
See Ng and Cardie (2002) for a detailed description of the features. $$$$$ Second, in an attempt to understand whether incorporating additional knowledge can improve the performance of a corpus-based coreference resolution system, we expand the Soon et al. feature set from 12 features to an arguably deeper set of 53.
See Ng and Cardie (2002) for a detailed description of the features. $$$$$ Unfortunately, we find that performance drops significantly when using the full feature set; we attribute this, at least in part, to the system’s poor performance on common noun resolution and to data fragmentation problems that arise with the larger feature set.
See Ng and Cardie (2002) for a detailed description of the features. $$$$$ The process terminates as soon as an antecedent is found for NP✄ or the beginning of the text is reached.

We now show that the search problem in (2) can equivalently be solved by the more intuitive best first decoder (Ng and Cardie, 2002), rather than using the CLE decoder. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 0081334 and 0074896.
We now show that the search problem in (2) can equivalently be solved by the more intuitive best first decoder (Ng and Cardie, 2002), rather than using the CLE decoder. $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.
We now show that the search problem in (2) can equivalently be solved by the more intuitive best first decoder (Ng and Cardie, 2002), rather than using the CLE decoder. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 0081334 and 0074896.
We now show that the search problem in (2) can equivalently be solved by the more intuitive best first decoder (Ng and Cardie, 2002), rather than using the CLE decoder. $$$$$ As a result, we modify the coreference clustering algorithm to select as the antecedent of NP✄ the NP with the highest coreference likelihood value from among preceding NPs with coreference class values above 0.5.

The use of latent antecedents goes back to the work of Yu and Joachims (2009), although the idea of determining meaningful antecedents for mentions can be tracedback to Ng and Cardie (2002) who used a rule based approach. $$$$$ As a result, we modify the coreference clustering algorithm to select as the antecedent of NP✄ the NP with the highest coreference likelihood value from among preceding NPs with coreference class values above 0.5.
The use of latent antecedents goes back to the work of Yu and Joachims (2009), although the idea of determining meaningful antecedents for mentions can be tracedback to Ng and Cardie (2002) who used a rule based approach. $$$$$ As a result, we modify the coreference clustering algorithm to select as the antecedent of NP✄ the NP with the highest coreference likelihood value from among preceding NPs with coreference class values above 0.5.

One way to utilize the semantic compatibility is to take it as a feature under the single-candidate learning model as employed by Ng and Cardie (2002). $$$$$ This method of negative instance selection is further described in Soon et al. (2001); it is designed to operate in conjunction with their method for creating coreference chains, which is explained next.
One way to utilize the semantic compatibility is to take it as a feature under the single-candidate learning model as employed by Ng and Cardie (2002). $$$$$ Results on the learning framework modifications are shown in Table 2 (third block of results).
One way to utilize the semantic compatibility is to take it as a feature under the single-candidate learning model as employed by Ng and Cardie (2002). $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.
One way to utilize the semantic compatibility is to take it as a feature under the single-candidate learning model as employed by Ng and Cardie (2002). $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.

In the testing phase, we used the best-first clustering as in Ng and Cardie (2002). $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.
In the testing phase, we used the best-first clustering as in Ng and Cardie (2002). $$$$$ Results are shown in Table 2 (Duplicated Soon Baseline) where performance is reported in terms of recall, precision, and F-measure using the modeltheoretic MUC scoring program (Vilain et al., 1995). features.
In the testing phase, we used the best-first clustering as in Ng and Cardie (2002). $$$$$ Improvements arise from two sources: extra-linguistic changes to the learning framework and a large-scale expansion of the feature set to include more sophisticated linguistic knowledge.

We test on the ANC Test set (1291 instances) also used in Bergsma (2005) (highest resolution accuracy reported: 73.3%), the anaphora labelled portion of AQUAINT used in Cherry and Bergsma (2005) (1078 instances, highest accuracy: 71.4%), and the anaphoric pronoun subset of the MUC7 (1997) coreference evaluation formal test set (169 instances, highest precision of 62.1 reported on all pronouns in (Ng and Cardie, 2002)). $$$$$ We investigate two methods to improve existing machine learning approaches to the problem of noun phrase coreference resolution.
We test on the ANC Test set (1291 instances) also used in Bergsma (2005) (highest resolution accuracy reported: 73.3%), the anaphora labelled portion of AQUAINT used in Cherry and Bergsma (2005) (1078 instances, highest accuracy: 71.4%), and the anaphoric pronoun subset of the MUC7 (1997) coreference evaluation formal test set (169 instances, highest precision of 62.1 reported on all pronouns in (Ng and Cardie, 2002)). $$$$$ Improvements arise from two sources: extra-linguistic changes to the learning framework and a large-scale expansion of the feature set to include more sophisticated linguistic knowledge.
We test on the ANC Test set (1291 instances) also used in Bergsma (2005) (highest resolution accuracy reported: 73.3%), the anaphora labelled portion of AQUAINT used in Cherry and Bergsma (2005) (1078 instances, highest accuracy: 71.4%), and the anaphoric pronoun subset of the MUC7 (1997) coreference evaluation formal test set (169 instances, highest precision of 62.1 reported on all pronouns in (Ng and Cardie, 2002)). $$$$$ We plan to continue investigations along these lines, developing, for example, a true best-first clustering coreference framework and exploring a “supervised clustering” approach to the problem.
We test on the ANC Test set (1291 instances) also used in Bergsma (2005) (highest resolution accuracy reported: 73.3%), the anaphora labelled portion of AQUAINT used in Cherry and Bergsma (2005) (1078 instances, highest accuracy: 71.4%), and the anaphoric pronoun subset of the MUC7 (1997) coreference evaluation formal test set (169 instances, highest precision of 62.1 reported on all pronouns in (Ng and Cardie, 2002)). $$$$$ For example, coreferent NPs must agree both in gender and number (AGREEMENT); cannot SPAN one another (e.g.

Ng and Cardie (2002) expanded the feature set of Soon et al (2001) from 12 to 53 features. $$$$$ We follow the procedure employed in Soon et al. to create the training data: we rely on coreference chains from the MUC answer keys to create (1) a positive instance for each anaphoric noun phrase, NP✄ , and its closest preceding antecedent, NP✂ ; and (2) a negative instance for NP✄ paired with each of the intervening NPs, NP✂ , NP✂ , , NP✄ .
Ng and Cardie (2002) expanded the feature set of Soon et al (2001) from 12 to 53 features. $$$$$ Results on the learning framework modifications are shown in Table 2 (third block of results).
Ng and Cardie (2002) expanded the feature set of Soon et al (2001) from 12 to 53 features. $$$$$ We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC- 6 and MUC-7 coreference resolution data sets — F-measures of 70.4 and 63.4, respectively.
Ng and Cardie (2002) expanded the feature set of Soon et al (2001) from 12 to 53 features. $$$$$ Overall, the learning framework and linguistic knowledge source modifications boost performance of Soon’s learning-based coreference resolution approach from an F-measure of 62.6 to 70.4, and from 60.4 to 63.4 for the MUC-6 and MUC-7 data sets, respectively.

Ng and Cardie (2002) split this feature into several primitive features, depending on the type of noun phrases. $$$$$ Building an NP coreference classifier.
Ng and Cardie (2002) split this feature into several primitive features, depending on the type of noun phrases. $$$$$ Because sources of linguistic information in a learning-based system are represented as features, we can, in contrast, incorporate them selectively rather than as universal hard constraints.
Ng and Cardie (2002) split this feature into several primitive features, depending on the type of noun phrases. $$$$$ For pronouns, we assume that the most confident antecedent is simply its closest preceding antecedent.

Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.
Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 0081334 and 0074896.
Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ Results are shown in Table 2 (Duplicated Soon Baseline) where performance is reported in terms of recall, precision, and F-measure using the modeltheoretic MUC scoring program (Vilain et al., 1995). features.
Barzilay and Lapata (2008) use the coreference system of Ng and Cardie (2002) to obtain coreference annotations. $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 0081334 and 0074896.

Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.
Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. $$$$$ For the MUC-7 corpus, we obtain a training set of 35895 instances (4.4% positive) from 5270 NPs and a test set of 22699 instances (3.9% positive) from 3558 NPs.
Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. $$$$$ Similar, but weaker, effects occur when applying each of the learning framework modifications to the Baseline system in isolation.
Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. $$$$$ The primary reason for improvements over the original Soon system for the MUC-6 data set appears to be our higher upper bound on recall (93.8% vs. 89.9%), due to better identification of NPs.

Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information can be incorporated into a coreference resolution system. $$$$$ First, we find that performance drops significantly when using the full feature set, even though the learning algorithms investigated have built-in feature selection mechanisms.
Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information can be incorporated into a coreference resolution system. $$$$$ First, we propose three extra-linguistic modifications to the machine learning framework, which together consistently produce statistically significant gains in precision and corresponding increases in F-measure.
Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information can be incorporated into a coreference resolution system. $$$$$ We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC- 6 and MUC-7 coreference resolution data sets — F-measures of 70.4 and 63.4, respectively.
Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information can be incorporated into a coreference resolution system. $$$$$ We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC- 6 and MUC-7 coreference resolution data sets — F-measures of 70.4 and 63.4, respectively.

In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning. $$$$$ We demonstrate empirically that the degradation in performance can be attributed, at least in part, to poor performance on common noun resolution.
In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning. $$$$$ We also plan to investigate previous work on common noun phrase interpretation (e.g.
In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning. $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.
In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning. $$$$$ Lappin and Leass (1994)) and NP coreference resolution (e.g.

It is the same as most prior work in the literature, including Soon et al (2001) and Ng and Cardie (2002b). $$$$$ Exact string match is likely to be a better coreference predictor for proper names than it is for pronouns, for example.
It is the same as most prior work in the literature, including Soon et al (2001) and Ng and Cardie (2002b). $$$$$ Thanks to three anonymous reviewers for their comments and, in particular, for suggesting that we investigate data fragmentation issues.
It is the same as most prior work in the literature, including Soon et al (2001) and Ng and Cardie (2002b). $$$$$ Here, feature selection does not depend on a separate development corpus and is guided solely by inspection of the features associated with low-precision rules induced from the training data.
It is the same as most prior work in the literature, including Soon et al (2001) and Ng and Cardie (2002b). $$$$$ In addition, we provide the learning algorithms with many additional linguistic knowledge sources for coreference resolution.

In the literature, besides the training instance extraction methods proposed by Soon et al (2001) and Ng and Cardie (2002b) as discussed in Section 2, McCarthy and Lehnert (1995) used all possible pairs of training instances. $$$$$ Nevertheless, there is substantial room for improvement.
In the literature, besides the training instance extraction methods proposed by Soon et al (2001) and Ng and Cardie (2002b) as discussed in Section 2, McCarthy and Lehnert (1995) used all possible pairs of training instances. $$$$$ We plan to continue investigations along these lines, developing, for example, a true best-first clustering coreference framework and exploring a “supervised clustering” approach to the problem.
In the literature, besides the training instance extraction methods proposed by Soon et al (2001) and Ng and Cardie (2002b) as discussed in Section 2, McCarthy and Lehnert (1995) used all possible pairs of training instances. $$$$$ In particular, our tree makes use of many of the features that are not present in the original Soon feature set.
In the literature, besides the training instance extraction methods proposed by Soon et al (2001) and Ng and Cardie (2002b) as discussed in Section 2, McCarthy and Lehnert (1995) used all possible pairs of training instances. $$$$$ First, we propose three extra-linguistic modifications to the machine learning framework, which together consistently produce statistically significant gains in precision and corresponding increases in F-measure.

Plenty of machine learning algorithms such as Decision tree (Ng and Cardie, 2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. $$$$$ We also plan to investigate previous work on common noun phrase interpretation (e.g.
Plenty of machine learning algorithms such as Decision tree (Ng and Cardie, 2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. $$$$$ 53.3 for MUC-6/RIPPER and 61.0 for MUC7/RIPPER with lower recall in both cases) where the primary mechanism employed by the classifiers for common noun resolution is its high-precision string matching facility.
Plenty of machine learning algorithms such as Decision tree (Ng and Cardie, 2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. $$$$$ We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC- 6 and MUC-7 coreference resolution data sets — F-measures of 70.4 and 63.4, respectively.
Plenty of machine learning algorithms such as Decision tree (Ng and Cardie, 2002), maximum entropy model, logistic regression (Bjorkelund and Nugues, 2011), Support Vector Machines, have been used to solve this problem. $$$$$ As in Soon et al., texts are processed from left to right.

At first glance, source coreference resolution appears equivalent to the task of noun phrase coreference resolution and therefore amenable to traditional coreference resolution techniques (e.g. Ng and Cardie (2002), Morton (2000)). $$$$$ Both sets of results are at least as strong as the original Soon results (row one of Table 2), indicating indirectly that our Baseline system is a reasonable duplication of that system.4 In addition, the trees produced by Soon and by our Duplicated Soon Baseline are essentially the same, differing only in two places where the Baseline system imposes additional conditions on coreference.
At first glance, source coreference resolution appears equivalent to the task of noun phrase coreference resolution and therefore amenable to traditional coreference resolution techniques (e.g. Ng and Cardie (2002), Morton (2000)). $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 0081334 and 0074896.
At first glance, source coreference resolution appears equivalent to the task of noun phrase coreference resolution and therefore amenable to traditional coreference resolution techniques (e.g. Ng and Cardie (2002), Morton (2000)). $$$$$ In sections 2 and 3, we present the baseline coreference system and explore extra-linguistic modifications to the machine learning framework.

Coreference resolution is a relatively well studied NLP problem (e.g. Morton (2000), Ng and Cardie (2002), Iida et al (2003), McCallum and Wellner (2003)). $$$$$ Similarly, three new features determine the grammatical role of one or both of the NPs.
Coreference resolution is a relatively well studied NLP problem (e.g. Morton (2000), Ng and Cardie (2002), Iida et al (2003), McCallum and Wellner (2003)). $$$$$ We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC- 6 and MUC-7 coreference resolution data sets — F-measures of 70.4 and 63.4, respectively.
Coreference resolution is a relatively well studied NLP problem (e.g. Morton (2000), Ng and Cardie (2002), Iida et al (2003), McCallum and Wellner (2003)). $$$$$ We test for ancestor-descendent relationships in WordNet (SUBCLASS), for example, and also measure the WordNet graph-traversal distance (WNDIST) between NP✄ and NP✂ .
Coreference resolution is a relatively well studied NLP problem (e.g. Morton (2000), Ng and Cardie (2002), Iida et al (2003), McCallum and Wellner (2003)). $$$$$ The most substantial changes to the feature set, however, occur for grammatical features: we add 26 new features to allow the acquisition of more sophisticated syntactic coreference resolution rules.

Our general approach to source coreference resolution is inspired by the state-of-the-art performance of one such approach to coreference resolution, which relies on a rule learner and single-link clustering as described in Ng and Cardie (2002). $$$$$ This rule covers 38 examples, but has 18 exceptions.
Our general approach to source coreference resolution is inspired by the state-of-the-art performance of one such approach to coreference resolution, which relies on a rule learner and single-link clustering as described in Ng and Cardie (2002). $$$$$ We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC- 6 and MUC-7 coreference resolution data sets — F-measures of 70.4 and 63.4, respectively.
Our general approach to source coreference resolution is inspired by the state-of-the-art performance of one such approach to coreference resolution, which relies on a rule learner and single-link clustering as described in Ng and Cardie (2002). $$$$$ Relational features test whether some property P holds for the NP pair under consideration and indicate whether the NPs are COMPATIBLE or INCOMPATIBLE w.r.t.
Our general approach to source coreference resolution is inspired by the state-of-the-art performance of one such approach to coreference resolution, which relies on a rule learner and single-link clustering as described in Ng and Cardie (2002). $$$$$ We investigate two methods to improve existing machine learning approaches to the problem of noun phrase coreference resolution.

We use the features introduced by Ng and Cardie (2002) for the task of coreference resolution. $$$$$ For MUC-7, our improvement stems from increases in precision, presumably due to more accurate feature value computation.
We use the features introduced by Ng and Cardie (2002) for the task of coreference resolution. $$$$$ We follow the procedure employed in Soon et al. to create the training data: we rely on coreference chains from the MUC answer keys to create (1) a positive instance for each anaphoric noun phrase, NP✄ , and its closest preceding antecedent, NP✂ ; and (2) a negative instance for NP✄ paired with each of the intervening NPs, NP✂ , NP✂ , , NP✄ .
We use the features introduced by Ng and Cardie (2002) for the task of coreference resolution. $$$$$ Discussion.
We use the features introduced by Ng and Cardie (2002) for the task of coreference resolution. $$$$$ When used in combination, the modifications consistently provide statistically significant gains in precision over the Baseline system 5This new method of training set creation slightly alters the class value distribution in the training data: for the MUC-6 corpus, there are now 27654 training instances of which 5.2% are positive; for the MUC-7 corpus, there are now 37870 training instances of which 4.2% are positive. without any loss in recall.6 As a result, we observe reasonable increases in F-measure for both classifiers and both data sets.

We develop a novel method for partially supervised clustering, which is motivated by the success of a rule learner (RIPPER) for coreference resolution (Ng and Cardie, 2002). $$$$$ We present a noun phrase coreference system that extends the work of Soon et al. (2001) and, to our knowledge, produces the best results to date on the MUC- 6 and MUC-7 coreference resolution data sets — F-measures of 70.4 and 63.4, respectively.
We develop a novel method for partially supervised clustering, which is motivated by the success of a rule learner (RIPPER) for coreference resolution (Ng and Cardie, 2002). $$$$$ This work was supported in part by DARPA TIDES contract N66001-00-C-8009, and NSF Grants 0081334 and 0074896.
We develop a novel method for partially supervised clustering, which is motivated by the success of a rule learner (RIPPER) for coreference resolution (Ng and Cardie, 2002). $$$$$ Similar, but weaker, effects occur when applying each of the learning framework modifications to the Baseline system in isolation.
We develop a novel method for partially supervised clustering, which is motivated by the success of a rule learner (RIPPER) for coreference resolution (Ng and Cardie, 2002). $$$$$ As in Soon et al., texts are processed from left to right.
