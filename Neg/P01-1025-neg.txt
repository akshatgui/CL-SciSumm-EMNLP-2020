We are aware of the fact that other measures of lexical association have been proposed (Evert and Krenn, 2001, and MI values were computed using Adam Berger's trigger toolkit (Berger, 1997). $$$$$ Even the highest precision estimates fall well below the 6.41% precision baseline of the PNV data with .
We are aware of the fact that other measures of lexical association have been proposed (Evert and Krenn, 2001, and MI values were computed using Adam Berger's trigger toolkit (Berger, 1997). $$$$$ It is imaginable, then, that one of the AMs 11To be precise, the binomial distribution is itself an approximation of the exact hypergeometric probabilities (cf.
We are aware of the fact that other measures of lexical association have been proposed (Evert and Krenn, 2001, and MI values were computed using Adam Berger's trigger toolkit (Berger, 1997). $$$$$ In the case of the AdjN data ( , ), we find that at a confidence level of 99% ( ).
We are aware of the fact that other measures of lexical association have been proposed (Evert and Krenn, 2001, and MI values were computed using Adam Berger's trigger toolkit (Berger, 1997). $$$$$ Finally, our results question the widely accepted argument that the strength of loglikelihood lies in handling low-frequency data.

 $$$$$ We also show how estimates for the very large number of hapaxlegomena and double occurrences can be inferred from random samples.
 $$$$$ Based on these requirements, we introduce an experimentation procedure, and discuss the evaluation results for a number of widely used AMs.
 $$$$$ The first set comprises bigrams of adjacent, lemmatized AdjN pairs extracted from a small ( word) corpus of freely available German law texts.3 Due to the extraction strategy, the data are homogeneous and grammatically correct, i.e., there is (almost) always a grammatical dependency between adjacent adjectives and nouns in running text.
 $$$$$ As the full curves show, log-likelihood is obviously the best measure.

Following the methodology described by Evert and Krenn (2001), German PP-verb combinations were extracted from a chunk-parsed version of the Frankfurter Rundschau Corpus. $$$$$ Manual annotation was performed for AdjN pairs with frequency and PNV triples with only (see section 5 for a discussion of the excluded low-frequency candidates).
Following the methodology described by Evert and Krenn (2001), German PP-verb combinations were extracted from a chunk-parsed version of the Frankfurter Rundschau Corpus. $$$$$ In order to reduce the amount of manual work, the precision values for each AM are based on a 10% random sample from the 10 000 highest ranked candidates.
Following the methodology described by Evert and Krenn (2001), German PP-verb combinations were extracted from a chunk-parsed version of the Frankfurter Rundschau Corpus. $$$$$ The picture differs slightly for the PNV data (Figure 2).
Following the methodology described by Evert and Krenn (2001), German PP-verb combinations were extracted from a chunk-parsed version of the Frankfurter Rundschau Corpus. $$$$$ In our approach, we compare the entire list of candidates, sorted according to the particular measures, to a reference set of manually identified “true positives”.

 $$$$$ The measures – Mutual Information ( ) (Church and Hanks, 1989), the log-likelihood ratio test (Dunning, 1993), two statistical tests: t-test and -test, and co-occurrence frequency – are applied to two sets of data: adjective-noun (AdjN) pairs and preposition-noun-verb (PNV) triples, where the AMs are applied to (PN,V) pairs.
 $$$$$ Thus, there should be at most 320 TPs among the AdjN candidates with Compared to the 737 TPs identified in the AdjN data with , our decision to exclude the hapaxlegomena was well justified.
 $$$$$ Consequently, results achieved by individual measures may very well be due to chance (cf. sections 4.1 and 4.2), and evaluation with respect to frequency strata is not possible (cf. section 4.3).
 $$$$$ The second set consists of PNV triples extracted from an 8 million word portion of the Frankfurter Rundschau Corpus4, in which partof-speech tags and minimal PPs were identified.5 The PNV triples were selected automatically such that the preposition and the noun are constituents of the same PP, and the PP and the verb co-occur within a sentence.

In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable than frequency counting. $$$$$ : zur Verfügung stellen (at_the availability put, ‘make available’), am Herzen liegen (at the heart lie, ‘have at heart’).7 General statistics for the AdjN and PNV base sets are given in Table 1.
In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable than frequency counting. $$$$$ In our experiments, none of the AMs was able to extract a substantial number of collocations from the set of hapaxlegomena.
In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable than frequency counting. $$$$$ Log-likelihood achieves precision values above 50% for the first 10% of the list, but is outperformed by the t-test afterwards.

In particular Evert and Krenn (2001) use the chi-square test which assumes independent samples and is thus not really suitable for testing the significance of differences of two or more measures which are typically run on the same set of candidates (i.e., a dependent sample). $$$$$ The criteria used for the distinction between collocations and arbitrary word combinations are: There is a grammatical relation between the verb and the PP, and the triple can be interpreted as support verb construction and/or a metaphoric or idiomatic reading is available, e.g.
In particular Evert and Krenn (2001) use the chi-square test which assumes independent samples and is thus not really suitable for testing the significance of differences of two or more measures which are typically run on the same set of candidates (i.e., a dependent sample). $$$$$ Again, we conclude that the exclusion of low-frequency candidates was well justified.
In particular Evert and Krenn (2001) use the chi-square test which assumes independent samples and is thus not really suitable for testing the significance of differences of two or more measures which are typically run on the same set of candidates (i.e., a dependent sample). $$$$$ And only for -best lists with , frequency performs marginally significantly worse than log-likelihood.

As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). $$$$$ In our approach, we compare the entire list of candidates, sorted according to the particular measures, to a reference set of manually identified “true positives”.
As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). $$$$$ Two human annotators independently marked candidate pairs perceived as “typical” combinations, including idioms ((die) hohe See, ‘the high seas’), legal terms (üble Nachrede, ‘slander’), and proper names (Rotes Kreuz, ‘Red Cross’).
As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). $$$$$ (2) For the same reason, it is impossible to determine recall values, which are important for many practical applications.
As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). $$$$$ Typically, the number of true positives (TPs) among the 50 or 100 (or slightly more) highest ranked word combinations is manually identified by a human evaluator, in most cases the author of the paper in which the evaluation is presented.

To overcome these limitations, we use the evaluation method described by Evert and Krenn (2001). $$$$$ In contrast to our expectation stated at the beginning of this section, the performance of and relative to the other AMs is not better for high-frequency data than for low-frequency data.
To overcome these limitations, we use the evaluation method described by Evert and Krenn (2001). $$$$$ A practical reason for cutting off low-frequency data is the need to reduce the amount of manual work when the complete data set has to be evaluated, which is a precondition for the exact calculation of recall and for plotting precision curves.
To overcome these limitations, we use the evaluation method described by Evert and Krenn (2001). $$$$$ In our approach, we compare the entire list of candidates, sorted according to the particular measures, to a reference set of manually identified “true positives”.

Cf. also Evert and Krenn (2001) for empirical evidence justifying the exclusion of low-frequency data. $$$$$ The authors would like to thank the anonymous reviewers for many helpful comments and interesting references.
Cf. also Evert and Krenn (2001) for empirical evidence justifying the exclusion of low-frequency data. $$$$$ This procedure allows us to assess the performance of AMs within different frequency strata.
Cf. also Evert and Krenn (2001) for empirical evidence justifying the exclusion of low-frequency data. $$$$$ Log-likelihood is second best but achieves the best results for highfrequency AdjN data. ence between the AMs for low-frequency data, except for co-occurrence frequency, which leads to worse results than all other measures.

The comparison to the t-test is especially interesting because it was found to achieve the best overall precision scores in other studies (see Evert and Krenn (2001)). $$$$$ Samples comprising particular frequency strata (high versus low frequencies) are examined (section 4.3).
The comparison to the t-test is especially interesting because it was found to achieve the best overall precision scores in other studies (see Evert and Krenn (2001)). $$$$$ Samples comprising particular frequency strata (high versus low frequencies) are examined (section 4.3).
The comparison to the t-test is especially interesting because it was found to achieve the best overall precision scores in other studies (see Evert and Krenn (2001)). $$$$$ : zur Verfügung stellen (at_the availability put, ‘make available’), am Herzen liegen (at the heart lie, ‘have at heart’).7 General statistics for the AdjN and PNV base sets are given in Table 1.
The comparison to the t-test is especially interesting because it was found to achieve the best overall precision scores in other studies (see Evert and Krenn (2001)). $$$$$ There is no significant difference between loglikelihood and t-test.

We also define four features that represent known collocation measures (Evert and Krenn, 2001): Point-wise mutual information (PMI); T-Score; log-likelihood; and the raw frequency of N1 N2 in the corpus. $$$$$ Again, we conclude that the exclusion of low-frequency candidates was well justified.
We also define four features that represent known collocation measures (Evert and Krenn, 2001): Point-wise mutual information (PMI); T-Score; log-likelihood; and the raw frequency of N1 N2 in the corpus. $$$$$ We have also shown that the evaluation results and the ranking of AMs differ depending on the kind of collocations to be identified, and the proportion of hapaxes in the candidate sets.
We also define four features that represent known collocation measures (Evert and Krenn, 2001): Point-wise mutual information (PMI); T-Score; log-likelihood; and the raw frequency of N1 N2 in the corpus. $$$$$ (3) The introduction of new measures or changes to the calculation methods require additional manual evaluation, as new -best lists are generated.

To eliminate noisy low-frequency data (cf. also Evert and Krenn (2001)), we defined different frequency cut-off thresholds, c, for the bigram, trigram and quadgram candidate sets and only considered candidates above these thresholds. $$$$$ For the PNV data (not shown), the t-test is significantly better than log-likelihood, but the difference between frequency and the t-test is at best marginally significant.
To eliminate noisy low-frequency data (cf. also Evert and Krenn (2001)), we defined different frequency cut-off thresholds, c, for the bigram, trigram and quadgram candidate sets and only considered candidates above these thresholds. $$$$$ We have applied the statistical test described above to obtain confidence intervals for the true precision values of the bestperforming AM (frequency), given our 10% sample.
To eliminate noisy low-frequency data (cf. also Evert and Krenn (2001)), we defined different frequency cut-off thresholds, c, for the bigram, trigram and quadgram candidate sets and only considered candidates above these thresholds. $$$$$ Finally, our results question the widely accepted argument that the strength of loglikelihood lies in handling low-frequency data.
To eliminate noisy low-frequency data (cf. also Evert and Krenn (2001)), we defined different frequency cut-off thresholds, c, for the bigram, trigram and quadgram candidate sets and only considered candidates above these thresholds. $$$$$ We apply a one-tailed statistical test based on the probabilities to our samples in order to obtain an upper estimate for the actual proportion of collocations among the low-frequency data: the estimate is accepted at a given significance level if . ) was much lower and we find that at the same confidence level of 99%.

We compare our P-Mod algorithm against the t-test measure, which, of all standard measures, yields the best results in general-language collocation extraction studies (Evert and Krenn, 2001), and also against the widely used C-value, which aims at enhancing the common frequency of occurrence measure by making it sensitive to nested terms (Frantzi et al, 2000). $$$$$ This paper presents methods for a qualitative, unbiased comparison of lexical association measures and the results we have obtained for adjective-noun pairs and preposition-noun-verb triples extracted from German corpora.
We compare our P-Mod algorithm against the t-test measure, which, of all standard measures, yields the best results in general-language collocation extraction studies (Evert and Krenn, 2001), and also against the widely used C-value, which aims at enhancing the common frequency of occurrence measure by making it sensitive to nested terms (Frantzi et al, 2000). $$$$$ P12920.

Studies on collocation extraction (e.g., by Evert and Krenn (2001)) also point out the inadequacy of such evaluation methods. $$$$$ In our approach, we compare the entire list of candidates, sorted according to the particular measures, to a reference set of manually identified “true positives”.
Studies on collocation extraction (e.g., by Evert and Krenn (2001)) also point out the inadequacy of such evaluation methods. $$$$$ Financial support for ÖFAI is provided by the Austrian Federal Ministry of Education, Science and Culture.
Studies on collocation extraction (e.g., by Evert and Krenn (2001)) also point out the inadequacy of such evaluation methods. $$$$$ The significance of differences between the AMs is addressed in section 6.
Studies on collocation extraction (e.g., by Evert and Krenn (2001)) also point out the inadequacy of such evaluation methods. $$$$$ The significance of differences between the AMs is addressed in section 6.

The evaluation procedure used here (first suggested by Evert and Krenn (2001) for evaluating measures of lexical association) involves producing and evaluating just such a ranking. $$$$$ We have also shown that the evaluation results and the ranking of AMs differ depending on the kind of collocations to be identified, and the proportion of hapaxes in the candidate sets.
The evaluation procedure used here (first suggested by Evert and Krenn (2001) for evaluating measures of lexical association) involves producing and evaluating just such a ranking. $$$$$ Figure 9 shows precision curves for the 10 000 highest ranked word combinations from each SL for PNV combinations with (the vertical lines correspond to -best lists for ).
The evaluation procedure used here (first suggested by Evert and Krenn (2001) for evaluating measures of lexical association) involves producing and evaluating just such a ranking. $$$$$ The work of B. Krenn has been sponsored by the Fonds zur Förderung der wissenschaftlichen Forschung (FWF), Grant No.
The evaluation procedure used here (first suggested by Evert and Krenn (2001) for evaluating measures of lexical association) involves producing and evaluating just such a ranking. $$$$$ We have assessed the significance of differences between AMs using the well-known test as described in (Krenn, 2000).12 The thin lines in Figure 10 delimit 95% confidence intervals around the best-performing measure for the AdjN data with (log-likelihood).

This is consistent with results reportedby Evert and Krenn (2001). $$$$$ In our approach, we compare the entire list of candidates, sorted according to the particular measures, to a reference set of manually identified “true positives”.
This is consistent with results reportedby Evert and Krenn (2001). $$$$$ Financial support for ÖFAI is provided by the Austrian Federal Ministry of Education, Science and Culture.
This is consistent with results reportedby Evert and Krenn (2001). $$$$$ The proportion of TPs in the PNV sample (

Our evaluation was partly inspired by Evert and Krenn (2001). $$$$$ This is a widely used strategy, and it is motivated by the fact that it is in general highly problematic to draw conclusions from low-frequency data with statistical methods (cf.
Our evaluation was partly inspired by Evert and Krenn (2001). $$$$$ The dotted horizontal line represents the percentage of true collocations in the base set.
Our evaluation was partly inspired by Evert and Krenn (2001). $$$$$ Another crucial but still unsolved issue in statistical collocation identification is the treatment of lowfrequency data.
Our evaluation was partly inspired by Evert and Krenn (2001). $$$$$ Consequently, results achieved by individual measures may very well be due to chance (cf. sections 4.1 and 4.2), and evaluation with respect to frequency strata is not possible (cf. section 4.3).

In Krenn & Evert 2001, frequency outperformed mutual information though not the t test, while in Evert and Krenn 2001, log-likelihood and the t-test gave the best results, and mutual information again performed worse than frequency. $$$$$ We have shown that simple -best approaches are not suitable for a qualitative evaluation of lexical association measures, mainly for the following reasons: the instability of precision values obtained from the first few percent of the data in the SLs; the lack of significant differences between the AMs after approx.
In Krenn & Evert 2001, frequency outperformed mutual information though not the t test, while in Evert and Krenn 2001, log-likelihood and the t-test gave the best results, and mutual information again performed worse than frequency. $$$$$ The proportion of TPs in the PNV sample (
In Krenn & Evert 2001, frequency outperformed mutual information though not the t test, while in Evert and Krenn 2001, log-likelihood and the t-test gave the best results, and mutual information again performed worse than frequency. $$$$$ Consequently, results achieved by individual measures may very well be due to chance (cf. sections 4.1 and 4.2), and evaluation with respect to frequency strata is not possible (cf. section 4.3).
In Krenn & Evert 2001, frequency outperformed mutual information though not the t test, while in Evert and Krenn 2001, log-likelihood and the t-test gave the best results, and mutual information again performed worse than frequency. $$$$$ Finally, our results question the widely accepted argument that the strength of loglikelihood lies in handling low-frequency data.
