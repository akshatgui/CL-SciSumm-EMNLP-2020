It has been pointed out in (Zens and Ney, 2003) that the ITG constraints can be characterized as follows $$$$$ The applications were, for instance, the segmentation of Chinese character sequences into Chinese “words” and the bracketing of the source sentence into sub-sentential chunks.
It has been pointed out in (Zens and Ney, 2003) that the ITG constraints can be characterized as follows $$$$$ The training corpus (Train) was used to train the IBM model parameters.
It has been pointed out in (Zens and Ney, 2003) that the ITG constraints can be characterized as follows $$$$$ The resulting algorithm is similar to the one presented in Sect.
It has been pointed out in (Zens and Ney, 2003) that the ITG constraints can be characterized as follows $$$$$ Then, we will compare the translation results when restricting the search to either of these constraints.

A comparison of the ITG constraints and the IBM constraints for single-word based models can be found in (Zens and Ney, 2003). $$$$$ 3.1, but here, we use monotone translation hypotheses of the full IBM Model 4 as initialization, whereas in (Wu, 1996) a single-word based lexicon model is used.
A comparison of the ITG constraints and the IBM constraints for single-word based models can be found in (Zens and Ney, 2003). $$$$$ The evaluation consists of two parts: First, we check how many of the Viterbi alignments of the training corpus satisfy each of these constraints.
A comparison of the ITG constraints and the IBM constraints for single-word based models can be found in (Zens and Ney, 2003). $$$$$ This comparison includes a theoretical discussion on the permitted number of reorderings for each of these constraints.
A comparison of the ITG constraints and the IBM constraints for single-word based models can be found in (Zens and Ney, 2003). $$$$$ Second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.

(Zens and Ney, 2003) did comparative study over different reordering constraints. $$$$$ This representation is equivalent to the parse trees of the simple grammar in (Wu, 1997).
(Zens and Ney, 2003) did comparative study over different reordering constraints. $$$$$ In statistical machine translation, we are given a source language (‘French’) sentence fJ1 = f1 ... fj ... fJ, which is to be translated into a target language (‘English’) sentence eI1 = e1 ... ei ... eI.
(Zens and Ney, 2003) did comparative study over different reordering constraints. $$$$$ Table 2 shows the corpus statistics of this corpus.
(Zens and Ney, 2003) did comparative study over different reordering constraints. $$$$$ The applications were, for instance, the segmentation of Chinese character sequences into Chinese “words” and the bracketing of the source sentence into sub-sentential chunks.

6 compares our results to related work, in particular Zens and Ney (2003). $$$$$ Therefore, in this section, we will describe different aspects of the search algorithm for the ITG constraints.
6 compares our results to related work, in particular Zens and Ney (2003). $$$$$ The ITG constraints were introduced in (Wu, 1995).

Related work includes Wu (1997), Zens and Ney (2003) and Wellington et al (2006). $$$$$ In Tab.
Related work includes Wu (1997), Zens and Ney (2003) and Wellington et al (2006). $$$$$ In (Wu, 1996) the baseline ITG constraints were used for statistical machine translation.
Related work includes Wu (1997), Zens and Ney (2003) and Wellington et al (2006). $$$$$ Then, we check for every sentence if the alignment satisfies each of the constraints.
Related work includes Wu (1997), Zens and Ney (2003) and Wellington et al (2006). $$$$$ Second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.

xITGs (Zens and Ney, 2003) in part solves this problem. $$$$$ The edges are annotated with target language words or phrases.

 $$$$$ 2.
 $$$$$ For longer sentences, the ITG constraints allow for much more flexibility than the IBM constraints.
 $$$$$ On the Canadian Hansards task the baseline ITG constraints were not sufficient.
 $$$$$ The evaluation consists of two parts: First, we check how many of the Viterbi alignments of the training corpus satisfy each of these constraints.

Zens and Ney (2003) used GIZA++ to word-align the Verbmobil task (English and German) and the Canadian Hansards task (English and French) and tested the coverage of ITGs and xITGs, i.e. the ratio of the number of alignment configurations that could be induced by the theories and the sentences in the two tasks. $$$$$ Among all possible target language sentences, we will choose the sentence with the highest probability: The decomposition into two knowledge sources in Eq.
Zens and Ney (2003) used GIZA++ to word-align the Verbmobil task (English and German) and the Canadian Hansards task (English and French) and tested the coverage of ITGs and xITGs, i.e. the ratio of the number of alignment configurations that could be induced by the theories and the sentences in the two tasks. $$$$$ These extended ITG constraints increase the alignment coverage from about 87% to 96%.
Zens and Ney (2003) used GIZA++ to word-align the Verbmobil task (English and German) and the Canadian Hansards task (English and French) and tested the coverage of ITGs and xITGs, i.e. the ratio of the number of alignment configurations that could be induced by the theories and the sentences in the two tasks. $$$$$ This idea is illustrated in Fig.

ITG imposes constraints on which alignments are possible, and these constraints have been shown to be a good match for real bi text data (Zens and Ney, 2003). $$$$$ The target language model describes the well-formedness of the target language sentence.
ITG imposes constraints on which alignments are possible, and these constraints have been shown to be a good match for real bi text data (Zens and Ney, 2003). $$$$$ The situation gets even worse when a trigram language model is used.
ITG imposes constraints on which alignments are possible, and these constraints have been shown to be a good match for real bi text data (Zens and Ney, 2003). $$$$$ The first constraints are based on inversion transduction grammars (ITG) (Wu, 1995; Wu, 1997).
ITG imposes constraints on which alignments are possible, and these constraints have been shown to be a good match for real bi text data (Zens and Ney, 2003). $$$$$ We observe that a given permutation may be constructed in several ways by the above method.

For a comparison and a more detailed discussion of the two approaches see (Zens and Ney, 2003). $$$$$ Table 2 shows the corpus statistics of this corpus.
For a comparison and a more detailed discussion of the two approaches see (Zens and Ney, 2003). $$$$$ A significantly higher coverage of about 96% is obtained with the extended ITG constraints.
For a comparison and a more detailed discussion of the two approaches see (Zens and Ney, 2003). $$$$$ For the Verbmobil task, the baseline ITG constraints and the IBM constraints result in a similar coverage.

Such reordering was realized either by an additional constraint for decoding, such as window constraints, IBM constraints or ITG-constraints (Zens and Ney,2003), or by lexicalized reordering feature functions (Tillman, 2004). $$$$$ In our experiments, we use the following error criteria: The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the target sentence.
Such reordering was realized either by an additional constraint for decoding, such as window constraints, IBM constraints or ITG-constraints (Zens and Ney,2003), or by lexicalized reordering feature functions (Tillman, 2004). $$$$$ 4 shows the results for the Verbmobil task and for the Canadian Hansards task.
Such reordering was realized either by an additional constraint for decoding, such as window constraints, IBM constraints or ITG-constraints (Zens and Ney,2003), or by lexicalized reordering feature functions (Tillman, 2004). $$$$$ The training corpus (Train) was used to train the IBM model parameters.

Zens and Ney (2003) found that the constraints of ITG were a better match to the decoding task than the heuristics used in the IBM decoder of Berger et al (1996). $$$$$ 5 the results for the Verbmobil task are shown.
Zens and Ney (2003) found that the constraints of ITG were a better match to the decoding task than the heuristics used in the IBM decoder of Berger et al (1996). $$$$$ On the other hand, if we restrict the possible word-reorderings in an appropriate way, we obtain a polynomial-time search algorithm.
Zens and Ney (2003) found that the constraints of ITG were a better match to the decoding task than the heuristics used in the IBM decoder of Berger et al (1996). $$$$$ This comparison includes a theoretical discussion on the permitted number of reorderings for each of these constraints.
Zens and Ney (2003) found that the constraints of ITG were a better match to the decoding task than the heuristics used in the IBM decoder of Berger et al (1996). $$$$$ Let us now consider the ITG constraints.

The ITG we apply in our experiments has more structural labels than the primitive bracketing grammar $$$$$ Table 3 shows the training and test corpus statistics.
The ITG we apply in our experiments has more structural labels than the primitive bracketing grammar $$$$$ 5 the results for the Verbmobil task are shown.
The ITG we apply in our experiments has more structural labels than the primitive bracketing grammar $$$$$ In the following, we will call these the ITG constraints.
The ITG we apply in our experiments has more structural labels than the primitive bracketing grammar $$$$$ 2 is the so-called source-channel approach to statistical machine translation (Brown et al., 1990).

Some of the properties of these alignments are studied in (Zens and Ney, 2003). $$$$$ Here, J is the length of the source sentence and E is the vocabulary size of the target language.
Some of the properties of these alignments are studied in (Zens and Ney, 2003). $$$$$ For each test sentence, not only a single reference translation is used, as for the WER, but a whole set of reference translations.
Some of the properties of these alignments are studied in (Zens and Ney, 2003). $$$$$ In (Vilar, 1998) a model similar to Wu’s method was considered.
Some of the properties of these alignments are studied in (Zens and Ney, 2003). $$$$$ With the extended ITG constraints the coverage improves significantly on both tasks.

A comparison of both methods can be found in Zens and Ney (2003). $$$$$ BLEU measures accuracy, i.e. large BLEU scores are better.
A comparison of both methods can be found in Zens and Ney (2003). $$$$$ Therefore, in this section we will show the corpus statistics for each of these tasks.
A comparison of both methods can be found in Zens and Ney (2003). $$$$$ Here, the coverage increases from about 87% for the IBM constraints to about 96% for the extended ITG constraints.
A comparison of both methods can be found in Zens and Ney (2003). $$$$$ In this section, we will investigate for each of the constraints the coverage of the training corpus alignment.

A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints with m= 4 as IBM (4). $$$$$ The ratio of the number of satisfied alignments and the total number of sentences is referred to as coverage.
A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints with m= 4 as IBM (4). $$$$$ On the Canadian Hansards task the coverage increases from about 87% to about 96%.
A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints with m= 4 as IBM (4). $$$$$ In the first example, the German verb-group (“w¨urde vorschlagen”) is split into two parts.
A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints with m= 4 as IBM (4). $$$$$ On the Canadian Hansards task the baseline ITG constraints were not sufficient.

Zens and Ney (2003) [3] show that ITG constraints yield significantly better alignment coverage than the constraints used in IBM statistical machine translation models on both German-English (Verbmobil corpus) and French-English (Canadian Hansards corpus). $$$$$ Future work will include the automatic extraction of the bilingual grammar as well as the use of this grammar for the translation process.
Zens and Ney (2003) [3] show that ITG constraints yield significantly better alignment coverage than the constraints used in IBM statistical machine translation models on both German-English (Verbmobil corpus) and French-English (Canadian Hansards corpus). $$$$$ The final word graphs is constructed by merging the two start nodes and the two end nodes, respectively.
Zens and Ney (2003) [3] show that ITG constraints yield significantly better alignment coverage than the constraints used in IBM statistical machine translation models on both German-English (Verbmobil corpus) and French-English (Canadian Hansards corpus). $$$$$ For the Canadian Hansards task, the baseline ITG constraints yield a worse coverage than the IBM constraints.
Zens and Ney (2003) [3] show that ITG constraints yield significantly better alignment coverage than the constraints used in IBM statistical machine translation models on both German-English (Verbmobil corpus) and French-English (Canadian Hansards corpus). $$$$$ The search with the ITG constraints is able to produce a correct translation.

Because of this, Wu (1997) and Zens and Ney (2003) introduced a normal form ITG which avoids this over-counting. $$$$$ Additionally, edges may be annotated with probabilities of the language or translation model.
Because of this, Wu (1997) and Zens and Ney (2003) introduced a normal form ITG which avoids this over-counting. $$$$$ A significantly higher coverage of about 96% is obtained with the extended ITG constraints.
Because of this, Wu (1997) and Zens and Ney (2003) introduced a normal form ITG which avoids this over-counting. $$$$$ The target language model describes the well-formedness of the target language sentence.
Because of this, Wu (1997) and Zens and Ney (2003) introduced a normal form ITG which avoids this over-counting. $$$$$ Only towards the end of the sentence this is reduced to the number of remaining uncovered source positions.

This source of overcounting is considered and fixed by Wu (1997) and Zens and Ney (2003), which we briefly review here. $$$$$ Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000).
This source of overcounting is considered and fixed by Wu (1997) and Zens and Ney (2003), which we briefly review here. $$$$$ Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000).
This source of overcounting is considered and fixed by Wu (1997) and Zens and Ney (2003), which we briefly review here. $$$$$ Afterwards, we will analyze the Viterbi alignments produced during the training of the alignment models.
This source of overcounting is considered and fixed by Wu (1997) and Zens and Ney (2003), which we briefly review here. $$$$$ It can be further decomposed into alignment and lexicon model.

 $$$$$ We have described the ITG constraints in detail and compared them to the IBM constraints.
 $$$$$ Then, we check for every sentence if the alignment satisfies each of the constraints.
 $$$$$ With the IBM constraints, it is not possible to translate this verb-group correctly, because the distance between the two parts is too large (more than four words).
