Baldwin et al (2003) use LSA as a technique foranalysing the compositionality (or decomposability) of a given MWE. $$$$$ Because of LSA’s independence from linguistic constraints, it is equally applicable to all languages, assuming there is some way of segmenting inputs into constituent words.
Baldwin et al (2003) use LSA as a technique foranalysing the compositionality (or decomposability) of a given MWE. $$$$$ Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet.
Baldwin et al (2003) use LSA as a technique foranalysing the compositionality (or decomposability) of a given MWE. $$$$$ Out of these, we selected those compounds that are listed in WordNet, resulting in 5,405 NN compound types (208,000 tokens).

Some of these are mutual information (Church and Hanks, 1989), distributed frequency (Tapanainen et al, 1998) and Latent Semantic Analysis (LSA) model (Baldwin et al, 2003). $$$$$ With simple decomposable MWEs, we can expect the constituents (and particularly the head) to be hypernyms (ancestor nodes) or synonyms of the MWE.
Some of these are mutual information (Church and Hanks, 1989), distributed frequency (Tapanainen et al, 1998) and Latent Semantic Analysis (LSA) model (Baldwin et al, 2003). $$$$$ Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet.
Some of these are mutual information (Church and Hanks, 1989), distributed frequency (Tapanainen et al, 1998) and Latent Semantic Analysis (LSA) model (Baldwin et al, 2003). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.

Some of them are Frequency, Point-wise mutual information (Church and Hanks, 1989), Distributed frequency of object (Tapanainen et al, 1998), Distributed frequency of object using verb information (Venkatapathyand Joshi, 2005), Similarity of object in verb object pair using the LSA model (Baldwin et al,2003), (Venkatapathy and Joshi, 2005) and Lexical and Syntactic fixedness (Fazly and Stevenson, 2006). $$$$$ We would like to thank the anonymous reviewers for their valuable input on this research.
Some of them are Frequency, Point-wise mutual information (Church and Hanks, 1989), Distributed frequency of object (Tapanainen et al, 1998), Distributed frequency of object using verb information (Venkatapathyand Joshi, 2005), Similarity of object in verb object pair using the LSA model (Baldwin et al,2003), (Venkatapathy and Joshi, 2005) and Lexical and Syntactic fixedness (Fazly and Stevenson, 2006). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
Some of them are Frequency, Point-wise mutual information (Church and Hanks, 1989), Distributed frequency of object (Tapanainen et al, 1998), Distributed frequency of object using verb information (Venkatapathyand Joshi, 2005), Similarity of object in verb object pair using the LSA model (Baldwin et al,2003), (Venkatapathy and Joshi, 2005) and Lexical and Syntactic fixedness (Fazly and Stevenson, 2006). $$$$$ Because of LSA’s independence from linguistic constraints, it is equally applicable to all languages, assuming there is some way of segmenting inputs into constituent words.

For example, Baldwin et al (2003) studied vector extraction for phrases because they were interested in the decomposability of multi word expressions. $$$$$ In the case that a noun phrase followed the particle candidate, we performed attachment disambiguation to determine the transitivity of the particle candidate.
For example, Baldwin et al (2003) studied vector extraction for phrases because they were interested in the decomposability of multi word expressions. $$$$$ According to LSA, however, sim(chairman, vice chairman) = .508 and sim(president, vice president) = .551.
For example, Baldwin et al (2003) studied vector extraction for phrases because they were interested in the decomposability of multi word expressions. $$$$$ We use latent semantic analysis to determine the similarity between a multiword expression and its constituent words, and claim that higher similarities indicate greater decomposability.
For example, Baldwin et al (2003) studied vector extraction for phrases because they were interested in the decomposability of multi word expressions. $$$$$ While it would be possible to set arbitrary thresholds to artificially partition up the space of MWEs based on LSA similarity (or alternatively use statistical tests to derive confidence intervals for similarity values), we feel that more work needs to be done in establishing exactly what different LSA similarities for different MWE– constituent word combinations mean.

According to Baldwin et al (2003), divergences in VPC and head verb semantics are often reflected in differing selectional preferences, as manifested in patterns of noun co-occurrence. $$$$$ As observed above, simple decomposable MWEs such as motor car fail the substitution test not because of nondecomposability, but because the expression is institutionalised to the point of blocking alternates.
According to Baldwin et al (2003), divergences in VPC and head verb semantics are often reflected in differing selectional preferences, as manifested in patterns of noun co-occurrence. $$$$$ They undergo a certain degree of syntactic variation (e.g. the cat was let out of the bag).
According to Baldwin et al (2003), divergences in VPC and head verb semantics are often reflected in differing selectional preferences, as manifested in patterns of noun co-occurrence. $$$$$ Analysis of the semantic correlation between the constituent parts and whole of an MWE is perhaps more commonly discussed under the banner of compositionality (Nunberg et al., 1994; Lin, 1999).
According to Baldwin et al (2003), divergences in VPC and head verb semantics are often reflected in differing selectional preferences, as manifested in patterns of noun co-occurrence. $$$$$ If we partition the data up into low- and high-frequency MWEs, as defined by a threshold of 100 corpus occurrences, we find that the graphs for the low-frequency data (NN(head)LOW and VPC(head)LOW) are both monotonically decreasing, whereas those for high-frequency data (NN(head)HIGH and VPC(head)HIGH) are more haphazard in nature.

Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSAto distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ We claim that substitution-based tests are useful in demarcating MWEs from productive word combinations (as attested by Pearce (2001a) in a MWE detection task), but not in distinguishing the different classes of decomposability.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSAto distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ The BNC data, on the other hand, contains more colloquial and prosaic texts and is thus a richer source of verb-particles.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSAto distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ This is calculated over a corpus of text. where C0 is the lowest class in the hierarchy that subsumes both classes. lations” of different strength to determine the similarity of word senses, conditioned on the type, direction and relative distance of edges separating them.
Prior work in discovering non-compositional phrases has been carried out by Lin (1999) and Baldwin et al (2003), who also used LSAto distinguish between compositional and non compositional verb-particle constructions and noun noun compounds. $$$$$ For MWEs such as house boat, therefore, we can expect to capture the fact that the MWE is highly similar in meaning to both constituent words (i.e. the modifier house and head noun boat).

Some of these are Frequency, Mutual Information (Church and Hanks, 1989), distributed frequency of object (Tapanainen et al, 1998) and LSA model (Baldwin et al, 2003) (Schutze, 1998). $$$$$ As the first step down the path toward an empirical model of decomposability, we focus on demarcating simple decomposable MWEs from idiosyncratically decomposable and non-decomposable MWEs.
Some of these are Frequency, Mutual Information (Church and Hanks, 1989), distributed frequency of object (Tapanainen et al, 1998) and LSA model (Baldwin et al, 2003) (Schutze, 1998). $$$$$ The LSA model we built is similar to that described in (Sch¨utze, 1998).
Some of these are Frequency, Mutual Information (Church and Hanks, 1989), distributed frequency of object (Tapanainen et al, 1998) and LSA model (Baldwin et al, 2003) (Schutze, 1998). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.

An interesting way of quantifying the relative compositionality of a MWE is proposed by Baldwin, Bannard, Tanaka and Widdows (Baldwin et al, 2003). $$$$$ The results for the low-frequency items are particularly encouraging given that the LSAbased similarities were found to correlate poorly with WordNet-derived similarities.
An interesting way of quantifying the relative compositionality of a MWE is proposed by Baldwin, Bannard, Tanaka and Widdows (Baldwin et al, 2003). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
An interesting way of quantifying the relative compositionality of a MWE is proposed by Baldwin, Bannard, Tanaka and Widdows (Baldwin et al, 2003). $$$$$ We claim that substitution-based tests are useful in demarcating MWEs from productive word combinations (as attested by Pearce (2001a) in a MWE detection task), but not in distinguishing the different classes of decomposability.
An interesting way of quantifying the relative compositionality of a MWE is proposed by Baldwin, Bannard, Tanaka and Widdows (Baldwin et al, 2003). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.

They evaluate their model on English NN compounds and verb-particles, and showed that the model correlated moderately well with the Word net based decomposability theory (Baldwin et al, 2003). $$$$$ As observed above, simple decomposable MWEs such as motor car fail the substitution test not because of nondecomposability, but because the expression is institutionalised to the point of blocking alternates.
They evaluate their model on English NN compounds and verb-particles, and showed that the model correlated moderately well with the Word net based decomposability theory (Baldwin et al, 2003). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
They evaluate their model on English NN compounds and verb-particles, and showed that the model correlated moderately well with the Word net based decomposability theory (Baldwin et al, 2003). $$$$$ The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990).

The LSA model we built is similar to that described in (Schutze, 1998) and (Baldwin et al, 2003). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
The LSA model we built is similar to that described in (Schutze, 1998) and (Baldwin et al, 2003). $$$$$ This produces the unconvincing scores of 15.7% for precision and 13.7% for recall.

 $$$$$ If we partition the data up into low- and high-frequency MWEs, as defined by a threshold of 100 corpus occurrences, we find that the graphs for the low-frequency data (NN(head)LOW and VPC(head)LOW) are both monotonically decreasing, whereas those for high-frequency data (NN(head)HIGH and VPC(head)HIGH) are more haphazard in nature.
 $$$$$ Hyponymy provides the most immediate way of evaluating decomposability.
 $$$$$ More importantly, LSA makes no assumptions about the lexical or syntactic composition of the inputs, and thus constitutes a fully construction- and language-inspecific method of modelling decomposability.
 $$$$$ This paper presents a constructioninspecific model of multiword expression decomposability based on latent semantic analysis.

Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ We extracted the NN compounds from the 1996 Wall Street Journal data (WSJ, 31m words), and the verb-particles from the British National Corpus (BNC, 90m words: Burnard (2000)).
Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ The similarity measures described above calculate the similarity between a pair of senses.
Katz and Giesbrecht (2006) and Baldwin et al (2003) use Latent Semantic Analysis for this purpose. $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.

(Baldwin et al, 2003) use WordNet $$$$$ While it would be possible to set arbitrary thresholds to artificially partition up the space of MWEs based on LSA similarity (or alternatively use statistical tests to derive confidence intervals for similarity values), we feel that more work needs to be done in establishing exactly what different LSA similarities for different MWE– constituent word combinations mean.
(Baldwin et al, 2003) use WordNet $$$$$ For both the NN compound and verb-particle data, we replaced each token occurrence with a single-word POS-tagged token to feed into the LSA model.
(Baldwin et al, 2003) use WordNet $$$$$ We would like to thank the anonymous reviewers for their valuable input on this research.
(Baldwin et al, 2003) use WordNet $$$$$ One area in which we plan to extend this research is the analysis of MWEs in languages other than English.

Baldwin et al (2003) proposed a LSA-based model for measuring the decomposability of MWEs by examining the similarity between them and their constituent words, with higher similarity indicating the greater decomposability. $$$$$ We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet.
Baldwin et al (2003) proposed a LSA-based model for measuring the decomposability of MWEs by examining the similarity between them and their constituent words, with higher similarity indicating the greater decomposability. $$$$$ Melamed (1997)), there has been little work on detecting “non-compositional” (i.e. non-decomposable and idiosyncratically decomposable) items of variable syntactic type in monolingual corpora.
Baldwin et al (2003) proposed a LSA-based model for measuring the decomposability of MWEs by examining the similarity between them and their constituent words, with higher similarity indicating the greater decomposability. $$$$$ They successfully combined statistical and distributional techniques (including LSA) with a substitution test in analysing compositionality.

Baldwin et al (2003) investigate semantic decomposability of noun-noun compounds and verb constructions. $$$$$ In an ideal world, we would hope that the values for mean hyponymy were nearly 1 for the first partition and nearly 0 for the last.
Baldwin et al (2003) investigate semantic decomposability of noun-noun compounds and verb constructions. $$$$$ To summarise, we have proposed a constructioninspecific empirical model of MWE decomposability, based on latent semantic analysis.
Baldwin et al (2003) investigate semantic decomposability of noun-noun compounds and verb constructions. $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
Baldwin et al (2003) investigate semantic decomposability of noun-noun compounds and verb constructions. $$$$$ While recognising the dangers associated with dictionarybased evaluation, we commit ourselves to this paradigm and focus on searching for appropriate means of demonstrating the correlation between dictionary- and corpus-based similarities.

In the above model, if a=0 and b=1, the resulting model is similar to that of Baldwin et al (2003). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
In the above model, if a=0 and b=1, the resulting model is similar to that of Baldwin et al (2003). $$$$$ Ideally, we would like to be able to differentiate between three classes of MWEs: nondecomposable, idiosyncratically decomposable and simple decomposable (derived from Nunberg et al.’s sub-classification of idioms (1994)).

Baldwin et al, (2003) focus more narrowly on distinguishing English noun-noun compound sand verb-particle constructions which are compositional from those which are not compositional. $$$$$ The BNC data, on the other hand, contains more colloquial and prosaic texts and is thus a richer source of verb-particles.
Baldwin et al, (2003) focus more narrowly on distinguishing English noun-noun compound sand verb-particle constructions which are compositional from those which are not compositional. $$$$$ As can be seen, the noun fire (as in the substance/element) and the verb fire (mainly used to mean firing some sort of weapon) are related to quite different areas of meaning.
Baldwin et al, (2003) focus more narrowly on distinguishing English noun-noun compound sand verb-particle constructions which are compositional from those which are not compositional. $$$$$ The function hyponym(wordi, mwe) thus returns a value of 1 if some sense of wordz subsumes a sense of mwe, and a value of 0 otherwise.
Baldwin et al, (2003) focus more narrowly on distinguishing English noun-noun compound sand verb-particle constructions which are compositional from those which are not compositional. $$$$$ Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet.

To compare our method with that proposed by Baldwin et al (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to theMWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE. $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
To compare our method with that proposed by Baldwin et al (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to theMWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE. $$$$$ Singular-value decomposition (Deerwester et al., 1990) was then used to reduce the number of dimensions from 1000 to 100.
To compare our method with that proposed by Baldwin et al (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to theMWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE. $$$$$ The Patwardhan et al. (2003) implementation that we used calculates the information values from SemCor, a semantically tagged subset of the Brown corpus.
To compare our method with that proposed by Baldwin et al (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to theMWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE. $$$$$ Looking to the curves for these three rankings, we see that they are all fairly flat, nondescript curves.

There is some evidence (Baldwin et al, 2003) that part of speech tagging might improve results in this kind of task. $$$$$ They successfully combined statistical and distributional techniques (including LSA) with a substitution test in analysing compositionality.
There is some evidence (Baldwin et al, 2003) that part of speech tagging might improve results in this kind of task. $$$$$ Note that the existence of anticollocations is also a test for non-decomposable and idiosyncratically decomposable MWEs (e.g. hot dog vs. #warm dog or #hot canine).
There is some evidence (Baldwin et al, 2003) that part of speech tagging might improve results in this kind of task. $$$$$ We would like to thank the anonymous reviewers for their valuable input on this research.
There is some evidence (Baldwin et al, 2003) that part of speech tagging might improve results in this kind of task. $$$$$ Ideally, we would like to be able to differentiate between three classes of MWEs: nondecomposable, idiosyncratically decomposable and simple decomposable (derived from Nunberg et al.’s sub-classification of idioms (1994)).

Other approaches use Latent Semantic Analysis (LSA) to determine the similarity between a potential idiom and its components (Baldwin et al, 2003). $$$$$ No hyponymy relation holds with non-decomposable or idiosyncratically decomposable MWEs (i.e., they are exocentric), as even if the semantics of the head noun can be determined through decomposition, by definition this will not correspond to a simplex sense of the word.
Other approaches use Latent Semantic Analysis (LSA) to determine the similarity between a potential idiom and its components (Baldwin et al, 2003). $$$$$ As the first step down the path toward an empirical model of decomposability, we focus on demarcating simple decomposable MWEs from idiosyncratically decomposable and non-decomposable MWEs.
Other approaches use Latent Semantic Analysis (LSA) to determine the similarity between a potential idiom and its components (Baldwin et al, 2003). $$$$$ Significance here is defined as the absence of overlap between the 95% confidence interval of the mutual information scores.
Other approaches use Latent Semantic Analysis (LSA) to determine the similarity between a potential idiom and its components (Baldwin et al, 2003). $$$$$ BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.
