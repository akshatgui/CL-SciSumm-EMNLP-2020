 $$$$$ It encodes syntactic, semantic, and pragmatic information.
 $$$$$ The placeholders are parsed by the grammar using special placeholder lexical entries.
 $$$$$ The nominal uses are produced by a lexical rule which nominalizes the verbal nouns.

By using a Japanese grammar (JACY $$$$$ &quot;â€™ The formative to is actually ambiguous between a complementizer and a conjunction.
By using a Japanese grammar (JACY $$$$$ Watashi ga sensei ni hon wo I NOM teacher DAT book ACC katte morat-ta. buy get-past 'The teacher bought me a book.'
By using a Japanese grammar (JACY $$$$$ The inflection type is translated to an HPSG type.
By using a Japanese grammar (JACY $$$$$ The grammar is couched in the theoretical framework of Head-Driven Phrase Structure Grammar (HPSG) (Pollard & Sag 1994), with semantic representations in Minimal Recursion Semantics (MRS) (Copestake et al. 2001).

JACY (Siegel and Bender, 2002) is a hand-crafted Japanese HPSG grammar that provides semantic information as well as linguistically motivated analysis of complex constructions. $$$$$ Robustness requires not only wide coverage by the grammar (in both syntax and semantics), but also large and extensible lexica as well as interfaces to preprocessing systems for named entity recognition, non-linguistic structures such as addresses, etc.
JACY (Siegel and Bender, 2002) is a hand-crafted Japanese HPSG grammar that provides semantic information as well as linguistically motivated analysis of complex constructions. $$$$$ While couched within the same general framework (BPSG), our approach differs from that of Kanayama et al (2000).
JACY (Siegel and Bender, 2002) is a hand-crafted Japanese HPSG grammar that provides semantic information as well as linguistically motivated analysis of complex constructions. $$$$$ The coverage was 61%.
JACY (Siegel and Bender, 2002) is a hand-crafted Japanese HPSG grammar that provides semantic information as well as linguistically motivated analysis of complex constructions. $$$$$ The grammar currently covers 93.4% of constructed examples for the banking domain (747 sentences) and 78.2% of realistic email correspondence data (316 sentences), concerning requests for documents.

The grammars used for the experiments reported here are the LinGO English Resource Grammar (ERG; Flickinger (2000)) and JACY (Siegel and Bender, 2002), precision grammars of English and Japanese, respectively. $$$$$ For verbs and adjectives, ChaSen gives information about stems and inflection that is used in a similar way.
The grammars used for the experiments reported here are the LinGO English Resource Grammar (ERG; Flickinger (2000)) and JACY (Siegel and Bender, 2002), precision grammars of English and Japanese, respectively. $$$$$ These are triggered by the part-ofspeech information given by ChaSen, if there is no existing entry in the lexicon.
The grammars used for the experiments reported here are the LinGO English Resource Grammar (ERG; Flickinger (2000)) and JACY (Siegel and Bender, 2002), precision grammars of English and Japanese, respectively. $$$$$ Furthermore, because of gapless relative clauses like the one cited above, we have opted for a non-extraction analysis of relative clauses.2 Nonetheless, the well-formedness constraints on MRS representations require that there be 2 There is in fact some linguistic evidence for extraction in some relative clauses in Japanese (see e.g., Baldwin 2001).
The grammars used for the experiments reported here are the LinGO English Resource Grammar (ERG; Flickinger (2000)) and JACY (Siegel and Bender, 2002), precision grammars of English and Japanese, respectively. $$$$$ For the most part, semantic representations and the syntax-semantic interface already worked out in the ERG were directly applicable to the Japanese grammar.

In this paper, we explore the utility of different evaluation metrics at predicting parse performance through a series of experiments over two broad coverage grammars $$$$$ Initial evaluation of the grammar on new domains and the growth curve of grammar coverage should bear this out.
In this paper, we explore the utility of different evaluation metrics at predicting parse performance through a series of experiments over two broad coverage grammars $$$$$ English number names can appear directly as modifiers of NPs and are treated semantically as adjectives in the ERG.
In this paper, we explore the utility of different evaluation metrics at predicting parse performance through a series of experiments over two broad coverage grammars $$$$$ The evaluation shows that the grammar is at a stage where domain adaptation is possible in a reasonable amount of time.
In this paper, we explore the utility of different evaluation metrics at predicting parse performance through a series of experiments over two broad coverage grammars $$$$$ The work described there achieves impressive coverage (83.7% on the EDR corpus of newspaper text) with an underspecified grammar consisting of a small number of lexical entries, lexical types associated with parts of speech, and six underspecified grammar rules.

JACY (Siegel and Bender, 2002) is a broad coverage linguistically precise HPSG-based grammar of Japanese. $$$$$ The grammar is created for use in real world applications, such that robustness and performance issues play an important role.
JACY (Siegel and Bender, 2002) is a broad coverage linguistically precise HPSG-based grammar of Japanese. $$$$$ This default mechanism is often used for different kinds of names and 'ordinary' nouns, but also for adverbs, interjections and verbal nouns (where we assume a default transitive valence pattern).3 The ChaSen lexicon is extended with a domainspecific lexicon, containing, among others, names in the domain of banking.
JACY (Siegel and Bender, 2002) is a broad coverage linguistically precise HPSG-based grammar of Japanese. $$$$$ The grammar system is connected to a morphological analysis system and uses default entries for words unknown to the HPSG lexicon.

Of these, the most thorough work on Japanese honorification is seen in JACY, a Japanese HPSG grammar (Siegel 2000, Siegel and Bender 2002). $$$$$ Phenomena occurring in semi-spontaneous language (email correspondence), such as interjections (e.g. maa 'well'), contracted verb forms (e.g. tabe-chatta < tabete-shimatta '(someone) ate it all up'), fragmentary sentences (e.g. bangou: 1265 'number: 1265') and NP fragments (e.g. bangou?
Of these, the most thorough work on Japanese honorification is seen in JACY, a Japanese HPSG grammar (Siegel 2000, Siegel and Bender 2002). $$$$$ The output of the preprocessing tool replaces these expressions in the string with placeholders.
Of these, the most thorough work on Japanese honorification is seen in JACY, a Japanese HPSG grammar (Siegel 2000, Siegel and Bender 2002). $$$$$ The coverage of the document request data increased 51.43% in the following two weeks.
Of these, the most thorough work on Japanese honorification is seen in JACY, a Japanese HPSG grammar (Siegel 2000, Siegel and Bender 2002). $$$$$ The grammar is created for use in real world applications, such that robustness and performance issues play an important role.

 $$$$$ It is difficult, because one particle can fulfill more than one function and they can co-occur, but not arbitrarily.
 $$$$$ Therefore, robustness and performance issues play an important role.
 $$$$$ As the grammar is aimed at working in applications with real-world data, performance and robustness issues are important.
 $$$$$ Finally, for use in real-world applications, NLP systems meeting the above desiderata must also be efficient.

The grammar is an HPSG implementation (JACY $$$$$ As the lexical coverage of ChaSen is higher than that of the HPSG lexicon, default part-of-speech entries are inserted into the lexicon.
The grammar is an HPSG implementation (JACY $$$$$ The grammar is couched in the theoretical framework of Head-Driven Phrase Structure Grammar (HPSG) (Pollard & Sag 1994), with semantic representations in Minimal Recursion Semantics (MRS) (Copestake et al. 2001).
The grammar is an HPSG implementation (JACY $$$$$ However, we saw no practical need to allow for this possibility in our grammar, and particularly not one that would justify the increase in ambiguity.

 $$$$$ VAL contains the agreement information for the argument.
 $$$$$ In addition, a head noun modified by a relative clause need not correspond to any gap in the relative clause, as shown by examples like the following (Matsumoto 1997): head NOM better become book 'a book that makes one smarter' Therefore, if we were to posit an attributive adjective + noun construction (distinct from the relative clause + noun possibility) we would have systematic ambiguities for NPs like akai hon ('red book'), ambiguities which could never be resolved based on information in the sentence.

We take our examples from JACY (Siegel and Bender, 2002), a large grammar of Japanese built in the HPSG framework. $$$$$ With the quotation marks, however, only the complementizer to is possible.
We take our examples from JACY (Siegel and Bender, 2002), a large grammar of Japanese built in the HPSG framework. $$$$$ These structures give compact representations of ambiguities that are often irrelevant to the task at hand.
We take our examples from JACY (Siegel and Bender, 2002), a large grammar of Japanese built in the HPSG framework. $$$$$ We also use the ChaSen tokenizer and POS tagger (Asahara & Matsumoto 2000).
We take our examples from JACY (Siegel and Bender, 2002), a large grammar of Japanese built in the HPSG framework. $$$$$ That means that we could get correct MRSs in 55.61% of all sentences.

The grammar is an HPSG implementation (JACY $$$$$ That means that we could get correct MRSs in 55.61% of all sentences.
The grammar is an HPSG implementation (JACY $$$$$ Utterances can express social distance between addressee and speaker and third persons.
The grammar is an HPSG implementation (JACY $$$$$ Consider example 1.
The grammar is an HPSG implementation (JACY $$$$$ The output of the preprocessing tool replaces these expressions in the string with placeholders.

The Grammar Matrix was developed initially on the basis of broad coverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), ModernGreek (Kordoni and Neu, 2005), and Spanish (Marimon et al, 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). $$$$$ The grammar system is connected to a morphological analysis system and uses default entries for words unknown to the HPSG lexicon.
The Grammar Matrix was developed initially on the basis of broad coverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), ModernGreek (Kordoni and Neu, 2005), and Spanish (Marimon et al, 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). $$$$$ Both of these points illustrate the cross-linguistic validity and practical utility of MRS representations.
The Grammar Matrix was developed initially on the basis of broad coverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), ModernGreek (Kordoni and Neu, 2005), and Spanish (Marimon et al, 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). $$$$$ The development of this grammar constitutes an important test of the cross-linguistic validity of the MRS formalism.
The Grammar Matrix was developed initially on the basis of broad coverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), ModernGreek (Kordoni and Neu, 2005), and Spanish (Marimon et al, 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). $$$$$ The coverage was 61%.

There are also several grammars $$$$$ During three months of work, the coverage in the banking domain increased 48.49%.
There are also several grammars $$$$$ Integrating MRS representations parallel to those used in the ERG into the Japanese grammar took approximately 3 months.
There are also several grammars $$$$$ The inflection type is translated to an HPSG type.
There are also several grammars $$$$$ With the quotation marks, however, only the complementizer to is possible.

In this section, we outline the resources targeted in this research, namely the English Resource Grammar (ERG $$$$$ The careful treatment of Japanese particles is essential, because they are the most frequently occurring words and have various central functions in the grammar.
In this section, we outline the resources targeted in this research, namely the English Resource Grammar (ERG $$$$$ The coverage was 61%.
In this section, we outline the resources targeted in this research, namely the English Resource Grammar (ERG $$$$$ It is connected to a POS tagging and word segmentation tool.

Fujita et al (2007) add sense information to improve parse ranking with JaCy (Siegel and Bender,2002), an HPSG-based grammar which uses similar machinery to the ERG. $$$$$ We present a broad coverage Japanese grammar written in the HPSG formalism with MRS semantics.
Fujita et al (2007) add sense information to improve parse ranking with JaCy (Siegel and Bender,2002), an HPSG-based grammar which uses similar machinery to the ERG. $$$$$ However, if the technology is to meet the demands of real-world applications, this must not come at the cost of robustness.
Fujita et al (2007) add sense information to improve parse ranking with JaCy (Siegel and Bender,2002), an HPSG-based grammar which uses similar machinery to the ERG. $$$$$ During three months of work, the coverage in the banking domain increased 48.49%.
Fujita et al (2007) add sense information to improve parse ranking with JaCy (Siegel and Bender,2002), an HPSG-based grammar which uses similar machinery to the ERG. $$$$$ Stochastic disambiguation methods being developed for the ERG by the Redwoods project at Stanford University (Oepen et al. 2002) should be applicable to this grammar as well.

In order to examine the cross-lingual applicability of our methods, we also use Jacy, an HPSG-based grammar of Japanese (Siegel and Bender, 2002). $$$$$ MRS is a flat semantic formalism that works well with typed feature structures and is flexible in that it provides structures that are under-specified for scopal information.
In order to examine the cross-lingual applicability of our methods, we also use Jacy, an HPSG-based grammar of Japanese (Siegel and Bender, 2002). $$$$$ We also use the ChaSen tokenizer and POS tagger (Asahara & Matsumoto 2000).
In order to examine the cross-lingual applicability of our methods, we also use Jacy, an HPSG-based grammar of Japanese (Siegel and Bender, 2002). $$$$$ Phenomena occurring in semi-spontaneous language (email correspondence), such as interjections (e.g. maa 'well'), contracted verb forms (e.g. tabe-chatta < tabete-shimatta '(someone) ate it all up'), fragmentary sentences (e.g. bangou: 1265 'number: 1265') and NP fragments (e.g. bangou?
In order to examine the cross-lingual applicability of our methods, we also use Jacy, an HPSG-based grammar of Japanese (Siegel and Bender, 2002). $$$$$ These are triggered by the part-ofspeech information given by ChaSen, if there is no existing entry in the lexicon.

Language specific analyses have been implemented in deep, broad-coverage grammars for languages such as Japanese (Masuichi et al (2003), Siegel and Bender (2002)) and Portuguese (Branco and Costa (2008)). $$$$$ The grammar currently covers 93.4% of constructed examples for the banking domain (747 sentences) and 78.2% of realistic email correspondence data (316 sentences), concerning requests for documents.
Language specific analyses have been implemented in deep, broad-coverage grammars for languages such as Japanese (Masuichi et al (2003), Siegel and Bender (2002)) and Portuguese (Branco and Costa (2008)). $$$$$ It is connected to a POS tagging and word segmentation tool.
Language specific analyses have been implemented in deep, broad-coverage grammars for languages such as Japanese (Masuichi et al (2003), Siegel and Bender (2002)) and Portuguese (Branco and Costa (2008)). $$$$$ In future work, this grammar could be further adapted to another domain, such as the EDR newspaper corpus (including a headline grammar).

In order to produce semantic representations we are using an open source HPSG grammar of Japanese $$$$$ In order to reduce ambiguity, we leave the relationship between these genitive marked NPs and the nominalized verbal noun underspecified.
In order to produce semantic representations we are using an open source HPSG grammar of Japanese $$$$$ The coverage of the document request data increased 51.43% in the following two weeks.
In order to produce semantic representations we are using an open source HPSG grammar of Japanese $$$$$ In order to capture this intuition, we opted for an analysis that essentially treats verbal nouns as underlyingly verbal.
In order to produce semantic representations we are using an open source HPSG grammar of Japanese $$$$$ We applied the grammar to unseen data in one of the covered domains, namely the FAQ site of a Japanese bank.

We used the Japanese grammar Jacy (Siegel and Bender, 2002), a deep parsing HPSG grammar that produces RMRSs for our primary input source. $$$$$ It encodes syntactic, semantic, and pragmatic information.
We used the Japanese grammar Jacy (Siegel and Bender, 2002), a deep parsing HPSG grammar that produces RMRSs for our primary input source. $$$$$ These specific default entries assign a type to the word that contains features typical to its part-of-speech.
We used the Japanese grammar Jacy (Siegel and Bender, 2002), a deep parsing HPSG grammar that produces RMRSs for our primary input source. $$$$$ The coverage was 61%.
We used the Japanese grammar Jacy (Siegel and Bender, 2002), a deep parsing HPSG grammar that produces RMRSs for our primary input source. $$$$$ The placeholders are parsed by the grammar using special placeholder lexical entries.
