 $$$$$ Like previous work, we implement pronominal coreference resolution by enforcing agreement constraints between the coreferent mentions.
 $$$$$ This initial clustering step will assign the correct animacy attribute (inanimate) to the corresponding geo-political entity, which will prevent the incorrect merging with the mention we (animate) in later steps.
 $$$$$ Each tier builds on the entity clusters constructed by previous models in the sieve, guaranteeing that stronger features are given precedence over weaker ones.
 $$$$$ Each tier builds on the entity clusters constructed by previous models in the sieve, guaranteeing that stronger features are given precedence over weaker ones.

Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ For a fair comparison with previous work, we do not use gold named entity labels or mention types but, instead, take the labels provided by the Stanford named entity recognizer (NER) (Finkel et al., 2005).
Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ The comparison indicates that both these contributions help: our single-pass system outperforms Haghighi and Klein (2009) consistently, and the multi-pass architecture further improves the performance of our single-pass system between 1 and 4 F1 points, depending on the corpus and evaluation metric.
Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ We presented a simple deterministic approach to coreference resolution that incorporates documentlevel information, which is typically exploited only by more complex, joint learning models.

Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ Our sieve framework is implemented as a succession of independent coreference models.
Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ Many thanks to Jenny Finkel for writing a reimplementation of much of Haghighi and Klein (2009), which served as the starting point for the work reported here.
Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ Recent work on coreference resolution has shown that a rich feature space that models lexical, syntactic, semantic, and discourse phenomena is crucial to successfully address the task (Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010).
Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ (2010) used “baby steps” for unsupervised dependency parsing, etc.

In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ We parse all documents using the Stanford parser (Klein and Manning, 2003).
In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ Our sieve architecture applies a battery of deterministic coreference models one at a time from highest to lowest precision, where each model builds on the previous model’s cluster output.
In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ An additional benefit of the sieve framework is its modularity: new features or models can be inserted in the system with limited understanding of the other features already deployed.
In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ Haghighi and Klein (2010) propose a generative approach that models entity clusters explicitly using a mostly-unsupervised generative model.

We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ From a high level perspective, this work falls under the theory of shaping, defined as a “method of successive approximations” for learning (Skinner, 1938).
We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ We also thank Nicholas Rizzolo and Dan Roth for helping us replicate their experimental setup, and Heng Ji and Dekang Lin for providing their gender lexicon.
We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ Mentions are usually noun phrases (NPs) headed by nominal or pronominal terminals.

Please see (Raghunathan et al, 2010) for more details. $$$$$ We sort candidate antecedents using syntactic information provided by the Stanford parser, as follows: Same Sentence – Candidates in the same sentence are sorted using left-to-right breadth-first traversal of syntactic trees (Hobbs, 1977).
Please see (Raghunathan et al, 2010) for more details. $$$$$ Our code is publicly released5 and can be used both as a stand-alone coreference system and as a platform for the development of future systems.
Please see (Raghunathan et al, 2010) for more details. $$$$$ The other corpora are reserved for testing.
Please see (Raghunathan et al, 2010) for more details. $$$$$ The sieve model outperforms all other systems on at least two test sets, even though most of the other models are significantly richer.

The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ Our sieve architecture applies a battery of deterministic coreference models one at a time from highest to lowest precision, where each model builds on the previous model’s cluster output.
The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ Many thanks to Jenny Finkel for writing a reimplementation of much of Haghighi and Klein (2009), which served as the starting point for the work reported here.
The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ The Haghighi and Klein (2009) numbers have two variants: with semantics (+S) and without (−S).

Proper Head Word Match $$$$$ For example, the two mentions in ... intervene in the [Florida Supreme Court]’s move ... does look like very dramatic change made by [the Florida court] point to the same entity, but the two mentions in the text below belong to different clusters: The pilot had confirmed ... he had turned onto [the correct runway] but pilots behind him say he turned onto [the wrong runway].
Proper Head Word Match $$$$$ From a high level perspective, this work falls under the theory of shaping, defined as a “method of successive approximations” for learning (Skinner, 1938).
Proper Head Word Match $$$$$ This work builds upon the recent observation that strong features outweigh complex models for coreference resolution, in both supervised and unsupervised learning setups (Bengston and Roth, 2008; Haghighi and Klein, 2009).
Proper Head Word Match $$$$$ We also thank Nicholas Rizzolo and Dan Roth for helping us replicate their experimental setup, and Heng Ji and Dekang Lin for providing their gender lexicon.

The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ This is a simple heuristic for speaker detection, e.g., I and she point to the same person in “[I] voted my conscience,” [she] said.
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ First, early cluster mentions are usually better defined than subsequent ones, which are likely to have fewer modifiers or are pronouns (Fox, 1993).
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ Role appositive – the candidate antecedent is headed by a noun and appears as a modifier in an NP whose head is the current mention, e.g., [[actress] Rebecca Schaeffer].
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ This cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time.

By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ Additionally, the deterministic models in our tiered model are significantly simpler, yet perform generally better than the complex inference models proposed in these works.
By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features.
By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ For a fair comparison with previous work, we do not use gold named entity labels or mention types but, instead, take the labels provided by the Stanford named entity recognizer (NER) (Finkel et al., 2005).
By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ Gender – we assign gender attributes from static lexicons from (Bergsma and Lin, 2006; Ji and Lin, 2009).

Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ We gratefully acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.
Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ From a high level perspective, this work falls under the theory of shaping, defined as a “method of successive approximations” for learning (Skinner, 1938).
Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ Additionally, the deterministic models in our tiered model are significantly simpler, yet perform generally better than the complex inference models proposed in these works.

We incorporate lexicalized feature sets into two different coreference architectures $$$$$ In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora.
We incorporate lexicalized feature sets into two different coreference architectures $$$$$ Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features.
We incorporate lexicalized feature sets into two different coreference architectures $$$$$ Most state-of-the-art models will incorrectly link we to the israelis because of their proximity and compatibility of attributes (both we and the israelis are plural).
We incorporate lexicalized feature sets into two different coreference architectures $$$$$ Our sieve model outperforms all systems on two out of the four evaluation corpora (ACE2004ROTH-DEV and ACE2004-NWIRE), on all metrics.

There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ Note that this feature is actually more relaxed than naive head matching between mention and antecedent candidate because it is satisfied when the mention’s head matches the head of any entity in the candidate’s cluster.
There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ We include in the table all recent systems that report results under the same conditions as our experimental setup (i.e., using gold mentions) and use the same corpora.
There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ This theory is known by different names in many NLP applications: Brown et al. (1993) used simple models as “stepping stones” for more complex word alignment models; Collins (1999) used “cautious” decision list learning for named entity classification; Spitkovsky et al.

Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ Intra-document coreference resolution clusters together textual mentions within a single document based on the underlying referent entity.
Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ Despite its simplicity, our approach outperforms or performs comparably to the state of the art on several corpora.
Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ We presented a simple deterministic approach to coreference resolution that incorporates documentlevel information, which is typically exploited only by more complex, joint learning models.
Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora.

This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ We refer the interested reader to (X. Luo, 2005; Finkel and Manning, 2008) for an analysis of these metrics.
This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ FA8750-09-C-0181.
This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ The comparison indicates that both these contributions help: our single-pass system outperforms Haghighi and Klein (2009) consistently, and the multi-pass architecture further improves the performance of our single-pass system between 1 and 4 F1 points, depending on the corpus and evaluation metric.
This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ In MUC6-TEST, our sieve’s B3 F1 score is 1.8 points lower than Haghighi and Klein (2009) +S, but it outperforms a supervised system that used gold named entity labels.

This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ The strong performance of our system suggests the use of sieves in other NLP tasks for which a variety of very high-precision features can be designed and non-local features can be shared; likely candidates include relation and event extraction, template slot filling, and author name deduplication.
This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ Our code is publicly released5 and can be used both as a stand-alone coreference system and as a platform for the development of future systems.
This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ We present the results of our approach and other relevant prior work in Table 3.
This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ Mentions are usually noun phrases (NPs) headed by nominal or pronominal terminals.

Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects $$$$$ For a fair comparison with previous work, we do not use gold named entity labels or mention types but, instead, take the labels provided by the Stanford named entity recognizer (NER) (Finkel et al., 2005).
Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects $$$$$ Subjects are more probable antecedents for pronouns (Kertz et al., 2006).
Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects $$$$$ All our components are unsupervised, in the sense that they do not require training on gold coreference links.
Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects $$$$$ This cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time.

(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ Each tier builds on the previous tier’s entity cluster output.
(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ [we]’re checking our facts on that one.
(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ We present the results of our approach and other relevant prior work in Table 3.
(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ Our sieve architecture applies a battery of deterministic coreference models one at a time from highest to lowest precision, where each model builds on the previous model’s cluster output.

The ordering should be such that (a) maximum amount of information is injected at early stages (b) the precision at the early stages is as high as possible (Raghunathan et al 2010). $$$$$ The system that is closest to ours is Haghighi and Klein (2009) −S.
The ordering should be such that (a) maximum amount of information is injected at early stages (b) the precision at the early stages is as high as possible (Raghunathan et al 2010). $$$$$ We include in the table all recent systems that report results under the same conditions as our experimental setup (i.e., using gold mentions) and use the same corpora.

Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ Consider this example: The second attack occurred after some rocket firings aimed, apparently, toward [the israelis], apparently in retaliation.
Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ Additionally, the deterministic models in our tiered model are significantly simpler, yet perform generally better than the complex inference models proposed in these works.
Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ Not surprisingly, the causes are unique to each type.
Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ [we]’re checking our facts on that one.
