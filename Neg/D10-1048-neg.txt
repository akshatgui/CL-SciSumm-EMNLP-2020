 $$$$$ We gratefully acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.
 $$$$$ This flexibility is in sharp contrast to supervised classifiers that require their models to be retrained on labeled data, and unsupervised systems that do not offer a clear insertion point for new features.
 $$$$$ Furthermore, each model’s decisions are richly informed by sharing attributes across the mentions clustered in earlier tiers.
 $$$$$ As previously mentioned, our work is not constrained by first-order or Bayesian formalisms in how it uses cluster information.

Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ The framework is highly modular: new coreference modules can be plugged in without any change to the other modules.
Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision.
Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ This work builds upon the recent observation that strong features outweigh complex models for coreference resolution, in both supervised and unsupervised learning setups (Bengston and Roth, 2008; Haghighi and Klein, 2009).
Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al, 2010). $$$$$ Most state-of-the-art models will incorrectly link we to the israelis because of their proximity and compatibility of attributes (both we and the israelis are plural).

Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ The common noun recall errors are very different from proper nouns: 17 of the 20 random examples can be classified as semantic knowledge.
Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ The intuition behind this heuristic is two-fold.
Our system is an extension of Stanford's multi-pass sieve system, (Raghunathan et al, 2010) and (Lee et al, 2011), by adding novel constraints and sieves. $$$$$ We also thank Nicholas Rizzolo and Dan Roth for helping us replicate their experimental setup, and Heng Ji and Dekang Lin for providing their gender lexicon.

In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ We presented a simple deterministic approach to coreference resolution that incorporates documentlevel information, which is typically exploited only by more complex, joint learning models.
In contrast, (Raghunathan et al, 2010) proposed a rule based model which obtained competitive result with less time. $$$$$ To the best of our knowledge, we are the first to apply this theory to coreference resolution.

We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision.
We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ Recent unsupervised coreference work from Haghighi and Klein (2009) included a novel semantic component that matched related head words (e.g., AOL is a company) learned from select wikipedia articles.
We made three considerable extensions to the Raghunathan et al (2010) model. $$$$$ Our approach has the highest precision on all corpora, regardless of evaluation metric.

Please see (Raghunathan et al, 2010) for more details. $$$$$ We also thank Nicholas Rizzolo and Dan Roth for helping us replicate their experimental setup, and Heng Ji and Dekang Lin for providing their gender lexicon.
Please see (Raghunathan et al, 2010) for more details. $$$$$ For example, in ACE2004CULOTTA-TEST our system has a B3 F1 score only .4 points lower than Bengston and Roth (2008) and it outperforms all unsupervised approaches.
Please see (Raghunathan et al, 2010) for more details. $$$$$ Any opinions, findings, and conclusion or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of DARPA, AFRL, or the US government.
Please see (Raghunathan et al, 2010) for more details. $$$$$ Demonym – one of the mentions is a demonym of the other, e.g., [Israel] ... [Israeli].

The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ We use three evaluation metrics widely used in the literature: (a) pairwise F1 (Ghosh, 2003) – computed over mention pairs in the same entity cluster; (b) MUC (Vilain et al., 1995) – which measures how many predicted clusters need to be merged to cover the gold clusters; and (c) B3 (Amit and Baldwin, 1998) – which uses the intersection between predicted and gold clusters for a given mention to mark correct mentions and the sizes of the the predicted and gold clusters as denominators for precision and recall, respectively.
The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ Our system does not rely on labeled corpora for training (like supervised approaches) nor access to corpora during testing (like Haghighi and Klein (2009)).
The core of our coreference resolution system is an incremental extension of the system described in Raghunathan et al (2010). $$$$$ To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision.

Proper Head Word Match: This sieve marks two mentions headed by proper nouns as coreferent if they have the same head word and satisfy the following constraints: Not i-within-i same as Raghunathan et al (2010). $$$$$ Finally, the multi-pass architecture always beats the equivalent single-pass system with its contribution ranging between 1 and 4 F1 points depending on the corpus and evaluation metric.
Proper Head Word Match: This sieve marks two mentions headed by proper nouns as coreferent if they have the same head word and satisfy the following constraints: Not i-within-i same as Raghunathan et al (2010). $$$$$ ... the president, quoted by ari fleischer, his spokesman, is saying he’s concerned the strike will undermine efforts by palestinian authorities to bring an end to terrorist attacks and does not contribute to the security of [israel].
Proper Head Word Match: This sieve marks two mentions headed by proper nouns as coreferent if they have the same head word and satisfy the following constraints: Not i-within-i same as Raghunathan et al (2010). $$$$$ This suggests that sievebased approaches could be applied to other NLP tasks.
Proper Head Word Match: This sieve marks two mentions headed by proper nouns as coreferent if they have the same head word and satisfy the following constraints: Not i-within-i same as Raghunathan et al (2010). $$$$$ We parse all documents using the Stanford parser (Klein and Manning, 2003).

The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones.
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ We present the results of our approach and other relevant prior work in Table 3.
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ Relative pronoun – the mention is a relative pronoun that modifies the head of the antecedent NP, e.g., [the finance street [which] has already formed in the Waitan district].
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity (Raghunathan et al, 2010). $$$$$ We propose an unsupervised sieve-like approach to coreference resolution that addresses these is1As we will discuss below, some approaches use an additional component to infer the overall best mention clusters for a document, but this is still based on confidence scores assigned using local information. sues.

By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ Further, our model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster.
By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ They first identified articles relevant to the entity mentions in the test set, and then bootstrapped from known syntactic patterns for apposition and predicate-nominatives in order to learn a database of related head pairs.
By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in (Raghunathanet al, 2010) and (Lee et al, 2011) have been manually ordered using a separate development dataset. $$$$$ We exclude from this analysis two notable works that report results only on a version of the task that includes finding mentions (Haghighi and Klein, 2010; Stoyanov, 2010).

Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ An additional benefit of the sieve framework is its modularity: new features or models can be inserted in the system with limited understanding of the other features already deployed.
Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ This theory is known by different names in many NLP applications: Brown et al. (1993) used simple models as “stepping stones” for more complex word alignment models; Collins (1999) used “cautious” decision list learning for named entity classification; Spitkovsky et al.
Chen built upon the sieve architecture proposed in Raghunathan et al (2010) and added one more sieve - head match - for Chinese and modified two sieves. $$$$$ These four highlighted errors (lengthening, semantics, attributes, ordering) add up to 77% of all recall errors in the selected set.

We incorporate lexicalized feature sets into two different coreference architectures: Reconcile (Stoyanov et al, 2010), a pairwise coreference classifier, and Sieve (Raghunathan et al, 2010), a rule-based system. $$$$$ Table 4 shows the number of incorrect pair-wise links generated by our system on the MUC6-TEST corpus.
We incorporate lexicalized feature sets into two different coreference architectures: Reconcile (Stoyanov et al, 2010), a pairwise coreference classifier, and Sieve (Raghunathan et al, 2010), a rule-based system. $$$$$ Recent work on coreference resolution has shown that a rich feature space that models lexical, syntactic, semantic, and discourse phenomena is crucial to successfully address the task (Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010).
We incorporate lexicalized feature sets into two different coreference architectures: Reconcile (Stoyanov et al, 2010), a pairwise coreference classifier, and Sieve (Raghunathan et al, 2010), a rule-based system. $$$$$ Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features.
We incorporate lexicalized feature sets into two different coreference architectures: Reconcile (Stoyanov et al, 2010), a pairwise coreference classifier, and Sieve (Raghunathan et al, 2010), a rule-based system. $$$$$ This initial clustering step will assign the correct animacy attribute (inanimate) to the corresponding geo-political entity, which will prevent the incorrect merging with the mention we (animate) in later steps.

There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ We also thank Nicholas Rizzolo and Dan Roth for helping us replicate their experimental setup, and Heng Ji and Dekang Lin for providing their gender lexicon.
There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ To measure the contribution of our multi-pass system, we also present results from a single-pass variant of our system that uses all applicable features from the multi-pass system (marked as “single pass” in the table).
There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like manner (Raghunathan et al, 2010). $$$$$ Two recent works that diverge from this pattern are Culotta et al. (2007) and Poon and Domingos (2008).

Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ Our work reinforces this observation, and extends it by proposing a novel architecture that: (a) allows easy deployment of such features, and (b) infuses global information that can be readily exploited by these features or constraints.
Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ Any opinions, findings, and conclusion or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of DARPA, AFRL, or the US government.
Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ This suggests that sievebased approaches could be applied to other NLP tasks.
Compared with machine learning methods, (Raghunathan et al, 2010) proposed rule-base models which have been witnessed good performance. $$$$$ We parse all documents using the Stanford parser (Klein and Manning, 2003).

This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ All our components are unsupervised, in the sense that they do not require training on gold coreference links.
This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ This theory is known by different names in many NLP applications: Brown et al. (1993) used simple models as “stepping stones” for more complex word alignment models; Collins (1999) used “cautious” decision list learning for named entity classification; Spitkovsky et al.
This fact explains a new trend to develop accurate unsupervised systems that exploit simple but robust linguistic principles (Raghunathan et al, 2010). $$$$$ The Haghighi and Klein (2009) numbers have two variants: with semantics (+S) and without (−S).

This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ In MUC6-TEST, our sieve’s B3 F1 score is 1.8 points lower than Haghighi and Klein (2009) +S, but it outperforms a supervised system that used gold named entity labels.
This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ Not i-within-i – the two mentions are not in an iwithin-i construct, i.e., one cannot be a child NP in the other’s NP constituent (Haghighi and Klein, 2009).
This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ The table indicates that most of our errors are for nominal mentions.
This is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains (Raghunathan et al, 2010), and also on other bio data (hsiang Lin and Liang, 2004). $$$$$ In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora.

Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects: (a) our sieves are machine-learning classifiers, (b) the same pair of mentions can fall into multiple sieves, (c) later sieves can override the decisions made by earlier sieves, allowing to recover from errors as additional evidence becomes available. $$$$$ With one exception (Pass 2), all the previous coreference models focus on nominal coreference resolution.
Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects: (a) our sieves are machine-learning classifiers, (b) the same pair of mentions can fall into multiple sieves, (c) later sieves can override the decisions made by earlier sieves, allowing to recover from errors as additional evidence becomes available. $$$$$ However, our approach does not make any assumptions about the underlying mentions, so it is trivial to adapt it to predicted mention boundaries (e.g., see Haghighi and Klein (2010) for a simple mention detection model).
Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects: (a) our sieves are machine-learning classifiers, (b) the same pair of mentions can fall into multiple sieves, (c) later sieves can override the decisions made by earlier sieves, allowing to recover from errors as additional evidence becomes available. $$$$$ Additionally, the deterministic models in our tiered model are significantly simpler, yet perform generally better than the complex inference models proposed in these works.
Our multi-sieve approach is different from (Raghunathan et al 2010) in several respects: (a) our sieves are machine-learning classifiers, (b) the same pair of mentions can fall into multiple sieves, (c) later sieves can override the decisions made by earlier sieves, allowing to recover from errors as additional evidence becomes available. $$$$$ We parse all documents using the Stanford parser (Klein and Manning, 2003).

(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ However, our approach does not make any assumptions about the underlying mentions, so it is trivial to adapt it to predicted mention boundaries (e.g., see Haghighi and Klein (2010) for a simple mention detection model).
(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ Our code is publicly released5 and can be used both as a stand-alone coreference system and as a platform for the development of future systems.
(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ We presented a simple deterministic approach to coreference resolution that incorporates documentlevel information, which is typically exploited only by more complex, joint learning models.
(Raghunathan et al 2010) recorded the best result on CoNLL 2011 shared task. $$$$$ We implemented all components in our approach using only deterministic models.

The ordering should be such that (a) maximum amount of information is injected at early stages (b) the precision at the early stages is as high as possible (Raghunathan et al 2010). $$$$$ Like us, they use a rich set of features and deterministic decisions.
The ordering should be such that (a) maximum amount of information is injected at early stages (b) the precision at the early stages is as high as possible (Raghunathan et al 2010). $$$$$ Any opinions, findings, and conclusion or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of DARPA, AFRL, or the US government.
The ordering should be such that (a) maximum amount of information is injected at early stages (b) the precision at the early stages is as high as possible (Raghunathan et al 2010). $$$$$ Relative pronoun – the mention is a relative pronoun that modifies the head of the antecedent NP, e.g., [the finance street [which] has already formed in the Waitan district].

Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ The table also highlights that most of our errors are recall errors.
Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ Intra-document coreference resolution clusters together textual mentions within a single document based on the underlying referent entity.
Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ Two recent works that diverge from this pattern are Culotta et al. (2007) and Poon and Domingos (2008).
Third, while our division to sieves may resemble witchcraft, it is motivated by the intuition that mentions appearing close to one another are easier instances of co-ref as well as linguistic insights of (Raghunathan et al 2010). $$$$$ For instance, once a new high precision feature (or group of features) is inserted as its own stage, it will benefit later stages with more precise clusters, but it will not interfere with their particular algorithmic decisions.
