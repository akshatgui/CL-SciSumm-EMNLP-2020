If we analyze these three models in terms of expressive power, the Galley et al (2006) model is more expressive than the SPMT models, which in turn, are more expressive than Chiang's model. $$$$$ Since xRs rules can be converted to context-free productions by increasing the number of non-terminals, we implemented our decoder as a standard CKY parser with beam search.
If we analyze these three models in terms of expressive power, the Galley et al (2006) model is more expressive than the SPMT models, which in turn, are more expressive than Chiang's model. $$$$$ While syntactic approaches seek to remedy word ordering problems common to statistical machine translation (SMT) systems, many of the earlier models?particularly child re-ordering models?
If we analyze these three models in terms of expressive power, the Galley et al (2006) model is more expressive than the SPMT models, which in turn, are more expressive than Chiang's model. $$$$$ We also usereal examples to show that our probability mod els estimated from a large number of derivations favor phrasal re-orderings that are linguistically well motivated.

The xRS formalism utilized by Galley et al (2006) allows for the use of translation rules that have multi-level target tree annotations and discontinuous source language phrases. $$$$$ Minimal rules defined over G are thosethat cannot be decomposed into simpler rules induced by the same graph G, e.g., all rules in Table 1.
The xRS formalism utilized by Galley et al (2006) allows for the use of translation rules that have multi-level target tree annotations and discontinuous source language phrases. $$$$$ , x0 .0234 , ( x1 x0 ? .0289 Table 4: Translation probabilities promote linguistically motivated constituent re-orderings (for lhs1 and lhs2), and enable non-constituent (lhs3) and non-contiguous (lhs4) phrasal translations.per levels of the tree.
The xRS formalism utilized by Galley et al (2006) allows for the use of translation rules that have multi-level target tree annotations and discontinuous source language phrases. $$$$$ In this paper, we developed probability models for the multi-level transfer rules presented in (Galley et al, 2004), showed how to acquire larger rules that crucially condition on more syntactic context, and how to pack multiple derivations, including interpretations of unaligned words, into derivation forests.
The xRS formalism utilized by Galley et al (2006) allows for the use of translation rules that have multi-level target tree annotations and discontinuous source language phrases. $$$$$ fail to account for human translation behavior.Galley et al (2004) alleviate this modeling prob lem and present a method for acquiring millions of syntactic transfer rules from bilingual corpora,which we review below.

The parameters of the SPMT models presented in this paper are easier to estimate than those of Galley et als (2006) and can easily exploit and expand on previous research in phrase-based machine translation. $$$$$ Statistical MT has made great progress in the last few years, but current translation models are weakon re-ordering and target language fluency.

 $$$$$ With the notable exception of Poutsma, most related works rely on models that are restricted to synchronous context-free grammars (SCFG).While the state-of-the-art hierarchical SMT system (Chiang, 2005) performs well despite stringent constraints imposed on its context-free gram mar, we believe its main advantage lies in its ability to extract hierarchical rules across phrasal boundaries.
 $$$$$ Statistical MT has made great progress in the last few years, but current translation models are weakon re-ordering and target language fluency.

Syntax-driven (Galley et al, 2006) and hierarchical translation models (Chiang, 2005) take advantage of probabilistic synchronous context free grammars (PSCFGs) to represent structured, lexical reordering constraints during the decoding process. $$$$$ HR0011 06-C-0022.
Syntax-driven (Galley et al, 2006) and hierarchical translation models (Chiang, 2005) take advantage of probabilistic synchronous context free grammars (PSCFGs) to represent structured, lexical reordering constraints during the decoding process. $$$$$ On the other hand, our syntax decoder is still work in progress: only one model was used during search, i.e., the EM-trained root-normalized SBTM, and as yet no language model is incorporated in thesearch (whereas the search in the AlTemp sys tem uses two phrase-based translation models and 967 Syntactic AlTemp Arabic-to-English 40.2 46.6 Chinese-to-English 24.3 30.7 Table 5: BLEU-4 scores for the 2005 NIST test set.
Syntax-driven (Galley et al, 2006) and hierarchical translation models (Chiang, 2005) take advantage of probabilistic synchronous context free grammars (PSCFGs) to represent structured, lexical reordering constraints during the decoding process. $$$$$ Context-free grammars (such as PennTreebank and Chiang?s grammars) make independence assumptions that are arguably often unrea sonable, but as our work suggests, relaxations of these assumptions by using contextually richer rules results in translations of increasing quality.

(Galley et al, 2006) use syntactic constituents for the PSCFG nonterminal set and (Zollmann and Venugopal, 2006) take advantage of CCG (Steedman, 1999) categories, while (Chiang, 2005) uses a single generic nonterminal. $$$$$ Syn tactic approaches seek to remedy these problems.In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Gal ley et al, 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we constructa large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words.

Similarly, the tree-to-string syntax-based transduction approach offers a complete translation framework (Galley et al, 2006). $$$$$ Statistical MT has made great progress in the last few years, but current translation models are weakon re-ordering and target language fluency.
Similarly, the tree-to-string syntax-based transduction approach offers a complete translation framework (Galley et al, 2006). $$$$$ This work was partially supported under theGALE program of the Defense Advanced Research Projects Agency, Contract No.
Similarly, the tree-to-string syntax-based transduction approach offers a complete translation framework (Galley et al, 2006). $$$$$ An empirical evaluation against a state-of-the-art SMT system similar to (Och and Ney, 2004) indicates positive prospects.

 $$$$$ pi as lhs(ri), appending a variable to each leaf node of ? that is internal to pi, adding those variables to rhs(ri), ordering them in accordance to a, and if necessary inserting any word of f to ensure that rhs(ri) is a sequence of contiguous spans (e.g., [4-5][6][7-8] for rule (f) in Table 1).
 $$$$$ Formally, transfor mational rules ri presented in (Galley et al, 2004) are equivalent to 1-state xRs transducers mapping a given pattern (subtree to match in pi) to a right hand side string.

Six MT systems were combined: three (A, C, E) were phrase based similar to (Koehn, 2004), two (B, D) were hierarchical similar to (Chiang, 2005) and one (F) was syntax-based similar to (Galley et al, 2006). $$$$$ Thus, the total probability mass, which is dis-.
Six MT systems were combined: three (A, C, E) were phrase based similar to (Koehn, 2004), two (B, D) were hierarchical similar to (Chiang, 2005) and one (F) was syntax-based similar to (Galley et al, 2006). $$$$$ We believe it will be beneficial to account for this finding in future work in syntax-based SMT and in efforts to improve upon (Chiang, 2005).
Six MT systems were combined: three (A, C, E) were phrase based similar to (Koehn, 2004), two (B, D) were hierarchical similar to (Chiang, 2005) and one (F) was syntax-based similar to (Galley et al, 2006). $$$$$ in G that are neither descendants nor ancestors of n. Nodesof G whose spans and complement spans are non overlapping form the frontier set F ? G.What is particularly interesting about the fron tier set?

In this paper, we focus on syntactic translation with tree-transducer rules (Galley et al, 2006). $$$$$ The when-NP-are-VP construction of lhs4 presents such a case.
In this paper, we focus on syntactic translation with tree-transducer rules (Galley et al, 2006). $$$$$ Each node of the graph is labeled with its span and complement span (the latter in italic in the figure).

GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al, 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). $$$$$ Syn tactic approaches seek to remedy these problems.In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Gal ley et al, 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we constructa large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words.
GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al, 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). $$$$$ We contrast our work with (Galley et al, 2004), highlight some severe limitations of probability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair.
GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al, 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). $$$$$ While the general theory presented in GHKM ac counts for any kind of derivation consistent with G, it does not particularly discuss the case where some words of the source-language string f are not aligned to any word of e, thus disconnectedfrom the rest of the graph.

Using these alignments, which we refer to as GIZA++ union + link deletion, we train a syntax-based translation system similar to that described in (Galley et al., 2006). $$$$$ We presented some theoretical argumentsfor not limiting extraction to minimal rules, val idated them on concrete examples, and presented experiments showing that contextually richer rulesprovide a 3.63 BLEU point increase over the min imal rules of (Galley et al, 2004).
Using these alignments, which we refer to as GIZA++ union + link deletion, we train a syntax-based translation system similar to that described in (Galley et al., 2006). $$$$$ Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of (Galley et al, 2004).

For example, Galley et al (2004) initially built a syntax-based system using only minimal rules, and subsequently reported (Galley et al, 2006) that composing rules improves Bleu by 3.6 points, while increasing grammar size 60-fold and decoding time 15-fold. $$$$$ This work was partially supported under theGALE program of the Defense Advanced Research Projects Agency, Contract No.
For example, Galley et al (2004) initially built a syntax-based system using only minimal rules, and subsequently reported (Galley et al, 2006) that composing rules improves Bleu by 3.6 points, while increasing grammar size 60-fold and decoding time 15-fold. $$$$$ Conversely, NP(x0:DT, x1:CD:, x2:NNS) is not the lhs of any rule extractible from G, since its frontier constituents CD[2] and NNS[2] haveoverlapping spans.3 Finally, the GHKM proce dure produces a single derivation from G, which is shown in Table 1.
For example, Galley et al (2004) initially built a syntax-based system using only minimal rules, and subsequently reported (Galley et al, 2006) that composing rules improves Bleu by 3.6 points, while increasing grammar size 60-fold and decoding time 15-fold. $$$$$ While syntactic approaches seek to remedy word ordering problems common to statistical machine translation (SMT) systems, many of the earlier models?particularly child re-ordering models?

Galley et al (2006 )argued that breaking a single tree pair into multiple decompositions is important for correct probability modeling. $$$$$ AcknowledgmentsWe would like to thank anonymous review ers for their helpful comments and suggestions.
Galley et al (2006 )argued that breaking a single tree pair into multiple decompositions is important for correct probability modeling. $$$$$ Similarly to (Poutsma, 2000; Wu, 1997; Yamadaand Knight, 2001; Chiang, 2005), the rules dis cussed in this paper are equivalent to productions of synchronous tree substitution grammars.

For example, Galley et al (2006) proposed the idea of rule composing which composes two or more rules with shared states to form a larger, composed rule. $$$$$ We will see in Sections 3 and 5 why extracting only minimal rules can be highly problematic.
For example, Galley et al (2006) proposed the idea of rule composing which composes two or more rules with shared states to form a larger, composed rule. $$$$$ We believe it will be beneficial to account for this finding in future work in syntax-based SMT and in efforts to improve upon (Chiang, 2005).
For example, Galley et al (2006) proposed the idea of rule composing which composes two or more rules with shared states to form a larger, composed rule. $$$$$ The question is what to do with such lexical items, e.g., ? inFigure 2(a).

Following Galley et al (2006)'s work, Marcu et al (2006) proposed SPMT models to improve the coverage of phrasal rules, and demonstrated that the system performance could be further improved by using their proposed models. $$$$$ We contrast our work with (Galley et al, 2004), highlight some severe limitations of probability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair.
Following Galley et al (2006)'s work, Marcu et al (2006) proposed SPMT models to improve the coverage of phrasal rules, and demonstrated that the system performance could be further improved by using their proposed models. $$$$$ rhs(ri) is represented as a se quence of target-language words and variables.
Following Galley et al (2006)'s work, Marcu et al (2006) proposed SPMT models to improve the coverage of phrasal rules, and demonstrated that the system performance could be further improved by using their proposed models. $$$$$ Since all rules in that example have probability 1, and 5If each tree fragment in pi is the lhs of some rule in R, then we have |?| = 2n, where n is the number of nodes of the frontier set F ? G (each node is a binary choice point).

As shown in the following parts of this paper, it works very well with the existing techniques, such as rule composing (Galley et al, 2006), SPMT models (Marcu et al, 2006) and rule extraction with k best parses (Venugopal et al, 2008). $$$$$ With the notable exception of Poutsma, most related works rely on models that are restricted to synchronous context-free grammars (SCFG).While the state-of-the-art hierarchical SMT system (Chiang, 2005) performs well despite stringent constraints imposed on its context-free gram mar, we believe its main advantage lies in its ability to extract hierarchical rules across phrasal boundaries.
As shown in the following parts of this paper, it works very well with the existing techniques, such as rule composing (Galley et al, 2006), SPMT models (Marcu et al, 2006) and rule extraction with k best parses (Venugopal et al, 2008). $$$$$ Here, we make the fol lowing new contributions: (1) we show how to acquire larger rules that crucially condition onmore syntactic context, and show how to compute multiple derivations for each training exam ple, capturing both large and small rules, as well as multiple interpretations for unaligned words;(2) we develop probability models for these multi level transfer rules, and give estimation methods for assigning probabilities to very large rule sets.
As shown in the following parts of this paper, it works very well with the existing techniques, such as rule composing (Galley et al, 2006), SPMT models (Marcu et al, 2006) and rule extraction with k best parses (Venugopal et al, 2008). $$$$$ We presented some theoretical argumentsfor not limiting extraction to minimal rules, val idated them on concrete examples, and presented experiments showing that contextually richer rulesprovide a 3.63 BLEU point increase over the min imal rules of (Galley et al, 2004).

In this work, the issue of translation rule extraction is studied in the string-to-tree model proposed by Galley et al (2006). $$$$$ Syn tactic approaches seek to remedy these problems.In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Gal ley et al, 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we constructa large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words.
In this work, the issue of translation rule extraction is studied in the string-to-tree model proposed by Galley et al (2006). $$$$$ While the general theory presented in GHKM ac counts for any kind of derivation consistent with G, it does not particularly discuss the case where some words of the source-language string f are not aligned to any word of e, thus disconnectedfrom the rest of the graph.
In this work, the issue of translation rule extraction is studied in the string-to-tree model proposed by Galley et al (2006). $$$$$ Similarly to (Poutsma, 2000; Wu, 1997; Yamadaand Knight, 2001; Chiang, 2005), the rules dis cussed in this paper are equivalent to productions of synchronous tree substitution grammars.

Finally, the rule composing method (Galley et al, 2006) is used to compose two or more minimal GHKM or SPMT rules having shared states to form larger rules. $$$$$ We registered both systems in the NIST 2005 evaluation; results are presented in Table 5.
Finally, the rule composing method (Galley et al, 2006) is used to compose two or more minimal GHKM or SPMT rules having shared states to form larger rules. $$$$$ fail to account for human translation behavior.Galley et al (2004) alleviate this modeling prob lem and present a method for acquiring millions of syntactic transfer rules from bilingual corpora,which we review below.

Our baseline MT system is built based on the string-to-tree model proposed in (Galley et al, 2006). $$$$$ Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of (Galley et al, 2004).
Our baseline MT system is built based on the string-to-tree model proposed in (Galley et al, 2006). $$$$$ An empirical evaluation against a state-of-the-art SMT system similar to (Och and Ney, 2004) indicates positive prospects.
Our baseline MT system is built based on the string-to-tree model proposed in (Galley et al, 2006). $$$$$ On the other hand, our syntax decoder is still work in progress: only one model was used during search, i.e., the EM-trained root-normalized SBTM, and as yet no language model is incorporated in thesearch (whereas the search in the AlTemp sys tem uses two phrase-based translation models and 967 Syntactic AlTemp Arabic-to-English 40.2 46.6 Chinese-to-English 24.3 30.7 Table 5: BLEU-4 scores for the 2005 NIST test set.
