 $$$$$ We showed that temporal reasoning can be used as an oversampling method to dramatically expand the amount of training data for TLINK labeling, resulting in labeling predictive accuracy as high as 93% using an off-the-shelf Maximum Entropy classifier.
 $$$$$ The results are shown in Table 4 (lines GTag+VerbOcean).
 $$$$$ The paper showed that ME-C performed significantly better than a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
 $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.

 $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
 $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
 $$$$$ This paper 1 investigates a machine learning approach for temporally ordering events in natural language texts.
 $$$$$ For example, given (3a), a TLINK tag orders an instance of the event of entering to an instance of the drinking with the relation type AFTER.

Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006). $$$$$ (Li et al. 2004) obtained 78-88% accuracy on ordering within-sentence temporal relations in Chinese texts.
Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006). $$$$$ In the case of humans, in fact, when a TLINK is posited by both annotators between the same pairs of events or times, the inter-annotator agreement on the labels is a .77 average of P&R.
Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006). $$$$$ These results suggest the time is ripe for exploiting ‘imperfect’ features in our machine learning approach.

Thus, the features in Mani et al (2006) are augmented with those used to describe signals detailed in Derczynski and Gaizauskas (2010), with some slight changes. $$$$$ GTag takes a document with TimeML tags, along with syntactic information from part-of-speech tagging and chunking from Carafe, and then uses 187 syntactic and lexical rules to infer and label TLINKs between tagged events and other tagged events or times.
Thus, the features in Mani et al (2006) are augmented with those used to describe signals detailed in Derczynski and Gaizauskas (2010), with some slight changes. $$$$$ The only closely comparable machinelearning approach to the problem of TLINK extraction was that of (Boguraev and Ando 2005), who trained a classifier on Timebank 1.1 for event anchoring for events and times within the same sentence, obtaining an F-measure (for tasks A and B together) of 53.1.
Thus, the features in Mani et al (2006) are augmented with those used to describe signals detailed in Derczynski and Gaizauskas (2010), with some slight changes. $$$$$ An event or time INCLUDES another event or time if the latter occupies a proper subinterval of the former.
Thus, the features in Mani et al (2006) are augmented with those used to describe signals detailed in Derczynski and Gaizauskas (2010), with some slight changes. $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.

The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded. $$$$$ Such rules, when mined by robust, large corpusbased methods, as in the Google-derived VerbOcean, are clearly relevant, but too specific to apply more than a few times in the OTC corpus.
The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded. $$$$$ SputLink’s transitivity table is represented by 745 axioms.
The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded. $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.

 $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.
 $$$$$ Clearly, lexical rules have a role to play in semantic and pragmatic reasoning from language, as in the discussion of example (2) in Section 1.
 $$$$$ (Note that as a result, the majority class percentages for the closed data have changed from the unclosed data.)
 $$$$$ What if both a core GTag rule and a VerbOcean-derived rule could both apply?

While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data. $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data. $$$$$ This means that for preprocessing new data sets to produce noisily annotated data for this classification task, it is far better to use machinelearning from closed human annotations rather than machine-learning from closed annotations produced by an intuitive baseline.
While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data. $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data. $$$$$ These inferences are shown (in slightly abbreviated form) in the annotations in (4) and (5).

Recently, extensions of Mani et al (2006)'s research is briefly described in (Mani et al, 2007). $$$$$ (Mani et al. 2003) obtained 80.2 F-measure training a decision tree on 2069 clauses in anchoring events to reference times that were inferred for each clause.
Recently, extensions of Mani et al (2006)'s research is briefly described in (Mani et al, 2007). $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.

This technical report addresses two problems found in (Mani et al, 2006) $$$$$ To address data sparseness, we used temporal reasoning as an over-sampling method to dramatically expand the amount of training data.
This technical report addresses two problems found in (Mani et al, 2006) $$$$$ This can result in the classifier producing an inconsistently annotated text.

 $$$$$ The TimeBank was developed in the early stages of TimeML development, and was partitioned across five annotators with different levels of expertise.
 $$$$$ The tagger takes pairs of TLINKable items (event and/or time) and searches for the single most-confident rule to apply to it, if any, to produce a labeled TLINK between those items.

Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. $$$$$ Given the pair <X, Z>, such a classifier has no idea if <Y, Z> has been classified as BEFORE, in which case, through closure, <X, Z> should be classified as BEFORE.
Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.
Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. $$$$$ In TimeML, inter-annotator agreement for time expressions and events is 0.83 and 0.78 (average of Precision and Recall) respectively, but on TLINKs it is 0.55 (P&R average), due to the large number of event pairs that can be selected for comparison.

Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning. $$$$$ For example, the narrative convention of events being described in the order in which they occur is followed in (1), but overridden by means of a discourse relation, Explanation in (2).
Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning. $$$$$ The anchor relation is an Event-Time TLINK, and the order relation is an Event-Event TLINK.
Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning. $$$$$ Without it, performance on this task of learning temporal relations is poor; with it, it is excellent.
Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning. $$$$$ Our research has uncovered one new finding: semantic reasoning (in this case, logical axioms for temporal closure), can be extremely valuable in addressing data sparseness.

 $$$$$ One could consider another obvious hybrid, namely learning from annotations created by GTag-annotated corpora.
 $$$$$ There were only 19 occasions when a happens-before pair from VerbOcean correctly matched a human BEFORE TLINK, of which 6 involved the same rule being right twice (including learn happens-before forget, a rule which students are especially familiar with!
 $$$$$ The Opinion Corpus was developed very recently, and was partitioned across just two highly trained annotators, and could therefore be expected to be less noisy.
 $$$$$ These results suggest the time is ripe for exploiting ‘imperfect’ features in our machine learning approach.

 $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.
 $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.

These differences are likely to come from the fact that $$$$$ The TimeML scheme flags tensed verbs, adjectives, and nominals with EVENT tags with various attributes, including the class of event, tense, grammatical aspect, polarity (negative or positive), any modal operators which govern the event being tagged, and cardinality of the event if it’s mentioned more than once.
These differences are likely to come from the fact that $$$$$ To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.
These differences are likely to come from the fact that $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.

As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006). $$$$$ Being able to bootstrap more training data is of course very useful.
As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006). $$$$$ The machine learning approach of (Cohen et al. 1999) addresses this, but their approach is limited to total orderings involving BEFORE, whereas TLINKs introduce partial orderings involving BEFORE and five other relations.
As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006). $$$$$ The first experiment (Closed Class Distribution) simply sampled 6145 instances uniformly from the closed instances, while the second experiment (Unclosed Class Distribution) sampled instances according to the same distribution as the unclosed data.
As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006). $$$$$ An important strategy in this area is of course the development of annotated corpora than can facilitate the machine learning of such ordering inferences.

Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data. $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data. $$$$$ For temporal relations, TimeML defines a TLINK tag that links tagged events to other events and/or times.
Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data. $$$$$ The reason for this might be due to the relatively modest increase in SIMULTANEOUS relations from applying closure (roughly factor of 2). closed graph for a document is in TLINKs, the greater the impact in terms of closure.
Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data. $$$$$ Thus, we can consider TLINK inference as the following classification problem: given an ordered pair of elements X and Y, where X and Y are events or times which the human has related temporally via a TLINK, the classifier has to assign a label in RelTypes.

 $$$$$ Thus, we can consider TLINK inference as the following classification problem: given an ordered pair of elements X and Y, where X and Y are events or times which the human has related temporally via a TLINK, the classifier has to assign a label in RelTypes.
 $$$$$ Without it, performance on this task of learning temporal relations is poor; with it, it is excellent.
 $$$$$ Finally, (Lapata and Lascarides 2004) use found data to successfully learn which (possibly ambiguous) temporal markers connect a main and subordinate clause, without inferring underlying temporal relations.
 $$$$$ For learning, we used an off-the-shelf Maximum Entropy (ME) classifier (from Carafe, available at sourceforge.net/projects/carafe).

Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ However, when using the same class distribution as the unclosed data (removing factor (2) from above), the accuracy, 76%, is higher than using the full unclosed data.
Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ The paper showed that ME-C performed significantly better than a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ This can result in the classifier producing an inconsistently annotated text.
Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ Our approach of classifying pairs independently during learning does not take into account dependencies between pairs.

In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ What is the reason for the improvement?5 One reason is the dramatic increase in the amount of training data.
In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ Thus, we can consider TLINK inference as the following classification problem: given an ordered pair of elements X and Y, where X and Y are events or times which the human has related temporally via a TLINK, the classifier has to assign a label in RelTypes.
In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ This paper investigates a machine learning approach for temporally ordering and anchoring events in natural language texts.
In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ Future research will investigate this effect further, as well as examine factors that enhance or mitigate this effect in different corpora.
