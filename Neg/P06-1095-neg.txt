 $$$$$ There has been a considerable amount of activity related to this scheme; we focus here on some of the challenges posed by the TLINK annotation, the part that is directly relevant to the temporal ordering and anchoring problems.
 $$$$$ A basic learning approach is described in Section 3.
 $$$$$ The machine learning approach of (Cohen et al. 1999) addresses this, but their approach is limited to total orderings involving BEFORE, whereas TLINKs introduce partial orderings involving BEFORE and five other relations.

 $$$$$ To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.
 $$$$$ The time complexity of the human TLINK annotation task is quadratic in the number of events and times in the document.
 $$$$$ Our work is, accordingly, evaluated in comparison against four baselines: (i) the usual majority class statistical baseline, shown along with each result, (ii) a more sophisticated baseline that uses hand-coded rules (Section 4.1), (iii) a hybrid baseline based on hand-coded rules expanded with Google-induced rules (Section 4.2), and (iv) a machine learning version that learns from imperfect annotation produced by (ii) (Section 4.3).
 $$$$$ (Note that as a result, the majority class percentages for the closed data have changed from the unclosed data.)

Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006). $$$$$ GTag takes a document with TimeML tags, along with syntactic information from part-of-speech tagging and chunking from Carafe, and then uses 187 syntactic and lexical rules to infer and label TLINKs between tagged events and other tagged events or times.
Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006). $$$$$ Future research will investigate methods for tighter integration of temporal reasoning and statistical classification.
Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006). $$$$$ TimeML uses 14 temporal relations in the TLINK RelTypes, which reduce to a disjunctive classification of 6 temporal relations RelTypes = {SIMULTANEOUS, IBEFORE, BEFORE, BEGINS, ENDS, INCLUDES}.
Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006). $$$$$ In order to help determine the effects of the above factors, we carried out two experiments in which we sampled 6145 vectors from the closed data – i.e. approximately the number of EventEvent vectors in the unclosed data.

Thus, the features in Mani et al (2006) are augmented with those used to describe signals detailed in Derczynski and Gaizauskas (2010), with some slight changes. $$$$$ In terms of hand-coded approaches, (Mani and Wilson 2000) used a baseline method of blindly propagating TempEx time values to events based on proximity, obtaining 59.4% on a small sample of 8,505 words of text.
Thus, the features in Mani et al (2006) are augmented with those used to describe signals detailed in Derczynski and Gaizauskas (2010), with some slight changes. $$$$$ The Opinion Corpus was developed very recently, and was partitioned across just two highly trained annotators, and could therefore be expected to be less noisy.

The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded. $$$$$ This paper investigates a machine learning approach for temporally ordering and anchoring events in natural language texts.
The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded. $$$$$ The greater class distribution skew in the closed data clearly contributes to improved accuracy.
The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded. $$$$$ These results suggest the time is ripe for exploiting ‘imperfect’ features in our machine learning approach.
The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded. $$$$$ Likewise, time expressions are flagged and their values normalized, based on TIMEX3, an extension of the ACE (2004) (tern.mitre.org) TIMEX2 annotation scheme.

 $$$$$ The only closely comparable machinelearning approach to the problem of TLINK extraction was that of (Boguraev and Ando 2005), who trained a classifier on Timebank 1.1 for event anchoring for events and times within the same sentence, obtaining an F-measure (for tasks A and B together) of 53.1.
 $$$$$ It’s possible that feature engineering could improve performance, but since this is “perfect” data, the result is not encouraging.
 $$$$$ We automatically extracted all the ‘happensbefore’ relations from the VerbOcean resource at the above web site, and then automatically converted those relations to GTag format, producing 4,199 rules.
 $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.

While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data. $$$$$ Recently, researchers have developed other tools for automatically tagging aspects of TimeML, including EVENT (Sauri et al. 2005) at 0.80 F-measure and TIMEX36 tags at 0.82-0.85 F-measure.
While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data. $$$$$ We automatically extracted all the ‘happensbefore’ relations from the VerbOcean resource at the above web site, and then automatically converted those relations to GTag format, producing 4,199 rules.
While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data. $$$$$ To expand our training set, we use a temporal closure component SputLink (Verhagen 2004), that takes known temporal relations in a text and derives new implied relations from them, in effect making explicit what was implicit.

Recently, extensions of Mani et al (2006)'s research is briefly described in (Mani et al, 2007). $$$$$ Future research will investigate this effect further, as well as examine factors that enhance or mitigate this effect in different corpora.
Recently, extensions of Mani et al (2006)'s research is briefly described in (Mani et al, 2007). $$$$$ Such intuitions led to the development of pattern matching rules incorporated in a TLINK tagger called GTag.
Recently, extensions of Mani et al (2006)'s research is briefly described in (Mani et al, 2007). $$$$$ Our approach of classifying pairs independently during learning does not take into account dependencies between pairs.
Recently, extensions of Mani et al (2006)'s research is briefly described in (Mani et al, 2007). $$$$$ Our work is, accordingly, evaluated in comparison against four baselines: (i) the usual majority class statistical baseline, shown along with each result, (ii) a more sophisticated baseline that uses hand-coded rules (Section 4.1), (iii) a hybrid baseline based on hand-coded rules expanded with Google-induced rules (Section 4.2), and (iv) a machine learning version that learns from imperfect annotation produced by (ii) (Section 4.3).

This technical report addresses two problems found in (Mani et al, 2006): (1) feature vector duplication caused by the data normalization process (once fixed, the accuracy drops to 76.56% and 83.23%) and (2) a somewhat unrealistic evaluation scheme (we describe Mani et al (2007)'s results in Section 4.1). $$$$$ Task A is hard to evaluate since, in the absence of massive preprocessing, many links are ignored by the human in creating the annotated corpora.
This technical report addresses two problems found in (Mani et al, 2006): (1) feature vector duplication caused by the data normalization process (once fixed, the accuracy drops to 76.56% and 83.23%) and (2) a somewhat unrealistic evaluation scheme (we describe Mani et al (2007)'s results in Section 4.1). $$$$$ Finally, (Lapata and Lascarides 2004) use found data to successfully learn which (possibly ambiguous) temporal markers connect a main and subordinate clause, without inferring underlying temporal relations.
This technical report addresses two problems found in (Mani et al, 2006): (1) feature vector duplication caused by the data normalization process (once fixed, the accuracy drops to 76.56% and 83.23%) and (2) a somewhat unrealistic evaluation scheme (we describe Mani et al (2007)'s results in Section 4.1). $$$$$ The reason VerbOcean didn’t help is again one of data sparseness, due to most verbs occurring rarely in the OTC.
This technical report addresses two problems found in (Mani et al, 2006): (1) feature vector duplication caused by the data normalization process (once fixed, the accuracy drops to 76.56% and 83.23%) and (2) a somewhat unrealistic evaluation scheme (we describe Mani et al (2007)'s results in Section 4.1). $$$$$ Such intuitions led to the development of pattern matching rules incorporated in a TLINK tagger called GTag.

 $$$$$ The mining uses a set of lexical and syntactic patterns to test for pairs of verb strongly associated on the Web in an asymmetric ‘happens-before’ relation.
 $$$$$ The number of BEFORE links goes up from 3170 (51.6%) Event-Event and 1229 Event-Time TLINKs (26.75%) to 68585 (75.2%) EventEvent and 18665 (62.3%) Event-Time TLINKs, making BEFORE the majority class in the closed data for both Event-Event and Event-Time TLINKs.
 $$$$$ There were only 5 occasions when a VerbOcean rule incorrectly matched a human BEFORE TLINK, involving just three rules.
 $$$$$ We assume the one with the higher confidence is chosen.

Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. $$$$$ An event or time is SIMULTANEOUS with another event or time if they occupy the same time interval.
Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. $$$$$ Our approach of classifying pairs independently during learning does not take into account dependencies between pairs.
Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. $$$$$ (Mani et al. 2003) obtained 80.2 F-measure training a decision tree on 2069 clauses in anchoring events to reference times that were inferred for each clause.
Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations. $$$$$ The effect of closing the TLINKs on the corpus has a dramatic impact on learning.

Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning. $$$$$ GTag takes a document with TimeML tags, along with syntactic information from part-of-speech tagging and chunking from Carafe, and then uses 187 syntactic and lexical rules to infer and label TLINKs between tagged events and other tagged events or times.
Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning. $$$$$ It may be possible to acquire confidence weights for at least some of the intuitive rules in GTag from Google searches, so that we have a level field for integrating confidence weights from the fairly general GTag rules and the fairly specific VerbOcean-like lexical rules.
Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning. $$$$$ (Schilder and Habel 2001) report 84% accuracy inferring temporal relations in German data, and (Li et al. 2001) report 93% accuracy on extracting temporal relations in Chinese.

 $$$$$ The more connected the initial un5Interestingly, performance does not improve for SIMULTANEOUS.
 $$$$$ Further, the GTag and VerbOcean rules could be incorporated as features for machine learning, along with features from automatic preprocessing.
 $$$$$ The reason for this might be due to the relatively modest increase in SIMULTANEOUS relations from applying closure (roughly factor of 2). closed graph for a document is in TLINKs, the greater the impact in terms of closure.

 $$$$$ In terms of hand-coded approaches, (Mani and Wilson 2000) used a baseline method of blindly propagating TempEx time values to events based on proximity, obtaining 59.4% on a small sample of 8,505 words of text.
 $$$$$ However, the noise in the corpus and the sparseness of links present challenges to a learning approach.
 $$$$$ SMO performance (but not naïve Bayes) was comparable with ME, with SMO trailing it in a few cases (to save space, we report just ME performance).

These differences are likely to come from the fact that: (i) (Mani et al, 2006) perform a 6-way classification, and not a 13-way classification, and (ii) (Chambers and Jurafsky, 2008) use a relation set that is even more restrictive than TempEval's. $$$$$ Further, the GTag and VerbOcean rules could be incorporated as features for machine learning, along with features from automatic preprocessing.
These differences are likely to come from the fact that: (i) (Mani et al, 2006) perform a 6-way classification, and not a 13-way classification, and (ii) (Chambers and Jurafsky, 2008) use a relation set that is even more restrictive than TempEval's. $$$$$ The reason VerbOcean didn’t help is again one of data sparseness, due to most verbs occurring rarely in the OTC.

As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006). $$$$$ The growing interest in practical NLP applications such as question-answering and text summarization places increasing demands on the processing of temporal information.
As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006). $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.
As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006). $$$$$ Once a tagger has tagged the events and times, the first task (A) is to link events and/or times, and the second task (B) is to label the links.

Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data. $$$$$ Such rules, when mined by robust, large corpusbased methods, as in the Google-derived VerbOcean, are clearly relevant, but too specific to apply more than a few times in the OTC corpus.
Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data. $$$$$ This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data. $$$$$ The reason VerbOcean didn’t help is again one of data sparseness, due to most verbs occurring rarely in the OTC.

 $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.
 $$$$$ Since the intuitive baseline fares badly, this may not be that attractive.
 $$$$$ Given the pair <X, Z>, such a classifier has no idea if <Y, Z> has been classified as BEFORE, in which case, through closure, <X, Z> should be classified as BEFORE.
 $$$$$ Our results in these comparisons confirm the lessons learned from the corpus-based revolution, namely that rules based on intuition alone are prone to incompleteness and are hard to tune without access to the distributions found in empirical data.

Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ Here is one such converted rule: Adding these lexical rules to GTag (with morphological normalization being added for rule matching on word features) amounts to a considerable augmentation of the rule-set, by a factor of 22.
Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ Given the availability of a corpus like OTC, it is natural to try a machine learning approach to see if it can be used to provide that preprocessing.
Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ A wealth of prior research by (Passoneau 1988), (Webber 1988), (Hwang and Schubert 1992), (Kamp and Reyle 1993), (Lascarides and Asher 1993), (Hitzeman et al. 1995), (Kehler 2000) and others, has explored the different knowledge sources used in inferring the temporal ordering of events, including temporal adverbials, tense, aspect, rhetorical relations, pragmatic conventions, and background knowledge.
Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data. $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.

In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ We showed that temporal reasoning can be used as an oversampling method to dramatically expand the amount of training data for TLINK labeling, resulting in labeling predictive accuracy as high as 93% using an off-the-shelf Maximum Entropy classifier.
In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ Table 1 shows the distribution of EVENTs and TIMES, and TLINK RelTypes3 in the OTC.
In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.
In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents. $$$$$ Such rules, when mined by robust, large corpusbased methods, as in the Google-derived VerbOcean, are clearly relevant, but too specific to apply more than a few times in the OTC corpus.
