Riezler et al (2002) report on our WSJ parsing experiments. $$$$$ While disambiguation performance of around 79% F-score on WSJ data seems promising, from one perspective it only offers a 3% absolute improvement over a lower bound random baseline.
Riezler et al (2002) report on our WSJ parsing experiments. $$$$$ Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets.
Riezler et al (2002) report on our WSJ parsing experiments. $$$$$ We think that the high lower bound measure highlights an important aspect of symbolic constraintbased grammars (in contrast to treebank grammars): the symbolic grammar already significantly restricts/disambiguates the range of possible analyses, giving the disambiguator a much narrower window in which to operate.

The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ For example, our labeled bracketing of wsj 1305.mrg is [NP-SBJHis credibility] is/VBZ also [PP-PRD on the line] in the investment community.
The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ Furthermore, let p[f] denote the expectation of function f under distribution p. Then P(λ) can be defined for a conditional exponential model pλ(zIy) as: Intuitively, the goal of estimation is to find model pa'An earlier approach using partially labeled data for estimating stochastics parsers is Pereira and Schabes’s (1992) work on training PCFG from partially bracketed data.
The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized.
The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ They report an F-score of 75.1% for a DO evaluation that ignores predicate labels, counting only dependencies.

 $$$$$ This procedure is based on a frequency cutoff on instantiations of properties for the parses in the labeled training set.
 $$$$$ In this paper we are concerned with conditional exponential models of the form: where X(y) is the set of parses for sentence y, Zλ(y) = PxEX(y) eλ'f(x) is a normalizing constant, λ = (λ1, ... , λn) E IRn is a vector of log-parameters, f = (f1, ... , fn) is a vector of property-functions fi : X IR for i = 1, ... , n on the set of parses X, and λ f(x) is the vector dot product Pni=1 λifi(x).
 $$$$$ Under this measure, our system achieves 76.1% F-score.

Specifically, we parsed a dump of English Wikipedia (July 2008) with the XLE parser (Riezler et al, 2002) and extracted the following dependency relations for nouns $$$$$ An evaluation on a gold standard of dependency relations for
Specifically, we parsed a dump of English Wikipedia (July 2008) with the XLE parser (Riezler et al, 2002) and extracted the following dependency relations for nouns $$$$$ The combined system trained on WSJ data achieves full grammar coverage and disambiguation performance of 79% F-score on WSJ data, and 76% F-score on the Brown corpus test set.
Specifically, we parsed a dump of English Wikipedia (July 2008) with the XLE parser (Riezler et al, 2002) and extracted the following dependency relations for nouns $$$$$ Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets.

They are still reasonably popular today, as exemplified by major systems like PARC's XLE (Riezler et al, 2002). $$$$$ The first evaluation we present measures matches of predicate-argument relations in LFG fstructures (henceforth the LFG annotation scheme) to a gold standard of manually annotated f-structures for a representative subset of the WSJ treebank.

See e.g. Riezler et al (2002) and Zhang et al (2007) for chart based parsers which can produce fragmentary analyses. $$$$$ In our experiments, we used around 1000 complex property-functions comprising information about c-structure, f-structure, and lexical elements in parses, similar to the properties used in Johnson et al. (1999).
See e.g. Riezler et al (2002) and Zhang et al (2007) for chart based parsers which can produce fragmentary analyses. $$$$$ On a gold standard of manually annotated f-structures for a subset of the WSJ treebank, this evaluation reaches 79% F-score.
See e.g. Riezler et al (2002) and Zhang et al (2007) for chart based parsers which can produce fragmentary analyses. $$$$$ Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations.

In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ This guarantees that XLE finishes processing a sentence in a polynomial amount of time.
In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model.
In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ The rudimentary treebank annotations are thus used to provide partially labeled data for discriminative estimation of a probability model on linguistically fine-grained parses.
In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ They report an F-score of 75.1% for a DO evaluation that ignores predicate labels, counting only dependencies.

Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ As such, it is more appropriate to assess the disambiguator in terms of reduction in error rate (36% relative to the upper bound) than in terms of absolute F-score.
Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ We think that the high lower bound measure highlights an important aspect of symbolic constraintbased grammars (in contrast to treebank grammars): the symbolic grammar already significantly restricts/disambiguates the range of possible analyses, giving the disambiguator a much narrower window in which to operate.
Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ As such, it is more appropriate to assess the disambiguator in terms of reduction in error rate (36% relative to the upper bound) than in terms of absolute F-score.
Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ The grammar uses several lexicons and two guessers: one guesser for words recognized by the morphological analyzer but not in the lexicons and one for those not recognized.

Riezler et al (2002) describe a discriminative LFG parsing model that is trained on standard (syntax only) tree bank annotations by treating each tree as a full LFG analysis with an observed c-structure and hidden f-structure. $$$$$ The first evaluation we present measures matches of predicate-argument relations in LFG fstructures (henceforth the LFG annotation scheme) to a gold standard of manually annotated f-structures for a representative subset of the WSJ treebank.
Riezler et al (2002) describe a discriminative LFG parsing model that is trained on standard (syntax only) tree bank annotations by treating each tree as a full LFG analysis with an observed c-structure and hidden f-structure. $$$$$ We employed the well-known family of exponential models for stochastic disambiguation.

For sentences out of coverage, it employs the robustness techniques (fragment parsing, 'skimming') implemented in XLE and described in Riezler et al. (2002), so that 100% of our corpus sentences receive at least some sort of analysis. $$$$$ As a result, the labeled bracketed version of this sentence does not receive a full parse, even though its unlabeled, string-only counterpart is wellformed.
For sentences out of coverage, it employs the robustness techniques (fragment parsing, 'skimming') implemented in XLE and described in Riezler et al. (2002), so that 100% of our corpus sentences receive at least some sort of analysis. $$$$$ In section 3 we present the details of the exponential model on LFG parses and the discriminative statistical estimation technique.
For sentences out of coverage, it employs the robustness techniques (fragment parsing, 'skimming') implemented in XLE and described in Riezler et al. (2002), so that 100% of our corpus sentences receive at least some sort of analysis. $$$$$ They report an F-score of 75.1% for a DO evaluation that ignores predicate labels, counting only dependencies.

Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in Riezler et al (2002). $$$$$ The set of fragment parses is then chosen on the basis of a fewest-chunk method.
Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in Riezler et al (2002). $$$$$ The model combines full and partial parsing techniques to reach full grammar coverage on unseen data.
Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in Riezler et al (2002). $$$$$ The error reduction row lists the reduction in error rate relative to the upper and lower bounds obtained by the stochastic disambiguation model.
Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in Riezler et al (2002). $$$$$ However, instead of retreating to unsupervised estimation techniques or creating small LFG treebanks by hand, we use the labeled bracketing of the WSJ training sections to guide discriminative estimation.

For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ That is, discriminative criteria are defined with respect to the set ofparses consistent with the WSJ annotations.1 The objective function in our approach, denoted by P(λ), is the joint of the negative log-likelihood −L(λ) and a Gaussian regularization term −G(λ) on the parameters λ.
For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ Furthermore, the effort involved in coding broadcoverage grammars by hand has often led to the specialization of grammars to relatively small domains, thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text.
For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model.
For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ As a result, the labeled bracketed version of this sentence does not receive a full parse, even though its unlabeled, string-only counterpart is wellformed.

We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ To increase robustness, the standard grammar has been augmented with a FRAGMENT grammar.
We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model.
We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ High versus low attachment is indicated by property functions counting the number of recursively embedded phrases.
We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses.

This was done to some extent in Riezler et al (2002) to automatically generate training data for the log-linear disambiguation component of XLE. $$$$$ The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal (henceforth WSJ) treebank (Marcus et al., 1994).
This was done to some extent in Riezler et al (2002) to automatically generate training data for the log-linear disambiguation component of XLE. $$$$$ We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model.
This was done to some extent in Riezler et al (2002) to automatically generate training data for the log-linear disambiguation component of XLE. $$$$$ An evaluation on a gold standard of dependency relations for

XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al, 2002) that works on the packed representations. $$$$$ They report an F-score of 75.1% for a DO evaluation that ignores predicate labels, counting only dependencies.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al, 2002) that works on the packed representations. $$$$$ The problem of grammar coverage, i.e. the fact that not all sentences receive an analysis, is tackled in our approach by an extension of a fullfledged Lexical-Functional Grammar (LFG) and a constraint-based parser with partial parsing techniques.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al, 2002) that works on the packed representations. $$$$$ The grammar coverage achieved 100% of section 23 as unseen unlabeled data: 74.7% as full parses, 25.3% FRAGMENT and/or SKIMMED parses.

XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear (a.k.a. maximum-entropy) probability model (Riezler et al, 2002). $$$$$ Evaluation with this metric measures the matches of dependency relations to Carroll et al.’s gold standard corpus.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear (a.k.a. maximum-entropy) probability model (Riezler et al, 2002). $$$$$ The treebank annotations are used to provide partially labeled data for discriminative statistical estimation using exponential models.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear (a.k.a. maximum-entropy) probability model (Riezler et al, 2002). $$$$$ The model combines full and partial parsing techniques to reach full grammar coverage on unseen data.

For a more detailed description of the optimization problem and the feature-functions we use for stochastic LFG parsing see Riezler et al (2002). $$$$$ We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model.
For a more detailed description of the optimization problem and the feature-functions we use for stochastic LFG parsing see Riezler et al (2002). $$$$$ Their approach differs from the one we use here in that Pereira and Schabes take an EM-based approach maximizing the joint likelihood of the parses and strings of their training data, while we maximize the conditional likelihood of the sets of parses given the corresponding strings in a discriminative estimation setting. rameters which make the two expectations in the last equation equal, i.e. which adjust the model parameters to put all the weight on the parses consistent with the annotations, modulo a penalty term from the Gaussian prior for too large or too small weights.

We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ In parsing section 23, 7.2% of the sentences were skimmed; 26.1% of these resulted in full parses, while 73.9% were FRAGMENT parses.
We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ Performance on the LFG-annotated WSJ test set was measured using both the LFG and DR metrics, thanks to an f-structure-to-DR annotation mapping.
We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ On a gold standard of manually annotated f-structures for a subset of the WSJ treebank, this evaluation reaches 79% F-score.
We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ Furthermore, a maximal exploitation of treebank annotations for estimating a distribution on fine-grained LFG parses is achieved by letting grammar analyses which are consistent with the WSJ labeled bracketing define a gold standard set for discriminative estimation.

The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation $$$$$ On a gold standard of manually annotated f-structures for a subset of the WSJ treebank, this evaluation reaches 79% F-score.
The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation $$$$$ In our experiments, we used around 1000 complex property-functions comprising information about c-structure, f-structure, and lexical elements in parses, similar to the properties used in Johnson et al. (1999).
The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation $$$$$ We have presented a first attempt at scaling up a stochastic parsing system combining a hand-coded linguistically fine-grained grammar and a stochastic disambiguation model to the WSJ treebank.
The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation $$$$$ The basic training data for our experiments are sections 02-21 of the WSJ treebank.

Following Pereira and Schabes' (1992) success with partial annotations in training a model of (English) constituents generatively, their idea has been extended to discriminative estimation (Riezler et al., 2002) and also proved useful in modeling (Japanese) dependencies (Sassano, 2005). $$$$$ In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized.
Following Pereira and Schabes' (1992) success with partial annotations in training a model of (English) constituents generatively, their idea has been extended to discriminative estimation (Riezler et al., 2002) and also proved useful in modeling (Japanese) dependencies (Sassano, 2005). $$$$$ However, the LFG grammar treats it as the OBJ of the matrix clause.
Following Pereira and Schabes' (1992) success with partial annotations in training a model of (English) constituents generatively, their idea has been extended to discriminative estimation (Riezler et al., 2002) and also proved useful in modeling (Japanese) dependencies (Sassano, 2005). $$$$$ We define discriminative or conditional criteria with respect to the set of grammar parses consistent with the treebank annotations.
