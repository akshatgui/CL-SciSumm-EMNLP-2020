Riezler et al (2002) report on our WSJ parsing experiments. $$$$$ We have presented a first attempt at scaling up a stochastic parsing system combining a hand-coded linguistically fine-grained grammar and a stochastic disambiguation model to the WSJ treebank.
Riezler et al (2002) report on our WSJ parsing experiments. $$$$$ Some mismatches between the WSJ labeled bracketing and the LFG grammar remain.
Riezler et al (2002) report on our WSJ parsing experiments. $$$$$ The effect of the quality of the parses on disambiguation performance can be illustrated by breaking down the F-scores according to whether the parser yields full parses, FRAGMENT, SKIMMED, or SKIMMED+FRAGMENT parses for the test sentences.
Riezler et al (2002) report on our WSJ parsing experiments. $$$$$ Under this measure we obtain 76% F-score.

The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ The third column reports F-scores for examples which receive only non-full parses, i.e.
The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ An evaluation on a gold standard of dependency relations for
The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ In this version of the corpus, all WSJ labels with -SBJ are retained and are restricted to phrases corresponding to SUBJ in the LFG grammar; in addition, it contains NP under VP (OBJ and OBJth in the LFG grammar), all -LGS tags (OBL-AG), all -PRD tags (XCOMP), VP under VP (XCOMP), SBAR- (COMP), and verb POS tags under VP (V in the c-structure).
The limitation of deterministic transfer rules has been recognized in prior work (Riezler et al, 2002). $$$$$ Skimming is used to avoid timeouts and memory problems.

 $$$$$ Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations.
 $$$$$ Both the DR and LFG annotations broadly agree in their measure of error reduction.
 $$$$$ We think that the high lower bound measure highlights an important aspect of symbolic constraintbased grammars (in contrast to treebank grammars): the symbolic grammar already significantly restricts/disambiguates the range of possible analyses, giving the disambiguator a much narrower window in which to operate.

Specifically, we parsed a dump of English Wikipedia (July 2008) with the XLE parser (Riezler et al, 2002) and extracted the following dependency relations for nouns: Verb-Subject, Verb-Object, Noun coordination, NN-compound, Adj-Mod. $$$$$ Under this measure, our system achieves 76.1% F-score.
Specifically, we parsed a dump of English Wikipedia (July 2008) with the XLE parser (Riezler et al, 2002) and extracted the following dependency relations for nouns: Verb-Subject, Verb-Object, Noun coordination, NN-compound, Adj-Mod. $$$$$ More complex property functions are designed to indicate, for example, the branching behaviour of c-structures and the (non)parallelism of coordinations on both c-structure and f-structure levels.
Specifically, we parsed a dump of English Wikipedia (July 2008) with the XLE parser (Riezler et al, 2002) and extracted the following dependency relations for nouns: Verb-Subject, Verb-Object, Noun coordination, NN-compound, Adj-Mod. $$$$$ For example, our labeled bracketing of wsj 1305.mrg is [NP-SBJHis credibility] is/VBZ also [PP-PRD on the line] in the investment community.

They are still reasonably popular today, as exemplified by major systems like PARC's XLE (Riezler et al, 2002). $$$$$ For example, in wsj 1303.mrg Japan’s Daiwa Securities Co. named Masahiro Dozen president., the noun phrase Masahiro Dozen is labeled as an NP-SBJ.
They are still reasonably popular today, as exemplified by major systems like PARC's XLE (Riezler et al, 2002). $$$$$ While disambiguation performance of around 79% F-score on WSJ data seems promising, from one perspective it only offers a 3% absolute improvement over a lower bound random baseline.
They are still reasonably popular today, as exemplified by major systems like PARC's XLE (Riezler et al, 2002). $$$$$ The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal (henceforth WSJ) treebank (Marcus et al., 1994).
They are still reasonably popular today, as exemplified by major systems like PARC's XLE (Riezler et al, 2002). $$$$$ Furthermore, only sentences 2An alternative numerical method would be a combination of iterative scaling techniques with a conditional EM algorithm (Jebara and Pentland, 1998).

See e.g. Riezler et al (2002) and Zhang et al (2007) for chart based parsers which can produce fragmentary analyses. $$$$$ Evaluation with this metric measures the matches of dependency relations to Carroll et al.’s gold standard corpus.
See e.g. Riezler et al (2002) and Zhang et al (2007) for chart based parsers which can produce fragmentary analyses. $$$$$ The evaluation measure counts the number of predicateargument relations in the f-structure of the parse selected by the stochastic model that match those in the gold standard annotation.
See e.g. Riezler et al (2002) and Zhang et al (2007) for chart based parsers which can produce fragmentary analyses. $$$$$ We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model.
See e.g. Riezler et al (2002) and Zhang et al (2007) for chart based parsers which can produce fragmentary analyses. $$$$$ For example, the WSJ’s ADJP-PRD label must correspond to an AP in the c-structure and an XCOMP in the f-structure.

In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ Some other bracketing mismatches remain, usually the result of adjunct attachment.
In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ Rather, parameter estimation for such models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999).
In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ An evaluation on a gold standard of dependency relations for
In this project, a broad-coverage LFG grammar and parser for English was employed (see Riezler et al (2002)). $$$$$ As a result, the labeled bracketed version of this sentence does not receive a full parse, even though its unlabeled, string-only counterpart is wellformed.

Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ However, it has been shown experimentally that conjugate gradient techniques can outperform iterative scaling techniques by far in running time (Minka, 2001). which received at most 1,000 parses were used.
Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ While disambiguation performance of around 79% F-score on WSJ data seems promising, from one perspective it only offers a 3% absolute improvement over a lower bound random baseline.
Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ Evaluation with this metric measures the matches of dependency relations to Carroll et al.’s gold standard corpus.
Alternatively, a single input parse could be selected by stochastic models such as the one described in Riezler et al (2002). $$$$$ In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more complex LFG parses.

Riezler et al (2002) describe a discriminative LFG parsing model that is trained on standard (syntax only) tree bank annotations by treating each tree as a full LFG analysis with an observed c-structure and hidden f-structure. $$$$$ Experimental results are reported in section 4.
Riezler et al (2002) describe a discriminative LFG parsing model that is trained on standard (syntax only) tree bank annotations by treating each tree as a full LFG analysis with an observed c-structure and hidden f-structure. $$$$$ The predicateargument relations of the f-structure for one parse of the sentence Meridian will pay a premium of $30.5 million to assume $2 billion in deposits. are shown in Fig.
Riezler et al (2002) describe a discriminative LFG parsing model that is trained on standard (syntax only) tree bank annotations by treating each tree as a full LFG analysis with an observed c-structure and hidden f-structure. $$$$$ The problem of grammar coverage, i.e. the fact that not all sentences receive an analysis, is tackled in our approach by an extension of a fullfledged Lexical-Functional Grammar (LFG) and a constraint-based parser with partial parsing techniques.
Riezler et al (2002) describe a discriminative LFG parsing model that is trained on standard (syntax only) tree bank annotations by treating each tree as a full LFG analysis with an observed c-structure and hidden f-structure. $$$$$ As a first step, all sections were parsed, and the packed parse forests unpacked and stored.

For sentences out of coverage, it employs the robustness techniques (fragment parsing, 'skimming') implemented in XLE and described in Riezler et al. (2002), so that 100% of our corpus sentences receive at least some sort of analysis. $$$$$ These often arise when a given constituent fills a grammatical role in more than one clause.
For sentences out of coverage, it employs the robustness techniques (fragment parsing, 'skimming') implemented in XLE and described in Riezler et al. (2002), so that 100% of our corpus sentences receive at least some sort of analysis. $$$$$ To our knowledge, so far the only direct point of comparison is the parser of Carroll et al. (1999) which is also evaluated on Carroll et al.’s test corpus.
For sentences out of coverage, it employs the robustness techniques (fragment parsing, 'skimming') implemented in XLE and described in Riezler et al. (2002), so that 100% of our corpus sentences receive at least some sort of analysis. $$$$$ Two different sets of test data were used: (i) 700 sentences randomly extracted from section 23 of the WSJ treebank and given gold-standard f-structure annotations according to our LFG scheme, and (ii) 500 sentences from the Brown corpus given gold standard annotations by Carroll et al. (1999) according to their dependency relations (DR) scheme.3 Annotating the WSJ test set was bootstrapped by parsing the test sentences using the LFG grammar and also checking for consistency with the Penn Treebank annotation.
For sentences out of coverage, it employs the robustness techniques (fragment parsing, 'skimming') implemented in XLE and described in Riezler et al. (2002), so that 100% of our corpus sentences receive at least some sort of analysis. $$$$$ In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more complex LFG parses.

Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in Riezler et al (2002). $$$$$ Performance on the DR-annotated Brown test set was only measured using the DR metric.
Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in Riezler et al (2002). $$$$$ This grammar parses the sentence as well-formed chunks specified by the grammar, in particular as Ss, NPs, PPs, and VPs.
Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in Riezler et al (2002). $$$$$ Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations.

For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ The model combines full and partial parsing techniques to reach full grammar coverage on unseen data.
For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ This grammar parses the sentence as well-formed chunks specified by the grammar, in particular as Ss, NPs, PPs, and VPs.
For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ Under this measure, our system achieves 76.1% F-score.
For our experiments, we used a stochastic parsing system for LFG that we trained on section 02-21 of the UPenn Wall Street Journal treebank (Marcus et al., 1993) by discriminative estimation of a conditional maximum-entropy model from partially labeled data (see Riezler et al. (2002)). $$$$$ The treebank annotations are used to provide partially labeled data for discriminative statistical estimation using exponential models.

We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ For a direct comparison of our results with Carroll et al.’s system, we computed an F-score that does not distinguish different types of dependency relations.
We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ However, it has been shown experimentally that conjugate gradient techniques can outperform iterative scaling techniques by far in running time (Minka, 2001). which received at most 1,000 parses were used.
We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ The main verb lexicon contains 9,652 verb stems and 23,525 subcategorization frame-verb stem entries; there are also lexicons for adjectives and nouns with subcategorization frames and for closed class items.
We follow Collins' (2000) approach to discriminative reranking (see also (Riezler et al., 2002)). $$$$$ F-structures encode predicate-argument relations and other grammatical information, e.g., number, tense.

This was done to some extent in Riezler et al (2002) to automatically generate training data for the log-linear disambiguation component of XLE. $$$$$ Due to the lack of standard evaluation measures and gold standards for predicate-argument matching, a comparison of our results to other stochastic parsing systems is difficult.
This was done to some extent in Riezler et al (2002) to automatically generate training data for the log-linear disambiguation component of XLE. $$$$$ They report an F-score of 75.1% for a DO evaluation that ignores predicate labels, counting only dependencies.
This was done to some extent in Riezler et al (2002) to automatically generate training data for the log-linear disambiguation component of XLE. $$$$$ Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets.
This was done to some extent in Riezler et al (2002) to automatically generate training data for the log-linear disambiguation component of XLE. $$$$$ A discussion of results is in section 5.

XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al, 2002) that works on the packed representations. $$$$$ Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al, 2002) that works on the packed representations. $$$$$ They report an F-score of 75.1% for a DO evaluation that ignores predicate labels, counting only dependencies.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al, 2002) that works on the packed representations. $$$$$ The treebank annotations are used to provide partially labeled data for discriminative statistical estimation using exponential models.

XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear (a.k.a. maximum-entropy) probability model (Riezler et al, 2002). $$$$$ In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more complex LFG parses.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear (a.k.a. maximum-entropy) probability model (Riezler et al, 2002). $$$$$ More complex property functions are designed to indicate, for example, the branching behaviour of c-structures and the (non)parallelism of coordinations on both c-structure and f-structure levels.
XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear (a.k.a. maximum-entropy) probability model (Riezler et al, 2002). $$$$$ Full grammar coverage is achieved by combining specialized constraint-based parsing techniques for LFG grammars with partial parsing techniques.

For a more detailed description of the optimization problem and the feature-functions we use for stochastic LFG parsing see Riezler et al (2002). $$$$$ The grammar has 314 rules with regular expression right-hand sides which compile into a collection of finite-state machines with a total of 8,759 states and 19,695 arcs.
For a more detailed description of the optimization problem and the feature-functions we use for stochastic LFG parsing see Riezler et al (2002). $$$$$ Section 2 describes the Lexical-Functional Grammar, the constraint-based parser, and the robustness techniques employed in this work.
For a more detailed description of the optimization problem and the feature-functions we use for stochastic LFG parsing see Riezler et al (2002). $$$$$ Their approach differs from the one we use here in that Pereira and Schabes take an EM-based approach maximizing the joint likelihood of the parses and strings of their training data, while we maximize the conditional likelihood of the sets of parses given the corresponding strings in a discriminative estimation setting. rameters which make the two expectations in the last equation equal, i.e. which adjust the model parameters to put all the weight on the parses consistent with the annotations, modulo a penalty term from the Gaussian prior for too large or too small weights.

We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ We define discriminative or conditional criteria with respect to the set of grammar parses consistent with the treebank annotations.
We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ These successive selection steps resulted in a final training set consisting of 10,000 sentences, each with parses for partially labeled and unlabeled versions.
We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ This paper is organized as follows.
We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (Riezler et al, 2002), as well as an architecture for distributed data mining within this corpus, called Oceanography (Waterman, 2009). $$$$$ The predicateargument relations of the f-structure for one parse of the sentence Meridian will pay a premium of $30.5 million to assume $2 billion in deposits. are shown in Fig.

The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation: the probabilistic Shalmaneser system for frame and role annotation (Erk and Pado, 2006), and the rule-based Detour system for frame assignment (Burchardt et al, 2005. $$$$$ We have presented a first attempt at scaling up a stochastic parsing system combining a hand-coded linguistically fine-grained grammar and a stochastic disambiguation model to the WSJ treebank.
The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation: the probabilistic Shalmaneser system for frame and role annotation (Erk and Pado, 2006), and the rule-based Detour system for frame assignment (Burchardt et al, 2005. $$$$$ Firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grained statistical parsing systems.
The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation: the probabilistic Shalmaneser system for frame and role annotation (Erk and Pado, 2006), and the rule-based Detour system for frame assignment (Burchardt et al, 2005. $$$$$ These successive selection steps resulted in a final training set consisting of 10,000 sentences, each with parses for partially labeled and unlabeled versions.

Following Pereira and Schabes' (1992) success with partial annotations in training a model of (English) constituents generatively, their idea has been extended to discriminative estimation (Riezler et al., 2002) and also proved useful in modeling (Japanese) dependencies (Sassano, 2005). $$$$$ In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more complex LFG parses.
Following Pereira and Schabes' (1992) success with partial annotations in training a model of (English) constituents generatively, their idea has been extended to discriminative estimation (Riezler et al., 2002) and also proved useful in modeling (Japanese) dependencies (Sassano, 2005). $$$$$ One difference between the annotation schemes is that the LFG representation in general specifies more relation tuples than the DR representation.
Following Pereira and Schabes' (1992) success with partial annotations in training a model of (English) constituents generatively, their idea has been extended to discriminative estimation (Riezler et al., 2002) and also proved useful in modeling (Japanese) dependencies (Sassano, 2005). $$$$$ Furthermore, properties refering to lexical elements based on an auxiliary distribution approach as presented in Riezler et al. (2000) are included in the model.
