This extension will require using a more selective alignment technique (similar to that of (Hatzivassiloglou et al., 1999)). $$$$$ Every primitive element is associated with a value which is the number of textual units in which the primitive appeared in the corpus.
This extension will require using a more selective alignment technique (similar to that of (Hatzivassiloglou et al., 1999)). $$$$$ We have presented a new method to detect similarity between small textual units, which combines primitive and composite features using machine learning.
This extension will require using a more selective alignment technique (similar to that of (Hatzivassiloglou et al., 1999)). $$$$$ For example, Frawley [1992] discusses all semantic typing in terms of two mechanisms: the detection of similarity and difference.
This extension will require using a more selective alignment technique (similar to that of (Hatzivassiloglou et al., 1999)). $$$$$ On the other hand, unit (c) in Figure 1 is not similar to either (a) or (b).

Another approach (Hatzivassiloglou et al,1999) has been to use a machine learning algorithm in which features are based on combinations of simple features (e.g., a pair of nouns appear within 5 words from one another in both texts). $$$$$ Although there is related empirical research on determining text similarity, primarily in the information retrieval community, there are two major differences between the goals of this earlier work and the problem we address in this (a) An OH-58 helicopter, carrying a crew of two, was on a routine training orientation when contact was lost at about 11:30 a.m. Saturday (9:30 p.m. EST Friday). paper.
Another approach (Hatzivassiloglou et al,1999) has been to use a machine learning algorithm in which features are based on combinations of simple features (e.g., a pair of nouns appear within 5 words from one another in both texts). $$$$$ Future work includes testing on textual units of different size, comparing with additional techniques proposed for document similarity in the information retrieval and computational linguistics literature, and extending the feature set to incorporate other types of linguistic information in the statistical learning method.
Another approach (Hatzivassiloglou et al,1999) has been to use a machine learning algorithm in which features are based on combinations of simple features (e.g., a pair of nouns appear within 5 words from one another in both texts). $$$$$ Hence, there is a balance between the discriminatory power of these features and their applicability to a large number of cases.
Another approach (Hatzivassiloglou et al,1999) has been to use a machine learning algorithm in which features are based on combinations of simple features (e.g., a pair of nouns appear within 5 words from one another in both texts). $$$$$ In addition to the above primitive features that compare single items from each text unit, we use composite features which combine pairs of primitive features.

We use SimFinder (Hatzivassiloglou et al, 1999) for sentence clustering and the f-measure for word overlap to compare noun phrases. $$$$$ The distance between vectors for one text (usually a query) and another (usually a document) then determines closeness or similarity [van Rijsbergen 1979].
We use SimFinder (Hatzivassiloglou et al, 1999) for sentence clustering and the f-measure for word overlap to compare noun phrases. $$$$$ Although all three refer to a helicopter, the primary focus in (c) is on the emergency landing rather than the loss of contact.
We use SimFinder (Hatzivassiloglou et al, 1999) for sentence clustering and the f-measure for word overlap to compare noun phrases. $$$$$ Hence, there is a balance between the discriminatory power of these features and their applicability to a large number of cases.
We use SimFinder (Hatzivassiloglou et al, 1999) for sentence clustering and the f-measure for word overlap to compare noun phrases. $$$$$ In both cases, we have less data to compare, and thus have to explore additional or more informative indicators of similarity.

We use SimFinder (Hatzivassiloglou et al, 1999) for sentence clustering and its similarity metric to evaluate cluster quality; SimFinder outputs similarity values (simvals) between 0 and 1 for pairs of sentences, based on word overlap, synonymy andn-gram matches. $$$$$ For example, Frawley [1992] discusses all semantic typing in terms of two mechanisms: the detection of similarity and difference.
We use SimFinder (Hatzivassiloglou et al, 1999) for sentence clustering and its similarity metric to evaluate cluster quality; SimFinder outputs similarity values (simvals) between 0 and 1 for pairs of sentences, based on word overlap, synonymy andn-gram matches. $$$$$ We are grateful to Regina Barzilay, Hongyan Jing, Kathy McKeown, Shimei Pan, and Yoram Singer for numerous discussions of earlier versions of this paper and for their help with setting up and running RIPPER and SMART.
We use SimFinder (Hatzivassiloglou et al, 1999) for sentence clustering and its similarity metric to evaluate cluster quality; SimFinder outputs similarity values (simvals) between 0 and 1 for pairs of sentences, based on word overlap, synonymy andn-gram matches. $$$$$ Third, we use as a baseline method the default selection of the most frequent category, i.e., &quot;not similar&quot;.

We then cluster the simplified sentences withSimFinder (Hatzivassiloglou et al, 1999). $$$$$ In this task, judges were given the opportunity to provide reasons for claiming similarity or dissimilarity, and comments on the task were logged for future analysis.
We then cluster the simplified sentences withSimFinder (Hatzivassiloglou et al, 1999). $$$$$ This type of normalization also uses equation (2) but averages the normalization values of each primitive in the composite feature.
We then cluster the simplified sentences withSimFinder (Hatzivassiloglou et al, 1999). $$$$$ Future work includes testing on textual units of different size, comparing with additional techniques proposed for document similarity in the information retrieval and computational linguistics literature, and extending the feature set to incorporate other types of linguistic information in the statistical learning method.
We then cluster the simplified sentences withSimFinder (Hatzivassiloglou et al, 1999). $$$$$ Primitive features are named according to the type of the feature (e.g., Verb for the feature that counts the number of matching verbs according to exact matches).

At the level of short passages or sentences, (Hatzivassiloglou et al, 1999) goes beyond N-gram, taking advantage of WordNet synonyms, as well as ordering and distance between shared words. $$$$$ Our results indicate that our method outperforms the standard techniques for detecting similarity, and the system has been successfully integrated into a larger multipledocument summarization system [McKeown et al. 1999].
At the level of short passages or sentences, (Hatzivassiloglou et al, 1999) goes beyond N-gram, taking advantage of WordNet synonyms, as well as ordering and distance between shared words. $$$$$ This is motivated by the fact that infrequently matching primitive elements are likely to have a higher impact on similarity than primitives which match more frequently.
At the level of short passages or sentences, (Hatzivassiloglou et al, 1999) goes beyond N-gram, taking advantage of WordNet synonyms, as well as ordering and distance between shared words. $$$$$ First, the notion of similarity as defined in the previous section is more restrictive than the traditional definition of similarity [Anderberg 1973; Willet 1988].
At the level of short passages or sentences, (Hatzivassiloglou et al, 1999) goes beyond N-gram, taking advantage of WordNet synonyms, as well as ordering and distance between shared words. $$$$$ We discuss an experimental validation of our similarity definition in Section 5.2, after we introduce the corpus we use in our experiments.

For instance, Hatzivassiloglou et al (1999) trained a classifier for paraphrase detection, though their performance only reached roughly 37% recall and 61% precision. $$$$$ This type of normalization also uses equation (2) but averages the normalization values of each primitive in the composite feature.
For instance, Hatzivassiloglou et al (1999) trained a classifier for paraphrase detection, though their performance only reached roughly 37% recall and 61% precision. $$$$$ Future work includes testing on textual units of different size, comparing with additional techniques proposed for document similarity in the information retrieval and computational linguistics literature, and extending the feature set to incorporate other types of linguistic information in the statistical learning method.
For instance, Hatzivassiloglou et al (1999) trained a classifier for paraphrase detection, though their performance only reached roughly 37% recall and 61% precision. $$$$$ As comparisons are made between all pairs of paragraphs from the same topic, the total number of comparisons is equal to 2 the number of paragraphs in all selected articles from topical category i.
For instance, Hatzivassiloglou et al (1999) trained a classifier for paraphrase detection, though their performance only reached roughly 37% recall and 61% precision. $$$$$ Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the National Science Foundation.

In the context of multi document summarization, SimFinder (Hatzivassiloglou et al, 1999) identifies sentences that convey similar information across in put documents to select the summary content. $$$$$ Figure 5: Precision-recall graph comparing our using line with squares) versus TF*IDF (dotted line with triangles). not reflect our task.
In the context of multi document summarization, SimFinder (Hatzivassiloglou et al, 1999) identifies sentences that convey similar information across in put documents to select the summary content. $$$$$ Table 2 presents a selected subset of primitive and composite features in order to demonstrate our results.
In the context of multi document summarization, SimFinder (Hatzivassiloglou et al, 1999) identifies sentences that convey similar information across in put documents to select the summary content. $$$$$ Similarity is a complex concept which has been widely discussed in the linguistic, philosophical, and information theory communities.

An obvious choice for a baseline in this task is the following $$$$$ Matching noun phrases. the LINKIT tool [Wacholder 1998] to identify simplex noun phrases and match those that share the same head.
An obvious choice for a baseline in this task is the following $$$$$ This research has been supported in part by an NSF STIMULATE grant, IRI-96-1879.
An obvious choice for a baseline in this task is the following $$$$$ This type of normalization also uses equation (2) but averages the normalization values of each primitive in the composite feature.

To this end, we intend to implement a second-pass analysis that would rerank the candidates produced by fuzzy inverted generation by computing text similarities over short passages such as those propose din (Hatzivassiloglou et al, 1999). $$$$$ We address concerns of sparse data and the narrower than topical definition of similarity by exploring several linguistic features, in addition to shared words or collocations, as indicators of text similarity.
To this end, we intend to implement a second-pass analysis that would rerank the candidates produced by fuzzy inverted generation by computing text similarities over short passages such as those propose din (Hatzivassiloglou et al, 1999). $$$$$ Although there is related empirical research on determining text similarity, primarily in the information retrieval community, there are two major differences between the goals of this earlier work and the problem we address in this (a) An OH-58 helicopter, carrying a crew of two, was on a routine training orientation when contact was lost at about 11:30 a.m. Saturday (9:30 p.m. EST Friday). paper.
To this end, we intend to implement a second-pass analysis that would rerank the candidates produced by fuzzy inverted generation by computing text similarities over short passages such as those propose din (Hatzivassiloglou et al, 1999). $$$$$ This research has been supported in part by an NSF STIMULATE grant, IRI-96-1879.
To this end, we intend to implement a second-pass analysis that would rerank the candidates produced by fuzzy inverted generation by computing text similarities over short passages such as those propose din (Hatzivassiloglou et al, 1999). $$$$$ Nevertheless, we can account for the high probability of inter-reviewer agreement expected by chance, 0.97.0.97+ (1 —0.97)- (1-0.97) --- 0.9418, by referring to the kappa statistic [Cohen 1960; Carletta 1996].

Hatzivassiloglou et al (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation of sentences. $$$$$ We have presented a new method to detect similarity between small textual units, which combines primitive and composite features using machine learning.
Hatzivassiloglou et al (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation of sentences. $$$$$ We validated our similarity definition using human judges, applied our method to a substantial number of paragraph pairs from news articles, and compared results to baseline and standard information retrieval techniques.
Hatzivassiloglou et al (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation of sentences. $$$$$ For evaluation, we use a set of articles already classified into topical subsets which we obtained from the Reuters part of the 1997 pilot Topic Detection and Tracking (TDT) corpus.
Hatzivassiloglou et al (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation of sentences. $$$$$ But since our definition of similarity is oriented to the small-segment goal, we make more fine-grained distinctions.
