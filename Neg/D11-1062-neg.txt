In our first experiment we used the English-German portion of the CLTE corpus described in (Negri et al., 2011), consisting of 500 multi-directional entailment pairs which we equally divided into training and test sets. $$$$$ As described in Section 4.1, the resulting monolingual English TE corpus (ENG/ENG1) is used to create the following mono/cross-lingual TE corpora:
In our first experiment we used the English-German portion of the CLTE corpus described in (Negri et al., 2011), consisting of 500 multi-directional entailment pairs which we equally divided into training and test sets. $$$$$ The issues related to the shortage of datasets and the high costs for their creation are more evident in the CLTE scenario, where: i) the only dataset currently available is an English-Spanish corpus obtained by translating the RTE-3 corpus (Negri and Mehdad, 2010), and ii) the application of the standard methods adopted to build RTE pairs requires proficiency in multiple languages, thus significantly increasing the costs of the data creation process.
In our first experiment we used the English-German portion of the CLTE corpus described in (Negri et al., 2011), consisting of 500 multi-directional entailment pairs which we equally divided into training and test sets. $$$$$ In line with recent works emphasizing the need of large-scale annotation efforts for textual entailment, our work aims to: the scarcity of data available to train evaluate systems, and the recourse to crowdsourcing as an effective way to reduce the costs of data collection without sacrificing quality.
In our first experiment we used the English-German portion of the CLTE corpus described in (Negri et al., 2011), consisting of 500 multi-directional entailment pairs which we equally divided into training and test sets. $$$$$ Cross-lingual Textual Entailment (CLTE) has been recently proposed by (Mehdad et al., 2010; Mehdad et al., 2011) as an extension of Textual Entailment (Dagan and Glickman, 2004).

The corpora used in the experiments comes from a cross-lingual Textual Entailment dataset presented in (Negri et al, 2011), and provided by the task organizers. $$$$$ In the latter case, Turkers are faced with creative tasks consisting in the production of textual material (e.g. writing a correct translation, or a summary of a given text).
The corpora used in the experiments comes from a cross-lingual Textual Entailment dataset presented in (Negri et al, 2011), and provided by the task organizers. $$$$$ The issues related to the shortage of datasets and the high costs for their creation are more evident in the CLTE scenario, where: i) the only dataset currently available is an English-Spanish corpus obtained by translating the RTE-3 corpus (Negri and Mehdad, 2010), and ii) the application of the standard methods adopted to build RTE pairs requires proficiency in multiple languages, thus significantly increasing the costs of the data creation process.
The corpora used in the experiments comes from a cross-lingual Textual Entailment dataset presented in (Negri et al, 2011), and provided by the task organizers. $$$$$ As a contribution beyond the few works on TE/CLTE data acquisition, we define an effective methodology that: i) does not involve experts in the most complex (and costly) stages of the process, ii) does not require preprocessing tools, and iii) does not rely on the availability of already annotated RTE corpora. to non-experts, difficult to accomplish, and not suitable for the application of the quality-check mechanisms provided by current crowdsourcing services.
The corpora used in the experiments comes from a cross-lingual Textual Entailment dataset presented in (Negri et al, 2011), and provided by the task organizers. $$$$$ For annotation jobs, quality control mechanisms can be easily set up by calculating Turkers’ agreement, by applying voting schemes, or by adding hidden gold units to the data to be annotated8.

Defining "entailment" is quite difficult when dealing with expert annotators and still more with non-experts, as was noted by Negri et al. (2011). $$$$$ The task consists of deciding, given a text (T) and an hypothesis (H) in different languages, if the meaning of H can be inferred from the meaning of T. As in other NLP applications, both for monolingual and cross-lingual TE,
Defining "entailment" is quite difficult when dealing with expert annotators and still more with non-experts, as was noted by Negri et al. (2011). $$$$$ L2/L2, L2/L3).
Defining "entailment" is quite difficult when dealing with expert annotators and still more with non-experts, as was noted by Negri et al. (2011). $$$$$ Our primary goal was the creation of large-scale collections of entailment pairs for different language combinations.
Defining "entailment" is quite difficult when dealing with expert annotators and still more with non-experts, as was noted by Negri et al. (2011). $$$$$ As regards the first stage, in this work we started from a set of 467 English/Italian/German aligned sentences extracted from parallel documents downloaded from the Cafebabel European Magazine11.

Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al, 2011) and a corpus freely available for CLTE is published (Castillo, 2011). $$$$$ The authors would like to thank Emanuele Pianta for the helpful discussions, and Giovanni Moretti for the valuable support in the creation of the CLTE dataset.
Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al, 2011) and a corpus freely available for CLTE is published (Castillo, 2011). $$$$$ Finally, as a by-product of our method, the acquired pairs are fully aligned for all language combinations, thus enabling meaningful comparisons between scenarios of different complexity (monolingual TE, and CLTE between close or distant languages).
Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al, 2011) and a corpus freely available for CLTE is published (Castillo, 2011). $$$$$ These HITs are combined in an iterative process that alternates text generation, grammaticality check, and entailment annotation steps.
Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al, 2011) and a corpus freely available for CLTE is published (Castillo, 2011). $$$$$ The task consists of deciding, given a text (T) and an hypothesis (H) in different languages, if the meaning of H can be inferred from the meaning of T. As in other NLP applications, both for monolingual and cross-lingual TE,

The dataset provided by the organizers consists of 500 CLTE pairs translated to four languages following the crowdsourcing-based methodology proposed in (Negri et al., 2011). $$$$$ The result of our work is the first large-scale dataset containing both monolingual and cross-lingual corpora for several combinations of texts-hypotheses in English, Italian, and German.
The dataset provided by the organizers consists of 500 CLTE pairs translated to four languages following the crowdsourcing-based methodology proposed in (Negri et al., 2011). $$$$$ There is an increasing need of annotated data to develop new solutions to the Textual Entailment problem, explore new entailment-related tasks, and set up experimental frameworks targeting real-world applications.
The dataset provided by the organizers consists of 500 CLTE pairs translated to four languages following the crowdsourcing-based methodology proposed in (Negri et al., 2011). $$$$$ Besides the achievement of our primary objectives, the adopted approach led to some interesting by-products.
The dataset provided by the organizers consists of 500 CLTE pairs translated to four languages following the crowdsourcing-based methodology proposed in (Negri et al., 2011). $$$$$ The modified sentences (ENG1) are translated into Italian (ITA1) through (multilingual) generation HITs reproducing the approach described in (Negri and Mehdad, 2010).

The dataset was created following the crowdsourcing methodology proposed in (Negri et al, 2011), which consists of the following steps. $$$$$ Crowdsourcing services, such as Amazon Mechanical Turk6 (MTurk) and CrowdFlower7, have been recently used with success for a variety of NLP applications (Callison-Burch and Dredze, 2010).
The dataset was created following the crowdsourcing methodology proposed in (Negri et al, 2011), which consists of the following steps. $$$$$ We address the creation of cross-lingual textual entailment corpora by means of crowdsourcing.
The dataset was created following the crowdsourcing methodology proposed in (Negri et al, 2011), which consists of the following steps. $$$$$ The few solutions integrating validation HITs address the translation of single sentences, a task that is substantially different from ours (Negri and Mehdad, 2010; Bloodgood and Callison-Burch, 2010).
The dataset was created following the crowdsourcing methodology proposed in (Negri et al, 2011), which consists of the following steps. $$$$$ Our approach presents several key innovations with respect to the related works on TE data acquisition.

Two datasets were provided by the organization of SemEval 2012 (Negri et al, 2011) $$$$$ the availability of large quantities of annotated data is an enabling factor for systems development and evaluation.
Two datasets were provided by the organization of SemEval 2012 (Negri et al, 2011) $$$$$ To address these issues, in this paper we devise a cost-effective methodology to create cross-lingual textual entailment corpora.
Two datasets were provided by the organization of SemEval 2012 (Negri et al, 2011) $$$$$ Related research in the CLTE direction is reported in (Negri and Mehdad, 2010), which describes the creation of an English-Spanish corpus obtained from the RTE-3 dataset by translating the English hypotheses into Spanish.
Two datasets were provided by the organization of SemEval 2012 (Negri et al, 2011) $$$$$ These include the decomposition of a complex content generation task in a pipeline of simpler subtasks accessible to a large crowd of non-experts, and the integration of quality control mechanisms at each stage of the process.

There was one training set for each French-English, German-English, Italian-English, Spanish-English language combination (Negri et al, 2011). $$$$$ However, our annotation is not limited to the standard RTE framework, where only unidirectional entailment from T to H is considered.
There was one training set for each French-English, German-English, Italian-English, Spanish-English language combination (Negri et al, 2011). $$$$$ cide which of two English sentences (the original ENG, and a modified ENG1) provides more information.
There was one training set for each French-English, German-English, Italian-English, Spanish-English language combination (Negri et al, 2011). $$$$$ As expected, we observe lower rejection rates, corresponding to higher inter-annotator agreement, for grammaticality HITs (5.55% on average) than for more complex entailment-related tasks (12.02% on average).
There was one training set for each French-English, German-English, Italian-English, Spanish-English language combination (Negri et al, 2011). $$$$$ There is an increasing need of annotated data to develop new solutions to the Textual Entailment problem, explore new entailment-related tasks, and set up experimental frameworks targeting real-world applications.

The values of the parameters were chosen based on the CLTE development dataset (Negri et al, 2011) and were as follows. $$$$$ For annotation jobs, quality control mechanisms can be easily set up by calculating Turkers’ agreement, by applying voting schemes, or by adding hidden gold units to the data to be annotated8.
The values of the parameters were chosen based on the CLTE development dataset (Negri et al, 2011) and were as follows. $$$$$ To tackle these issues the “divide and conquer” approach described in the next section consists in the decomposition of a difficult content generation job into easier subtasks that are: i) self-contained and easy to explain, ii) easy to execute without any NLP expertise, and iii) suitable for the integration of a variety of runtime control mechanisms (regional qualifications, gold units, “validation HITs”) able to ensure a good quality of the collected material.
The values of the parameters were chosen based on the CLTE development dataset (Negri et al, 2011) and were as follows. $$$$$ As regards the amount of data collected, the resulting corpus contains 1,620 pairs with the following distribution of entailment relations: i) 449 bidirectional entailments, ii) 491 ENG→ENG1 unidirectional entailments, and iii) 680 ENG←ENG1 unidirectional entailments.
The values of the parameters were chosen based on the CLTE development dataset (Negri et al, 2011) and were as follows. $$$$$ In line with recent works emphasizing the need of large-scale annotation efforts for textual entailment, our work aims to: the scarcity of data available to train evaluate systems, and the recourse to crowdsourcing as an effective way to reduce the costs of data collection without sacrificing quality.
