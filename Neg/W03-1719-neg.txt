For details on the word segmentation bakeoff, see (Sproat and Emerson, 2003). $$$$$ Similarly the topline performance is only less than 1.0 in cases where there are two or more possible decompositions of a string, and where the option with the longest prefix is not the correct one.
For details on the word segmentation bakeoff, see (Sproat and Emerson, 2003). $$$$$ We give the motivation for having an international segmentation contest (given that there have been two within-China contests to date) and we report on the results of this first international contest, analyze these results, and make some recommendations for the future.
For details on the word segmentation bakeoff, see (Sproat and Emerson, 2003). $$$$$ Links to descriptions of the corpora can be found at http://www.sighan.org/bakeoff2003/ bakeoff_instr.html; publications on specific corpora are (Huang et al., 1997) (Academia Sinica), (Xia, 1999) (Chinese Treebank); the Beijing University standard is very similar to that outlined in (GB/T 13715–92, 1993).

We refer readers to (Sproat and Emerson, 2003) for details on the evaluation measures. $$$$$ Without the generous contribution of these resources, this competition would not have been possible.
We refer readers to (Sproat and Emerson, 2003) for details on the evaluation measures. $$$$$ An unfortunate, and sometimes unforseen, complexity in dealing with Chinese text on the computer is the plethora of character sets and character encodings used throughout Greater China.
We refer readers to (Sproat and Emerson, 2003) for details on the evaluation measures. $$$$$ We believe that there should be future competitions of this kind, possibly not every year, but certainly every couple of years and we have some specific recommendations on how things might be improved in such future competitions: to the restriction that participants may not be evaluated on data from their own institution.
We refer readers to (Sproat and Emerson, 2003) for details on the evaluation measures. $$$$$ Andi Wu and Aitao Chen provided useful feedback on errors in some of the corpora.

We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm. $$$$$ We give the motivation for having an international segmentation contest (given that there have been two within-China contests to date) and we report on the results of this first international contest, analyze these results, and make some recommendations for the future.
We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm. $$$$$ This is problematic in systems that utilize Unicode internally, since transcoding back to the original encoding may lose information.
We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm. $$$$$ We then used this dictionary with a simple maximum matching algorithm to segment the test corpus.

After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson,2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as? Achilles? that consists of four modules mainly $$$$$ Finally note that the top performance of any system on any track was S09 on ASc (F=0.961).
After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson,2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as? Achilles? that consists of four modules mainly $$$$$ The contest followed a strict set of guidelines and a rigid timetable.
After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson,2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as? Achilles? that consists of four modules mainly $$$$$ This is problematic in systems that utilize Unicode internally, since transcoding back to the original encoding may lose information.
After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson,2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as? Achilles? that consists of four modules mainly $$$$$ The Chinese Treebank Project, University of Pennsylvania, and the Linguistic Data Consortium.

In the last SIGHAN bakeoff, there is no single system consistently outperforms the others on different test standards of Chinese WS and NER standards (Sproat and Emerson, 2003). $$$$$ This is not only because of differences in segmentation standards but also due to differences in the design of systems: Systems based exclusively (or even primarily) on lexical and grammatical analysis will often be at a disadvantage during the comparison compared to systems trained exclusively on the training data.
In the last SIGHAN bakeoff, there is no single system consistently outperforms the others on different test standards of Chinese WS and NER standards (Sproat and Emerson, 2003). $$$$$ Accuracies in the mid 80’s to mid 90’s were reported for the four systems that participated in the first evaluation, with higher scores (many in the high nineties) being reported for the second evaluation.
In the last SIGHAN bakeoff, there is no single system consistently outperforms the others on different test standards of Chinese WS and NER standards (Sproat and Emerson, 2003). $$$$$ We give the motivation for having an international segmentation contest (given that there have been two within-China contests to date) and we report on the results of this first international contest, analyze these results, and make some recommendations for the future.
In the last SIGHAN bakeoff, there is no single system consistently outperforms the others on different test standards of Chinese WS and NER standards (Sproat and Emerson, 2003). $$$$$ Also, the OOV rate for this corpus is much higher than all of the other corpora, and since error rates are generally higher on OOV, this is surely a contributing factor.

The official scorer program is publicly available and described in (Sproat and Emerson, 2003). $$$$$ The final set of participants in the bakeoff include two from Mainland China, three from Hong Kong, one from Japan, one from Singapore, one from Taiwan and four from the United States.
The official scorer program is publicly available and described in (Sproat and Emerson, 2003). $$$$$ The Chinese Treebank Project, University of Pennsylvania, and the Linguistic Data Consortium.
The official scorer program is publicly available and described in (Sproat and Emerson, 2003). $$$$$ The detailed instructions for the bakeoff can be found at http://www.sighan. org/bakeoff2003/bakeoff_instr.html (with simplified and traditional Chinese versions also available).

Measuring homogeneity by counting word/ lexeme frequencies introduces additional difficulties as it assumes that the word is an obvious, well-defined unit, which is not the case in the Chinese (Sproat and Emerson 2003) or Japanese language (Matsumoto et al, 2002), for instance, where word segmentation is not trivial. $$$$$ For the closed-track entries that did well on OOV, one must conclude that they have effective unknown-word detection methods.
Measuring homogeneity by counting word/ lexeme frequencies introduces additional difficulties as it assumes that the word is an obvious, well-defined unit, which is not the case in the Chinese (Sproat and Emerson 2003) or Japanese language (Matsumoto et al, 2002), for instance, where word segmentation is not trivial. $$$$$ The suffixes “o” and “c” will be used to denote open and closed tracks, respectively: Thus “ASo,c” denotes the Academia Sinica corpus, both open and closed tracks; and “PKc” denotes the Beijing University corpus, closed track.
Measuring homogeneity by counting word/ lexeme frequencies introduces additional difficulties as it assumes that the word is an obvious, well-defined unit, which is not the case in the Chinese (Sproat and Emerson 2003) or Japanese language (Matsumoto et al, 2002), for instance, where word segmentation is not trivial. $$$$$ 4.
Measuring homogeneity by counting word/ lexeme frequencies introduces additional difficulties as it assumes that the word is an obvious, well-defined unit, which is not the case in the Chinese (Sproat and Emerson 2003) or Japanese language (Matsumoto et al, 2002), for instance, where word segmentation is not trivial. $$$$$ Participating sites are shown in Table 2.

The out-of-vocabulary (OOV) is defined as tokens in the test set that are not in the training set (Sproat and Emerson, 2003). $$$$$ The values for are given in Tables 5–12, under the heading “c ”.
The out-of-vocabulary (OOV) is defined as tokens in the test set that are not in the training set (Sproat and Emerson, 2003). $$$$$ The Chinese Treebank Project, University of Pennsylvania, and the Linguistic Data Consortium.
The out-of-vocabulary (OOV) is defined as tokens in the test set that are not in the training set (Sproat and Emerson, 2003). $$$$$ It has also been observed that different segmentation standards are appropriate for different purposes; that the segmentation standard that one might prefer for information retrieval applications is likely to be different from the one that one would prefer for text-to-speech synthesis; see (Wu, 2003) for useful discussion.

Following (Sproat and Emerson, 2003), we also measured the recall onOOV (ROOV) tokens and in-vocabulary (RIV) tokens. $$$$$ Finally, one question that we did not ask that should have been asked was whether the tested system is used as part of a commercial product or not.
Following (Sproat and Emerson, 2003), we also measured the recall onOOV (ROOV) tokens and in-vocabulary (RIV) tokens. $$$$$ This is problematic in systems that utilize Unicode internally, since transcoding back to the original encoding may lose information.
Following (Sproat and Emerson, 2003), we also measured the recall onOOV (ROOV) tokens and in-vocabulary (RIV) tokens. $$$$$ Per normal usage, OOV is defined as the set of words in the test corpus not occurring in the training corpus.2 We expect systems to do at least as well as this baseline.
Following (Sproat and Emerson, 2003), we also measured the recall onOOV (ROOV) tokens and in-vocabulary (RIV) tokens. $$$$$ Participating sites are shown in Table 2.

In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003). $$$$$ Similarly ((corporate) vice president) is segmented as one word in training data but as two words ( / ) in the testing data.
In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003). $$$$$ Another issue that is not accounted for in the current collection of evaluations is the handling of short strings with minimal context, such as queries submitted to a search engine.
In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003). $$$$$ They can be interpreted as follows: To decide whether two sites are significantly different (at the 95% confidence level) in their performance on a particular task, one just has to compute whether their confidence intervals overlap.
In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003). $$$$$ We then used this dictionary with a simple maximum matching algorithm to segment the test corpus.

A recent Chinese word segmentation competition (Sproat and Emerson, 2003) has made comparisons easier. $$$$$ The Chinese Treebank Project, University of Pennsylvania, and the Linguistic Data Consortium.
A recent Chinese word segmentation competition (Sproat and Emerson, 2003) has made comparisons easier. $$$$$ We computed a baseline for each of the corpora by compiling a dictionary of all and only the words in the training portion of the corpus.
A recent Chinese word segmentation competition (Sproat and Emerson, 2003) has made comparisons easier. $$$$$ Andi Wu and Aitao Chen provided useful feedback on errors in some of the corpora.
A recent Chinese word segmentation competition (Sproat and Emerson, 2003) has made comparisons easier. $$$$$ This is problematic in systems that utilize Unicode internally, since transcoding back to the original encoding may lose information.

 $$$$$ Scoring was completely automatic.
 $$$$$ We believe that there should be future competitions of this kind, possibly not every year, but certainly every couple of years and we have some specific recommendations on how things might be improved in such future competitions: to the restriction that participants may not be evaluated on data from their own institution.
 $$$$$ See (Yao, 2001; Yao, 2002) for the first and second of these; the third evaluation will be held in August 2003.
 $$$$$ This paper presents the results from the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff held in 2003 and reported in conjunction with the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.

This is due to significant inconsistent segmentation in training and testing (Sproat and Emerson, 2003). $$$$$ We would like to expand the testing data to include texts of various lengths, particularly short strings, in order to emulate query strings seen in commercial search engines.
This is due to significant inconsistent segmentation in training and testing (Sproat and Emerson, 2003). $$$$$ In some cases, more training data will also be needed.
This is due to significant inconsistent segmentation in training and testing (Sproat and Emerson, 2003). $$$$$ During the course of this bakeoff, a number of inconsistencies in segmentation were noted in the CTB corpus by one of the participants.

No other material was allowed (Sproat and Emerson, 2003). $$$$$ What all of this suggests is that the CTB may simply be less consistent than the other corpora in its segmentation; indeed one of the participants (Andi Wu) noted a number of inconsistencies in both the training and the test data (though inconsistencies were also noted for the AS corpus).4 Systems that ran on both closed and open tracks for the same corpus generally did better on the open track, indicating (not surprisingly) that using additional data can help.
No other material was allowed (Sproat and Emerson, 2003). $$$$$ The final set of participants in the bakeoff include two from Mainland China, three from Hong Kong, one from Japan, one from Singapore, one from Taiwan and four from the United States.
No other material was allowed (Sproat and Emerson, 2003). $$$$$ 4.
No other material was allowed (Sproat and Emerson, 2003). $$$$$ The test corpora were segmented according to the Chinese national standard GB 13715 (GB/T 13715–92, 1993), though some lenience was granted in the case of plausible alternative segmentations (Yao, 2001); so while GB 13715 specifies the segmentation / for Mao Zedong, was also allowed.

In order to show the impact to the evaluation result caused by EIs existing in test data of Bakeoff, we conduct the baseline close test with PK and AS corpora, i.e. we compile lexicons only containing words in their training data and then use the lexicons with a forward maximum matching algorithm to segment their test data respectively (Sproat and Emerson, 2003). $$$$$ This is demonstrated in the Encoding column of Table 1: This variation of encoding is exacerbated by the usual lack of specific declaration in the files.
In order to show the impact to the evaluation result caused by EIs existing in test data of Bakeoff, we conduct the baseline close test with PK and AS corpora, i.e. we compile lexicons only containing words in their training data and then use the lexicons with a forward maximum matching algorithm to segment their test data respectively (Sproat and Emerson, 2003). $$$$$ This paper presents the results from the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff held in 2003 and reported in conjunction with the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.
In order to show the impact to the evaluation result caused by EIs existing in test data of Bakeoff, we conduct the baseline close test with PK and AS corpora, i.e. we compile lexicons only containing words in their training data and then use the lexicons with a forward maximum matching algorithm to segment their test data respectively (Sproat and Emerson, 2003). $$$$$ Also, the OOV rate for this corpus is much higher than all of the other corpora, and since error rates are generally higher on OOV, this is surely a contributing factor.

For instance, 'vice president' is considered to be one word in the Penn Chinese Treebank (Xue et al, 2005), but is split into two words by the Peking University corpus in the SIGHAN Bakeoffs (Sproat and Emerson, 2003). $$$$$ The problem with this literature has always been that it is very hard to compare systems, due to the lack of any common standard test set.
For instance, 'vice president' is considered to be one word in the Penn Chinese Treebank (Xue et al, 2005), but is split into two words by the Peking University corpus in the SIGHAN Bakeoffs (Sproat and Emerson, 2003). $$$$$ This paper presents the results from the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff held in 2003 and reported in conjunction with the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.
For instance, 'vice president' is considered to be one word in the Penn Chinese Treebank (Xue et al, 2005), but is split into two words by the Peking University corpus in the SIGHAN Bakeoffs (Sproat and Emerson, 2003). $$$$$ We then used this dictionary with a simple maximum matching algorithm to segment the test corpus.

We use three Chinese word-segmented corpora, the Academia Sinica corpus (AS), the Hong Kong City University corpus (HK) and the Beijing University corpus (PK), all of which were used in the First International Chinese Word Segmentation Bake off (Sproat and Emerson, 2003) at ACL-SIGHAN 2003. $$$$$ Scoring was completely automatic.
We use three Chinese word-segmented corpora, the Academia Sinica corpus (AS), the Hong Kong City University corpus (HK) and the Beijing University corpus (PK), all of which were used in the First International Chinese Word Segmentation Bake off (Sproat and Emerson, 2003) at ACL-SIGHAN 2003. $$$$$ For this meaas one word in the test data.
We use three Chinese word-segmented corpora, the Academia Sinica corpus (AS), the Hong Kong City University corpus (HK) and the Beijing University corpus (PK), all of which were used in the First International Chinese Word Segmentation Bake off (Sproat and Emerson, 2003) at ACL-SIGHAN 2003. $$$$$ They can be interpreted as follows: To decide whether two sites are significantly different (at the 95% confidence level) in their performance on a particular task, one just has to compute whether their confidence intervals overlap.
We use three Chinese word-segmented corpora, the Academia Sinica corpus (AS), the Hong Kong City University corpus (HK) and the Beijing University corpus (PK), all of which were used in the First International Chinese Word Segmentation Bake off (Sproat and Emerson, 2003) at ACL-SIGHAN 2003. $$$$$ In some cases, more training data will also be needed.

The top three systems participated in the SIGHAN Bakeoff (Sproat and Emerson, 2003). $$$$$ They can be interpreted as follows: To decide whether two sites are significantly different (at the 95% confidence level) in their performance on a particular task, one just has to compute whether their confidence intervals overlap.
The top three systems participated in the SIGHAN Bakeoff (Sproat and Emerson, 2003). $$$$$ We give the motivation for having an international segmentation contest (given that there have been two within-China contests to date) and we report on the results of this first international contest, analyze these results, and make some recommendations for the future.
The top three systems participated in the SIGHAN Bakeoff (Sproat and Emerson, 2003). $$$$$ We would also like to thank Martha Palmer for making funds available to pay for translations of the detailed bakeoff instructions, and to Fu-Dong Chiou, Susan Converse and Nianwen Xue for their work on the translations.

In Chinese text processing context, lexicons are particularly important for dictionary-based word segmentation techniques in which out-of-vocabulary words are an important cause of errors (Sproat and Emerson, 2003). $$$$$ The suffixes “o” and “c” will be used to denote open and closed tracks, respectively: Thus “ASo,c” denotes the Academia Sinica corpus, both open and closed tracks; and “PKc” denotes the Beijing University corpus, closed track.
In Chinese text processing context, lexicons are particularly important for dictionary-based word segmentation techniques in which out-of-vocabulary words are an important cause of errors (Sproat and Emerson, 2003). $$$$$ Institute of Computational Linguistics, Beijing University.
In Chinese text processing context, lexicons are particularly important for dictionary-based word segmentation techniques in which out-of-vocabulary words are an important cause of errors (Sproat and Emerson, 2003). $$$$$ This is demonstrated in the Encoding column of Table 1: This variation of encoding is exacerbated by the usual lack of specific declaration in the files.
In Chinese text processing context, lexicons are particularly important for dictionary-based word segmentation techniques in which out-of-vocabulary words are an important cause of errors (Sproat and Emerson, 2003). $$$$$ 4.

 $$$$$ Generally a file is said to be “Big Five” or “GB”, when in actuality the file is encoded in a variation of these.
 $$$$$ One thing we do not do here is get into the details of specific systems; each of the participants was required to provide a four page description of their system along with detailed discussion of their results, and these papers are published in this volume.
 $$$$$ This has been studied indirectly through the cross-language information retrieval work performed for the TREC 5 and TREC 6 competitions (Smeaton and Wilkinson, 1997; Wilkinson, 1998).
 $$$$$ Generally a file is said to be “Big Five” or “GB”, when in actuality the file is encoded in a variation of these.
