Brill and Resnik (1994) applied Error-Driven Transformation Based Learning, Ratnaparkhi, Reynar and Roukos (1994) applied a Maximum Entropy model, Franz (1996) used a Loglinear model, and Collins and Brooks (1995) obtained good results using a BackOff model. $$$$$ When evaluating an algorithm it is useful to have an idea of the lower and upper bounds on its performance.
Brill and Resnik (1994) applied Error-Driven Transformation Based Learning, Ratnaparkhi, Reynar and Roukos (1994) applied a Maximum Entropy model, Franz (1996) used a Loglinear model, and Collins and Brooks (1995) obtained good results using a BackOff model. $$$$$ This paper proposes a new statistical method for PP-attachment disambiguation based on the four head words.
Brill and Resnik (1994) applied Error-Driven Transformation Based Learning, Ratnaparkhi, Reynar and Roukos (1994) applied a Maximum Entropy model, Franz (1996) used a Loglinear model, and Collins and Brooks (1995) obtained good results using a BackOff model. $$$$$ The backed-off method based on just the f(v,p) and Anil, p) counts would be: If P(11v,n1,p)>= 0.5 then choose noun attachment, else choose verb attachment, where f (1, v , f(1,n1,p) fi(liv,n1,P)= f(v,p)+ f(nl,p) An experiment was implemented to investigate the difference in performance between these two methods.

As we have argued in Zavrel and Daelemans (1997), this corresponds exactly to the behavior of the Back-Off algorithm of Collins and Brooks (1995), so that it comes as no surprise that the accuracy of both methods is the same. $$$$$ Recent work has considered corpus-based or statistical approaches to the problem of prepositional attachment ambiguity.
As we have argued in Zavrel and Daelemans (1997), this corresponds exactly to the behavior of the Back-Off algorithm of Collins and Brooks (1995), so that it comes as no surprise that the accuracy of both methods is the same. $$$$$ Both of these methods consider the second noun, n2, as well as v, n1 and p, with the hope that this additional information will improve results.
As we have argued in Zavrel and Daelemans (1997), this corresponds exactly to the behavior of the Back-Off algorithm of Collins and Brooks (1995), so that it comes as no surprise that the accuracy of both methods is the same. $$$$$ For example a simple method for estimation of nl, p, n2) would go from MLE estimates of Ally, n1, p, n2) to nl, p) to j3(1 v, iii) to polo to pm.
As we have argued in Zavrel and Daelemans (1997), this corresponds exactly to the behavior of the Back-Off algorithm of Collins and Brooks (1995), so that it comes as no surprise that the accuracy of both methods is the same. $$$$$ The backed-off estimate scores appreciably better than other methods which have been tested on the Wall Street Journal corpus.

The results of Brill's method on the present benchmark were reconstructed by Collins and Brooks (1995). $$$$$ Results on Wall Street Journal data of 84.5% accuracy are obtained using this method.
The results of Brill's method on the present benchmark were reconstructed by Collins and Brooks (1995). $$$$$ When evaluating an algorithm it is useful to have an idea of the lower and upper bounds on its performance.
The results of Brill's method on the present benchmark were reconstructed by Collins and Brooks (1995). $$$$$ For example a simple method for estimation of nl, p, n2) would go from MLE estimates of Ally, n1, p, n2) to nl, p) to j3(1 v, iii) to polo to pm.
The results of Brill's method on the present benchmark were reconstructed by Collins and Brooks (1995). $$$$$ Results on Wall Street Journal data of 84.5% accuracy are obtained using this method.

Collins and Brooks (1995) used a Back-Off model, which enables them to take low frequency effects into account on the Ratnaparkhi dataset (with good results). $$$$$ The accuracy figure is then the percentage accuracy on the test cases where the (v, nl, n2) counts were used.
Collins and Brooks (1995) used a Back-Off model, which enables them to take low frequency effects into account on the Ratnaparkhi dataset (with good results). $$$$$ The accuracy of 84.5% is close to the human performance figure of 88% using the 4 head words alone.
Collins and Brooks (1995) used a Back-Off model, which enables them to take low frequency effects into account on the Ratnaparkhi dataset (with good results). $$$$$ In [RRR94] a cut-off 'between 3 and 5' is used for all events.

The perhaps underwhelming human performance is partially due to misclassifications by the Treebank assemblers who made these determinations by hand, and also unclear cases, which we discuss in the next section. Collins and Brooks (1995) introduced modifications to the Ratnaparkhi et al (1994) dataset meant to combat data sparsity and used the modified version to train their backed-off model. $$$$$ In particular, quadruples and triples seen in test data will frequently be seen only once or twice in training data.
The perhaps underwhelming human performance is partially due to misclassifications by the Treebank assemblers who made these determinations by hand, and also unclear cases, which we discuss in the next section. Collins and Brooks (1995) introduced modifications to the Ratnaparkhi et al (1994) dataset meant to combat data sparsity and used the modified version to train their backed-off model. $$$$$ Recent work has considered corpus-based or statistical approaches to the problem of prepositional attachment ambiguity.
The perhaps underwhelming human performance is partially due to misclassifications by the Treebank assemblers who made these determinations by hand, and also unclear cases, which we discuss in the next section. Collins and Brooks (1995) introduced modifications to the Ratnaparkhi et al (1994) dataset meant to combat data sparsity and used the modified version to train their backed-off model. $$$$$ The human performance results are taken from [RRR94], and are the average performance of 3 treebanking experts on a set of 300 randomly selected test events from the WSJ corpus, first looking at the four head words alone, then using the whole sentence.

Abney, Schapire, and Singer (1999) used the dataset from Collins and Brooks (1995) with a boosting algorithm and achieved 85.4% accuracy. Their algorithm also was able to order the specific data points by how much weight they were assigned by the learning algorithm. $$$$$ When evaluating an algorithm it is useful to have an idea of the lower and upper bounds on its performance.
Abney, Schapire, and Singer (1999) used the dataset from Collins and Brooks (1995) with a boosting algorithm and achieved 85.4% accuracy. Their algorithm also was able to order the specific data points by how much weight they were assigned by the learning algorithm. $$$$$ At each stage there is a sharp difference in accuracy between tuples with and without a preposition.
Abney, Schapire, and Singer (1999) used the dataset from Collins and Brooks (1995) with a boosting algorithm and achieved 85.4% accuracy. Their algorithm also was able to order the specific data points by how much weight they were assigned by the learning algorithm. $$$$$ The PP 'as a nonexecutive director' can either attach to the NP 'the board' or to the VP 'joined', giving two alternative structures.

Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995). $$$$$ Results on Wall Street Journal data of 84.5% accuracy are obtained using this method.
Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995). $$$$$ The attachment decisions for these triples were unknown, so an unsupervised training method was used (section 5.2 describes the algorithm in more detail).
Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995). $$$$$ In [RRR94] a cut-off 'between 3 and 5' is used for all events.
Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995). $$$$$ The development set with no morphological processing was used for these tests.

Stetina and Nagao (1997) trained on a version of the Ratnaparkhi et al (1994) dataset that contained modifications similar to those by Collins and Brooks (1995) and excluded forms not present in WordNet. $$$$$ Finally, more training data is almost certain to improve results.
Stetina and Nagao (1997) trained on a version of the Ratnaparkhi et al (1994) dataset that contained modifications similar to those by Collins and Brooks (1995) and excluded forms not present in WordNet. $$$$$ Finally, more training data is almost certain to improve results.

Collins and Brooks (1995) used a supervised back-off model to achieve 84.5% precision on the Ratnaparkhi test set. $$$$$ Both papers describe methods which look at the four head words involved in the attachment - the VP head, the first NP head, the preposition and the second NP head (in this case joined, board, as and director respectively).
Collins and Brooks (1995) used a supervised back-off model to achieve 84.5% precision on the Ratnaparkhi test set. $$$$$ They use a maximum entropy model which also considers subsets of the quadruple.
Collins and Brooks (1995) used a supervised back-off model to achieve 84.5% precision on the Ratnaparkhi test set. $$$$$ Prepositional phrase attachment is a common cause of structural ambiguity in natural language.
Collins and Brooks (1995) used a supervised back-off model to achieve 84.5% precision on the Ratnaparkhi test set. $$$$$ On the surface the method described in [11R93] looks very similar to the backed-off estimate.

However, the baseline is similarly high for the PP problem if the most likely attachment is chosen per preposition $$$$$ The probability of the attachment variable A being 1 or 0 (signifying noun or verb attachment respectively) is a probability, p, which is conditional on the values of the words in the quadruple.
However, the baseline is similarly high for the PP problem if the most likely attachment is chosen per preposition $$$$$ The accuracy figure is then the percentage accuracy on the test cases where the (v, nl, n2) counts were used.
However, the baseline is similarly high for the PP problem if the most likely attachment is chosen per preposition $$$$$ For this reason only tuples which contained the preposition were used in backed off estimates - this reduces the problem to a choice between 3 triples and 3 pairs at each respective stage.

(Collins and Brooks, 1995) also present a model with multiple back offs. $$$$$ A particularly surprising result is the significance of low count events in training data.
(Collins and Brooks, 1995) also present a model with multiple back offs. $$$$$ Counts of lower order tuples can also be made - for example 1(1, P = from) is the number of times (P = from) is seen with noun attachment in training data, f(V = is, N2 = research) is the number of times (V = is, N2 = research) is seen with either attachment and any value of Ni and P. A maximum likelihood method would use the training data to give the following estimation for the conditional probability: Unfortunately sparse data problems make this estimate useless.
(Collins and Brooks, 1995) also present a model with multiple back offs. $$$$$ A possible criticism of the backed-off estimate is that it uses low count events without any smoothing, which has been shown to be a mistake in similar problems such as n-gram language models.

Later, Collins and Brooks (1995) achieved 84.5% accuracy by employing a backed-off model to smooth for unseen events. $$$$$ The probability of the attachment variable A being 1 or 0 (signifying noun or verb attachment respectively) is a probability, p, which is conditional on the values of the words in the quadruple.
Later, Collins and Brooks (1995) achieved 84.5% accuracy by employing a backed-off model to smooth for unseen events. $$$$$ (In this case the VP attachment is correct): NP-attach: (joined ((the board) (as a nonexecutive director))) VP-attach: ((joined (the board)) (as a nonexecutive director)) Work by Ratnaparkhi, Reynar and Roukos [RRR94] and Brill and Resnik [BR94] has considered corpus-based approaches to this problem, using a set of examples to train a model which is then used to make attachment decisions on test data.
Later, Collins and Brooks (1995) achieved 84.5% accuracy by employing a backed-off model to smooth for unseen events. $$$$$ The human performance results are taken from [RRR94], and are the average performance of 3 treebanking experts on a set of 300 randomly selected test events from the WSJ corpus, first looking at the four head words alone, then using the whole sentence.
Later, Collins and Brooks (1995) achieved 84.5% accuracy by employing a backed-off model to smooth for unseen events. $$$$$ Results on Wall Street Journal data of 84.5% accuracy are obtained using this method.

In our experiments, we only considered features that contained P since the preposition is the most important lexical item (Collins and Brooks, 1995). $$$$$ In [RRR94] a cut-off 'between 3 and 5' is used for all events.

We describe the different classifiers below $$$$$ It is defined recursively as follows: Else backing-off continues in the same way.
We describe the different classifiers below $$$$$ The figure below shows the results for the method on the 3097 test sentences, also giving the total count and accuracy at each of the backed-off stages.
We describe the different classifiers below $$$$$ For this reason the two methods deserve closer comparison.

The accuracy is reported in (Collins and Brooks, 1995). $$$$$ For example (P = of) might have a strong weight for noun attachment, while (V = buy, P = for) would have a strong weight for verb attachment.
The accuracy is reported in (Collins and Brooks, 1995). $$$$$ (Typical examples would be 'If P=of then choose noun attachment' or 'If V= buy and P=for choose verb attachment').
The accuracy is reported in (Collins and Brooks, 1995). $$$$$ A key observation in choosing between these tuples is that the preposition is particularly important to the attachment decision.
The accuracy is reported in (Collins and Brooks, 1995). $$$$$ Firstly, while we have shown the importance of low-count events, some kind of smoothing may improve performance further - this needs to be investigated.

p (Rjright; a; b) =# (R; right; a; b)# (right; a; b) (6) e.g. for the Verb-PP attachment relation pobj (following (Collins and Brooks, 1995) including the description noun 7) p (pobjjright; verb; prep ;desc $$$$$ Over 200,000 (v, nl,p) triples were extracted from 13 million words of AP news stories.
p (Rjright; a; b) =# (R; right; a; b)# (right; a; b) (6) e.g. for the Verb-PP attachment relation pobj (following (Collins and Brooks, 1995) including the description noun 7) p (pobjjright; verb; prep ;desc $$$$$ Two human judges annotated the attachment decision for 880 test examples, and the method performed at 80% accuracy on these cases.
p (Rjright; a; b) =# (R; right; a; b)# (right; a; b) (6) e.g. for the Verb-PP attachment relation pobj (following (Collins and Brooks, 1995) including the description noun 7) p (pobjjright; verb; prep ;desc $$$$$ Prepositional phrase attachment is a common cause of structural ambiguity in natural language.

For example, the sentence Congress accused the president of peccadillos is classified according to the attachment site of the prepositional phrase $$$$$ When evaluating an algorithm it is useful to have an idea of the lower and upper bounds on its performance.
For example, the sentence Congress accused the president of peccadillos is classified according to the attachment site of the prepositional phrase $$$$$ These figures should be taken in the context of the lower and upper bounds of 72.2%-88.2% proposed in section 2.3.

We used the same training and test data as Collins and Brooks (1995). $$$$$ The following method of combining the counts was found to work best in practice: Note that this method effectively gives more weight to tuples with high overall counts.
We used the same training and test data as Collins and Brooks (1995). $$$$$ The backed-off estimate scores appreciably better than other methods which have been tested on the Wall Street Journal corpus.
We used the same training and test data as Collins and Brooks (1995). $$$$$ Typically, ambiguous verb phrases of the form v p np2 through a model which considers values of the four head words (v, nl, paper shows that the problem is analogous to n-gram language models in speech recognition, and that one of the most common methods for language modeling, the backed-off estimate, is applicable.

Our approach can be seen as an extension of (Collins and Brooks, 1995) from PP-attachment to most dependency relations. $$$$$ The test used in [HR93] can then be stated as follows in our notation: This is effectively a comparison of the maximum likelihood estimates of Ill and , a different measure from the backed-off estimate which gives 73(iiv,p, n1).
Our approach can be seen as an extension of (Collins and Brooks, 1995) from PP-attachment to most dependency relations. $$$$$ (In this case the VP attachment is correct): NP-attach: (joined ((the board) (as a nonexecutive director))) VP-attach: ((joined (the board)) (as a nonexecutive director)) Work by Ratnaparkhi, Reynar and Roukos [RRR94] and Brill and Resnik [BR94] has considered corpus-based approaches to this problem, using a set of examples to train a model which is then used to make attachment decisions on test data.
Our approach can be seen as an extension of (Collins and Brooks, 1995) from PP-attachment to most dependency relations. $$$$$ Hindle and Rooth's method scored 82.1% accuracy (1580 correct) on this set, whereas the backed-off measure scored 86.5% (1665 correct).
Our approach can be seen as an extension of (Collins and Brooks, 1995) from PP-attachment to most dependency relations. $$$$$ A possible criticism of the backed-off estimate is that it uses low count events without any smoothing, which has been shown to be a mistake in similar problems such as n-gram language models.

Supervised methods are as varied as the Back off approach by Collins and Brooks (1995) and the Transformation-based approach by Brill and Resnik (1994). $$$$$ (ie. the above inequality is strictly less-than or greater-than).
Supervised methods are as varied as the Back off approach by Collins and Brooks (1995) and the Transformation-based approach by Brill and Resnik (1994). $$$$$ [KATZ87] describes backed-off n-gram word models for speech recognition.
Supervised methods are as varied as the Back off approach by Collins and Brooks (1995) and the Transformation-based approach by Brill and Resnik (1994). $$$$$ The NILE estimate of this probability would be: But again the denominator f(wi, w2....wn_1) will frequently be zero, especially for large n. The backed-off estimate is a method of combating the sparse data problem.
