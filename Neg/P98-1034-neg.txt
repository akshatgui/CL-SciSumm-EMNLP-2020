While early approaches to the NP-chunking task (Cardie and Pierce, 1998) relied on part-of-speech information alone, it is widely accepted that lexical information (word forms) is crucial for building accurate systems for these tasks. $$$$$ To identify base NPs in an unseen text, we could simply search for all occurrences of the base NPs seen during training â€” it, time, their biannual powwow, .. .
While early approaches to the NP-chunking task (Cardie and Pierce, 1998) relied on part-of-speech information alone, it is widely accepted that lexical information (word forms) is crucial for building accurate systems for these tasks. $$$$$ If there are multiple rules that match beginning at ti, use the longest matching rule R. Add the new base noun phrase t(i,i+IRi_i) to the set of base NPs.
While early approaches to the NP-chunking task (Cardie and Pierce, 1998) relied on part-of-speech information alone, it is widely accepted that lexical information (word forms) is crucial for building accurate systems for these tasks. $$$$$ Second, we have only recently begun to explore the use of local repair heuristics.
While early approaches to the NP-chunking task (Cardie and Pierce, 1998) relied on part-of-speech information alone, it is widely accepted that lexical information (word forms) is crucial for building accurate systems for these tasks. $$$$$ Given these observations, we implemented three local repair heuristics.

The approaches tested were Error Driven Pruning (EDP) (Cardie and Pierce, 1998) and Transformational Based Learning of IOB tagging (TBL) (Ramshaw and Marcus, 1995). $$$$$ For some applications, this minor drop in performance may be worth the decrease in training time.
The approaches tested were Error Driven Pruning (EDP) (Cardie and Pierce, 1998) and Transformational Based Learning of IOB tagging (TBL) (Ramshaw and Marcus, 1995). $$$$$ Finally, rule (NNP NNP) receives a score of 1 for correctly identifying Palm Beach as a base NP.
The approaches tested were Error Driven Pruning (EDP) (Cardie and Pierce, 1998) and Transformational Based Learning of IOB tagging (TBL) (Ramshaw and Marcus, 1995). $$$$$ For example, the rule (VBG NNS), which was extracted from manufacturing/VBG titans/NNS in the example text, is ambiguous, and will cause erroneous bracketing in sentences such as The execs squeezed in a few meetings before [boarding/VBG buses/NNS] again.
The approaches tested were Error Driven Pruning (EDP) (Cardie and Pierce, 1998) and Transformational Based Learning of IOB tagging (TBL) (Ramshaw and Marcus, 1995). $$$$$ Unfortunately, there is an obvious problem with the algorithm described above.

Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998), and we plan to address them in future work. $$$$$ Using this simple algorithm with a naive heuristic for matching rules, we achieve surprising accuracy in an evaluation on the
Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998), and we plan to address them in future work. $$$$$ Unfortunately, there is an obvious problem with the algorithm described above.
Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998), and we plan to address them in future work. $$$$$ The overall results are surprisingly good, especially considering the simplicity of the method.
Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998), and we plan to address them in future work. $$$$$ Future work will concentrate on the corpusbased acquisition of local repair heuristics.

Our implementation of the NP-based QA system uses the Empire noun phrase finder, which is described in detail in Cardie and Pierce (1998). $$$$$ More specifically, we assume that the training corpus is a sequence of words wi, w2,..., along with a set of base NP annotations b(i1,j1), ..., where b(,j) indicates that the NP brackets words i through j: [Nr, wi, , wj].
Our implementation of the NP-based QA system uses the Empire noun phrase finder, which is described in detail in Cardie and Pierce (1998). $$$$$ The training phase of the algorithm is based on two successful techniques: first the base NP grammar is read from a &quot;treebank&quot; corpus; then the grammar is improved by selecting rules with high &quot;benefit&quot; scores.
Our implementation of the NP-based QA system uses the Empire noun phrase finder, which is described in detail in Cardie and Pierce (1998). $$$$$ The final column indicates the performance of rule sets that had been pruned using the handcrafted pruning heuristics.
Our implementation of the NP-based QA system uses the Empire noun phrase finder, which is described in detail in Cardie and Pierce (1998). $$$$$ We describe each, in turn, in the subsections below.

(Cardie and Pierce, 1998, 1999) applied a scoring method to select new rules and a naive heuristic for matching rules to evaluate the results and accuracy. $$$$$ Given a ranking on the rule set, the threshold algorithm simply discards rules whose score is less than a predefined threshold R. For all of our experiments, we set R = 1 to select rules that propose more correct bracketings than incorrect.
(Cardie and Pierce, 1998, 1999) applied a scoring method to select new rules and a naive heuristic for matching rules to evaluate the results and accuracy. $$$$$ This paper presents a new algorithm for identifying base NPs in an arbitrary text.
(Cardie and Pierce, 1998, 1999) applied a scoring method to select new rules and a naive heuristic for matching rules to evaluate the results and accuracy. $$$$$ While previous empirical methods for base NP identification have been rather complex, this paper instead proposes a very simple algorithm that is tailored to the relative simplicity of the task.

(Cardie and Pierce, 1998) present an approach to chunking based on a mixture of finite state and context-free techniques. $$$$$ Using this simple algorithm with a naive heuristic for matching rules, we achieve surprising accuracy in an evaluation on the
(Cardie and Pierce, 1998) present an approach to chunking based on a mixture of finite state and context-free techniques. $$$$$ For some applications, this minor drop in performance may be worth the decrease in training time.
(Cardie and Pierce, 1998) present an approach to chunking based on a mixture of finite state and context-free techniques. $$$$$ Finally, rule (NNP NNP) receives a score of 1 for correctly identifying Palm Beach as a base NP.
(Cardie and Pierce, 1998) present an approach to chunking based on a mixture of finite state and context-free techniques. $$$$$ It employs two existing corpus-based techniques: the initial noun phrase grammar is extracted directly from an annotated corpus; and a benefit score calculated from errors on an improvement corpus selects the best subset of rules via a coarse- or fine-grained pruning algorithm.

(Cardie and Pierce, 1998) store POS tag sequences that make up complete chunks and use these sequences as rules for classifying unseen data. $$$$$ More specifically, we assume that the training corpus is a sequence of words wi, w2,..., along with a set of base NP annotations b(i1,j1), ..., where b(,j) indicates that the NP brackets words i through j: [Nr, wi, , wj].
(Cardie and Pierce, 1998) store POS tag sequences that make up complete chunks and use these sequences as rules for classifying unseen data. $$$$$ We are currently investigating such extensions.
(Cardie and Pierce, 1998) store POS tag sequences that make up complete chunks and use these sequences as rules for classifying unseen data. $$$$$ Finding simple, non-recursive, base noun phrases is an important subtask for many natural language processing applications.
(Cardie and Pierce, 1998) store POS tag sequences that make up complete chunks and use these sequences as rules for classifying unseen data. $$$$$ Thus, rules that form erroneous bracketings are not penalized if another rule previously bracketed part of the same reference NP.

We tested this hypothesis by training the Error-Driven Pruning (EDP) method of (Cardie and Pierce, 1998) with an extended set of features. $$$$$ Instead, we use a similar approach, but back off from lexical items to parts of speech: we identify as a base NP any string having the same part-of-speech tag sequence as a base NP from the training corpus.
We tested this hypothesis by training the Error-Driven Pruning (EDP) method of (Cardie and Pierce, 1998) with an extended set of features. $$$$$ Our general pruning procedure is shown in Figure 3.
We tested this hypothesis by training the Error-Driven Pruning (EDP) method of (Cardie and Pierce, 1998) with an extended set of features. $$$$$ /National Association) of /Manufacturers! settled on the Hoosier capital) of [Indianapolis) for I its next meeting).
