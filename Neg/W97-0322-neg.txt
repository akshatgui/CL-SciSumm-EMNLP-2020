Once the corpus has been processed, clusters are repeatedly merged using HAC with the aver age link criteria, following (Pedersen and Bruce,1997). $$$$$ We discuss three algorithms, McQuitty's similarity analysis (McQuitty, 1966), Ward's minimum—variance method (Ward, 1963) and the EM algorithm (Dempster, Laird, and Rubin, 1977), that can be used to distinguish among the known senses of an ambiguous word without the aid of disambiguated examples.
Once the corpus has been processed, clusters are repeatedly merged using HAC with the aver age link criteria, following (Pedersen and Bruce,1997). $$$$$ There words are represented in terms of the cooccurrence statistics of four letter sequences.
Once the corpus has been processed, clusters are repeatedly merged using HAC with the aver age link criteria, following (Pedersen and Bruce,1997). $$$$$ This limits the applicability of such approaches to domains where this hard to acquire knowledge is already available.

Here we are following (Pedersen and Bruce, 1997), who likewise took this approach to feature representation. $$$$$ Our methods and feature sets were found to be most successful in disambiguating nouns rather than adjectives or verbs.
Here we are following (Pedersen and Bruce, 1997), who likewise took this approach to feature representation. $$$$$ However, for decomposable models, such as the Naive Bayes, the E-step simplifies to the calculation of the expected counts in the marginal distributions of interdependent features, where the expectation is with respect to 0.
Here we are following (Pedersen and Bruce, 1997), who likewise took this approach to feature representation. $$$$$ For example, in Figure 1 we have four observations.
Here we are following (Pedersen and Bruce, 1997), who likewise took this approach to feature representation. $$$$$ The methods described in this paper, McQuitty's similarity analysis, Ward's minimum—variance method, and the EM algorithm, assign each instance of an ambiguous word to a known sense definition based solely on the values of automatically identifiable features in text.

Context Representations SenseClusters supports two different representations of context, first order context vectors as used by (Pedersen and Bruce, 1997) and second order context vectors as suggested by (Schutze,1998). $$$$$ The EM algorithm produces maximum likelihood estimates of the parameters of a probabilistic model, where that model has been specified in advance.
Context Representations SenseClusters supports two different representations of context, first order context vectors as used by (Pedersen and Bruce, 1997) and second order context vectors as suggested by (Schutze,1998). $$$$$ A supervised learning algorithm is trained with a small amount of manually sense tagged text and applied to a held out test set.
Context Representations SenseClusters supports two different representations of context, first order context vectors as used by (Pedersen and Bruce, 1997) and second order context vectors as suggested by (Schutze,1998). $$$$$ Thus, before we employ either clustering algorithm, we represent our data sample in terms of a dissimilarity matrix.
Context Representations SenseClusters supports two different representations of context, first order context vectors as used by (Pedersen and Bruce, 1997) and second order context vectors as suggested by (Schutze,1998). $$$$$ The dissimilarity between any existing cluster Cr and CKL is computed as: where DKI is the number of dissimilar features between clusters CK and C1 and DLI is similarly defined for clusters CL and C1.

But our model does have a natural preference for the most frequent sense in the thesaurus training corpus, which is a useful heuristic for word sense disambiguation (Pedersen and Bruce, 1997). $$$$$ In this study, we evaluated the performance of three unsupervised learning algorithms on the disambiguation of 13 words in naturally occurring text.
But our model does have a natural preference for the most frequent sense in the thesaurus training corpus, which is a useful heuristic for word sense disambiguation (Pedersen and Bruce, 1997). $$$$$ Experiments with 11 other words using collocation seeds result in an average accuracy of 96 percent.
But our model does have a natural preference for the most frequent sense in the thesaurus training corpus, which is a useful heuristic for word sense disambiguation (Pedersen and Bruce, 1997). $$$$$ In this case, an alternative is to use the more computationally expensive method of Gibbs Sampling (Geman and Geman, 1984).

Previous work in word sense discrimination has shown that contexts of an ambiguous word can be effectively represented using first order (Pedersen and Bruce, 1997) or second order (Schutze, 1998) representations. $$$$$ For example, McQuitty's method was significantly more accurate overall in combination with feature set C while the EM algorithm was more accurate with Feature Set A, and the accuracy of Ward's method was the least favorable with Feature Set B.
Previous work in word sense discrimination has shown that contexts of an ambiguous word can be effectively represented using first order (Pedersen and Bruce, 1997) or second order (Schutze, 1998) representations. $$$$$ In this study, we evaluated the performance of three unsupervised learning algorithms on the disambiguation of 13 words in naturally occurring text.
Previous work in word sense discrimination has shown that contexts of an ambiguous word can be effectively represented using first order (Pedersen and Bruce, 1997) or second order (Schutze, 1998) representations. $$$$$ This algorithm requires a small number of training examples to serve as a seed.
Previous work in word sense discrimination has shown that contexts of an ambiguous word can be effectively represented using first order (Pedersen and Bruce, 1997) or second order (Schutze, 1998) representations. $$$$$ In order to use the EM algorithm, the parametric form of the model representing the data must be known.

 $$$$$ We discuss the thirteen words (Section 4) and the three feature sets (Section 5) used in our experiments.
 $$$$$ While the choice of feature set impacts accuracy, overall it is only to a small degree.
 $$$$$ This paper presents three unsupervised learning algorithms that are able to distinguish among the known senses (i.e., as defined in some dictionary) of a word, based only on features that can be automatically extracted from untagged text.
 $$$$$ Overall, the most accurate of these procedures is McQuitty's similarity analysis in combination with a high dimensional feature set.

 $$$$$ In this study, the accuracy of the unsupervised algorithms was less than that of the majority classifier in every case where the percentage of the majority sense exceeded 68%.
 $$$$$ (Li, Szpakowicz, and Matwin, 1995)).
 $$$$$ In this case, an alternative is to use the more computationally expensive method of Gibbs Sampling (Geman and Geman, 1984).
 $$$$$ In future work, we will investigate modifications of these algorithms and feature set selection that are more effective on highly skewed sense distributions.

(Pedersen and Bruce, 1997) and (Pedersen and Bruce,1998) propose a (dis) similarity based discrimination approach that computes (dis) similarity among each pair of instances of the target word. $$$$$ For most domains such text is not available and is expensive to create.
(Pedersen and Bruce, 1997) and (Pedersen and Bruce,1998) propose a (dis) similarity based discrimination approach that computes (dis) similarity among each pair of instances of the target word. $$$$$ (Devijver and Kittler, 1982)).
(Pedersen and Bruce, 1997) and (Pedersen and Bruce,1998) propose a (dis) similarity based discrimination approach that computes (dis) similarity among each pair of instances of the target word. $$$$$ The set of context vectors for the word to be disambiguated are then clustered, and the clusters are manually sense tagged.
(Pedersen and Bruce, 1997) and (Pedersen and Bruce,1998) propose a (dis) similarity based discrimination approach that computes (dis) similarity among each pair of instances of the target word. $$$$$ The average accuracies for each feature set over 100 random trials were as follows: A 80.9%, B 87.7%, and C 82.7%.

(Schutze, 1998) points out that single link clustering tends to place all instances into a single elongated cluster, whereas (Pedersen and Bruce, 1997) and (Purandare, 2003) show that hierarchical agglomerative clustering using average link (via McQuitty's method) fares well. $$$$$ The creation of sense tagged text sufficient to serve as a training sample is expensive and time consuming.
(Schutze, 1998) points out that single link clustering tends to place all instances into a single elongated cluster, whereas (Pedersen and Bruce, 1997) and (Purandare, 2003) show that hierarchical agglomerative clustering using average link (via McQuitty's method) fares well. $$$$$ In future work, we will investigate modifications of these algorithms and feature set selection that are more effective on highly skewed sense distributions.
(Schutze, 1998) points out that single link clustering tends to place all instances into a single elongated cluster, whereas (Pedersen and Bruce, 1997) and (Purandare, 2003) show that hierarchical agglomerative clustering using average link (via McQuitty's method) fares well. $$$$$ This paper describes an experimental comparison of three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text.

The objective of this research is to extend previous work in discrimination by (Pedersen and Bruce, 1997), who developed an approach using agglomerative clustering. $$$$$ The algorithms are McQuitty's similarity analysis, Ward's minimum-variance method, and the EM algorithm.
The objective of this research is to extend previous work in discrimination by (Pedersen and Bruce, 1997), who developed an approach using agglomerative clustering. $$$$$ This paper describes an experimental comparison of three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text.
The objective of this research is to extend previous work in discrimination by (Pedersen and Bruce, 1997), who developed an approach using agglomerative clustering. $$$$$ They indicate the presences or absences of a particular content word in the same sentence as the ambiguous word.
The objective of this research is to extend previous work in discrimination by (Pedersen and Bruce, 1997), who developed an approach using agglomerative clustering. $$$$$ Merging of the two closest clusters continues until only some specified number of clusters remain.

We believe that this is an aggressive number of senses for a discrimination system to attempt, considering that (Pedersen and Bruce, 1997) experimented with 2 and 3 senses, and (Schutze, 1998) made binary distinctions. $$$$$ Each occurrence of line is tagged with a single sense defined in WordNet (Miller, 1995).
We believe that this is an aggressive number of senses for a discrimination system to attempt, considering that (Pedersen and Bruce, 1997) experimented with 2 and 3 senses, and (Schutze, 1998) made binary distinctions. $$$$$ Our methods and feature sets were found to be most successful in disambiguating nouns rather than adjectives or verbs.
We believe that this is an aggressive number of senses for a discrimination system to attempt, considering that (Pedersen and Bruce, 1997) experimented with 2 and 3 senses, and (Schutze, 1998) made binary distinctions. $$$$$ For verbs, the value of M indicates the tense of the verb and can have up to 7 possible values.
We believe that this is an aggressive number of senses for a discrimination system to attempt, considering that (Pedersen and Bruce, 1997) experimented with 2 and 3 senses, and (Schutze, 1998) made binary distinctions. $$$$$ The values of these features are defined much like the unrestricted collocations above, except that these are restricted to the 19 most frequent content words that occur only one position to the left or right of the ambiguous word.

Our method of name discrimination is described in more detail in (Pedersen et al, 2005), but in general is based on an unsupervised approach to word sense discrimination introduced by (Purandare and 25 Pedersen, 2004), which builds upon earlier work in word sense discrimination, including (Schutze, 1998) and (Pedersen and Bruce, 1997). $$$$$ All data, with the exception of the data for line, come from the ACL/DCI Wall Street Journal corpus (Marcus, Santorini, and Marcinkiewicz, 1993).
Our method of name discrimination is described in more detail in (Pedersen et al, 2005), but in general is based on an unsupervised approach to word sense discrimination introduced by (Purandare and 25 Pedersen, 2004), which builds upon earlier work in word sense discrimination, including (Schutze, 1998) and (Pedersen and Bruce, 1997). $$$$$ Supervised learning approaches to word—sense disambiguation fall victim to the knowledge acquisition bottleneck.
Our method of name discrimination is described in more detail in (Pedersen et al, 2005), but in general is based on an unsupervised approach to word sense discrimination introduced by (Purandare and 25 Pedersen, 2004), which builds upon earlier work in word sense discrimination, including (Schutze, 1998) and (Pedersen and Bruce, 1997). $$$$$ Every experiment utilizes all of the sentences available for each word.

For example, Pedersen and Bruce (1997) cluster the occurrences of an ambiguous word by constructing a vector of terms occurring in the context of the target. $$$$$ In these experiments we use 4 unrestricted collocation features, UL2, ULi, URI, and UR2.
For example, Pedersen and Bruce (1997) cluster the occurrences of an ambiguous word by constructing a vector of terms occurring in the context of the target. $$$$$ They suggest that a word should potentially have different neighborhoods corresponding to the different LDOCE subject code.
For example, Pedersen and Bruce (1997) cluster the occurrences of an ambiguous word by constructing a vector of terms occurring in the context of the target. $$$$$ Note that million and company occur frequently.
For example, Pedersen and Bruce (1997) cluster the occurrences of an ambiguous word by constructing a vector of terms occurring in the context of the target. $$$$$ Overall, the most accurate of these procedures is McQuitty's similarity analysis in combination with a high dimensional feature set.

An evaluation was carried out on the full 27,132 instance train+test data set using the SenseClusters evaluation methodology, which was first defined in (Pedersen and Bruce, 1997). $$$$$ Each POS feature can have one of 5 possible values: noun, verb, adjective, adverb or other.
An evaluation was carried out on the full 27,132 instance train+test data set using the SenseClusters evaluation methodology, which was first defined in (Pedersen and Bruce, 1997). $$$$$ The number of sentences available per word is shown as &quot;total count&quot; in Figure 3.
An evaluation was carried out on the full 27,132 instance train+test data set using the SenseClusters evaluation methodology, which was first defined in (Pedersen and Bruce, 1997). $$$$$ In few cases is the standard deviation very small.
An evaluation was carried out on the full 27,132 instance train+test data set using the SenseClusters evaluation methodology, which was first defined in (Pedersen and Bruce, 1997). $$$$$ This bottleneck is eliminated through the use of unsupervised learning approaches which distinguish the sense of a word based only on features that can be automatically identified.

 $$$$$ These common features may be sufficient for the level of disambiguation achieved here.
 $$$$$ Statistical methods for natural language processing are often dependent on the availability of costly knowledge sources such as manually annotated text or semantic networks.
 $$$$$ Overall, the most accurate of these procedures is McQuitty's similarity analysis in combination with a high dimensional feature set.

 $$$$$ In this study, we evaluated the performance of three unsupervised learning algorithms on the disambiguation of 13 words in naturally occurring text.
 $$$$$ All data, with the exception of the data for line, come from the ACL/DCI Wall Street Journal corpus (Marcus, Santorini, and Marcinkiewicz, 1993).
 $$$$$ Other clustering approaches to word—sense disambiguation have been based on measures of semantic distance defined with respect to a semantic network such as WordNet.
 $$$$$ In this model, all features are conditionally independent given the value of the classification feature, i.e., the sense of the ambiguous word.

In (Pedersen and Bruce, 1997), they described an experimental comparison of three clustering algorithms for word sense discrimination. $$$$$ This paper presents three unsupervised learning algorithms that are able to distinguish among the known senses (i.e., as defined in some dictionary) of a word, based only on features that can be automatically extracted from untagged text.
In (Pedersen and Bruce, 1997), they described an experimental comparison of three clustering algorithms for word sense discrimination. $$$$$ In order to evaluate the unsupervised learning algorithms we use sense—tagged text in these experiments.
In (Pedersen and Bruce, 1997), they described an experimental comparison of three clustering algorithms for word sense discrimination. $$$$$ This paper presents three unsupervised learning algorithms that are able to distinguish among the known senses (i.e., as defined in some dictionary) of a word, based only on features that can be automatically extracted from untagged text.
In (Pedersen and Bruce, 1997), they described an experimental comparison of three clustering algorithms for word sense discrimination. $$$$$ Statistical methods for natural language processing are often dependent on the availability of costly knowledge sources such as manually annotated text or semantic networks.
