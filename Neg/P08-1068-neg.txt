Second, for syntactic dependency parsing, combining Brown cluster features with word forms or POS tags yields high accuracy even with little training data (Koo et al, 2008). $$$$$ Our approach is similar to theirs in that the Brown algorithm produces clusters based on distributional similarity, and the clusterbased features can be viewed as being a kind of “backed-off” version of the baseline features.
Second, for syntactic dependency parsing, combining Brown cluster features with word forms or POS tags yields high accuracy even with little training data (Koo et al, 2008). $$$$$ These improved clusters can then be used to retrain an improved parser, resulting in an overall algorithm similar to that of McClosky et al. (2006).
Second, for syntactic dependency parsing, combining Brown cluster features with word forms or POS tags yields high accuracy even with little training data (Koo et al, 2008). $$$$$ Abbreviations: ht = head POS, hw = head word, hc4 = 4-bit prefix of head, hc6 = 6-bit prefix of head, hc* = full bit string of head; mt,mw,mc4,mc6,mc* = likewise for modifier; st,gt,sc4,gc4,... = likewise for sibling and grandchild.
Second, for syntactic dependency parsing, combining Brown cluster features with word forms or POS tags yields high accuracy even with little training data (Koo et al, 2008). $$$$$ Bilexical dependencies are thus ideal candidates for the application of coarse word proxies such as word clusters.

Additional templates we include are the relative position (Bj ?orkelund et al, 2009), geneological relationship, distance (Zhao et al, 2009), and binned distance (Koo et al, 2008) between two words in the path. $$$$$ By using prefixes of various lengths, we can produce clusterings of different granularities (Miller et al., 2004).
Additional templates we include are the relative position (Bj ?orkelund et al, 2009), geneological relationship, distance (Zhao et al, 2009), and binned distance (Koo et al, 2008) between two words in the path. $$$$$ We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank, and we show that the cluster-based features yield substantial gains in performance across a wide range of conditions.
Additional templates we include are the relative position (Bj ?orkelund et al, 2009), geneological relationship, distance (Zhao et al, 2009), and binned distance (Koo et al, 2008) between two words in the path. $$$$$ Crucially, however, these methods do not exploit unlabeled data when learning their representations.
Additional templates we include are the relative position (Bj ?orkelund et al, 2009), geneological relationship, distance (Zhao et al, 2009), and binned distance (Koo et al, 2008) between two words in the path. $$$$$ For simplicity, we did not retrain a tagger for each reduced dataset, so we always use the (automatically-assigned) part of speech tags provided in the corpus.

In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al, 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al, 2004). $$$$$ One possible explanation is that the clusterings generated by the Brown algorithm can be noisy or only weakly relevant to syntax; thus, the clusters are best exploited when “anchored” to words or parts of speech.
In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al, 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al, 2004). $$$$$ In our experiments, we employed two different feature sets: a baseline feature set which draws upon “normal” information sources such as word forms and parts of speech, and a cluster-based feature set that also uses information derived from the Brown cluster hierarchy.
In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al, 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al, 2004). $$$$$ Despite this success, there are several ways in which our approach might be improved.
In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al, 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al, 2004). $$$$$ Intuitively, there is a “mismatch” between the kind of lexical information that is captured by the Brown clusters and the kind of lexical information that is modeled in dependency parsing.

We did not observe the same trend in the reduction of annotation need with cluster-based features as in Koo et al (2008) for dependency parsing. $$$$$ Intuitively, there is a “mismatch” between the kind of lexical information that is captured by the Brown clusters and the kind of lexical information that is modeled in dependency parsing.
We did not observe the same trend in the reduction of annotation need with cluster-based features as in Koo et al (2008) for dependency parsing. $$$$$ The first- and second-order cluster-based feature sets are supersets of the baseline feature sets: they include all of the baseline feature templates, and add an additional layer of features that incorporate word clusters.
We did not observe the same trend in the reduction of annotation need with cluster-based features as in Koo et al (2008) for dependency parsing. $$$$$ In higher-order parsing models, the parts can consist of interactions between more than two words.
We did not observe the same trend in the reduction of annotation need with cluster-based features as in Koo et al (2008) for dependency parsing. $$$$$ The algorithm then repeatedly merges the pair of clusters which causes the smallest decrease in the likelihood of the text corpus, according to a class-based bigram language model defined on the word clusters.

Koo et al (2008) have proposed to use word clusters as features to improve graph-based statistical dependency parsing for English and Czech. $$$$$ These approaches have the advantage that the model is able to learn different usages for the hidden variables, depending on the target problem at hand.
Koo et al (2008) have proposed to use word clusters as features to improve graph-based statistical dependency parsing for English and Czech. $$$$$ Intuitively, there is a “mismatch” between the kind of lexical information that is captured by the Brown clusters and the kind of lexical information that is modeled in dependency parsing.
Koo et al (2008) have proposed to use word clusters as features to improve graph-based statistical dependency parsing for English and Czech. $$$$$ Given a factorization of dependency structures into parts, we restate dependency parsing as the folAbove, we have assumed that each part is scored by a linear model with parameters w and featuremapping f(·).

The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al, 2008) and named entity recognition (Liang, 2005). $$$$$ Alternately, one could design clustering algorithms that cluster entire head-modifier arcs rather than individual words.
The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al, 2008) and named entity recognition (Liang, 2005). $$$$$ We are thus relying on the ability of discriminative learning methods to identify and exploit informative features while remaining agnostic as to the origin of such features.
The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al, 2008) and named entity recognition (Liang, 2005). $$$$$ We focus on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus.
The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al, 2008) and named entity recognition (Liang, 2005). $$$$$ We present a simple and effective semisupervised method for training dependency parsers.

This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al, 2008) and transfer (Hwa et al, 2005) systems for prediction of linguistic structure. $$$$$ Alternately, one could design clustering algorithms that cluster entire head-modifier arcs rather than individual words.
This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al, 2008) and transfer (Hwa et al, 2005) systems for prediction of linguistic structure. $$$$$ Full bit strings,3 which we used as substitutes for word forms.
This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al, 2008) and transfer (Hwa et al, 2005) systems for prediction of linguistic structure. $$$$$ For example, the baseline feature set includes indicators for word-to-word and tag-to-tag interactions between the head and modifier of a dependency.
This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al, 2008) and transfer (Hwa et al, 2005) systems for prediction of linguistic structure. $$$$$ For many different part factorizations and structure domains Y(·), it is possible to solve the above maximization efficiently, and several recent efforts have concentrated on designing new maximization algorithms with increased contextsensitivity (Eisner, 2000; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007).

We observe an average absolute increase in LAS of approximately 1%, which is inline with previous observations (Koo et al, 2008). $$$$$ The English experiments were performed on the Penn Treebank (Marcus et al., 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation.6 We split the Treebank into a training set (Sections 2–21), a development set (Section 22), and several test sets (Sections 0,7 1, 23, and 24).
We observe an average absolute increase in LAS of approximately 1%, which is inline with previous observations (Koo et al, 2008). $$$$$ Table 2 compiles our final test results and also includes two results from previous work by McDonald et al. (2005a) and McDonald and Pereira (2006), for the purposes of comparison.

A simple method for using unlabeled data in discriminative dependency parsing was provided in (Koo et al, 2008) which involved clustering the labeled and unlabeled data and then each word in the dependency tree bank was assigned a cluster identifier. $$$$$ Note that the performance obtained by using clusters without parts of speech is close to the performance of the baseline features.
A simple method for using unlabeled data in discriminative dependency parsing was provided in (Koo et al, 2008) which involved clustering the labeled and unlabeled data and then each word in the dependency tree bank was assigned a cluster identifier. $$$$$ For simplicity, we did not retrain a tagger for each reduced dataset, so we always use the (automatically-assigned) part of speech tags provided in the corpus.
A simple method for using unlabeled data in discriminative dependency parsing was provided in (Koo et al, 2008) which involved clustering the labeled and unlabeled data and then each word in the dependency tree bank was assigned a cluster identifier. $$$$$ However, our target task of dependency parsing involves more complex structured relationships than named-entity tagging; moreover, it is not at all clear that word clusters should have any relevance to syntactic structure.

In this work, following (Koo et al, 2008), we use word cluster identifiers as the source of an additional set of features. $$$$$ We focus on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus.
In this work, following (Koo et al, 2008), we use word cluster identifiers as the source of an additional set of features. $$$$$ Wang et al. (2005) used distributional similarity scores to smooth a generative probability model for dependency parsing and obtained improvements in a Chinese parsing task.
In this work, following (Koo et al, 2008), we use word cluster identifiers as the source of an additional set of features. $$$$$ For example, in the case of English unlabeled second-order parsing, we improve from a baseline accuof in the case of Czech unlabeled second-order parsing, we from a baseline accuracy of addition, we demonstrate that our method also improves performance when small amounts of training data are available, and can roughly halve the amount of supervised data required to reach a desired level of performance.

The reader is directed to (Koo et al, 2008) for the list of cluster-based feature templates. $$$$$ It is therefore attractive to consider intermediate entities which exist at a coarser level than the words themselves, yet capture the information necessary to resolve the relevant ambiguities.
The reader is directed to (Koo et al, 2008) for the list of cluster-based feature templates. $$$$$ We present a simple and effective semisupervised method for training dependency parsers.
The reader is directed to (Koo et al, 2008) for the list of cluster-based feature templates. $$$$$ Another idea would be to integrate the clustering algorithm into the training algorithm in a limited fashion.

Our first word representation is exactly the same as the one used in (Koo et al, 2008) where words are clustered using the Brown algorithm (Brown et al, 1992). $$$$$ Note that the performance of cluster-based features is fairly insensitive to the threshold value, whereas the performance of baseline features clearly degrades as the vocabulary size is reduced.
Our first word representation is exactly the same as the one used in (Koo et al, 2008) where words are clustered using the Brown algorithm (Brown et al, 1992). $$$$$ Full bit strings,3 which we used as substitutes for word forms.

In our experiments we use the clusters obtained in (Koo et al, 2008), but were unable to match the accuracy reported there, perhaps due to additional features used in their implementation not described in the paper. $$$$$ Wang et al. (2005) used distributional similarity scores to smooth a generative probability model for dependency parsing and obtained improvements in a Chinese parsing task.
In our experiments we use the clusters obtained in (Koo et al, 2008), but were unable to match the accuracy reported there, perhaps due to additional features used in their implementation not described in the paper. $$$$$ These improved clusters can then be used to retrain an improved parser, resulting in an overall algorithm similar to that of McClosky et al. (2006).
In our experiments we use the clusters obtained in (Koo et al, 2008), but were unable to match the accuracy reported there, perhaps due to additional features used in their implementation not described in the paper. $$$$$ For simplicity, we did not implement a deprojectivization stage on top of our second-order parser, but we conjecture that such techniques may yield some additional performance gains; we leave this to future work.

Terry Koo was kind enough to share the source code for the (Koo et al, 2008) paper with us, and we plan to incorporate all the features in our future work. $$$$$ Bilexical dependencies are thus ideal candidates for the application of coarse word proxies such as word clusters.
Terry Koo was kind enough to share the source code for the (Koo et al, 2008) paper with us, and we plan to incorporate all the features in our future work. $$$$$ Our approach is similar to theirs in that the Brown algorithm produces clusters based on distributional similarity, and the clusterbased features can be viewed as being a kind of “backed-off” version of the baseline features.
Terry Koo was kind enough to share the source code for the (Koo et al, 2008) paper with us, and we plan to incorporate all the features in our future work. $$$$$ We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank, and we show that the cluster-based features yield substantial gains in performance across a wide range of conditions.

Moreover, we introduce two extensions related to dependency parsing $$$$$ The part of speech tags for the development and test data were automatically assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9 The Czech experiments were performed on the Prague Dependency Treebank 1.0 (Hajiˇc, 1998; Hajiˇc et al., 2001), which is directly annotated with dependency structures.
Moreover, we introduce two extensions related to dependency parsing $$$$$ Despite this success, there are several ways in which our approach might be improved.
Moreover, we introduce two extensions related to dependency parsing $$$$$ Using these two types of clusters, we generated new features by mimicking the template structure of the original baseline features.
Moreover, we introduce two extensions related to dependency parsing $$$$$ Dtd.

In particular, Koo et al (2008) describe a semi-supervised approach that makes use of cluster features induced from unlabeled data, and gives state-of-the-art results on the widely used dependency parsing test collections $$$$$ Nevertheless, our experiments demonstrate that word clusters can be quite effective in dependency parsing applications.
In particular, Koo et al (2008) describe a semi-supervised approach that makes use of cluster features induced from unlabeled data, and gives state-of-the-art results on the widely used dependency parsing test collections $$$$$ Many thanks also to Percy Liang for providing his implementation of the Brown algorithm, and Ryan McDonald for his assistance with the experimental setup.

The first extension is to combine our method with the cluster-based semi-supervised method of (Koo et al, 2008). $$$$$ Key to the success of our approach is the use of features which allow word-cluster-based information to assist the parser.
The first extension is to combine our method with the cluster-based semi-supervised method of (Koo et al, 2008). $$$$$ For example, after training an initial parser, one could parse a large amount of unlabeled text and use those parses to improve the quality of the clusters.
The first extension is to combine our method with the cluster-based semi-supervised method of (Koo et al, 2008). $$$$$ We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank, and we show that the cluster-based features yield substantial gains in performance across a wide range of conditions.

Our experiments investigate the effectiveness of $$$$$ For a given sentence x, let Y(x) denote the set of possible dependency structures spanning x, where each y E Y(x) decomposes into a set of “parts” r E y.
Our experiments investigate the effectiveness of $$$$$ However, our work is focused on discriminative learning as opposed to generative models.
Our experiments investigate the effectiveness of $$$$$ However, our work is focused on discriminative learning as opposed to generative models.
Our experiments investigate the effectiveness of $$$$$ In this paper, we have presented a simple but effective semi-supervised learning approach and demonstrated that it achieves substantial improvement over a competitive baseline in two broad-coverage dependency parsing tasks.

We simply use the cluster based feature-vector representation f (x, y) introduced by (Koo et al, 2008) as the basis of our approach. $$$$$ In our initial attempts, we focused on features that used cluster information exclusively.
We simply use the cluster based feature-vector representation f (x, y) introduced by (Koo et al, 2008) as the basis of our approach. $$$$$ For example, in the case of English unlabeled second-order parsing, we improve from a baseline accuof in the case of Czech unlabeled second-order parsing, we from a baseline accuracy of addition, we demonstrate that our method also improves performance when small amounts of training data are available, and can roughly halve the amount of supervised data required to reach a desired level of performance.
We simply use the cluster based feature-vector representation f (x, y) introduced by (Koo et al, 2008) as the basis of our approach. $$$$$ In natural language parsing, lexical information is seen as crucial to resolving ambiguous relationships, yet lexicalized statistics are sparse and difficult to estimate directly.
We simply use the cluster based feature-vector representation f (x, y) introduced by (Koo et al, 2008) as the basis of our approach. $$$$$ Specifically, for any feature that is predicated on a word form, we eliminate this feature if the word in question is not one of the top-N most frequent words in the corpus.

These data sets are identical to the unlabeled data used in (Koo et al, 2008), and are disjoint from the training, development and test sets. $$$$$ Despite this success, there are several ways in which our approach might be improved.
These data sets are identical to the unlabeled data used in (Koo et al, 2008), and are disjoint from the training, development and test sets. $$$$$ 6/21/1998.
