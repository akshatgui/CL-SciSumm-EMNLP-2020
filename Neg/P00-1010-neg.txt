Related work by Mani and Wilson (2000) focuses only on the core temporal expressions neglecting the temporal information conveyed by prepositions (e.g. Friday vs. by Friday). The main part of the system is a temporal expression tagger that employs finite state transducers based on hand-written rules. $$$$$ (The MUC task required recognizing a wider variety of TIMEXs, including event-dependent ones.
Related work by Mani and Wilson (2000) focuses only on the core temporal expressions neglecting the temporal information conveyed by prepositions (e.g. Friday vs. by Friday). The main part of the system is a temporal expression tagger that employs finite state transducers based on hand-written rules. $$$$$ Finally, expressions which are ambiguous without a strongly preferred reading are left without a value.
Related work by Mani and Wilson (2000) focuses only on the core temporal expressions neglecting the temporal information conveyed by prepositions (e.g. Friday vs. by Friday). The main part of the system is a temporal expression tagger that employs finite state transducers based on hand-written rules. $$$$$ The time expression identifying rules assumed that these had been tagged as lexical items, but this lexicalization has not yet been implemented.
Related work by Mani and Wilson (2000) focuses only on the core temporal expressions neglecting the temporal information conveyed by prepositions (e.g. Friday vs. by Friday). The main part of the system is a temporal expression tagger that employs finite state transducers based on hand-written rules. $$$$$ In addition to features based on words cooccurring with “today” (Said, Will, Even, Most, and Some features below), some other features (DOW and CCYY) were added based on a granularity hypothesis.

A more complex set of temporal expressions as extracted by recent systems (e.g. (Mani and Wilson, 2000)) was tagged. $$$$$ For example, “Christmas” has a seasonal use (e.g., “I spent Christmas visiting European capitals”) distinct from its reference to a specific day use as “December 25th” (e.g., “We went to a great party on Christmas”).
A more complex set of temporal expressions as extracted by recent systems (e.g. (Mani and Wilson, 2000)) was tagged. $$$$$ Such a verb is found by first searching backward to the last TIMEX, if any, in the sentence, then forward to the end of the sentence and finally backwards to the beginning of the sentence.
A more complex set of temporal expressions as extracted by recent systems (e.g. (Mani and Wilson, 2000)) was tagged. $$$$$ The information of the sort shown in Figure 2 can be used to sort and cluster events temporally, allowing for various time-line based presentations of this information in response to specific queries.

The systems compared against are: GUTime (Mani and Wilson, 2000), a widely used, older rule-based system. $$$$$ In multidocument summarization, providing finegrained chronologies of events over time (e.g., for a biography of a person, or a history of a crisis) can be very useful.
The systems compared against are: GUTime (Mani and Wilson, 2000), a widely used, older rule-based system. $$$$$ We also report on a preliminary effort towards constructing event chronologies from this data.
The systems compared against are: GUTime (Mani and Wilson, 2000), a widely used, older rule-based system. $$$$$ The system architecture of the temporal tagger is shown in Figure 1.
The systems compared against are: GUTime (Mani and Wilson, 2000), a widely used, older rule-based system. $$$$$ If the year can be chosen in a way that makes the date in question less than a month from the reference date, that year is chosen.

Although Ahn et al (2007) compared their results with those presented by Mani and Wilson (2000), they went on to point out that, for a variety of reasons, the numbers they provided were not really comparable. $$$$$ Interval expressions like “From May 1999 to June 1999”, or “from 3 pm to 6 pm” are represented as two separate TIMEX expressions.
Although Ahn et al (2007) compared their results with those presented by Mani and Wilson (2000), they went on to point out that, for a variety of reasons, the numbers they provided were not really comparable. $$$$$ To summarize, the features we used for the “today” problem are as follows (features are boolean except for string-valued POS1 and POS2): Poss: whether “today” has a possessive inflection Qcontext: whether “today” is inside a quotation Said: presence of “said” in the same sentence Will: presence of “will” in the same sentence Even: presence of “even” in the same sentence Most: presence of “most” in the same sentence Some: presence of “some” in the same sentence Year: presence of “year” in the same sentence CCYY: presence of a four-digit year in the same sentence DOW: presence of a day of the week expression (“Monday” thru “Sunday”) in the same sentence FW: “today” is the first word of the sentence POST: part-of-speech of the word before “today” POS2: part-of-speech of the word after “today” Label: specific or non-specific (class label) Table 3 shows the performance of different classifiers in classifying occurrences of “today” as generic versus specific.
Although Ahn et al (2007) compared their results with those presented by Mani and Wilson (2000), they went on to point out that, for a variety of reasons, the numbers they provided were not really comparable. $$$$$ Here we discuss machine learning results in distinguishing specific use of “today” (meaning the day of the utterance) from its generic use meaning “nowadays”.
Although Ahn et al (2007) compared their results with those presented by Mani and Wilson (2000), they went on to point out that, for a variety of reasons, the numbers they provided were not really comparable. $$$$$ This is the single biggest source of errors in the value assignments.

Most closely relevant to the work described in the present paper are the approaches described in (Baldwin, 2002), (Jang et al, 2004) and (Mani and Wilson, 2000). $$$$$ Finally, there is a large body of work, e.g., (Moens and Steedman 1988), (Passoneau 1988), (Webber 1988), (Hwang 1992), (Song and Cohen 1991), that has focused on a computational analysis of tense and aspect.
Most closely relevant to the work described in the present paper are the approaches described in (Baldwin, 2002), (Jang et al, 2004) and (Mani and Wilson, 2000). $$$$$ A total of 94 errors were made in the assignment of values to time expressions that had been correctly identified.
Most closely relevant to the work described in the present paper are the approaches described in (Baldwin, 2002), (Jang et al, 2004) and (Mani and Wilson, 2000). $$$$$ They obtained roughly .91 Precision and .80 Recall on one test set, and .87 Precision and .68 Recall on another.

In the system presented in (Mani and Wilson, 2000), weekday name interpretation is implemented as part of a sequence of interpretation rules for temporal expression interpretation more generally. $$$$$ To summarize, the features we used for the “today” problem are as follows (features are boolean except for string-valued POS1 and POS2): Poss: whether “today” has a possessive inflection Qcontext: whether “today” is inside a quotation Said: presence of “said” in the same sentence Will: presence of “will” in the same sentence Even: presence of “even” in the same sentence Most: presence of “most” in the same sentence Some: presence of “some” in the same sentence Year: presence of “year” in the same sentence CCYY: presence of a four-digit year in the same sentence DOW: presence of a day of the week expression (“Monday” thru “Sunday”) in the same sentence FW: “today” is the first word of the sentence POST: part-of-speech of the word before “today” POS2: part-of-speech of the word after “today” Label: specific or non-specific (class label) Table 3 shows the performance of different classifiers in classifying occurrences of “today” as generic versus specific.
In the system presented in (Mani and Wilson, 2000), weekday name interpretation is implemented as part of a sequence of interpretation rules for temporal expression interpretation more generally. $$$$$ The program then takes the entire document and passes it to a discourse processing module (DP) which resolves context-dependent time expressions (indexicals as well as other expressions).
In the system presented in (Mani and Wilson, 2000), weekday name interpretation is implemented as part of a sequence of interpretation rules for temporal expression interpretation more generally. $$$$$ If the tense is future, the direction is forward.
In the system presented in (Mani and Wilson, 2000), weekday name interpretation is implemented as part of a sequence of interpretation rules for temporal expression interpretation more generally. $$$$$ We have developed a temporal annotation specification, and an algorithm for resolving a class of time expressions found in news.

GUTime (Mani and Wilson, 2000) presents an older but widely used baseline. $$$$$ A baseline of just tagging values of absolute, fully specified TIMEXs (e.g., “January 31st, 1999”) is shown for comparison in parentheses.
GUTime (Mani and Wilson, 2000) presents an older but widely used baseline. $$$$$ The MUC-7 task (MUC-7 98) did not require VALs, but did test TIMEX recognition accuracy.
GUTime (Mani and Wilson, 2000) presents an older but widely used baseline. $$$$$ 97), (Busemann et al. 97)), where the goal is to schedule a time for the meeting.

As a result, many timex interpretation systems are a mixture of both rule-based and machine learning approaches (Mani and Wilson, 2000). $$$$$ Table 2 shows the number of errors made by the program classified by the type of error.
As a result, many timex interpretation systems are a mixture of both rule-based and machine learning approaches (Mani and Wilson, 2000). $$$$$ For example, “Christmas” has a seasonal use (e.g., “I spent Christmas visiting European capitals”) distinct from its reference to a specific day use as “December 25th” (e.g., “We went to a great party on Christmas”).
As a result, many timex interpretation systems are a mixture of both rule-based and machine learning approaches (Mani and Wilson, 2000). $$$$$ A total of 94 errors were made in the assignment of values to time expressions that had been correctly identified.
As a result, many timex interpretation systems are a mixture of both rule-based and machine learning approaches (Mani and Wilson, 2000). $$$$$ With each successive event, the temporal focus is either maintained or shifted, and a temporal ordering relation between the event and the focus is asserted, using heuristics defining coherent tense sequences; see (Song and Cohen 1991) for more details.

 $$$$$ The system, which is based on both hand-crafted and machine-learnt rules, achieves an 83.2% accuracy (Fmeasure) against hand-annotated data.
 $$$$$ The algorithm, which is relatively knowledge-poor, uses a mix of hand-crafted and machine-learnt rules and obtains reasonable results.
 $$$$$ We also hope to handle a wider class of time expressions, as well as further improve our extraction and evaluation of event chronologies.
 $$$$$ The print data was much cleaner than the transcribed broadcast data in the sense that there were very few typographical errors, spelling and grammar were good.

The GUTime tagger, developed at Georgetown University, extends the capabilities of the TempEx tagger (Mani and Wilson, 2000). $$$$$ We also hope to handle a wider class of time expressions, as well as further improve our extraction and evaluation of event chronologies.
The GUTime tagger, developed at Georgetown University, extends the capabilities of the TempEx tagger (Mani and Wilson, 2000). $$$$$ We introduce an annotation scheme for temporal expressions, and describe a method for resolving temporal expressions in print and broadcast news.
The GUTime tagger, developed at Georgetown University, extends the capabilities of the TempEx tagger (Mani and Wilson, 2000). $$$$$ In the last step after years of preparation, the countries <lex eindex=“9” precedes=“10|” TIME=“19981231”>locked</lex> in the exchange rates of their individual currencies to the euro, thereby <lex eindex=“10” TIME=“19981231”>setting</lex> the value at which the euro will begin <lex eindex=“11” TIME=“19990104”>trading</lex> when financial markets open
The GUTime tagger, developed at Georgetown University, extends the capabilities of the TempEx tagger (Mani and Wilson, 2000). $$$$$ Positional offsets from reference time: Expressions like “next month”, “last year” and “this coming Thursday” use lexical markers (underlined) to describe the direction and magnitude of the offset from the reference time.

The system of Mani and Wilson (2000) goes further in using separate sets of hand-crafted rules for recognition and normalization and in separating out several disambiguation tasks. $$$$$ The temporal references in meeting scheduling are somewhat more constrained than in news, where (e.g., in a historical news piece on toxic dumping) dates and times may be relatively unconstrained.
The system of Mani and Wilson (2000) goes further in using separate sets of hand-crafted rules for recognition and normalization and in separating out several disambiguation tasks. $$$$$ The standard also supports the representation of weeks and days of the week in the format CC:YY:Wwwd where ww specifies which week within the year (1-53) and d specifies the day of the week (1-7).

Mani and Wilson (2000) and Ahn et al (2005b) also perform limited semantic class disambiguation. $$$$$ “nineteen seventynine”.
Mani and Wilson (2000) and Ahn et al (2005b) also perform limited semantic class disambiguation. $$$$$ If the tense is future, the direction is forward.
Mani and Wilson (2000) and Ahn et al (2005b) also perform limited semantic class disambiguation. $$$$$ The tagger uses a variety of hand-crafted and machine-discovered rules, all of which rely on lexical features that are easily recognized.
Mani and Wilson (2000) and Ahn et al (2005b) also perform limited semantic class disambiguation. $$$$$ A total of 44 errors were made in the identification of TIMEX expressions.

(Mani and Wilson, 2000) use a heuristic method for this task, while (Ahn et al, 2005b) use a machine learned classifier. $$$$$ This is the single biggest source of errors in the value assignments.
(Mani and Wilson, 2000) use a heuristic method for this task, while (Ahn et al, 2005b) use a machine learned classifier. $$$$$ Arguments can be made for either position, as long as both intervals and points are accommodated.
(Mani and Wilson, 2000) use a heuristic method for this task, while (Ahn et al, 2005b) use a machine learned classifier. $$$$$ Finally, there is a large body of work, e.g., (Moens and Steedman 1988), (Passoneau 1988), (Webber 1988), (Hwang 1992), (Song and Cohen 1991), that has focused on a computational analysis of tense and aspect.
(Mani and Wilson, 2000) use a heuristic method for this task, while (Ahn et al, 2005b) use a machine learned classifier. $$$$$ The algorithm, which is relatively knowledge-poor, uses a mix of hand-crafted and machine-learnt rules and obtains reasonable results.

The feature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000). $$$$$ Finally, there is a large body of work, e.g., (Moens and Steedman 1988), (Passoneau 1988), (Webber 1988), (Hwang 1992), (Song and Cohen 1991), that has focused on a computational analysis of tense and aspect.
The feature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000). $$$$$ For example, “last week” might receive the VAL 20:00:W16.
The feature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000). $$$$$ The test data was marked by hand tagging the time expressions and assigning value to them where appropriate.
The feature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000). $$$$$ We introduce an annotation scheme for temporal expressions, and describe a method for resolving temporal expressions in print and broadcast news.

A natural way to go about update summarization would be extracting temporal tags (dates, elapsed times, temporal expressions...) (Mani and Wilson, 2000) or to automatically construct the timeline from documents (Swan and Allan, 2000). $$$$$ For example, in the following passage, “Thursday” is resolved to the Thursday prior to the reference date because “was”, which has a past tense tag, is found earlier in the sentence: The Iraqi news agency said the first shipment of 600,000 barrels was loaded Thursday by the oil tanker Edinburgh.
A natural way to go about update summarization would be extracting temporal tags (dates, elapsed times, temporal expressions...) (Mani and Wilson, 2000) or to automatically construct the timeline from documents (Swan and Allan, 2000). $$$$$ Some initial steps towards tagging event chronologies are also described.
A natural way to go about update summarization would be extracting temporal tags (dates, elapsed times, temporal expressions...) (Mani and Wilson, 2000) or to automatically construct the timeline from documents (Swan and Allan, 2000). $$$$$ The program passes each sentence first to a module that identifies time expressions, and then to another module (SC) that resolves selfcontained time expressions.
A natural way to go about update summarization would be extracting temporal tags (dates, elapsed times, temporal expressions...) (Mani and Wilson, 2000) or to automatically construct the timeline from documents (Swan and Allan, 2000). $$$$$ Our work in this area is highly preliminary.

In terms of hand-coded approaches, (Mani and Wilson 2000) used a baseline method of blindly propagating TempEx time values to events based on proximity, obtaining 59.4% on a small sample of 8,505 words of text. $$$$$ More recently, (Setzer and Gaizauskas 2000) have independently developed an annotation scheme which represents both time values and more fine-grained interevent and event-time temporal relations.
In terms of hand-coded approaches, (Mani and Wilson 2000) used a baseline method of blindly propagating TempEx time values to events based on proximity, obtaining 59.4% on a small sample of 8,505 words of text. $$$$$ However, at least 30% of the dates and times in the MUC test were fixed-format ones occurring in document headers, trailers, and copyright notices. )
In terms of hand-coded approaches, (Mani and Wilson 2000) used a baseline method of blindly propagating TempEx time values to events based on proximity, obtaining 59.4% on a small sample of 8,505 words of text. $$$$$ Finally, expressions which are ambiguous without a strongly preferred reading are left without a value.
In terms of hand-coded approaches, (Mani and Wilson 2000) used a baseline method of blindly propagating TempEx time values to events based on proximity, obtaining 59.4% on a small sample of 8,505 words of text. $$$$$ There were two different genres used in the testing: print news and broadcast news transcripts.

The use of machine learning techniques — mainly statistical — for this task is a more recent development, either alongside the traditional hand-grammar approach to learn to distinguish specific difficult cases (Mani and Wilson, 2000), or on its own (Hacioglu et al., 2005). $$$$$ In turn, when a time expression is found, the immediately previous verb lacking a time expression is given that expression's VAL as its TIME.
The use of machine learning techniques — mainly statistical — for this task is a more recent development, either alongside the traditional hand-grammar approach to learn to distinguish specific difficult cases (Mani and Wilson, 2000), or on its own (Hacioglu et al., 2005). $$$$$ As noted earlier, distinguishing between specific use of a time expression and a generic use (e.g., “today”, “now”, etc.) was and is a significant source of error.
The use of machine learning techniques — mainly statistical — for this task is a more recent development, either alongside the traditional hand-grammar approach to learn to distinguish specific difficult cases (Mani and Wilson, 2000), or on its own (Hacioglu et al., 2005). $$$$$ We also hope to handle a wider class of time expressions, as well as further improve our extraction and evaluation of event chronologies.

Mani and Wilson (2000) worked on news and introduced an annotation scheme for temporal expressions, and a method for using explicit temporal expressions to assign activity times to the entirety of an article. $$$$$ We have developed a temporal annotation specification, and an algorithm for resolving a class of time expressions found in news.
Mani and Wilson (2000) worked on news and introduced an annotation scheme for temporal expressions, and a method for using explicit temporal expressions to assign activity times to the entirety of an article. $$$$$ Some initial steps towards tagging event chronologies are also described.
Mani and Wilson (2000) worked on news and introduced an annotation scheme for temporal expressions, and a method for using explicit temporal expressions to assign activity times to the entirety of an article. $$$$$ The DP module uses an ordered sequence of rules to handle the context-dependent expressions.
Mani and Wilson (2000) worked on news and introduced an annotation scheme for temporal expressions, and a method for using explicit temporal expressions to assign activity times to the entirety of an article. $$$$$ We do not tag unanchored intervals, such as “half an hour (long)” or “(for) one month”.

Mani and Wilson (2000) attribute over half the errors of their baseline method to propagation of an incorrect event time to neighboring events. $$$$$ A total of 44 errors were made in the identification of TIMEX expressions.
Mani and Wilson (2000) attribute over half the errors of their baseline method to propagation of an incorrect event time to neighboring events. $$$$$ In the last step after years of preparation, the countries <lex eindex=“9” precedes=“10|” TIME=“19981231”>locked</lex> in the exchange rates of their individual currencies to the euro, thereby <lex eindex=“10” TIME=“19981231”>setting</lex> the value at which the euro will begin <lex eindex=“11” TIME=“19990104”>trading</lex> when financial markets open
Mani and Wilson (2000) attribute over half the errors of their baseline method to propagation of an incorrect event time to neighboring events. $$$$$ Finally, there is a large body of work, e.g., (Moens and Steedman 1988), (Passoneau 1988), (Webber 1988), (Hwang 1992), (Song and Cohen 1991), that has focused on a computational analysis of tense and aspect.
Mani and Wilson (2000) attribute over half the errors of their baseline method to propagation of an incorrect event time to neighboring events. $$$$$ Over half the errors were due to propagation of spreading of an incorrect event time to neighboring events; about 15% of the errors were due to event times preceding the initial TIMEX expression (here the initial reference time should have been used); and at least 10% of the errors were due to explicitly marked tense switches.

It was cited in (Mani and Wilson 2000) as achieving a .83 F-measure against hand-annotated data. $$$$$ 14 of the 138 errors (9 NYT vs. 5 VOA) were due to the document date being incorrect as a reference time.
It was cited in (Mani and Wilson 2000) as achieving a .83 F-measure against hand-annotated data. $$$$$ Note that if the human said the TIMEX had no value, and the system decided it had a value, this is treated as an error.
It was cited in (Mani and Wilson 2000) as achieving a .83 F-measure against hand-annotated data. $$$$$ “nineteen seventynine”.
