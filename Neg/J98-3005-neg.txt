 $$$$$ FUF is a functional unification formalism that uses a large systemic grammar of English, called SURGE, to fill in syntactic constraints, build a syntactic tree, choose closed class words, and eventually linearize the tree as a sentence.
 $$$$$ These planning operators are empirically based, coming from analysis of existing summaries, and allow for the generation of concise briefings.
 $$$$$ While useful in general, sentence extraction approaches cannot handle the task that we address, aggregate summarization across multiple documents, since this requires reasoning about similarities and differences across documents to produce generalizations or contradictions at a conceptual level.
 $$$$$ Our framework allows for experimentation with summaries of different lengths and for the combination of multiple, independent summary operators to produce more complex summaries with added descriptions.

For examples of work in producing abstract-like summaries, see Radev and McKeown (1998), which combines work in information extraction and natural language processing. $$$$$ A description of the operators we identified in our corpus follows, accompanied by an example of system output for each operator.
For examples of work in producing abstract-like summaries, see Radev and McKeown (1998), which combines work in information extraction and natural language processing. $$$$$ One of the more important current goals is to increase coverage of the system by providing interfaces to a large number of on-line sources of news.
For examples of work in producing abstract-like summaries, see Radev and McKeown (1998), which combines work in information extraction and natural language processing. $$$$$ Descriptions are then categorized using the WordNet hierarchy.

Radev and McKeown (1998) point out when summarizing interesting news events from multiple sources, one can expect reports with contradictory and redundant information. $$$$$ These planning operators are empirically based, coming from analysis of existing summaries, and allow for the generation of concise briefings.
Radev and McKeown (1998) point out when summarizing interesting news events from multiple sources, one can expect reports with contradictory and redundant information. $$$$$ In the remainder of this section, we highlight the novel techniques of SUMMONS and explain why they are important for our work.
Radev and McKeown (1998) point out when summarizing interesting news events from multiple sources, one can expect reports with contradictory and redundant information. $$$$$ FUF is a functional unification formalism that uses a large systemic grammar of English, called SURGE, to fill in syntactic constraints, build a syntactic tree, choose closed class words, and eventually linearize the tree as a sentence.
Radev and McKeown (1998) point out when summarizing interesting news events from multiple sources, one can expect reports with contradictory and redundant information. $$$$$ A feature of our work is the extraction of descriptions of entities such as people and places for reuse to enhance a briefing.

Notable systems are SUMMONS (Radev and McKeown, 1998). $$$$$ The right side of the figure shows how proper nouns and their descriptions are extracted from past news.
Notable systems are SUMMONS (Radev and McKeown, 1998). $$$$$ This work was partially supported by NSF grants GER-90-24069, IRI-96-19124, IRI-96-18797, and CDA-96-25374, as well as a grant from Columbia University's Strategic Initiative Fund sponsored by the Provost's Office.
Notable systems are SUMMONS (Radev and McKeown, 1998). $$$$$ The lexical chooser also receives input from the World Factbook and possible descriptions of people or organizations to augment the base summary The full content is then passed through a sentence generator, implemented using the FUF / SURGE language generation system (Elhadad 1993; Robin 1994).
Notable systems are SUMMONS (Radev and McKeown, 1998). $$$$$ The four news articles are transformed into four templates that correspond to four separate accounts of two related events and will be included in the set of templates from which the template combiner will work.

While template-based representations have been proposed for information merging in the past (Radev and McKeown, 1998), they considered only domain-specific scenarios. $$$$$ In the absence of values indicating the reliability of the sources, a summary cannot report either of them as true, but can indicate that the facts are not clear.
While template-based representations have been proposed for information merging in the past (Radev and McKeown, 1998), they considered only domain-specific scenarios. $$$$$ This helps to alleviate the otherwise knowledge-intensive nature of the task.
While template-based representations have been proposed for information merging in the past (Radev and McKeown, 1998), they considered only domain-specific scenarios. $$$$$ The system extracts data from the different sources and then combines it into a conceptual representation of the summary.
While template-based representations have been proposed for information merging in the past (Radev and McKeown, 1998), they considered only domain-specific scenarios. $$$$$ ZEDDoc (Passormeau et al. 1997; Kukich et al.

the main previous body of work on biographical summarization is that of (Radev and McKeown 1998). $$$$$ The prototype system that we have developed serves as the springboard for research in a variety of directions.
the main previous body of work on biographical summarization is that of (Radev and McKeown 1998). $$$$$ Given that no alternative approaches to conceptual summarization of multiple articles exist, we have found it very hard to perform an adequate evaluation of the summaries generated by SUMMONS.
the main previous body of work on biographical summarization is that of (Radev and McKeown 1998). $$$$$ 4.3.1 Change of Perspective.
the main previous body of work on biographical summarization is that of (Radev and McKeown 1998). $$$$$ Currently, we have incorporated facilities to various live news streams, the CIA World Factbook, and past newspaper archives.

This is particularly problematic in the case of multi-document summarization, where sentences extracted from related documents are very likely to express similar information in different ways (Radev and McKeown, 1998). $$$$$ First and foremost is the need to use statistical techniques to increase the robustness and vocabulary of the system.
This is particularly problematic in the case of multi-document summarization, where sentences extracted from related documents are very likely to express similar information in different ways (Radev and McKeown, 1998). $$$$$ Facilities are used to provide a transparent interface to heterogeneous data sources that run on several machines and may be written in different programming languages.
This is particularly problematic in the case of multi-document summarization, where sentences extracted from related documents are very likely to express similar information in different ways (Radev and McKeown, 1998). $$$$$ This has been successful in different domains (Preston and Williams 1994) and is, in fact, the approach used in recent commercial summarizers (Apple [Boguraev and Kennedy 1997], Microsoft, and in)(ight).
This is particularly problematic in the case of multi-document summarization, where sentences extracted from related documents are very likely to express similar information in different ways (Radev and McKeown, 1998). $$$$$ There are no clear answers to these questions.

Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ Facilities are used to provide a transparent interface to heterogeneous data sources that run on several machines and may be written in different programming languages.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ The system that we developed, SUMMONS, uses the output of systems developed for the DARPA Message Understanding Conferences to generate summaries of multiple documents on the same or related events, presenting similarities and differences, contradictions, and generalizations among sources of information.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ We describe the various components of the system, showing how information from multiple articles is combined, organized into a paragraph, and finally, realized as English sentences.
Existing work in abstractive summarization has been quite limited and can be categorized into two categories $$$$$ The authors are grateful to the following people for their invaluable comments during the writing of the paper and at presentations of work related to the content of the paper: Alfred Aho, Shih-Fu Chang, Eleazar Eskin, Vasileios Hatzivassiloglou, Alejandro Jaimes, Hongyan Jing, Judith Klavans, Min-Yen Kan, Carl Sable, Eric Siegel, John Smith, Nina Wacholder, Kazi Zaman as well as the anonymous reviewers and the editors of the special issue on natural language generation.

Since data producing these summaries can be sourced in different documents, summary fusion techniques as proposed in (Radev and McKeown, 1998) can be employed. $$$$$ It builds a first draft using fixed information that must appear in the summary (e.g., in basketball summaries, the score and who won and lost is always present).
Since data producing these summaries can be sourced in different documents, summary fusion techniques as proposed in (Radev and McKeown, 1998) can be employed. $$$$$ In the first one, we have to pick one single description from the database that best fits the summary we are generating.
Since data producing these summaries can be sourced in different documents, summary fusion techniques as proposed in (Radev and McKeown, 1998) can be employed. $$$$$ We show how planning operators can be used to synthesize summary content from a set of templates, each representing a single article.
Since data producing these summaries can be sourced in different documents, summary fusion techniques as proposed in (Radev and McKeown, 1998) can be employed. $$$$$ Our prototype system demonstrates the feasibility of generating briefings of a series of domain-specific news articles on the same event, highlighting changes over time as well as similarities and differences among sources and including some historical information about the participants.

Since (Radev and McKeown, 1998) describes the summary fusion mechanisms, Class 3 of questions can be reduced in this paper to Class 2, which deals with the processing of the template. $$$$$ This is useful if a summary discusses events related to one description associated with the entity more than the others.
Since (Radev and McKeown, 1998) describes the summary fusion mechanisms, Class 3 of questions can be reduced in this paper to Class 2, which deals with the processing of the template. $$$$$ 4.4.4 Discourse Planning.
Since (Radev and McKeown, 1998) describes the summary fusion mechanisms, Class 3 of questions can be reduced in this paper to Class 2, which deals with the processing of the template. $$$$$ We conclude this article in Sections 7 and 8 by describing some directions for future work in symbolic summarization of heterogeneous sources.
Since (Radev and McKeown, 1998) describes the summary fusion mechanisms, Class 3 of questions can be reduced in this paper to Class 2, which deals with the processing of the template. $$$$$ We have also implemented the modules to connect to the World Factbook.

(Radev and McKeown, 1998) and (Harabagiu and Lacatusu, 2004) define agreement (when two sources report the same information), addition (when a second source reports additional information), contradiction (when two sources report conflicting information). $$$$$ 1995).
(Radev and McKeown, 1998) and (Harabagiu and Lacatusu, 2004) define agreement (when two sources report the same information), addition (when a second source reports additional information), contradiction (when two sources report conflicting information). $$$$$ To avoid repetitiveness, such a system will have to resort to using different descriptions (as well as referring expressions) to address a specific entity.'
(Radev and McKeown, 1998) and (Harabagiu and Lacatusu, 2004) define agreement (when two sources report the same information), addition (when a second source reports additional information), contradiction (when two sources report conflicting information). $$$$$ Marcu (1997) uses a rhetorical parser to build rhetorical structure trees for arbitrary texts and produces a summary by extracting sentences that span the major rhetorical nodes of the tree.
(Radev and McKeown, 1998) and (Harabagiu and Lacatusu, 2004) define agreement (when two sources report the same information), addition (when a second source reports additional information), contradiction (when two sources report conflicting information). $$$$$ There are no clear answers to these questions.

Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). $$$$$ The next two sections describe in more detail how a base summary is generated from multiple source articles and how the base summary is extended using descriptions extracted from on-line sources.
Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). $$$$$ We collect such descriptions from on-line sources of past news and represent them using our generation formalism for reuse in later generation of summaries.
Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). $$$$$ By using automated, statistical techniques to find additional phrases, we could increase the size of the lexicon and use the additional phrases to identify new summarization strategies to add to our stock of operators.
Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). $$$$$ 1994), the use of extensive name lists, place names, titles and &quot;gazetteers&quot; in conjunction with partial grammars in order to recognize proper nouns as unknown words in close proximity to known words (Cowie et al. 1992; Aberdeen et al.

These include comparing templates filled in by extracting information using specialized, domain specific knowledge sources from the document, and then generating natural language summaries from the templates (Radev and McKeown, 1998). $$$$$ It is important to notice that even though WordNet typically presents problems with disambiguation of words retrieved from arbitrary text, we don't have any trouble disambiguating arm in this case due to the constraints on the context in which it appears (as an apposition describing an entity).
These include comparing templates filled in by extracting information using specialized, domain specific knowledge sources from the document, and then generating natural language summaries from the templates (Radev and McKeown, 1998). $$$$$ During training, the system uses abstracts of existing articles to identify the features of sentences that are typically included in abstracts.
These include comparing templates filled in by extracting information using specialized, domain specific knowledge sources from the document, and then generating natural language summaries from the templates (Radev and McKeown, 1998). $$$$$ By relying on these systems, the task we have addressed to date is happily more restricted than direct summarization of full text.
These include comparing templates filled in by extracting information using specialized, domain specific knowledge sources from the document, and then generating natural language summaries from the templates (Radev and McKeown, 1998). $$$$$ We have chosen the domain of news on terrorism for several reasons.

Similarly, Radev and McKeown (1998) used IE combined with Natural Language Generation (NLG) in their SUMMON system. $$$$$ The authors are grateful to the following people for their invaluable comments during the writing of the paper and at presentations of work related to the content of the paper: Alfred Aho, Shih-Fu Chang, Eleazar Eskin, Vasileios Hatzivassiloglou, Alejandro Jaimes, Hongyan Jing, Judith Klavans, Min-Yen Kan, Carl Sable, Eric Siegel, John Smith, Nina Wacholder, Kazi Zaman as well as the anonymous reviewers and the editors of the special issue on natural language generation.
Similarly, Radev and McKeown (1998) used IE combined with Natural Language Generation (NLG) in their SUMMON system. $$$$$ We describe the various components of the system, showing how information from multiple articles is combined, organized into a paragraph, and finally, realized as English sentences.
Similarly, Radev and McKeown (1998) used IE combined with Natural Language Generation (NLG) in their SUMMON system. $$$$$ We present a methodology for summarization of news about current events in the form of briefings that include appropriate background (historical) information.
Similarly, Radev and McKeown (1998) used IE combined with Natural Language Generation (NLG) in their SUMMON system. $$$$$ The database will have a defined interface that will allow for systems such as SUMMONS to connect to it.
