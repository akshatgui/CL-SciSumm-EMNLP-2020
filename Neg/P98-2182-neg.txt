We chose three clusters produced by a program similar to Roark and Charniak (1998) except that it is based on a generative probability model and tries to classify all nouns rather than just those in pre-selected clusters. $$$$$ Other categories that we investigated were crimes, people, commercial sites, states (as in static states of affairs), and machines.
We chose three clusters produced by a program similar to Roark and Charniak (1998) except that it is based on a generative probability model and tries to classify all nouns rather than just those in pre-selected clusters. $$$$$ Our algorithm finds more correct terms and fewer incorrect ones than previous work in this area.
We chose three clusters produced by a program similar to Roark and Charniak (1998) except that it is based on a generative probability model and tries to classify all nouns rather than just those in pre-selected clusters. $$$$$ Generically, their algorithm can be outlined as follows: Our algorithm uses roughly this same generic structure, but achieves notably superior results, by changing the specifics of: what counts as co-occurrence; which figures of merit to use for new seed word selection and final ranking; the method of initial seed word selection; and how to manage compound nouns.
We chose three clusters produced by a program similar to Roark and Charniak (1998) except that it is based on a generative probability model and tries to classify all nouns rather than just those in pre-selected clusters. $$$$$ Nouns are matched with their plurals in the corpus, and a single representation is settled upon for both, e.g. car(s).

This problem is addressed by Riloff and Shepherd (1997), Roark and Charniak (1998) and more recently by Widdows and Dorow (2002). $$$$$ semantic lexicons semiautomatically could be a great time saver, relative to creating them by hand.
This problem is addressed by Riloff and Shepherd (1997), Roark and Charniak (1998) and more recently by Widdows and Dorow (2002). $$$$$ Another option would be to use head nouns identified in Wordnet, which, as a set, should include the most common members of the category in question.
This problem is addressed by Riloff and Shepherd (1997), Roark and Charniak (1998) and more recently by Widdows and Dorow (2002). $$$$$ Co-Occurrence bigrams are collected for head nouns according to the notion of co-occurrence outlined above.

Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used co occurrence statistics in local context to discover sibling relations. $$$$$ We termed this phenomenon infection, and found that it can be so strong as to kill the further progress of a category.
Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used co occurrence statistics in local context to discover sibling relations. $$$$$ Effective lexicons must often include many domainspecific terms, so that available broad coverage resources, such as Wordnet (Miller, 1990), are inadequate.

Rilo and Shepherd (Rilo and Shepherd, 1997) developed a bootstrap ping algorithm that exploits lexical co-occurrence statistics, and Roark and Charniak (Roark and Charniak, 1998) re ned this algorithm to focus more explicitly on certain syntactic structures. $$$$$ Related words (e.g. crash for the category vehicle) did not count.
Rilo and Shepherd (Rilo and Shepherd, 1997) developed a bootstrap ping algorithm that exploits lexical co-occurrence statistics, and Roark and Charniak (Roark and Charniak, 1998) re ned this algorithm to focus more explicitly on certain syntactic structures. $$$$$ It, in turn, produced sparse results with the MUC-4 corpus.
Rilo and Shepherd (Rilo and Shepherd, 1997) developed a bootstrap ping algorithm that exploits lexical co-occurrence statistics, and Roark and Charniak (Roark and Charniak, 1998) re ned this algorithm to focus more explicitly on certain syntactic structures. $$$$$ As an illustration of this last condition, neither Galileo Probe nor gray plane is a valid entry, the former because it denotes an individual and the latter because it is a class of planes based upon an incidental feature (color).
Rilo and Shepherd (Rilo and Shepherd, 1997) developed a bootstrap ping algorithm that exploits lexical co-occurrence statistics, and Roark and Charniak (Roark and Charniak, 1998) re ned this algorithm to focus more explicitly on certain syntactic structures. $$$$$ This is done, in the spirit of the Dependency Model of Lauer (1995), by selecting the noun to its right in the compound with the highest probability of occuring with the word in question when occurring in a noun compound.

The main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular category, such as vehicles or weapons (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998). $$$$$ Additionally, the entries that are generated potentially provide broader coverage of the category than would occur to an individual coding them by hand.
The main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular category, such as vehicles or weapons (Riloff and Shepherd, 1997) (Roarkand Charniak, 1998). $$$$$ In evaluating the word nuclearpowered, it is unclear if this word is attached to aircraft or to carrier.

Roark and Charniak describe a "generic algorithm" for extracting such lists of similar words using the notion of semantic similarity, as follows (Roark and Charniak, 1998). $$$$$ (In the case that two nouns have the same probability, the rightmost noun is chosen.)
Roark and Charniak describe a "generic algorithm" for extracting such lists of similar words using the notion of semantic similarity, as follows (Roark and Charniak, 1998). $$$$$ Our algorithm finds more correct terms and fewer incorrect ones than previous work in this area.
Roark and Charniak describe a "generic algorithm" for extracting such lists of similar words using the notion of semantic similarity, as follows (Roark and Charniak, 1998). $$$$$ More generally, the relative success of the algorithm demonstrates the potential benefit of narrowing corpus input to specific kinds of constructions, despite the danger of compounding sparse data problems.

Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ In Riloff and Shepherd (1997), noun co-occurrence statistics were used to indicate nominal category membership, for the purpose of aiding in the construction of semantic lexicons.
Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ The method for evaluating whether or not to include a noun compound in the second list is intended to exclude constructions such as government plane and include constructions such as fighter plane.
Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ The non-head nouns in a compound noun may or may not be legitimate members of the category.
Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. $$$$$ semantic lexicons semiautomatically could be a great time saver, relative to creating them by hand.

Since lists are usually comprised of objects which are similar in some way, these relationships have been used to extract lists of nouns with similar properties (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). $$$$$ Additionally, the entries that are generated potentially provide broader coverage of the category than would occur to an individual coding them by hand.
Since lists are usually comprised of objects which are similar in some way, these relationships have been used to extract lists of nouns with similar properties (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). $$$$$ We have also examined in detail the reasons why it works, and have shown it to work well for multiple corpora and multiple categories.
Since lists are usually comprised of objects which are similar in some way, these relationships have been used to extract lists of nouns with similar properties (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). $$$$$ How does this compare to the noun fighter?

Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ Additionally, the entries that are generated potentially provide broader coverage of the category than would occur to an individual coding them by hand.
Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ Co-Occurrence bigrams are collected for head nouns according to the notion of co-occurrence outlined above.
Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ Co-Occurrence bigrams are collected for head nouns according to the notion of co-occurrence outlined above.
Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively. $$$$$ The log likelihood statistic, we found, is poorly suited to selecting new seed words in an iterative algorithm of this sort, because it promotes high frequency nouns, which can then overly influence selections in future iterations, if they are selected as seed words.

The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ In the word sense disambiguation task, no such claim is made: words can serve their disambiguating purpose regardless of part-of-speech or semantic characteristics.
The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ Utilizing existing resources, such as on-line corpora, to aid in this task could improve performance both by decreasing the time to construct the lexicon and by improving its quality.
The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ Whereas the R&S algorithm produced just 11 terms not already present in Wordnet for the two categories combined, our algorithm produced 106, or over 3 for every 5 valid terms produced.
The experiments in (Riloff and Shepherd, 1997) were performed on the 500,000 word MUC-4 corpus, and those of (Roark and Charniak, 1998) were performed using MUC-4 and the Wall Street Journal corpus (some 30 million words). $$$$$ More generally, the relative success of the algorithm demonstrates the potential benefit of narrowing corpus input to specific kinds of constructions, despite the danger of compounding sparse data problems.

The high accuracy achieved thus questions the conclusion drawn by Roark and Charniak (1998) that parsing is invaluable. $$$$$ If one of those weapons occurs frequently enough, the scores for the words that it co-occurs with may exceed those of any vehicles, and this effect may be strong enough that no vehicles are selected in any future iteration.
The high accuracy achieved thus questions the conclusion drawn by Roark and Charniak (1998) that parsing is invaluable. $$$$$ We have already mentioned that the simple ratio is ill suited to dealing with infrequent occurrences.
The high accuracy achieved thus questions the conclusion drawn by Roark and Charniak (1998) that parsing is invaluable. $$$$$ This is a sensible approach in any case, since it provides the broadest coverage of category occurrences, from which to select additional likely category members.
The high accuracy achieved thus questions the conclusion drawn by Roark and Charniak (1998) that parsing is invaluable. $$$$$ The relation is stipulated to be transitive, so that all head nouns in a list co-occur with each other (e.g. in the phrase planes, trains, and automobiles all three nouns are counted as co-occuring with each other).

Roark and Charniak (1998) used the co-occurrence of words as features to classify nouns. $$$$$ In this paper, we present an algorithm for extracting potential entries for a category from an on-line corpus, based upon a small set of exemplars.
Roark and Charniak (1998) used the co-occurrence of words as features to classify nouns. $$$$$ Our algorithm finds many terms not included within Wordnet (many more than previous algorithms), and could be viewed as an &quot;enhancer&quot; of existing broad-coverage resources.
Roark and Charniak (1998) used the co-occurrence of words as features to classify nouns. $$$$$ The algorithm then proceeds as follows:

The goal of extracting semantic information from text is well-established, and has encouraged work on lexical acquisition (Roark and Charniak, 1998), information extraction (Cardie, 1997), and ontology engineering (Hahn and Schnattinger, 1998). $$$$$ The input to the algorithm is a parsed corpus and a set of initial seed words for the desired category.
The goal of extracting semantic information from text is well-established, and has encouraged work on lexical acquisition (Roark and Charniak, 1998), information extraction (Cardie, 1997), and ontology engineering (Hahn and Schnattinger, 1998). $$$$$ For this purpose, we take two counts for each ,noun in the compound: For each non-head noun in the compound, we evaluate whether or not to omit it in the output.
The goal of extracting semantic information from text is well-established, and has encouraged work on lexical acquisition (Roark and Charniak, 1998), information extraction (Cardie, 1997), and ontology engineering (Hahn and Schnattinger, 1998). $$$$$ The rationale for using two different statistics for this task is that each is well suited for its particular role, and not particularly well suited to the other.

This may be explained by the fact that words appearing in conjunctions are often taxonomically similar (Roark and Charniak, 1998) and that taxonomic information is particularly useful for compound interpretation, as evidenced by the success of WordNet-based methods (see Section 5). $$$$$ Semantic lexicons play an important role in many natural language processing tasks.
This may be explained by the fact that words appearing in conjunctions are often taxonomically similar (Roark and Charniak, 1998) and that taxonomic information is particularly useful for compound interpretation, as evidenced by the success of WordNet-based methods (see Section 5). $$$$$ Our statistics allow for the inclusion of rare occcurances.
This may be explained by the fact that words appearing in conjunctions are often taxonomically similar (Roark and Charniak, 1998) and that taxonomic information is particularly useful for compound interpretation, as evidenced by the success of WordNet-based methods (see Section 5). $$$$$ We have outlined an algorithm in this paper that, as it stands, could significantly speed up the task of building a semantic lexicon.
This may be explained by the fact that words appearing in conjunctions are often taxonomically similar (Roark and Charniak, 1998) and that taxonomic information is particularly useful for compound interpretation, as evidenced by the success of WordNet-based methods (see Section 5). $$$$$ The input to the algorithm is a parsed corpus and a set of initial seed words for the desired category.

To select seed words, we used the procedure proposed by Roark and Charniak (1998), ranking all of the head nouns in the training corpus by frequency and manually selecting the first 10 nouns that unambiguously belong to each category. $$$$$ We have also examined in detail the reasons why it works, and have shown it to work well for multiple corpora and multiple categories.
To select seed words, we used the procedure proposed by Roark and Charniak (1998), ranking all of the head nouns in the training corpus by frequency and manually selecting the first 10 nouns that unambiguously belong to each category. $$$$$ The first question that must be answered in investigating this task is why one would expect it to work at all.
To select seed words, we used the procedure proposed by Roark and Charniak (1998), ranking all of the head nouns in the training corpus by frequency and manually selecting the first 10 nouns that unambiguously belong to each category. $$$$$ semantic lexicons semiautomatically could be a great time saver, relative to creating them by hand.

 $$$$$ To this end, parsing is invaluable.
 $$$$$ Effective lexicons must often include many domainspecific terms, so that available broad coverage resources, such as Wordnet (Miller, 1990), are inadequate.
 $$$$$ Table 1 shows the seed words that were used for some of the categories tested.

For example, Hearst (Hearst, 1992) learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as NP, NP, and other NPs, and Roarkand Charniak (Roark and Charniak, 1998) generated semantically related words by applying statistical measures to syntactic contexts involving appositives, lists, and conjunctions. $$$$$ Another option would be to use head nouns identified in Wordnet, which, as a set, should include the most common members of the category in question.
For example, Hearst (Hearst, 1992) learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as NP, NP, and other NPs, and Roarkand Charniak (Roark and Charniak, 1998) generated semantically related words by applying statistical measures to syntactic contexts involving appositives, lists, and conjunctions. $$$$$ We made the simplifying assumption that the higher the probability of the head given the non-head noun, the better the construction for our purposes.
For example, Hearst (Hearst, 1992) learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as NP, NP, and other NPs, and Roarkand Charniak (Roark and Charniak, 1998) generated semantically related words by applying statistical measures to syntactic contexts involving appositives, lists, and conjunctions. $$$$$ The two figures of merit that we employ, one to select and one to produce a final rank, use the following two counts for each noun: To select new seed words, we take the ratio of count 1 to count 2 for the noun in question.
For example, Hearst (Hearst, 1992) learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as NP, NP, and other NPs, and Roarkand Charniak (Roark and Charniak, 1998) generated semantically related words by applying statistical measures to syntactic contexts involving appositives, lists, and conjunctions. $$$$$ The input to the algorithm is a parsed corpus and a set of initial seed words for the desired category.

In previous research on semantic lexicon induction, Roark and Charniak (Roark and Charniak, 1998) showed that 3 of every 5 words learned by their system were not present in WordNet. $$$$$ The input to the algorithm is a parsed corpus and a set of initial seed words for the desired category.
In previous research on semantic lexicon induction, Roark and Charniak (Roark and Charniak, 1998) showed that 3 of every 5 words learned by their system were not present in WordNet. $$$$$ The first question that must be answered in investigating this task is why one would expect it to work at all.
In previous research on semantic lexicon induction, Roark and Charniak (Roark and Charniak, 1998) showed that 3 of every 5 words learned by their system were not present in WordNet. $$$$$ Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation (Schiitze, 1992; Gale et al., 1992; Yarowsky, 1995).
In previous research on semantic lexicon induction, Roark and Charniak (Roark and Charniak, 1998) showed that 3 of every 5 words learned by their system were not present in WordNet. $$$$$ Their figure of merit was simply the ratio of the times the noun coocurs with a noun in the seed list to the total frequency of the noun in the corpus.

Roark and Charniak (Roark and Charniak, 1998) followed up on this work by using a parser to explicitly capture these structures. $$$$$ Two head nouns co-occur in this algorithm if they meet the following four conditions: In contrast, R&S counted the closest noun to the left and the closest noun to the right of a head noun as co-occuring with it.
Roark and Charniak (Roark and Charniak, 1998) followed up on this work by using a parser to explicitly capture these structures. $$$$$ The algorithm generates many words not included in broad coverage resources, such as Wordnet, and could be thought of as a Wordnet &quot;enhancer&quot; for domain-specific applications.
Roark and Charniak (Roark and Charniak, 1998) followed up on this work by using a parser to explicitly capture these structures. $$$$$ We have also examined in detail the reasons why it works, and have shown it to work well for multiple corpora and multiple categories.

Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. $$$$$ Co-Occurrence bigrams are collected for head nouns according to the notion of co-occurrence outlined above.
Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. $$$$$ semantic lexicons semiautomatically could be a great time saver, relative to creating them by hand.
Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. $$$$$ The non-head nouns in a compound noun may or may not be legitimate members of the category.
