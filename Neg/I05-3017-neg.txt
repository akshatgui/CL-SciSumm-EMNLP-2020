In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using CRFs for the IOB tagging, yielded a very high R-oov in all of the four corpora used, but the R-iv rates were lower. $$$$$ These data indicate that OOV handling is still the Achilles heel of segmentation systems, even when the OOV rates are relatively small.
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using CRFs for the IOB tagging, yielded a very high R-oov in all of the four corpora used, but the R-iv rates were lower. $$$$$ With one exception, all of the corpora wereprovided in a single character encoding.
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using CRFs for the IOB tagging, yielded a very high R-oov in all of the four corpora used, but the R-iv rates were lower. $$$$$ The Traditional Chinese corpora were provided by Academia Sinica in Taiwan and the City University of Hong Kong.

The experiments of closed tests on the second SIGHAN Bakeoff (Emerson, 2005) show that the joint model significantly outperforms the baseline models of both generative and discriminative approaches. $$$$$ Each provider supplied separate training andtruth data sets.
The experiments of closed tests on the second SIGHAN Bakeoff (Emerson, 2005) show that the joint model significantly outperforms the baseline models of both generative and discriminative approaches. $$$$$ Partici pants were asked to submit their data using very strict naming conventions to facilitate this: inonly a couple of instances were these not fol lowed and human intervention was required.
The experiments of closed tests on the second SIGHAN Bakeoff (Emerson, 2005) show that the joint model significantly outperforms the baseline models of both generative and discriminative approaches. $$$$$ However, it has been made available (both training and truth data) on the SIGHAN website along with the other corpora.

The corpora provided by the second SIGHAN Bakeoff (Emerson, 2005) were used in our experiments. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
The corpora provided by the second SIGHAN Bakeoff (Emerson, 2005) were used in our experiments. $$$$$ Sites were allowed submit multiple runs within a track, allowing them to compare various approaches.
The corpora provided by the second SIGHAN Bakeoff (Emerson, 2005) were used in our experiments. $$$$$ We de cided to provide all of the data in both Unicode (UTF-8 encoding) and the standard encoding used in each locale.

For more detailed information on the corpora, refer to Emerson (2005). $$$$$ This word segmentation problem has been active areaof research in computational linguistics for almost two decades and is a topic of active re search around the world.
For more detailed information on the corpora, refer to Emerson (2005). $$$$$ Inc. Aitao CHEN US "!
For more detailed information on the corpora, refer to Emerson (2005). $$$$$ 13 Nanjing University Jiajun CHEN ZH "!

Four training and testing corpora were used in the second bakeoff (Emerson, 2005), including the Academia Sinica corpus (AS), the Hong Kong City University Corpus (CU), the Peking University Corpus (PK) and the Microsoft Research Corpus (MR). $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
Four training and testing corpora were used in the second bakeoff (Emerson, 2005), including the Academia Sinica corpus (AS), the Hong Kong City University Corpus (CU), the Peking University Corpus (PK) and the Microsoft Research Corpus (MR). $$$$$ They then had two days to process the test corpora and return them to the organizer via email on Jul 29 for scoring.
Four training and testing corpora were used in the second bakeoff (Emerson, 2005), including the Academia Sinica corpus (AS), the Hong Kong City University Corpus (CU), the Peking University Corpus (PK) and the Microsoft Research Corpus (MR). $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.

We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang et al (2006) for comparison. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang et al (2006) for comparison. $$$$$ 123 pages on the SIGHAN website.
We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang et al (2006) for comparison. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang et al (2006) for comparison. $$$$$ can be very complex.

SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, successfully conducted four prior word segmentation bakeoffs, in 2003 (Sproat and Emerson, 2003), 2005 (Emerson, 2005), 2006 (Levow, 2006) and 2007 (Jin and Chen, 2007), and the bakeoff 2007 was jointly organized with the Chinese Information Processing Society of China (CIPS). $$$$$ The Corpora Four corpora were used in the evaluation, two each using Simplified and Traditional Chinese characters.1 The Simplified Chinese corporawere provided by Beijing University and Micro soft Research Beijing.
SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, successfully conducted four prior word segmentation bakeoffs, in 2003 (Sproat and Emerson, 2003), 2005 (Emerson, 2005), 2006 (Levow, 2006) and 2007 (Jin and Chen, 2007), and the bakeoff 2007 was jointly organized with the Chinese Information Processing Society of China (CIPS). $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.
SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, successfully conducted four prior word segmentation bakeoffs, in 2003 (Sproat and Emerson, 2003), 2005 (Emerson, 2005), 2006 (Levow, 2006) and 2007 (Jin and Chen, 2007), and the bakeoff 2007 was jointly organized with the Chinese Information Processing Society of China (CIPS). $$$$$ The People?s Republic of China had the greatest number with 17, followed by the United States (6), Hong Kong (5), Taiwan (3), six others with one each.

In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower. $$$$$ Participant Run ID Word Count R Cr P Cp F OOV Roov Riv 14 106873 0.962 ?0.00117 0.966 ?0.00111 0.964 0.026 0.717 0.968 7 106873 0.962 ?0.00117 0.962 ?0.00117 0.962 0.026 0.592 0.972 27 a 106873 0.969 ?0.00106 0.952 ?0.00131 0.960 0.026 0.379 0.985 27 b 106873 0.968 ?0.00108 0.953 ?0.00129 0.960 0.026 0.381 0.984 4 106873 0.973 ?0.00099 0.945 ?0.00139 0.959 0.026 0.323 0.991 15 b 106873 0.952 ?0.00131 0.964 ?0.00114 0.958 0.026 0.718 0.958 5 106873 0.974 ?0.00097 0.940 ?0.00145 0.957 0.026 0.21 0.995 13 106873 0.959 ?0.00121 0.956 ?0.00125 0.957 0.026 0.496 0.972 12 106873 0.952 ?0.00131 0.960 ?0.00120 0.956 0.026 0.673 0.96 24 6 106873 0.958 ?0.00123 0.952 ?0.00131 0.955 0.026 0.503 0.97 24 7 106873 0.958 ?0.00123 0.952 ?0.00131 0.955 0.026 0.504 0.97 24 4 106873 0.958 ?0.00123 0.949 ?0.00135 0.954 0.026 0.465 0.972 24 5 106873 0.958 ?0.00123 0.951 ?0.00132 0.954 0.026 0.493 0.971 24 3 106873 0.968 ?0.00108 0.938 ?0.00148 0.953 0.026 0.205 0.989 33 106873 0.965 ?0.00112 0.935 ?0.00151 0.950 0.026 0.189 0.986 15 a 106873 0.955 ?0.00127 0.942 ?0.00143 0.949 0.026 0.378 0.971 21 106873 0.945 ?0.00139 0.949 ?0.00135 0.947 0.026 0.576 0.955 24 0 106873 0.956 ?0.00125 0.938 ?0.00148 0.947 0.026 0.327 0.973 34 106873 0.948 ?0.00136 0.942 ?0.00143 0.945 0.026 0.664 0.955 24 2 106873 0.964 ?0.00114 0.924 ?0.00162 0.944 0.026 0.025 0.989 15 c 106873 0.964 ?0.00114 0.923 ?0.00163 0.943 0.026 0.025 0.99 24 1 106873 0.963 ?0.00115 0.924 ?0.00162 0.943 0.026 0.025 0.989 29 a 106873 0.946 ?0.00138 0.933 ?0.00153 0.939 0.026 0.587 0.956 29 b 106873 0.941 ?0.00144 0.932 ?0.00154 0.937 0.026 0.624 0.95 8 b 106873 0.957 ?0.00124 0.917 ?0.00169 0.936 0.026 0.025 0.982 8 c 106873 0.955 ?0.00127 0.915 ?0.00171 0.935 0.026 0.025 0.98 26 106873 0.937 ?0.00149 0.928 ?0.00158 0.932 0.026 0.457 0.95 8 a 106873 0.898 ?0.00185 0.896 ?0.00187 0.897 0.026 0.327 0.914 Table 9: Microsoft Research ? Closed (italics indicate performance below baseline) 129 4!
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower. $$$$$ This shows a general trend to a decrease in error rates, from 3.9% to 2.8%!
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower. $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower. $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.

For detailed info. of the corpora and these scores, refer to (Emerson, 2005). $$$$$ This value appears in subsequent tables under the column cr.
For detailed info. of the corpora and these scores, refer to (Emerson, 2005). $$$$$ The best OOV recall in the open evaluation was 0.872 compared to just 0.813 on the closed track.

SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, conducted two prior word segmentation bakeoffs, in 2003 and 2005 (Emerson, 2005), which established benchmarks for word segmentation against which other systems are judged. $$$$$ During the winter of 2004 it was decided to hold a second evaluation to determine how the latest research has affected segmentation technology.
SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, conducted two prior word segmentation bakeoffs, in 2003 and 2005 (Emerson, 2005), which established benchmarks for word segmentation against which other systems are judged. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, conducted two prior word segmentation bakeoffs, in 2003 and 2005 (Emerson, 2005), which established benchmarks for word segmentation against which other systems are judged. $$$$$ This shows a general trend to a decrease in error rates, from 3.9% to 2.8%!

As an evidence, the CWS evaluation campaign, the Sighan Bakeoff (Emerson, 2005) has been held four times since 2004. $$$$$ On July 11 the training data was made available on the Bakeoff website for downloading: the same data was used regardless of the tracks the sites registered for.
As an evidence, the CWS evaluation campaign, the Sighan Bakeoff (Emerson, 2005) has been held four times since 2004. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
As an evidence, the CWS evaluation campaign, the Sighan Bakeoff (Emerson, 2005) has been held four times since 2004. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.

These specs were used in the second Sighan Bakeoff (Emerson, 2005). $$$$$ 2.3!
These specs were used in the second Sighan Bakeoff (Emerson, 2005). $$$$$ We calculated these values at the 95% confidence interval with the formula ?2 !(p Participant Run ID Word Count R Cr P Cp F OOV Roov Riv 14 40936 0.941 ?0.00233 0.946 ?0.00223 0.943 0.074 0.698 0.961 15 a 40936 0.942 ?0.00231 0.941 ?0.00233 0.942 0.074 0.629 0.967 15 b 40936 0.937 ?0.00240 0.946 ?0.00223 0.941 0.074 0.736 0.953 27 40936 0.949 ?0.00217 0.931 ?0.00251 0.94 0.074 0.561 0.98 7 40936 0.944 ?0.00227 0.933 ?0.00247 0.939 0.074 0.626 0.969 12 40936 0.931 ?0.00251 0.941 ?0.00233 0.936 0.074 0.657 0.953 29 d 40936 0.937 ?0.00240 0.922 ?0.00265 0.929 0.074 0.698 0.956 15 c 40936 0.915 ?0.00276 0.94 ?0.00235 0.928 0.074 0.598 0.94 29 a 40936 0.938 ?0.00238 0.915 ?0.00276 0.927 0.074 0.658 0.961 29 b 40936 0.936 ?0.00242 0.913 ?0.00279 0.925 0.074 0.656 0.959 21 40936 0.917 ?0.00273 0.925 ?0.00260 0.921 0.074 0.539 0.948 29 c 40936 0.925 ?0.00260 0.896 ?0.00302 0.91 0.074 0.639 0.948 4 40936 0.934 ?0.00245 0.865 ?0.00338 0.898 0.074 0.248 0.989 5 40936 0.932 ?0.00249 0.862 ?0.00341 0.895 0.074 0.215 0.989 Table 7: City University of Hong Kong ? Closed (italics indicate performance below baseline) Participant Run ID Word Count R Cr P Cp F OOV Roov Riv 19 40936 0.967 ?0.00177 0.956 ?0.00203 0.962 0.074 0.806 0.98 16 40936 0.958 ?0.00198 0.95 ?0.00215 0.954 0.074 0.775 0.973 27 40936 0.952 ?0.00211 0.937 ?0.00240 0.945 0.074 0.608 0.98 7 40936 0.944 ?0.00227 0.938 ?0.00238 0.941 0.074 0.667 0.966 12 40936 0.933 ?0.00247 0.94 ?0.00235 0.936 0.074 0.653 0.955 4 40936 0.946 ?0.00223 0.898 ?0.00299 0.922 0.074 0.417 0.989 5 40936 0.94 ?0.00235 0.901 ?0.00295 0.92 0.074 0.41 0.982 Table 8: City University of Hong Kong ? Open (italics indicate performance below baseline) 128 (1 - p)/n) where n is the number of words.
These specs were used in the second Sighan Bakeoff (Emerson, 2005). $$$$$ can be very complex.

The current state-of-the-art segmentation software developed by (Low et al, 2005), which ranks as the best in the SIGHAN bakeoff (Emerson, 2005), attains word precision and recall of 96.9% and 96.8%, respectively, on the PKU track. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
The current state-of-the-art segmentation software developed by (Low et al, 2005), which ranks as the best in the SIGHAN bakeoff (Emerson, 2005), attains word precision and recall of 96.9% and 96.8%, respectively, on the PKU track. $$$$$ That competition was the first con ducted outside of China and has become the benchmark with which researchers evaluate their segmentation systems.
The current state-of-the-art segmentation software developed by (Low et al, 2005), which ranks as the best in the SIGHAN bakeoff (Emerson, 2005), attains word precision and recall of 96.9% and 96.8%, respectively, on the PKU track. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.

We used the data provided by the second SIGHAN Bakeoff (Emerson, 2005) to test the two segmentation models. $$$$$ nology Masayuki ASAHARA JP " " " " 16 Academia Sinica Yu-Fang TSAI TW ! !.
We used the data provided by the second SIGHAN Bakeoff (Emerson, 2005) to test the two segmentation models. $$$$$ Participating SitesThirty-six sites representing 10 countries ini tially signed up for the bakeoff.
We used the data provided by the second SIGHAN Bakeoff (Emerson, 2005) to test the two segmentation models. $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.

In the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model. $$$$$ As in the previous evaluation, to test the confidence level that two trials are significantly different from each other we used the Central Limit Theorem for Bernoulli trials (Grinstead and Snell, 1997), assuming that the recall rates from the various trials represents the probability that a word will be successfully identified, and that a binomial distribution is appropriate for the experiment.
In the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model. $$$$$ can be very complex.
In the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model. $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.

The data used was the Microsoft Research Beijing corpus from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), and we used the same train/test split used in the competition. $$$$$ The best score on any track in the 2003 bakeoff was F=0.961, while the best for this evaluation was F=0.972, followed by 17 other scores above 0.961.
The data used was the Microsoft Research Beijing corpus from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), and we used the same train/test split used in the competition. $$$$$ Details on each corpus are pro vided in Table!1.
The data used was the Microsoft Research Beijing corpus from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), and we used the same train/test split used in the competition. $$$$$ A summary of participating groups and the tracks for which they submitted results can be found in Table!2 on the preceding page.

We did not explicitly test the utility of CRF-type features for improving recall on out-of-vocabulary items, but we note that in the Bakeoff, the model of Tseng et al (2005), which was very similar to our CRF-only system (only containing a few more feature templates), was consistently among the best performing systems in terms of test OOV recall (Emerson, 2005). $$$$$ 34 Institute of Computing Technology,.
We did not explicitly test the utility of CRF-type features for improving recall on out-of-vocabulary items, but we note that in the Bakeoff, the model of Tseng et al (2005), which was very similar to our CRF-only system (only containing a few more feature templates), was consistently among the best performing systems in terms of test OOV recall (Emerson, 2005). $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
We did not explicitly test the utility of CRF-type features for improving recall on out-of-vocabulary items, but we note that in the Bakeoff, the model of Tseng et al (2005), which was very similar to our CRF-only system (only containing a few more feature templates), was consistently among the best performing systems in terms of test OOV recall (Emerson, 2005). $$$$$ The CityU data was seg mented using the LIVAC corpus standard, and the MSR data to Microsoft's internal standard.

After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson, 2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as 'Achilles' that consists of four modules mainly $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.
After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson, 2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as 'Achilles' that consists of four modules mainly $$$$$ in Chinese is hotly debated, so thedetermination of the correct division of a Chi nese sentence into ?words?
After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson, 2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as 'Achilles' that consists of four modules mainly $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.

We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm. $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.
We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm. $$$$$ The scripts used for scoring can be downloaded from the Corpus Word Count R P F OOV Roov Riv AS 122,610 0.909 0.857 0.882 0.043 0.004 0.950 CityU 40936 0.882 0.790 0.833 0.074 0.000 0.952 MSR 106,873 0.955 0.912 0.933 0.026 0.000 0.981 PKU 104,372 0.904 0.836 0.869 0.058 0.059 0.956 Table 3: Baseline scores generated via maximal matching using only words from the training data Corpus Word Count R P F OOV Roov Riv AS 122,610 0.979 0.985 0.982 0.043 0.996 0.978 CityU 40,936 0.988 0.991 0.989 0.074 0.997 0.988 MSR 106,873 0.991 0.992 0.991 0.026 0.998 0.990 PKU 104,372 0.985 0.988 0.987 0.058 0.994 0.985 Table 4: Topline scores generated via maximal matching using only words from the testing data 126 Bakeoff 2005 web site.
We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm. $$$$$ The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.
We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm. $$$$$ Chinese is written without inter-word spaces, so finding word-boundaries is an essential first stepin many natural language processing applications including mono- and cross-lingual infor mation retrieval and text-to-speech systems.

The second benchmark that we adopted is the SIGHAN Bakeoff-2005 dataset (Emerson, 2005) for Chinese word segmentation. $$$$$ 3!
The second benchmark that we adopted is the SIGHAN Bakeoff-2005 dataset (Emerson, 2005) for Chinese word segmentation. $$$$$ As the very notion of ?word-hood?
The second benchmark that we adopted is the SIGHAN Bakeoff-2005 dataset (Emerson, 2005) for Chinese word segmentation. $$$$$ We found that the technol ogy has improved over the intervening two years, though the out-of-vocabularyproblem is still or paramount impor tance.
