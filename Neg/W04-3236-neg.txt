So we first segmented Chinese text with a Chinese word segmenter that was based on maximum entropy modeling (Ng and Low, 2004). $$$$$ Now that we have successfully built a state-ofthe-art Chinese word segmenter, we are ready to explore issues of processing architecture and feature representation for Chinese POS tagging.
So we first segmented Chinese text with a Chinese word segmenter that was based on maximum entropy modeling (Ng and Low, 2004). $$$$$ We analyze the performance of the different approaches in our attempt to find the best approach.
So we first segmented Chinese text with a Chinese word segmenter that was based on maximum entropy modeling (Ng and Low, 2004). $$$$$ This paper presents an in-depth study on such issues of processing architecture and feature representation for Chinese POS tagging, within a maximum entropy framework.
So we first segmented Chinese text with a Chinese word segmenter that was based on maximum entropy modeling (Ng and Low, 2004). $$$$$ While our investigation reveals that such an approach gives good accuracy, our findings however indicate that a one-at-a-time, character-based approach to POS tagging gave quite comparable accuracy, with the benefit of incurring much reduced computational cost.

If we extend these positional tags to include POS information ,segmentation and POS tagging can be performed by a single pass under a unify classification framework (Ng and Low, 2004). $$$$$ Figure 3: POS tagging accuracy using one-at-atime, word-based POS tagger The POS tagging accuracy is plotted in Figure 3.
If we extend these positional tags to include POS information ,segmentation and POS tagging can be performed by a single pass under a unify classification framework (Ng and Low, 2004). $$$$$ Similarly, character features were used to build a maximum entropy Chinese parser by (Luo, 2003), where his parser could perform word segmentation, POS tagging, and parsing in an integrated, unified approach.
If we extend these positional tags to include POS information ,segmentation and POS tagging can be performed by a single pass under a unify classification framework (Ng and Low, 2004). $$$$$ To our knowledge, our work is the first to systematically investigate such issues in Chinese POS tagging.

In the rest of the paper, we call this operation mode Joint S&T. Experiments of Ng and Low (2004) shown that, compared with performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging. $$$$$ Note that an all-atonce, word-based approach is not applicable as word segmentation requires character features to determine the word boundaries.
In the rest of the paper, we call this operation mode Joint S&T. Experiments of Ng and Low (2004) shown that, compared with performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging. $$$$$ Most corpus-based language processing research has focused on the English language.
In the rest of the paper, we call this operation mode Joint S&T. Experiments of Ng and Low (2004) shown that, compared with performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging. $$$$$ Zhou and Su (2003) investigated an approach to build a Chinese analyzer that integrated word segmentation, POS tagging and parsing, based on a hidden Markov model.
In the rest of the paper, we call this operation mode Joint S&T. Experiments of Ng and Low (2004) shown that, compared with performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging. $$$$$ However, the time required for training and testing is increased significantly for the all-atonce approach.

As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively. $$$$$ In addition, since the out-of-vocabulary (OOV) rate for Chinese words is much higher than the OOV rate for Chinese characters, in the presence of an unknown word, using the component characters in the word to help predict the correct POS tag is a good heuristic.
As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively. $$$$$ Applying it in the context of Chinese POS tagging, Ratnaparkhi’s method assumes that words are pre-segmented, and it assigns POS tags on a word-by-word basis, making use of word features in the surrounding context.
As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively. $$$$$ C−2W0 )POS(C−1W0 ) : For the same example given above, when considering the character “A”, the feature POS(C−2W0 )POS(C−1W0 ) =P_PN is set to 1 (assuming “对” was tagged as P and “k” was tagged as PN).

The features we use to build the classifier are generated from the templates of Ng and Low (2004). $$$$$ Using a character-based approach for Chinese POS tagging is more effective than a word-based approach.
The features we use to build the classifier are generated from the templates of Ng and Low (2004). $$$$$ Applying it in the context of Chinese POS tagging, Ratnaparkhi’s method assumes that words are pre-segmented, and it assigns POS tags on a word-by-word basis, making use of word features in the surrounding context.

The table's upper column lists the templates that immediately from Ng and Low (2004). $$$$$ 10-fold CV on CTB was carried out again, using unsegmented test sentences as input to the program.
The table's upper column lists the templates that immediately from Ng and Low (2004). $$$$$ However, in practice, the special characteristics of different languages introduce complications.
The table's upper column lists the templates that immediately from Ng and Low (2004). $$$$$ We found that while the all-at-once, characterbased approach is the best, the one-at-a-time, character-based approach is a worthwhile compromise, performing only slightly worse in terms of accuracy, but taking shorter time to train and run.

Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ng and Low, 2004). $$$$$ For example, the single Chinese character “0” means “know”.
Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ng and Low, 2004). $$$$$ In addition, since the out-of-vocabulary (OOV) rate for Chinese words is much higher than the OOV rate for Chinese characters, in the presence of an unknown word, using the component characters in the word to help predict the correct POS tag is a good heuristic.
Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ng and Low, 2004). $$$$$ W refers to a word while POS refers to the POS tag assigned.
Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ng and Low, 2004). $$$$$ Applying it in the context of Chinese POS tagging, Ratnaparkhi’s method assumes that words are pre-segmented, and it assigns POS tags on a word-by-word basis, making use of word features in the surrounding context.

Compared to performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging (Ng and Low, 2004). $$$$$ Figure 4 shows the detailed POS tagging accuracy.
Compared to performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging (Ng and Low, 2004). $$$$$ Unlike in English where each English letter by itself does not possess any meaning, many Chinese characters have well defined meanings.

Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types: b: the begin of the word m: the middle of the word e: the end of the word s: a single-character word. $$$$$ The feature Pu(W0) checks if all characters in the current word are punctuation characters.
Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types: b: the begin of the word m: the middle of the word e: the end of the word s: a single-character word. $$$$$ In Chinese, individual characters encode information that aids in POS tagging.
Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types: b: the begin of the word m: the middle of the word e: the end of the word s: a single-character word. $$$$$ The average training time taken to train on 90% of the 250K-word CTB was 12 minutes, while testing on 10% of CTB took about 1 minute.
Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types: b: the begin of the word m: the middle of the word e: the end of the word s: a single-character word. $$$$$ Luo presented a maximum entropy character-based parser, which as a consequence of parsing also performed word segmentation and POS tagging.

In order to perform POS tagging at the same time, we expand boundary tags to include POS information by attaching a POS to the tail of a boundary tag as a postfix following Ng and Low (2004). $$$$$ For Chinese in particular, words are not demarcated in a Chinese sentence.
In order to perform POS tagging at the same time, we expand boundary tags to include POS information by attaching a POS to the tail of a boundary tag as a postfix following Ng and Low (2004). $$$$$ However, in practice, the special characteristics of different languages introduce complications.

Templates immediately borrowed from Ng and Low (2004) are listed in the upper column named non-lexical-target. $$$$$ Table 1 summarizes the methods investigated in this paper.
Templates immediately borrowed from Ng and Low (2004) are listed in the upper column named non-lexical-target. $$$$$ : This feature refers to the POS tag of the previous character before the current word.
Templates immediately borrowed from Ng and Low (2004) are listed in the upper column named non-lexical-target. $$$$$ However, in practice, the special characteristics of different languages introduce complications.

Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ In Chinese, individual characters encode information that aids in POS tagging.
Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ POS tagging accuracy is simply calculated as (number of characters assigned correct POS tag) / (total number of characters).
Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ In Chinese, individual characters encode information that aids in POS tagging.
Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ However, since words are not demarcated in a Chinese sentence, Chinese POS tagging requires word segmentation as a prerequisite.

Similar trend appeared in experiments of Ng and Low (2004), where they conducted experiments on CTB 3.0 and achieved F measure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation. $$$$$ The features we used are identical to those employed in the character-based POS tagger described in section 4.1, except that features (g) and (h) are replaced with those listed below.
Similar trend appeared in experiments of Ng and Low (2004), where they conducted experiments on CTB 3.0 and achieved F measure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation. $$$$$ Language differences between English and Chinese have made direct porting of an English POS tagging method to Chinese ineffective.
Similar trend appeared in experiments of Ng and Low (2004), where they conducted experiments on CTB 3.0 and achieved F measure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation. $$$$$ Similarly, character features were used to build a maximum entropy Chinese parser by (Luo, 2003), where his parser could perform word segmentation, POS tagging, and parsing in an integrated, unified approach.
Similar trend appeared in experiments of Ng and Low (2004), where they conducted experiments on CTB 3.0 and achieved F measure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation. $$$$$ Figure 4: POS tagging accuracy using one-at-atime, character-based POS tagger When a paired t-test was carried out to compare character-based and word-based one-ata-time approaches, the character-based approach was found to be significantly better than the word-based approach, at the level of significance 0.01.

In addition, all knowledge sources we used in the core perceptron and the outside-layer linear model come from the training corpus, whereas many open knowledge sources (lexicon etc.) can be used to improve performance (Ng and Low, 2004). $$$$$ To build a Chinese POS tagger, the following questions naturally arise: This paper presents an in-depth study on such issues of processing architecture and feature representation for Chinese POS tagging, within a maximum entropy framework.
In addition, all knowledge sources we used in the core perceptron and the outside-layer linear model come from the training corpus, whereas many open knowledge sources (lexicon etc.) can be used to improve performance (Ng and Low, 2004). $$$$$ As part of our investigation, we also built a state-of-the-art Chinese word segmenter, which outperforms the best SIGHAN 2003 word segmenters in the closed track on 3 out of 4 test corpora.
In addition, all knowledge sources we used in the core perceptron and the outside-layer linear model come from the training corpus, whereas many open knowledge sources (lexicon etc.) can be used to improve performance (Ng and Low, 2004). $$$$$ For example, when considering the character “年” in the character sequence “九〇年代W”, the feature T (C_2) ... T (C2) =11243 will be set to 1 ( “九” and “〇” are the Chinese characters for “9” and “0” respectively).

For example, Li et al (2010) reported that a joint syntactic and semantic model improved the accuracy of both tasks, while Ng and Low (2004) showed it is beneficial to integrate word segmentation and part-of-speech tagging into one model. $$$$$ We could perform Chinese POS tagging strictly after word segmentation approach), or perform both word segmentation and POS tagging in a combined, single step simultaneously (all-atonce approach).
For example, Li et al (2010) reported that a joint syntactic and semantic model improved the accuracy of both tasks, while Ng and Low (2004) showed it is beneficial to integrate word segmentation and part-of-speech tagging into one model. $$$$$ The testing algorithm is similar to that described in Section 3.2, except that the probability of a word being assigned a POS tag t is estimated by the product of the probability of its individual characters being assigned the same POS tag t. For example, when estimating the probability of “WTWU” being tagged NR, we find the product of the probability of “WT” being tagged NR, “W” being tagged NR, and “U” being tagged NR.
For example, Li et al (2010) reported that a joint syntactic and semantic model improved the accuracy of both tasks, while Ng and Low (2004) showed it is beneficial to integrate word segmentation and part-of-speech tagging into one model. $$$$$ However, in practice, the special characteristics of different languages introduce complications.

In this bakeoff, our models built for the tasks are similar to that in the work of Ng and Low (2004). $$$$$ And when a character appears as part of a word, the word derives part of its meaning from the component characters.
In this bakeoff, our models built for the tasks are similar to that in the work of Ng and Low (2004). $$$$$ The average training timing was 55 minutes, while testing took about 50 seconds.
In this bakeoff, our models built for the tasks are similar to that in the work of Ng and Low (2004). $$$$$ Language differences between English and Chinese have made direct porting of an English POS tagging method to Chinese ineffective.

For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ Our study has also revealed that the one-at-a-time, character-based approach gives relatively good POS tagging accuracy with a much improved training and testing time,
For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ We could perform Chinese POS tagging strictly after word segmentation approach), or perform both word segmentation and POS tagging in a combined, single step simultaneously (all-atonce approach).
For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ We could perform Chinese POS tagging strictly after word segmentation approach), or perform both word segmentation and POS tagging in a combined, single step simultaneously (all-atonce approach).
For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ As such, we need to perform word segmentation before we can proceed with other tasks such as part-of-speech (POS) tagging and parsing, since one POS tag is assigned to each Chinese word (i.e., all characters in a Chinese word have the same POS tag), and the leaves of a parse tree for a Chinese sentence are words.

Our linguistic features are adopted from (Ng and Low, 2004) and (Tseng et al., 2005). $$$$$ The features we used are identical to those employed in the character-based POS tagger described in section 4.1, except that features (g) and (h) are replaced with those listed below.
Our linguistic features are adopted from (Ng and Low, 2004) and (Tseng et al., 2005). $$$$$ However, since words are not demarcated in a Chinese sentence, Chinese POS tagging requires word segmentation as a prerequisite.
Our linguistic features are adopted from (Ng and Low, 2004) and (Tseng et al., 2005). $$$$$ 10-fold CV for CTB is repeated for this POS tagger.

 $$$$$ Similarly, character features were used to build a maximum entropy Chinese parser by (Luo, 2003), where his parser could perform word segmentation, POS tagging, and parsing in an integrated, unified approach.
 $$$$$ Also, we could choose to assign POS tags on a word-by-word basis, making use of word features in the surrounding context (word-based), or on a character-by-character basis with character features (character-based).
 $$$$$ Using a character-based approach for Chinese POS tagging is more effective than a word-based approach.
 $$$$$ The average POS tagging accuracy achieved for the 10 experiments was only 84.1%, far lower than the 96% achievable by English POS taggers on the English Penn Treebank tag set.

Similar to (Ng and Low, 2004), we found the overall F measure only goes up a tiny bit, but we do find a significant OOV recall rate improvement. $$$$$ For example, in the character sequence “74 AL MA”, when considering the character “A”, the feature POS(C−1W0 ) =PN is set to 1 (assuming “k” was tagged as PN).
Similar to (Ng and Low, 2004), we found the overall F measure only goes up a tiny bit, but we do find a significant OOV recall rate improvement. $$$$$ We also added additional features (d) − (f).
Similar to (Ng and Low, 2004), we found the overall F measure only goes up a tiny bit, but we do find a significant OOV recall rate improvement. $$$$$ Using a character-based approach for Chinese POS tagging is more effective than a word-based approach.
Similar to (Ng and Low, 2004), we found the overall F measure only goes up a tiny bit, but we do find a significant OOV recall rate improvement. $$$$$ Much previous research on Chinese language processing focused on word segmentation (Sproat et al., 1996; Teahan et al., 2000; Sproat and Emerson, 2003).
