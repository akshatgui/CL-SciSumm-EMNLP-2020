So we first segmented Chinese text with a Chinese word segmenter that was based on maximum entropy modeling (Ng and Low, 2004). $$$$$ When a paired t-test was carried out at the level of significance 0.01, the all-at-once approach was found to be significantly better than the one-at-a-time approach for POS tagging accuracy, although the difference was insignificant for word segmentation.
So we first segmented Chinese text with a Chinese word segmenter that was based on maximum entropy modeling (Ng and Low, 2004). $$$$$ However, since words are not demarcated in a Chinese sentence, Chinese POS tagging requires word segmentation as a prerequisite.

If we extend these positional tags to include POS information ,segmentation and POS tagging can be performed by a single pass under a unify classification framework (Ng and Low, 2004). $$$$$ For each of the 4 corpora, we trained our word segmenter on only the official released training data of that corpus.
If we extend these positional tags to include POS information ,segmentation and POS tagging can be performed by a single pass under a unify classification framework (Ng and Low, 2004). $$$$$ In addition, since the out-of-vocabulary (OOV) rate for Chinese words is much higher than the OOV rate for Chinese characters, in the presence of an unknown word, using the component characters in the word to help predict the correct POS tag is a good heuristic.
If we extend these positional tags to include POS information ,segmentation and POS tagging can be performed by a single pass under a unify classification framework (Ng and Low, 2004). $$$$$ For Chinese in particular, words are not demarcated in a Chinese sentence.

In the rest of the paper, we call this operation mode Joint S&T. Experiments of Ng and Low (2004) shown that, compared with performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging. $$$$$ Feature (e) encodes the class of characters that constitute the surrounding words (similar to feature (f) of the word segmenter in Section 2.1).
In the rest of the paper, we call this operation mode Joint S&T. Experiments of Ng and Low (2004) shown that, compared with performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging. $$$$$ The average training timing was 55 minutes, while testing took about 50 seconds.

As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively. $$$$$ On this CTBO task, we used as additional training data the AS training corpus provided by SIGHAN, after converting the AS training corpus to GB encoding.
As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively. $$$$$ The average training timing was 55 minutes, while testing took about 50 seconds.
As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively. $$$$$ Our study has also revealed that the one-at-a-time, character-based approach gives relatively good POS tagging accuracy with a much improved training and testing time,
As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively. $$$$$ In Chinese, individual characters encode information that aids in POS tagging.

The features we use to build the classifier are generated from the templates of Ng and Low (2004). $$$$$ In this approach, both word segmentation and POS tagging will be performed in a combined, single step simultaneously.
The features we use to build the classifier are generated from the templates of Ng and Low (2004). $$$$$ For example, the single Chinese character “0” means “know”.

The table's upper column lists the templates that immediately from Ng and Low (2004). $$$$$ Using a character-based approach for Chinese POS tagging is more effective than a word-based approach.
The table's upper column lists the templates that immediately from Ng and Low (2004). $$$$$ Beam search algorithm is used with N = 3 during the testing phase.

Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ng and Low, 2004). $$$$$ Training was conducted with feature cutoff of 2 and 100 iterations (these parameters were obtained by cross validation on the training set), except for the AS corpus where we used cutoff 3 since the AS training corpus was too big to train with cutoff 2.
Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ng and Low, 2004). $$$$$ While our investigation reveals that such an approach gives good accuracy, our findings however indicate that a one-at-a-time, character-based approach to POS tagging gave quite comparable accuracy, with the benefit of incurring much reduced computational cost.
Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ng and Low, 2004). $$$$$ As part of our investigation, we also built a state-of-the-art Chinese word segmenter, which outperforms the best SIGHAN 2003 word segmenters in the closed track on 3 out of 4 test corpora.

Compared to performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging (Ng and Low, 2004). $$$$$ However, since words are not demarcated in a Chinese sentence, Chinese POS tagging requires word segmentation as a prerequisite.
Compared to performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging (Ng and Low, 2004). $$$$$ That is, we enforce the constraint that all characters within a segmented word in the presegmented input sentence must have the same POS tag.
Compared to performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging (Ng and Low, 2004). $$$$$ The all-at-once, characterbased approach reported in this paper is essentially the approach proposed by Luo.
Compared to performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging (Ng and Low, 2004). $$$$$ Language differences between Chinese and English have no doubt made the direct porting of an English POS tagging method to Chinese ineffective.

Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types $$$$$ The average POS tagging accuracy achieved for the 10 experiments was only 84.1%, far lower than the 96% achievable by English POS taggers on the English Penn Treebank tag set.
Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types $$$$$ We found that while the all-at-once, characterbased approach is the best, the one-at-a-time, character-based approach is a worthwhile compromise, performing only slightly worse in terms of accuracy, but taking shorter time to train and run.
Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types $$$$$ With an allat-once, character-based approach, an average word segmentation F-measure of 95.2% and an average POS tagging accuracy of 91.9% was achieved.
Ac cording to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types $$$$$ Beam search algorithm is used with N = 3 during the testing phase.

In order to perform POS tagging at the same time, we expand boundary tags to include POS information by attaching a POS to the tail of a boundary tag as a postfix following Ng and Low (2004). $$$$$ Language differences between English and Chinese have made direct porting of an English POS tagging method to Chinese ineffective.
In order to perform POS tagging at the same time, we expand boundary tags to include POS information by attaching a POS to the tail of a boundary tag as a postfix following Ng and Low (2004). $$$$$ An English POS tagger based on maximum entropy modeling was built by (Ratnaparkhi, 1996).
In order to perform POS tagging at the same time, we expand boundary tags to include POS information by attaching a POS to the tail of a boundary tag as a postfix following Ng and Low (2004). $$$$$ We found that while the all-at-once, characterbased approach is the best, the one-at-a-time, character-based approach is a worthwhile compromise, performing only slightly worse in terms of accuracy, but taking shorter time to train and run.
In order to perform POS tagging at the same time, we expand boundary tags to include POS information by attaching a POS to the tail of a boundary tag as a postfix following Ng and Low (2004). $$$$$ However, in practice, the special characteristics of different languages introduce complications.

Templates immediately borrowed from Ng and Low (2004) are listed in the upper column named non-lexical-target. $$$$$ Similarly, character features were used to build a maximum entropy Chinese parser by (Luo, 2003), where his parser could perform word segmentation, POS tagging, and parsing in an integrated, unified approach.
Templates immediately borrowed from Ng and Low (2004) are listed in the upper column named non-lexical-target. $$$$$ The all-at-once approach, which considers all aspects of available information in an integrated, unified compared with the all-at-once, character-based approach previously proposed. framework, can make better informed decisions, but incurs a higher computational cost.
Templates immediately borrowed from Ng and Low (2004) are listed in the upper column named non-lexical-target. $$$$$ To our knowledge, our work is the first to systematically investigate such issues in Chinese POS tagging.

Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ That is, we enforce the constraint that all characters within a segmented word in the presegmented input sentence must have the same POS tag.
Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ Jing et al. (2003) focused on Chinese named entity recognition, considering issues like character-based versus word-based approaches.
Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ Note that an all-atonce, word-based approach is not applicable as word segmentation requires character features to determine the word boundaries.
Note that the templates of Ng and Low (2004) have already contained some lexical-target ones. $$$$$ While our investigation reveals that such an approach gives good accuracy, our findings however indicate that a one-at-a-time, character-based approach to POS tagging gave quite comparable accuracy, with the benefit of incurring much reduced computational cost.

Similar trend appeared in experiments of Ng and Low (2004), where they conducted experiments on CTB 3.0 and achieved F measure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation. $$$$$ Luo presented a maximum entropy character-based parser, which as a consequence of parsing also performed word segmentation and POS tagging.
Similar trend appeared in experiments of Ng and Low (2004), where they conducted experiments on CTB 3.0 and achieved F measure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation. $$$$$ The all-at-once approach, which considers all aspects of available information in an integrated, unified compared with the all-at-once, character-based approach previously proposed. framework, can make better informed decisions, but incurs a higher computational cost.

In addition, all knowledge sources we used in the core perceptron and the outside-layer linear model come from the training corpus, whereas many open knowledge sources (lexicon etc.) can be used to improve performance (Ng and Low, 2004). $$$$$ This feature checks whether the current character is a punctuation symbol (such as “。”, “-”, “,”).
In addition, all knowledge sources we used in the core perceptron and the outside-layer linear model come from the training corpus, whereas many open knowledge sources (lexicon etc.) can be used to improve performance (Ng and Low, 2004). $$$$$ Besides implementing a subset of the features described in (Xue and Shen, 2003), we also came up with three additional types of features ((d) − (f) below) which improved the accuracy of word segmentation.
In addition, all knowledge sources we used in the core perceptron and the outside-layer linear model come from the training corpus, whereas many open knowledge sources (lexicon etc.) can be used to improve performance (Ng and Low, 2004). $$$$$ Language differences between English and Chinese have made direct porting of an English POS tagging method to Chinese ineffective.
In addition, all knowledge sources we used in the core perceptron and the outside-layer linear model come from the training corpus, whereas many open knowledge sources (lexicon etc.) can be used to improve performance (Ng and Low, 2004). $$$$$ During testing, the probability of a boundary tag sequence assignment t1... tn given a character sequence c1 ...cn is determined by using the maximum entropy classifier to compute the probability that a boundary tag ti is assigned to each individual character ci.

For example, Li et al (2010) reported that a joint syntactic and semantic model improved the accuracy of both tasks, while Ng and Low (2004) showed it is beneficial to integrate word segmentation and part-of-speech tagging into one model. $$$$$ The features that were used for our word segmenter ((a) − (f)) in Section 2.1 were yet again applied, with two additional features (g) and (h) to aid POS tag prediction.
For example, Li et al (2010) reported that a joint syntactic and semantic model improved the accuracy of both tasks, while Ng and Low (2004) showed it is beneficial to integrate word segmentation and part-of-speech tagging into one model. $$$$$ 10-fold CV for CTB is repeated for this POS tagger.
For example, Li et al (2010) reported that a joint syntactic and semantic model improved the accuracy of both tasks, while Ng and Low (2004) showed it is beneficial to integrate word segmentation and part-of-speech tagging into one model. $$$$$ Theoretically, we should be able to just port corpus-based, machine learning techniques across different languages since the techniques are largely language independent.
For example, Li et al (2010) reported that a joint syntactic and semantic model improved the accuracy of both tasks, while Ng and Low (2004) showed it is beneficial to integrate word segmentation and part-of-speech tagging into one model. $$$$$ For example, “0V,” means “knowledge”, “3'u0” means “ignorant”, “0-8” means “well-known”, etc.

In this bakeoff, our models built for the tasks are similar to that in the work of Ng and Low (2004). $$$$$ The all-at-once, characterbased approach reported in this paper is essentially the approach proposed by Luo.
In this bakeoff, our models built for the tasks are similar to that in the work of Ng and Low (2004). $$$$$ Language differences between English and Chinese have made direct porting of an English POS tagging method to Chinese ineffective.
In this bakeoff, our models built for the tasks are similar to that in the work of Ng and Low (2004). $$$$$ However, the time required for training and testing is increased significantly for the all-atonce approach.

For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ To our knowledge, our work is the first to systematically investigate such issues in Chinese POS tagging.
For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ Most corpus-based language processing research has focused on the English language.
For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ The Java opennlp maximum entropy package from sourceforge1 was used in our implementation, and training was done with a feature cutoff of 2 and 100 iterations.
For this task, because of the time limitation as mentioned in the previous section, we could only port our implemented model by using a part of the feature set which was used in the word-based tagger discussed in the work of Ng and Low (2004). $$$$$ To build a Chinese POS tagger, the following questions naturally arise: This paper presents an in-depth study on such issues of processing architecture and feature representation for Chinese POS tagging, within a maximum entropy framework.

Our linguistic features are adopted from (Ng and Low, 2004) and (Tseng et al., 2005). $$$$$ The features that worked well for English POS tagging did not seem to apply to Chinese in the maximum entropy framework.
Our linguistic features are adopted from (Ng and Low, 2004) and (Tseng et al., 2005). $$$$$ Encouraged by the success of character features, we next explored whether a change in processing architecture, from one-at-a-time to all-at-once, while still retaining the use of character features, could give further improvement to POS tagging accuracy.
Our linguistic features are adopted from (Ng and Low, 2004) and (Tseng et al., 2005). $$$$$ When efficiency is a major consideration, or if high quality hand-segmented text is available, the one-at-a-time, characterbased approach could indeed be a worthwhile compromise, performing only slightly worse than the all-at-once approach.
Our linguistic features are adopted from (Ng and Low, 2004) and (Tseng et al., 2005). $$$$$ This paper presents an in-depth study on such issues of processing architecture and feature representation for Chinese POS tagging, within a maximum entropy framework.

 $$$$$ To our knowledge, our work is the first to systematically investigate such issues in Chinese POS tagging.
 $$$$$ Figure 2 shows our word segmenter’s Fmeasure (based on the official word segmentation scorer of 2003 SIGHAN bakeoff) compared to those reported by all the 2003 SIGHAN participants in the four closed tracks (ASc, HKc, PKc, CTBc).
 $$$$$ Our word segmenter achieved higher F-measure than the best reported F-measure in the SIGHAN bakeoff on the ASc, HKc, and PKc corpus.
 $$$$$ Similarly, character features were used to build a maximum entropy Chinese parser by (Luo, 2003), where his parser could perform word segmentation, POS tagging, and parsing in an integrated, unified approach.

Similar to (Ng and Low, 2004), we found the overall F measure only goes up a tiny bit, but we do find a significant OOV recall rate improvement. $$$$$ We observed that character features were successfully used to build our word segmenter and that of (Xue and Shen, 2003).
Similar to (Ng and Low, 2004), we found the overall F measure only goes up a tiny bit, but we do find a significant OOV recall rate improvement. $$$$$ When efficiency is a major consideration, or if high quality hand-segmented text is available, the one-at-a-time, characterbased approach could indeed be a worthwhile compromise, performing only slightly worse than the all-at-once approach.
Similar to (Ng and Low, 2004), we found the overall F measure only goes up a tiny bit, but we do find a significant OOV recall rate improvement. $$$$$ Figure 1: CTB 10-fold CV word segmentation Fmeasure for our word segmenter As further evaluation, we tested our word segmenter on all the 4 test corpora (CTB, Academia Sinica (AS), Hong Kong CityU (HK) , and Peking University (PK)) of the closed track of the 2003 ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff (Sproat and Emerson, 2003).
