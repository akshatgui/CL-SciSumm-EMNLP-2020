Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ Our approach is similar in spirit to co-training, where two classifiers, complementary by the virtue of having different views of the data, are trained jointly to encourage agreement (Blum and Mitchell, 1998; Collins and Singer, 1999).
Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ As a preprocessing step, we lowercased all words.
Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ All three models are generative models of the form p(f  |e) = Ea p(a, f  |e), where e = (e1, ... , eI) is the English sentence, f = (f1, ... , fJ) is the French sentence, and a = (a1, ... , aJ) is the (asymmetric) alignment which specifies the position of an English word aligned to each French word.
Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.

By also including as features the posteriors of the model of Liang et al (2006), we achieve AER of 3.8, and 96.7/95.5 precision/recall. $$$$$ Viewing intersection as a way of finding predictions that both models agree on, we take the agreement idea one step further.
By also including as features the posteriors of the model of Liang et al (2006), we achieve AER of 3.8, and 96.7/95.5 precision/recall. $$$$$ In this paper, we introduce a new method for word alignment that addresses the three issues above.
By also including as features the posteriors of the model of Liang et al (2006), we achieve AER of 3.8, and 96.7/95.5 precision/recall. $$$$$ Intersection after training produces alignments that both models agree on.
By also including as features the posteriors of the model of Liang et al (2006), we achieve AER of 3.8, and 96.7/95.5 precision/recall. $$$$$ Our approach is similar in spirit to co-training, where two classifiers, complementary by the virtue of having different views of the data, are trained jointly to encourage agreement (Blum and Mitchell, 1998; Collins and Singer, 1999).

Liang et al (2006) propose agreement-based learning, which jointly learns probabilities by maximizing a combination of likelihood and agreement between two directional models. $$$$$ Using GIZA++ model 4 alignments and Pharaoh (Koehn et al., 2003), we achieved a BLEU score of 0.3035.
Liang et al (2006) propose agreement-based learning, which jointly learns probabilities by maximizing a combination of likelihood and agreement between two directional models. $$$$$ Word alignment is an important component of a complete statistical machine translation pipeline (Koehn et al., 2003).
Liang et al (2006) propose agreement-based learning, which jointly learns probabilities by maximizing a combination of likelihood and agreement between two directional models. $$$$$ All three models are generative models of the form p(f  |e) = Ea p(a, f  |e), where e = (e1, ... , eI) is the English sentence, f = (f1, ... , fJ) is the French sentence, and a = (a1, ... , aJ) is the (asymmetric) alignment which specifies the position of an English word aligned to each French word.
Liang et al (2006) propose agreement-based learning, which jointly learns probabilities by maximizing a combination of likelihood and agreement between two directional models. $$$$$ The idea of exploiting agreement between two latent variable models is not new; there has been substantial previous work on leveraging the strengths of two complementary models.

Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ We could perhaps attempt to compute q using a variety of approximate probabilistic inference techniques, for example, sampling or variational methods.
Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ Posterior decoding is in principle capable of proposing many-to-many alignments, but these alignments occur infrequently since the posteriors are generally sharply peaked around the Viterbi alignment.
Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ The distortion parameters pd(aj = i0 | aj− = i) depend on the particular model (we write aj = 0 to denote the event that the j-th French word where p0 is the null-word probability and c(·) contains the distortion parameters for each offset argudepending on the length of the English sentence, which we found to be more effective than using a constant p0.
Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ Our approach is similar in spirit to co-training, where two classifiers, complementary by the virtue of having different views of the data, are trained jointly to encourage agreement (Blum and Mitchell, 1998; Collins and Singer, 1999).

Concerning the former, we trained an unsupervised model with the Berkeley aligner, an implementation of the symmetric word-alignment model described by Liang et al (2006). $$$$$ First and most importantly, we use joint training instead of independent training and posterior decoding (with the optimal threshold) instead of Viterbi decoding, evaluated on the development set. independent training, which gives us a huge boost.
Concerning the former, we trained an unsupervised model with the Berkeley aligner, an implementation of the symmetric word-alignment model described by Liang et al (2006). $$$$$ Also, when we want to combine two models for prediction, finding the Viterbi alignment argmaxz p1(z  |x)p2(z  |x) is intractable for HMM models (by a reduction from quadratic assignment), and a hard intersection argmaxz' p1(z1 | x) n argmaxz, p2(z2  |x) might be too sparse.
Concerning the former, we trained an unsupervised model with the Berkeley aligner, an implementation of the symmetric word-alignment model described by Liang et al (2006). $$$$$ Moreover, a simple and efficient pair of HMM aligners provides a 29% reduction in AER over symmetrized IBM model 4 predictions.
Concerning the former, we trained an unsupervised model with the Berkeley aligner, an implementation of the symmetric word-alignment model described by Liang et al (2006). $$$$$ First, even with the highly optimized implementations in GIZA++, models 3 and above are still very slow to train.

The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ To compute ZX in the E-step, we must sum the product of two model posteriors over the set of possible zs with nonzero probability under both models.
The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ See the appendix for the derivation. where ZX is a normalization constant.
The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ Klein and Manning (2004) combine two complementary models for grammar induction, one that models constituency and one that models dependency, in a manner broadly similar to the current work.
The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ Finally, we show that word alignments from our system can be used in a phrasebased translation system to modestly improve BLEU score.

We used version two of the Berkeley alignment model (Liang et al, 2006), with the posterior threshold set at 0.5. $$$$$ First, even with the highly optimized implementations in GIZA++, models 3 and above are still very slow to train.
We used version two of the Berkeley alignment model (Liang et al, 2006), with the posterior threshold set at 0.5. $$$$$ While AER is only a weak indicator of final translation quality in many current translation systems, we hope that more accurate alignments can eventually lead to improvements in the end-to-end translation process.
We used version two of the Berkeley alignment model (Liang et al, 2006), with the posterior threshold set at 0.5. $$$$$ We briefly review the sequence-based word alignment models (Brown et al., 1994; Och and Ney, 2003) and describe some of the choices in our implementation.

The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ Finally, we show that word alignments from our system can be used in a phrasebased translation system to modestly improve BLEU score.
The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ Viewing intersection as a way of finding predictions that both models agree on, we take the agreement idea one step further.
The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ We have described an efficient and fully unsupervised method of producing state-of-the-art word alignments.
The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ Our jointly trained HMM models reduce AER by 29% over test-time intersected GIZA++ model 4 alignments and also increase our robustness to varying initialization regimens.

As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ We speculate that since the HMM model provides a richer family of distributions over alignments than either models 1 or 2, we can learn to synchronize the predictions of the two models, whereas models 1 and 2 have a much more limited capacity to synchronize.
As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ To our knowledge, this is the lowest published unsupervised AER result, and it is competitive with supervised approaches.
As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ By training two simple sequence-based models to agree, we achieve substantial error reductions over standard models.
As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ . we we we deemed deemed deemed it it it inadvisable inadvisable inadvisable to to to attend attend attend the the the meeting meeting meeting and and and so so so informed informed informed cojo cojo cojo .

Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ The idea of exploiting agreement between two latent variable models is not new; there has been substantial previous work on leveraging the strengths of two complementary models.
Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ One key difference in our work is that we rely exclusively on data likelihood to guide the two models in an unsupervised manner, rather than relying on an initial handful of labeled examples.
Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ One key difference in our work is that we rely exclusively on data likelihood to guide the two models in an unsupervised manner, rather than relying on an initial handful of labeled examples.
Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ The distortion parameters pd(aj = i0 | aj− = i) depend on the particular model (we write aj = 0 to denote the event that the j-th French word where p0 is the null-word probability and c(·) contains the distortion parameters for each offset argudepending on the length of the English sentence, which we found to be more effective than using a constant p0.

They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ In E—*F: 84.2/92.0/13.0 F—*E: 86.9/91.1/11.5 Intersection: 97.0/86.9/7.6 Joint training nous nous nous ne ne ne avons avons avons pas pas pas cru cru cru bon bon bon de de de assister assister assister a` a` a` la la la r´eunion r´eunion r´eunion et et et en en en avons avons avons inform´e inform´e inform´e le le le cojo cojo cojo en en en cons´equence cons´equence cons´equence .
They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ Our jointly trained HMM models reduce AER by 29% over test-time intersected GIZA++ model 4 alignments and also increase our robustness to varying initialization regimens.
They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ Our jointly trained HMM models reduce AER by 29% over test-time intersected GIZA++ model 4 alignments and also increase our robustness to varying initialization regimens.
They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ Moreover, a simple and efficient pair of HMM aligners provides a 29% reduction in AER over symmetrized IBM model 4 predictions.

We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al, 2006) and one supervised aligner, ITG (Haghighi et al, 2009) as representatives in this work. $$$$$ There is a large range from 0.2 to 0.5 where posterior decoding outperforms Viterbi decoding.
We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al, 2006) and one supervised aligner, ITG (Haghighi et al, 2009) as representatives in this work. $$$$$ Posterior decoding is in principle capable of proposing many-to-many alignments, but these alignments occur infrequently since the posteriors are generally sharply peaked around the Viterbi alignment.
We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al, 2006) and one supervised aligner, ITG (Haghighi et al, 2009) as representatives in this work. $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.

We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al, 2006), and ITG (Haghighi et al, 2009). $$$$$ Aside from investigating a different domain, one novel aspect of this paper is that we present a formal objective and a training algorithm for combining two generic models.
We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al, 2006), and ITG (Haghighi et al, 2009). $$$$$ The translation cost for forcing that edge is smaller than the distortion cost.
We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al, 2006), and ITG (Haghighi et al, 2009). $$$$$ In model 2, pd(·  |·) is still independent of aj−, but it can now depend on j and i0 through c(·).
We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al, 2006), and ITG (Haghighi et al, 2009). $$$$$ The last column shows the relative reduction in AER.

The HMM aligner used in this work was due to Liang et al (2006). $$$$$ Our jointly trained HMM models reduce AER by 29% over test-time intersected GIZA++ model 4 alignments and also increase our robustness to varying initialization regimens.
The HMM aligner used in this work was due to Liang et al (2006). $$$$$ Initialization and convergence In addition to improving performance, joint training also enjoys certain robustness properties.
The HMM aligner used in this work was due to Liang et al (2006). $$$$$ This works better than using a single set of parameters or ignoring the transitions at the two ends.
The HMM aligner used in this work was due to Liang et al (2006). $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.

Second, an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al, 2006). $$$$$ All three models are generative models of the form p(f  |e) = Ea p(a, f  |e), where e = (e1, ... , eI) is the English sentence, f = (f1, ... , fJ) is the French sentence, and a = (a1, ... , aJ) is the (asymmetric) alignment which specifies the position of an English word aligned to each French word.
Second, an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al, 2006). $$$$$ By training two simple sequence-based models to agree, we achieve substantial error reductions over standard models.
Second, an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al, 2006). $$$$$ Viewing intersection as a way of finding predictions that both models agree on, we take the agreement idea one step further.
Second, an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al, 2006). $$$$$ Acknowledgments We thank the anonymous reviewers for their comments.

As suggested by Liang et al (2006), we can group the distortion parameters into a few buckets. $$$$$ This works better than using a single set of parameters or ignoring the transitions at the two ends.
As suggested by Liang et al (2006), we can group the distortion parameters into a few buckets. $$$$$ Acknowledgments We thank the anonymous reviewers for their comments.
As suggested by Liang et al (2006), we can group the distortion parameters into a few buckets. $$$$$ The distortion parameters pd(aj = i0 | aj− = i) depend on the particular model (we write aj = 0 to denote the event that the j-th French word where p0 is the null-word probability and c(·) contains the distortion parameters for each offset argudepending on the length of the English sentence, which we found to be more effective than using a constant p0.

As an additional experiment, we tested the Cross EM aligner (Liang et al, 2006) from the Berkeley Aligner package on the MSR data. $$$$$ By jointly training two simple HMM models, we obtain 4.9% AER on the standard English-French Hansards task.
As an additional experiment, we tested the Cross EM aligner (Liang et al, 2006) from the Berkeley Aligner package on the MSR data. $$$$$ Finally, the fertility-based models are asymmetric, and symmetrization is commonly employed to improve alignment quality by intersecting alignments induced in each translation direction.
As an additional experiment, we tested the Cross EM aligner (Liang et al, 2006) from the Berkeley Aligner package on the MSR data. $$$$$ By jointly training two simple HMM models, we obtain 4.9% AER on the standard English-French Hansards task.
As an additional experiment, we tested the Cross EM aligner (Liang et al, 2006) from the Berkeley Aligner package on the MSR data. $$$$$ We emphasize that this technique is quite general and can be applied in many different situations where we want to couple two tractable models over input x and output z.

Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ While AER is only a weak indicator of final translation quality in many current translation systems, we hope that more accurate alignments can eventually lead to improvements in the end-to-end translation process.
Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ Each model was trained for 5 iterations, using the same training regimen as in Och and Ney (2003). and joint training across different size training sets and different models, evaluated on the development set.
Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ Klein and Manning (2004) combine two complementary models for grammar induction, one that models constituency and one that models dependency, in a manner broadly similar to the current work.
Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.

Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ The central idea of our approach is to not only make the predictions of the models agree at test time, but also encourage agreement during training.
Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ The E→F model gives 0 probability to any many-to-one alignments and the F→E model gives 0 probability to any one-to-many alignments.
Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ We define an intuitive objective function which incorporates both data likelihood and a measure of agreement between models.
Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ In model 1, the distortion pd(·  |·) specifies a uniform distribution over English positions.

We performed word alignment using a cross EM word aligner (Liang et al, 2006). $$$$$ We first replace the asymmetric alignments a with a set of indicator variables for each potential alignment edge (i, j): z = {zij ∈ {0, 1} : 1 ≤ i ≤ I,1 ≤ j ≤ J}.
We performed word alignment using a cross EM word aligner (Liang et al, 2006). $$$$$ We can now think of the two directional sequence-based models as each inducing a distribution over the same space of sentence pairs and alignments (x, z): In the next two sections, we describe how to jointly train the two models using an EM-like algorithm.
We performed word alignment using a cross EM word aligner (Liang et al, 2006). $$$$$ We have described an efficient and fully unsupervised method of producing state-of-the-art word alignments.
