Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ .
Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ We have described an efficient and fully unsupervised method of producing state-of-the-art word alignments.
Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ All three models are generative models of the form p(f  |e) = Ea p(a, f  |e), where e = (e1, ... , eI) is the English sentence, f = (f1, ... , fJ) is the French sentence, and a = (a1, ... , aJ) is the (asymmetric) alignment which specifies the position of an English word aligned to each French word.
Moreover, including predictions of bi-directional IBM Model 4 and model of Liang et al (2006) as features, we achieve an absolute AER of 3.8 on the English French Hansards alignment task - the best AER result published on this task to date. $$$$$ Another phenomenon is the insertion of “stepping stone” alignments.

By also including as features the posteriors of the model of Liang et al (2006), we achieve AER of 3.8, and 96.7/95.5 precision/recall. $$$$$ By training two simple sequence-based models to agree, we achieve substantial error reductions over standard models.
By also including as features the posteriors of the model of Liang et al (2006), we achieve AER of 3.8, and 96.7/95.5 precision/recall. $$$$$ Word alignment is an important component of a complete statistical machine translation pipeline (Koehn et al., 2003).

Liang et al (2006) propose agreement-based learning, which jointly learns probabilities by maximizing a combination of likelihood and agreement between two directional models. $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.
Liang et al (2006) propose agreement-based learning, which jointly learns probabilities by maximizing a combination of likelihood and agreement between two directional models. $$$$$ In this paper, we introduce a new method for word alignment that addresses the three issues above.
Liang et al (2006) propose agreement-based learning, which jointly learns probabilities by maximizing a combination of likelihood and agreement between two directional models. $$$$$ The idea of exploiting agreement between two latent variable models is not new; there has been substantial previous work on leveraging the strengths of two complementary models.

Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ We parameterize the distortion c(·) using a multinomial distribution over 11 offset buckets c(<_ −5), c(−4),.
Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ By training two simple sequence-based models to agree, we achieve substantial error reductions over standard models.
Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ We emphasize that this technique is quite general and can be applied in many different situations where we want to couple two tractable models over input x and output z.
Training is performed using the agreement-based learning method which encourages the directional models to overlap (Liang et al, 2006). $$$$$ By training two simple sequence-based models to agree, we achieve substantial error reductions over standard models.

Concerning the former, we trained an unsupervised model with the Berkeley aligner, an implementation of the symmetric word-alignment model described by Liang et al (2006). $$$$$ Acknowledgments We thank the anonymous reviewers for their comments.
Concerning the former, we trained an unsupervised model with the Berkeley aligner, an implementation of the symmetric word-alignment model described by Liang et al (2006). $$$$$ This works better than using a single set of parameters or ignoring the transitions at the two ends.
Concerning the former, we trained an unsupervised model with the Berkeley aligner, an implementation of the symmetric word-alignment model described by Liang et al (2006). $$$$$ Because the E-step is intractable in our case, we use a heuristic approximation which nonetheless works well in practice.

The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ To see whether our improvement in AER also improves BLEU score, we aligned 100K EnglishFrench sentences from the Europarl corpus and tested on 3000 sentences of length 5–15.
The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ Common errors The major source of remaining errors are recall errors that come from the shortcomings of the HMM model.
The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ In model 1, the distortion pd(·  |·) specifies a uniform distribution over English positions.
The state-of-the-art unsupervised Berkeley aligner (Liang et al, 2006) with default setting is used to construct word alignments. $$$$$ Compared to the standard practice of intersecting predictions of independently-trained models, joint training provides a 32% reduction in AER.

We used version two of the Berkeley alignment model (Liang et al, 2006), with the posterior threshold set at 0.5. $$$$$ By enforcing agreement, the two models are effectively restricted to one-to-one (or zero) alignments.
We used version two of the Berkeley alignment model (Liang et al, 2006), with the posterior threshold set at 0.5. $$$$$ An alternative is to use posterior decoding, where we keep an edge (i, j) if the marginal edge rectly in extracting phrases for phrase-based translation.
We used version two of the Berkeley alignment model (Liang et al, 2006), with the posterior threshold set at 0.5. $$$$$ The joint training procedure we describe below builds on this idea by encouraging the models to agree during training.
We used version two of the Berkeley alignment model (Liang et al, 2006), with the posterior threshold set at 0.5. $$$$$ We have described an efficient and fully unsupervised method of producing state-of-the-art word alignments.

The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ Models 2 and HMM were initialized with uniform distortion probabilities and model 1 translation probabilities.
The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ Then we derive an EM-like algorithm to maximize this objective function.
The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ Moreover, a simple and efficient pair of HMM aligners provides a 29% reduction in AER over symmetrized IBM model 4 predictions.
The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 (Liang et al., 2006), with the posterior probability to being 0.5. $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.

As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ While AER is only a weak indicator of final translation quality in many current translation systems, we hope that more accurate alignments can eventually lead to improvements in the end-to-end translation process.
As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ The idea of exploiting agreement between two latent variable models is not new; there has been substantial previous work on leveraging the strengths of two complementary models.
As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ In model 1, the distortion pd(·  |·) specifies a uniform distribution over English positions.
As is standard in unsupervised alignment models, we initialized the translation parameters pt by first training 5 iterations of IBM Model 1 using the joint training algorithm of Liang et al (2006), and then trained our model for 5 EM iterations. $$$$$ Moreover, a simple and efficient pair of HMM aligners provides a 29% reduction in AER over symmetrized IBM model 4 predictions.

Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ All three models factor in the following way: where j− is the position of the last non-null-aligned French word before position j.2 The translation parameters pt(fj  |eaj) are parameterized by an (unsmoothed) lookup table that stores the appropriate local conditional probability distributions.
Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ The classic approaches to unsupervised word alignment are based on IBM models 1–5 (Brown et al., 1994) and the HMM model (Ney and Vogel, 1996) (see Och and Ney (2003) for a systematic comparison).
Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ To compute ZX in the E-step, we must sum the product of two model posteriors over the set of possible zs with nonzero probability under both models.
Previous evaluation of Addicter shows that hypothesis-reference alignment coverage (in terms of discovered word pairs) directly influences error analysis quality; to increase alignment coverage we used Berkeley aligner (Liang et al, 2006) and trained it on and applied it to the whole set of reference-hypothesis pairs for every language pair. $$$$$ The distortion parameters pd(aj = i0 | aj− = i) depend on the particular model (we write aj = 0 to denote the event that the j-th French word where p0 is the null-word probability and c(·) contains the distortion parameters for each offset argudepending on the length of the English sentence, which we found to be more effective than using a constant p0.

They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ Our jointly trained HMM models reduce AER by 29% over test-time intersected GIZA++ model 4 alignments and also increase our robustness to varying initialization regimens.
They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ Acknowledgments We thank the anonymous reviewers for their comments.
They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ On the other hand, if we jointly train two HMMs starting from a uniform initialization, the HMMs converge to a surprisingly good solution.
They could reach an AER of 3.8 on the same task, but only if they also included the posteriors of the model of Liang et al (2006). $$$$$ To compute ZX in the E-step, we must sum the product of two model posteriors over the set of possible zs with nonzero probability under both models.

We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al, 2006) and one supervised aligner, ITG (Haghighi et al, 2009) as representatives in this work. $$$$$ The E→F model gives 0 probability to any many-to-one alignments and the F→E model gives 0 probability to any one-to-many alignments.
We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al, 2006) and one supervised aligner, ITG (Haghighi et al, 2009) as representatives in this work. $$$$$ Lastly, we ran our models on the last 347 sentences of the test set to get final AER results.
We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al, 2006) and one supervised aligner, ITG (Haghighi et al, 2009) as representatives in this work. $$$$$ Our approach is similar in spirit to co-training, where two classifiers, complementary by the virtue of having different views of the data, are trained jointly to encourage agreement (Blum and Mitchell, 1998; Collins and Singer, 1999).
We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al, 2006) and one supervised aligner, ITG (Haghighi et al, 2009) as representatives in this work. $$$$$ Aside from investigating a different domain, one novel aspect of this paper is that we present a formal objective and a training algorithm for combining two generic models.

We used three aligners in this work $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.
We used three aligners in this work $$$$$ As a result, many practitioners use the complex GIZA++ software package (Och and Ney, 2003) as a black box, selecting model 4 as a good compromise between alignment quality and efficiency.
We used three aligners in this work $$$$$ Lastly, we ran our models on the last 347 sentences of the test set to get final AER results.
We used three aligners in this work $$$$$ While AER is only a weak indicator of final translation quality in many current translation systems, we hope that more accurate alignments can eventually lead to improvements in the end-to-end translation process.

The HMM aligner used in this work was due to Liang et al (2006). $$$$$ Compared to the standard practice of intersecting predictions of independently-trained models, joint training provides a 32% reduction in AER.
The HMM aligner used in this work was due to Liang et al (2006). $$$$$ We have described an efficient and fully unsupervised method of producing state-of-the-art word alignments.
The HMM aligner used in this work was due to Liang et al (2006). $$$$$ We briefly review the sequence-based word alignment models (Brown et al., 1994; Och and Ney, 2003) and describe some of the choices in our implementation.
The HMM aligner used in this work was due to Liang et al (2006). $$$$$ In this paper, we introduce a new method for word alignment that addresses the three issues above.

Second, an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al, 2006). $$$$$ We have described an efficient and fully unsupervised method of producing state-of-the-art word alignments.
Second, an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al, 2006). $$$$$ If we initialize the HMM model with uniform translation parameters, the HMM converges to a completely senseless local optimum with AER above 50%.
Second, an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al, 2006). $$$$$ We have described an efficient and fully unsupervised method of producing state-of-the-art word alignments.

As suggested by Liang et al (2006), we can group the distortion parameters into a few buckets. $$$$$ Word alignment is an important component of a complete statistical machine translation pipeline (Koehn et al., 2003).
As suggested by Liang et al (2006), we can group the distortion parameters into a few buckets. $$$$$ The idea of exploiting agreement between two latent variable models is not new; there has been substantial previous work on leveraging the strengths of two complementary models.
As suggested by Liang et al (2006), we can group the distortion parameters into a few buckets. $$$$$ Also, when we want to combine two models for prediction, finding the Viterbi alignment argmaxz p1(z  |x)p2(z  |x) is intractable for HMM models (by a reduction from quadratic assignment), and a hard intersection argmaxz' p1(z1 | x) n argmaxz, p2(z2  |x) might be too sparse.
As suggested by Liang et al (2006), we can group the distortion parameters into a few buckets. $$$$$ Table 2 shows the HMM models compared to model 4 alignments produced by GIZA++ on the test set.

As an additional experiment, we tested the Cross EM aligner (Liang et al, 2006) from the Berkeley Aligner package on the MSR data. $$$$$ Aside from investigating a different domain, one novel aspect of this paper is that we present a formal objective and a training algorithm for combining two generic models.
As an additional experiment, we tested the Cross EM aligner (Liang et al, 2006) from the Berkeley Aligner package on the MSR data. $$$$$ Following past work, we initialized the translation probabilities of model 1 uniformly over word pairs that occur together in some sentence pair.
As an additional experiment, we tested the Cross EM aligner (Liang et al, 2006) from the Berkeley Aligner package on the MSR data. $$$$$ Note that in general, this new procedure is not guaranteed to increase our joint objective.

Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ In model 2, pd(·  |·) is still independent of aj−, but it can now depend on j and i0 through c(·).
Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ One key difference in our work is that we rely exclusively on data likelihood to guide the two models in an unsupervised manner, rather than relying on an initial handful of labeled examples.
Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ Table 3 quantifies the contribution of each of these two dimensions.
Exceptions where discriminative SMT has been used on large training data are Liang et al (2006a) who trained 1.5 million features on 67,000 sentences. $$$$$ In model 2, pd(·  |·) is still independent of aj−, but it can now depend on j and i0 through c(·).

Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ For these results, the threshold used for posterior decoding was tuned on the development set.
Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.
Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ Klein and Manning (2004) combine two complementary models for grammar induction, one that models constituency and one that models dependency, in a manner broadly similar to the current work.
Training data for discriminative learning are prepared by comparing a 100-best list of translations against a single reference using smoothed per sentence BLEU (Liang et al, 2006a). $$$$$ Our jointly trained HMM models reduce AER by 29% over test-time intersected GIZA++ model 4 alignments and also increase our robustness to varying initialization regimens.

We performed word alignment using a cross EM word aligner (Liang et al, 2006). $$$$$ The E→F model gives 0 probability to any many-to-one alignments and the F→E model gives 0 probability to any one-to-many alignments.
We performed word alignment using a cross EM word aligner (Liang et al, 2006). $$$$$ While the English and French sentences play a symmetric role in the word alignment task, sequence-based models are asymmetric: they are generative models of the form p(f  |e) (E—*F), or p(e  |f) (F—*E) by reversing the roles of source and target.
We performed word alignment using a cross EM word aligner (Liang et al, 2006). $$$$$ By training two simple sequence-based models to agree, we achieve substantial error reductions over standard models.
