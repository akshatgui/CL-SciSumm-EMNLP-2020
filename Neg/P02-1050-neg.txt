Recent work (Hwa et al, 2002) suggests that translational corresponence of linguistic structures can indeed be useful in projecting parses across languages. $$$$$ For example, SITG can generate verb initial (English) and verb final (Japanese) verb phrases using the same rule VP V NP.
Recent work (Hwa et al, 2002) suggests that translational corresponence of linguistic structures can indeed be useful in projecting parses across languages. $$$$$ In of the Workshop on Linguistic Knowledge Acquisition and Representation: Bootstrapping Anno- Language Data. appear.

The dependency projection method DPA (Hwa et al, 2005) based on Direct Correspondence Assumption (Hwa et al, 2002) can be described as: if there is a pair of source words with a dependency relationship, the corresponding aligned words in target sentence can be considered as having the same dependency relationship equivalently. $$$$$ That is, the thematic (who-did-what-to-whom) relationships are likely to hold true across translations evert for typologically different languages.
The dependency projection method DPA (Hwa et al, 2005) based on Direct Correspondence Assumption (Hwa et al, 2002) can be described as: if there is a pair of source words with a dependency relationship, the corresponding aligned words in target sentence can be considered as having the same dependency relationship equivalently. $$$$$ In of NAACL, Shieber.
The dependency projection method DPA (Hwa et al, 2005) based on Direct Correspondence Assumption (Hwa et al, 2002) can be described as: if there is a pair of source words with a dependency relationship, the corresponding aligned words in target sentence can be considered as having the same dependency relationship equivalently. $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.
The dependency projection method DPA (Hwa et al, 2005) based on Direct Correspondence Assumption (Hwa et al, 2002) can be described as: if there is a pair of source words with a dependency relationship, the corresponding aligned words in target sentence can be considered as having the same dependency relationship equivalently. $$$$$ As art example where the DCA relates dependency structures, consider the hierarchical alignment algorithm proposed by Alshawi et al. (2000).

This idea was followed by (Hwa et al, 2002) who investigated English to Chinese projections based on the direct correspondence assumption. $$$$$ The English-Basque example (1) illustrates: if the English word buy is aligned to the Basque word erosi and gift is aligned to opari, the creation of the head-modifier relationship between buy and gift is accompanied by the creation of a corresponding head-modifier relationship between erosi and opari.
This idea was followed by (Hwa et al, 2002) who investigated English to Chinese projections based on the direct correspondence assumption. $$$$$ In Yamada and Knight's (2001) extension of the IBM models, on the other hand, grammatical information from the source language is propagated into the noisy channel, and the grammatical transformations in their channel model appear to respect direct correspondence.3 The simultaneous parsing and alignment algorithm of Alshawi et al. (2000) is essentially art implementation of the DCA in which relationship R has no linguistic import (i.e. anything can be a head).
This idea was followed by (Hwa et al, 2002) who investigated English to Chinese projections based on the direct correspondence assumption. $$$$$ 2001.
This idea was followed by (Hwa et al, 2002) who investigated English to Chinese projections based on the direct correspondence assumption. $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.

Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al, 2002). $$$$$ Our experiments confirm the linguistic intuition, indicating that one cannot safely assume a direct mapping between the syntactic dependencies of one language and the syntactic dependencies of another.
Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al, 2002). $$$$$ Because our error analysis and subsequent algorithm refinements made use of our original Chinese-English data set, we created a new test set based on 88 new Chinese sentences from the Penn Chinese Treebank, already manually translated into English as part of the NIST MT evaluation preview.5 These sentences averaged 19.0 words in length.
Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al, 2002). $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.

Analogously to Hwa et al (2002), we investigate whether there are indeed semantic correspondences between two languages, since there is little hope for projecting meaningful annotations in nonparallel semantic structures. $$$$$ Inspection of the results revealed that our manually aligned parallel corpus contained many instances of multiply aligned or unaligned tokens, owing either to freeness of translation 40ne author of this paper served as one of the annotators.
Analogously to Hwa et al (2002), we investigate whether there are indeed semantic correspondences between two languages, since there is little hope for projecting meaningful annotations in nonparallel semantic structures. $$$$$ In this framework, wordlevel alignments and paired dependency structures are constructed simultaneously.
Analogously to Hwa et al (2002), we investigate whether there are indeed semantic correspondences between two languages, since there is little hope for projecting meaningful annotations in nonparallel semantic structures. $$$$$ Intelligence,
Analogously to Hwa et al (2002), we investigate whether there are indeed semantic correspondences between two languages, since there is little hope for projecting meaningful annotations in nonparallel semantic structures. $$$$$ Another deals with aspectual markers for verbs: â€¢ If vi, vk, a sequence of Chinese words aligned with English verbs, is followed by a, an aspect marker, make a into a modifier of the last verb vk.

Similarly to previous work (Hwa et al, 2002), we find that some mileage can be gained by assuming direct correspondence between two languages. $$$$$ As art example where the DCA relates dependency structures, consider the hierarchical alignment algorithm proposed by Alshawi et al. (2000).
Similarly to previous work (Hwa et al, 2002), we find that some mileage can be gained by assuming direct correspondence between two languages. $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.
Similarly to previous work (Hwa et al, 2002), we find that some mileage can be gained by assuming direct correspondence between two languages. $$$$$ In of NAACL, Shieber.

We take as the starting point of annotation projection the direct correspondence assumption as formulated in (Hwa et al, 2002): for two sentences in parallel translation, the syntactic relationships in one language directly map the syntactic relationships in the other, and extend it to POS tags as well. $$$$$ (DCA): Given a pair of sentences E and F that are (literal) translations of each other with syntactic structures TreeE and TreeF, if nodes E and YE of TreeE are aligned with nodes xF and YF of TreeF, respectively, and if syntactic relationship R(x E, YE) holds in TreeE, then R(x F , YF) holds in TreeF.
We take as the starting point of annotation projection the direct correspondence assumption as formulated in (Hwa et al, 2002): for two sentences in parallel translation, the syntactic relationships in one language directly map the syntactic relationships in the other, and extend it to POS tags as well. $$$$$ Unfortunately, the DCA is flawed, even for literal translations.
We take as the starting point of annotation projection the direct correspondence assumption as formulated in (Hwa et al, 2002): for two sentences in parallel translation, the syntactic relationships in one language directly map the syntactic relationships in the other, and extend it to POS tags as well. $$$$$ The English-Basque example (1) illustrates: if the English word buy is aligned to the Basque word erosi and gift is aligned to opari, the creation of the head-modifier relationship between buy and gift is accompanied by the creation of a corresponding head-modifier relationship between erosi and opari.

Hwa et al (2002) have noticed that applying elementary linguistic transformations considerably increases precision and recall when projecting syntactic relations, at least for the English/Chinese language pair. $$$$$ 2001.
Hwa et al (2002) have noticed that applying elementary linguistic transformations considerably increases precision and recall when projecting syntactic relations, at least for the English/Chinese language pair. $$$$$ Let us formalize this intuitive idea about corresponding syntactic relationships in the following more general way:
Hwa et al (2002) have noticed that applying elementary linguistic transformations considerably increases precision and recall when projecting syntactic relations, at least for the English/Chinese language pair. $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.
Hwa et al (2002) have noticed that applying elementary linguistic transformations considerably increases precision and recall when projecting syntactic relations, at least for the English/Chinese language pair. $$$$$ Let us formalize this intuitive idea about corresponding syntactic relationships in the following more general way:

In a different approach, Hwa et al (2002) aligned the parallel sentences using phrase based statistical MT models and then projected the alignments back to the parse trees. $$$$$ Our error analysis led to the conclusion that the correspondence of syntactic relationships would be improved by a better handling of the one-tomany mappings and the unaligned cases.
In a different approach, Hwa et al (2002) aligned the parallel sentences using phrase based statistical MT models and then projected the alignments back to the parse trees. $$$$$ Chinese and English share the property that they are headinitial for most phrase types.
In a different approach, Hwa et al (2002) aligned the parallel sentences using phrase based statistical MT models and then projected the alignments back to the parse trees. $$$$$ Yet this is not art unfamiliar situation.
In a different approach, Hwa et al (2002) aligned the parallel sentences using phrase based statistical MT models and then projected the alignments back to the parse trees. $$$$$ This will break the bottleneck in developing appropriately annotated training corpora.

Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al, 2002). $$$$$ Systematic application of this sort of linguistic knowledge turns out to be the key in getting beyond the DCA's limitations.
Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al, 2002). $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.

Our DS projection algorithm is similar to the projection algorithms described in (Hwa et al, 2002) and (Quirk et al, 2005). $$$$$ In this framework, wordlevel alignments and paired dependency structures are constructed simultaneously.

Following Hwa et al (2002), we looked at dependency links in the true English parses from the KTB where both the dependent and the head were linked to words on the Korean side using the intersection alignment. $$$$$ For years, stochastic modeling of language has depended on the linguistically implausible assumptions underlying'n-gram models, hidden Markov models, context-free grammars, and the like, with remarkable success.
Following Hwa et al (2002), we looked at dependency links in the true English parses from the KTB where both the dependent and the head were linked to words on the Korean side using the intersection alignment. $$$$$ 2001.
Following Hwa et al (2002), we looked at dependency links in the true English parses from the KTB where both the dependent and the head were linked to words on the Korean side using the intersection alignment. $$$$$ The experimental results show that evert the simplistic DCA can be useful when operating in conjunction with small quantities of systematic linguistic knowledge.

Since unary productions do not translate well from language to language (Hwa et al, 2002), we collapse them to their lower nodes. $$$$$ 1994.
Since unary productions do not translate well from language to language (Hwa et al, 2002), we collapse them to their lower nodes. $$$$$ 1994.
Since unary productions do not translate well from language to language (Hwa et al, 2002), we collapse them to their lower nodes. $$$$$ In Chinese, verbal and prepositional phrases respect the English ordering but heads in the nominal system uniformly appear to the right.
Since unary productions do not translate well from language to language (Hwa et al, 2002), we collapse them to their lower nodes. $$$$$ In addition to resolving the remaining problematic cases for our projection framework, we are exploring ways to automatically create large quantities of syntactically annotated data.

Fox (2002) has considered English and French, and Hwa et al (2002) investigate Chinese and English. $$$$$ The inadequacy of the DCA should come as no surprise.
Fox (2002) has considered English and French, and Hwa et al (2002) investigate Chinese and English. $$$$$ Let us formalize this intuitive idea about corresponding syntactic relationships in the following more general way:
Fox (2002) has considered English and French, and Hwa et al (2002) investigate Chinese and English. $$$$$ As art example where the DCA relates dependency structures, consider the hierarchical alignment algorithm proposed by Alshawi et al. (2000).
Fox (2002) has considered English and French, and Hwa et al (2002) investigate Chinese and English. $$$$$ The English-Basque example (1) illustrates: if the English word buy is aligned to the Basque word erosi and gift is aligned to opari, the creation of the head-modifier relationship between buy and gift is accompanied by the creation of a corresponding head-modifier relationship between erosi and opari.

Our hand-aligned test data were those used in Hwa et al (2002), and consisted of 48 sentence pairs also with less than 25 words in either language, for a total of 788 English words and 580 Chinese words. $$$$$ We are also actively developing art alternative alignment model that makes more use of the syntactic structure (Lopez et al., 2002).
Our hand-aligned test data were those used in Hwa et al (2002), and consisted of 48 sentence pairs also with less than 25 words in either language, for a total of 788 English words and 580 Chinese words. $$$$$ Having made the DCA explicit, we would suggest that the right questions are: to what extent is it true, and how useful is it when it holds?
Our hand-aligned test data were those used in Hwa et al (2002), and consisted of 48 sentence pairs also with less than 25 words in either language, for a total of 788 English words and 580 Chinese words. $$$$$ A best-first alignment algorithm for automatic extraction of transfer mappings from bilingual cor- In of the 39th Annual Meeting of the Association for Computational Linguistics DDMT Workshop, France.

Hwa et al (2002) found that human translations from Chinese to English preserved only 39-42% of the unlabeled Chinese dependencies. $$$$$ The corpus for this experiment was constructed by obtaining manual English translations for 124 Chinese newswire sentences (with 40 words or less) contained in sections 001-015 of the Penn Chinese Treebank (Xia et al., 2000).
Hwa et al (2002) found that human translations from Chinese to English preserved only 39-42% of the unlabeled Chinese dependencies. $$$$$ Our first goal is to minimize the degree of degradation in the quality of the projected trees when the input analyses and word alignments are automatically generated by a statistical parser and word alignment model.

Moreover, as stressed in previous research, using syntactic dependencies seems to be particularly well suited to coping with the problem of linguistic variation across languages (Hwa et al, 2002). $$$$$ Because our error analysis and subsequent algorithm refinements made use of our original Chinese-English data set, we created a new test set based on 88 new Chinese sentences from the Penn Chinese Treebank, already manually translated into English as part of the NIST MT evaluation preview.5 These sentences averaged 19.0 words in length.
Moreover, as stressed in previous research, using syntactic dependencies seems to be particularly well suited to coping with the problem of linguistic variation across languages (Hwa et al, 2002). $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.
Moreover, as stressed in previous research, using syntactic dependencies seems to be particularly well suited to coping with the problem of linguistic variation across languages (Hwa et al, 2002). $$$$$ Intelligence,

A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ (Lin, 1998)) and to perform a qualitative error analysis.
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ In of NAACL, Shieber.

These sets were the data used by Hwa et al (2002). $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.

IGT's unique structure â€” effectively each instance consists of a bitext between English and some target language â€” can be easily enriched through alignment and projection (e.g., (Yarowsky and Ngai, 2001), (Hwa et al., 2002)). $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.
IGT's unique structure â€” effectively each instance consists of a bitext between English and some target language â€” can be easily enriched through alignment and projection (e.g., (Yarowsky and Ngai, 2001), (Hwa et al., 2002)). $$$$$ resource acquisition.
IGT's unique structure â€” effectively each instance consists of a bitext between English and some target language â€” can be easily enriched through alignment and projection (e.g., (Yarowsky and Ngai, 2001), (Hwa et al., 2002)). $$$$$ For example, in sentence pair (1), the indirect object of the verb is expressed in English using a prepositional phrase (headed by the word for) that attaches to the verb, but it is expressed with the dative case marking ort anaiari (BROTHER-DAT) it Basque.
