Recent work (Hwa et al, 2002) suggests that translational corresponence of linguistic structures can indeed be useful in projecting parses across languages. $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.
Recent work (Hwa et al, 2002) suggests that translational corresponence of linguistic structures can indeed be useful in projecting parses across languages. $$$$$ In of NAACL, Shieber.
Recent work (Hwa et al, 2002) suggests that translational corresponence of linguistic structures can indeed be useful in projecting parses across languages. $$$$$ To what extent is the DCA a valid assumption?

The dependency projection method DPA (Hwa et al, 2005) based on Direct Correspondence Assumption (Hwa et al, 2002) can be described as $$$$$ â€¢ many-to-one if wjE, wnE E E are all uniquely aligned to WF E F, then delete all alignments between wiE (1 < i < n) and WF except for the head (denoted as whE ); moreover, if wiE , a modifier of .tchE, had its own modifiers, R(tviE, wjE) R(tch, wJF).
The dependency projection method DPA (Hwa et al, 2005) based on Direct Correspondence Assumption (Hwa et al, 2002) can be described as $$$$$ Currently, we are following two research directions.
The dependency projection method DPA (Hwa et al, 2005) based on Direct Correspondence Assumption (Hwa et al, 2002) can be described as $$$$$ The English-Basque example (1) illustrates: if the English word buy is aligned to the Basque word erosi and gift is aligned to opari, the creation of the head-modifier relationship between buy and gift is accompanied by the creation of a corresponding head-modifier relationship between erosi and opari.

This idea was followed by (Hwa et al, 2002) who investigated English to Chinese projections based on the direct correspondence assumption. $$$$$ The syntax literature dating back to Cltomsky (1981), together with a rich computational literature on translation divergences (e.g.
This idea was followed by (Hwa et al, 2002) who investigated English to Chinese projections based on the direct correspondence assumption. $$$$$ Intelligence,

Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al, 2002). $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.
Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al, 2002). $$$$$ For example, SITG can generate verb initial (English) and verb final (Japanese) verb phrases using the same rule VP V NP.
Previous work has primarily focused on the projection of grammatical (Yarowsky and Ngai, 2001) and syntactic information (Hwa et al, 2002). $$$$$ Similarly, a one-to-many mapping (e.g., aligning got with erosi (Buy) and nion (PAST) in this example) can also be problematic for the DCA.

Analogously to Hwa et al (2002), we investigate whether there are indeed semantic correspondences between two languages, since there is little hope for projecting meaningful annotations in nonparallel semantic structures. $$$$$ Moreover, the DCA makes possible more elegant formalisms (e.g.
Analogously to Hwa et al (2002), we investigate whether there are indeed semantic correspondences between two languages, since there is little hope for projecting meaningful annotations in nonparallel semantic structures. $$$$$ Currently, we are following two research directions.
Analogously to Hwa et al (2002), we investigate whether there are indeed semantic correspondences between two languages, since there is little hope for projecting meaningful annotations in nonparallel semantic structures. $$$$$ First, we adopted a simple strategy informed by the tendency of languages to have a consistent direction for &quot;headedness&quot;.

Similarly to previous work (Hwa et al, 2002), we find that some mileage can be gained by assuming direct correspondence between two languages. $$$$$ Moreover, the DCA makes possible more elegant formalisms (e.g.
Similarly to previous work (Hwa et al, 2002), we find that some mileage can be gained by assuming direct correspondence between two languages. $$$$$ 1994.

We take as the starting point of annotation projection the direct correspondence assumption as formulated in (Hwa et al, 2002) $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.
We take as the starting point of annotation projection the direct correspondence assumption as formulated in (Hwa et al, 2002) $$$$$ The approach described here strikes a balance somewhere between the endless construction-by-construction tuning of rule-based approaches, ort the one hand, and, ort the other, the development of insufficiently constrained stochastic models.
We take as the starting point of annotation projection the direct correspondence assumption as formulated in (Hwa et al, 2002) $$$$$ Unfortunately, the DCA is flawed, even for literal translations.

Hwa et al (2002) have noticed that applying elementary linguistic transformations considerably increases precision and recall when projecting syntactic relations, at least for the English/Chinese language pair. $$$$$ How useful is the DCA?
Hwa et al (2002) have noticed that applying elementary linguistic transformations considerably increases precision and recall when projecting syntactic relations, at least for the English/Chinese language pair. $$$$$ 2001.

In a different approach, Hwa et al (2002) aligned the parallel sentences using phrase based statistical MT models and then projected the alignments back to the parse trees. $$$$$ For example, to quantify a Chinese noun with a determiner, one also needs to supply a measure word in addition to the quantity.
In a different approach, Hwa et al (2002) aligned the parallel sentences using phrase based statistical MT models and then projected the alignments back to the parse trees. $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.

Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al, 2002). $$$$$ For arty derivation using this rule, if VE and NPE are the English verb and noun phrase, and they are respectively aligned with Japanese verb and noun phrase v j and NP j, then VERB-OBJECT(VE, NPE) and VERB-OBJECT(V j, NP j) mug both be true.

Our DS projection algorithm is similar to the projection algorithms described in (Hwa et al, 2002) and (Quirk et al, 2005). $$$$$ We have systematically diagnosed a common assumption that has been dealt with previously ort a case by case basis, but not named.
Our DS projection algorithm is similar to the projection algorithms described in (Hwa et al, 2002) and (Quirk et al, 2005). $$$$$ The IBM MT models (Brown et al., 1993) do not respect the DCA, but neither do they attempt to model arty higher level syntactic relationship between constituents within or across languages the translation model (alignments) and the language model are statistically independent.

Following Hwa et al (2002), we looked at dependency links in the true English parses from the KTB where both the dependent and the head were linked to words on the Korean side using the intersection alignment. $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.
Following Hwa et al (2002), we looked at dependency links in the true English parses from the KTB where both the dependent and the head were linked to words on the Korean side using the intersection alignment. $$$$$ (Lin, 1998)) and to perform a qualitative error analysis.
Following Hwa et al (2002), we looked at dependency links in the true English parses from the KTB where both the dependent and the head were linked to words on the Korean side using the intersection alignment. $$$$$ 1998.
Following Hwa et al (2002), we looked at dependency links in the true English parses from the KTB where both the dependent and the head were linked to words on the Korean side using the intersection alignment. $$$$$ More important, we have shown that linguistically informed strategies can be developed efficiently to improve output that is otherwise compromised by situations where the DCA does not hold.

Since unary productions do not translate well from language to language (Hwa et al, 2002), we collapse them to their lower nodes. $$$$$ For arty derivation using this rule, if VE and NPE are the English verb and noun phrase, and they are respectively aligned with Japanese verb and noun phrase v j and NP j, then VERB-OBJECT(VE, NPE) and VERB-OBJECT(V j, NP j) mug both be true.
Since unary productions do not translate well from language to language (Hwa et al, 2002), we collapse them to their lower nodes. $$$$$ As art example where the DCA relates dependency structures, consider the hierarchical alignment algorithm proposed by Alshawi et al. (2000).
Since unary productions do not translate well from language to language (Hwa et al, 2002), we collapse them to their lower nodes. $$$$$ This work has been supported, in part, by ONR MUM Contract FCP0.810548265, NSA RD02-5700, DARPA/ITO Cooperative Agreement N660010028910, and Mitre Contract 0104187712.

Fox (2002) has considered English and French, and Hwa et al (2002) investigate Chinese and English. $$$$$ To what extent is the DCA a valid assumption?
Fox (2002) has considered English and French, and Hwa et al (2002) investigate Chinese and English. $$$$$ The DCA seems to be a reasonable principle, especially when expressed in terms of syntactic dependencies that abstract away word order.
Fox (2002) has considered English and French, and Hwa et al (2002) investigate Chinese and English. $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.

Our hand-aligned test data were those used in Hwa et al (2002), and consisted of 48 sentence pairs also with less than 25 words in either language, for a total of 788 English words and 580 Chinese words. $$$$$ Intelligence,
Our hand-aligned test data were those used in Hwa et al (2002), and consisted of 48 sentence pairs also with less than 25 words in either language, for a total of 788 English words and 580 Chinese words. $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.

Hwa et al (2002) found that human translations from Chinese to English preserved only 39-42% of the unlabeled Chinese dependencies. $$$$$ The DCA seems to be a reasonable principle, especially when expressed in terms of syntactic dependencies that abstract away word order.
Hwa et al (2002) found that human translations from Chinese to English preserved only 39-42% of the unlabeled Chinese dependencies. $$$$$ For example, in sentence pair (1), the indirect object of the verb is expressed in English using a prepositional phrase (headed by the word for) that attaches to the verb, but it is expressed with the dative case marking ort anaiari (BROTHER-DAT) it Basque.

Moreover, as stressed in previous research, using syntactic dependencies seems to be particularly well suited to coping with the problem of linguistic variation across languages (Hwa et al, 2002). $$$$$ To improve the quality of the input analyses, we are adapting active learning and co-training techniques (Hwa, 2000; Sarkar, 2001) to exploit the most reliable data.
Moreover, as stressed in previous research, using syntactic dependencies seems to be particularly well suited to coping with the problem of linguistic variation across languages (Hwa et al, 2002). $$$$$ Because Chinese classifiers, aspectual particles, and other functional words do not appear in the English sentence, there is no way for a projected English analysis to correctly account for them.
Moreover, as stressed in previous research, using syntactic dependencies seems to be particularly well suited to coping with the problem of linguistic variation across languages (Hwa et al, 2002). $$$$$ Similarly, a one-to-many mapping (e.g., aligning got with erosi (Buy) and nion (PAST) in this example) can also be problematic for the DCA.

A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ Most of the models we know of from early work at IBM to second-generation models such as that of Knight and Yamada rectify glaring problems caused by the failure of the DCA using a range of pre- or post-processing techniques.
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ In this framework, wordlevel alignments and paired dependency structures are constructed simultaneously.
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ SITG) and more efficient algorithms It may allow us to use the syntactic analysis for one language to infer annotations for the corresponding sentence in another language, helping to reduce the labor and expense of creating treebanks in new languages (Cabezas et al., 2001; Yarowsky and Ngai, 2001).
A wide range of annotations from part of speech (Hi and Hwa, 2005) and chunks (Yarowsky et al, 2001) to word senses (Diab and Resnik, 2002), dependencies (Hwa et al, 2002) and semantic roles (Pado and Lapata, 2009) have been successfully transferred between languages. $$$$$ The IBM MT models (Brown et al., 1993) do not respect the DCA, but neither do they attempt to model arty higher level syntactic relationship between constituents within or across languages the translation model (alignments) and the language model are statistically independent.

These sets were the data used by Hwa et al (2002). $$$$$ For example, current theories claim that languages employ stable headcomplement orders across construction types.
These sets were the data used by Hwa et al (2002). $$$$$ Annotation style guide for the blinker project.
These sets were the data used by Hwa et al (2002). $$$$$ Currently, we are following two research directions.

IGT's unique structure â€” effectively each instance consists of a bitext between English and some target language â€” can be easily enriched through alignment and projection (e.g., (Yarowsky and Ngai, 2001), (Hwa et al., 2002)). $$$$$ The authors would like to thank Edward Hung, Gina Levow, and Lingling Zhang for their assistance as annotators; Michael Collins for the use of his parser; Franz Josef Och for his help with GIZA++; and Lillian Lee, the students of CM5C828, and the anonymous reviewers for their comments ort this paper.
IGT's unique structure â€” effectively each instance consists of a bitext between English and some target language â€” can be easily enriched through alignment and projection (e.g., (Yarowsky and Ngai, 2001), (Hwa et al., 2002)). $$$$$ The implication of this work for statistical translation modeling is that a little bit of knowledge can be a good thing.
IGT's unique structure â€” effectively each instance consists of a bitext between English and some target language â€” can be easily enriched through alignment and projection (e.g., (Yarowsky and Ngai, 2001), (Hwa et al., 2002)). $$$$$ Technical Report IRCS 98-06, University of Pennsylvania.
IGT's unique structure â€” effectively each instance consists of a bitext between English and some target language â€” can be easily enriched through alignment and projection (e.g., (Yarowsky and Ngai, 2001), (Hwa et al., 2002)). $$$$$ Unfortunately, the DCA is flawed, even for literal translations.
