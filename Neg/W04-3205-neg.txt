LSA Match $$$$$ The verb relations we discover are similarity, strength, antonymy, enablement, and temporal relations.
LSA Match $$$$$ Further work may refine extraction methods and further process the mined semantics to derive other relations such as entailment.
LSA Match $$$$$ The authors wish to thank the reviewers for their helpful comments and Google Inc. for supporting high volume querying of their index.
LSA Match $$$$$ Broad-coverage repositories of semantic relations between verbs could benefit many NLP tasks.

We will consider to use a supervised learning approach, as well as the similar features employed for temporal relation classification task, in addition to lexical information (e.g. WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004)) and the existing causal signals. $$$$$ This research was partly supported by NSF grant #EIA-0205111.
We will consider to use a supervised learning approach, as well as the similar features employed for temporal relation classification task, in addition to lexical information (e.g. WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004)) and the existing causal signals. $$$$$ On a set of 29,165 associated verb pairs, experimental results show an accuracy of 65.5% in assigning similarity, strength, antonymy, enablement, and happens-before.
We will consider to use a supervised learning approach, as well as the similar features employed for temporal relation classification task, in addition to lexical information (e.g. WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004)) and the existing causal signals. $$$$$ Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus.

For event terms, we first find the root verbs of deverbal nouns and then measure verb similarity by using the fine-grained relations provided by VerbOcean (Chklovski and Pantel, 2004), which has proved useful in summarization (Liu et al, 2007). $$$$$ For verbs, we need to estimate the frequency of the verbs, but avoid counting other parts-of-speech (e.g. chair as a noun or painted as an adjective).
For event terms, we first find the root verbs of deverbal nouns and then measure verb similarity by using the fine-grained relations provided by VerbOcean (Chklovski and Pantel, 2004), which has proved useful in summarization (Liu et al, 2007). $$$$$ For verbs, we need to estimate the frequency of the verbs, but avoid counting other parts-of-speech (e.g. chair as a noun or painted as an adjective).

In particular, we could emulate the approach used in VerbOcean (Chklovski and Pantel 2004). $$$$$ Our approach can potentially be extended to multiword paths.
In particular, we could emulate the approach used in VerbOcean (Chklovski and Pantel 2004). $$$$$ Further work may refine extraction methods and further process the mined semantics to derive other relations such as entailment.
In particular, we could emulate the approach used in VerbOcean (Chklovski and Pantel 2004). $$$$$ This research was partly supported by NSF grant #EIA-0205111.

The work on VerbOcean is similar to our research in the use of the Web for acquiring relationships (Chklovski and Pantel, 2004). $$$$$ Finally, as discussed in Section 5.3, entailment relations may be derivable by processing the complete graph of the identified semantic relation.
The work on VerbOcean is similar to our research in the use of the Web for acquiring relationships (Chklovski and Pantel, 2004). $$$$$ If the entire database is viewed as a graph, we currently leverage and enforce only local consistency.
The work on VerbOcean is similar to our research in the use of the Web for acquiring relationships (Chklovski and Pantel, 2004). $$$$$ The authors wish to thank the reviewers for their helpful comments and Google Inc. for supporting high volume querying of their index.
The work on VerbOcean is similar to our research in the use of the Web for acquiring relationships (Chklovski and Pantel, 2004). $$$$$ Another possibility would be to use more relaxed patterns when the part of speech confusion is not likely (e.g.

Work on semantic similarity learning such as Chklovski and Pantel (2004) also automatically learns relations between verbs. $$$$$ V1 stronger-than V2, and V2 strongerthan V3 indicates that V1 stronger-than V3, which may be leveraged to identify additional relations or inconsistent relations (e.g.
Work on semantic similarity learning such as Chklovski and Pantel (2004) also automatically learns relations between verbs. $$$$$ For example, it may be valuable to know that if someone has bought an item, they may sell it at a later time.
Work on semantic similarity learning such as Chklovski and Pantel (2004) also automatically learns relations between verbs. $$$$$ 73% gives an idea of an upper bound for humans on this task.
Work on semantic similarity learning such as Chklovski and Pantel (2004) also automatically learns relations between verbs. $$$$$ In document classification, Klavans and Kan (1998) demonstrate that document type is correlated with the presence of many verbs of a certain EVCA class (Levin 1993).

For example, Chklovski and Pantel (2004) loosely define ENABLEMENT as a relation that holds between two verbs V1 and V2 when the pair can be glossed as V1 is accomplished by V2 and gives two examples $$$$$ We use a total of 35 patterns, which are listed in Table 2 along with the estimated frequency of hits.
For example, Chklovski and Pantel (2004) loosely define ENABLEMENT as a relation that holds between two verbs V1 and V2 when the pair can be glossed as V1 is accomplished by V2 and gives two examples $$$$$ There are several ways to improve the accuracy of the current algorithm and to detect relations between low frequency verb pairs.
For example, Chklovski and Pantel (2004) loosely define ENABLEMENT as a relation that holds between two verbs V1 and V2 when the pair can be glossed as V1 is accomplished by V2 and gives two examples $$$$$ This research was partly supported by NSF grant #EIA-0205111.
For example, Chklovski and Pantel (2004) loosely define ENABLEMENT as a relation that holds between two verbs V1 and V2 when the pair can be glossed as V1 is accomplished by V2 and gives two examples $$$$$ Happens-before.

Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hy ponyms (Hearst, 1992) ,meronyms (Girju, 2003), synonyms (Lin et al, 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al, 2003). $$$$$ For symmetric relations only, the verbs can fill the lexico-syntactic pattern in either order.
Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hy ponyms (Hearst, 1992) ,meronyms (Girju, 2003), synonyms (Lin et al, 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al, 2003). $$$$$ We provide the called for download at
Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hy ponyms (Hearst, 1992) ,meronyms (Girju, 2003), synonyms (Lin et al, 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al, 2003). $$$$$ This research was partly supported by NSF grant #EIA-0205111.
Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hy ponyms (Hearst, 1992) ,meronyms (Girju, 2003), synonyms (Lin et al, 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al, 2003). $$$$$ This research was partly supported by NSF grant #EIA-0205111.

Chklovski and Pantel (2004) used patterns like 'x-ed by y-ing' ('obtained by borrowing') to get co-occurrence data on candidate pairs from the Web. $$$$$ On a set of 29,165 strongly associated verb pairs, our extraction algorithm yielded 65.5% accuracy.
Chklovski and Pantel (2004) used patterns like 'x-ed by y-ing' ('obtained by borrowing') to get co-occurrence data on candidate pairs from the Web. $$$$$ Finally, as described in Section 4.3, we compare the strengths of the individual semantic relations and, preferring the most specific and then strongest relations, output a consistent set as the final output.
Chklovski and Pantel (2004) used patterns like 'x-ed by y-ing' ('obtained by borrowing') to get co-occurrence data on candidate pairs from the Web. $$$$$ Our approach addresses verbs and provides for a richer and finer-grained set of semantics.

Chklovski and Pantel (2004) introduce a 5-class set, designed specifically for characterizing verb-verb semantic relations. $$$$$ The authors wish to thank the reviewers for their helpful comments and Google Inc. for supporting high volume querying of their index.
Chklovski and Pantel (2004) introduce a 5-class set, designed specifically for characterizing verb-verb semantic relations. $$$$$ The judges were also asked to identify their preferred semantic relations (i.e. those relations which seem most plausible).
Chklovski and Pantel (2004) introduce a 5-class set, designed specifically for characterizing verb-verb semantic relations. $$$$$ We detect similarity, strength, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs using lexicosyntactic patterns over the Web.
Chklovski and Pantel (2004) introduce a 5-class set, designed specifically for characterizing verb-verb semantic relations. $$$$$ We present a semi-automatic method for extracting fine-grained semantic relations between verbs.

This metric allows to match synonym predicates by using verb ontologies such as VerbNet (Schuler, 2006) and VerbOcean (Chklovski and Pantel, 2004) and distributional semantics similarity metrics, such as Dekang Lin's thesaurus (Lin, 1998), where previous semantic metrics only perform exact match of predicate structures and arguments. $$$$$ On a set of 29,165 associated verb pairs, experimental results show an accuracy of 65.5% in assigning similarity, strength, antonymy, enablement, and happens-before.
This metric allows to match synonym predicates by using verb ontologies such as VerbNet (Schuler, 2006) and VerbOcean (Chklovski and Pantel, 2004) and distributional semantics similarity metrics, such as Dekang Lin's thesaurus (Lin, 1998), where previous semantic metrics only perform exact match of predicate structures and arguments. $$$$$ This research was partly supported by NSF grant #EIA-0205111.
This metric allows to match synonym predicates by using verb ontologies such as VerbNet (Schuler, 2006) and VerbOcean (Chklovski and Pantel, 2004) and distributional semantics similarity metrics, such as Dekang Lin's thesaurus (Lin, 1998), where previous semantic metrics only perform exact match of predicate structures and arguments. $$$$$ We detect similarity, strength, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs using lexicosyntactic patterns over the Web.

Work was also done on relations be tween verbs (Chklovski and Pantel, 2004). $$$$$ Finally, as discussed in Section 5.3, entailment relations may be derivable by processing the complete graph of the identified semantic relation.
Work was also done on relations be tween verbs (Chklovski and Pantel, 2004). $$$$$ This research was partly supported by NSF grant #EIA-0205111.
Work was also done on relations be tween verbs (Chklovski and Pantel, 2004). $$$$$ Rather, verbs are often similar or related.

Hence, when exploring very specific relation ship types or very generic, but not widely accepted, types (like verb strength), many researchers resort to manual human-based evaluation (Chklovski and Pantel, 2004). $$$$$ As discussed by Fellbaum (1998), it can arise from switching thematic roles associated with the verb (as in buy :: sell, lend :: borrow).
Hence, when exploring very specific relation ship types or very generic, but not widely accepted, types (like verb strength), many researchers resort to manual human-based evaluation (Chklovski and Pantel, 2004). $$$$$ It would be useful to enforce global consistency, e.g.
Hence, when exploring very specific relation ship types or very generic, but not widely accepted, types (like verb strength), many researchers resort to manual human-based evaluation (Chklovski and Pantel, 2004). $$$$$ In addition to discovering relations identified in WordNet, such as opposition and enablement, we obtain strong results on strength relations (for which no wide-coverage resource is available).

30 relations are noun compound relationships as proposed in the (Nastase and Szpakowicz, 2003 ) classification scheme, and 5 relations are verb-verb relations proposed by (Chklovski and Pantel, 2004). $$$$$ The Appendix shows sample relationships discovered by the system.
30 relations are noun compound relationships as proposed in the (Nastase and Szpakowicz, 2003 ) classification scheme, and 5 relations are verb-verb relations proposed by (Chklovski and Pantel, 2004). $$$$$ We have demonstrated that certain fine-grained semantic relations between verbs are present on the Web, and are extractable with a simple patternbased approach.
30 relations are noun compound relationships as proposed in the (Nastase and Szpakowicz, 2003 ) classification scheme, and 5 relations are verb-verb relations proposed by (Chklovski and Pantel, 2004). $$$$$ However, DIRT only outputs pairs of paths that have some semantic relation.
30 relations are noun compound relationships as proposed in the (Nastase and Szpakowicz, 2003 ) classification scheme, and 5 relations are verb-verb relations proposed by (Chklovski and Pantel, 2004). $$$$$ We have demonstrated that certain fine-grained semantic relations between verbs are present on the Web, and are extractable with a simple patternbased approach.

Other types of relations that have been studied by pattern-based approaches include question answer relations (such as birthdates and inventor) (Ravichandran and Hovy, 2002), synonyms and antonyms (Lin et al, 2003), general purpose analogy (Turney et al, 2003), verb relations (including similarity, strength, antonym, enable ment and temporal) (Chklovski and Pantel, 2004), entailment (Szpektor et al, 2004), and more specific relations, such as purpose, creation (Cimiano and Wenderoth, 2007), LivesIn, and EmployedBy (Bunescu and Mooney, 2007). $$$$$ Sample verb pairs extracted by our system, in the order weak to strong, are: taint :: poison, permit :: authorize, surprise :: startle, startle :: shock.
Other types of relations that have been studied by pattern-based approaches include question answer relations (such as birthdates and inventor) (Ravichandran and Hovy, 2002), synonyms and antonyms (Lin et al, 2003), general purpose analogy (Turney et al, 2003), verb relations (including similarity, strength, antonym, enable ment and temporal) (Chklovski and Pantel, 2004), entailment (Szpektor et al, 2004), and more specific relations, such as purpose, creation (Cimiano and Wenderoth, 2007), LivesIn, and EmployedBy (Bunescu and Mooney, 2007). $$$$$ The authors wish to thank the reviewers for their helpful comments and Google Inc. for supporting high volume querying of their index.
Other types of relations that have been studied by pattern-based approaches include question answer relations (such as birthdates and inventor) (Ravichandran and Hovy, 2002), synonyms and antonyms (Lin et al, 2003), general purpose analogy (Turney et al, 2003), verb relations (including similarity, strength, antonym, enable ment and temporal) (Chklovski and Pantel, 2004), entailment (Szpektor et al, 2004), and more specific relations, such as purpose, creation (Cimiano and Wenderoth, 2007), LivesIn, and EmployedBy (Bunescu and Mooney, 2007). $$$$$ Broad-coverage repositories of semantic relations between verbs could benefit many NLP tasks.
Other types of relations that have been studied by pattern-based approaches include question answer relations (such as birthdates and inventor) (Ravichandran and Hovy, 2002), synonyms and antonyms (Lin et al, 2003), general purpose analogy (Turney et al, 2003), verb relations (including similarity, strength, antonym, enable ment and temporal) (Chklovski and Pantel, 2004), entailment (Szpektor et al, 2004), and more specific relations, such as purpose, creation (Cimiano and Wenderoth, 2007), LivesIn, and EmployedBy (Bunescu and Mooney, 2007). $$$$$ &quot;eat&quot; is a common verb which does not have a noun sense, and patterns need not protect against noun senses when testing such verbs).

We introduce VerbOcean (Chklovski and Pantel, 2004), a broad-coverage repository of semantic verb relations, into event-based summarization. $$$$$ The authors wish to thank the reviewers for their helpful comments and Google Inc. for supporting high volume querying of their index.
We introduce VerbOcean (Chklovski and Pantel, 2004), a broad-coverage repository of semantic verb relations, into event-based summarization. $$$$$ The authors wish to thank the reviewers for their helpful comments and Google Inc. for supporting high volume querying of their index.
We introduce VerbOcean (Chklovski and Pantel, 2004), a broad-coverage repository of semantic verb relations, into event-based summarization. $$$$$ For tasks which require canonicalization of natural language statements or derivation of plausible inferences from such statements, a particularly valuable resource is one which (i) relates verbs to one another and (ii) provides broad coverage of the verbs in the target language.
We introduce VerbOcean (Chklovski and Pantel, 2004), a broad-coverage repository of semantic verb relations, into event-based summarization. $$$$$ Enablement is classified as a type of causal relation by Barker and Szpakowicz (1995).

Chklovski and Pantel (2004) address the automatic acquisition of verb-verb pairs and their relations from the web. $$$$$ We identify this as the strength relation.
Chklovski and Pantel (2004) address the automatic acquisition of verb-verb pairs and their relations from the web. $$$$$ While we hope that applications will benefit from this resource as is, an interesting next step would be to augment it with sense information.
Chklovski and Pantel (2004) address the automatic acquisition of verb-verb pairs and their relations from the web. $$$$$ This research was partly supported by NSF grant #EIA-0205111.

An ablation study that formed part of the official RTE 5 evaluation attempted to evaluate the contribution of publicly available knowledge resources such as WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004), and DIRT (Lin and Pantel, 2001) used by many of the systems. $$$$$ Our approach extends previously formulated ones that use surface patterns as indicators of semantic relations between nouns (Hearst 1992; Etzioni 2003; Ravichandran and Hovy 2002).
An ablation study that formed part of the official RTE 5 evaluation attempted to evaluate the contribution of publicly available knowledge resources such as WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004), and DIRT (Lin and Pantel, 2001) used by many of the systems. $$$$$ In discussing future work on the system's logical form matching component, Rus (2002 p. 143) points to incorporating entailment and causation verb relations to improve the matcher's performance.
An ablation study that formed part of the official RTE 5 evaluation attempted to evaluate the contribution of publicly available knowledge resources such as WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004), and DIRT (Lin and Pantel, 2001) used by many of the systems. $$$$$ Considering a coarser extraction where stronger-than relations are merged with similarity, the task of judging system tags and the task of identifying the preferred semantic relation both jump to 68.2% accuracy.

The latter utilized several resources for matching hypothesis terms with text terms $$$$$ We relate verbs to each other rather than organize them into classes or identify their frames or thematic roles.
The latter utilized several resources for matching hypothesis terms with text terms $$$$$ This approach is taken, inter alia, by a top-performing system (Moldovan et al. 2002).
The latter utilized several resources for matching hypothesis terms with text terms $$$$$ First, we identify pairs of highly associated verbs co-occurring on the Web with sufficient frequency using previous work by Lin and Pantel (2001), as described in Section 4.4.
The latter utilized several resources for matching hypothesis terms with text terms $$$$$ Sample verb pairs extracted by our system, in the order weak to strong, are: taint :: poison, permit :: authorize, surprise :: startle, startle :: shock.

Chklovski and Pantel (2004) used patterns to extract a set of relations between verbs, such as similarity, strength and antonymy. $$$$$ A set of paraphrases was generated for each pair of associated paths.
Chklovski and Pantel (2004) used patterns to extract a set of relations between verbs, such as similarity, strength and antonymy. $$$$$ The Preferred Tags Correct column gives the percentage of verb pairs whose system output relations matched exactly the human's preferred relations.
Chklovski and Pantel (2004) used patterns to extract a set of relations between verbs, such as similarity, strength and antonymy. $$$$$ In addition to discovering relations identified in WordNet, such as opposition and enablement, we obtain strong results on strength relations (for which no wide-coverage resource is available).
Chklovski and Pantel (2004) used patterns to extract a set of relations between verbs, such as similarity, strength and antonymy. $$$$$ Finally, as discussed in Section 5.3, entailment relations may be derivable by processing the complete graph of the identified semantic relation.
