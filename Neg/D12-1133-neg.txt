 $$$$$ In future work we intend to explore joint models that incorporate not only basic part-of-speech tags but also more fine-grained morphological features.
 $$$$$ Thus, Lee et al. (2011) show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian.
 $$$$$ Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins.

Li et al (2012) and Bohnet and Nivre (2012) use joint models for POS tagging and dependency parsing, significantly outperforming their pipeline counterparts. $$$$$ This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing.
Li et al (2012) and Bohnet and Nivre (2012) use joint models for POS tagging and dependency parsing, significantly outperforming their pipeline counterparts. $$$$$ The error analysis reveals improvements in tagging accuracy for syntactically central categories, mainly verbs, with improvement in syntactic accuracy for core grammatical functions as a result.
Li et al (2012) and Bohnet and Nivre (2012) use joint models for POS tagging and dependency parsing, significantly outperforming their pipeline counterparts. $$$$$ We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees.
Li et al (2012) and Bohnet and Nivre (2012) use joint models for POS tagging and dependency parsing, significantly outperforming their pipeline counterparts. $$$$$ In future work we intend to explore joint models that incorporate not only basic part-of-speech tags but also more fine-grained morphological features.

In parsing, Bohnet and Nivre (2012) and Bohnet et al (2013) propose a model for joint morphological analysis, part-of speech tagging and dependency parsing using a Usingeval.pl from Buchholz and Marsi (2006). $$$$$ (2011) only evaluate their model on Chinese, and of these only Hatori et al. (2011) report consistent improvements in both tagging and parsing accuracy.
In parsing, Bohnet and Nivre (2012) and Bohnet et al (2013) propose a model for joint morphological analysis, part-of speech tagging and dependency parsing using a Usingeval.pl from Buchholz and Marsi (2006). $$$$$ As a result, the hash kernel often improves accuracy as well as efficiency compared to traditional techniques that only make use of features that occur in gold standard parses (Bohnet, 2010).
In parsing, Bohnet and Nivre (2012) and Bohnet et al (2013) propose a model for joint morphological analysis, part-of speech tagging and dependency parsing using a Usingeval.pl from Buchholz and Marsi (2006). $$$$$ DT = determiner; IN = preposition or subordinating conjunction; JJ = adjective; JJR = comparative adjective; NN = singular or mass noun; NNS = plural noun; POS = possessive clitic; RB = adverb; RBR = comparative adverb; RP = particle; UH = interjection; VB = base form verb; VBD = past tense verb; VBG = gerund or present participle; VBN = past participle; VBP = present tense verb, not 3rd person singular; VBZ = present tense verb, 3rd person singular.

 $$$$$ However, all three models only perform unlabeled parsing, while our model incorporates dependency labels into the parsing process.
 $$$$$ Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011).
 $$$$$ Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages.
 $$$$$ The symbols h.c, h.s and h.f denote, respectively, the configuration, score and feature representation of a hypothesis h; h.c.A denotes the arc set of h.c. ing parameters b1 and b2.

Bohnet and Nivre (2012)'s transition-based system jointly performs POS tagging and dependency parsing, which shows higher accuracy than ours. $$$$$ Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011).
Bohnet and Nivre (2012)'s transition-based system jointly performs POS tagging and dependency parsing, which shows higher accuracy than ours. $$$$$ Similarly, the score of the new hypothesis is the sum of the score f(t, h.c) Â· w of the current configuration-transition pair and the score of the old hypothesis (line 10).
Bohnet and Nivre (2012)'s transition-based system jointly performs POS tagging and dependency parsing, which shows higher accuracy than ours. $$$$$ With bi = 40, UAS improves by 0.25 and POS by 0.30, and the TLAS improvement is again highly significant (p < 0.01, paired t-test).
Bohnet and Nivre (2012)'s transition-based system jointly performs POS tagging and dependency parsing, which shows higher accuracy than ours. $$$$$ The new hypothesis is then inserted into TMP in score-sorted order (line 12).

Bohnet and Nivre (2012) introduced a transition-based system that jointly performed POS tagging and dependency parsing. $$$$$ The error analysis reveals improvements in tagging accuracy for syntactically central categories, mainly verbs, with improvement in syntactic accuracy for core grammatical functions as a result.
Bohnet and Nivre (2012) introduced a transition-based system that jointly performed POS tagging and dependency parsing. $$$$$ Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights.
Bohnet and Nivre (2012) introduced a transition-based system that jointly performed POS tagging and dependency parsing. $$$$$ It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other.
Bohnet and Nivre (2012) introduced a transition-based system that jointly performed POS tagging and dependency parsing. $$$$$ Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006).

 $$$$$ Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011).
 $$$$$ Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011).
 $$$$$ Since joint tagging and parsing increases the size of the search space and is likely to require novel features, we use beam search in combination with structured perceptron learning.
 $$$$$ Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board.
