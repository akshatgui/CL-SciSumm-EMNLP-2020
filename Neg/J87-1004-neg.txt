 $$$$$ That a semantic grammar in the LFG-like notation can also be generated automatically from a domain semantics specification and a purely syntactic grammar is discussed further in Tomita and Carbonell (1986).
 $$$$$ Since space is limited, we only show the highlights of the results, referring the reader to chapter 6 of Tomita (1985) for more detail.
 $$$$$ Lori Levin, Teruko Watanabe, Peggy Anderson, and Donna Gates have developed Japanese and English grammars in the LFG-like notation.

Similar to the work of Lang (1974) and Tomita (1987) extending LR parsers for arbitrary CFGs, the LR parsers for TAGs can be extended to solve by pseudo-parallelism the conflicts of moves. $$$$$ In this section, we present some empirical results of the algorithm's practical performance.
Similar to the work of Lang (1974) and Tomita (1987) extending LR parsers for arbitrary CFGs, the LR parsers for TAGs can be extended to solve by pseudo-parallelism the conflicts of moves. $$$$$ Kazuhiro Toyoshima and Hideto Kagamida have implemented the runtime parser and the LR table compiler, respectively, in Common Lisp.
Similar to the work of Lang (1974) and Tomita (1987) extending LR parsers for arbitrary CFGs, the LR parsers for TAGs can be extended to solve by pseudo-parallelism the conflicts of moves. $$$$$ Hiroaki Saito has implemented the algorithm for speech input.
Similar to the work of Lang (1974) and Tomita (1987) extending LR parsers for arbitrary CFGs, the LR parsers for TAGs can be extended to solve by pseudo-parallelism the conflicts of moves. $$$$$ Hiroaki Saito has implemented the algorithm for speech input.

We developed a set of augmented context free grammar rules for general English syntactic analysis and the analyzer is implemented using Tomita LR parsing algorithm (Tomita, 1987). $$$$$ The parser takes about 1-3 seconds CPU time per sentence on a Symbolics 3600 with about 800 grammar rules; its response time (real time), however, is less than a second due to on-line parsing.
We developed a set of augmented context free grammar rules for general English syntactic analysis and the analyzer is implemented using Tomita LR parsing algorithm (Tomita, 1987). $$$$$ Hiroaki Saito has implemented the algorithm for speech input.
We developed a set of augmented context free grammar rules for general English syntactic analysis and the analyzer is implemented using Tomita LR parsing algorithm (Tomita, 1987). $$$$$ Although these two nodes have the same category name (e.g., NP), they may have different attribute values.
We developed a set of augmented context free grammar rules for general English syntactic analysis and the analyzer is implemented using Tomita LR parsing algorithm (Tomita, 1987). $$$$$ Another benefit of on-line parsing is that it can detect an error almost as soon as the error occurs, and it can warn the user immediately.

The RASP parser is a generalized LR parser which builds a non-deterministic generalized LALR parse table from the grammar (Tomita, 1987). $$$$$ It is in general very painful to create, extend, and modify augmentations written in Lisp.
The RASP parser is a generalized LR parser which builds a non-deterministic generalized LALR parse table from the grammar (Tomita, 1987). $$$$$ The parser accepts the sentence in only one way, and returns &quot;10&quot; as the root node of the parse forest.
The RASP parser is a generalized LR parser which builds a non-deterministic generalized LALR parse table from the grammar (Tomita, 1987). $$$$$ An efficient parsing algorithm for augmented context-free grammars is introduced, and its application to on-line natural language interfaces discussed.
The RASP parser is a generalized LR parser which builds a non-deterministic generalized LALR parse table from the grammar (Tomita, 1987). $$$$$ In several experiments with different English grammars and sentences, timings indicate a five- to tenfold speed advantage over Earley's context-free parsing algorithm.

a graph-structured stack (Tomita, 1987) was used to efficiently represent ambiguous index operations in a GIG stack. $$$$$ Also, a commercial on-line parser for Japanese language is being built by Intelligent Technology Incorporation, on the technique developed at
a graph-structured stack (Tomita, 1987) was used to efficiently represent ambiguous index operations in a GIG stack. $$$$$ An unknown word can be thought of as a special type of a multi-part-of-speech word whose categories can be anything.
a graph-structured stack (Tomita, 1987) was used to efficiently represent ambiguous index operations in a GIG stack. $$$$$ Also, a commercial on-line parser for Japanese language is being built by Intelligent Technology Incorporation, based on the technique developed at CMU.
a graph-structured stack (Tomita, 1987) was used to efficiently represent ambiguous index operations in a GIG stack. $$$$$ Further studies on human factors are necessary.

A context-free backbone is automatically derived from the unification grammar1 and a generalized or non-deterministic LALR(1) table is constructed from this backbone (Tomita, 1987). $$$$$ The graph-structured stack allows an LR shift-reduce parser to maintain multiple parses without parsing any part of the input twice in the same way.
A context-free backbone is automatically derived from the unification grammar1 and a generalized or non-deterministic LALR(1) table is constructed from this backbone (Tomita, 1987). $$$$$ The top nodes of subtrees that represent local ambiguity are merged and treated by higher-level structures as if there were only one node.
A context-free backbone is automatically derived from the unification grammar1 and a generalized or non-deterministic LALR(1) table is constructed from this backbone (Tomita, 1987). $$$$$ This characteristics makes on-line parsing possible; i.e., to parse a sentence as the user types it in, without waiting for completion of the sentence.
A context-free backbone is automatically derived from the unification grammar1 and a generalized or non-deterministic LALR(1) table is constructed from this backbone (Tomita, 1987). $$$$$ This subsection gives a trace of the algorithm with the grammar in Figure 2.1, the parsing table in Figure 2.2, and the sentence I saw a man in the park with a telescope.

The parsers create parse forests (Tomita, 1987) that incorporate subtree sharing (in which identical sub-analyses are shared between differing superordinate analyses) and node packing (where sub analyses covering the same portion of input whose root categories are in a subsumption relationship are merged into a single node). $$$$$ An example session of on-line parsing is presented in Figure 7.1 for the sample sentence I saw a man with a telescope.
The parsers create parse forests (Tomita, 1987) that incorporate subtree sharing (in which identical sub-analyses are shared between differing superordinate analyses) and node packing (where sub analyses covering the same portion of input whose root categories are in a subsumption relationship are merged into a single node). $$$$$ Ron Kaplan, Martin Kay, Lauri Karttunen, and Stuart Shieber provided useful comments on the implementation of LFG and dag structure sharing.
The parsers create parse forests (Tomita, 1987) that incorporate subtree sharing (in which identical sub-analyses are shared between differing superordinate analyses) and node packing (where sub analyses covering the same portion of input whose root categories are in a subsumption relationship are merged into a single node). $$$$$ Figure 5.1 shows the relationship between parsing time of the Tomita algorithm and the length of input sentence, and Figure 5.2 shows the comparison with Earley's algorithm (or active chart parsing), using a sample English grammar that consists of 220 context-free rules and 40 sample sentences taken from actual publications.
The parsers create parse forests (Tomita, 1987) that incorporate subtree sharing (in which identical sub-analyses are shared between differing superordinate analyses) and node packing (where sub analyses covering the same portion of input whose root categories are in a subsumption relationship are merged into a single node). $$$$$ The parser is used in the multi-lingual machine translation project at CMU.

In this parser, the LALR (1) technique (Aho, Sethi Ullman, 1986) is used, in conjunction with a graph-structured stack (Tomita, 1987), adapting for unification-based parsing Kipps's (1989) Tomita-like recogniser that achieves polynomial complexity on input length through caching. $$$$$ Recall that within the given time the algorithm produces all possible parses in the shared-packed forest representation.
In this parser, the LALR (1) technique (Aho, Sethi Ullman, 1986) is used, in conjunction with a graph-structured stack (Tomita, 1987), adapting for unification-based parsing Kipps's (1989) Tomita-like recogniser that achieves polynomial complexity on input length through caching. $$$$$ A generated function takes a list of arguments, each of which is a value associated with each right-hand side symbol, and returns a value to be associated with the left-hand side symbol.
In this parser, the LALR (1) technique (Aho, Sethi Ullman, 1986) is used, in conjunction with a graph-structured stack (Tomita, 1987), adapting for unification-based parsing Kipps's (1989) Tomita-like recogniser that achieves polynomial complexity on input length through caching. $$$$$ It is concluded that our algorithm can parse (and produce a forest for) a very ambiguous sentence with a million possible parses in a reasonable time.

A forest (Tomita, 1987) compactly encodes an exponential number of parse trees. $$$$$ Using this relatively simple procedure, our parsing algorithm can produce the shared forest as its output without any other special book-keeping mechanism, because it never does the same reduce action twice in the same manner.
A forest (Tomita, 1987) compactly encodes an exponential number of parse trees. $$$$$ This characteristics makes on-line parsing possible; i.e., to parse a sentence as the user types it in, without waiting for completion of the sentence.
