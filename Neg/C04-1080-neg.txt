While replicating earlier experiments, Banko and Moore (2004) discovered that performance was highly dependent on cleaning tag dictionaries using statistics gleaned from the tokens. $$$$$ Using a 50% 50% train-test split of the Penn Treebank to assess HMMs, maximum entropy Markov models (MEMMs) and conditional random fields (CRFs), they found that CRFs, which make use of observation features from both the past and future, outperformed HMMs which in turn outperformed MEMMs.
While replicating earlier experiments, Banko and Moore (2004) discovered that performance was highly dependent on cleaning tag dictionaries using statistics gleaned from the tokens. $$$$$ Observing that the quality of the lexicon greatly impacts the accuracy that can be achieved by the algorithms, we present a method of HMM training that improves accuracy when training of lexical probabilities is unstable.
While replicating earlier experiments, Banko and Moore (2004) discovered that performance was highly dependent on cleaning tag dictionaries using statistics gleaned from the tokens. $$$$$ Second we describe a method for sequential unsupervised training of tag sequence and lexical probabilities in an HMM, which we observe leads to improved accuracy over simultaneous training with certain types of models.
While replicating earlier experiments, Banko and Moore (2004) discovered that performance was highly dependent on cleaning tag dictionaries using statistics gleaned from the tokens. $$$$$ In addition, we explore two new ideas for improving tagging accuracy.

Second, the expectation maximization algorithm for bi tag HMMs is efficient and has been shown to be quite effective for acquiring accurate POS taggers given only a lexicon (tag dictionary) and certain favorable conditions (Banko and Moore, 2004). $$$$$ We varied this threshold until accuracy did not significantly change on our set of heldout data.
Second, the expectation maximization algorithm for bi tag HMMs is efficient and has been shown to be quite effective for acquiring accurate POS taggers given only a lexicon (tag dictionary) and certain favorable conditions (Banko and Moore, 2004). $$$$$ Without supervision, this new HMM structure improved results slightly compared to a simple trigram tagger as described in Merialdo, which takes into account only the current tag in predicting the lexical item.

As Banko and Moore (2004) discovered when 5 Note that the POS tag information is not used in these experiments, except for by the C& amp; C tagger. $$$$$ This result falls only slightly below the full-blown training intensive dependency-based conditional model.
As Banko and Moore (2004) discovered when 5 Note that the POS tag information is not used in these experiments, except for by the C& amp; C tagger. $$$$$ In a traditional HMM tagger, the probability of transitioning into a state representing tag ti is computed based on the previous two tags ti-1 and ti 2, and the probability of a word wi is conditioned only on the current tag ti.
As Banko and Moore (2004) discovered when 5 Note that the POS tag information is not used in these experiments, except for by the C& amp; C tagger. $$$$$ Another highly-accurate method for part-of speech tagging from unlabelled data is Brill?s unsupervised transformation-based learner (UTBL) (Brill, 1995).

To consider the effect of the CCG-based initialization for lexicons with differing ambiguity, I use tag cutoffs that remove any lexical entry containing a category that appears with a particular word less than X% of the time (Banko and Moore, 2004), as well as using no cutoffs at all. $$$$$ For further comparison, we evaluated these part of speech taggers against Toutanova et als supervised dependency-network based tagger, which currently achieves the highest accuracy on this dataset to date.
To consider the effect of the CCG-based initialization for lexicons with differing ambiguity, I use tag cutoffs that remove any lexical entry containing a category that appears with a particular word less than X% of the time (Banko and Moore, 2004), as well as using no cutoffs at all. $$$$$ This type of structure is analogous to context-dependent phone models used in acoustic modeling for speech recognition (e.g.Young, 1999, Section 4.3).
To consider the effect of the CCG-based initialization for lexicons with differing ambiguity, I use tag cutoffs that remove any lexical entry containing a category that appears with a particular word less than X% of the time (Banko and Moore, 2004), as well as using no cutoffs at all. $$$$$ This finding highlights the importance of the need for clean dictionaries whether they are constructed by hand or automatically when we seek to be fully unsupervised.
To consider the effect of the CCG-based initialization for lexicons with differing ambiguity, I use tag cutoffs that remove any lexical entry containing a category that appears with a particular word less than X% of the time (Banko and Moore, 2004), as well as using no cutoffs at all. $$$$$ We have presented a comprehensive evaluation of several methods for unsupervised part-of-speech tagging, comparing several variations of hidden Markov model taggers and unsupervised transformation-based learning using the same corpus and same lexicons.

However, as Banko and Moore (2004) point out, the accuracy achieved by these unsupervised methods depends strongly on the precise nature of the supervised training data (in their case, the ambiguity of the tag lexicon available to the system), which makes it more difficult to understand the behaviour of such systems. $$$$$ Finally, we show how this new tagger achieves state-of-the-art results in a supervised, non-training intensive framework.
However, as Banko and Moore (2004) point out, the accuracy achieved by these unsupervised methods depends strongly on the precise nature of the supervised training data (in their case, the ambiguity of the tag lexicon available to the system), which makes it more difficult to understand the behaviour of such systems. $$$$$ Second, we revised the training paradigm for HMMs, in which lexical and transition probabilities are typically estimated simultaneously.

Banko and Moore (2004) compared unsupervised HMM and transformation-based taggers trained on the same portions of the Penn Treebank, and showed that the quality of the lexicon used for training had a high impact on the tagging results. Duh and Kirchhoff (2005) presented a minimally supervised approach to tagging for dialectal Arabic (Colloquial Egyptian), based on a morphological analyzer for Modern Standard Arabic and unlabeled texts in a number of dialects. $$$$$ We present a new HMM tagger that exploits context on both sides of a word to be tagged, and evaluate it in both the unsupervised and supervised case.
Banko and Moore (2004) compared unsupervised HMM and transformation-based taggers trained on the same portions of the Penn Treebank, and showed that the quality of the lexicon used for training had a high impact on the tagging results. Duh and Kirchhoff (2005) presented a minimally supervised approach to tagging for dialectal Arabic (Colloquial Egyptian), based on a morphological analyzer for Modern Standard Arabic and unlabeled texts in a number of dialects. $$$$$ As shown in Table 3, incorporating more context into an HMM when estimating lexical probabilities improved accuracy from 95.87% to 96.59%, relatively reducing error rate by 17.4%.
Banko and Moore (2004) compared unsupervised HMM and transformation-based taggers trained on the same portions of the Penn Treebank, and showed that the quality of the lexicon used for training had a high impact on the tagging results. Duh and Kirchhoff (2005) presented a minimally supervised approach to tagging for dialectal Arabic (Colloquial Egyptian), based on a morphological analyzer for Modern Standard Arabic and unlabeled texts in a number of dialects. $$$$$ In a traditional HMM tagger, the probability of transitioning into a state representing tag ti is computed based on the previous two tags ti-1 and ti 2, and the probability of a word wi is conditioned only on the current tag ti.

Unsupervised Part-of-Speech Tagging Since the work of Merialdo (1994), the HMM has been the model of choice for unsupervised tagging (Banko and Moore, 2004). $$$$$ In section 2, we provide a brief description of the methods we evaluate and review published results.
Unsupervised Part-of-Speech Tagging Since the work of Merialdo (1994), the HMM has been the model of choice for unsupervised tagging (Banko and Moore, 2004). $$$$$ Filtering the possible part-of speech assignments contained in a basic lexicon automatically constructed from the commonly used Penn Treebank improved results by as much as 22%.
Unsupervised Part-of-Speech Tagging Since the work of Merialdo (1994), the HMM has been the model of choice for unsupervised tagging (Banko and Moore, 2004). $$$$$ To avoid the problem of unknown words, each learner was provided with a lexicon constructed from tagged versions of the full Treebank.

Author Language Average accuracy Toutanova et al (2003) English 97.24% Banko and Moore (2004) English 96.55% Dandapat and Sarkar (2006) Bengali 84.37% Rao et al (2007) Hindi 76.34% Bengali 72.17% Telegu 53.17% Rao and Yarowsky (2007) Hindi 70.67% Bengali 65.47% Telegu 65.85% Sastry et al (2007) Hindi 69.98% Bengali 67.52% Telegu 68.32% Ekbal et al (2007) Hindi 71.65% Bengali 80.63% Telegu 53.15% Ours Assamese 85.64% and searched in the affix-probability table. $$$$$ Unfortunately none of these results can be directly compared to the others, as they have used different, randomized and irreproducible splits of training and test data (Brill and Kupiec), different tag sets (Merialdo) or different corpora altogether.
Author Language Average accuracy Toutanova et al (2003) English 97.24% Banko and Moore (2004) English 96.55% Dandapat and Sarkar (2006) Bengali 84.37% Rao et al (2007) Hindi 76.34% Bengali 72.17% Telegu 53.17% Rao and Yarowsky (2007) Hindi 70.67% Bengali 65.47% Telegu 65.85% Sastry et al (2007) Hindi 69.98% Bengali 67.52% Telegu 68.32% Ekbal et al (2007) Hindi 71.65% Bengali 80.63% Telegu 53.15% Ours Assamese 85.64% and searched in the affix-probability table. $$$$$ Words contained within the same equivalence classes are those which possess the same set of possible parts of speech.
Author Language Average accuracy Toutanova et al (2003) English 97.24% Banko and Moore (2004) English 96.55% Dandapat and Sarkar (2006) Bengali 84.37% Rao et al (2007) Hindi 76.34% Bengali 72.17% Telegu 53.17% Rao and Yarowsky (2007) Hindi 70.67% Bengali 65.47% Telegu 65.85% Sastry et al (2007) Hindi 69.98% Bengali 67.52% Telegu 68.32% Ekbal et al (2007) Hindi 71.65% Bengali 80.63% Telegu 53.15% Ours Assamese 85.64% and searched in the affix-probability table. $$$$$ Finally, we show how this new tagger achieves state-of-the-art results in a supervised, non-training intensive framework.

As for contextualized lexical probabilities, our extension is very similar to Banko and Moore (2004) who use P (wi $$$$$ It is important to note that this accuracy can be obtained without the intensive training required by Toutanova et. al?s log-linear models.
As for contextualized lexical probabilities, our extension is very similar to Banko and Moore (2004) who use P (wi $$$$$ 5.3 Results.

One difficulty with their approach ,noted by Banko and Moore (2004), is the treatment of unseen words $$$$$ Finally, we show how this new tagger achieves state-of-the-art results in a supervised, non-training intensive framework.
One difficulty with their approach ,noted by Banko and Moore (2004), is the treatment of unseen words $$$$$ For example, verbs which subcategorize strongly for a particular part-of speech but can also be tagged as nouns or pronouns (e.g. ?thinking that?)
One difficulty with their approach ,noted by Banko and Moore (2004), is the treatment of unseen words $$$$$ In section 2, we provide a brief description of the methods we evaluate and review published results.
One difficulty with their approach ,noted by Banko and Moore (2004), is the treatment of unseen words $$$$$ = = iiiiiiii iiiiiii tttptwtwtp tttwptwtwwp Given that we are using an increased context size during the estimation of lexical probabilities, thus fragmenting the data, we have found it desirable to smooth these estimates, for which we use a standard absolute discounting scheme (Ney, Essen and Knesser, 1994).

If we follow Banko and Moore (2004) and construct a full (no OOV) morphological lexicon from the tagged version of the test corpus, we obtain 96.95% precision where theirs was 96.59%. $$$$$ For further comparison, we evaluated these part of speech taggers against Toutanova et als supervised dependency-network based tagger, which currently achieves the highest accuracy on this dataset to date.
If we follow Banko and Moore (2004) and construct a full (no OOV) morphological lexicon from the tagged version of the test corpus, we obtain 96.95% precision where theirs was 96.59%. $$$$$ 4.1 Corpora and Lexicon Construction.
If we follow Banko and Moore (2004) and construct a full (no OOV) morphological lexicon from the tagged version of the test corpus, we obtain 96.95% precision where theirs was 96.59%. $$$$$ Observing that the quality of the lexicon greatly impacts the accuracy that can be achieved by the algorithms, we present a method of HMM training that improves accuracy when training of lexical probabilities is unstable.

The reason why Banko and Moore (2004) get less than HunPos is not because their system is inherently worse, but rather because it lacks the engineering hacks built into TnT and HunPos. $$$$$ Lafferty et al (2001) also compared the accuracies of several supervised part-of-speech tagging models, while examining the effect of directionality in graphical models.
The reason why Banko and Moore (2004) get less than HunPos is not because their system is inherently worse, but rather because it lacks the engineering hacks built into TnT and HunPos. $$$$$ 4.2 The Effect of Lexicon Construction on.
The reason why Banko and Moore (2004) get less than HunPos is not because their system is inherently worse, but rather because it lacks the engineering hacks built into TnT and HunPos. $$$$$ As shown in Table 1, the elimination of noisy possible part-of-speech assignments raised accuracy back into the realm of previously published results.
The reason why Banko and Moore (2004) get less than HunPos is not because their system is inherently worse, but rather because it lacks the engineering hacks built into TnT and HunPos. $$$$$ ?= n i iiiiiiiii twtwtpttwtwwpTWp 1 111111 )..|()...|(),( by replacing the approximation: )|()..|( )|()...|( 1211 1111 ????

Smith and Eisner (2005) employ a contrastive estimation tech 1As (Banko and Moore, 2004) point out, unsupervised tagging accuracy varies wildly depending on the dictionary employed. $$$$$ Kupiec (1992) describes a modified trigram HMM tagger in which he computes word classes for which lexical probabilities are then estimated, instead of computing probabilities for individual words.
Smith and Eisner (2005) employ a contrastive estimation tech 1As (Banko and Moore, 2004) point out, unsupervised tagging accuracy varies wildly depending on the dictionary employed. $$$$$ It is important to note that this accuracy can be obtained without the intensive training required by Toutanova et. al?s log-linear models.
Smith and Eisner (2005) employ a contrastive estimation tech 1As (Banko and Moore, 2004) point out, unsupervised tagging accuracy varies wildly depending on the dictionary employed. $$$$$ Unfiltered Lexicon Optimized Lexicon Merialdo HMM 71.9 93.9 Contextualized HMM 76.9 94.0 Kupiec HMM 77.1 95.9 UTBL 77.2 95.9 Contextualized HMM with Classes 77.2 95.9 Table 1: Tag Accuracy of Unsupervised POS Taggers 5.1 Using Unambiguous Tag Sequences To.

We define the unsupervised part-of-speech (POS) tagging problem as predicting the correct part-of speech tag of a word in a given context using an unlabeled corpus and a dictionary with possible word? tag pairs0 The performance of an unsupervised POS tagging system depends highly on the quality of the word7ujh tag dictionary (Bankoand Moore, 2004). $$$$$ Kupiec?s HMM class-based tagger, when trained on a sample of 440,000 words of the original Brown corpus, obtained a test set accuracy of 95.7%.
We define the unsupervised part-of-speech (POS) tagging problem as predicting the correct part-of speech tag of a word in a given context using an unlabeled corpus and a dictionary with possible word? tag pairs0 The performance of an unsupervised POS tagging system depends highly on the quality of the word7ujh tag dictionary (Bankoand Moore, 2004). $$$$$ This finding highlights the importance of the need for clean dictionaries whether they are constructed by hand or automatically when we seek to be fully unsupervised.
We define the unsupervised part-of-speech (POS) tagging problem as predicting the correct part-of speech tag of a word in a given context using an unlabeled corpus and a dictionary with possible word? tag pairs0 The performance of an unsupervised POS tagging system depends highly on the quality of the word7ujh tag dictionary (Bankoand Moore, 2004). $$$$$ With respect to part-of-speech tagging, we believe that the way forward from the relatively small number of languages for which we can currently identify parts of speech in context with reasonable accuracy will make use of unsupervised methods that require only an untagged corpus and a lexicon of words and their possible parts of speech.

by Banko and Moore (2004), these works made use of filtered dictionaries $$$$$ It is important to note that this accuracy can be obtained without the intensive training required by Toutanova et. al?s log-linear models.
by Banko and Moore (2004), these works made use of filtered dictionaries $$$$$ The training of HMM?
by Banko and Moore (2004), these works made use of filtered dictionaries $$$$$ In addition, we presented a variation on HMM model training in which the tag sequence and lexical probabilities are estimated in sequence.

Later, Banko and Moore (2004) observed that earlier unsupervised HMM-EM results were artificially high due to use of Optimized Lexicons, in which only frequent-enough analyses of each word were kept. $$$$$ In the interest of being as unsupervised as possible, we sought to find a way to cope with the noisy aspects of the unfiltered lexicon described in the previous section.
Later, Banko and Moore (2004) observed that earlier unsupervised HMM-EM results were artificially high due to use of Optimized Lexicons, in which only frequent-enough analyses of each word were kept. $$$$$ Specifically, we looked for trigrams in which all words contained at most one possible part-of-speech tag.
Later, Banko and Moore (2004) observed that earlier unsupervised HMM-EM results were artificially high due to use of Optimized Lexicons, in which only frequent-enough analyses of each word were kept. $$$$$ We then used these n-grams and their counts to bias the initial estimates of state transitions in the HMM taggers.
Later, Banko and Moore (2004) observed that earlier unsupervised HMM-EM results were artificially high due to use of Optimized Lexicons, in which only frequent-enough analyses of each word were kept. $$$$$ As one more way to assess the potential benefit from using left and right context in an HMM tagger, we tested our tagging model in the supervised framework, using the same sections of the Treebank previously allocated for unsupervised training, development and testing.

In this paper, we show how these strategies may becombined straightforwardly to produce improvements on the task of learning super taggers from lexicons that have not been filtered in any way.1 We demonstrate their cross-lingual effectiveness on CCGbank (English) and the Italian CCG-TUT 1See Banko and Moore (2004) for a description of how many early POS-tagging papers in fact used a number of heuristic cutoffs that greatly simplify the problem. $$$$$ Section 3 describes the contextualized variation on HMM tagging that we have explored.
In this paper, we show how these strategies may becombined straightforwardly to produce improvements on the task of learning super taggers from lexicons that have not been filtered in any way.1 We demonstrate their cross-lingual effectiveness on CCGbank (English) and the Italian CCG-TUT 1See Banko and Moore (2004) for a description of how many early POS-tagging papers in fact used a number of heuristic cutoffs that greatly simplify the problem. $$$$$ As we look to the future, we expect that relatively unsupervised methods will grow in applicability, reducing the need for expensive human annotation of data.

We use the standard splits of the data used in semi-supervised tagging experiments (e.g.Banko and Moore (2004)) $$$$$ In section 2, we provide a brief description of the methods we evaluate and review published results.
We use the standard splits of the data used in semi-supervised tagging experiments (e.g.Banko and Moore (2004)) $$$$$ 4.1 Corpora and Lexicon Construction.
We use the standard splits of the data used in semi-supervised tagging experiments (e.g.Banko and Moore (2004)) $$$$$ In contrast to the HMM taggers previously described, which make use of contextual information coming from the left side only, UTBL considers both left and right contexts.

Banko and Moore (2004) showed that unsupervised tagger ac curacies on English degrade from 96% to 77% if the lexicon is not constrained such that only high frequency tags exist in the POS-set for each word. $$$$$ One issue we noticed which impacted tagging accuracy was that of a frequently occurring word (a) The/VB Lyneses/NNP ,/, of/IN Powder/NNP Springs/NNP ,/, Ga./NNP ,/, have/VBP filed/VBN suit/NN in/IN Georgia/NNP state/NN court/NN against/IN Stuart/NNP James/NNP ,/, *-1/-NONE- alleging/VBG fraud/NN ./.
Banko and Moore (2004) showed that unsupervised tagger ac curacies on English degrade from 96% to 77% if the lexicon is not constrained such that only high frequency tags exist in the POS-set for each word. $$$$$ The best result for this tagger, at 97.24%, makes use of both lexical and tag features coming from the left and right sides of the target.
Banko and Moore (2004) showed that unsupervised tagger ac curacies on English degrade from 96% to 77% if the lexicon is not constrained such that only high frequency tags exist in the POS-set for each word. $$$$$ While this makes unsupervised part-of-speech tagging a relatively well-studied problem, published results to date have not been comparable with respect to the training and test data used, or the lexicons which have been made available to the learners.

Some of these are annotation errors in the tree bank (Banko and Moore, 2004, Figure 2) $$$$$ We also chose to examine this tagger?s results when using only <ti, t i-1, t i+1> as feature templates, which represents the same amount of context built into our contextualized tagger.
Some of these are annotation errors in the tree bank (Banko and Moore, 2004, Figure 2) $$$$$ Observing that the quality of the lexicon greatly impacts the accuracy that can be achieved by the algorithms, we present a method of HMM training that improves accuracy when training of lexical probabilities is unstable.
Some of these are annotation errors in the tree bank (Banko and Moore, 2004, Figure 2) $$$$$ 5.2 HMM Model Training Revised.
Some of these are annotation errors in the tree bank (Banko and Moore, 2004, Figure 2) $$$$$ As one more way to assess the potential benefit from using left and right context in an HMM tagger, we tested our tagging model in the supervised framework, using the same sections of the Treebank previously allocated for unsupervised training, development and testing.
