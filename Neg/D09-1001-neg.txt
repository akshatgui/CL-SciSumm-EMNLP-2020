Take the following example from Poon and Domingos (2009), in which the same semantic relation can be expressed by a transitive verb or an attributive prepositional phrase: (1) Utah borders Idaho. $$$$$ A lexical entry defines the logical form for a lexical item (e.g., a word).
Take the following example from Poon and Domingos (2009), in which the same semantic relation can be expressed by a transitive verb or an attributive prepositional phrase: (1) Utah borders Idaho. $$$$$ We then introduce their lambda forms and clusters, and show how semantic parsing works in this setting.
Take the following example from Poon and Domingos (2009), in which the same semantic relation can be expressed by a transitive verb or an attributive prepositional phrase: (1) Utah borders Idaho. $$$$$ It also assigns binary atoms of the form b(n, n′) to the part as argument forms and creates a new argument type for each.

To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ First we introduce some definitions: a partition is called A-reducible from p if it can be obtained from the current partition by recursively A-reducing the part containing p with one of its arguments; such a partition is Algorithm 1 USP-Parse(MLN, QLF) Form parts for individual atoms in QLF and assign each to its most probable cluster repeat for all parts p in the current partition do for all partitions that are A-reducible from p and feasible do Find the most probable cluster and argument type assignments for the new part Change to the new partition and assignments with the highest gain in probability until none of these improve the probability return current partition and assignments called feasible if the core form of the new part is contained in some cluster.
To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ These MAP parses formed our knowledge base (KB).
To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ For example, in Stanford dependencies, the object of a verb uses the dependency dobj in the active voice, but nsubjpass in passive.

We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ Manually encoding all these variations into the grammar is tedious and error-prone.
We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ This in turn allows it to correctly answer many more questions than systems based on TextRunner (Banko et al., 2007) and DIRT (Lin and Pantel, 2001).
We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ It also resolves many nouns correctly and forms meaningful groups of relations.

More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ For larger k and m, this is very expensive.
More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ Notice that with these constraints the completion likelihood P(Q, L) can be computed in closed form for any L. In particular, each formula group contributes a term equal to the weight of the currently satisfied formula.
More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ We thank the anonymous reviewers for their comments.
More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ Enumerating all L’s is intractable.

On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ Manually encoding all these variations into the grammar is tedious and error-prone.
On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ This in turn allows it to correctly answer many more questions than systems based on TextRunner (Banko et al., 2007) and DIRT (Lin and Pantel, 2001).
On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ This enables us to leverage advanced syntactic parsers and (indirectly) the available rich resources for them.
On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ These lambda-forms may later be merged with other clusters (e.g., borders).

Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ The last two rules compose the meanings of sub-parts into that of the larger part.
Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.
Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.
Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ We thank the anonymous reviewers for their comments.

Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ Traditionally, semantic parsers were constructed manually, but this is too costly and brittle.
Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ For example, the first rule applies to the word “borders” and generates syntactic category Verb with the meaning AyAx.borders(x, y) that represents the nextto relation.
Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ Inverted indexes (e.g., from p to eligible core forms) are used to further improve the efficiency.
Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ For example, consider the QLF of “Utah borders Idaho” and assume that the current partition is Ax2x3.borders(n1) ∧ nsubj(n1, x2) ∧ dobj(n1, x3), Utah(n2), Idaho(n3).

In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets: for example, the MLN model induces 18,543 distinct clusters from 18,471 sentences of the GENIA corpus (Poon and Domingos, 2009). $$$$$ As a first approximation to the questions a biomedical researcher might ask, we generated a set of two thousand questions on relations between entities.
In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets: for example, the MLN model induces 18,543 distinct clusters from 18,471 sentences of the GENIA corpus (Poon and Domingos, 2009). $$$$$ The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them.
In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets: for example, the MLN model induces 18,543 distinct clusters from 18,471 sentences of the GENIA corpus (Poon and Domingos, 2009). $$$$$ ), where p is a part, i is the index of an argument, and f is a QLF subformula.
In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets: for example, the MLN model induces 18,543 distinct clusters from 18,471 sentences of the GENIA corpus (Poon and Domingos, 2009). $$$$$ This allows the maximum flexibility in learning.

In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ It contains 1999 PubMed abstracts and marks all mentions of biomedical entities according to the GENIA ontology, such as cell, protein, and DNA.
In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ USP learning uses the same optimization objective as hard EM, and is also guaranteed to find a local optimum since at each step it improves the log-likelihood.
In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ On the other hand, as already noted in the previous section, the lambda-form distribution is generally sparse.
In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ This forms the initial clustering and semantic parses.

Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in (Poon and Domingos, 2009). $$$$$ The first is to merge two clusters, denoted by MERGE(C1, C2) for clusters C1, C2, which does the following: and there is the local normalization constraint Ef ewc,f = 1.
Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in (Poon and Domingos, 2009). $$$$$ If the verb does not contain the expected argument, the sentence is ignored.

Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ This paper introduces the first unsupervised approach to learning semantic parsers.
Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ We have successfully applied USP to extracting a knowledge base from biomedical text and answering questions based on it.
Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.
Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ First we introduce some definitions: a partition is called A-reducible from p if it can be obtained from the current partition by recursively A-reducing the part containing p with one of its arguments; such a partition is Algorithm 1 USP-Parse(MLN, QLF) Form parts for individual atoms in QLF and assign each to its most probable cluster repeat for all parts p in the current partition do for all partitions that are A-reducible from p and feasible do Find the most probable cluster and argument type assignments for the new part Change to the new partition and assignments with the highest gain in probability until none of these improve the probability return current partition and assignments called feasible if the core form of the new part is contained in some cluster.

The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ Semantic parsing maps text to formal meaning representations.
The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ Inverted indexes (e.g., from p to eligible core forms) are used to further improve the efficiency.
The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ For a fair comparison, we also ran RESOLVER using all extractions, and manually tuned the parameters based on eyeballing of clustering quality.
The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ We thank the anonymous reviewers for their comments.

In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ We thank the anonymous reviewers for their comments.
In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ This paper introduces the first unsupervised approach to learning semantic parsers.
In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ Existing approaches differ in the meaning representation languages they use and the amount of annotation required.

We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.
We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ ; use of context and discourse to aid expression clustering and semantic parsing; more efficient learning and inference; application to larger corpora; etc.
We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ For example, after the first and third rules are fired, the fourth rule fires and generates VP[AyAx.borders(x, y)(Idaho)]; this meaning simplifies to Ax.borders(x, Idaho) by the A-reduction rule, which substitutes the argument for a variable in a functional application.
We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ It generated Stanford dependencies (de Marneffe et al., 2006) from the input text using the Stanford parser, and then fed these to USP-Learn11, which produced an MLN with learned weights and the MAP semantic parses of the input sentences.

Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ The meaning composition of two sub-formulas is simply their conjunction.
Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ However, they are supervised, and providing the target logical form for each sentence is costly and difficult to do consistently and with high quality.
Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.
Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ The types are considered in decreasing order of their numbers of occurrences so that more information is available for each decision.

USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ Evaluating unsupervised semantic parsers is difficult, because there is no predefined formal language or gold logical forms for the input sentences.
USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ To model distributions over arguments, we introduce three more predicates: ArgType(p, i, a!) signifies that the ith argument of p is assigned to argument type a; Arg(p, i, p′) signifies that the ith argument of p is p′; Number(p, a, n) signifies that there are n arguments of p that are assigned to type a.
USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ Therefore, a lambda form can usually only belong to a small number of clusters, if not a unique one.
USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ Our USP system is based on Markov logic, and recursively clusters expressions to abstract away syntactic variations of the same meaning.

Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ We have successfully applied USP to extracting a knowledge base from biomedical text and answering questions based on it.
Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.
Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them.
Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ The QLFs which contain an affected part are reparsed, and operations in the agenda whose score might be affected are re-evaluated.

Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ Experiments on a biomedical corpus show that this approach is able to successfully translate syntactic variations into a logical representation of their common meaning (e.g., USP learns to map active and passive voice to the same logical form, etc.).
Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ In the past, unsupervised approaches have been applied to some semantic tasks, but not to semantic parsing.
Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ More importantly, it separates the complexity in syntactic analysis from the semantic one, and makes the latter much easier to perform.
Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ TextRunner achieved good accuracy when exact match is used (TR-EXACT), but only obtained a fraction of the answers compared to USP.

Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ Since the optimal weights and log-likelihood can be derived in closed form given the semantic parses L, we simply search over semantic parses, evaluating them using log-likelihood.
Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ We thank the anonymous reviewers for their comments.
Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ The QLFs and their sub-formulas have natural lambda forms, as will be described later.
Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.

Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task.
Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ The final output is a probability distribution over lambda-form clusters and their compositions, as well as the MAP semantic parses of training sentences.
Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ Sentence: The data presented here indicate that (1) the 12-lipoxygenase activity of murine macrophages is upregulated in vitro and in vivo by IL-4 and/or IL-13, .
