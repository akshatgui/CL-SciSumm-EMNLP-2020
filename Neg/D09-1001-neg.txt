Take the following example from Poon and Domingos (2009), in which the same semantic relation can be expressed by a transitive verb or an attributive prepositional phrase $$$$$ Lambda-form clusters abstract away syntactic variations of the same meaning.

To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ For unrestricted text, the complexity and subjectivity of annotation render it essentially infeasible; even pre-specifying the target predicates and objects is very difficult.
To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ For example, the aforementioned sentence can be rephrased as “Utah is next to Idaho,”“Utah shares a border with Idaho,” etc.
To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ Starting with clusters of lambda forms at the atom level, USP recursively builds up clusters of larger lambda forms.
To do so, we semi-automatically restrict the question-answer pairs by using the output of an unsupervised clustering semantic parser (Poon and Domingos, 2009). $$$$$ Our USP system starts by clustering tokens of the same type, and then recursively clusters expressions whose subexpressions belong to the same clusters.

We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.
We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ During initialization, USP forms a part and creates a new cluster for each unary atom u(n).
We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ Moreover, most state-of-the-art QA systems use supervised learning in their key components and/or require domain-specific engineering efforts.
We used the question-answer pairs extracted by the Poon and Domingos (2009) semantic parser from the GENIA biomedical corpus that have been manually checked to be correct (295 pairs). $$$$$ Directions for future work include: better handling of antonyms, subsumption relations among expressions, quantifier scoping, more complex lambda forms, etc.

More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ Markov logic makes it possible to compactly specify probability distributions over complex relational domains, and has been successfully applied to unsupervised coreference resolution (Poon and Domingos, 2008) and other tasks.
More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ USP extracted the highest number of answers, almost doubling that of the second highest (RS-SUB).
More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ This algorithm is very efficient, and is used repeatedly in learning.
More recent examples of similar techniques include the Resolver system (Yates and Etzioni, 2009) and Poon and Domingos's USP system (Poon and Domingos, 2009). $$$$$ Directions for future work include: better handling of antonyms, subsumption relations among expressions, quantifier scoping, more complex lambda forms, etc.

On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task.
On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ These will be pursued in future work. variables with a plus sign.
On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives. $$$$$ However, they are supervised, and providing the target logical form for each sentence is costly and difficult to do consistently and with high quality.

Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ This paper introduces the first unsupervised approach to learning semantic parsers.
Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ If the verb does not contain the expected argument, the sentence is ignored.
Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ We have successfully applied USP to extracting a knowledge base from biomedical text and answering questions based on it.
Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. $$$$$ Given that a central challenge to semantic parsing is resolving syntactic variations of the same meaning, we also compare with RESOLVER (Yates and Etzioni, 2009), a state-of-the-art unsupervised system based on TextRunner for jointly resolving entities and relations, and DIRT (Lin and Pantel, 2001), which resolves paraphrases of binary relations.

Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ 6Regularizations, e.g., Gaussian priors on weights, alleviate this problem by penalizing large weights, but it remains true that weights within a short range are roughly equivalent. and update agenda and candidate operations until agenda is empty return the MLN with learned weights and the semantic parses Another major challenge in USP learning is the summation in the likelihood, which is over all possible semantic parses for a given dependency tree.
Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ Here, the ni are Skolem constants indexed by the nodes.
Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ We leave this to future work. above a threshold.9 The operation with the highest score is executed, and the parameters are updated with the new optimal values.
Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of (Poon and Domingos, 2009) which have to perform model selection and use heuristics to penalize more complex models of semantics. $$$$$ This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.

In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.
In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets $$$$$ Instead, USP uses a greedy algorithm to search for the MAP parse.
In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets $$$$$ This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.
In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets $$$$$ The learning problem in USP is to maximize the log-likelihood of observing the QLFs obtained from the dependency trees, denoted by Q, summing out the unobserved semantic parses: Here, L are the semantic parses, 0 are the MLN parameters, and PB(Q, L) are the completion likelihoods.

In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ Evaluating unsupervised semantic parsers is difficult, because there is no predefined formal language or gold logical forms for the input sentences.
In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ In the approach of Zettlemoyer and Collins (2005), the training data consists of sentences paired with their meanings in lambda form.
In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ Recently, a number of machine learning approaches have been proposed (Zettlemoyer and Collins, 2005; Mooney, 2007).
In both cases, we follow (Poon and Domingos, 2009) in using the corpus of biomedical abstracts. $$$$$ At learning time, USP maintains an agenda that contains operations that have been evaluated and are pending execution.

Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in (Poon and Domingos, 2009). $$$$$ The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them.
Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in (Poon and Domingos, 2009). $$$$$ It successfully identifies many distinct argument forms that mean the same (e.g., “X stimulates Y” ≈ “Y is stimulated with X”, “expression of X” ≈ “X expression”).
Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in (Poon and Domingos, 2009). $$$$$ For example, when applying their approach to a different domain with somewhat less rigid syntax, Zettlemoyer and Collins (2007) need to introduce new combinators and new forms of candidate lexical entries.

Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ As a first approximation to the questions a biomedical researcher might ask, we generated a set of two thousand questions on relations between entities.
Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ Finally, we present the Markov logic network (MLN) used by USP.
Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ We evaluate our approach by using it to extract a knowledge base from biomedical abstracts and answer questions.
Semantic classes correspond to lambda-form clusters in (Poon and Domingos, 2009) terminology. $$$$$ Existing approaches differ in the meaning representation languages they use and the amount of annotation required.

The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ Given a sentence and the quasi-logical form Q derived from its dependency tree, the conditional probability for a semantic parse L is given by Pr(L|Q) a exp (Ei wini(L, Q)).
The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ This paper introduces the first unsupervised approach to learning semantic parsers.
The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ We thank the anonymous reviewers for their comments.
The work of (Poon and Domingos, 2009) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. $$$$$ Recently, a number of machine learning approaches have been proposed (Zettlemoyer and Collins, 2005; Mooney, 2007).

In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ We then introduce their lambda forms and clusters, and show how semantic parsing works in this setting.
In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ Directions for future work include: better handling of antonyms, subsumption relations among expressions, quantifier scoping, more complex lambda forms, etc.
In order to overcome this problem, (Poon and Domingos, 2009) group parameters and impose local normalization constraints within each group. $$$$$ For a new part p and a cluster that contains p’s core form, there are km ways of assigning p’s m arguments to the k argument types of the cluster.

We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ Unsupervised approaches have been applied to shallow semantic tasks (e.g., paraphrasing (Lin and Pantel, 2001), information extraction (Banko et al., 2007)), but not to semantic parsing.
We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task.
We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in (Poon and Domingos, 2009). $$$$$ We omit the proof here but point out that it is related to the unordered subtree matching problem which can be solved in linear time (Kilpelainen, 1992).

Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic.
Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task.
Other approaches are completely unsupervised, but do not tie the language to an existing meaning representation (Poon and Domingos, 2009). $$$$$ Thus the best way to test them is by using them for the ultimate goal: answering questions based on the input corpus.

USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, DARPA, NSF, ONR, or the United States Government.
USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic.
USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ If both match, we return the other argument string in the triple as an answer.
USP (Poon and Domingos, 2009) is based on Markov Logic Networks and attempts to create a full semantic parse in an unsupervised fashion. $$$$$ The first three lines are lexical entries.

Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.
Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic.
Markov Logic has been used previously in other NLP application (e.g. Poon and Domingos (2009)). $$$$$ However, they are supervised, and providing the target logical form for each sentence is costly and difficult to do consistently and with high quality.

Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ The MAP semantic parse is simply arg maxL & wini(L, Q).
Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ The MAP semantic parse is simply arg maxL & wini(L, Q).
Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.
Despite the existence of a large amount of related work in the literature, distinguishing synonyms and antonyms is still considered as a difficult open problem in general (Poon and Domingos, 2009). $$$$$ Here, we use the standard lambdacalculus notation, where AyAx.borders(x, y) represents a function that is true for any (x, y)pair such that borders(x, y) holds.

Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ We omit the proof here but point out that it is related to the unordered subtree matching problem which can be solved in linear time (Kilpelainen, 1992).
Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.
Dependency information is useful for a wealth of natural language processing tasks, including question answering (Wang et al, 2007), semantic parsing (Poon and Domingos, 2009), and machine translation (Galley and Manning, 2009). $$$$$ This paper introduces the first unsupervised approach to learning semantic parsers.

Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ Then the following partition is A-reducible from the first part in the above partition: Ax3.borders(n1) ∧ nsubj(n1, n2) ∧ Utah(n2) ∧ dobj(n1, x3), Idaho(n3).
Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ The standard language for formal meaning representation is first-order logic.
Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ The last two rules compose the meanings of sub-parts into that of the larger part.
Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (Poon and Domingos, 2009). $$$$$ This in turn allows it to correctly answer many more questions than systems based on TextRunner (Banko et al., 2007) and DIRT (Lin and Pantel, 2001).
