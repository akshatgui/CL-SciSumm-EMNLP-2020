Recently, Dowding et al (1993) reported syntactic and semantic coverage of 86% for the DARPA Airline reservation corpus (Dowding et al, 1993). $$$$$ Research in the construction of the Gemini system is ongoing to improve Gemini's speed and coverage, as well as to examine deeper integration strategies with speech recognition, and integration of prosodic information into spoken language disambiguation.
Recently, Dowding et al (1993) reported syntactic and semantic coverage of 86% for the DARPA Airline reservation corpus (Dowding et al, 1993). $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the Advanced Research Projects Agency of the U.S. Government. the multiple analyses arising before and after all this added robustness are managed in two ways: first, by highly constraining the additional rulebased modules by partitioning the rules into preference classes, and second, through the addition of a postprocessing parse preference component.
Recently, Dowding et al (1993) reported syntactic and semantic coverage of 86% for the DARPA Airline reservation corpus (Dowding et al, 1993). $$$$$ The approach taken in Gemini differs in that the utterance grammar uses the same syntactic and semantic rule formalism used by the constituent grammar.

In a test set containing 26 repairs (Dowding et al, 1993), they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a recall rate of 62%. $$$$$ In our approach to resolving the tension between overgeneration and robustness in a spoken language understanding system, some aspects of Gemini are specifically oriented towards limiting overgeneration, such as the on-line property for the parser, and fully interleaved syntactic and semantic processing.
In a test set containing 26 repairs (Dowding et al, 1993), they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a recall rate of 62%. $$$$$ Research in the construction of the Gemini system is ongoing to improve Gemini's speed and coverage, as well as to examine deeper integration strategies with speech recognition, and integration of prosodic information into spoken language disambiguation.
In a test set containing 26 repairs (Dowding et al, 1993), they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a recall rate of 62%. $$$$$ This formalism is related directly to the Core Language Engine, but more conceptually it is closely related to that of other unification-based grammar formalisms with a context-free skeleton, such as PATR-II (Shieber et al., 1983), Categorial Unification Grammar (Uszkoreit, 1986), Generalized Phrase-Structure Grammar (Gazdar et al., 1982), Gemini differs from other unification formalisms in the following ways.
In a test set containing 26 repairs (Dowding et al, 1993), they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a recall rate of 62%. $$$$$ Forgiving an error risks throwing away crucial information; furthermore, devices added to a system to enhance robustness can sometimes enrich the ways of finding an analysis, multiplying the number of analyses for a given input, and making it more difficult to find the correct analysis.

Dowding et al (1993) used a similar setup for their data. $$$$$ Table 1 contains a summary of the coverage of the various components on both the training and fair test sets.
Dowding et al (1993) used a similar setup for their data. $$$$$ If no semantically acceptable utterance-spanning edges are found during this phase, a component to recognize and correct certain grammatical disfluencies is applied.

Typed Unification Grammars (TUG), like HPSG (Pollard and Sag 1994) and Gemini (Dowding et al. 1993) are a more expressive formalism in which to write formal grammars. $$$$$ This paper describes the details of the system, and includes relevant measurements of size, efficiency, and performance of each of its components.
Typed Unification Grammars (TUG), like HPSG (Pollard and Sag 1994) and Gemini (Dowding et al. 1993) are a more expressive formalism in which to write formal grammars. $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the Advanced Research Projects Agency of the U.S. Government. the multiple analyses arising before and after all this added robustness are managed in two ways: first, by highly constraining the additional rulebased modules by partitioning the rules into preference classes, and second, through the addition of a postprocessing parse preference component.
Typed Unification Grammars (TUG), like HPSG (Pollard and Sag 1994) and Gemini (Dowding et al. 1993) are a more expressive formalism in which to write formal grammars. $$$$$ Other components, such as the fragment and run-on processing provided by the utterance grammar, and the correction of recognizable grammatical repairs, increase the robustness of Gemini.

Initial language processing is carried out Using the SRI Gemini system (Dowding et al, 1993), using a domain-independent unification. $$$$$ For example, in our application the object of the transitive verb depart (as in flights departing Boston) is restricted to be an airport or a city, obviously a domain-specific requirement.
Initial language processing is carried out Using the SRI Gemini system (Dowding et al, 1993), using a domain-independent unification. $$$$$ The following sections describe each of these components in detail, with the exception of the query-answering subsystem, which is not described in this paper.

We use the Open Agent Architecture (Martin et al 1999) for communication between agents based on the Nuance speech recognizer, the Gemini natural language system (Dowding et al 1993), and Festival speech synthesis. $$$$$ Sorts are located in a conceptual hierarchy and are implemented as Prolog terms such that more general sorts subsume more specific sorts (Mellish, 1988).
We use the Open Agent Architecture (Martin et al 1999) for communication between agents based on the Nuance speech recognizer, the Gemini natural language system (Dowding et al 1993), and Festival speech synthesis. $$$$$ We believe a robust system can still recognize and disprefer utterances containing recognition errors.
We use the Open Agent Architecture (Martin et al 1999) for communication between agents based on the Nuance speech recognizer, the Gemini natural language system (Dowding et al 1993), and Festival speech synthesis. $$$$$ Processing starts in Gemini when syntactic, semantic, and lexical rules are applied by a bottom-up all-paths constituent parser to populate a chart with edges containing syntactic, semantic, and logical form information.

Finally, we are developing an interface to a new large-vocabulary version of the Gemini parser (Dowding et al, 1993) which will allow us to use semantic parse information as features in the individual sub-class classifiers, and also to extract entity and event representations from the classified utterances for automatic addition of entries to calendars and to-do lists. $$$$$ Gemini was trained on a 5875-utterance dataset from this domain, with another 688 utterances used as a blind test (not explicitly trained on, but run multiple times) to monitor our performance on a dataset on which we did not train.
Finally, we are developing an interface to a new large-vocabulary version of the Gemini parser (Dowding et al, 1993) which will allow us to use semantic parse information as features in the individual sub-class classifiers, and also to extract entity and event representations from the classified utterances for automatic addition of entries to calendars and to-do lists. $$$$$ We believe a robust system can still recognize and disprefer utterances containing recognition errors.
Finally, we are developing an interface to a new large-vocabulary version of the Gemini parser (Dowding et al, 1993) which will allow us to use semantic parse information as features in the individual sub-class classifiers, and also to extract entity and event representations from the classified utterances for automatic addition of entries to calendars and to-do lists. $$$$$ Since Gemini was designed with spoken language interpretation in mind, key aspects of the Gemini parser are motivated by the increased needs for robustness and efficiency that characterize spoken language.
Finally, we are developing an interface to a new large-vocabulary version of the Gemini parser (Dowding et al, 1993) which will allow us to use semantic parse information as features in the individual sub-class classifiers, and also to extract entity and event representations from the classified utterances for automatic addition of entries to calendars and to-do lists. $$$$$ Other components, such as the fragment and run-on processing provided by the utterance grammar, and the correction of recognizable grammatical repairs, increase the robustness of Gemini.

Questions are posed to GeoLogica in a subset of English and translated into logic by a natural language parser, the system Gemini (Dowding et al, 1993). $$$$$ On the other hand, a system should be able to detect that a recognized string is not a sentence of English, to help filter recognition errors by the speech recognizer.
Questions are posed to GeoLogica in a subset of English and translated into logic by a natural language parser, the system Gemini (Dowding et al, 1993). $$$$$ In our approach to resolving the tension between overgeneration and robustness in a spoken language understanding system, some aspects of Gemini are specifically oriented towards limiting overgeneration, such as the on-line property for the parser, and fully interleaved syntactic and semantic processing.

This is contrasted with the all-paths bottom-up strategy in GEMINI (Dowding et al 1993) that finds all admissable edges of the grammar. $$$$$ We believe a robust system can still recognize and disprefer utterances containing recognition errors.

To handle the ASR results of disfluent utterances, we employ SRI's Gemini robust language parser (Dowding et al, 1993). $$$$$ In our component-by-component view of Gemini, we provide detailed statistics on each component's size, speed, coverage, and accuracy.
To handle the ASR results of disfluent utterances, we employ SRI's Gemini robust language parser (Dowding et al, 1993). $$$$$ In designing any NL understanding system, there is a tension between robustness and correctness.

The most likely hypothesis is input to SRI's Gemini natural language parser/generator (Dowding et al. 1993), which attempts to parse the speech recognition output. $$$$$ The highest ranked class consists of rules to identify simple complete sentences, the next highest class consists of rules to identify simple isolated sentence fragments, and so on.
The most likely hypothesis is input to SRI's Gemini natural language parser/generator (Dowding et al. 1993), which attempts to parse the speech recognition output. $$$$$ In our component-by-component view of Gemini, we provide detailed statistics on each component's size, speed, coverage, and accuracy.

The dialogue system uses the Nuance 8.0 speech recognizer with language models compiled from a grammar (written using the Gemini system (Dowding et al, 1993)), which is also used for parsing and generation. $$$$$ The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the Advanced Research Projects Agency of the U.S. Government. the multiple analyses arising before and after all this added robustness are managed in two ways: first, by highly constraining the additional rulebased modules by partitioning the rules into preference classes, and second, through the addition of a postprocessing parse preference component.
The dialogue system uses the Nuance 8.0 speech recognizer with language models compiled from a grammar (written using the Gemini system (Dowding et al, 1993)), which is also used for parsing and generation. $$$$$ In our approach to resolving the tension between overgeneration and robustness in a spoken language understanding system, some aspects of Gemini are specifically oriented towards limiting overgeneration, such as the on-line property for the parser, and fully interleaved syntactic and semantic processing.

Annotating sub-constituents with grammatical relations regularizes the syntactic structure with respect to particular grammatical rules, and allows a 'relation-to-relation' form of compositionality, as opposed to the more traditional 'rule-to-rule' version that is exemplified by such systems as Gemini (Dowding et al 1993) and the Core Language Engine (Alshawi, 1992). $$$$$ In our approach to resolving the tension between overgeneration and robustness in a spoken language understanding system, some aspects of Gemini are specifically oriented towards limiting overgeneration, such as the on-line property for the parser, and fully interleaved syntactic and semantic processing.
Annotating sub-constituents with grammatical relations regularizes the syntactic structure with respect to particular grammatical rules, and allows a 'relation-to-relation' form of compositionality, as opposed to the more traditional 'rule-to-rule' version that is exemplified by such systems as Gemini (Dowding et al 1993) and the Core Language Engine (Alshawi, 1992). $$$$$ Other components, such as the fragment and run-on processing provided by the utterance grammar, and the correction of recognizable grammatical repairs, increase the robustness of Gemini.
Annotating sub-constituents with grammatical relations regularizes the syntactic structure with respect to particular grammatical rules, and allows a 'relation-to-relation' form of compositionality, as opposed to the more traditional 'rule-to-rule' version that is exemplified by such systems as Gemini (Dowding et al 1993) and the Core Language Engine (Alshawi, 1992). $$$$$ Our current best guess is that recognizer errors are essentially orthogonal to repairs and that a filter including the repairs module will not suffer from precision problems.
