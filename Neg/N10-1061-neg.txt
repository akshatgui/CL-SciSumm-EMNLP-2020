These abstract notions (lexical association, proximity, tendencies towards few or many relations, and allowing for unassociated items) play an important role in many relation-detection tasks (e.g., co-reference resolution, Haghighi and Klein 2010). $$$$$ A second group comprises loglinear parameters π over discourse choices, also described below.
These abstract notions (lexical association, proximity, tendencies towards few or many relations, and allowing for unassociated items) play an important role in many relation-detection tasks (e.g., co-reference resolution, Haghighi and Klein 2010). $$$$$ Our system deterministically extracts mention boundaries from parse trees (Section 5.2).
These abstract notions (lexical association, proximity, tendencies towards few or many relations, and allowing for unassociated items) play an important role in many relation-detection tasks (e.g., co-reference resolution, Haghighi and Klein 2010). $$$$$ By sharing lexical statistics at the level of abstract entity types, our model is able to substantially reduce semantic compatibility errors, resulting in the best results to date on the complete end-to-end coreference task.

Many other existing systems applied supervised or unsupervised (Haghighi and Klein, 2010) learning models. $$$$$ Together, these distributions control the lists Lr for entities of that type.
Many other existing systems applied supervised or unsupervised (Haghighi and Klein, 2010) learning models. $$$$$ We compared our output to the deterministic system of Haghighi and Klein (2009).
Many other existing systems applied supervised or unsupervised (Haghighi and Klein, 2010) learning models. $$$$$ Our model does not represent the negative covariance between these modifiers.

However, such structured knowledge bases are of limited scope, and, while Haghighi and Klein (2010) self-acquires knowledge about coreference, it does so only via reference constructions and on a limited scale. $$$$$ The entity assignments Z are similarly divided into Zr and Zp components.
However, such structured knowledge bases are of limited scope, and, while Haghighi and Klein (2010) self-acquires knowledge about coreference, it does so only via reference constructions and on a limited scale. $$$$$ We now discuss errors and improvements made by our system.
However, such structured knowledge bases are of limited scope, and, while Haghighi and Klein (2010) self-acquires knowledge about coreference, it does so only via reference constructions and on a limited scale. $$$$$ As a result, it leverages semantic constraints more effectively than systems operating at either level alone.
However, such structured knowledge bases are of limited scope, and, while Haghighi and Klein (2010) self-acquires knowledge about coreference, it does so only via reference constructions and on a limited scale. $$$$$ On this more lenient setting, they report 78.4 B3 on the A04CU test set.

Altogether, our final system produces the best numbers reported to date on end-to-end coreference resolution (with automatically detected system mentions) on multiple data sets (ACE 2004 and ACE2005) and metrics (MUC and B3), achieving significant improvements over the Reconcile DT baseline and over the state-of-the-art results of Haghighi and Klein (2010). $$$$$ 11See nlp.cs.berkeley.edu and aria42.com/software.html for software release.
Altogether, our final system produces the best numbers reported to date on end-to-end coreference resolution (with automatically detected system mentions) on multiple data sets (ACE 2004 and ACE2005) and metrics (MUC and B3), achieving significant improvements over the Reconcile DT baseline and over the state-of-the-art results of Haghighi and Klein (2010). $$$$$ 11See nlp.cs.berkeley.edu and aria42.com/software.html for software release.
Altogether, our final system produces the best numbers reported to date on end-to-end coreference resolution (with automatically detected system mentions) on multiple data sets (ACE 2004 and ACE2005) and metrics (MUC and B3), achieving significant improvements over the Reconcile DT baseline and over the state-of-the-art results of Haghighi and Klein (2010). $$$$$ Intuitively, a small value of αr indicates that an entity prefers to re-use a small number of words for property r. This is typically the case for proper and nominal heads as well as modifiers.
Altogether, our final system produces the best numbers reported to date on end-to-end coreference resolution (with automatically detected system mentions) on multiple data sets (ACE 2004 and ACE2005) and metrics (MUC and B3), achieving significant improvements over the Reconcile DT baseline and over the state-of-the-art results of Haghighi and Klein (2010). $$$$$ One frequent source of error is the merging of mentions with explicitly contrasting modifiers, such as new president and old president.

In ACE04 and ACE05, we have only the newswire portion (of the original ACE 2004 and 2005 training sets) and use the standard train/test splits reported in Stoyanov et al (2009) and Haghighi and Klein (2010). $$$$$ By sharing lexical statistics at the level of abstract entity types, our model is able to substantially reduce semantic compatibility errors, resulting in the best results to date on the complete end-to-end coreference task.
In ACE04 and ACE05, we have only the newswire portion (of the original ACE 2004 and 2005 training sets) and use the standard train/test splits reported in Stoyanov et al (2009) and Haghighi and Klein (2010). $$$$$ Table 1 shows our results.
In ACE04 and ACE05, we have only the newswire portion (of the original ACE 2004 and 2005 training sets) and use the standard train/test splits reported in Stoyanov et al (2009) and Haghighi and Klein (2010). $$$$$ We decompose the mentions M into referring mentions (propers and nominals), Mr, and pronominal mentions, Mp (with sizes nr and np respectively).
In ACE04 and ACE05, we have only the newswire portion (of the original ACE 2004 and 2005 training sets) and use the standard train/test splits reported in Stoyanov et al (2009) and Haghighi and Klein (2010). $$$$$ We now discuss errors and improvements made by our system.

In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ 11See nlp.cs.berkeley.edu and aria42.com/software.html for software release.
In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ For nominal and pronoun mentions, there are several well-studied anaphora cues, including centering (Grosz et al., 1995), nearness (Hobbs, 1978), and deterministic constraints, which have all been utilized in prior coreference work (Soon et al., 1999; Ng and Cardie, 2002).
In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ We present a generative, model-based approach in which each of these factors is modularly encapsulated and learned in a primarily unsupervised manner.
In ACE05-ALL, we have the full ACE 2005 training set and use the standard train/test splits reported in Rahman and Ng (2009) and Haghighi and Klein (2010). $$$$$ Our generative model exploits a large inventory of distributional entity types, including standard NER types like PERSON and ORG, as well as more refined types like WEAPON and VEHICLE.

 $$$$$ During training, we proceed in stages, each consisting of 5 iterations: We evaluate our system at the end of stage using the B3All metric on the A05CU development set (see Section 5 for details).
 $$$$$ We decompose the mentions M into referring mentions (propers and nominals), Mr, and pronominal mentions, Mp (with sizes nr and np respectively).
 $$$$$ Our semantic representation first hypothesizes an underlying set of latent which generate specific entities that in turn render individual mentions.
 $$$$$ The entity assignments Z are similarly divided into Zr and Zp components.

Our main comparison is against Haghighi and Klein (2010), a mostly-unsupervised generative approach that models latent entity types, which generate specific entities that in turn render individual mentions. $$$$$ Ai either points to a previous antecedent mention position (Ai < i) and “steals” its entity assignment or begins a new entity (Ai = i).
Our main comparison is against Haghighi and Klein (2010), a mostly-unsupervised generative approach that models latent entity types, which generate specific entities that in turn render individual mentions. $$$$$ While the pairwise approach has high precision, it is neither realistic nor scalable to explicitly enumerate all pairs of compatible word pairs.
Our main comparison is against Haghighi and Klein (2010), a mostly-unsupervised generative approach that models latent entity types, which generate specific entities that in turn render individual mentions. $$$$$ One frequent source of error is the merging of mentions with explicitly contrasting modifiers, such as new president and old president.
Our main comparison is against Haghighi and Klein (2010), a mostly-unsupervised generative approach that models latent entity types, which generate specific entities that in turn render individual mentions. $$$$$ For example, the left mention in Figure 1(a) has a proper head property, denoted NAM-HEAD, with value “Obama.” The set of properties we consider, denoted R, includes several varieties of heads, modifiers, and governors (see Section 5.2 for details).

For the ACE05 and ACE05-ALL datasets, we revert to the 'AllPairs' (AP) setting of Reconcile because this gives us baselines competitive with Haghighi and Klein (2010). $$$$$ By sharing lexical statistics at the level of abstract entity types, our model is able to substantially reduce semantic compatibility errors, resulting in the best results to date on the complete end-to-end coreference task.
For the ACE05 and ACE05-ALL datasets, we revert to the 'AllPairs' (AP) setting of Reconcile because this gives us baselines competitive with Haghighi and Klein (2010). $$$$$ However, to our knowledge, this is the first work to incorporate such a model into an entity reference process.
For the ACE05 and ACE05-ALL datasets, we revert to the 'AllPairs' (AP) setting of Reconcile because this gives us baselines competitive with Haghighi and Klein (2010). $$$$$ Together, these two groups are drawn according to P(τ|λ)P(π|Q2), where λ and Q2 are a small number of scalar hyper-parameters described in Section 4.

Our submission was a reduced version of the system described in Haghighi and Klein (2010), with extensions to improve mention detection to suit the OntoNotes annotation scheme. $$$$$ We present a generative, model-based approach in which each of these factors is modularly encapsulated and learned in a primarily unsupervised manner.
Our submission was a reduced version of the system described in Haghighi and Klein (2010), with extensions to improve mention detection to suit the OntoNotes annotation scheme. $$$$$ However, to our knowledge, this is the first work to incorporate such a model into an entity reference process.
Our submission was a reduced version of the system described in Haghighi and Klein (2010), with extensions to improve mention detection to suit the OntoNotes annotation scheme. $$$$$ We present a generative, model-based approach in which each of these factors is modularly encapsulated and learned in a primarily unsupervised manner.
Our submission was a reduced version of the system described in Haghighi and Klein (2010), with extensions to improve mention detection to suit the OntoNotes annotation scheme. $$$$$ Our semantic representation first hypothesizes an underlying set of latent which generate specific entities that in turn render individual mentions.

Unlike previous work, we did not use the Bllip or Wikipedia data described in Haghighi and Klein (2010). $$$$$ 11See nlp.cs.berkeley.edu and aria42.com/software.html for software release.
Unlike previous work, we did not use the Bllip or Wikipedia data described in Haghighi and Klein (2010). $$$$$ Separately from the type-entity semantic module, a log-linear discourse model captures configurational effects.
Unlike previous work, we did not use the Bllip or Wikipedia data described in Haghighi and Klein (2010). $$$$$ On this more lenient setting, they report 78.4 B3 on the A04CU test set.

The specific update methods vary for each set of parameters; for details see Section 4 of Haghighi and Klein (2010). $$$$$ N000140911081.
The specific update methods vary for each set of parameters; for details see Section 4 of Haghighi and Klein (2010). $$$$$ We present a generative, model-based approach in which each of these factors is modularly encapsulated and learned in a primarily unsupervised manner.
The specific update methods vary for each set of parameters; for details see Section 4 of Haghighi and Klein (2010). $$$$$ These elements are generated as follows: Draw entity type T — 0 For each mention property r E R, Fetch {(fr, Br)} for TT Draw word list length |Lr |— fr Draw |Lr |words from w — Br See Figure 2 for an illustration of this process.
The specific update methods vary for each set of parameters; for details see Section 4 of Haghighi and Klein (2010). $$$$$ For example, for the type PERSON, Br for proper heads is quite flat (there are many last names) but fr is peaked at 1 (people have a single last name).

Unlike Haghighi and Klein (2010), no extra data from Wikipedia or Bllip was used, a restriction that was necessary to be eligible for the closed part of the task. $$$$$ Not every mention has a value for every property.
Unlike Haghighi and Klein (2010), no extra data from Wikipedia or Bllip was used, a restriction that was necessary to be eligible for the closed part of the task. $$$$$ For instance, for the PERSON type we might provide: Bush, Gore, Hussein president, minister, official he, his, she, him, her, you, ...
Unlike Haghighi and Klein (2010), no extra data from Wikipedia or Bllip was used, a restriction that was necessary to be eligible for the closed part of the task. $$$$$ Our model yields 80.3.
Unlike Haghighi and Klein (2010), no extra data from Wikipedia or Bllip was used, a restriction that was necessary to be eligible for the closed part of the task. $$$$$ To train, we included the text of all documents above, though of course not looking at either their mention boundaries or reference annotations in any way.

Generative models are also used in unsupervised coreference (Haghighi and Klein, 2010). $$$$$ We also compared to the strong deterministic system of Haghighi and Klein (2009).10 Across all data sets, our model, despite being largely unsupervised, consistently outperforms these systems, which are the best previously reported results on end-to-end coreference resolution (i.e. including mention detection).
Generative models are also used in unsupervised coreference (Haghighi and Klein, 2010). $$$$$ 10Haghighi and Klein (2009) reports on true mentions; here, we report performance on automatically detected mentions. are not.
Generative models are also used in unsupervised coreference (Haghighi and Klein, 2010). $$$$$ For example, analyst and it cannot corefer in our system because it is not a likely pronoun for the type PERSON.

While early approaches focused on surface-level methods such as wrapper induction (Kushmerick et al, 1997), more recent work in this area includes Bayesian nonparametrics to select the number of rows in the database (Haghighi and Klein, 2010a). $$$$$ Perhaps because configurational features are inherently easier to learn from small data sets, past work has often emphasized them over semantic knowledge.
While early approaches focused on surface-level methods such as wrapper induction (Kushmerick et al, 1997), more recent work in this area includes Bayesian nonparametrics to select the number of rows in the database (Haghighi and Klein, 2010a). $$$$$ Note that this task is substantially more difficult than the unsupervised NER in Elsner et al. (2009) because the inventory of named entities is larger (7 vs. 3) and because we predict types over nominal mentions that are more difficult to judge from surface forms.
While early approaches focused on surface-level methods such as wrapper induction (Kushmerick et al, 1997), more recent work in this area includes Bayesian nonparametrics to select the number of rows in the database (Haghighi and Klein, 2010a). $$$$$ Finally, a mention generation module independently renders the sequence of mentions (M) from their underlying entities.
While early approaches focused on surface-level methods such as wrapper induction (Kushmerick et al, 1997), more recent work in this area includes Bayesian nonparametrics to select the number of rows in the database (Haghighi and Klein, 2010a). $$$$$ Hypotheses are extended via adding a new mention to an existing entity or creating a new one.

The best coreference systems depend on carefully crafted, problem-specific linguistic features (Bengtson and Roth, 2008) and external knowledge (Haghighi and Klein, 2010b). $$$$$ Since the person type in ACE conflates individual persons with groups of people (e.g., soldier vs. soldiers), we added the group (GROUP) type and generated a prototype specification.
The best coreference systems depend on carefully crafted, problem-specific linguistic features (Bengtson and Roth, 2008) and external knowledge (Haghighi and Klein, 2010b). $$$$$ We also compared to the strong deterministic system of Haghighi and Klein (2009).10 Across all data sets, our model, despite being largely unsupervised, consistently outperforms these systems, which are the best previously reported results on end-to-end coreference resolution (i.e. including mention detection).
The best coreference systems depend on carefully crafted, problem-specific linguistic features (Bengtson and Roth, 2008) and external knowledge (Haghighi and Klein, 2010b). $$$$$ We now discuss errors and improvements made by our system.
The best coreference systems depend on carefully crafted, problem-specific linguistic features (Bengtson and Roth, 2008) and external knowledge (Haghighi and Klein, 2010b). $$$$$ While the focus of our model is coreference resolution, we can also isolate and evaluate the type component of our model as an NER system.

This knowledge could be especially helpful for cross document coreference resolution systems (Haghighi and Klein, 2010), which actually represent concepts and track mentions of them across documents. $$$$$ Many improvements arise from correctly identifying mentions which are semantically compatible but which do not explicitly appear in an appositive or predicatenominative configuration in the data.
This knowledge could be especially helpful for cross document coreference resolution systems (Haghighi and Klein, 2010), which actually represent concepts and track mentions of them across documents. $$$$$ We test this component by presenting our learned model with boundary-annotated non-pronominal entities from the A05ST dev set and querying their predicted type variable T. Doing so yields 83.2 entity classification accuracy under the mapping between our prototyped types and the coarse ACE types.

 $$$$$ Our learning procedure involves finding parameters and assignments which are likely under our model’s posterior distribution P(E, Z, T, 9C|M, X).
 $$$$$ We set αr to 1 for pronoun heads as well as for the governor of the head properties.
 $$$$$ Our model is able to acquire and exploit knowledge at either the level of individual entities (“Obama” is a “president”) and entity types (“company” can refer to a corporation).
 $$$$$ We utilized MUC (Vilain et al., 1995), B3All (Stoyanov et al., 2009), B3None (Stoyanov et al., 2009), and Pairwise F1.

For instance, Haghighi and Klein (2010) include the governor of the head of nominal mentions as features in their model. $$$$$ The syntactic position and structure of mentions are treated as observed, including the mention forms (pronominal, etc.).
For instance, Haghighi and Klein (2010) include the governor of the head of nominal mentions as features in their model. $$$$$ As an example of nominal headword compatibility, a “president” can be a “leader” but cannot be not an “increase.” Past systems have often computed the compatibility of specific headword pairs, extracted either from lexical resources (Ng, 2007; Bengston and Roth, 2008; Rahman and Ng, 2009), web statistics (Yang et al., 2005), or surface syntactic patterns (Haghighi and Klein, 2009).
For instance, Haghighi and Klein (2010) include the governor of the head of nominal mentions as features in their model. $$$$$ Coreference resolution is governed by syntactic, semantic, and discourse constraints.
For instance, Haghighi and Klein (2010) include the governor of the head of nominal mentions as features in their model. $$$$$ In conjunction with reasonable, but simple, factors capturing discourse and syntactic configurational preferences, our entity-centric semantic model lowers coreference error rate substantially, particularly on semantically disambiguated references, giving a sizable improvement over the state-of-the-art.11 Acknowledgements: This project is funded in part by the Office of Naval Research under MURI Grant No.

Daume III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. $$$$$ The prototypes were used as follows: Any entity with a prototype on any proper or nominal head word attribute list (Section 3.1) was constrained to have the specified type; i.e. the qk factor (Section 4) places probability one on that single type.
Daume III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. $$$$$ During training, we proceed in stages, each consisting of 5 iterations: We evaluate our system at the end of stage using the B3All metric on the A05CU development set (see Section 5 for details).
Daume III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. $$$$$ Our model yields 80.3.
Daume III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. $$$$$ The Stoyanov et al. (2009) numbers represent their THRESHOLD ESTIMATION setting and the Rahman and Ng (2009) numbers represent their highestperforming cluster ranking model.
