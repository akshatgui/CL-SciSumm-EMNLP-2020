Virga and Khudanpur (2003) reported 8.3% absolute accuracy drops when converting from Pinyin to Chinese character. $$$$$ We have found small gains in the extrinsic evaluation of our procedure: mAP improvement from 0.501 to 0.517.
Virga and Khudanpur (2003) reported 8.3% absolute accuracy drops when converting from Pinyin to Chinese character. $$$$$ For CLIR applications in particular, proper names and technical terms are especially important, as they carry the most distinctive information in a query as corroborated by their relatively low document frequency.
Virga and Khudanpur (2003) reported 8.3% absolute accuracy drops when converting from Pinyin to Chinese character. $$$$$ It is plausible, though we cannot find a stronger justification for it, that by using the 10-best transliterations produced by our automatic system, we are adding robustness against ASR errors in the retrieval of proper names.

Virga and Khudanpur (2003) and Kuo et al (2005) adopted the noisy channel modeling framework. $$$$$ The LDC Chinese-English named entity list was compiled from Xinhua News sources, and consists of nine pairs of lists, one each to cover personnames, place-names, organizations, etc.
Virga and Khudanpur (2003) and Kuo et al (2005) adopted the noisy channel modeling framework. $$$$$ We therefore went back to Step 3 of the procedure outlined above, where we had used alignment scores from an MT system to select “good” sentence-pairs from our training data, and instead of using the MT system trained in Step 2 immediately preceding it, we used the previously built Big MT system of Section 2.1, which we know is trained on a small but clean data-set of 3625 namepairs.
Virga and Khudanpur (2003) and Kuo et al (2005) adopted the noisy channel modeling framework. $$$$$ We demonstrate the application of statistical machine translation techniques to “translate” the phonemic representation of an English name, obtained by using an automatic text-to-speech system, to a sequence of initials and finals, commonly used subword units of pronunciation for Chinese.

Technologies developed for SMTare borrowed in Virga and Khudanpur (2003) and AbdulJaleel and Larkey (2003). $$$$$ We expect to further refine the translation models in the future and apply them in other tasks such as text translation.
Technologies developed for SMTare borrowed in Virga and Khudanpur (2003) and AbdulJaleel and Larkey (2003). $$$$$ We retrained the statistical MT system on this presumably “good” training set and evaluated the pin-yin error rate of the transliteration.
Technologies developed for SMTare borrowed in Virga and Khudanpur (2003) and AbdulJaleel and Larkey (2003). $$$$$ This paper describes a statistical approach for the second step.
Technologies developed for SMTare borrowed in Virga and Khudanpur (2003) and AbdulJaleel and Larkey (2003). $$$$$ We address the problem of transliterating English names using Chinese orthography in support of cross-lingual speech and text processing applications.

The proposed transliteration framework obtained significant improvements over a strong baseline transliteration approach similar to AbdulJaleel and Larkey (2003) and Virga and Khudanpur (2003). $$$$$ We have presented a name transliteration procedure based on statistical machine translation techniques and have investigated its use in a cross lingual spoken document retrieval task.
The proposed transliteration framework obtained significant improvements over a strong baseline transliteration approach similar to AbdulJaleel and Larkey (2003) and Virga and Khudanpur (2003). $$$$$ We continue to believe that careful data-selection is the key to successful use of this beta-release of the LDC Named Entity corpus.
The proposed transliteration framework obtained significant improvements over a strong baseline transliteration approach similar to AbdulJaleel and Larkey (2003) and Virga and Khudanpur (2003). $$$$$ We then use another statistical translation model to map the initial/final sequence to Chinese characters.
The proposed transliteration framework obtained significant improvements over a strong baseline transliteration approach similar to AbdulJaleel and Larkey (2003) and Virga and Khudanpur (2003). $$$$$ We also present an evaluation of this module in retrieval of Mandarin spoken documents from the TDT corpus using English text queries.

This result was comparable to other state-of-the-art statistical name transliteration systems (Virga and Khudanpur, 2003). $$$$$ We therefore went back to Step 3 of the procedure outlined above, where we had used alignment scores from an MT system to select “good” sentence-pairs from our training data, and instead of using the MT system trained in Step 2 immediately preceding it, we used the previously built Big MT system of Section 2.1, which we know is trained on a small but clean data-set of 3625 namepairs.
This result was comparable to other state-of-the-art statistical name transliteration systems (Virga and Khudanpur, 2003). $$$$$ Without name transliteration, the performance of the two CLIR systems is nearly identical: a paired t-test shows that the difference in the mAPs of 0.514 and 0.501 is significant only at a -value of 0.74.
This result was comparable to other state-of-the-art statistical name transliteration systems (Virga and Khudanpur, 2003). $$$$$ We evaluated this system on the 3122 namepair test set for transliteration performance, and the results are included in Table 3.

 $$$$$ We evaluated this system on the 3122 namepair test set for transliteration performance, and the results are included in Table 3.
 $$$$$ We have presented a name transliteration procedure based on statistical machine translation techniques and have investigated its use in a cross lingual spoken document retrieval task.

Virga and Khudanpur (2003) model this scoring function using a separate translation and language model, that is, s (e, f)= Pr (f $$$$$ We then use another statistical translation model to map the initial/final sequence to Chinese characters.
Virga and Khudanpur (2003) model this scoring function using a separate translation and language model, that is, s (e, f)= Pr (f $$$$$ We then aligned all the (nearly 1M) training “sentence” pairs with this translation model, and extracted roughly a third of the sentences with an alignment score above a certain tunable threshold ().
Virga and Khudanpur (2003) model this scoring function using a separate translation and language model, that is, s (e, f)= Pr (f $$$$$ Thus even the initial requirement of creating candidate transformation rules, which may require knowledge of the phonology of the target language, is eliminated.

Past studies on phoneme-based E2C have reported their adverse effects (e.g. Virga and Khudanpur, 2003). $$$$$ Several multi-lingual speech and text applications require some form of name transliteration, crosslingual spoken document retrieval being a prototypical example.
Past studies on phoneme-based E2C have reported their adverse effects (e.g. Virga and Khudanpur, 2003). $$$$$ This linguistic knowledge, however, need not be imparted by hand in the IBM model.
Past studies on phoneme-based E2C have reported their adverse effects (e.g. Virga and Khudanpur, 2003). $$$$$ To our surprise, the mAP improvement from 0.501 to 0.506 was statistically insignificant ( -value of 0.421) and the reason why the use of the ostensibly correct transliteration most of the time still does not result in any significant gain in CLIR performance continues to elude us.
Past studies on phoneme-based E2C have reported their adverse effects (e.g. Virga and Khudanpur, 2003). $$$$$ We expect to further refine the translation models in the future and apply them in other tasks such as text translation.

Virga and Khudanpur (2003) reported 8.3% absolute accuracy drops when converting from Pinyin to Chinese characters, due to homophone confusion. $$$$$ We also investigate incorporation of this transliteration system in a cross-lingual spoken document retrieval application, in which English text queries are used to index and retrieve Mandarin audio from the TDT corpus.
Virga and Khudanpur (2003) reported 8.3% absolute accuracy drops when converting from Pinyin to Chinese characters, due to homophone confusion. $$$$$ We also investigate incorporation of this transliteration system in a cross-lingual spoken document retrieval application, in which English text queries are used to index and retrieve Mandarin audio from the TDT corpus.
Virga and Khudanpur (2003) reported 8.3% absolute accuracy drops when converting from Pinyin to Chinese characters, due to homophone confusion. $$$$$ We make an ad hoc correction of such sequences when mapping a GIF sequence to pin-yin, which is otherwise trivial for all legal sequences of initials and finals.

In CLIR or multilingual corpus alignment (Virga and Khudanpur, 2003), N-best results will be very helpful to increase chances of correct hits. $$$$$ Unlike specialized terminology, however, proper names are amenable to a speech-inspired translation approach.
In CLIR or multilingual corpus alignment (Virga and Khudanpur, 2003), N-best results will be very helpful to increase chances of correct hits. $$$$$ The statistical significance of the improvement from 0.514 to 0.522 by Meng et al (2001) is not known to us.
In CLIR or multilingual corpus alignment (Virga and Khudanpur, 2003), N-best results will be very helpful to increase chances of correct hits. $$$$$ The overall architecture of the proposed transliteration system is illustrated in Figure 2.
In CLIR or multilingual corpus alignment (Virga and Khudanpur, 2003), N-best results will be very helpful to increase chances of correct hits. $$$$$ A character trigram model with Good-Turing discounting and Katz back-off is estimated from the list of transliterated names.

The reference data are extracted from Table 1 and 3 of (Virga and Khudanpur 2003). $$$$$ We then use another statistical translation model to map the initial/final sequence to Chinese characters.
The reference data are extracted from Table 1 and 3 of (Virga and Khudanpur 2003). $$$$$ We then use another statistical translation model to map the initial/final sequence to Chinese characters.
The reference data are extracted from Table 1 and 3 of (Virga and Khudanpur 2003). $$$$$ We expect to further refine the translation models in the future and apply them in other tasks such as text translation.
