The concept of compatible coverage vectors for the locations of translated words becomes the notion of reachability between frontier nodes in the lattice (Dyer et al, 2008). $$$$$ Although the number of source phrases in a word lattice can be exponential in the number of nodes, enumerating the possible translations of every span in a lattice is in practice tractable, as described by Bertoldi et al. (2007).
The concept of compatible coverage vectors for the locations of translated words becomes the notion of reachability between frontier nodes in the lattice (Dyer et al, 2008). $$$$$ The word lattice decoder works similarly, only now the decoder keeps track not of the words that have been covered, but of the nodes, given a topological ordering of the nodes.
The concept of compatible coverage vectors for the locations of translated words becomes the notion of reachability between frontier nodes in the lattice (Dyer et al, 2008). $$$$$ The Arabic-English morphological segmentation lattices are similar in spirit to backoff translation models (Yang and Kirchhoff, 2006), which consider alternative morphological segmentations and simplifications of a surface token when the surface token can not be translated.
The concept of compatible coverage vectors for the locations of translated words becomes the notion of reachability between frontier nodes in the lattice (Dyer et al, 2008). $$$$$ Additionally, we resolve a significant complication that non-linear word lattice inputs introduce in reordering models.

We also plan to jointly optimize MT and name tagging by propagating multiple word segmentation and name annotation hypotheses in lattice structure to statistical MT and conduct lattice based decoding (Dyer et al, 2008). $$$$$ On both test sets, the shortest path metric improved the BLEU scores.
We also plan to jointly optimize MT and name tagging by propagating multiple word segmentation and name annotation hypotheses in lattice structure to statistical MT and conduct lattice based decoding (Dyer et al, 2008). $$$$$ Dyer (2007) uses confusion networks to encode morphological alternatives in Czech-English translation, and Xu et al. (2005) takes an approach very similar to ours for Chinese-English translation and encodes multiple word segmentations in a lattice, but which is decoded with a conventionally trained translation model and without a sophisticated reordering model.

In applications like the one described by Dyer et al (2008), where several different segmenters for Chinese are combined to create the lattice, this is not possible. $$$$$ Mathias and Byrne (2006) build a phrase-based translation system as a cascaded series of FSTs which can accept any input FSA; however, the only reordering that is permitted is the swapping of two adjacent phrases.
In applications like the one described by Dyer et al (2008), where several different segmenters for Chinese are combined to create the lattice, this is not possible. $$$$$ In Section 2, we discuss decoding with this model in general, and then show how two classes of translation models can easily be adapted for lattice translation; we achieve a unified treatment of finite-state and hierarchical phrase-based models by treating lattices as a subcase of weighted finite state automata (FSAs).
In applications like the one described by Dyer et al (2008), where several different segmenters for Chinese are combined to create the lattice, this is not possible. $$$$$ Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.
In applications like the one described by Dyer et al (2008), where several different segmenters for Chinese are combined to create the lattice, this is not possible. $$$$$ Matusov et al. (2005) decodes monotonically and then uses a finite state reordering model on the single-best translation, along the lines of Bangalore and Riccardi (2000).

Dyer et al (2008) use it to encode different Chinese word segmentations or Arabic morphological analyses. $$$$$ The results are summarized in Table 4.
Dyer et al (2008) use it to encode different Chinese word segmentations or Arabic morphological analyses. $$$$$ In large lattices, where a single arc may span many nodes, the possible distances may vary quite substantially depending on what path is ultimately taken, and handling this properly therefore crucial.
Dyer et al (2008) use it to encode different Chinese word segmentations or Arabic morphological analyses. $$$$$ Our experiments evaluating the approach demonstrate substantial gains for Chinese- English and Arabic-English translation.

Our work differs from (Dyer et al, 2008) in that we explicitly distinguish the various preprocessing types in the lattice so that we can define specific path features and lexicalize the lattice path probabilities within the phrase model. $$$$$ In this paper, we go beyond speech translation by showing that lattice decoding can also yield improvements for text by preserving alternative analyses of the input.
Our work differs from (Dyer et al, 2008) in that we explicitly distinguish the various preprocessing types in the lattice so that we can define specific path features and lexicalize the lattice path probabilities within the phrase model. $$$$$ In both hierarchical and phrase-based models, the distance between words in the source sentence is used to limit where in the target sequence their translations will be generated.
Our work differs from (Dyer et al, 2008) in that we explicitly distinguish the various preprocessing types in the lattice so that we can define specific path features and lexicalize the lattice path probabilities within the phrase model. $$$$$ Our results generalize previous gains for lattice translation of spoken language input, and we have further generalized the approach by introducing an algorithm for lattice decoding using a hierarchical phrase-based model.

It was noted by Dyer et al (2008) that the standard distance-based reordering model needs to be redefined for lattice input. $$$$$ Additionally, we resolve a significant complication that non-linear word lattice inputs introduce in reordering models.
It was noted by Dyer et al (2008) that the standard distance-based reordering model needs to be redefined for lattice input. $$$$$ Our results generalize previous gains for lattice translation of spoken language input, and we have further generalized the approach by introducing an algorithm for lattice decoding using a hierarchical phrase-based model.

Using the shortest path within the lattice is reported to have better performance in (Dyer et al, 2008), however we did not implement it due to time constraints. $$$$$ On both test sets, the shortest path metric improved the BLEU scores.
Using the shortest path within the lattice is reported to have better performance in (Dyer et al, 2008), however we did not implement it due to time constraints. $$$$$ Parsing and formal language theory.
Using the shortest path within the lattice is reported to have better performance in (Dyer et al, 2008), however we did not implement it due to time constraints. $$$$$ For an additional datapoint, we added a lexicalized reordering model that models the probability of each phrase pair appearing in three different orientations (swap, monotone, other) in the training corpus (Koehn et al., 2005).

Our word lattices are similar to those used by Dyer et al (2008) for handling word segmentation in Chinese and Arabic. $$$$$ We show that prior work in translating lattices using finite state techniques can be naturally extended to more expressive synchronous context-free grammarbased models.
Our word lattices are similar to those used by Dyer et al (2008) for handling word segmentation in Chinese and Arabic. $$$$$ Our experiments evaluating the approach demonstrate substantial gains for Chinese- English and Arabic-English translation.
Our word lattices are similar to those used by Dyer et al (2008) for handling word segmentation in Chinese and Arabic. $$$$$ This research was supported by the GALE program of the Defense Advanced Research Projects Agency, Contract No.
Our word lattices are similar to those used by Dyer et al (2008) for handling word segmentation in Chinese and Arabic. $$$$$ HR0011-06-2-0001.

Recent studies have shown that SMT systems can benefit from widening the annotation pipeline: using packed forests instead of 1-best trees (Mi and Huang,2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and weighted alignment matrices instead of 1-best alignments (Liu et al, 2009). $$$$$ In a non-linear word lattice, a further constraint must be enforced ensuring that there is always a path from the starting node of the translation extension’s source to the node representing the nearest right edge of the already-translated material, as well as a path from the ending node of the translation extension’s source to future translated spans.
Recent studies have shown that SMT systems can benefit from widening the annotation pipeline: using packed forests instead of 1-best trees (Mi and Huang,2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and weighted alignment matrices instead of 1-best alignments (Liu et al, 2009). $$$$$ Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.
Recent studies have shown that SMT systems can benefit from widening the annotation pipeline: using packed forests instead of 1-best trees (Mi and Huang,2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and weighted alignment matrices instead of 1-best alignments (Liu et al, 2009). $$$$$ Additionally, we have shown that although word lattices complicate modeling of word reordering, a simple heuristic offers good performance and enables many standard distortion models to be used directly with lattice input.
Recent studies have shown that SMT systems can benefit from widening the annotation pipeline: using packed forests instead of 1-best trees (Mi and Huang,2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and weighted alignment matrices instead of 1-best alignments (Liu et al, 2009). $$$$$ FSAs where every path does not pass through every node.

Lattice represent the system implemented as Dyer et al, (2008). $$$$$ Nonetheless, state-of-the-art systems commonly identify a single analysis f during a preprocessing step, and decode according to the decision rule in (1).
Lattice represent the system implemented as Dyer et al, (2008). $$$$$ Lattice Translation.
Lattice represent the system implemented as Dyer et al, (2008). $$$$$ We adapted the Moses phrase-based decoder to translate word lattices (Koehn et al., 2007).
Lattice represent the system implemented as Dyer et al, (2008). $$$$$ HR0011-06-2-0001.

Same as Dyer et al, (2008), we also extracted rules from a combined bilingual corpus which contains three copies from different segmenters. $$$$$ We see that using word lattices improves BLEU scores both in the phrase-based model and hierarchical model as compared to the single-best segmentation approach.
Same as Dyer et al, (2008), we also extracted rules from a combined bilingual corpus which contains three copies from different segmenters. $$$$$ We have achieved substantial gains in translation performance by decoding compact representations of alternative source language analyses, rather than single-best representations.
Same as Dyer et al, (2008), we also extracted rules from a combined bilingual corpus which contains three copies from different segmenters. $$$$$ For these experiments we made use of the entire NIST MT08 training data, although for training of the system, we used a subsampling method proposed by Kishore Papineni that aims to include training sentences containing ngrams in the test data (personal communication).
Same as Dyer et al, (2008), we also extracted rules from a combined bilingual corpus which contains three copies from different segmenters. $$$$$ The intuition behind this model is that since most translation is monotonic, the cost of skipping ahead or back in the source should be proportional to the number of words that are skipped.

Du et al (2010), in this proceedings, explore the use of source paraphrases without targeting apparent mistranslations, using lattice translation (Dyer et al, 2008) to efficiently represent and decode the resulting very large space of paraphrase alternatives. $$$$$ HR0011-06-2-0001.
Du et al (2010), in this proceedings, explore the use of source paraphrases without targeting apparent mistranslations, using lattice translation (Dyer et al, 2008) to efficiently represent and decode the resulting very large space of paraphrase alternatives. $$$$$ The first decoder we present is a SCFG-based decoder similar to the one described in Chiang (2007).
Du et al (2010), in this proceedings, explore the use of source paraphrases without targeting apparent mistranslations, using lattice translation (Dyer et al, 2008) to efficiently represent and decode the resulting very large space of paraphrase alternatives. $$$$$ FSAs where every path does not pass through every node.
Du et al (2010), in this proceedings, explore the use of source paraphrases without targeting apparent mistranslations, using lattice translation (Dyer et al, 2008) to efficiently represent and decode the resulting very large space of paraphrase alternatives. $$$$$ Thus, we make use of the following general decision rule: In principle, one could decode according to (2) simply by enumerating and decoding each f� ∈ F(o); however, for any interestingly large F(o) this will be impractical.

Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al, 2008) in order to allow a compact representation of alternative inputs to an SMT system. $$$$$ HR0011-06-2-0001.
Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al, 2008) in order to allow a compact representation of alternative inputs to an SMT system. $$$$$ The pattern is the same, showing a clear increase in BLEU for the shortest path metric over the baseline.
Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al, 2008) in order to allow a compact representation of alternative inputs to an SMT system. $$$$$ Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.
Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al, 2008) in order to allow a compact representation of alternative inputs to an SMT system. $$$$$ Table 3 summarizes the results of our experiment comparing the performance of two distance metrics to determine whether a rule has exceeded the decoder’s span limit.

All of the systems we present use the lattice input format to Moses (Dyer et al, 2008), including the baselines which do not need them. $$$$$ In Section 5 we discuss relevant prior work, and we conclude in Section 6.
All of the systems we present use the lattice input format to Moses (Dyer et al, 2008), including the baselines which do not need them. $$$$$ The pattern is the same, showing a clear increase in BLEU for the shortest path metric over the baseline.
All of the systems we present use the lattice input format to Moses (Dyer et al, 2008), including the baselines which do not need them. $$$$$ Our results generalize previous gains for lattice translation of spoken language input, and we have further generalized the approach by introducing an algorithm for lattice decoding using a hierarchical phrase-based model.
All of the systems we present use the lattice input format to Moses (Dyer et al, 2008), including the baselines which do not need them. $$$$$ HR0011-06-2-0001.

Recently, several studies have shown that offering more alternatives of annotations to SMT systems will result in significant improvements, such as replacing 1-best trees with packed forests (Miet al, 2008) and replacing 1-best word segmentations with word lattices (Dyer et al, 2008). $$$$$ Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.
Recently, several studies have shown that offering more alternatives of annotations to SMT systems will result in significant improvements, such as replacing 1-best trees with packed forests (Miet al, 2008) and replacing 1-best word segmentations with word lattices (Dyer et al, 2008). $$$$$ Ri,j is the node number of the node on the right side of the jth transition leaving node i.
Recently, several studies have shown that offering more alternatives of annotations to SMT systems will result in significant improvements, such as replacing 1-best trees with packed forests (Miet al, 2008) and replacing 1-best word segmentations with word lattices (Dyer et al, 2008). $$$$$ The corresponding transition cost is pi,j.

Recent studies has shown that SMT systems can benefit from making the annotation pipeline wider: using packed forests instead of 1-best trees (Mi et al, 2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and n-best alignments instead of 1-best alignments (Venugopal et al, 2008). $$$$$ By encoding alternatives in the input in a word lattice, the decision as to which granularity to use for a given span can be resolved during decoding rather than when constructing the system.
Recent studies has shown that SMT systems can benefit from making the annotation pipeline wider: using packed forests instead of 1-best trees (Mi et al, 2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and n-best alignments instead of 1-best alignments (Venugopal et al, 2008). $$$$$ Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.
Recent studies has shown that SMT systems can benefit from making the annotation pipeline wider: using packed forests instead of 1-best trees (Mi et al, 2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and n-best alignments instead of 1-best alignments (Venugopal et al, 2008). $$$$$ In Section 5 we discuss relevant prior work, and we conclude in Section 6.
Recent studies has shown that SMT systems can benefit from making the annotation pipeline wider: using packed forests instead of 1-best trees (Mi et al, 2008), word lattices instead of 1-best segmentations (Dyer et al, 2008), and n-best alignments instead of 1-best alignments (Venugopal et al, 2008). $$$$$ As with sentencebased decoding, a translation hypothesis is complete when all nodes in the input lattice are covered.

As lattice is a more general form of confusion network (Dyer et al, 2008), we expect that replacing confusion networks with lattices will further improve system combination. $$$$$ We used both a phrase-based translation model, decoded using our modified version of Moses (Koehn et al., 2007), and a hierarchical phrase-based translation model, using our modified version of Hiero (Chiang, 2005; Chiang, 2007).
As lattice is a more general form of confusion network (Dyer et al, 2008), we expect that replacing confusion networks with lattices will further improve system combination. $$$$$ We adapted the Moses phrase-based decoder to translate word lattices (Koehn et al., 2007).
As lattice is a more general form of confusion network (Dyer et al, 2008), we expect that replacing confusion networks with lattices will further improve system combination. $$$$$ FSAs where every path does not pass through every node.

Our implementation's runtime and memory overhead is proportional to the size of the lattice, rather than the number of paths in the lattice (Dyer et al, 2008). $$$$$ Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.
Our implementation's runtime and memory overhead is proportional to the size of the lattice, rather than the number of paths in the lattice (Dyer et al, 2008). $$$$$ The systems used in these experiments were trained on the NIST MT06 Eval corpus without the UN data (approximatively 950K sentences).
Our implementation's runtime and memory overhead is proportional to the size of the lattice, rather than the number of paths in the lattice (Dyer et al, 2008). $$$$$ FSAs where every path does not pass through every node.
Our implementation's runtime and memory overhead is proportional to the size of the lattice, rather than the number of paths in the lattice (Dyer et al, 2008). $$$$$ In large lattices, where a single arc may span many nodes, the possible distances may vary quite substantially depending on what path is ultimately taken, and handling this properly therefore crucial.

Lattice parsing is not new to translation (Dyer et al, 2008), but to our knowledge it has not been used in this way. $$$$$ (2007)) comment directly on the impracticality of using n-best lists to translate speech.
Lattice parsing is not new to translation (Dyer et al, 2008), but to our knowledge it has not been used in this way. $$$$$ Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.
Lattice parsing is not new to translation (Dyer et al, 2008), but to our knowledge it has not been used in this way. $$$$$ The authors wish to thank Niyu Ge for the Chinese named-entity analysis, Pi-Chuan Chang for her assistance with the Stanford Chinese segmenter, and Tie-Jun Zhao and Congui Zhu for making the Harbin Chinese segmenter available to us.

Dyer et al (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. $$$$$ On both test sets, the shortest path metric improved the BLEU scores.
Dyer et al (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. $$$$$ HR0011-06-2-0001.
Dyer et al (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. $$$$$ Our experiments evaluating the approach demonstrate substantial gains for Chinese- English and Arabic-English translation.
Dyer et al (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. $$$$$ Parsing and formal language theory.
