Given the fine-grained syntactic and semantic analysis of the HPSG grammar and its robustness (through SNLP integration), we decided to use the semantic representation (MRS, see (Copestake et al, 2001)) as additional input for IE. $$$$$ There are some aspects which cannot be encoded within currently implemented TFS formalisms because they involve negative conditions: for instance, we could not write TFS constraints that absolutely prevent a grammar writer sneaking in a disallowed coindexation by specifying a path into the lzt.
Given the fine-grained syntactic and semantic analysis of the HPSG grammar and its robustness (through SNLP integration), we decided to use the semantic representation (MRS, see (Copestake et al, 2001)) as additional input for IE. $$$$$ When structures are composed, a hole in one structure (the semantic head) is filled with the hook of the other (by equating the variables) and their lzts are appended.
Given the fine-grained syntactic and semantic analysis of the HPSG grammar and its robustness (through SNLP integration), we decided to use the semantic representation (MRS, see (Copestake et al, 2001)) as additional input for IE. $$$$$ For instance, like(e, x, y) is a well-formed SEP.
Given the fine-grained syntactic and semantic analysis of the HPSG grammar and its robustness (through SNLP integration), we decided to use the semantic representation (MRS, see (Copestake et al, 2001)) as additional input for IE. $$$$$ Moore (1989) is also concerned with formalizing existing practice in unification grammars (see also Alshawi, 1992), though he assumes Prolog-style unification, rather than TFSs.

The semantic representations used are flat semantic representations in the sense of [Copestake et al, 2001] and the semantic parameters (that is, the semantic indices representing the missing arguments of the semantic functors) are represented by unification variables. $$$$$ We add to the model a set of labels L (handles denote these via g) and a wellfounded partial order G on L (this helps interpret the hcons; cf.
The semantic representations used are flat semantic representations in the sense of [Copestake et al, 2001] and the semantic parameters (that is, the semantic indices representing the missing arguments of the semantic functors) are represented by unification variables. $$$$$ We are grateful to Ted Briscoe, Alistair Knott and the anonymous reviewers for their comments on this paper.
The semantic representations used are flat semantic representations in the sense of [Copestake et al, 2001] and the semantic parameters (that is, the semantic indices representing the missing arguments of the semantic functors) are represented by unification variables. $$$$$ In both cases, x0e is both the external argument of expect and its subject’s index, but in the first structure x0e is also the external argument of the complement, thus giving the control effect. expect 1 (as in Kim expected to sleep) [he, ee, x0 e]{[hs, x0 e, x0 s]subj, [hc, ec, x0 e]comp1,..
The semantic representations used are flat semantic representations in the sense of [Copestake et al, 2001] and the semantic parameters (that is, the semantic indices representing the missing arguments of the semantic functors) are represented by unification variables. $$$$$ In MRS, labels called handles are associated with each EP.

Ge and Mooney (2009) extracts semantic representations using syntactic structures while Copestake et al (2001) develops algebras for semantic construction within grammars. $$$$$ Since the constraints need not be checked at runtime, it seems better to regard them as metalevel conditions on the description of the grammar, which can anyway easily be checked by code which converts the TFS into the algebraic representation.
Ge and Mooney (2009) extracts semantic representations using syntactic structures while Copestake et al (2001) develops algebras for semantic construction within grammars. $$$$$ In other words, [op(a1, a2)] = f([a1], [a2]) for some function f. Intuitively, where the SMRS of the SEMENT a1 denotes G1 and the SMRS of the SEMENT a2 denotes G2, we want the semantic value of the SMRS of op(a1, a2) to denote the following: G1 ∩ G2 ∩ [hook(a1) = hole(a2)] But this cannot be constructed purely as a function of G1 and G2.
Ge and Mooney (2009) extracts semantic representations using syntactic structures while Copestake et al (2001) develops algebras for semantic construction within grammars. $$$$$ .}

Recent work in semantic construction for HPSG (Copestake et al., 2001) supports our conjecture $$$$$ For instance, like(e, x, y) is a well-formed SEP.
Recent work in semantic construction for HPSG (Copestake et al., 2001) supports our conjecture $$$$$ We are grateful to Ted Briscoe, Alistair Knott and the anonymous reviewers for their comments on this paper.

The original Grammar Matrix consisted of types defining the basic feature geometry, types associated with Minimal Recursion Semantics (e.g., (Copestake et al, 2001)), types for lexical and syntactic rules, and configuration files for the LKB grammar development environment (Copestake, 2002) and the PET system (Callmeier,2000). $$$$$ He has to divorce the interpretation of the expressions from the notion of truth with respect to the model, which is much like treating the semantics as a description of a logic formula.
The original Grammar Matrix consisted of types defining the basic feature geometry, types associated with Minimal Recursion Semantics (e.g., (Copestake et al, 2001)), types for lexical and syntactic rules, and configuration files for the LKB grammar development environment (Copestake, 2002) and the PET system (Callmeier,2000). $$$$$ A SEMENT then denotes an element of H x ...H x P(G), where the Hs (= L x I) are the new hook and holes.
The original Grammar Matrix consisted of types defining the basic feature geometry, types associated with Minimal Recursion Semantics (e.g., (Copestake et al, 2001)), types for lexical and syntactic rules, and configuration files for the LKB grammar development environment (Copestake, 2002) and the PET system (Callmeier,2000). $$$$$ However, from the standpoint of the compositional semantics, the determiner is the semantic head, and it is only its SPEC hole which is involved: the N' must be treated as having an empty SPR hole.
The original Grammar Matrix consisted of types defining the basic feature geometry, types associated with Minimal Recursion Semantics (e.g., (Copestake et al, 2001)), types for lexical and syntactic rules, and configuration files for the LKB grammar development environment (Copestake, 2002) and the PET system (Callmeier,2000). $$$$$ The SEPs and EQs can be interpreted with respect to a first order model hE, A, Fi where: Definition 4 Denotations of SEMENTs If a =6 ⊥ is a SEMENT, [a]M = h[i], [i0], Gi where: The truth definition of the SEPs and EQs (which we group together under the term SMRS, for simple MRS) is as follows: Thus, with respect to a model M, an SMRS can be viewed as denoting an element of P(G), where G is the set of variable assignment functions (i.e., elements of G assign the variables e,... and x, .. . their denotations): [smrs]M = {g : g is a variable assignment function and M |=g smrs} We now consider the semantics of the algebra.

The Redwoods tree bank provides deeper semantics expressed in the Minimum Recursion Semantics formalism (Copestake et al, 2001), but in the present experiments we have not explored this fully. $$$$$ The full inventory of labels for the ERG is: SUBJ, SPR, SPEC, COMP1, COMP2, COMP3 and MOD (see Pollard and Sag, 1994).
The Redwoods tree bank provides deeper semantics expressed in the Minimum Recursion Semantics formalism (Copestake et al, 2001), but in the present experiments we have not explored this fully. $$$$$ Because the ERG is large and complex, we have not yet fully completed the exercise of retrospectively implementing the constraints throughout.

In future work we will compare our semantics construction principles to the general model of Copestake et al (2001). $$$$$ This research was partially supported by the National Science Foundation, grant number IRI9612682.
In future work we will compare our semantics construction principles to the general model of Copestake et al (2001). $$$$$ A SEMENT then denotes an element of H x ...H x P(G), where the Hs (= L x I) are the new hook and holes.
In future work we will compare our semantics construction principles to the general model of Copestake et al (2001). $$$$$ Type raising also adds to the complexity.
In future work we will compare our semantics construction principles to the general model of Copestake et al (2001). $$$$$ Furthermore, the range of op is within E. So (E, op) is an algebra.

The semantic interpretations are expressed using Minimal Recursion Semantics (MRS) (Copestake et al, 2001), which provides the means to represent interpretations with a flat, underspecified semantics using terms of the predicate calculus and generalized quantifiers. $$$$$ There will be similar operations opcomp1, opcomp2 etc for each labelled hole.
The semantic interpretations are expressed using Minimal Recursion Semantics (MRS) (Copestake et al, 2001), which provides the means to represent interpretations with a flat, underspecified semantics using terms of the predicate calculus and generalized quantifiers. $$$$$ For instance, Figure 1 shows representations of typed feature structures (TFSs) for Kim, sleeps and the phrase Kim sleeps, in an HPSG-like representation, loosely based on Sag and Wasow (1999).
The semantic interpretations are expressed using Minimal Recursion Semantics (MRS) (Copestake et al, 2001), which provides the means to represent interpretations with a flat, underspecified semantics using terms of the predicate calculus and generalized quantifiers. $$$$$ In §4 to §6, we generalize to the full algebra needed to capture the use of in the LinGO English Resource Grammar (ERG).

The grammar is couched in the theoretical framework of Head-Driven Phrase Structure Grammar (HPSG) (Pollard; Sag 1994), with semantic representations in Minimal Recursion Semantics (MRS) (Copestake et al 2001). $$$$$ A SEMENT then denotes an element of H x ...H x P(G), where the Hs (= L x I) are the new hook and holes.
The grammar is couched in the theoretical framework of Head-Driven Phrase Structure Grammar (HPSG) (Pollard; Sag 1994), with semantic representations in Minimal Recursion Semantics (MRS) (Copestake et al 2001). $$$$$ He has to divorce the interpretation of the expressions from the notion of truth with respect to the model, which is much like treating the semantics as a description of a logic formula.
The grammar is couched in the theoretical framework of Head-Driven Phrase Structure Grammar (HPSG) (Pollard; Sag 1994), with semantic representations in Minimal Recursion Semantics (MRS) (Copestake et al 2001). $$$$$ We now start considering the elaborations necessary for real grammars.
The grammar is couched in the theoretical framework of Head-Driven Phrase Structure Grammar (HPSG) (Pollard; Sag 1994), with semantic representations in Minimal Recursion Semantics (MRS) (Copestake et al 2001). $$$$$ This follows from the definitions of [], op and f.

Our method effectively performs automatic RMRS semantics construction from functional dependencies, following the semantic algebra of Copestake et al (2001). $$$$$ These operations can be proved to form an algebra (E, opsubj, opcomp1, .
Our method effectively performs automatic RMRS semantics construction from functional dependencies, following the semantic algebra of Copestake et al (2001). $$$$$ Compared with A-calculus, the approach to composition adopted in constraint-based grammars and formalized here has considerable advantages in terms of simplicity.
Our method effectively performs automatic RMRS semantics construction from functional dependencies, following the semantic algebra of Copestake et al (2001). $$$$$ We can assume that semantic composition always involves two arguments, since we can define composition in ternary rules etc as a sequence of binary operations.
Our method effectively performs automatic RMRS semantics construction from functional dependencies, following the semantic algebra of Copestake et al (2001). $$$$$ We have increased the generator’s reliability by making the ERG monotonic and we expect further improvements in practical performance once we take full advantage of the restrictions in the grammar to cut down the search space.

We show how to adapt the construction principles of the semantic algebra of Copestake et al (2001) to RMRS construction from dependencies in a rewrite scenario, and discuss the treatment of some special phenomena, such as verbal complementation, coordination and modification. $$$$$ In other words, [op(a1, a2)] = f([a1], [a2]) for some function f. Intuitively, where the SMRS of the SEMENT a1 denotes G1 and the SMRS of the SEMENT a2 denotes G2, we want the semantic value of the SMRS of op(a1, a2) to denote the following: G1 ∩ G2 ∩ [hook(a1) = hole(a2)] But this cannot be constructed purely as a function of G1 and G2.
We show how to adapt the construction principles of the semantic algebra of Copestake et al (2001) to RMRS construction from dependencies in a rewrite scenario, and discuss the treatment of some special phenomena, such as verbal complementation, coordination and modification. $$$$$ However, much of the work has been done and the process revealed many bugs in the grammar, which demonstrates the potential for enhanced maintainability.
We show how to adapt the construction principles of the semantic algebra of Copestake et al (2001) to RMRS construction from dependencies in a rewrite scenario, and discuss the treatment of some special phenomena, such as verbal complementation, coordination and modification. $$$$$ We can extend this to include (several) labelled holes and operations, as before.

For (R) MRS construction from dependencies we follow the algebra for semantics composition in Copestake et al (2001). $$$$$ We believe that the handle, index, external argument triple constitutes all the semantic information that a sign should make accessible to a functor.
For (R) MRS construction from dependencies we follow the algebra for semantics composition in Copestake et al (2001). $$$$$ The semantic representation expressed is intended to be equivalent to r name(x, Kim) ∧ sleep(e, x).1 Note: A similar approach has been used in a large number of implemented grammars (see Shieber (1986) for a fairly early example).
For (R) MRS construction from dependencies we follow the algebra for semantics composition in Copestake et al (2001). $$$$$ In fact, Nerbonne (1995) explicitly advocates nonmonotonicity.

Copestake et al (2001) mention a third feature to be included in the hook as an externally visible variable, which they instantiate with the index of the controlled subject in equi constructions and which is also used to implement the semantics of predicative modification. $$$$$ a hook and the second part and is the holes.
Copestake et al (2001) mention a third feature to be included in the hook as an externally visible variable, which they instantiate with the index of the controlled subject in equi constructions and which is also used to implement the semantics of predicative modification. $$$$$ We can now define the following operation f over these denotations to create an algebra: Definition 5 Semantics of the Semantic Construction Algebra where G0 = {g : g(i1) = g(i02)} And this operation demonstrates that semantic construction is compositional: Theorem 2 Semantics of Semantic Construction is Compositional The mapping [] : hΣ, opi −→ hhI, I, Gi, fi is a homomorphism (so [op(a1, a2)] = f([a1], [a2])).
Copestake et al (2001) mention a third feature to be included in the hook as an externally visible variable, which they instantiate with the index of the controlled subject in equi constructions and which is also used to implement the semantics of predicative modification. $$$$$ It should be intuitively obvious that there is a straightforward relationship between this algebra and the shown in Figure 1, although there are other architectures which would share the same encoding.

Otherwise, composition strictly follows the semantic operations of the algebra of Copestake et al (2001) $$$$$ .) in a similar way to the unlabelled case shown in Theorem 1.
Otherwise, composition strictly follows the semantic operations of the algebra of Copestake et al (2001) $$$$$ The fact that only these pieces of information are visible means, for instance, that it is impossible to define a verb that controls the object of its complement.7 Although obviously changes to the syntactic valence features would necessitate modification of the hole labels, we think it unlikely that we will need to increase the inventory further.
Otherwise, composition strictly follows the semantic operations of the algebra of Copestake et al (2001) $$$$$ It is in many ways easier to work with than A-calculus based approaches (which we discuss further below) and has the great advantage of allowing generalizations about the syntax-semantics interface to be easily expressed.

The algebra of Copestake et al (2001) defines modifiers to externalise the variable of the ARG1. $$$$$ To illustrate the way the formalization goes with multiple slots, consider opsubj: Definition 6 The definition of opsubj where Tr stands for transitive closure.
The algebra of Copestake et al (2001) defines modifiers to externalise the variable of the ARG1. $$$$$ The algebra with labelled holes is sufficient to deal with simple grammars, such as that in Sag and Wasow (1999), but to deal with scope, more is needed.
The algebra of Copestake et al (2001) defines modifiers to externalise the variable of the ARG1. $$$$$ Note for convenience we omit the set markers {} from the hook and hole when there is no possible confusion.
The algebra of Copestake et al (2001) defines modifiers to externalise the variable of the ARG1. $$$$$ The truth definition for SEMENTS is analogous to before.

In future research, we will investigate how the semantic algebra of Copestake et al (2001) compares to Glue Semantics (Dalrymple, 1999). $$$$$ The conditions in hcons are accumulated by append.
In future research, we will investigate how the semantic algebra of Copestake et al (2001) compares to Glue Semantics (Dalrymple, 1999). $$$$$ .
In future research, we will investigate how the semantic algebra of Copestake et al (2001) compares to Glue Semantics (Dalrymple, 1999). $$$$$ The standard Montague grammar approach requires that arguments be presented in a fixed order, and that they be strictly typed, which leads to unnecessary multiplication of predicates which then have to be interrelated by meaning postulates (e.g., the two uses of expect mentioned earlier).
In future research, we will investigate how the semantic algebra of Copestake et al (2001) compares to Glue Semantics (Dalrymple, 1999). $$$$$ This research was partially supported by the National Science Foundation, grant number IRI9612682.

The coincidence with Copestake et al.'s terminology (Copestake et al, 2001) is not casual; in fact, our formulation can be regarded as a decoupled fragment of theirs, since neither our holes involves syntactic labels nor are scopal issues ever touched. $$$$$ Theorem 1 op is a function If a1 = a3 and a2 = a4, then a5 = op(a1, a2) = op(a3, a4) = a6.
The coincidence with Copestake et al.'s terminology (Copestake et al, 2001) is not casual; in fact, our formulation can be regarded as a decoupled fragment of theirs, since neither our holes involves syntactic labels nor are scopal issues ever touched. $$$$$ We believe that the handle, index, external argument triple constitutes all the semantic information that a sign should make accessible to a functor.
The coincidence with Copestake et al.'s terminology (Copestake et al, 2001) is not casual; in fact, our formulation can be regarded as a decoupled fragment of theirs, since neither our holes involves syntactic labels nor are scopal issues ever touched. $$$$$ Compared with A-calculus, the approach to composition adopted in constraint-based grammars and formalized here has considerable advantages in terms of simplicity.
The coincidence with Copestake et al.'s terminology (Copestake et al, 2001) is not casual; in fact, our formulation can be regarded as a decoupled fragment of theirs, since neither our holes involves syntactic labels nor are scopal issues ever touched. $$$$$ The solution is to add hooks and holes to the denotations of SEMENTS (cf.

We use this parser to parse the defining sentences into a full meaning representation using minimal recursion semantics (MRS $$$$$ It enforces monotonic accumulation of EPs by making all rules append the EPs of their daughters (an approach which was followed by Sag and Wasow (1999)) but it does not fully spectics in TFSs d to other work on unification based grammar. and abstracts away from the specific feature architecture used in individual grammars, but the essential features of the algebra can be encoded in the hierarchy of lexical and constructional type constraints.
We use this parser to parse the defining sentences into a full meaning representation using minimal recursion semantics (MRS $$$$$ Alex Lascarides was supported by an ESRC (UK) research fellowship.
We use this parser to parse the defining sentences into a full meaning representation using minimal recursion semantics (MRS $$$$$ Furthermore the operations on the semantics are not tightly specified or constrained.
We use this parser to parse the defining sentences into a full meaning representation using minimal recursion semantics (MRS $$$$$ Type raising also adds to the complexity.

The output is written in Minimal Recursion Semantics (Copestake et al, 2001). $$$$$ There is the option of moving to a more general TFS logic but this would require very considerable research to develop reasonable tractability.
The output is written in Minimal Recursion Semantics (Copestake et al, 2001). $$$$$ Alex Lascarides was supported by an ESRC (UK) research fellowship.
The output is written in Minimal Recursion Semantics (Copestake et al, 2001). $$$$$ We now start considering the elaborations necessary for real grammars.
The output is written in Minimal Recursion Semantics (Copestake et al, 2001). $$$$$ It is in many ways easier to work with than A-calculus based approaches (which we discuss further below) and has the great advantage of allowing generalizations about the syntax-semantics interface to be easily expressed.

An MRS consists of a bag of labeled elementary predicates and their arguments, a list of scoping constraints, and a pair of relations that provide a hook into the representation - a label, which must outscope all the handles, and an index (Copestake et al, 2001). $$$$$ The fact that only these pieces of information are visible means, for instance, that it is impossible to define a verb that controls the object of its complement.7 Although obviously changes to the syntactic valence features would necessitate modification of the hole labels, we think it unlikely that we will need to increase the inventory further.
An MRS consists of a bag of labeled elementary predicates and their arguments, a list of scoping constraints, and a pair of relations that provide a hook into the representation - a label, which must outscope all the handles, and an index (Copestake et al, 2001). $$$$$ We have developed a framework for formally specifying semantics within constraint-based representations which allows semantic operations in a grammar to be tightly specified and which allows a representation of semantic content which is largely independent of the feature structure architecture of the syntactic representation.
An MRS consists of a bag of labeled elementary predicates and their arguments, a list of scoping constraints, and a pair of relations that provide a hook into the representation - a label, which must outscope all the handles, and an index (Copestake et al, 2001). $$$$$ In §4 to §6, we generalize to the full algebra needed to capture the use of in the LinGO English Resource Grammar (ERG).
