Niu et al (2009) also use the reranker (RP) of Charniak and Johnson (2005) as a stronger baseline, but the results are missing. $$$$$ This result is only slightly higher than the highest reported result for this test-set, Bod’s (.907) (Bod, 2003).
Niu et al (2009) also use the reranker (RP) of Charniak and Johnson (2005) as a stronger baseline, but the results are missing. $$$$$ Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000).
Niu et al (2009) also use the reranker (RP) of Charniak and Johnson (2005) as a stronger baseline, but the results are missing. $$$$$ In more detail, for each string s the n-best parsing algorithm described in section 2 returns the n highest probability parses Y(s) = {y1(s), ... , yn(s)} together with the probability p(y) of each parse y according to the parser’s probability model.
Niu et al (2009) also use the reranker (RP) of Charniak and Johnson (2005) as a stronger baseline, but the results are missing. $$$$$ Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000).

Features extracted from the output of three probabilistic parsers of English (Charniak and Johnson, 2005), one trained on Wall Street Journal trees (Marcus et al, 1993), one trained on a distorted version of the tree bank obtained by automatically creating grammatical error and adjusting the parse trees, and the third trained on the union of the original and distorted versions. $$$$$ The system we described here has an f-score of 0.91 when trained and tested using the standard PARSEVAL framework.
Features extracted from the output of three probabilistic parsers of English (Charniak and Johnson, 2005), one trained on Wall Street Journal trees (Marcus et al, 1993), one trained on a distorted version of the tree bank obtained by automatically creating grammatical error and adjusting the parse trees, and the third trained on the union of the original and distorted versions. $$$$$ E1 and E2 are parameters of this schema; here E1 = 1 or E1 = 2 and E2 = 1.
Features extracted from the output of three probabilistic parsers of English (Charniak and Johnson, 2005), one trained on Wall Street Journal trees (Marcus et al, 1993), one trained on a distorted version of the tree bank obtained by automatically creating grammatical error and adjusting the parse trees, and the third trained on the union of the original and distorted versions. $$$$$ In more detail, for each string s the n-best parsing algorithm described in section 2 returns the n highest probability parses Y(s) = {y1(s), ... , yn(s)} together with the probability p(y) of each parse y according to the parser’s probability model.
Features extracted from the output of three probabilistic parsers of English (Charniak and Johnson, 2005), one trained on Wall Street Journal trees (Marcus et al, 1993), one trained on a distorted version of the tree bank obtained by automatically creating grammatical error and adjusting the parse trees, and the third trained on the union of the original and distorted versions. $$$$$ The reranker attempts to select the best parse for a sentence from the 50-best list of possible parses for the sentence.

Reranking has been used in many tasks to find better global solutions, such as machine translation (Wang et al, 2007), parsing (Charniak and Johnson, 2005), and disfluency detection (Zwarts and Johnson, 2011). $$$$$ (s) for each sentence s in the training data.
Reranking has been used in many tasks to find better global solutions, such as machine translation (Wang et al, 2007), parsing (Charniak and Johnson, 2005), and disfluency detection (Zwarts and Johnson, 2011). $$$$$ He finds that total parsing time is greatly reduced.
Reranking has been used in many tasks to find better global solutions, such as machine translation (Wang et al, 2007), parsing (Charniak and Johnson, 2005), and disfluency detection (Zwarts and Johnson, 2011). $$$$$ The PETSc/TAO toolkit provides a variety of other optimization algorithms and flags for controlling convergence, but preliminary experiments on the Collins’ trees with different algorithms and early stopping did not show any performance improvements, so we used the default PETSc/TAO setting for our experiments here.

 $$$$$ Rather than storing a single best parse of each edge, one stores n of them.
 $$$$$ By “coarse-to-fine” we mean that it first produces a crude version of the parse using coarse-grained dynamic programming states, and then builds fine-grained analyses by splitting the most promising of coarse-grained states.
 $$$$$ Each yield or terminal string in the training, development and test data sets is mapped to such an n-best list of parse/probability pairs; the cross-validation scheme described in Collins (2000) was used to avoid training the n-best parser on the sentence it was being used to parse.
 $$$$$ More to the point, however, is that the system we describe is reasonably efficient so it can be used for the kind of routine parsing currently being handled by the Charniak or Collins parsers.

 $$$$$ The unpruned edges are then exhaustively evaluated according to the fine-grained probabilistic model; in effect, each coarse-grained dynamic programming state is split into one or more fine-grained dynamic programming states.
 $$$$$ The parameters to this schema control whether nodes are annotated with their preterminal heads, their terminal heads and their ancestors’ categories.

We parse the English sentences with the Charniak Parser (Charniak and Johnson, 2005), and tag the Chinese sentences with a POS tagger implemented faithfully according to (Collins, 2002) and trained on the Penn Chinese Treebank 5.0 (Xue et al., 2005). $$$$$ CoLenPar (22) The instances of this schema indicate the binned difference in length (in terms of number of preterminals dominated) in adjacent conjuncts in the same coordinated structures, conjoined with a boolean flag that indicates whether the pair is final in the coordinated phrase.
We parse the English sentences with the Charniak Parser (Charniak and Johnson, 2005), and tag the Chinese sentences with a POS tagger implemented faithfully according to (Collins, 2002) and trained on the Penn Chinese Treebank 5.0 (Xue et al., 2005). $$$$$ Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000).
We parse the English sentences with the Charniak Parser (Charniak and Johnson, 2005), and tag the Chinese sentences with a POS tagger implemented faithfully according to (Collins, 2002) and trained on the Penn Chinese Treebank 5.0 (Xue et al., 2005). $$$$$ This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000).
We parse the English sentences with the Charniak Parser (Charniak and Johnson, 2005), and tag the Chinese sentences with a POS tagger implemented faithfully according to (Collins, 2002) and trained on the Penn Chinese Treebank 5.0 (Xue et al., 2005). $$$$$ Neighbours (38,245) This schema classifies nodes by their category, their binned length, and the part of speech categories of the E1 preterminals to the node’s left and the $2 preterminals to the node’s right.

This is similar to the pruning described in Charniak and Johnson (2005) where edges in a coarse-grained parse forest are pruned to allow full evaluation with fine grained categories. $$$$$ The system we described here has an f-score of 0.91 when trained and tested using the standard PARSEVAL framework.
This is similar to the pruning described in Charniak and Johnson (2005) where edges in a coarse-grained parse forest are pruned to allow full evaluation with fine grained categories. $$$$$ We n-best trees f-score New 0.9102 Collins 0.9037 best trees, with weights estimated from sections 2– 21 and the regularizer constant c adjusted for optimal f-score on section 24 and evaluated on sentences of length less than 100 in section 23. trained the n-best parser on sections 2–21 of the Penn Treebank, and used section 24 as development data to tune the mixing parameters of the smoothing model.
This is similar to the pruning described in Charniak and Johnson (2005) where edges in a coarse-grained parse forest are pruned to allow full evaluation with fine grained categories. $$$$$ The system we described here has an f-score of 0.91 when trained and tested using the standard PARSEVAL framework.

 $$$$$ The results are presented in Table 3.
 $$$$$ A 91.0 f-score represents a 13% reduction in fmeasure error over the best of these parsers.2 Both the 50-best parser, and the reranking parser can be found at ftp://ftp.cs.brown.edu/pub/nlparser/, named parser and reranker respectively.

Standard state-of-the-art parsing systems (e.g., Charniak and Johnson, 2005) typically involve two passes. $$$$$ This method generates 50-best lists that are of substantially higher quality than previously obtainable.
Standard state-of-the-art parsing systems (e.g., Charniak and Johnson, 2005) typically involve two passes. $$$$$ The first feature f1(y) = log p(y) is the logarithm of the parse probability p according to the n-best parser model.
Standard state-of-the-art parsing systems (e.g., Charniak and Johnson, 2005) typically involve two passes. $$$$$ This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000).
Standard state-of-the-art parsing systems (e.g., Charniak and Johnson, 2005) typically involve two passes. $$$$$ We use a MaxEnt estimator to find the feature weights ˆ0, where L is the loss function and R is a regularization penalty term: The training data D = (s1, ... , sn,) is a sequence of sentences and their correct parses y?

We experimented with three scenarios; in two of them we trained using the gold standard trees and then tested on gold standard parse trees (GoldGold), and text annotated using a state-of-the-art statistical parser (Charniak and Johnson, 2005) (Gold Charniak), respectively. $$$$$ We use a MaxEnt estimator to find the feature weights ˆ0, where L is the loss function and R is a regularization penalty term: The training data D = (s1, ... , sn,) is a sequence of sentences and their correct parses y?
We experimented with three scenarios; in two of them we trained using the gold standard trees and then tested on gold standard parse trees (GoldGold), and text annotated using a state-of-the-art statistical parser (Charniak and Johnson, 2005) (Gold Charniak), respectively. $$$$$ CoPar (10) The instances of this schema indicate conjunct parallelism at various different depths.
We experimented with three scenarios; in two of them we trained using the gold standard trees and then tested on gold standard parse trees (GoldGold), and text annotated using a state-of-the-art statistical parser (Charniak and Johnson, 2005) (Gold Charniak), respectively. $$$$$ (s1), ... , y?(sn).
We experimented with three scenarios; in two of them we trained using the gold standard trees and then tested on gold standard parse trees (GoldGold), and text annotated using a state-of-the-art statistical parser (Charniak and Johnson, 2005) (Gold Charniak), respectively. $$$$$ A somewhat different take on this paradigm is seen in the parser we use in this paper.

 $$$$$ While our reranker does not achieve anything like the oracle f-score, the parses it selects do have an f-score of 91.0, which is considerably better than the maximum probability parses of the n-best parser.
 $$$$$ The reranker selects the best parse from this set of parses using a wide variety of features.
 $$$$$ A discriminative reranker requires a source of candidate parses for each sentence.

Charniak and Johnson (2005) showed accuracy improvements from composed local tree features on top of a lexicalized base parser. $$$$$ Because the reranker only has to consider a relatively small number of parses per sentences, it is not necessary to use dynamic programming, which permits the features to be essentially arbitrary functions of the parse trees.
Charniak and Johnson (2005) showed accuracy improvements from composed local tree features on top of a lexicalized base parser. $$$$$ Consider the secondbest parse: if it is to differ from the best parse, then at least one of its parsing decisions must be suboptimal.
Charniak and Johnson (2005) showed accuracy improvements from composed local tree features on top of a lexicalized base parser. $$$$$ Similarly, we trained the feature weights θ with the MaxEnt reranker on sections 2–21, and adjusted the regularizer constant c to maximize the f-score on section 24 of the treebank.

 $$$$$ The results are presented in Table 3.
 $$$$$ This section explains how we estimate the feature weights 0 = (01, ... , 0m) for the feature functions f = (f1, ... , fm).
 $$$$$ A discriminative reranker requires a source of candidate parses for each sentence.
 $$$$$ In more detail, for each string s the n-best parsing algorithm described in section 2 returns the n highest probability parses Y(s) = {y1(s), ... , yn(s)} together with the probability p(y) of each parse y according to the parser’s probability model.

We adapt the maximum entropy reranker from Charniak and Johnson (2005) by creating a customized feature extractor for event structures - in all other ways, the reranker model is unchanged. $$$$$ Similarly, we trained the feature weights θ with the MaxEnt reranker on sections 2–21, and adjusted the regularizer constant c to maximize the f-score on section 24 of the treebank.
We adapt the maximum entropy reranker from Charniak and Johnson (2005) by creating a customized feature extractor for event structures - in all other ways, the reranker model is unchanged. $$$$$ We n-best trees f-score New 0.9102 Collins 0.9037 best trees, with weights estimated from sections 2– 21 and the regularizer constant c adjusted for optimal f-score on section 24 and evaluated on sentences of length less than 100 in section 23. trained the n-best parser on sections 2–21 of the Penn Treebank, and used section 24 as development data to tune the mixing parameters of the smoothing model.
We adapt the maximum entropy reranker from Charniak and Johnson (2005) by creating a customized feature extractor for event structures - in all other ways, the reranker model is unchanged. $$$$$ This paper has described a dynamic programming n-best parsing algorithm that utilizes a heuristic coarse-to-fine refinement of parses.

To improve performance and robustness, features are pruned as in Charniak and Johnson (2005): selected features must distinguish a parse with the highest F1 score in a n-best list, from a parse with a suboptimal F1 score at least five times. $$$$$ As shown by Eisner (Eisner and Satta, 1999) the dynamic programming algorithms for bilexicalized PCFGs require O(m3) states, so a n-best parser would require O(nm3) states.
To improve performance and robustness, features are pruned as in Charniak and Johnson (2005): selected features must distinguish a parse with the highest F1 score in a n-best list, from a parse with a suboptimal F1 score at least five times. $$$$$ The PETSc/TAO toolkit provides a variety of other optimization algorithms and flags for controlling convergence, but preliminary experiments on the Collins’ trees with different algorithms and early stopping did not show any performance improvements, so we used the default PETSc/TAO setting for our experiments here.
To improve performance and robustness, features are pruned as in Charniak and Johnson (2005): selected features must distinguish a parse with the highest F1 score in a n-best list, from a parse with a suboptimal F1 score at least five times. $$$$$ Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000).

To train the classifiers, we used parse trees from the Charniak and Johnson (2005) parser with the same feature representation as in the original system. $$$$$ That is, when using dynamic programming, rather than throwing away a candidate if it scores less than the best, one keeps it if it is one of the top n analyses for this edge discovered so far.
To train the classifiers, we used parse trees from the Charniak and Johnson (2005) parser with the same feature representation as in the original system. $$$$$ NGramTree (291,909) The instances of this schema are subtrees rooted in the least common ancestor of E contiguous preterminal nodes.
To train the classifiers, we used parse trees from the Charniak and Johnson (2005) parser with the same feature representation as in the original system. $$$$$ The n-best parser’s most probable parses are already of state-of-the-art quality, but the reranker further improves the f-score.
To train the classifiers, we used parse trees from the Charniak and Johnson (2005) parser with the same feature representation as in the original system. $$$$$ A discriminative reranker requires a source of candidate parses for each sentence.

Other training algorithms include perceptron-style algorithms (Liang et al, 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al, 2005). $$$$$ Similarly, we trained the feature weights θ with the MaxEnt reranker on sections 2–21, and adjusted the regularizer constant c to maximize the f-score on section 24 of the treebank.
Other training algorithms include perceptron-style algorithms (Liang et al, 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al, 2005). $$$$$ We used the Limited Memory Variable Metric optimization algorithm from the PETSc/TAO optimization toolkit (Benson et al., 2004) to find the optimal feature weights θˆ because this method seems substantially faster than comparable methods (Malouf, 2002).
Other training algorithms include perceptron-style algorithms (Liang et al, 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al, 2005). $$$$$ We used these parses as the input to a MaxEnt reranker (Johnson et al., 1999; Riezler et al., 2002) that selects the best parse from the set of parses for each sentence, obtaining an f-score of 91.0% on sentences of length 100 or less.

We examined 100 sentences using a phrase structure parser (Charniak and Johnson, 2005) and HPSG parser (Miyao and Tsujii, 2005). $$$$$ The PETSc/TAO toolkit provides a variety of other optimization algorithms and flags for controlling convergence, but preliminary experiments on the Collins’ trees with different algorithms and early stopping did not show any performance improvements, so we used the default PETSc/TAO setting for our experiments here.
We examined 100 sentences using a phrase structure parser (Charniak and Johnson, 2005) and HPSG parser (Miyao and Tsujii, 2005). $$$$$ This section explains how we estimate the feature weights 0 = (01, ... , 0m) for the feature functions f = (f1, ... , fm).
We examined 100 sentences using a phrase structure parser (Charniak and Johnson, 2005) and HPSG parser (Miyao and Tsujii, 2005). $$$$$ Similarly, we trained the feature weights θ with the MaxEnt reranker on sections 2–21, and adjusted the regularizer constant c to maximize the f-score on section 24 of the treebank.
We examined 100 sentences using a phrase structure parser (Charniak and Johnson, 2005) and HPSG parser (Miyao and Tsujii, 2005). $$$$$ Consider the secondbest parse: if it is to differ from the best parse, then at least one of its parsing decisions must be suboptimal.

Given a tree pair (f, c), whose respective parses (pif ,pic) were generated by the parser described in (Charniak and Johnson, 2005), the goal is to transform the tree pair into SCFG derivations, in order to build relative frequency estimates for our Markovized models from observed SCFG productions. $$$$$ The major difficulty in n-best parsing, compared to 1-best parsing, is dynamic programming.
Given a tree pair (f, c), whose respective parses (pif ,pic) were generated by the parser described in (Charniak and Johnson, 2005), the goal is to transform the tree pair into SCFG derivations, in order to build relative frequency estimates for our Markovized models from observed SCFG productions. $$$$$ E1 and E2 are parameters of this schema; here E1 = 1 or E1 = 2 and E2 = 1.
Given a tree pair (f, c), whose respective parses (pif ,pic) were generated by the parser described in (Charniak and Johnson, 2005), the goal is to transform the tree pair into SCFG derivations, in order to build relative frequency estimates for our Markovized models from observed SCFG productions. $$$$$ Indeed, Collins’s n-best list of parses for section 24 of the Penn tree-bank has some sentences with only a single parse, because the n-best parser could not find any parses.

The table below shows results from our own measurements of Charniak parser1 (Charniak and Johnson, 2005) accuracy (F-measure on sentences of all lengths), which are consistent with these studies. $$$$$ We evaluated the performance of our reranking parser using the standard PARSEVAL metrics.
The table below shows results from our own measurements of Charniak parser1 (Charniak and Johnson, 2005) accuracy (F-measure on sentences of all lengths), which are consistent with these studies. $$$$$ A good example of this is the Roark parser (Roark, 2001) which works left-to right through the sentence, and abjures dynamic programming in favor of a beam search, keeping some large number of possibilities to extend by adding the next word, and then re-pruning.
